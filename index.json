[
{
	"uri": "/path-to-production/dev-environment/arp/",
	"title": "Access Request Portal",
	"tags": [],
	"description": "",
	"content": "Access Request There are two main resources to which you will need to request access before you can get far with the development of anything at The Home Depot.\n   Access Name Description     RSA Software Token Will grant access to set up and use an RSA token which you will need for various logins, such as VPN, and server on demand.   Github Grants access to Github Enterprise. GitHub Enterprise is the source code management repository used at The Home Depot.    Requesting Access Through the Access Request Portal (ARP) Almost all access is requested and granted through the Home Depot\u0026rsquo;s Access Request Portal (ARP)\nTo request access for your RSA Software Token and GitHub Enterprise access, follow these steps:\n  Navigate to https://accessrequestportal.homedepot.com\n  Login with your Home Depot LDAP and password\n  You should see the following screen after logging in:\n Click on the icon with the keys and disk and select Request for Self\n  Search For RSA software\n  Click Select All\n  Click `Add Selected to Cart``\n  Search for GITHUB\n  Click Select All\n  Click Add Selected to Cart\n  Click Next at the top of the screen.\n  Enter Justification in the text box, then click Submit\n  "
},
{
	"uri": "/application-security/api-security/",
	"title": "API Security",
	"tags": [],
	"description": "",
	"content": "Welcome to API Security In this workshop we will be discussing how to use OAuth2 and OpenID Connect for API Security The material is divided into multiple sections:\nPreFlight Checklist This section will help you prepare for the start of class. Please complete this prior to the start of class.\nSection 1: Service to Service API Security using OAuth2 This section will walk through the details of:\n OAuth2 JWT Tokens Service to Service Security  Section 2: Human to Service API Security using OpenID Connect (OIDC) This section will use the material from Section 1 and add on:\n OpenID Connect (OIDC) How OIDC expands OAuth2. Details of Human to Service The roles of entitlement groups Public vs Private Clients  Section 3: Where To From Here? This section will help you move to understand where to go from here.\n"
},
{
	"uri": "/path-to-production/before-you-build/",
	"title": "Before You Build",
	"tags": [],
	"description": "",
	"content": "Objectives In order to get to production and complete some of the development steps, there are a few things you need to do and or be aware of.\nOnce complete, you should be able to:\n Understanding of what a 12 factor app is, and why this should influence how you design and build our app Request a Sub-experience Get started with the ASA  Index "
},
{
	"uri": "/react/foundations/misc/build-a-complete-react-app/",
	"title": "Build a Complete React App",
	"tags": [],
	"description": "",
	"content": "Concepts  Use Component Composition (stateful and presentational components) Work with the React useEffect hook to fetch data from an API Work with react-router to create routes and navigate between views  Introduction Now that we have covered all of the fundamentals of React, we are going to build a complete client-side application that makes use of the following:\n useState and useEffect hooks for managing component state and side-effects react-router to create navigation between components axios for dispatching HTTP requests to a RESTful API server css modules for styling  For our application we are going to build a budget app that can track credits and debits and calculate a balance.\nStep 1 - Create the Project and add Dependencies Use create-react-app to create the new project:\nnpx create-react-app budget-app cd budget-app We will need to add the following dependencies:\n react-router-dom axios for making calls to a server json-server to create a RESTful API server that persists our data to a JSON file.   NOTE: json-server is not recommended for production use but it is a nice tool for getting a quick RESTful API server running for demo and testing purposes. You can read more about json-server at Getting Started | json-server.\n Let\u0026rsquo;s install these dependencies:\nyarn add react-router-dom axios json-server Step 2 - Configuring json-server json-server will persist data to a file called db.json. To get started, we will need an initial db.json file with some data.\nCreate the db.json file:\ntouch db.json Now edit db.json and add the following to the file:\n{ \u0026#34;accounts\u0026#34;: [ { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;checking\u0026#34;, \u0026#34;startingBalance\u0026#34;: 100.00 }, { \u0026#34;id\u0026#34;: 2, \u0026#34;name\u0026#34;: \u0026#34;savings\u0026#34;, \u0026#34;startingBalance\u0026#34;: 500.00 } ], \u0026#34;transactions\u0026#34;: [ { \u0026#34;id\u0026#34;: 1, \u0026#34;accountId\u0026#34;: 1, \u0026#34;item\u0026#34;: \u0026#34;lunch\u0026#34;, \u0026#34;amount\u0026#34;: 8.00, \u0026#34;type\u0026#34;: \u0026#34;debit\u0026#34; }, { \u0026#34;id\u0026#34;: 2, \u0026#34;accountId\u0026#34;: 1, \u0026#34;item\u0026#34;: \u0026#34;birthday money\u0026#34;, \u0026#34;amount\u0026#34;: 100.00, \u0026#34;type\u0026#34;: \u0026#34;credit\u0026#34; }, { \u0026#34;id\u0026#34;: 3, \u0026#34;accountId\u0026#34;: 1, \u0026#34;item\u0026#34;: \u0026#34;new shoes\u0026#34;, \u0026#34;amount\u0026#34;: 45.00, \u0026#34;type\u0026#34;: \u0026#34;debit\u0026#34; }, { \u0026#34;id\u0026#34;: 4, \u0026#34;accountId\u0026#34;: 2, \u0026#34;item\u0026#34;: \u0026#34;balance transfer\u0026#34;, \u0026#34;amount\u0026#34;: 200.00, \u0026#34;type\u0026#34;: \u0026#34;debit\u0026#34; }, { \u0026#34;id\u0026#34;: 5, \u0026#34;accountId\u0026#34;: 2, \u0026#34;item\u0026#34;: \u0026#34;interest earned\u0026#34;, \u0026#34;amount\u0026#34;: 2.00, \u0026#34;type\u0026#34;: \u0026#34;credit\u0026#34; } ] } We will be running the json-server on port 4000 and based on the data above we will have 2 RESTful endpoints:\n http://localhost:4000/accounts http://localhost:4000/transactions  Let\u0026rsquo;s add a script to the package.json file for starting up our json-server:\n\u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;react-scripts start\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;react-scripts build\u0026#34;, \u0026#34;test\u0026#34;: \u0026#34;react-scripts test\u0026#34;, \u0026#34;eject\u0026#34;: \u0026#34;react-scripts eject\u0026#34;, \u0026#34;server\u0026#34;: \u0026#34;yarn json-server -w -p 4000 --delay 500 db.json\u0026#34; \u0026lt;-- add this line }, Let\u0026rsquo;s test out the server:\nyarn server Now you can use cURL (in a separate Terminal session) to test a server route:\ncurl localhost:4000/accounts You should see the following output\n[ { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;checking\u0026#34;, \u0026#34;startingBalance\u0026#34;: 100 }, { \u0026#34;id\u0026#34;: 2, \u0026#34;name\u0026#34;: \u0026#34;savings\u0026#34;, \u0026#34;startingBalance\u0026#34;: 500 } ] And likewise for the transactions:\ncurl localhost:4000/transactions You should see the following output\n[ { \u0026#34;id\u0026#34;: 1, \u0026#34;accountId\u0026#34;: 1, \u0026#34;item\u0026#34;: \u0026#34;lunch\u0026#34;, \u0026#34;amount\u0026#34;: 8, \u0026#34;type\u0026#34;: \u0026#34;debit\u0026#34; }, { \u0026#34;id\u0026#34;: 2, \u0026#34;accountId\u0026#34;: 1, \u0026#34;item\u0026#34;: \u0026#34;birthday money\u0026#34;, \u0026#34;amount\u0026#34;: 100, \u0026#34;type\u0026#34;: \u0026#34;credit\u0026#34; }, { \u0026#34;id\u0026#34;: 3, \u0026#34;accountId\u0026#34;: 1, \u0026#34;item\u0026#34;: \u0026#34;new shoes\u0026#34;, \u0026#34;amount\u0026#34;: 45, \u0026#34;type\u0026#34;: \u0026#34;debit\u0026#34; }, { \u0026#34;id\u0026#34;: 4, \u0026#34;accountId\u0026#34;: 2, \u0026#34;item\u0026#34;: \u0026#34;balance transfer\u0026#34;, \u0026#34;amount\u0026#34;: 200, \u0026#34;type\u0026#34;: \u0026#34;debit\u0026#34; }, { \u0026#34;id\u0026#34;: 5, \u0026#34;accountId\u0026#34;: 2, \u0026#34;item\u0026#34;: \u0026#34;interest earned\u0026#34;, \u0026#34;amount\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;credit\u0026#34; } ] You can leave the json-server running for now. It will both read and write to the db.json file and update it with changes sent via HTTP PUT, POST, PATCH, and DELETE requests.\nStep 3 - Creating a Navbar We will use a Navbar to navigate between the following routes:\n , - our \u0026ldquo;Home\u0026rdquo; route that shows a friendly greeting message /accounts - displays a list of accounts and their balances  Let\u0026rsquo;s create the Navbar component and CSS file:\nmkdir src/components mkdir src/components/navbar touch src/components/navbar/Navbar.jsx touch src/components/navbar/Navbar.module.css Add the following code to Navbar.jsx:\nimport React from \u0026#39;react\u0026#39; import classes from \u0026#39;./Navbar.module.css\u0026#39; import { NavLink } from \u0026#39;react-router-dom\u0026#39; function Navbar() { return ( \u0026lt;nav className={classes.navbar}\u0026gt; \u0026lt;NavLink exact to=\u0026#34;/\u0026#34; activeClassName={classes.active}\u0026gt;Home\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/accounts\u0026#34; activeClassName={classes.active}\u0026gt;Accounts\u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; ) } export default Navbar We can style the Navbar by adding the following content to Navbar.module.css:\n.navbar { background: black; padding: 20px; color: white; height: 20px; width: 100%; text-align: center; } .navbar a { color: white; margin-right: 2em; margin-top: 30px; font-size: 1.125em; text-decoration: none; } .navbar .active { text-decoration: underline; } Now we will want to edit App.js to display the Navbar and configure the two routes. First let\u0026rsquo;s move the App component\u0026rsquo;s source, test, and css files into a src/components/app folder to keep our project nice and organized:\nmkdir src/components/app mv src/App.js src/components/app/App.jsx mv src/App.css src/components/app/App.module.css mv src/App.test.js src/components/app/App.test.js  NOTE: We have changed the extension of App.js to App.jsx to reflect that the file contains JSX code. Projects created with create-react-app can use either .js or .jsx for the extension.\n Change the contents of App.jsx to the following:\nimport React from \u0026#39;react\u0026#39; import { BrowserRouter as Router } from \u0026#39;react-router-dom\u0026#39; import Navbar from \u0026#39;./navbar/Navbar\u0026#39; import classes from \u0026#39;./App.module.css\u0026#39; function App() { return ( \u0026lt;Router\u0026gt; \u0026lt;div className={classes.app}\u0026gt; \u0026lt;Navbar /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/Router\u0026gt; ) } export default App You will also need to update the import statement in the src/index.js file to be:\nimport App from \u0026#39;./components/app/App\u0026#39;; At this point you should be able to see the Navbar when you navigate your browser to http://localhost:3000/. Clicking on the Navbar links should change the browser\u0026rsquo;s URL.\nStep 4 - Adding the HomeView and AccountsView Components Next we will create the components, routes, and navlinks for two views:\n HomeView will display a simple greeting message. AccountsView will display a list of accounts and their balances.  Let\u0026rsquo;s create the folders and files for the HomeView and AccountsView components.\nmkdir src/components/home touch src/components/home/HomeView.jsx touch src/components/home/Home.module.css mkdir src/components/accounts touch src/components/accounts/AccountsView.jsx touch src/components/accounts/Accounts.module.css Edit src/components/home/HomeView.jsx and add the following contents:\nimport React from \u0026#39;react\u0026#39;; import classes from \u0026#39;./home.module.css\u0026#39; function HomeView() { return ( \u0026lt;div className={classes.container}\u0026gt; \u0026lt;h1\u0026gt;Welcome to the React Budget App\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; ) } export default HomeView For src/components/home/Home.module.css you can use the following:\n.container { text-align: center; } For src/components/accounts/AccountsView.jsx you can add the following:\nimport React from \u0026#39;react\u0026#39;; import classes from \u0026#39;./Accounts.module.css\u0026#39; function AccountsView() { return ( \u0026lt;div className={classes.container}\u0026gt; \u0026lt;h1\u0026gt;Accounts\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; ) } export default AccountsView And for src/components/accounts/Accounts.module.css:\n.container { text-align: center; } .link { text-decoration: none; } Finally we need to add the Routes to App.jsx:\nimport React from \u0026#39;react\u0026#39; import { BrowserRouter as Router, Switch, Route } from \u0026#39;react-router-dom\u0026#39; import Navbar from \u0026#39;./navbar/Navbar\u0026#39; import HomeView from \u0026#39;./home/HomeView\u0026#39; import AccountsView from \u0026#39;./accounts/AccountsView\u0026#39; import classes from \u0026#39;./App.module.css\u0026#39; function App() { return ( \u0026lt;Router\u0026gt; \u0026lt;div className={classes.app}\u0026gt; \u0026lt;Navbar /\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route exact path=\u0026#34;/\u0026#34; component={HomeView} /\u0026gt; \u0026lt;Route path=\u0026#39;/accounts\u0026#39; component={AccountsView} /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/Router\u0026gt; ) } export default App You should now be able to navigate between these routes using the Navbar and see the Home and Accounts views.\nStep 5 - Display Accounts in the AccountsView In this step we will fetch the accounts data from the server and display the accounts and their balances in the AccountsView component. Specifically we will:\n fetch the accounts and transactions data using the useEffect hook and the axios library store the accounts and transactions data using the useState hook  Here is the code for the AccountsView component:\nimport React, { useEffect, useState } from \u0026#39;react\u0026#39; import axios from \u0026#39;axios\u0026#39; import classes from \u0026#39;./Accounts.module.css\u0026#39; function AccountsView() { const [accounts, setAccounts] = useState([]) const [transactions, setTransactions] = useState([]) async function getServerData() { const [accountsResponse, transactionsResponse] = await Promise.all([ axios.get(\u0026#39;http://localhost:4000/accounts\u0026#39;), axios.get(\u0026#39;http://localhost:4000/transactions\u0026#39;) ]) setAccounts(accountsResponse.data) setTransactions(transactionsResponse.data) } useEffect(() =\u0026gt; { getServerData() }, []) const accountsJsx = accounts.map(a =\u0026gt; { const balance = transactions .filter(t =\u0026gt; t.accountId === a.id) .reduce((acc, t) =\u0026gt; t.type === \u0026#39;credit\u0026#39; ? acc + t.amount : acc - t.amount, a.startingBalance) return ( \u0026lt;\u0026gt; \u0026lt;dt\u0026gt;{a.name}\u0026lt;/dt\u0026gt; \u0026lt;dd\u0026gt;${balance}\u0026lt;/dd\u0026gt; \u0026lt;/\u0026gt; ) }) return ( \u0026lt;div className={classes.container}\u0026gt; \u0026lt;h1\u0026gt;Accounts\u0026lt;/h1\u0026gt; \u0026lt;dl\u0026gt; {accountsJsx} \u0026lt;/dl\u0026gt; \u0026lt;/div\u0026gt; ) } export default AccountsView  NOTE: We are using Promise.all to fetch data from two RESTful endpoints concurrently. This can improve performance as it leverages the asynchronous behavior of JavaScript I/O operations.\n For Accounts.module.css you can set the contents to:\n.container { margin: 0 auto; width: 100%; text-align: center; } .container dl { border-radius: 5px; padding: 0.5em; width: 200px; margin: auto; } .container dt { float: left; clear: left; width: 100px; text-align: right; font-weight: bold; color: #a0a0a0; } .container dt::after { content: \u0026#39;:\u0026#39;; } .container dd { margin: 0 0 0 110px; padding: 0 0 0.5em 0; } Step 6 - Display Transactions In this step we will add a dynamic nested route for displaying the transactions for a specific account. Thus clicking on an account will trigger the nested route to be rendered with a table containing the transactions for that account.\nFirst let\u0026rsquo;s add the NavLink to the AccountsView component so that we can click on an account and trigger the nested route.\nChange the accountsJsx expression to the following (which adds the NavLinks):\nconst accountsJsx = accounts.map(a =\u0026gt; { const balance = transactions .filter(t =\u0026gt; t.accountId === a.id) .reduce((acc, t) =\u0026gt; t.type === \u0026#39;credit\u0026#39; ? acc + t.amount : acc - t.amount, a.startingBalance) return ( \u0026lt;NavLink key={a.id} className={classes.link} to={`${match.url}/${a.id}`}\u0026gt; \u0026lt;dt\u0026gt;{a.name}\u0026lt;/dt\u0026gt; \u0026lt;dd\u0026gt;${balance}\u0026lt;/dd\u0026gt; \u0026lt;/NavLink\u0026gt; ) }) You will also need to add some imports and define match near the top of the AccountsView function:\nimport { NavLink, Route, useRouteMatch } from \u0026#39;react-router-dom\u0026#39; ... const match = useRouteMatch() Now let\u0026rsquo;s add a nested Route for rendering the AccountDetail component when we click on an Account. Edit the AccountsView.jsx file and add the following just after the \u0026lt;/dl\u0026gt;:\n\u0026lt;Route path=\u0026#39;/accounts/:id\u0026#39; render={props =\u0026gt; { const { id } = props.match.params const account = accounts.find(a =\u0026gt; a.id === Number(id)) const accountTransactions = transactions.filter(t =\u0026gt; t.accountId === account.id) || [] return account ? \u0026lt;AccountDetail account={account} transactions={accountTransactions} /\u0026gt; : null }} /\u0026gt; Next we will create the AccountDetail component and matching CSS file:\ntouch src/components/accounts/AccountDetail.jsx touch src/components/accounts/AccountDetail.module.css Edit the AccountDetail.jsx file and add the following:\nimport React from \u0026#39;react\u0026#39; import classes from \u0026#39;./AccountDetail.module.css\u0026#39; function AccountDetail({ account, transactions }) { let balance = account.startingBalance const transactionList = transactions.map(t =\u0026gt; { balance = t.type === \u0026#39;credit\u0026#39; ? balance + t.amount : balance - t.amount return ( \u0026lt;tr key={t.id}\u0026gt; \u0026lt;td\u0026gt;{t.item}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{t.type}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${t.amount}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${balance}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; ) }) return ( \u0026lt;div className={classes.container}\u0026gt; \u0026lt;h1\u0026gt;{account.name}\u0026lt;/h1\u0026gt; \u0026lt;table className={classes.transactions}\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Item\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Type\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Amount\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Balance\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; {transactionList} \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt; ) } export default AccountDetail For AccountDetail.module.css add the following:\n.transactions { margin: auto; width: 600px; border-collapse: collapse; } table { border-collapse: collapse; } .container table, th, td { border: 1px solid grey; } .container th, td { padding: 10px; } Finally add the following import to AccountsView.jsx:\nimport AccountDetail from \u0026#39;./AccountDetail\u0026#39; and add the following to the Accounts.module.css file:\n.link { text-decoration: none; } Your application is now code complete!\nTest it out in the browser and see if everything is working.\nSummary In this exercise we have created a simple Budget application that:\n composes multiple React components together manages the state using useState fetches data from a RESTful API using the useEffect hook and the axios library uses Routes and NavLinks to navigate between views uses css modules for styling  Hopefully this gives you a better understanding of how these features of React and React Router work together to build complete applications.\nBonus  Try adding a form for adding credits and debits. You can use axios.post to post the new transactions to the json-server. Make sure that the account balances are updated after posting a new transaction.  Bonus Solution Step 7 - Add a NewTransaction Component For now we will just stub out this component so that we can test our routing. In a later step we will add the full implementation.\nCreate the files for the NewTransaction component:\nmkdir src/components/transactions touch src/components/transactions/NewTransactionView.jsx touch src/components/transactions/transactions.module.css For the NewTransactionView.jsx add the stub code. We will come back and add more code later.\nimport React from \u0026#39;react\u0026#39; import classes from \u0026#39;./transactions.module.css\u0026#39; function NewTransactionView() { return ( \u0026lt;div className={classes.container}\u0026gt; \u0026lt;h1\u0026gt;New Transaction\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; ) } export default NewTransactionView Step 8 - Add a NavLink and a new Route for Adding a Transaction Add a NavLink to the Navbar Component:\n\u0026lt;NavLink to=\u0026#34;/new-transaction\u0026#34; activeClassName={classes.active}\u0026gt;NewTransaction\u0026lt;/NavLink\u0026gt; Add the Route to App.jsx and remember to import the NewTransaction component:\nimport NewTransactionView from \u0026#39;./transactions/NewTransactionView\u0026#39; ... \u0026lt;Route path=\u0026#39;/new-transaction\u0026#39; component={NewTransactionView} /\u0026gt; For the transactions.module.css file, add the following:\n.container { margin: 0 auto; width: 100%; text-align: center; } .account select { padding: 8px 10px; width: 200px; } .txnType { margin: 20px auto; padding: 10px; } .txnItem input { font-size: 1rem; margin: 10px; } .txnAmount input { font-size: 1rem; margin: 10px; } Now you should be able to test out the added NavLink, Route, and NewTransaction component.\nStep 9 - Implement the NewTransactionView Component Let\u0026rsquo;s add a form to the NewTransactionView component for creating new transactions. Put the following in the NewTransactionView.jsx file:\nimport React, { useEffect, useState } from \u0026#39;react\u0026#39; import axios from \u0026#39;axios\u0026#39; import classes from \u0026#39;./transactions.module.css\u0026#39; // a component for selecting an account function SelectAccount({ accounts, setAccount }) { const options = accounts.map(a =\u0026gt; ( \u0026lt;option key={a.id} value={a.id}\u0026gt;{a.name}\u0026lt;/option\u0026gt; )) const placeholderOption = \u0026lt;option value=\u0026#34;\u0026#34; disabled selected\u0026gt;Select an account\u0026lt;/option\u0026gt; options.unshift(placeholderOption) return ( \u0026lt;section className={classes.account}\u0026gt; \u0026lt;select id=\u0026#34;account\u0026#34; name=\u0026#34;account\u0026#34; onChange={e =\u0026gt; setAccount(e.target.value)}\u0026gt; {options} \u0026lt;/select\u0026gt; \u0026lt;/section\u0026gt; ) } // a component for selecting the transaction type (\u0026#39;credit\u0026#39; or \u0026#39;debit\u0026#39;) function SelectTxnType({ type, setType }) { return ( \u0026lt;section className={classes.txnType}\u0026gt; \u0026lt;label\u0026gt; \u0026lt;input type=\u0026#34;radio\u0026#34; value=\u0026#34;credit\u0026#34; checked={type === \u0026#39;credit\u0026#39;} onChange={e =\u0026gt; setType(e.target.value)} /\u0026gt;Credit \u0026lt;/label\u0026gt; \u0026lt;label\u0026gt; \u0026lt;input type=\u0026#34;radio\u0026#34; value=\u0026#34;debit\u0026#34; checked={type === \u0026#39;debit\u0026#39;} onChange={e =\u0026gt; setType(e.target.value)} /\u0026gt;Debit \u0026lt;/label\u0026gt; \u0026lt;/section\u0026gt; ) } // a component for entering the item / description function InputItem({ item, setItem }) { return ( \u0026lt;section className={classes.txnItem}\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Enter Description\u0026#34; value={item} onChange={e =\u0026gt; setItem(e.target.value)} /\u0026gt; \u0026lt;/section\u0026gt; ) } // a component for entering the transaction amount function InputAmount({ amount, setAmount }) { return ( \u0026lt;section className={classes.txnAmount}\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Enter Amount\u0026#34; value={amount} onChange={e =\u0026gt; setAmount(e.target.value)} /\u0026gt; \u0026lt;/section\u0026gt; ) } // our main component that composes the above components and manages state and side-effects function NewTransactionView() { const [accounts, setAccounts] = useState([]) const [txnAccountId, setTxnAccountId] = useState(null) const [txnItem, setTxnItem] = useState(\u0026#39;\u0026#39;) const [txnType, setTxnType] = useState(\u0026#39;debit\u0026#39;) const [txnAmount, setTxnAmount] = useState(\u0026#39;\u0026#39;) useEffect(() =\u0026gt; { async function getAccounts() { const response = await axios.get(\u0026#39;http://localhost:4000/accounts\u0026#39;) setAccounts(response.data) } getAccounts() }, []) function showMessage(message) { alert(message) } async function onSubmit(e) { e.preventDefault(); console.log(`You entered: ${txnAccountId}, ${txnType}, ${txnItem}, ${txnAmount}`) const response = await axios.post(\u0026#39;http://localhost:4000/transactions\u0026#39;, { accountId: Number(txnAccountId), item: txnItem, type: txnType, amount: Number(txnAmount) }) console.log(response.data) showMessage(`Transaction added: ${txnType}of $${txnAmount}for ${txnItem}on account ${txnAccountId}.`) clearForm() } function clearForm() { setTxnAccountId(\u0026#39;\u0026#39;) setTxnItem(\u0026#39;\u0026#39;) setTxnType(\u0026#39;debit\u0026#39;) setTxnAmount(\u0026#39;\u0026#39;) } function isFormValid() { console.log(\u0026#39;isFormValid\u0026#39;) if (!txnAccountId) { console.log(\u0026#39;txnAccountID not set\u0026#39;) return false } if (!txnItem) { return false; } if (!txnAmount) { console.log(\u0026#39;txnAmount not set\u0026#39;) return false } if (isNaN(txnAmount)) { console.log(\u0026#39;txnAmount is not a number\u0026#39;) return false } return true } return ( \u0026lt;div className={classes.container}\u0026gt; \u0026lt;h1\u0026gt;New Transaction\u0026lt;/h1\u0026gt; \u0026lt;form onSubmit={onSubmit}\u0026gt; \u0026lt;SelectAccount accounts={accounts} setAccount={setTxnAccountId} /\u0026gt; \u0026lt;SelectTxnType type={txnType} setType={setTxnType} /\u0026gt; \u0026lt;InputItem item={txnItem} setItem={setTxnItem} /\u0026gt; \u0026lt;InputAmount amount={txnAmount} setAmount={setTxnAmount} /\u0026gt; \u0026lt;section\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34; disabled={!isFormValid()}\u0026gt;Add\u0026lt;/button\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; ) } export default NewTransactionView Wow, that\u0026rsquo;s a lot of code, but that is the nature of doing HTML forms. The above form includes:\n form validation controlled inputs (setting the value and onChange handler) helper components for user input: SelectAccount, SelectTxnType, InputItem, and InputAmount   TIP: The user input \u0026ldquo;helper\u0026rdquo; components are used here to better organize the code. They could (and perhaps should) be refactored into separate files for testing and for reusability. You can always put multiple components into a single source file but typically only one component is exported.\n Final Summary Congratulations! You made it all the way through.\nIt may seem like a lot of code but each step is fairly straightforward once you understand the building blocks that go into a full application.\n"
},
{
	"uri": "/path-to-production/cicd/concourse-setup/",
	"title": "Concourse Setup",
	"tags": [],
	"description": "",
	"content": "Objectives Outline the steps to getting a basic Concourse CICD server set up.\n Pre Requisites You will need to have the following done before you can request a concourse server:\n  RSA Token\n  Github Access\n  Access to your PCF Org and space (if setting up a proxy for your concourse server)\n  Credential Store Options\n If you intend on setting up your Concourse server with Vault to store credentials, please follow this guide before moving on.\n  Proxy Name Because concourse servers expire every 60 days, it is a good idea to set up a proxy for your concourse server. This will allow you to share a consistent URL to your pipeline and only rquire an update in a single location.\nYou\u0026rsquo;ll want to have your concourse server generated before you deploy the proxy, but as part of the configuration process you will want to know the name (url) that will be used when the proxy is pushed to Cloud Foundry.\nCome up with a name, such as:\n ci-myapp ci-myorg  If you chose ci-myapp as your name, then your url will be ci-myapp.apps-np.homedepot.com. Because routes within a foundation must be unique, you will want to see if your route is available.\nDetermining URL Availability\n  Go to the CF API GraphQL page.\n  On the left hand side, paste in the query below, changing the text YOUR-NAME to the name you chose.\n{ routes(host: \u0026#34;YOUR-NAME\u0026#34;){ space{ name organization{ name } } } }   Press the play button to submit the query\n  If the route is not taken, you should receive the following response:\n{ \u0026#34;data\u0026#34;: { \u0026#34;routes\u0026#34;: [] } }    5. If you get back information showing a space and an org, then that means the route is registered to something there already. --- ## Enterprise Github Configuration Concourse will authorize team members using GitHub's OAuth flow. You will need to configure Github to allow this. 1. Navigate to your Github Org on [Enterprise Github](https://github.homedepot.com) 2. Click the \u0026quot;Settings\u0026quot; tab. **Note:** If you do not have access, you will need someone who does to do the following steps, or have them grant you access. 3. Under Developer settings, click \u0026quot;OAuth Apps\u0026quot; ![](/path-to-production/oautapp.png) 4. Fill out the **Register a new OAuth application** form. | Name| Description| Example | | -------------------------- | ------------------------------------------------------------ | ---------------------------------------------------------- | | Application name | A name to describe your concourse server as an app | MyApp CI Server | | Homepage URL | The url for your server. Use the proxy name you came up with here. | https://ci-myapp.apps-np.homedepot.com | | Application description | describe the app | | | Authorization callback URL | Your proxy url with `/auth/github/callback` attached to it. \u0026lt;br/\u0026gt; If you chose not to use a proxy, you will need to hold off on this step until you've created your server.\u0026lt;br/\u0026gt; The server name will need to be updated whenever you request a new server. | https://ci-myapp.apps-np.homedepot.com/auth/github/callback \u0026lt;br /\u0026gt; **No proxy:** http://ld12345.homedepot.com/auth/github/callback| 5. Click the **Register application** button **Example Form:** ![](/path-to-production/filledout.png) --- ## Requesting a Concourse Server 1. Navigate to [Server on Demand](https://server.homedepot.com) 2. Using your THD user/pass (ldap) and RSA token login ![](/path-to-production/cblogin.png) 3. If not already there, navigate to the [catalog](https://server.homedepot.com/catalog/) 4. Find the **Concourse w/ GHE Auth - U16** and click on it ![](/path-to-production/concoursetile.png) 5. Follow the steps listed in the **Server Setup** section 6. It can take several minutes for your server to be created. Once it is ready, you will get an email with the name of your server. The name of your server will be something similar to `ld12345`. 7. You should be able to navigate to your concourse server by using the name + `.homedepot.com` **Example**: `http://ld12345.homedepot.com ` **Note**: You will be unable to log in at this point if you configured your GitHub OAuth app with a proxy endpoint. 8. If you choose not to use a proxy, use the name that was generated to complete the `GitHub` set-up. ## Completing the Proxy Setup Once your server is created, you will use the name from the email to configure your proxy. ### Configure the Proxy App 1. Clone the cf-nginx-proxy `git clone https://github.homedepot.com/ci-cd/cf-nginx-proxy.git` 2. Navigate into the `cf-nginx-proxy` directory 3. Open the `manifest.yml` in an editor of your choice 4. Replace `ci-examples` with the proxy name you chose. 5. Replace the PROXY_DEST value with the name of your concourse server and save the file. **Example**: If your concourse server is `ld12345` and the proxy name you chose is `ci-myapp`, then the `manifest.yml` should look like this: ```yaml --- applications: - name: ci-myapp buildpack: nginx_buildpack memory: 64m disk_quota: 64m env: PROXY_DEST: ld12345.homedepot.com Pushing your Proxy App In the directory where you cloned cf-nginx-proxy:\n Login to the PCF np foundation. cf login -a https://api.run-np.homedepot.com  Enter your username and password Select the org/space in which you would like your proxy app to be deployed. Push! cf push  Next Steps Getting The Fly CLI\n  Navigate to your concourse server either by the proxy link or the server name link.\n  Look for the following icons ( current version has them at the bottom right of the page )\n  Click the Icon for your OS\n  Install the file somewhere on you $PATH\n  Execute\nSyntax: fly -t [target] login -c [url of your concourse server]\nExample: fly -t omci login -c https://om-curriculum-ci.apps-np.homedepot.com/\nNote: The target is an alias for the server you are passing to -c. This can be any name that you want. Some teams have several servers set up and use mutilpule targets to determeine what server they are working with.\n  Go to the link in the login message and you should be taken through the OAuth dance via your GitHub org.\n  Creating a Pipeline\nConcourse uses a YAML file as a way to configure the steps of your pipeline. You use the fly cli to push ( set-pipeline ) the configuration to your Concourse server. Setting up your pipeline is going to be specific to your apps needs. Configuring an entire yaml file is outside the scope of this lesson.\nHowever, take a look at the YAML files in this Java HelloWorld repo.\n"
},
{
	"uri": "/cloud/containers/",
	"title": "Containers",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Containers Offerings "
},
{
	"uri": "/path-to-production/change-management/creating-a-change/",
	"title": "Creating an RFC for PCF",
	"tags": [],
	"description": "",
	"content": "Before you Open a Request for Change Before you open the change, you will need:\n  To know who your change Coordinator is.\nIf you do not know, or know you should be, you can request access by filling out an ARP request to be added to the group SN_IT_Licensed_Holders.\n NOTE After spa, ServiceNow licenses, and their permissions, are revoked. To reactivate your license, follow one of thefollowing steps:\n a. Contact the manager of the managed ServiceNow access group(s) you were previously in, so that he or she can add your name back to those group(s).\nb. Post your request in the #servicenow Slack channel.\n  Test results are required as part of the change. Ensure you have them recorded.\n  VP approval required only during enterprise-freeze periods, unless specifically requested.\n  Part 1: Application Information   Go to the Service Now\n  In the left panel, navigate to Change and click on Create New\n  And select the appropriate type of change to create the RFC\n Choose PCF in the Staging if you are staging things, such as services or configurations required for your application Choose PCF in the Deployment section if this change is to actually push your application    A new RFC will be created with some fields predefined.\n  In the top section of the RFC, fill in the required details.\nDo not set status to Ready for Coordinator Review until all details are completed here. Only Coordinators and Managers are able to fill in the Watch List and submit for approval.\n Coordinator: Typically this is the Principal, Manager or Staff that is most familiar with what is being implemented. The coordinator must have a software license, so that the change can be marked as Ready for Approval\n Application or Service: The name of your application or service.\n Assigned: Someone who knows about the change and can speak to it. Typically this is one of the Software Engineers on the team.\n Validator: Someone who can validate that the change that was deployed is valid.\n Assigned-to: is the point of contact for the change. This can be someone like the Project Manager or Team Lead. The assigned-to does NOT approve the request.\n Validator: should be a person from the team that will be validating the changes.\n Category: describes the technology area that will be impacted by the change.\n Deployment Environment: should be technical environment for the change.\n Change Environment: should be Production or LLC.\n Deployment type: should be Standalone for a single implementation. Rollout allows for child changes to be added to the request.\n Downtime required: should be used to indicate whether downtown is required. Use the drop down to select Yes/No. In the comments, indicate what the downtime is, who it is impacting and if it is occurring during normal scheduled downtime with no impact.\n Testing Performed: should be selected from the drop down to Yes/No. Testing must be completed before approvals are requested on the change request. If Testing was not performed due to specific technical limitations and/or the change was not able to be tested. Additional approvals and/or justification may be required to proceed.\n Project ID: The SAP ID IT-####. You may hear it called FMS # as well.\n sub-experience: (select one of the sub-experiences). Often the same as business process team.\n Short Description: should clearly state what this change is for. Identify if project or if PCR specific.\n Description: should have a list of all PCRs involved (if any) and should provide a thorough description of the change.\n Justification: should provide details that justify need for the change, not a duplication of the description.\n Upload Testing Artifacts: Use to upload test results documents if you did not provide a QualityHub link to test results.\n   Part 2: Governance Questionnaire   Click the Schedule tab and enter the date and time when you plan to start the change and when you intend to be done by.\n  Press to save the details.\n  In Planning section, enter the manager, director and VP name. It may prefill based on the \u0026ldquo;Assigned To\u0026rdquo; person\u0026rsquo;s reporting structure. Always check the names on the planning tab just before requesting approvals to ensure that the change is assigned to the correct management chain.\n  Press to save the details.\n  In Affected CIs section, enter the configuration items that are being touch in the release. To add additional system, click and then search \u0026amp; add it.\n  In Change tasks section, click on the change request number to add details for change tasks by repeating the next steps for each:\n Detailed Implementation Plan Detailed Post Implementation Verification Detailed Backout Plan(If Implementation Plan has already been developed, then this will be easy, just cut and paste the details from the word document)    Select on Change Plan Steps to update the steps that are listed. Add the step and duration. Assign the task to necessary person or group. Provide the duration and the order number for the steps.\n  Click to save the changes.\n  Select again to add additional steps if needed. Otherwise, if no more steps for Implementation, press back arrow to go back to the tasks\n  Press to save the Change task details.\n   NOTE: The total duration of the change tasks cannot exceed duration between start and end time\n  Set status to Yes for Ready for Coordinator Review.  Approval Process An email will be sent person identified as Coordinator in part one.\nThe Coordinator will then:\n  update the Watch List details. The watch list pertains to those persons that should be aware of the changes.\n  Click on Save and set the request for approval, by clicking on  The sub-experience owner/manager gets the first email to approve. It is an auto-generated email from IT Service Management. Approval can be completed in two ways:\n  Within the email look for the link \u0026ldquo;Click here to approve CHG01234567\u0026rdquo;. Click the link. A new email will appear directed to IT Service Management. Type Approve. Press Send.\n  In the SN Approvers Section for the request, click beside your name and select the drop down box for Actions. Select Approve.\n    Once approved, by the manager, it routes to the governance inspectors (if needed). The approval status can be followed by checking the Approvers Section to see who it is waiting on.\n  After the inspectors approve, it routes to the sub-experience director for approval.\n   NOTE: Once all approvals have been received, (sometimes) an auto-generated email will send notification to all Watchers. However, if there are any changes to the RFC, such as changing the date or resetting to planning state, notification is sent to all watchers.\n If you need to update attachments on the RFC, click the ManageAttachments Link. All the required attachments should be on the request BEFORE you request approvals.\n"
},
{
	"uri": "/onboarding/cyber-security/getting-started/general/",
	"title": "Cyber Security General Onboarding",
	"tags": [],
	"description": "",
	"content": " General Cyber Onboarding  General Cyber Onboarding Course Proposal  Module 1 (Labeled Section A): Why it’s important to keep information secure   Module Success: Be an advocate:\n Drive accountability Engage in cyberculture Emulate secure behaviors Encourage security mindset Serve as a role model    Topic 1: Compromised company information due to poor security hygiene leads to significant business disruption: :\n Breach of customer \u0026amp; associate trust Damage to company reputation Diminished shareholder value Regulatory fines Recommended Tatic(s): Provide statistics about the cost of Home Depot’s data breach to help quantify the significance of keeping data secure.  Talking Points:  Data incidents can cause massive financial losses, damage company reputation as well as affect the trust with our customers, associates and shareholders The Home Depot had fallen victim to significant data incident in 2014 when cybercriminals stole credentials from one of our vendors, which were then used to penetrate and install malware within our network – compromising over 56 million records The data incident resulted in regulatory fines and settlements surpassing $150mm, impacted company sales and stock values, and also damaged the trust with our customers, associates and shareholders While Cyber infrastructure is critical in securing company information, something as simple as leaving credentials unprotected can lead to significant business disruption   Provided Statistics:  The global average cost of a breach is $3.9mm Share prices fall on average of 7.27% after a breach A breach can create customer turnover of 3.4% $17k is lost every minute to due to phishing attacks – globally        Topic 2: Protecting company information is rooted in our core values:\n Doing the right thing Creating shareholder value Taking care of our people Recommended Tatic(s): Share a 2-3-minute video clip where Stephen Ward, Chief Information Security Officer, highlights how the cyber mindset is rooted in our core values  Talking Points:  Protecting what matters most is rooted in our core values at THD Customers have entrusted us to handle their information with great care and diligence. Serving as information guardians is every associates priority and responsibility – it’s the right thing to do Securing every step on our ‘orange path’ journey is critical in meeting our ‘orange promise’ of delivering the most convenient experience and best value for our customers. Leaving any company information vulnerable due to poor security etiquette hinders this promise. Thus, keeping an excellent security hygiene is key to creating shareholder value Associates are one of the most important layers in Home Depot’s defense in keeping our networks, systems and information secure. This layer of defense is only strong as its weakest link. Practicing security hygiene with one another is critical to ensuring we protect customer, associate and customer information – a fundamental in taking care of our people        Topic 3: Securing company information is every associates priority and responsibility:\n Associates are a key layer in Home Depot’s cyber defenses Recommended Tatic(s): Share in person testimonials or examples of how something as simple as reporting a suspicious email can make a significant impact in keeping Home Depot secure  Talking Points:  Associates are a key layer in our cyber defenses. Human actions are increasingly at the root of data incidents as cyber criminals shift their focus from attacking cyber infrastructure to the human side of cyber In 2018, some associates in Technology had fallen victim to ‘Trickbot’ - malware designed to lock associates out of their device. This malware was introduced through a simple phishing email by encouraging associates to click a link. However, those who spotted and reported the phishing email saved themselves from the trouble of having to reimage their assets and the loss of their data There is a clear incentive for cybercriminals to attack the human element of cyber as opposed to cyber infrastructure. Cybercriminals have found that exploiting human curiosities, ignorance and negligence are far more effective than deploying a virus designed to find and exploit a system vulnerability. It is said that 95% of data breaches are caused by human error. Thus, our responsibility to secure company information has never been more critical   Provided Statistics:  94% of malware delivered is via email 95% of data breaches are caused by human error 95% of breaches in 2016 occurred in the retail, technology and government spaces        Module 2(Labeled Section C): Introduction to the Cybersecurity organization and how we support the business   Module Success:\n Understand Cybersecurity’s vision and services: Aware of service offerings Identify domains    Resources:\n Cybersecurity Policies \u0026amp; Standards Cyber Service Catalog Services Strategy Roadmap - 2020 Cyber Focus Areas – 2020    Domain POC’s\n Software Development Security: Mindy White Security Assessment \u0026amp; Testing: Imran Punja Security and Risk Management: Nalini Subu Identity Access Management: Linda Srouffe Security Operations: Jamil Mneimneh Assets Security: Larniece Stovell Security Architecture \u0026amp; Engineering: Jay Schnell Communications and Network Security: Jay Schnell    Topic 1: Cybersecurity serves to enable the business, especially Technology:\n Vision Services Recommended Tactic(s): Provide collateral that illustrates how Cybersecurity supports the Orange Promise/Technology objectives. Talking Points:  We’re here to enable the business. Our vision is to elevate The Home Depot’s cybersecurity posture to support the needs of our core business offerings today and into the future Cybersecurity is made of 9 key services that support and enable associates to work securely at The Home Depot: Architecture: Help Technology associates design secure solutions and provide security technical standards and guidelines to enable self-service Internal Threat: Enhance THD’s security posture and technical capabilities as it relates to internal threats Identity and Access Management: Provide the right access to the right people at the right time Issue \u0026amp; Compliance Management: Help THD maintain compliance with regulations and effectively manage issues Security Operations: Mitigate, deter, detect, analyze and respond to cyber incidents Risk Assessment \u0026amp; Advisory: Identify, analyze and advice on risks to the enterprise, perform cybersecurity risk assessments, and measure effectiveness of controls Strategic Planning: Coordinate cybersecurity services with the broader THD enterprise Governance: Define and coordinate security policy/standard creation and cybersecurity risk management activities across the enterprise Cybersecurity Consultants: Primary executive business partners for cyber to the business and corporate functions      Topic 2: Understand each cyber domain and how they apply to Technology associates:\n Define each of the 8 cybersecurity domains Explain how each of the 8 cybersecurity domains apply Talking Points:  Cybersecurity is made up of 8 domains. It is critical for associates to understand each domain and how it may apply their roles:  Software Development Security: Critical for Software Engineers to understand, this cyber domain focuses on keeping developed systems and applications secure by applying secure coding standards and guidelines throughout the software development lifecycle. Testing for code weaknesses is critical as well Security Assessment \u0026amp; Testing: This domain falls on the non-technical side of the cyber wheelhouse where risk assessments are performed on technologies and processes to help identify, quantify and manage risks based on cyber frameworks such as the Cybersecurity Policies and Standards. Findings generated from audits should be mitigated as soon as possible by Technology associates Security and Risk Management: This domain levels sets expectations by establishing policies, standards and controls to ensure overall cyber compliance to legal and regulatory frameworks such as SOX, PCI, etc. Associates should familiarize themselves with the Cybersecurity Policies and Standards and apply these security principles to avoid findings produced by audits Identity Access Management: Commonly referred to as IAM, this domain pertains to all the systems, processes and procedures Home Depot leverages to assign and verify identities – including access management. Accessing Home Depot’s network remotely via RSA token is a classic IAM function where an associate’s identity is verified through login credentials before access is granted to THD’s network. Associates who are designing systems, networks and applications as it relates to access management should always keep the concept of ‘least privileged’ in mind by keeping access and administrative rights to the bare minimum. Authentication should also be top of mind to ensure only authorized personnel are accessing Home Depot’s networks, systems and data Security Architecture \u0026amp; Engineering: This domain aims to keep Home Depot’s systems and networks secure through the use of firewall systems, anti-virus solutions, etc. Associates that design, implement and maintain Home Depot’s systems and networks should always leverage secure design capabilities and principles like cryptography to protect the confidentiality, integrity and accessibility of sensitive information Security Operations: This domain simply operationalizes the security engineering domain by actively monitoring and mitigating threats and vulnerabilities through technologies used to keep Home Depot’s systems and networks secure. Threat hunting and incident response are key functions of the domain Assets Security: Pulling from the physical security world, this domain ensures the physical side of cyber is secured through proper controls. This is seen in practice by limiting access to server rooms to authorized personnel only. The handling of data such as its retention and disposal also falls within this domain. Associates should always ensure they handle company information per the information classification and handling guidelines noted within the cyber policies. Communications and Network Security: This domain stresses the importance establishing secure networks and channels as per design.        Module 3 (Labeled Section B): You don’t have to be a security practitioner to keep information secure   Module Success:\n Practice basic security hygiene: Engage Cybersecurity  Report suspicious emails Consult Attend PSRB   Review polices    Provided Resources:\n Cybersecurity myApron Portal Cybersecurity Confluence Portal Cybersecurity Service Catalog    Topic 1: Protecting company information starts with you:\n We all have a role  Talking Points  We all make security decisions every day. From securely handling a customer’s credit card, to ensuring our promotions and product launches are kept secret until we surprise our customers. Together, these decisions keep the information of our customers, associates and The Home Depot secure. As such, associates are the most important layer of defense in keeping Home Depot’s information secure. Our everyday actions keep us protected from sophisticated cyber-attacks and vulnerabilities        Topic 2: Practicing basic security etiquette makes a significant impact:\n Be an information guardian e.g. Use strong passwords, dispose securely Engage Cybersecurity e.g. report suspicious emails, ask questions, etc. Protect on the go e.g. Use password protected WIFI’s, prevent shoulder surfing, etc. Be familiar with policies e.g. review policies Protect the network e.g. Use approved software, avoid connecting foreign devices, etc. Stop. Think. Verify e.g. share on a need to know, think twice before clicking, etc. Recommended Tactic: Gamify the best practices to help build muscle memory in a creative way Talking Points:  Protecting company information isn’t daunting because we all are empowered and possess the ability to work securely.       "
},
{
	"uri": "/onboarding/cyber-security/getting-started/cyber-specific/",
	"title": "Cybersecurity Specific Onboarding",
	"tags": [],
	"description": "",
	"content": " Specific Cyber Onboarding  Specific Cyber Onboarding Course Proposal  Module 1: The Cyber mission – protect what matters most.   Module Success:\n Have a general understanding of the following:  Cyber Mission Transformation 2020 Focus Areas Cyber Services      Mission\n  Transformation\n  2020 Focus Areas\n  Key Functions\n  Requested Tactic(s):\n Share a 2-3-minute video clip where Stephen Ward, Chief Information Security Officer, highlights the cyber mission our focus areas for the next year    Module 2: What’s in my cyber tool belt   Module Success:\n Have a general understanding of the following: Key technologies leveraged within Cyber Key resources Key partners    Topic 1: Tools to stay in the know:\n Archer: Predominately leveraged by the Governance and Risk Compliance functions, this tool is leveraged to manage cyber risk such as remediation (POC: Brett_Wallace@homedepot.com) Project Management Central: Commonly leverage by Project Managers and Business Analysts, this portfolio management tool charts progress of strategic projects across all cyber services (POC: Erin_Bowers@homedepot.com ) Cybersecurity Service Catalog: An enterprise facing website that defines how and when to engage cyber services (POC: Olivia_M_Leonaitis@homedepot.com) Cybersecurity Confluence Site: One-stop shop for all things cyber from development blue prints to technical protocols. Site is only available to cyber associates (POC: Agum Puri) Deadbolt: A tool with many functions, this site is leveraged to manage 3rd party contracts and financials as well as report out weekly updates from each cyber service (POC: liezl_azucena1@homedepot.com) Cyber myApron Site: One-stop shop for associates across the enterprise to help answer their commonly asked questions (POC: Jessica_Morse@homedepot.com) Portfolio Review: Monthly business review with leadership to discuss the overall progress of each strategic project within Cyber )POC: Erin_Bowers@homedepot.com) Knowledge Depot: Suit of trainings to help associates get up to speed on company expectations and requirements Requested Tatic(s): Showcase the value of these tools and how they help associates stay in the know through demos    Topic 2: How to make a difference:\n Women’s Council: Business council to support the advancement of women within Cybersecurity (POC: Sherrie L’Amoreaux) Voice of the Associate: Committee made up of cyber associates who aim to improve how the organization can support its associates (Davina_Harell@homedepot.com) Requested Tatic(s): Share in person testimonials from associates who are a part of these councils    **Topic 3: Key partners/tollgates:*-\n End User Community: Weekly tollgate meeting to vet efforts impacting the end user infrastructure Product Solution Review Board: Cross functional board that conducts workshops three times per week to review architecture and security designs to assure they meet business requirements    **Topic 4: Things to know by role/function (Verify in course proposal):*-\n  Module 3: The next 30 days Module Success: Able to grasp the cyber org. and hit the ground running in a relatively effective and efficient manner\n Topic 1: What to expect:  Meet with onboarding peer Attend Welcome Lunch Setup \u0026ldquo;Get to know you\u0026rdquo; (GTKY) Sessions Meeting with Leader expectations Review documentation  Cyber roadmap Glossary FAQ’s Org Chart Slack Channels      "
},
{
	"uri": "/python/web-framework/django_intro/",
	"title": "Django Introduction",
	"tags": [],
	"description": "",
	"content": "What is Django ¶ Django is a high-level Python Web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of Web development, so you can focus on writing your app without needing to reinvent the wheel. It\u0026rsquo;s free and open source..\nCreate a project directory name django_apps and type:\n$ cd django_apps $ pipenv install django --three Next, we\u0026rsquo;ll need to auto-generate some code that establishes a Django project – a collection of settings for an instance of Django, including database configuration, Django-specific options and application-specific settings.\nFrom the command line, cd into the same directory you installed django, then run the following commands:\n$ pipenv shell #starts pipenv environment $ django-admin startproject store_finder  The first command starts your python environment. The second one creates a store_finder directory in your current directory.  If it didn’t work, see Problems running django-admin.\nLet’s look at what django-admin startproject created:\ndjango_apps/ store_finder/ manage.py store_finder/ __init__.py settings.py urls.py wsgi.py These files are:\n   File Name Description Reference Page     The outer store\\_finder/ root directory just a container for your project. Its name doesn’t matter to Django; you can rename it to anything you like.    manage.py A command-line utility that lets you interact with this Django project in various ways. django-admin and manage.py   The inner store\\_finder/ directory The actual Python package for your project. Its name is the Python package name you’ll need to use to import anything inside it (e.g. store_finder.urls)    store\\_finder/\\_\\_init\\_\\_.py An empty file that tells Python that this directory should be considered a Python package. more about packages   store\\_finder/settings.py Settings/configuration for this Django project. Django settings   store\\_finder/urls.py The URL declarations for this Django project; a “table of contents” of your Django-powered site. URL dispatcher   store\\_finder/wsgi.py An entry-point for WSGI-compatible web servers to serve your project. How to deploy with WSGI WSGI    The development server Let\u0026rsquo;s verify our Django project works. Change into the outer store_finder directory, if you haven\u0026rsquo;t already, and run the following commands:\n$ python manage.py runserver You\u0026rsquo;ll see the following output on the command line:\nPerforming system checks... System check identified no issues (0 silenced). You have unapplied migrations; your app may not work properly until they are applied. Run \u0026#39;python manage.py migrate\u0026#39; to apply them. August 20, 2018 - 15:50:53 Django version 2.1, using settings \u0026#39;store_finder.settings\u0026#39; Starting development server at Quit the server with CONTROL-C.  Ignore the warning about unapplied database migrations for now; we’ll deal with the database shortly.\n You’ve started the Django development server, a lightweight Web server written purely in Python. We’ve included this with Django so you can develop things rapidly, without having to deal with configuring a production server – such as Apache – until you’re ready for production.\nNow that the server’s running, visit http://127.0.0.1:8000/ with your Web browser. You’ll see a “Congratulations!” page, with a rocket taking off. It worked!\n Creating the Locations app Now that your environment – a “project” – is set up, you’re set to start doing work.\nEach application you write in Django consists of a Python package that follows a certain convention. Django comes with a utility that automatically generates the basic directory structure of an app, so you can focus on writing code rather than creating directories.\nProjects vs. apps What’s the difference between a project and an app? An app is a Web application that does something – e.g., a Weblog system, a database of public records or a simple location app. A project is a collection of configuration and apps for a particular website. A project can contain multiple apps. An app can be in multiple projects.\nYour apps can live anywhere on your Python path. We\u0026rsquo;ll create our locations app right next to our manage.py file so that it can be imported as its own top-level module, rather than a submodule of store_finder.\nTo create your app, make sure you’re in the same directory as manage.py and type this command:\nMake sure you are in the outer store_finder directory\n$ python manage.py startapp locations That’ll create a locations directory, which is laid out like this:\nlocations/ __init__.py admin.py apps.py migrations/ __init__.py models.py tests.py views.py This directory structure will house the locations application.\n Write your first view Let’s write the first view. Open the project in Pycharm and navigate to locations/views.py and put the following Python code in it:\n\u0026#34;\u0026#34;\u0026#34; title: locations/views \u0026#34;\u0026#34;\u0026#34; from django.http import HttpResponse def index(request): return HttpResponse(\u0026#34;Hello, world. You\u0026#39;re at the locations index.\u0026#34;)  HttpReponse in detail\n This is the simplest view possible in Django. To call the view, we need to map it to a URL - and for this we need a URLconf. (URL configuration - Python module that maps a URL path to Python functions).\nTo create a URLconf in the locations directory, create a file called urls.py. Your app directory should now look like:\nlocations/ __init__.py admin.py apps.py migrations/ __init__.py models.py tests.py urls.py views.py In the locations/urls.py file include the following code:\n\u0026#34;\u0026#34;\u0026#34; title: locations/urls \u0026#34;\u0026#34;\u0026#34; from django.urls import path from . import views urlpatterns = [ path(\u0026#39;\u0026#39;, views.index, name=\u0026#39;index\u0026#39;), ] The next step is to point the root URLconf to the locations.urls module. In store_finder/urls.py, add an import for django.urls.include and insert an include() in the urlpatterns list, so you have:\n\u0026#34;\u0026#34;\u0026#34; title: store_finder/urls \u0026#34;\u0026#34;\u0026#34; from django.contrib import admin from django.urls import include, path urlpatterns = [ path(\u0026#39;locations/\u0026#39;, include(\u0026#39;locations.urls\u0026#39;)), path(\u0026#39;admin/\u0026#39;, admin.site.urls), ] The include() function allows referencing other URLconfs. Whenever Django encounters include(), it chops off whatever part of the URL matched up to that point and sends the remaining string to the included URLconf for further processing.\nThe idea behind include() is to make it easy to plug-and-play URLs. Since locations are in their own URLconf (locations/urls.py), they can be placed under “/locations/”, or under “/fun_ locations/”, or under “/content/locations/”, or any other path root, and the app will still work.\n ####When to use include() You should always use include() when you include other URL patterns. admin.site.urls is the only exception to this.\n You have now wired an index view into the URLconf. Lets verify it’s working by running the following command:\nMake sure you are in the outer store_finder directory\n$ python manage.py runserver Go to http://localhost:8000/locations/ in your browser, and you should see the text “Hello, world. You’re at the locations index.”, which you defined in the index view.\n ####Page not found? If you get an error page here, check that you’re going to http://localhost:8000/locations/ and not http://localhost:8000/.\n  The path() function is passed four arguments, two required: route and view, and two optional: kwargs, and name. At this point, it’s worth reviewing what these arguments are for.\npath() argument: route The route argument should be a string or gettext_lazy() (see Translating URL patterns) that contains a URL pattern. The string may contain angle brackets (like \u0026lt;username\u0026gt; above) to capture part of the URL and send it as a keyword argument to the view. The angle brackets may include a converter specification (like the int part of \u0026lt;int:section\u0026gt;) which limits the characters matched and may also change the type of the variable passed to the view. For example, \u0026lt;int:section\u0026gt; matches a string of decimal digits and converts the value to an int. See How Django processes a request for more details.\npath() argument: view The view argument is a view function or the result of as_view() for class-based views. It can also be an django.urls.include().\nWhen Django finds a matching pattern, it calls the specified view function with an HttpRequest object as the first argument and any “captured” values from the route as keyword arguments. We’ll give an example of this in a bit.\npath() argument: kwargs The kwargs argument allows you to pass additional arguments to the view function or method. See Passing extra options to view functions for an example.\npath() argument: name Naming your URL lets you refer to it unambiguously from elsewhere in Django, especially from within templates.\u0026rsquo;\n This powerful feature allows you to make global changes to the URL patterns of your project while only touching a single file.\n See Naming URL patterns for why the name argument is useful.\n Exercise: Create 2 Views \u0026amp; Another App Create 2 more views called:\n market_info()(locations/\u0026lt;int:marketNum\u0026gt;)   Have this view display a simple \u0026quot;Hello World! You are looking for market \u0026lt;marketNum\u0026gt;\u0026quot;. Replace \u0026lt;marketNum\u0026gt; with the number that was passed to the URL.  store_info()(locations/\u0026lt;int:marketNum\u0026gt;/\u0026lt;int:storeNum\u0026gt;).   Have this view display a simple \u0026quot;Hello World! You are looking for store \u0026lt;storeNum\u0026gt; that is in market \u0026lt;marketNum\u0026gt;\u0026quot;. Replace \u0026lt;marketNum\u0026gt; and \u0026lt;storeNum\u0026gt; with the corresponding parameters that were passed to the URL.   How do we create new views inside an app? How do we create routes for new views?  Create another app inside your project called: THD_API.\n How do we create a new app inside a project?   Setting up a pytest environment in Django Django has a built in Test module that uses the unit test module, and it already has built in functions. To learn more about Django.test got to documentation here.\nPytest Django Documentation pytest-django is a plugin for pytest that provides a set of useful tools for testing Django applications and projects.\nQuick Start Go to your terminal inside PyCharm and type:\n$ pipenv install pytest-django Create a pytest.ini file in the same directory as your manage.py directory. Make sure DJANGO_SETTINGS_MODULE is defined and make your tests discoverable with the following code:\ntitle: store_finder/pytest.ini [pytest] DJANGO_SETTINGS_MODULE = store_finder.settings python_files = tests.py test_*.py *_tests.py Make sure your in the same directory as your manage.py file and type the following command:\n$ pytest -v  The -v means verbose and tells pytest to return more information about the test\n  Configuring Pytest in PyCharm Make sure you have pytest added to the project by following these directions.\nGo to your locations/tests.py file and run it. You will see the Python console displaying the test results. Currently, your\nExample test:\n\u0026#34;\u0026#34;\u0026#34; title: locations/test \u0026#34;\u0026#34;\u0026#34; from django.http import response from django.test import TestCase, Client class test_locationViews(TestCase): def __int__(self): self.client = Client() return self def test_Index(self): # assert that the response code is 200 assert self.client.get(\u0026#39;/locations/\u0026#39;).status_code == 200 self.assertEqual(response.status_code, 200) def test_Stores(self): assert self.client.get(\u0026#39;/locations/1/\u0026#39;).status_code == 200  There is a difference in syntax between the two assert statements above in test_Index becuase the latter is a unittest specific way of doing assert statements. As you can see either ways works fine.\n The test above tests that our two views, StoresView() \u0026amp; IndexView(), both return a status code of 200, which represents OK status, meaning the request has succeeded.\n Pycharm doesn\u0026rsquo;t give all the details when executing test, that\u0026rsquo;s why my preferred method is using the terminal.\n  Why use pytest instead? Running the test suite with pytest offers some features that are not present in Django’s standard test mechanism:\n Less boilerplate: no need to import unittest, create a subclass with methods. Just write tests as regular functions. Manage test dependencies with fixtures. Run tests in multiple processes for increased speed. There are a lot of other nice plugins available for pytest. Easy switching: Existing unittest-style tests will still work without any modifications.   If you are in a different directory this command alone will not work you will have to make sure the directory you\u0026rsquo;re in has the pytest.ini file. Or else you will need to pass the name of the directory in with pytest\n Using pytest-django documentation, let\u0026rsquo;s set up our django app to work with pytest.\n Exercise: Testing Your Views Create a test that verifies the content returned by your idex view, is a random string from this list of strings everytime a request is made.\n[\u0026lsquo;Hello World\u0026rsquo;, \u0026ldquo;Hello Night\u0026rdquo;, \u0026lsquo;Python is Great!\u0026rsquo; , \u0026ldquo;Hello from index\u0026rdquo;]\nThis examples uses Django\u0026rsquo;s reverse module explained here\nfrom django.test import TestCase, Client from .models import Market class test_locationViews(TestCase): def __int__(self): self.client = Client() def test_Index(self): response=self.client.get(\u0026#39;/locations/\u0026#39;) "
},
{
	"uri": "/cloud/containers/docker-fundamentals/",
	"title": "Docker Fundamentals",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Docker Fundamentals Offerings "
},
{
	"uri": "/python/foundation/",
	"title": "Foundation",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/react/foundations/",
	"title": "Foundations",
	"tags": [],
	"description": "",
	"content": "Welcome to React Foundations! "
},
{
	"uri": "/onboarding/cyber-security/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "Planning \u0026amp; Execution [DRAFT] "
},
{
	"uri": "/software-eng-essentials/git-pillars/git-branching-out/",
	"title": "Git Branching Out",
	"tags": [],
	"description": "",
	"content": "The following OM content has been curated to create a course with topics specific to increasing Collaboration and work Flow\nGit Logs git log allows viewing and/or filtering of git history.\nGit Logs\nMerge Conflicts No matter how careful we are with our collaboration Merge Conflicts will happen. Merging helps resolve these and move on.\nMerging\nGit Rebase git rebase places other branch\u0026rsquo;s commits in front of the current history.\nRebase Lesson\nRebase Vs Merge Two ways of doing the same thing with a little different results.\nRebase vs Merge discussion\nCherry pick git cherry-pick allows for a single commit to be put into a branch. This might cause collisions but not near as many as merging an entire branch in just to get the changes from one commit.\nCherry Pick\nGit Workflow Using all of these methods will not increase productivity a workflow is agreed upon to maintain best practices.\nGit Workflow\n"
},
{
	"uri": "/javascript/nodejs/getting-started/npm-modules/intro/",
	"title": "Intro to NPM",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Demo setting up projects with npm and yarn Explain semantic versioning of dependencies Showcase using npm scripts Discuss Encapsulation with ES6 Modules  Skills  Use dependencies in your projects Write Modular Code  npm \u0026amp; yarn Node uses a package management system to distribute open-source modules.\nnpm We can use the default Node Package Manager by running the npm command.\nnpm often uses a file called package.json to store and manage project information such as project dependencies.\nHere are some common npm commands:\nshell\n$ npm install \u0026lt;module_name\u0026gt; // 1 $ npm install --save \u0026lt;module_name\u0026gt; // 2 $ npm install // 3 $ npm start // 4  install a module into the node_modules directory install a module into the node_modules directory, and add it as a project dependency + (adds an entry in the package.json file) install all of the dependencies listed in the package.json file into the node_modules folder run a startup script that is specified in the package.json file  yarn Yarn, billed as alternative to npm, came on the scene fairly recently.\nSome of the advantages yarn offers include speed and security.\n yarn manages a local cache of frequently downloaded dependencies security -yarn uses checksums to verify the integrity of every installed package   yarn sits on top of npm and uses the npm registry to locate and install packages\n yarn vs. npm Using yarn or npm comes down to a team decision. Thankfully, the commands mirror each other and switching between the two is trivial.\n At the time of this writing, yarn can sometimes fail to install dependencies on the bandsaw network. It is recommended to stick with npm for the time being.\n .npmrc and .yarnrc npm and yarn can be configured via rc files that live in your $HOME directory. These files are simply text files that store a set of key/value pairs for configuring npm and yarn\n With both npm and yarn we need to set the registry to our THD artifactory server so that we can push and pull artifacts from there instead of directly accessing the public npm registry. This allows us to:\n have faster downloads as we are hitting a local server have fewer accesses to the public npm registry (see comment below) publish internal artifacts to artifactory for shared use within The Home Depot  Setting the registry value is very important as The Home Depot was identified as one of top 1% highest volume users of npmjs.org. We were informed by nodejs.org that if we continue to exceed 10 million connections per month to nodejs.org (aka npmjs.com) that traffic from our domain will be blocked! See this slack message.\n Creating the .npmrc file You can run the following commands to ensure your ~/.npmrc file is correct:\nnpm config set always-auth true npm config set strict-ssl false npm config set email your_email@homedepot.com npm config set registry https://npm.artifactory.homedepot.com/artifactory/api/npm/npm  Remember to use your email when setting the email value. If you make a mistake, just run the command again with the correct data.\n You can see the current setting of any key via npm config get \u0026lt;key\u0026gt; or you can see all the settings with npm config list.\n You can read more about npm config files at npmrc\n Creating the .yarnrc file You can run the following commands to ensure your ~/.yarnrc file is correct:\nyarn config set strict-ssl false yarn config set email your_email@homedepot.com yarn config set registry \u0026#34;https://npm.artifactory.homedepot.com/artifactory/api/npm/npm\u0026#34;  Remember to use your email when setting the email value. If you make a mistake, just run the command again with the correct data.\n You can see the current setting of any key via yarn config get \u0026lt;key\u0026gt; or you can see all the settings with yarn config list.\nSetting up a project npm init To start a project with npm you need to create a new directory, cd into it and run npm init.\nmkdir my-app cd my-app npm init At this point, you\u0026rsquo;ll be prompted to answer a series of questions. Fill out any relevant info and press enter afterwords.\n Running npm init -y will initialize your project without any prompts.\n package.json The result of running npm init is that a package.json file will be added to the root of your directory.\nYou\u0026rsquo;ll notice that the information gathered from the previous step is all listed here.\nThe package.json serves as a manifest file for your project. Not only does it include metadata about the app, it also includes:\n project dependencies custom application scripts additional configuration info  Installing Dependencies www.npmjs.com contains a list of all available packages for use in our projects.\nHere you\u0026rsquo;ll find everything from popular client-side libraries like React, to tiny almost unknown command line utilities, and everything in between.\nOften you\u0026rsquo;ll find a link on a project\u0026rsquo;s GitHub for npm and vice-versa. Typically the npm page is a mirror of the readme found on GitHub.\nTo install a package we simply run npm install \u0026lt;package_name\u0026gt;.\nInstall InquireJS\n$ npm install inquirer After installation finishes we\u0026rsquo;ll find the list project listed as a dependency in the package.json.\npackage.json\n{ //...  \u0026#34;dependencies\u0026#34;: { \u0026#34;inquirer\u0026#34;: \u0026#34;^8.1.2\u0026#34; } //... } As we continue to add dependencies this list will grow.\n Running npm install will find all packages listed under dependencies (and devDependencies) and install them locally.\n semver (Semantic Versioning) You\u0026rsquo;ll notice that inquirer has a version number (in this case it\u0026rsquo;s \u0026quot;^8.1.2\u0026quot;).\nOur packages/dependencies will all include version numbers for semantic versioning.\nThe versioning scheme is pretty straight-forward.\n   Example Name Description     x.x.2 patch typically includes bug-fixes and minor-minor updates   x.1.x minor version typically includes new features and non/breaking changes   8.x.x major version typically includes major upgrades which often cause breaking changes    You\u0026rsquo;ll also notice special characters at the beginning of the version number.\nIn order to specify what changes you\u0026rsquo;ll allow to the dependencies in your project, you can use the ^ (caret) and ~ (tilde) symbols.\n Any package with a ~ (ie: \u0026quot;myDep\u0026quot;: \u0026quot;~1.0.1\u0026quot;) will only accept patch updates. Any package with the ^ (ie: \u0026quot;myDep\u0026quot;: \u0026quot;^1.0.1\u0026quot;) will accept patch and minor updates.  Packages without any kind of character will allow major, minor and patch updates.\nFor example:\n if you write ~0.13.0, you want to only update patch releases: 0.13.1 is ok, but 0.14.0 is not. if you write ^0.13.0, you want to get updates that do not change the leftmost non-zero number: 0.13.1, 0.13.2 and so on. If you write ^1.13.0, you will get patch and minor releases: 1.13.1, 1.14.0 and so on up to 2.0.0. if you write 0.13.0, that is the exact version that will be used, always  package-lock.json In version 5, npm introduced the package-lock.json file. The package.json file is much more common and has been around for much longer than package-lock.\nThe package-lock.json file:\n has a goal to keep track of the exact version of every package that is installed so that a product is 100% reproducible in the same way even if packages are updated by their maintainers. automatically is generated by npm whenever npm modifies either the node_modules tree, or the package.json file. contains additional information about each installed dependency, including where the dependency was downloaded from (such as registry.npmjs.org or THD\u0026rsquo;s artifactory) and a integrity / hash / fingerprint of the downloaded artifact to ensure that the file is downloaded without any accidental or malicious modifications.  A difference of package-lock.json vs package.json is that it ensures that the file comes from the proper source and that the file has not been accidentally or maliciously tampered with either in the file / artifact server or during transit over the network.\n To see more on package-lock: package-lock.json | npm docs\n Using Packages To use a package, we\u0026rsquo;ll refer to the documentation for proper import syntax, available methods and more.\nBefore moving forward though, let\u0026rsquo;s go ahead and create an index.js file.\n$ touch index.js Inside of index.js we\u0026rsquo;ll require inquire.\nindex.js\nconst inquirer = require(\u0026#39;inquirer\u0026#39;); // 1  The constant inquirer represents inquirer.  The require statement will import the inquirer package into our file so that we can use it.\nWe\u0026rsquo;ll then store the value that inquirer exports in the our inquirer constant.\nInquirerJS is a package that allows for command line interactions with the user. We\u0026rsquo;ll perform some operations with inquirer.\nindex.js\nconst inquirer = require(\u0026#34;inquirer\u0026#34;); // Bring in the Inquirer package  console.log(\u0026#34;Hi! Welcome to Node Pizza\u0026#34;); // With Inquirer, we can ask the user a series of question in the form of objects const questions = [ { type: \u0026#39;confirm\u0026#39;, name: \u0026#39;toBeDelivered\u0026#39;, message: \u0026#39;Is this for delivery?\u0026#39;, default: false, }, { type: \u0026#39;list\u0026#39;, name: \u0026#39;size\u0026#39;, message: \u0026#39;What size do you need?\u0026#39;, choices: [\u0026#39;Large\u0026#39;, \u0026#39;Medium\u0026#39;, \u0026#39;Small\u0026#39;], filter: function (val) { return val.toLowerCase(); }, }, { type: \u0026#39;input\u0026#39;, name: \u0026#39;quantity\u0026#39;, message: \u0026#39;How many do you need?\u0026#39;, validate: function (value) { var valid = !isNaN(parseInt(value)); return valid || \u0026#39;Please enter a number\u0026#39;; }, filter: Number, }, { type: \u0026#39;expand\u0026#39;, name: \u0026#39;toppings\u0026#39;, message: \u0026#39;What about the toppings?\u0026#39;, choices: [ { key: \u0026#39;p\u0026#39;, name: \u0026#39;Pepperoni and cheese\u0026#39;, value: \u0026#39;PepperoniCheese\u0026#39;, }, { key: \u0026#39;s\u0026#39;, name: \u0026#39;Sausage\u0026#39;, value: \u0026#39;sausage\u0026#39;, }, { key: \u0026#39;w\u0026#39;, name: \u0026#39;Hawaiian\u0026#39;, value: \u0026#39;hawaiian\u0026#39;, }, ], } ]; inquirer.prompt(questions).then((answers) =\u0026gt; { console.log(\u0026#34;\\nOrder receipt:\u0026#34;); console.log(JSON.stringify(answers, null, \u0026#34; \u0026#34;)); }) In the above example we sending a series of prompts to the user and recording the response. Attributes for each prompt depend on it\u0026rsquo;s type.\n Running node index.js will execute this file.\n npm scripts You\u0026rsquo;ll notice a section for scripts in the package.json file.\nThis allows us to store and run any type of scripts related to our projects. Some popular use cases include:\n Starting up a web-server Running and watching tests Database setup \u0026amp; teardown tasks Project setup tasks Running compile steps  Some teams even use npm scripts as their only build tool.\nLet\u0026rsquo;s create a start script.\npackage.json\n{ \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node index.js\u0026#34; } } Now, we can run npm start to run our application.\nLab 1  Installing and using node packages.  Working with Modules Like most other modern languages, Node.js is modular. This means that we can break up a large JavaScript program into several files and even package up JavaScript code into libraries (Node.js calls them modules).\n Modular programming is a software design technique that emphasizes separating the functionality of a program into independent, interchangeable modules, such that each contains everything necessary to execute only one aspect of the desired functionality.\n Wikipedia, Modular Programming\n  Some of the key benefits of modules in node include:\n avoids naming conflicts removes global variables better control over scope better control over 3rd party libraries logical load order faster tests  The History on JavaScript Module Systems There has been a long evolution of JavaScript module systems. It started with CommonJS. The developers of Node.js originally intended to follow the CommonJS specification but later decided against it and built their own module system inspired by CommonJS.\nAMD was born out of a group of developers that were displeased with the direction adopted by CommonJS. In fact, AMD was split from CommonJS early in its development. The main difference between AMD and CommonJS lies in its support for asynchronous module loading. Implementations of AMD include Require.js and Dojo.\nFortunately, the ECMA team behind the standardization of JavaScript decided to tackle the issue of modules. The result can be seen in the latest release of the JavaScript standard: ECMAScript 2015 (previously known as ECMAScript 6). The result is syntactically pleasing and compatible with both synchronous and asynchronous modes of operation. Unfortunately none of the major JavaScript runtimes support ES2015 modules in their current stable branches. This means no support in Firefox, Chrome or Node.js. Fortunately many transpilers do support modules and a polyfill is also available. Currently, the ES2015 preset for Babel can handle modules with no trouble.\nSystem.js is a universal module loader that supports CommonJS, AMD and ES2015 modules. It can work in tandem with transpilers such as Babel or Traceur and can support Node and IE8+ environments.\n CommonJS  Node.js Module System AMD  Require.js Dojo   Browserify (a bundler that uses CommonJS formatted modules)   ES-2015 Modules  Babel Webpack SystemJS    JS Module Bundlers, Totally Tooling Tips\n\nThe Node.js Module System Node.js allows you to export a JavaScript value via module.exports, and import a value via require().\nFor example, lets make two files, one that exports and one that imports.\n$ touch calculator.js index.js calculator.js\nconst add = (x, y) =\u0026gt; x + y; module.exports = add; index.js\nconst add = require(\u0026#34;./calculator\u0026#34;); console.log(add(2, 3)); You\u0026rsquo;ll notice the syntax is similar to working wit third party node packages.\nThe only major difference is that we import from a file path (./calculator in this case), because that\u0026rsquo;s where our module lives.\nThings to Note\n module.exports:\n an object to store the things that a module exports  require():\n reads and returns the module.exports of the file that was required it should normally be stored in a variable    The module\u0026rsquo;s source file is only executed the first time that the file is required.\n Lab 2  Create your own node module  Summary   With npm and yarn we can install packages for direct use in our projects.\n  The package.json file serves as a manifest for your application.\n  Writing modular code is the future of JavaScript.\n  Additional Resources   yarn vs npm - which Node package manager to use in 2018\n  Semver: Tilde and Caret\n  How to Use npm as a Build Tool\n  "
},
{
	"uri": "/onboarding/cyber-security/general/module-1-intro/",
	"title": "Introduction to Cyber Security",
	"tags": [],
	"description": "",
	"content": "Topics  Understand what Cybersecurity is Identify different domains and differentiate between them Cybersecurity is financial risk associated with information loss or misuse of information systems. Understand how the different domains protect against different kinds of risks. Introduce compliance; regulatory standards to ensure Cybersecurity standards.  Securing What Matters Most At Home Depot, we innovate to provide a better experience for our customers, partners and employees. Whether you are a Software Engineer, Project Manager, Human Resources, or anything in between, you will be leveraging technology in your day to day activities. This is why securing our information is not just important, it is critical to our life as a business.\nSecurity incidents happen more often than you would think. The cost of a security incident can be loss of money, reputation, productivity, or worse.\nA security incident could take the form of a phishing email, putting your data on the wrong website, or even just leaving your laptop unlocked in a public area.\nBy the end of this training, you will recognize key security practices that help you keep our business secure and know what to do should a security incident arise.\nCybersecurity is for:\n HR Developers Project Managers Product Managers \u0026hellip;. Everyone!  Quick Facts:\n The global average cost of a breach is $3.9 million dollars. Share prices fall on average of 7.27% after a breach. A breach can create customer turnover of 3.4%. The Home Depot breach in 2014 had 56 million records compromised.  *Stats courtesy of Cybersecurity leadership\n   Our Mission Our Vision     provide The Home Depot with a Cybersecurity posture that supports the needs of our core business offerings today and into the future. is to provide an agile, scalable and seamless approach to Cybersecurity service delivery aligned to our current threat landscape and adaptable to The Home Depot’s goals and priorities.    Cybersecurity is core to to our values Over the next several modules, you will learn how Cybersecurity impacts your role as an associate at Home Depot. First, lets take a birds eye view about Cybersecurity in the company.\nThe Secure 12 Cybersecurity covers a broad spectrum of technologies and practices. At Home Depot we have 12 domains to cover all of our cybersecurity needs. This will help you understand how we enact Cybersecurity with policy to govern our secure business practices.\nSecure 12 policies can be found at https://myapron.homedepot.com/en-us/myApron/it/Desktop_Support/it-security/security-secure-12.pdf.\nFor any questions, reach out to cybersecurity_policies_\u0026amp;_standards@homedepot.com\n     Domain      Application Security Secure application development and acquisition   Data Protection Secure sensitive data usage   Cybersecurity Governance, Risk \u0026amp; Compliance Managing risk and ensuring compliance   Security Monitoring Monitoring and logging activities on all THD assets   Cybersecurity Resilience \u0026amp; Recovery Ensuring availability for critical infrastructure   Security Operations Removing vulnerabilities and exploits from the environment   Access Management Ensure all access is authorized   Third Party Risk Management Oversight and monitoring for 3rd party applications   Physical Security Protect assets from unauthorized physical access   Personnel Security Expectations for a secure workforce   Network Security Expectations for securing THD\u0026rsquo;s networks   Security Incident Response Ensuring proper response to security incidents    Secure 12 policies can be found at https://myapron.homedepot.com/en-us/myApron/it/Desktop_Support/it-security/security-secure-12.pdf.\nFor any questions, reach out to cybersecurity_policies_\u0026amp;_standards@homedepot.com\nCompliance and you - protecting our business The government sets regulations and standards for businesses to operate securely. We must meet these regulatory requirements and its important to know how they affect your job role.\nPCI Compliance\nPayment Card Industry compliance is a set of regulation standards that affect all businesses that process payment card information.\nIf your job role works with payment card information in any way, make sure you operating within the guidelines.\nSecure Data Practices A big part of security is managing our data securely. This means keeping proprietary information on a need to know basis, ensuring we do not share our data with unnecessary parties. It also means ensuring you trust wherever you store or provide data, including web applications, SaaS (software-as-a-service) applications, and databases.\n"
},
{
	"uri": "/golang/foundations/",
	"title": "Introduction to Go",
	"tags": [],
	"description": "",
	"content": "Welcome to Go Foundations! Go was created by Google in November of 2009. Their goal was to create an amazing procedural language for scalable cloud software. It was built to be simple, and fast.\n"
},
{
	"uri": "/onboarding/general/module-1-Orange Academy/",
	"title": "Orange Academy: An Overview",
	"tags": [],
	"description": "",
	"content": "Who We Are Orange Academy was a result the Voice of the Associate (VOA) survey. THD Associates asked for more opportunities to grow their career within the organization. With that, OM was born! We offer free workshops to all technology associates and Apprenticeship Opportunities to the whole company!\nFor a detailed look at who we are, join us on slack at #Orange Academy or send an email to Orange Academy@homedepot.com\nOnboarding  As of 2020, HDU will now walk all newly hired associates through a foundational level orientation. This orientation will include.  A brief overview of THD Values \u0026amp; Culture Equipment setup How to utilize enterprise tools such as Outlook, Slack, and more   Orange Academy Onboarding is only for newly hired technology associates.  This is beneficial as it gives us the opportunity to spend more time going in-depth with how THD does technology differently.    We are still developing fresh, up-to-date content so check back for more details on how OM can help you navigate your first few weeks (and the rest of your career!)\nWorkshops Orange Academy workshops are free to all technology associates with manager approval. In 2020, OM went virtual to bring you hOMe school! Now you can take a workshop from wherever you have internet and VPN access. Our workshops are broken up by discipline and difficulty. Please see below for more detail.\n  Software Engineering Workshops\n Foundational: Designed to provide a base of understanding for a tool or language ex. \u0026ldquo;Intro to Python\u0026rdquo;, \u0026ldquo;Intro to Docker\u0026rdquo;, etc. Pillar: Build upon the skills gained at the Foundation level. Students learn more complex functions of a specific tool or language. ex. \u0026ldquo;Automation with Python\u0026rdquo;, \u0026ldquo;Containerizing your App with Docker\u0026rdquo;, etc.    Product Experience Workshops: A blend of Product Management and User Experience Design Workshops\n Foundational: Designed to provide a base of understanding of a philosophy, process, or concept. ex. \u0026ldquo;Foundations of Value Creation\u0026rdquo;, \u0026ldquo;Intro to Information Architecture\u0026rdquo;, etc. Pillar: Builds upon processes, philosophies, and concepts learned at the Foundation level. ex. \u0026ldquo;OKRs for Balanced Teams\u0026rdquo;, \u0026ldquo;Research Methods for Generating Information Architecture\u0026rdquo;, etc.    For more details about current workshops or to register, please visit The Orange Academy Homepage.\n  Apprenticeship Opportunities Full-Time Transformative programs for current associates interested in a career path change to Software Engineer or User Experience Designer\nWho is this for?\n Associates who have been with Home Depot for 1 year from the cohort\u0026rsquo;s start date are eligible to apply! Openings are posted in CareerDepot  Why we do it\n  This is an opportunity for associates within The Home Depot organization who want to change their career path and change their life.\n  It is also an opportunity for Home Depot as selected associates can often bring fresh ideas from their previous roles in the company and create change!\n  Want to know more?\n For more information about the apprenticeship, reach out to us via our slack channel #Orange Academy or email Orange Academy@homedepot.com    The Orange Academy Homepage View \u0026amp; Register for Workshops here "
},
{
	"uri": "/path-to-production/tech-stack/paved-road/",
	"title": "Paved Road",
	"tags": [],
	"description": "",
	"content": "Knowing What Technology to Use When deciding to develop a thing, you\u0026rsquo;ll want an idea of what technologies you are going to use to develop and support that thing. What technologies to use and what you should steer clear of can be difficult to determine, especially with the pace that these technologies change. Fortunately, developers have some guidance in this area in the form of the Paved Road.\nThe Paved Road is a list of technologies that are acceptable or that should be avoided. Technologies are broken down a few ways:\n The high level problem they solve ( Platform, language, cicd, etc) On-Prem vs Cloud vs Store used to filter options that are available for each. Do, Maybe and Avoid to help determine if its something you should peruse.  Do: These are solutions that have officially been accepted and no additional discussions should need to be had. Everything in the Do section has something in production using it today.\nMaybe: These are solutions that are still in the process of being reviewed and could possibly end up in the Do section in the future.\nAvoid: These are solutions that, as the name stats, should be avoided for new development if at all possible.\nIt is important to note that just because a technology isn\u0026rsquo;t listed in the Do section, doesn\u0026rsquo;t mean it isn\u0026rsquo;t a viable solution. It means that it hasn\u0026rsquo;t been on the radar for review or officially been approved. Its goal is to try to cover 80% of the use cases with the understanding that 20% of things may need other options, or to utilize legacy systems.\nWhat this means is if something is not on the list or not in the Do section, you should be having additional conversation to determine if it is the right solution for within Home Depot.\n"
},
{
	"uri": "/application-security/api-security/00_preflight/",
	"title": "PreFlight",
	"tags": [],
	"description": "",
	"content": "PreFlight Like any good adventure, it should start with some small steps to prepare.\nWatch the Following Videos We will cover this material in class, but in an effort to streamline the material, it would be helpful to have a basic understanding of JWT Technology and how Asymmetric Encryption (RSA) and Signatures.\nWhat is OAuth and why does it matter? - OAuth in Five Minutes\nWhat is JWT ? JSON Web Token Explained\nAsymmetric encryption - Simply explained\nDigital Signatures Explained\nRest Calls using Postman | Curl Please make sure you have solid understanding of how to use Postman or Curl and the basics of REST call such as:\n HTTP Verbs (GET, POST, PUT, PATCH, etc) HTTP Headers: Content-Type, Authorization, etc HTTP Request Body, specifically JSON HTTP Response Codes (200, 302, 400, 401, 403, 500)  Install jq https://stedolan.github.io/jq/download/\nMacOS If on a Mac simply use the super awesome homebrew\nbrew install jq Windows chocolatey install jq Install the STEP CLI The Step-CLI is one of the best command line tools for handling cryptography operations.\nMacOS If on a Mac simply use the super awesome homebrew\nbrew install step Windows If on Windows, go to the Step CLI latest release and download the Window tar.gz or zip file:\nCommunity Docs Skim through the community documents to get a feel for the latest state of this effort:\nhttps://app-secure-community-docs.apps-np.homedepot.com/\nhttps://app-secure-community-docs.apps-np.homedepot.com/quickstart/\n"
},
{
	"uri": "/path-to-production/platforms/provision_pcf/",
	"title": "Provisioning PCF",
	"tags": [],
	"description": "",
	"content": "Getting Set Up on Pivotal Cloud Foundry Installing the Cloud Foundry CLI Binary Download For just about everything you want to do with Cloud Foundry, you can do with the cli. For some things, such as deploying (pushing) code, the Cloud Foundry CLI is a requirement.\nYou can download the binary for all distributions from the PCF site.\nFollow the instructions for installing the cli.\nInstalling with Brew or Chocolatey (Windows) Brew $ brew install cf-cli\nChocolatey C:\\\u0026gt; choco install cloudfoundry-cli\nResources to Help You Throughout This Processes Slack You can find community assistance with all processes covered in this document in the #cloudfoundry channel.\nTHD PCF Documentation You can find documentation, including additional HOWTO\u0026rsquo;s on the Platform Team\u0026rsquo;s GitHub page site.\n PCF Provisioning Vocabulary  Foundation: A foundation is a term used to describe the an \u0026ldquo;instance\u0026rdquo; of cloud foundry. App names, routes, orgs, and spaces are unique to a foundation. Orgs and spaces are defined below.\nAt The Home Depot we have several Foundations decried after the network \u0026ldquo;zone\u0026rdquo; on which they are installed: za, zb, eb, and np (there is a GCP foundation as well; please refer to the platform documentation on this). You will need to create your orgs and spaces, as well as deploy your application to each of the needed foundations individually.\n Organization (Org): An org is the-top most structure with which a development team interacts. An org can represent one or more teams. An org-manager will control who has access. An org is made up of one or more spaces. Resource quotas for all spaces are set here. It is recommended to use the same org name across all Foundations.\n Space: The target location for deployment of an application. All services, routes and applications names are compartmentalized to a space.\n Org Quota: The quota plan granted to an org. The plan will determine how many resources (disk, memory, etc) can be allocated to all applications within the org.\n Non-Production Before you can push code to PCF, you need to be a member of an org and space; if your team is brand new to PCF, you may need to create these yourself. If an org exists and you are unware of whom to contact to be added, you can follow the steps in the last section to search for the org and managers.\n Creating your Org and Space From Scratch   Decide on 2 or more individuals to designate as org managers.\n  Log into cloud foundry cf login -a https://api.run-np.homedepot.com\nWHEN PROMPTED FOR EMAIL ENTER YOUR LDAP INSTEAD\nYou will probably get an error regarding not being a member of any spaces or orgs.\n  Have an org manager create the org (who ever creates the org is made an org-manager by default)\nSyntax: cf create-org \u0026lt;org-name\u0026gt; Example: cf create-org om-courses\nOutput:\nCreating org om-courses as exw5373... OK Assigning role OrgManager to user exw5373 in org om-courses... OK   Add another org manager to the organization\nSyntax: cf set-org-role USERNAME ORG ROLE\nExample: cf set-org-role exp0ct5 om-courses OrgManager\nOutput:\nAssigning role OrgManager to user exp0ct5 in org om-courses as exw5373... OK   Create a space\n  Org manager must be logged in\n  Create the space:\nSyntax: cf create-space SPACE [-o ORG]\nExample: cf create-space myapp -o om-courses\nOutput:\n  Creating space myapp in org om-courses as exw5373... OK Assigning role SpaceManager to user exw5373 in org om-courses / space myapp as exw5373... OK Assigning role SpaceDeveloper to user exw5373 in org om-courses / space myapp as exw5373... OK   Add developers to the space as needed\nSyntax: cf set-space-role USERNAME ORG SPACE ROLE\nExample: cf create-space myapp -o om-courses\nOutput:\nAssigning role RoleSpaceDeveloper to user ajg3tri in org om-courses / space myapp as exw5373... OK   You or the space developers you\u0026rsquo;ve added can now push applications.\n Production Provisioning Production requires additional ceremonies in order to have everything provisioned. It is recommended that you use the same org in all foundations.\n Ensure you meet all prerequisites Follow the steps to open a change for your new org and space   Using cf-api GraphiQL to Search for Org and Space Detail You may encounter the need to look up an org to see if it exists, or to determine who the org managers are to add you.\nYou can use the cf-api Graphiql interface to query for information on and org using GraphQL.\nFirst, go to the appropriate foundation\u0026rsquo;s cf-api\n   Foundation     Non-prod (np)   Zone A (za)   Zone B (za)   Atlanta Zone B (eb)    The following query will search for an org named \u0026ldquo;Orange Academy\u0026rdquo;:\n{ organizations(name:\u0026#34;Orange Academy\u0026#34;){ name managers{ name } } } Just replace the Orange Academy string with the name of the org for which you are searching.\nIf nothing is found this will be the results:\n{ \u0026#34;data\u0026#34;: { \u0026#34;organizations\u0026#34;: [] } } Otherwise it will display an array list of all Org manager.\n"
},
{
	"uri": "/software-eng-essentials/restful-api/rest/",
	"title": "RESTful APIs",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Describe what a RESTful API does Map the CRUD operations to a set of RESTful endpoints  What is REST?  REST stands for REpresentational State Transfer REST was designed by Roy Fielding in his PhD dissertation \u0026ldquo;Architectural Styles and the Design of Network-based Software Architectures\u0026rdquo; at UC Irvine, 2000. REST is a pattern for using HTTP and URLs to define a Web API  CRUD Routes RESTful web services are one way of provide access and manipulate textual representations of web resources using a uniform and predefined set of stateless operations.\nIn a REST web service, requests made to a resource\u0026rsquo;s URI will elicit a response that may be in XML, HTML, JSON or some other defined format.\n Wikipedia  This means that our client sends representations of objects to the server. The server then performs an operation with that representation (ie: create, read, update, destroy), and returns a response (often with a representation of an object stored on the server). This is known as state transfer. Once the client receives the response, the state of the client is updated.\nCRUD in REST and SQL The following shows how the CRUD operations are mapped to RESTful routes and to SQL statements.\nCREATE  RESTful Route: Create HTTP Method: POST Sample URL: /pets  INSERT INTO pets (column1, column2, ...) VALUES (value1, value2, ...); READ (many)  RESTful Route: Index HTTP Method: GET Sample URL: /pets  SELECT * FROM pets; READ (one)  RESTful Route: Show HTTP Route: GET Sample URL: /pets/:id  SELECT * FROM pets WHERE id = id_value; UPDATE  RESTful Route: Update HTTP Route: PUT or PATCH Sample URL: /pets/:id  UPDATE pets SET column1 = value1, column2 = value2, ... WHERE id = id_value; DELETE  RESTful Route: Destroy HTTP Route: DELETE Sample URL: /pets/:id  DELETE pets WHERE id = id_value; Request \u0026amp; Response The request and response cycle used in a REST architecture should seem pretty straight-forward.\nIn the request-response cycle used in a REST architecture, the client initiates a request via HTTP, and the server sends a response via HTTP.\nHTTP Requests usually contain the following properties:\n Request Line Headers Body  Request Line The Request Line contains:\n HTTP action  GET POST PUT PATCH DELETE   URI (also known as the endpoint) Version of HTTP being used (1.1 / 2.0)  Headers Headers are essentially information about the Request and Response that exist as KEY/VALUE pairs.\nThe header keys are predefined according the the HTTP spec. We as the engineer can set the value based on a number of options, that can be broken up into 3 primary categories:\n General: both request and response use them Request: request only Response: response only  The most common HTTP headers while building API\u0026rsquo;s are:\nAccept Accept which is used via request to specify what type of response is acceptable. ie:\n text/html text/csv text/plain application/json application/xml application/pdf  The values above are known as MIME types\nThe MIME type is the mechanism to tell the client the variety of document transmitted: the extension of a file name has no meaning on the web. It is, therefore, important that the server is correctly set up, so that the correct MIME type is transmitted with each document. Browsers often use the MIME-type to determine what default action to do when a resource is fetched.\nMIME types have a specific structure of type/subtype which consists of a type and a subtype, two strings, separated by a \u0026lsquo;/\u0026rsquo;. No space is allowed. The type represents the category and can be a discrete or a multipart type. The subtype is specific to each type.\nFor example, the type of application represents binary data, while text represents human readable data. The subtype then is more specific about the format of the data.\nContent-Type Content-Type is used in POST and PUT requests and defines the MIME type of the request body\nAuthorization Authorization contains authorization/authentication information of the client that is making a request.\nA standard signature looks similar to:\nAuthorization : credentials Authorization is outside of the scope of this particular lesson.\nUser-Agent User-Agent supplies the server with information about the client that is making the request.\nFor example:\nUser-Agent:Mozilla/5.0 (Macintosh; Intel Mac OS SOME_VERSION_HERE) Chrome/VERSION_NUMBER_HERE You can view the full list of HTTP header KEYS here and here\nRequest Body The request body, also known as the payload, is the representation of data that is being sent transferred in the request/response cycle.\nWhen a user submits a form, the form data is sent in the request body. For example, take a todo application\n{ \u0026#34;task\u0026#34;: { \u0026#34;name\u0026#34; : \u0026#34;Build an API\u0026#34;, \u0026#34;dueDate\u0026#34; : \u0026#34;1/20/2019\u0026#34;, \u0026#34;userId\u0026#34; : \u0026#34;1\u0026#34; } }  API\u0026rsquo;s often expect to send/receive data as JSON. The server will take that representation, perform an operation, and provide a JSON representation as a response.\n HTTP status codes This leads us into working with status codes.\nAccording to Mozilla\n HTTP response status codes indicate whether a specific HTTP request has been successfully completed. Responses are grouped in five classes: informational responses, successful responses, redirects, client errors, and servers errors.\n You can think of status codes as being grouped into 5 different families:\n 100 family - represents information 200 family - represents successful actions 300 family - represent redirects (as seen earlier) 400 family - represent client errors 500 family - represent server errors  Within each family/group we can find specific responses to fit the situation.\nCheck out the REST API tutorial for details on each status code.\nSummary  REST is a pattern for creating Web based APIs. REST uses HTTP methods to define the CRUD operation and URLs to define the data we want to operate on. Clients send a request with a representation of data, and servers respond with representations of data. As a result of this transfer, our client\u0026rsquo;s state is modified  Additional Resources  Wikipedia on REST REST API Tutorial Authentication Methods Explained The Anatomy of an HTTP POST Request  "
},
{
	"uri": "/javascript/pillars/resiliency-patterns/syllabus/",
	"title": "Syllabus",
	"tags": [],
	"description": "",
	"content": "Topics Course Description Details Requirements Prerequisites Outcomes   Schedule   Course Description Details Resiliency is the ability of a system to gracefully handle and recover from failures. The Retry and Circuit Breaker patterns are important for gracefully handling failures from upstream services. The Retry provides a way for handling services that are experiencing transient faults, while the Circuit Breaker pattern provides for handling persistent faults.\n  Requirements A laptop with node, npm or yarn, and your favorite text editor installed. Bring your own water bottle and/or coffee cup.\n  Prerequisites   A solid knowledge of the JavaScript language\n  Experience with JavaScript Promises and asynchronous operations\n  Experience with NodeJS and Express\n  Experience building RESTful APIs\n    Outcomes   Explain resiliency and resiliency patterns\n  Implement the Retry resiliency pattern in a NodeJS / Express application\n  Implement the Circuit Breaker resiliency pattern in a NodeJS / Express application\n      Schedule Lessons and Labs  Introduction to Resiliency Patterns\n  The Retry Pattern\n  The Circuit Breaker Pattern\n  Retry and Circuit Breaker Labs\n         "
},
{
	"uri": "/javascript/pillars/restful-api-express-node/syllabus/",
	"title": "Syllabus",
	"tags": [],
	"description": "",
	"content": "Learn how to build RESTful APIs with NodeJS and Express.\n Details RESTful APIs have become foundational to building web applications. Whether building a microservice or building an application server behind a modern UI front end, a RESTful API is essential for managing and processing data. In this course we will learn how to map the 4 CRUD operations (Create, Read, Update, and Delete) to RESTful routes, how to create nested routes, how to handle errors, and how to test with cURL and Postman.\n   Requirements A laptop with node, npm or yarn, and your favorite text editor installed. Bring your own water bottle and/or coffee cup.\n   Prerequisites Foundational knowledge of modern JavaScript (including ES6). Understanding of web fundamentals (HTTP, HTML).\n   Outcomes   How to design a RESTful API for processing data\n  How to write RESTful APIs in NodeJS and Express\n  How to handle and report errors\n     Schedule NodeJS and Helpful Tools  Node Refresher\n  Create a Node Server\n  Getting Started With Postman\n  Nodemon\n       Express  RESTful APIs\n  Express: An Introduction\n  Class Directory Lab\n     Express MVC\n  Lab for Express MVC\n     Error Handling with Express\n  Cumulative Lab for Node and Express API Pillar\n  Testing Express\n  Deploying to PCF\n         "
},
{
	"uri": "/onboarding/cyber-security/cyber-associates/module-1-mission/",
	"title": "The Cyber Mission",
	"tags": [],
	"description": "",
	"content": "Protect What Matters Most Mission To provide an agile, scalable and seamless approach to cybersecurity service delivery aligned to our current threat landscape and adaptable to The Home Depot’s goals and priorities.\nFor a detailed look at our mission and vision, see the power point presentations on the Cybersecurity Confluence homepage.\nTransformation In 2019 Cybersecurity began a process of transformation with our new CISO, Stephen Ward. Each department is assessed based on maturity level and given resources and strategy to increase their capabilities. We are still transforming to various degrees, the focus areas are listed in the section below.\nFor more details, see the power point presentations on the Cybersecurity Confluence homepage.\n2020 Focus Areas In 2020 we have set our sights on modernizing our security posture and increasing the robustness of our everyday business activities. Below we will outline the targets, for a more detailed look consult the road map on the Cybersecurity Confluence homepage.\n Secure our Payments Environment:  Enforce adherence to PCI by leveraging technological solutions. Identify high value information and expand data loss prevention (DLP) capabilities.   Modernize Network and Cloud Security:  Increase visibility into emerging threats across network, cloud, SaaS, and remote work environments.   Enhance our Maturity:  Enable a culture focused on security, risk, and resilience of critical business services Simplify the Cybersecurity engagement experience. Create amazing leaders and invest in our Cybersecurity talent to build new and mature existing capabilities and services.   For more details, see the power point presentations on the Cybersecurity Confluence homepage.  Key Functions (Services) The following are the key cybersecurity services being offered, with their respective sub-services. for more details, see the power point presentations on the Cybersecurity Confluence homepage.\nArchitecture\n Mission  Improves and enhances the architecture of The Home Depot by including security in all stages of design.   Strategy  Provide secure designs and an innovative technology strategy, enabling the organization to implement secure from the start solutions.   Sub-services  Application Development Cyber Solutions Engineering Secure Design    Governance\n Mission  Establish methodologies and controls to identify, monitor, and treat Cybersecurity risks.   Strategy  Establish a governance model for the cybersecurity program enabled by policies, standards and risk methodology.   Sub-services  Risk Assessment Methods and Analysis Security Policies and Standards Governance Design and Operation    Identity and Access Management\n Mission  Advance THD’s business, IT, and cybersecurity strategic objectives by enabling, enforcing and empowering secure access to information.   Strategy  Simplify the identity and access lifecycle to enable secure and modern enterprise-wide practices.   Sub-services  Customer IAM (CIAM) Authentication and Password Management (APM) Data and Directory Services Identity Analytics Identity and Access Lifecycle Management Privileged Access Management (PAM)    Internal Threat Operations\n Mission  Enable the business to continue using THD’s information assets, applications, and systems while supporting the appropriate levels of protection commensurate to the risk of loss and mitigation of internal threats.   Strategy  Modernize our data protection capabilities to identify and protect what matters most.   Sub-services  Data Protection Certificate Management Encryption Solutions Digital Forensics and e-Discovery Insider Threat    Issue and Compliance Management\n Mission  Provide guidance on efficient handling of issues such as management and remediation as well as to help THD maintain compliance to regulations and laws and efficiently assesses and verifies controls.   Strategy  Enhance program governance and manage resolution of risks and control gaps to enable ongoing SOX and PCI compliance.   Sub-services  Issue Management and Remediation Regulatory Compliance (IT SOX) Regulatory Compliance (PCI)    Risk Assessment Advisory\n Mission  Assist the cybersecurity program in identifying and analyzing risks to the enterprise and measure effectiveness of controls.   Strategy  Transform the risk assessment program to improve identification and awareness of risks and control gaps.   Sub-services  Perimeter Infrastructure Risk Assessment (PIRA) Risk Assessments and Advisory Third Party Risk Management    Security Consulting\n Mission  Enable project teams across the enterprise to leverage the cybersecurity program in reaching their goals in a secure manner and to provide measurements of inherent risk for risk based decision making.   Strategy  Empower the business to execute strategic initiatives with an awareness and appreciation for cybersecurity risks.   *Sub-services *  Cybersecurity Consultants Cybersecurity Insights    Security Operations\n Mission  Continuously monitor and improve THD’s security posture.   Strategy  Organize, train and equip security operations teams to elevate beyond reactive triage and continue building proactive, optimized services harnessing entrepreneurial spirit throughout the organization.   Sub-services  Network Security Operations Application Security Red Team Security Analytics and Cyber Threat Intelligence Threat Detection and Response SOC Systems Engineering Vulnerability Management    Service Optimization\n Mission  Make existing security processes more efficient by using automation, orchestration and data analytics.   Strategy  Increase security efficiency through orchestration and analytics.   Sub-services  GRC Technology Security Analytics    Strategic Planning\n Mission  Enable the Cybersecurity program to effectively support THD’s IT road map and strategic business objectives.   Strategy  Provide the governance, measurements, processes, and programs that enable the transformation to protect what matters most.   Sub-services  Finance Planning and Reporting Cyberculture and Engagement Human Capital Planning Metrics PMO \u0026amp; Portfolio Management Strategy and Service Management    A message from our CISO \u0026amp; Tech News Cyber Security - Tech News\n"
},
{
	"uri": "/path-to-production/before-you-build/12factor/",
	"title": "The Twelve-Factor App",
	"tags": [],
	"description": "",
	"content": "The Twelve-Factor App the set of best practices and standards for producing cloud native apps. By implementing the 12 Factor App, we can have scalable, maintainable, and portable services. Your app should be written and deployed to meet these standards as close as possible.\nBenefits of the Twelve-Factor App\n  Minimizes time and cost for new developers joining the project.\n  Offers maximum portability between execution environments.\n  Suitable for deployment on modern cloud platforms.\n  Removes the need for servers and systems administration.\n  Minimizes divergence between development and production.\n  Enables continuous deployment for maximum agility.\n  Scales up without significant changes to tooling and architecture.\n  The 12 Factors\nYou can read through detailed descriptions of all 12 factors on 12factor.net. If you are new to SaaS or cloud native applications, some of this may be difficult to grasp as written. The follow are good additional resources:\n Plain English version of 12 Factor App Video: 5 Years of 12 Factor Apps by Joe Kutner  "
},
{
	"uri": "/python/web_scraping/scrapy/",
	"title": "Web Scraping Tutorial",
	"tags": [],
	"description": "",
	"content": "Source\nScrapy Tutorial — Scrapy 1.5.0 documentation In this tutorial, we\u0026rsquo;ll assume that Scrapy is already installed on your system. If that\u0026rsquo;s not the case, see Installation guide.\nWe are going to scrape quotes.toscrape.com, a website that lists quotes from famous authors.\nThis tutorial will walk you through these tasks:\n Creating a new Scrapy project Writing a spider to crawl a site and extract data Exporting the scraped data using the command line Changing spider to recursively follow links Using spider arguments  Scrapy is written in Python. If you\u0026rsquo;re new to the language you might want to start by getting an idea of what the language is like, to get the most out of Scrapy.\nIf you\u0026rsquo;re already familiar with other languages, and want to learn Python quickly, we recommend reading through Dive Into Python 3. Alternatively, you can follow the Python Tutorial.\nIf you\u0026rsquo;re new to programming and want to start with Python, you may find useful the online book Learn Python The Hard Way. You can also take a look at this list of Python resources for non-programmers.\nCreating a project Before you start scraping, you will have to set up a new Scrapy project. Enter a directory where you\u0026rsquo;d like to store your code and run:\nscrapy startproject tutorial This will create a tutorial directory with the following contents:\ntutorial/ scrapy.cfg # deploy configuration file tutorial/ # project\u0026#39;s Python module, you\u0026#39;ll import your code from here __init__.py items.py # project items definition file middlewares.py # project middlewares file pipelines.py # project pipelines file settings.py # project settings file spiders/ # a directory where you\u0026#39;ll later put your spiders __init__.py Our first Spider Spiders are classes that you define and that Scrapy uses to scrape information from a website (or a group of websites). They must subclass scrapy.Spider and define the initial requests to make, optionally how to follow links in the pages, and how to parse the downloaded page content to extract data.\nThis is the code for our first Spider. Save it in a file named quotes_spider.py under the tutorial/spiders directory in your project:\nimport scrapy class QuotesSpider(scrapy.Spider): name = \u0026#34;quotes\u0026#34; def start_requests(self): urls = [ \u0026#39;http://quotes.toscrape.com/page/1/\u0026#39;, \u0026#39;http://quotes.toscrape.com/page/2/\u0026#39;, ] for url in urls: yield scrapy.Request(url=url, callback=self.parse) def parse(self, response): page = response.url.split(\u0026#34;/\u0026#34;)[-2] filename = \u0026#39;quotes-%s.html\u0026#39; % page with open(filename, \u0026#39;wb\u0026#39;) as f: f.write(response.body) self.log(\u0026#39;Saved file %s\u0026#39; % filename) As you can see, our Spider subclasses scrapy.Spider and defines some attributes and methods:\n name: identifies the Spider. It must be unique within a project, that is, you can\u0026rsquo;t set the same name for different Spiders. start_requests(): must return an iterable of Requests (you can return a list of requests or write a generator function) which the Spider will begin to crawl from. Subsequent requests will be generated successively from these initial requests. parse(): a method that will be called to handle the response downloaded for each of the requests made. The response parameter is an instance of TextResponse that holds the page content and has further helpful methods to handle it.  The parse() method usually parses the response, extracting the scraped data as dicts and also finding new URLs to follow and creating new requests (Request) from them.\nHow to run our spider To put our spider to work, go to the project\u0026rsquo;s top level directory and run:\nThis command runs the spider with name quotes that we\u0026rsquo;ve just added, that will send some requests for the quotes.toscrape.com domain. You will get an output similar to this:\n... (omitted for brevity) 2016-12-16 21:24:05 [scrapy.core.engine] INFO: Spider opened 2016-12-16 21:24:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min) 2016-12-16 21:24:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023 2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (404) (referer: None) 2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) (referer: None) 2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) (referer: None) 2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-1.html 2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-2.html 2016-12-16 21:24:05 [scrapy.core.engine] INFO: Closing spider (finished) ... Now, check the files in the current directory. You should notice that two new files have been created: quotes-1.html and quotes-2.html, with the content for the respective URLs, as our parse method instructs.\nNote\nIf you are wondering why we haven\u0026rsquo;t parsed the HTML yet, hold on, we will cover that soon.\nWhat just happened under the hood? Scrapy schedules the scrapy.Request objects returned by the start_requests method of the Spider. Upon receiving a response for each one, it instantiates Response objects and calls the callback method associated with the request (in this case, the parse method) passing the response as argument.\nA shortcut to the start_requests method Instead of implementing a start_requests() method that generates scrapy.Request objects from URLs, you can just define a start_urls class attribute with a list of URLs. This list will then be used by the default implementation of start_requests() to create the initial requests for your spider:\nimport scrapy class QuotesSpider(scrapy.Spider): name = \u0026#34;quotes\u0026#34; start_urls = [ \u0026#39;http://quotes.toscrape.com/page/1/\u0026#39;, \u0026#39;http://quotes.toscrape.com/page/2/\u0026#39;, ] def parse(self, response): page = response.url.split(\u0026#34;/\u0026#34;)[-2] filename = \u0026#39;quotes-%s.html\u0026#39; % page with open(filename, \u0026#39;wb\u0026#39;) as f: f.write(response.body) The parse() method will be called to handle each of the requests for those URLs, even though we haven\u0026rsquo;t explicitly told Scrapy to do so. This happens because parse() is Scrapy\u0026rsquo;s default callback method, which is called for requests without an explicitly assigned callback.\nStoring the scraped data The simplest way to store the scraped data is by using Feed exports, with the following command:\nscrapy crawl quotes -o quotes.json That will generate an quotes.json file containing all scraped items, serialized in JSON.\nFor historic reasons, Scrapy appends to a given file instead of overwriting its contents. If you run this command twice without removing the file before the second time, you\u0026rsquo;ll end up with a broken JSON file.\nYou can also use other formats, like JSON Lines:\nscrapy crawl quotes -o quotes.jl The JSON Lines format is useful because it\u0026rsquo;s stream-like, you can easily append new records to it. It doesn\u0026rsquo;t have the same problem of JSON when you run twice. Also, as each record is a separate line, you can process big files without having to fit everything in memory, there are tools like JQ to help doing that at the command-line.\nIn small projects (like the one in this tutorial), that should be enough. However, if you want to perform more complex things with the scraped items, you can write an Item Pipeline. A placeholder file for Item Pipelines has been set up for you when the project is created, in tutorial/pipelines.py. Though you don\u0026rsquo;t need to implement any item pipelines if you just want to store the scraped items.\nFollowing links Let\u0026rsquo;s say, instead of just scraping the stuff from the first two pages from , you want quotes from all the pages in the website.\nNow that you know how to extract data from pages, let\u0026rsquo;s see how to follow links from them.\nFirst thing is to extract the link to the page we want to follow. Examining our page, we can see there is a link to the next page with the following markup:\nNext → We can try extracting it in the shell:\n\u0026gt;\u0026gt;\u0026gt; response.css(\u0026#39;li.next a\u0026#39;).extract_first() \u0026#39;Next →\u0026#39; This gets the anchor element, but we want the attribute href. For that, Scrapy supports a CSS extension that let\u0026rsquo;s you select the attribute contents, like this:\n\u0026gt;\u0026gt;\u0026gt; response.css(\u0026#39;li.next a::attr(href)\u0026#39;).extract_first() \u0026#39;/page/2/\u0026#39; Let\u0026rsquo;s see now our spider modified to recursively follow the link to the next page, extracting data from it:\nimport scrapy class QuotesSpider(scrapy.Spider): name = \u0026#34;quotes\u0026#34; start_urls = [ \u0026#39;http://quotes.toscrape.com/page/1/\u0026#39;, ] def parse(self, response): for quote in response.css(\u0026#39;div.quote\u0026#39;): yield { \u0026#39;text\u0026#39;: quote.css(\u0026#39;span.text::text\u0026#39;).extract_first(), \u0026#39;author\u0026#39;: quote.css(\u0026#39;small.author::text\u0026#39;).extract_first(), \u0026#39;tags\u0026#39;: quote.css(\u0026#39;div.tags a.tag::text\u0026#39;).extract(), } next_page = response.css(\u0026#39;li.next a::attr(href)\u0026#39;).extract_first() if next_page is not None: next_page = response.urljoin(next_page) yield scrapy.Request(next_page, callback=self.parse) Now, after extracting the data, the parse() method looks for the link to the next page, builds a full absolute URL using the urljoin() method (since the links can be relative) and yields a new request to the next page, registering itself as callback to handle the data extraction for the next page and to keep the crawling going through all the pages.\nWhat you see here is Scrapy\u0026rsquo;s mechanism of following links: when you yield a Request in a callback method, Scrapy will schedule that request to be sent and register a callback method to be executed when that request finishes.\nUsing this, you can build complex crawlers that follow links according to rules you define, and extract different kinds of data depending on the page it\u0026rsquo;s visiting.\nIn our example, it creates a sort of loop, following all the links to the next page until it doesn\u0026rsquo;t find one – handy for crawling blogs, forums and other sites with pagination.\nA shortcut for creating Requests As a shortcut for creating Request objects you can use [response.follow]23:\nimport scrapy class QuotesSpider(scrapy.Spider): name = \u0026#34;quotes\u0026#34; start_urls = [ \u0026#39;http://quotes.toscrape.com/page/1/\u0026#39;, ] def parse(self, response): for quote in response.css(\u0026#39;div.quote\u0026#39;): yield { \u0026#39;text\u0026#39;: quote.css(\u0026#39;span.text::text\u0026#39;).extract_first(), \u0026#39;author\u0026#39;: quote.css(\u0026#39;span small::text\u0026#39;).extract_first(), \u0026#39;tags\u0026#39;: quote.css(\u0026#39;div.tags a.tag::text\u0026#39;).extract(), } next_page = response.css(\u0026#39;li.next a::attr(href)\u0026#39;).extract_first() if next_page is not None: yield response.follow(next_page, callback=self.parse) Unlike scrapy.Request, response.follow supports relative URLs directly - no need to call urljoin. Note that response.follow just returns a Request instance; you still have to yield this Request.\nYou can also pass a selector to response.follow instead of a string; this selector should extract necessary attributes:\nfor href in response.css(\u0026#39;li.next a::attr(href)\u0026#39;): yield response.follow(href, callback=self.parse) For `` elements there is a shortcut: response.follow uses their href attribute automatically. So the code can be shortened further:\nfor a in response.css(\u0026#39;li.next a\u0026#39;): yield response.follow(a, callback=self.parse) Note\nresponse.follow(response.css('li.next a')) is not valid because response.css returns a list-like object with selectors for all results, not a single selector. A for loop like in the example above, or response.follow(response.css('li.next a')[0]) is fine.\nMore examples and patterns Here is another spider that illustrates callbacks and following links, this time for scraping author information:\nimport scrapy class AuthorSpider(scrapy.Spider): name = \u0026#39;author\u0026#39; start_urls = [\u0026#39;http://quotes.toscrape.com/\u0026#39;] def parse(self, response): # follow links to author pages for href in response.css(\u0026#39;.author + a::attr(href)\u0026#39;): yield response.follow(href, self.parse_author) # follow pagination links for href in response.css(\u0026#39;li.next a::attr(href)\u0026#39;): yield response.follow(href, self.parse) def parse_author(self, response): def extract_with_css(query): return response.css(query).extract_first().strip() yield { \u0026#39;name\u0026#39;: extract_with_css(\u0026#39;h3.author-title::text\u0026#39;), \u0026#39;birthdate\u0026#39;: extract_with_css(\u0026#39;.author-born-date::text\u0026#39;), \u0026#39;bio\u0026#39;: extract_with_css(\u0026#39;.author-description::text\u0026#39;), } This spider will start from the main page, it will follow all the links to the authors pages calling the parse_author callback for each of them, and also the pagination links with the parse callback as we saw before.\nHere we\u0026rsquo;re passing callbacks to response.follow as positional arguments to make the code shorter; it also works for scrapy.Request.\nThe parse_author callback defines a helper function to extract and cleanup the data from a CSS query and yields the Python dict with the author data.\nAnother interesting thing this spider demonstrates is that, even if there are many quotes from the same author, we don\u0026rsquo;t need to worry about visiting the same author page multiple times. By default, Scrapy filters out duplicated requests to URLs already visited, avoiding the problem of hitting servers too much because of a programming mistake. This can be configured by the setting [DUPEFILTER_CLASS]24.\nHopefully by now you have a good understanding of how to use the mechanism of following links and callbacks with Scrapy.\nAs yet another example spider that leverages the mechanism of following links, check out the [CrawlSpider]25 class for a generic spider that implements a small rules engine that you can use to write your crawlers on top of it.\nAlso, a common pattern is to build an item with data from more than one page, using a trick to pass additional data to the callbacks.\nUsing spider arguments You can provide command line arguments to your spiders by using the -a option when running them:\nscrapy crawl quotes -o quotes-humor.json -a tag=humor These arguments are passed to the Spider\u0026rsquo;s __init__ method and become spider attributes by default.\nIn this example, the value provided for the tag argument will be available via self.tag. You can use this to make your spider fetch only quotes with a specific tag, building the URL based on the argument:\nimport scrapy class QuotesSpider(scrapy.Spider): name = \u0026#34;quotes\u0026#34; def start_requests(self): url = \u0026#39;http://quotes.toscrape.com/\u0026#39; tag = getattr(self, \u0026#39;tag\u0026#39;, None) if tag is not None: url = url + \u0026#39;tag/\u0026#39; + tag yield scrapy.Request(url, self.parse) def parse(self, response): for quote in response.css(\u0026#39;div.quote\u0026#39;): yield { \u0026#39;text\u0026#39;: quote.css(\u0026#39;span.text::text\u0026#39;).extract_first(), \u0026#39;author\u0026#39;: quote.css(\u0026#39;small.author::text\u0026#39;).extract_first(), } next_page = response.css(\u0026#39;li.next a::attr(href)\u0026#39;).extract_first() if next_page is not None: yield response.follow(next_page, self.parse) If you pass the tag=humor argument to this spider, you\u0026rsquo;ll notice that it will only visit URLs from the humor tag, such as http://quotes.toscrape.com/tag/humor.\nNext steps You can learn more about handling spider arguments and more Scrapy tutorials here.\n"
},
{
	"uri": "/path-to-production/tech-stack/data/",
	"title": "Choosing your Data Solution",
	"tags": [],
	"description": "",
	"content": "Data Classification Before you choose a data service, you will need to understand the data classification under which the data for your application falls.\nThis document provides a guideline on how data is classified, and how it needs to be treated throughout your solution.\nIf your data falls into any of the following categories, you will want to check with IT Security to determine the approved solution for you data.\n PII - Personal Identifiable Information Confidential Restricted PCI - Payment Card Information FI SOX   Database as a Service (DBaaS) If your data does not fall into any of the above categories, you can request on-prem databases through a DBaaS self-service.\nWhy?\nWhy choose DBaaS? Having the ability to request a database on demand can have your data base up in running in about 10 minutes. No more long waits on getting access or to have things provisioned. You control the tempo once it is generated.\nWhile you are in control of your data, the infrastructure team provides support for:\n Updates Backup Monitoring DB Health DB Backups   Databases Offered Through the Service On Prem:\n MongoDB Cassandra MySQL MSSQL Oracle PostgresSQL  Coming soon:\n Redis  Cloud Databases\nSolutions for GCP and MS Azure are coming soon.\n Access Request to DBaaS All DBaaS users must be a member of the Active Directory Group: GG_DBaaS_Self_Provisioning to authenticate their credentials.\nMembership to GG_DBaaS_Self_Provisioning can be requested through the Access Request Portal (ARP). Once approved, you will receive a verification email and all login attempts using the SSO login below will continue uninterrupted as long as the proper credentials are provided.\n How to request  Non Production aka QA Production  The following steps are for a non-production server, but are the same for a production server:\n  Login to the QA DBaaS site.\n  If you don\u0026rsquo;t have any databases, click the green box\n Otherwise select ProvisionDB from the top menu.    Click and Drag your Database of choice to the large gray rectangle with the flashing green message Drag a database here to Provision!. In this example, we will be using MariaDB.\n  Search for your project, select it and sub-experience : Search for your project, and then select the sub-experience Specify a name, abbreviation, and description of the application that will be using this database    Scroll down and fill out the database \u0026amp; security info  Database info\na. Life Cycle = QA/Non-Prod\nb. Initial Size = Small (1GB) (or the size you think you need)\nc. Description = Describe the purpose of your database\nd. Choose a password. IMPORTANT Remember this password. It is the password you will use to access your database!\n  Data Security is for internal use only\n  Once you click the agreement checkbox, click \u0026ldquo;ProvisionDB\u0026rdquo;\n    Wait for the email, or navigate back to the front page and eventually your database info will show up there.\n  Once complete, you will receive an email with the connection information (but not the password):   Contact information Service support can be found in the #DBaaS slack channel. Additionally the following channels are set up for each database:\n   Database Channel     MongoDB #mongodb   Cassandra #dbass-cassandra   MariaDB #mariadb   MSSQL \u0026amp; Oracle #dbaas_support     Homer Buckets: Azure Blob, Google Cloud Storage Homer Bucket is a self-service request process for requesting storage options on either GCP (Cloud Storage) or Microsoft\u0026rsquo;s Azure Blob Storage. If you need to store or stage data in a shared manner, then a Homer Bucket may be a solution for you.\nOther Use Cases:\n Store config files Archive log files Backup data and files Perfect for TeamCity and Concourse Stage deployment artifacts Move files between on-prem and cloud or cloud to cloud Share files with other trusted sources Store large amounts of unstructured objects to be used by a micro-service or application, like content, images, or videos.  Note: Buckets are not to be used to store Restricted, PCI, PII, or Confidential Data without the explicit approval from the security team. Enter a security assessment request via the Security Assessment Portal.\nRequesting a Storage Bucket   Navigate to the Homer Bucket Service Request Form\n  Fill out the form with your LDAP, a manager or above\u0026rsquo;s name and your experience.\n  Submit and you should get the following message:\n  Once approved, you should receive an email with the credentials.\n Open the confirmation email Click on the “Click Here” in the Bucket Details section Copy the client_email value, this is your SVC account name Save the file with a .json extension   Accessing your Google Bucket To access your google cloud bucket, you can use the gsutil command that can be installed with gcloud, which in turn can be installed from the Google Cloud SDK. While you can install through the official site, it is recommended that you install through THD App Store on mac, or the Software Center if you are using Windows.\nOnce the SDK is installed, you should be able to open a terminal, powershell or command prompt, and run the following command:\n$ gcloud components install gsutil You can then follow this guide to log in and access your bucket with gsutil\nAccessing your Microsoft Blob Storage To access MS Blob Storage, you can download the Storage Explorer. There is also a cli option that can be installed.\nBrew:\nbrew install azure-cli Chocolaty:\nchoco install azure-cli For further information on using Azure Blob Storage that you requested from the Homer Bucket service see this documentation\nHomer Bucket Support For support of questions see the official page or join the #Io1-Cloud slack channel.\n"
},
{
	"uri": "/onboarding/general/module-2-performance/",
	"title": "Company Performance, Strategy, &amp; Transformation",
	"tags": [],
	"description": "",
	"content": "Company Overview   Today, The Home Depot operates throughout North America and US territories, and is the 5th largest retail ecommerce company the US. Source\n Company Overview Highlights  2,288 Total Number of Stores Average Store Size is ~128k SqFt. More than 400k Associates    2019 Year in Review   Source\n 2019 in Review Highlights  Total sales of $110.2B Interconnected/Digital sales +21.4% over 2018 New Tagline! “How doers get more done.” 21 on the Forbes Most Admired Companies list    Q2 2020 Review   Source\n Q2 Highlights  38.1B in total Sales Online sales increased 100% More than 60% of online orders were picked up in-store    Company Strategy Our corporate strategy focuses on providing excellent customer service for our customers… As well as creating value for our shareholders!\nOne Home Depot Customers are blending the the physical and digital worlds as they shop now more than ever. Our goal is to make it easy for customers to do business with us - whether they transact online, research online and buy on store, need a quick delivery, want to pay for services in cart… and beyond.\nTo execute our strategy, we have committed approximately $11 billion over a multi-year period to key investments. Click below to hear Craig Menear say a few words about One Home Depot\n  What the investment looks like   What that means To expand on what Craig Menear said:\n Our investment in Stores helps us drive greater convenience and speed for customer. Our investment in Associates helps us maintain a competitive and agile workforce. Our investment in the Interconnected Experience allows us to create the best interconnected experience. Our investment in Product \u0026amp; Innovation allows us to maintain position as the #1 retailed in product authority. Our investment in Pro \u0026amp; Services lets us deliver one integrated approach for our Pro customers. Our investment in Supply Chain \u0026amp; Delivery enables us to offer the fastest and most efficient delivery in home improvement.  Enterprise Priorities Our overall 2020 objectives are:\n Grow Market share with the Pro and the customer Deliver shareholder value.  The goals we have in aid of these objectives are respectively:\n $120B in sales maintaining a 14.4% - 15% Operating margin and 45%+ Return on Investment Capital.  The way we reach these goals are through our enduring strategies. Connect associates to customer needs, Connect products \u0026amp; services to customer needs, Connect product to shelf, site \u0026amp; customer, Connect experience (store to online, online to store), and Innovate our business model \u0026amp; value chain.\n  As we have worked towards our goals as a company, there has arisen a need to fix some older legacy IT systems and processes, before we can stand up new systems. These underlying systems and processes are referred to as “big rocks”.\nOne example of “big rocks” is the One SKU initiative. Right now, the same hammer could have a different SKU online, from in the store, from in our MRO business - Interline. We need to address this so that every item only has one SKU - this allows systems to talk to each other and customers to seamlessly do business with us across any channels.\nEvery technology team has objectives and Key Results set for their product, that roll up to these objectives. They roll down from the organization level, to the portfolio, to experience, to product team. You will learn more about this as you join your product teams.\n2020 Strategy   Here are the strategies we are working on in support of our 2020 goals:\n  Connect associates to customer needs: We’ll empower associates to provide industry-leading customer service with differentiated staffing models, tools and organizational support to meet the needs of our DIY and Pro customers\n  Connect products \u0026amp; services to customer needs: We’ll help our customers tackle any project with compelling assortments at the right prices and services delivered by trusted Pros\n  Connect product to shelf, site \u0026amp; customer: We’ll continue to build an efficient end-to-end supply chain that delivers product to customers when and where they want – and we’ll set the standard for “last mile” delivery in home improvement\n  Interconnected experience (store to online, online to store): We’ll offer an interconnected shopping experience for customers, leveraging our stores, online platform and mobile app\n  Innovate our business model \u0026amp; value chain: We’ll seek ways to operate more efficiently to support growth opportunities across our business\n  Each associate will have a role in helping us work through those five strategies and we will focus on the commitment we have to our customers, both internally and externally, to make that happen.\nThe Technology Transformation A few year ago The Home Depot began as process of transforming into a modern technology environment. In this section, we’ll talk about what that looks like. Keep in mind that although this is our north star, we are very much still in transformation. Some teams are still working in under the old processes, or slowly adopting the changes.\nThis will equip you to understand the direction the company is moving in, and why. It will also help you work with other teams you encounter, if your space is not fully adopting these practices.\nHow we used to build: On Time \u0026amp; On Budget Our business partners would give us an allotment of dollars and a huge requirements documents. You might have heard things like:\n  \u0026ldquo;Here’s $1 million dollars, build us an application in 1 year. And here’s a document with all the things it needs to do.\u0026rdquo;\n  So our process would look something like this.\n We would spend a lot of time upfront planning - maybe 2 months. Spend another 2 months working on designing something - now we’re at 4 months. Another 3 months building - now we’re at 7 months. Then of course test it, and fix everything that went wrong for a months. This could take us up to 11 months. Now we finally go through the process of deploying it. Of course these timelines never stay as planned. There are things we could not have known upfront, and the timeline for each stage slips a little. Until you are 12 months, 13 months, 14 months, or even more.    How we build now: Agile While being on time and on budget sound like reasonable goals now we focus on:\n Feedback Learning Providing a positive customer experience Higher efficiency and productivity This change in our mindset ultimately provides the most value, and makes us successful.  Click the pictures below to see representations of how we used to build vs how we build now     Why change? Changing to an Agile Mindset allowed us to minimize risk by changing what we built and how, engaging users and stakeholders often, iterating quickly to integrate feedback. The benefits of moving to a product mindset are:\n Adapting rapidly to customer needs and expectations Moving us ahead of our competition Ability to provide transparency, predictable costs, improved productivity and quality to our customer Focusing on business value delivered through software solutions  "
},
{
	"uri": "/path-to-production/dev-environment/",
	"title": "Configure Your Development Environment",
	"tags": [],
	"description": "",
	"content": "Objectives Once complete, you should be able to:\n Use the cf-cli Configure orgs and spaces in PCF Add users to orgs and spaces Complete basic queries with the cfapi graphql instance.  Index "
},
{
	"uri": "/cloud/containers/developing-with-docker/containerizing-your-application/",
	"title": "Containerizing Your Application",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Containerizing Your Application Course Offerings "
},
{
	"uri": "/onboarding/cyber-security/general/module-2-hygiene/",
	"title": "Cyber Hygiene",
	"tags": [],
	"description": "",
	"content": "Topics  Cyber Hygiene Passwords Data Protection VPN Email Lost and Stolen Devices  Cyber Hygiene In 2014 Home Depot was hit with a cyber attack. It cost the company millions in settlement and hurt our reputation.\nNot every security event is a major hack that gets news coverage. Security incidents come in all shapes and sizes, and most of them can be prevented by following basic cyber hygiene. Just like with regular hygiene, cyber hygiene should be baked in to your daily routine until it becomes automatic.\nPasswords Creating strong passwords is important to protect your personal data. Many hackers exploit weak or reused passwords in order to gain an initial foothold. Lets walk through creating a strong password.\n   Secure Passwords      1. Passphrase fivegallonhomerbucket   2. Capital Letters fiveGallonHomerBucket   3. Numbers 5Gall0nH0merBucket   4. Special Characters 5Ga!!0nHomerBucket?    Passphrases are longer and easy to remember than passwords. Capital letters, numbers, and special characters increase complexity, making the password harder to break. Complexity requirements are enforced for your Single Sign On (SSO) password. You should adhere to these requirements for all other passwords you create to ensure your accounts are secure.\nPassword Tips\n Don\u0026rsquo;t reuse passwords on other sites Change your password frequently in accordance with policy Use an easy to remember password instead of storing it  Home Depot Case Study\nCybersecurity has found passwords stored in text files, stored in Confluence, and other applications. Don\u0026rsquo;t store your passwords on your computer or anywhere else someone is going to find them!\n Single Sign On (SSO)   Single Sign On (SSO) will allow you to access all home depot approved applications that require authentication using your Home Depot credentials.\nAny software that is created or purchased that requires authentication will have SSO as a requirement.\n External Media   Use of external media such as flash drives should be avoided and it is typically prohibited to save data to an external device.\nExternal storage devices can contain viruses, so make sure you trust the source if you are pulling information from one.\nInstead of using external media there are company sanctioned solutions, like OneDrive, to store data and share data.\n Data Protection As part of your job you will be working with proprietary data that belongs to Home Depot. Data protection means using common sense when working with company data; lets take a look at some quick tips to make sure you stay secure.\n Use sanctioned applications if at all possible, such as those from The Home Depot app store. Keep your applications up to date; the updates fix known security issues that could lead to data loss. Use internal web applications, like github.homedepot.com, vs public ones like github.com for all proprietary data. Public github can be used for approved open source projects and leveraging code. For 3rd party code repositories, make sure they are scanned and secure, using Artifactory. (For Developers) For questions about approved software, contact your department’s Technology partner or email: technology_partner@homedepot.com    VPN Using a VPN is required when working from outside of the office. A VPN (virtual private network) will protect your data from ease-dropping and route it to Home Depot where it can be secured from threats.\n  Covid-19 has moved a large part of the workforce out of the office. This means it is harder to secure sensitive company data. It\u0026rsquo;s more important than ever to use a VPN to keep our workforce secure!\nHome Depot Case Study\nCybersecurity has found associates with 3rd party VPNs. These can contain vulnerabilities and are not sanctioned. Make sure to use the Cisco AnyConnect client that is provided.\nEmail Email is a critical business tool but is used heavily by attackers. In fact, more attacks come through email than any other source.\nQuarantine, safe list, block list\nSuspicious emails may be automatically quarantined. They can also be manually blocked, or approved. You can view your email quarantine at https://000e6601.pphosted.com:10020\nPhishing\nPhishing is the use of email to trick a user into downloading malware (viruses). It is the most common way attackers get into networks, because all it takes is one user to click the wrong link in an email.\nPhishing techniques:\n  Trust: appear as if it is from an official source.\n  Fear: imply the user has done something wrong.\n  Urgency: imply the user has missed an opportunity or not performed a necessary action.\n     What techniques do you see used in this email?\nNote: COVID-19 and Economic Impact Payment phishing schemes:\n  Scams concerning the economic impact payments: These payments will be distributed automatically and will not require action from most people. To avoid a scam, be cautious with any request for personal information or money in exchange for expedited payment, never send money to anyone else in exchange for additional money, and never share your financial or personal information over the phone or in email. Also, be cautious with emails that use the phrase “stimulus package.”\n  Fraudulent email offers: Watch out for emails or pitches from people claiming to have high-demand medical and cleaning products like masks or sanitizers, especially if they encourage immediate action like “buy now, limited supply.” Look for branding irregularities, formatting and grammatical errors, and misspellings, which are common signs of phishing attempts.\n  Requests for personal information: Watch out for emails claiming to be from the World Health Organization or the Centers for Disease Control, especially if they request personal information. Legitimate government agencies won’t ask for sensitive information via email. Never respond with personal information.\n  Urgent alerts or notifications: Watch for suspicious emails that falsely link to medical advice. Never click on suspicious links or attachments. Instead, inspect the links within the email by hovering over them to reveal the URL.\n  Protecting yourself from phishing\n Report suspicious emails using the report phish button.  Engage with emailhygiene_cybersecurity@homedepot.com for questions and recommendations. Verify the sender and any URLs in the email.  Email Tips\n Don\u0026rsquo;t use personal email. Don\u0026rsquo;t access work email from non-work devices unless necessary. Be cautious of file sharing links, such as box.com, sent over email.  Home Depot Case Study\nMore than 20 million emails are blocked on a month to month basis for containing threats. Many associates have been phished, and phishing attempts happen every single day. Cybersecurity has had incidents where users were hacked over their personal email. Don\u0026rsquo;t use personal email, we can\u0026rsquo;t inspect it for attacks!\n   Lost and Stolen Devices A lost or stolen device can result in loss of sensitive data and productivity. Don\u0026rsquo;t leave your laptop unattended in your car or in public areas, associates have had their cars broken into for their laptops!\nUpon ending employment with Home Depot, return your laptop to your manager.\n"
},
{
	"uri": "/cloud/containers/developing-with-docker/",
	"title": "Developing with Docker",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Developing with Docker Course Offerings "
},
{
	"uri": "/onboarding/cyber-security/general/",
	"title": "General",
	"tags": [],
	"description": "",
	"content": "Introduction to Cybersecurity  Understand what Cybersecurity is Identify different domains and differentiate between them  Cyber Hygiene Security - A shared responsibility   Understand when to engage Cybersecurity\n  Understand how each role has a different responsibility for securing information\n  Understand how to report suspicious emails, engage Cybersecurity and review policies\n  Resources / Closing  Recap of contact information for Cybersecurity Links to Cybersecurity policies Secure Code Warrior PSRB - https://bit.ly/3eRzhkx  "
},
{
	"uri": "/javascript/nodejs/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "Getting Started with NodeJS "
},
{
	"uri": "/cloud/platforms/",
	"title": "Hosting",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Hosting Offerings "
},
{
	"uri": "/react/foundations/misc/intro-to-fp/",
	"title": "Intro to FP",
	"tags": [],
	"description": "",
	"content": "An brief introduction to Functional Programming\n Topics 1. Introduction 2. Example - Big Tipper 2.1. FP Solution   3. Example - Sum of Squares 3.1. FP Solution   4. Summary   1. Introduction \n With Functional Programming, each function gets data via its parameters and returns a result.\n   There are no dependencies on global state.\n  There are no side-effects!\n   \n   2. Example - Big Tipper Consider the following code:\n Big Tipper - Non FP let bigTipFactor = 0.20; let mediumTipFactor = 0.15; let smallTipFactor = 0.10; function calculateTip(amount, qualityOfService) { let tip = null; if (qualityOfService \u0026gt;= 8) { tip = amount * bigTipFactor; } else if (qualityOfService \u0026gt;= 5) { tip = amount * mediumTipFactor; } else { tip = amount * smallTipFactor; } return tip; } console.log(calculateTip(30.00, 9)); // prints 6 bigTipFactor = 0.28; console.log(calculateTip(30.00, 9)); // same args as before, but now prints 8.4       Here is a repl.it of the above code.     DISCUSS: What is wrong with the calculateTip code above? \n   DISCUSS: How would you fix the code? \n   2.1. FP Solution Here is an FP solution:\n Big Tipper - FP Solution function calculateTip(amount, qualityOfService, tipFactors) { let tip = null; if (qualityOfService \u0026gt;= 8) { tip = amount * tipFactors.bigTipFactor; } else if (qualityOfService \u0026gt;= 5) { tip = amount * tipFactors.mediumTipFactor; } else { tip = amount * tipFactors.smallTipFactor; } return tip; } const tipFactors = { bigTipFactor: 0.20, mediumTipFactor: 0.15, smallTipFactor: 0.10 }; console.log(calculateTip(30.00, 9, tipFactors)); tipFactors.bigTipFactor = 0.28; console.log(calculateTip(30.00, 9, tipFactors)); // different args, different answer!       Here is a repl.it of the above code.        3. Example - Sum of Squares Below is another example. In this example the function itself is pure, but the statements inside the function are not.\n Sum of Squares - Non FP function sumOfSquares(x) { let sum = 0; for (let i = 0; i \u0026lt; x.length; i++) { // i is being mutated. sum = sum + x[i] * x[i]; // sum is being mutated. } return sum; } console.log(sumOfSquares([1, 2, 3, 4, 5]));       Here is a repl.it of the above code.     In a pure functional programming language, even the \"variables\" inside a function are immutable.\n DISCUSS: How do we modify the sumOfSquares function to have no mutating variables? \n   3.1. FP Solution Sum of Squares - FP function sumOfSquares(x) { return x.map( n =\u0026gt; n * n ).reduce( (acc, n) =\u0026gt; acc + n, 0 ); } console.log(sumOfSquares([1, 2, 3, 4, 5]));       Here is a repl.it of the above code.     Does this code read better?\n    4. Summary The power and simplicity of functional programming is that we:\n   always get predictable results\n  can easily reason about large programs\n  can easily test functions\n  can easily compose (combine) functions to solve bigger problems - see: repl.it.\n       "
},
{
	"uri": "/javascript/nodejs/getting-started/npm-modules/intro-labs/",
	"title": "Labs for NPM",
	"tags": [],
	"description": "",
	"content": "Lab 1 - Installing and Using Node Packages  Create a new project named loggerApp   Make sure to create new directory and cd into it\n   Install chalk as a dependency\n  Using chalk in index.js\n print a the sentence \u0026ldquo;I am a JavaScript Ninja\u0026rdquo; to the terminal The sentence color should be bright blue or cyan The words \u0026ldquo;JavaScript Ninja\u0026rdquo; should be bold    Extra Credit:\n Add a blue or cyan background on \u0026ldquo;JavaScript Ninja\u0026rdquo; and use white text    Lab 2 - Create your own Node module Work with a teammate to create your own module named car.js\ncar.js should:\n define a car with properties and functions export the as a module to an index.js file.  Instructions\n  In the car.js file, define a Car constructor function\n  the Car constructor function should contain the following:\n Properties:  make, model, color, isConvertible (boolean), speed (set to 0 at first)   Methods:  toString method that returns a string containing the car\u0026rsquo;s color, make, model, and speed accelerate method should take one argument, the speed, and add it from the current speed decelerate method should take one argument, the speed, and subtract it from the current speed      car.js should export a Car constructor function that can be used by index.js to construct some cars.  In the index.js file:\n   require the module create a car object console log a message about your car object, including the current speed of the car.  "
},
{
	"uri": "/javascript/nodejs/getting-started/intro-to-node/",
	"title": "Node JS: An Introduction",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Explain what Node.js is \u0026amp; why it exists Compare synchronous and asynchronous code execution Explain the advantages of asynchronous I/O  Skills  Write a simple JavaScript program and execute it with Node.js Use npm or yarn to install node modules. Write a simple Node.js module using module.exports Import a Node.js module using require  What is Node.js? History Node.js was originally written in 2009 by Ryan Dahl. Dahl criticized the limited possibilities of the most popular web server in 2009, Apache HTTP Server, to handle a lot of concurrent connections (up to 10,000 and more) and the most common way of creating code (sequential programming), when code either blocked the entire process or implied multiple execution stacks in the case of simultaneous connections. Dahl demonstrated the project at the inaugural European JSConf on November 8, 2009. Node.js combined Google\u0026rsquo;s V8 JavaScript engine, an event loop and a low-level I/O API. The project received a standing ovation.\nIn January 2010, a package manager was introduced for the Node.js environment called npm. The package manager makes it easier for programmers to publish and share source code of Node.js libraries and is designed to simplify installation, updating and uninstallation of libraries.\nServer Side JavaScript The following was adapted from The Node Beginner Book by Manuel Kiessling.\n The first incarnations of JavaScript lived in browsers. But this is just the context. It defines what you can do with the language, but it doesn\u0026rsquo;t say much about what the language itself can do. JavaScript is a complete language: you can use it in many contexts and achieve everything with it you can achieve with any other complete language.\nNode.js really is just another context: it allows you to run JavaScript code in the backend, outside a browser.\nIn order to execute the JavaScript you intend to run in the backend, it needs to be interpreted and, well, executed. This is what Node.js does, by making use of Google\u0026rsquo;s V8 VM, the same runtime environment for JavaScript that Google Chrome uses.\nPlus, Node.js ships with a lot of useful modules, so you don\u0026rsquo;t have to write everything from scratch, like for example something that outputs a string on the console.\nThus, Node.js is really two things: a runtime environment and a library.\n Why are people excited about Node.js?  Node.js is a JavaScript runtime environment and collection of core libraries for developing a diverse variety of server tools and applications. Node.js is open-source and cross-platform. Node.js has a built-in module system. Many core Node.js modules are written in JavaScript and developers can write new modules in JavaScript. The Node.js runtime environment interprets JavaScript using Google\u0026rsquo;s extremely fast V8 JavaScript engine. Node.js allows developers to use a single language, JavaScript, to do full-stack web application development. Node.js provides an asynchronous / event-driven architecture that works well for building scalable web applications that have I/O bound performance.   CPU bound means the program is bottlenecked by the CPU, or central processing unit, while I/O bound means the program is bottlenecked by I/O, or input/output, such as reading or writing to disk, network, etc. In general, when optimizing computer programs, one tries to seek out the bottleneck and eliminate it.\n Asynchronous Execution of I/O Operations Node.js is designed to be event-driven and asynchronous. The asynchronous nature of Node.js means that Node.js sends slower operations (i.e. I/O operations) to the background and keeps going.\nHere are some of the types of I/O (input / output) operations that Node.js executes asynchronously:\n Network requests Terminal input / output File reads and writes Database reads and writes   I/O is anything that communicates beyond the CPU and core memory. Such communications are relatively slow (in the milliseconds) and thus NodeJS runs them asynchronously.\n Example 1 - Async Hello World Here is a simple example of an async operation in JavaScript:\nJavaScript\nsetTimeout(function() { console.log(\u0026#34;World!\u0026#34;); }, 2000); console.log(\u0026#34;Hello\u0026#34;); Observations\n In JavaScript:\n There is something fundamentally different going on. JavaScript apps never sleep. They are always doing something. JavaScript apps can be idling, but nothing is ever blocked. There are no mutex locks, no wait on state. Operations can be deferred, i.e. they can be scheduled for a later time or triggered on an event.   Example 2 - Sync vs. Async Sandwich Shop Sync Version Imagine a sandwich shop with a single line of customers waiting to place an order. When you get to the front of the line you place your order and do not move until you get your food. The other customers cannot even place their orders until you have placed your order and the order is prepared and you get your food. This is how blocking / synchronous I/O works in other languages such as Ruby.\nsync-sandwich-shop.js\n// JavaScript doesn\u0026#39;t really have a `sleep` function like some languages, // but we can create something similar using a Promise function sleep(seconds) { return new Promise(res =\u0026gt; setTimeout(res, seconds * 1000)) } async function orderSandwich(customer, description, duration, callback) { console.log(\u0026#39;\u0026gt; \u0026#39; + customer + \u0026#39; ordered a \u0026#39; + description); await sleep(duration); console.log(\u0026#39;- \u0026#39; + customer + \u0026#39;, you\\\u0026#39;re order is ready!\u0026#39;); var sandwich = \u0026#39;a delicious \u0026#39; + description; callback(customer, sandwich); } function enjoySandwich(customer, sandwich) { console.log(\u0026#39;\u0026lt; \u0026#39; + customer + \u0026#39; is enjoying \u0026#39; + sandwich); } async function orderAllSandwiches() { await orderSandwich(\u0026#39;Susan\u0026#39;, \u0026#39;Roast Pork and Pickled Cucumber Sandwich\u0026#39;, 4, enjoySandwich); await orderSandwich(\u0026#39;Mike\u0026#39;, \u0026#39;Reuben on Rye\u0026#39;, 2, enjoySandwich); await orderSandwich(\u0026#39;Shane\u0026#39;, \u0026#39;Smoked Salmon Salad Sandwich\u0026#39;, 6, enjoySandwich); await orderSandwich(\u0026#39;Brandon\u0026#39;, \u0026#39;Apple Peanut Butter Sandwich\u0026#39;, 1, enjoySandwich); console.log(\u0026#39;No More Customers.\u0026#39;); } orderAllSandwiches(); We can run this with the Unix time command to see how long the program takes to run:\ntime node sync-sandwich-shop.js Note that the total time is roughly the sum of the durations of the 4 sandwiches (13 seconds) because nothing could be done in parallel. Each sandwich is prepared in a blocking fashion (which we forced onto JavaScript via our sleep function).\nAsync Version Now imagine a sandwich shop with a single line of customers waiting to place an order. When you get to the front of the line you place your order and you get a ticket with a number on it. Other customers are free to move up in line and place their orders and they get tickets too. When your order is ready, they call your number and you pick up your food. This is how non-blocking / asynchronous I/O works (JavaScript).\nasync-sandwich-shop.js\nfunction orderSandwich(customer, description, duration, callback) { console.log(\u0026#39;\u0026gt; \u0026#39; + customer + \u0026#39; ordered a \u0026#39; + description); setTimeout(function() { console.log(\u0026#39;- \u0026#39; + customer + \u0026#39;, you\\\u0026#39;re order is ready!\u0026#39;); var sandwich = \u0026#39;a delicious \u0026#39; + description; callback(customer, sandwich); }, duration * 1000); } function enjoySandwich(customer, sandwich) { console.log(\u0026#39;\u0026lt; \u0026#39; + customer + \u0026#39; is enjoying \u0026#39; + sandwich); } orderSandwich(\u0026#39;Susan\u0026#39;, \u0026#39;Roast Pork and Pickled Cucumber Sandwich\u0026#39;, 4, enjoySandwich); orderSandwich(\u0026#39;Mike\u0026#39;, \u0026#39;Reuben on Rye\u0026#39;, 2, enjoySandwich); orderSandwich(\u0026#39;Shane\u0026#39;, \u0026#39;Smoked Salmon Salad Sandwich\u0026#39;, 6, enjoySandwich); orderSandwich(\u0026#39;Brandon\u0026#39;, \u0026#39;Apple Peanut Butter Sandwich\u0026#39;, 1, enjoySandwich); console.log(\u0026#39;No More Customers.\u0026#39;); Let\u0026rsquo;s also run this with the Unix time command:\ntime node async-sandwich-shop.js A total time of roughly 6 seconds (the maximum of the sandwich durations) as all 4 sandwiches could be prepared in parallel due to non-blocking / asynchronous execution.\nObservations:\n  All of the orders can be made before any of the orders are delivered. The sandwiches take varying amounts of time to prepare. The sandwiches come out in a different order than when they came in!  For instance, Brandon put in his order last but it came out first because it only took 1 second to make.      Writing code that executes asynchronously means that you will have to think and write your code a little differently than you would with a blocking framework like Ruby\u0026rsquo;s Rails, but you get the benefits of higher throughput (and thus better scalability) without the complexity of multi-threading (Java).\n How Does NodeJS Do This? JavaScript uses a single-threaded developer model, but internally it does run multiple threads for handling the asynchronous I/O operations. Each internal thread can invoke an async I/O operation and then wait for the response. The main event-loop thread will then poll to see when an async I/O operation has returned a result.\nAsync HTTP Request JavaScript\nvar http = require(\u0026#39;http\u0026#39;); var options = { host: \u0026#39;my-json-server.typicode.com\u0026#39;, path: \u0026#39;/typicode/demo/posts\u0026#39; }; callback = function(response) { var posts = \u0026#39;\u0026#39;; //another chunk of data has been received, so append it to `randomGitMessage`  response.on(\u0026#39;data\u0026#39;, function (chunk) { posts += chunk; }); //the whole response has been received, so we just print it out here  response.on(\u0026#39;end\u0026#39;, function () { console.log(\u0026#39;List of posts:\u0026#39;, posts); console.log(\u0026#39;We are there!!!\u0026#39;); }); } console.log(\u0026#39;Invoking an HTTP GET Request with url = http://\u0026#39; + options.host + options.path); http.request(options, callback).end(); console.log(\u0026#39;Are we there yet?\u0026#39;); console.log(\u0026#39;Are we there yet?\u0026#39;); console.log(\u0026#39;Are we there yet?\u0026#39;); When Does a JavaScript Program Terminate JavaScript programs have both synchronous blocking code (CPU and memory instructions) and asynchronous non-blocking code (I/O operations). Therefore a JavaScript program cannot just exit after all of the sync instructions have completed; it must also wait for any pending async operations to complete.\nSo when does a JavaScript program quit? Here are the rules:\nA JavaScript Program Quits When\n  The main script has completed (the sync operations) The async queue is empty (no more pending async operations and callbacks have completed) There are no active event listeners (no open ports)   The only exception to this rule is if the program receives a kill signal from the Operating System.\nHere is an example:\nJavaScript\nsetTimeout(function() { console.log(\u0026#39;Goodbye.\u0026#39;); }, 5000); setTimeout(function() { console.log(\u0026#39;World!\u0026#39;); }, 2000); setInterval(function() { console.log(\u0026#39;Are we there yet?\u0026#39;) }, 1000); console.log(\u0026#39;Hello\u0026#39;); Discussion: Pair up with someone and take 5-10 minutes take turns explaining\n I/O - What is it? How it is useful? Async - What does it mean for a program operate asynchronously?  Summary  Node.js provides a runtime environment for running JavaScript code outside of the browser. Node.js provides a platform for developing efficient and scalable web server applications that are characterized by I/O bound performance. The asynchronous nature of Node.js I/O operations provides high performance but requires writing code in an asynchronous / event-driven way (using callbacks or promises or observables).  Additional Resources   Node Documentation\n  Devhints Node.js Cheatsheet\n  "
},
{
	"uri": "/application-security/api-security/01_service_to_service_oauth2/",
	"title": "OAuth2 / Service to Service",
	"tags": [],
	"description": "",
	"content": "Introduction to Service to Service API Security Using OAuth2 Goals  Buying Beer with OAuth2 Learn about OAuth2 Understand how to use OAuth2 for server to server authorization Hands on Lab  "
},
{
	"uri": "/path-to-production/cicd/pipeline-stages/",
	"title": "Path to an Approved Pipeline",
	"tags": [],
	"description": "",
	"content": "Objectives To give a description of the steps required for a fully automated pipeline.\nYou will learn:\n What steps are needed inside of a pipeline to be considered for an approved pipeline to push to production. Where you can get the configuration What dependencies are required The process of getting your pipline approved   Flow and Concourse Common We have several tools at our disposal for assisting in building pipelines and automating our deployments. The two most common tools you\u0026rsquo;ll use in your Concourse pipelines can be found in the inner-source org ci-cd on GitHub Enterprise, and they are Flow and concourse-common\nFlow is an open source cli that allows you to interact with various components you\u0026rsquo;ll need to set up and operate your pipeline. Some of these components include Pivotal Tracker, Artifactory, PCF, etc. Flow is not strictly a concourse cli, and can be used as a general purpose tool outside of pipelines for these components as well.\nThe concourse-common repo contains a large set of scripts and modularized concourse job configurations that you can import into your pipelines.\nWhile you are not required to use either of these resources, they will help with the tasks that are common from team to team.\nImporting concourse-common As a resource resources: - name: concourse-common type: git source: uri: git@github.homedepot.com:ci-cd/concourse-common.git branch: master private_key: ((github-private-key-value)) check_every: 24h Requires:\n github private key  If you are interested in creating your own jobs and script using flow, this is a great gist that includes additional documentation and usage\n Preparing Your Repo Build Config You will need to have a buildConfig.json to utilize most of what flow and concourse-common offers.\nBelow is an example of a full buildConfig.json. When and how to use each section is called out in the following sections of this document. It is worth noting that the name of your project has significant impact on some of the external tools, such as Software Quality Hub, so be sure that this is correct and finalized before moving forward.\n{ \u0026#34;projectInfo\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;name-of-your-app\u0026#34;, \u0026#34;versionStrategy\u0026#34;: \u0026#34;tracker\u0026#34;, \u0026#34;fmsNumber\u0026#34;: \u0026#34;IT-012345\u0026#34;, \u0026#34;cdTemplate\u0026#34;: \u0026#34;CD0001001\u0026#34;, \u0026#34;language\u0026#34;: \u0026#34;java\u0026#34; }, \u0026#34;github\u0026#34;: { \u0026#34;org\u0026#34;: \u0026#34;your-ghe-org\u0026#34;, \u0026#34;repo\u0026#34;: \u0026#34;repo-for-this-code\u0026#34;, \u0026#34;URL\u0026#34;: \u0026#34;https://github.homedepot.com/api/v3/repos\u0026#34; }, \u0026#34;slack\u0026#34;: { \u0026#34;channel\u0026#34;: \u0026#34;your-slack-channel\u0026#34;, \u0026#34;botName\u0026#34;: \u0026#34;DeployBot\u0026#34;, \u0026#34;emoji\u0026#34;: \u0026#34;:robot_face:\u0026#34; }, \u0026#34;tracker\u0026#34;: { \u0026#34;projectId\u0026#34;: 123456 }, \u0026#34;artifact\u0026#34;: { \u0026#34;artifactoryDomain\u0026#34;: \u0026#34;https://maven.artifactory.homedepot.com/artifactory\u0026#34;, \u0026#34;artifactoryRepoKey\u0026#34;: \u0026#34;libs-release\u0026#34;, \u0026#34;artifactoryRepoKeySnapshot\u0026#34;: \u0026#34;libs-snapshot\u0026#34;, \u0026#34;artifactoryGroup\u0026#34;: \u0026#34;com/thd/your-group\u0026#34;, \u0026#34;artifactTypes\u0026#34;: [\u0026#34;jar\u0026#34;, \u0026#34;xml\u0026#34;,\u0026#34;zip\u0026#34;,\u0026#34;other-ext\u0026#34;] }, \u0026#34;environments\u0026#34;: { \u0026#34;development\u0026#34;: { \u0026#34;artifactCategory\u0026#34;: \u0026#34;snapshot\u0026#34;, \u0026#34;manualDeployEnvs\u0026#34;:[\u0026#34;development\u0026#34;], \u0026#34;associatedBranchName\u0026#34;: \u0026#34;development\u0026#34;, \u0026#34;createChange\u0026#34;: \u0026#34;False\u0026#34; }, \u0026#34;release\u0026#34;: { \u0026#34;artifactCategory\u0026#34;: \u0026#34;release\u0026#34;, \u0026#34;manualDeployEnvs\u0026#34;:[\u0026#34;release\u0026#34;], \u0026#34;associatedBranchName\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;createChange\u0026#34;: \u0026#34;False\u0026#34; } } }  Version \u0026amp; Tagging The first step is in a pipeline is normally generating a new version of the code that you are deploying. Flow and the scripts in concourse-common rely on git tags for versioning. Further build and test steps will utilize this tag to create other archives and updates based on the tag name.\nVersioning follows semantic versioning. A version bump is based on a combination of the environment (development or release) you are working with, and optionally the type of stories involved in the release.\n MAJOR version when you make API changes which are not backwards compatible (i.e. they cause consumers of your API to break), MINOR version when you add functionality in a backwards-compatible manner, and PATCH version when you make backwards-compatible bug fixes.  The job itself only bumps the minor and patch versions. If you have a new major version, you\u0026rsquo;ll need to create the release tag yourself via git or GitHub\nEnvironment and Version Bumping The job utilizes the ENVIRONMENT param to determine what version strategy it should use; i.e. indicate whether this just a \u0026ldquo;build\u0026rdquo; version or a \u0026ldquo;release\u0026rdquo; version.\nYou\u0026rsquo;ll want to be sure your environments are defined in your buildConfig.json, as this job relies on how these are defined to determine how to increase the build.\nBuild Version The build will add the build count to the end of the last release version/tag. For example, if your code was released at v2.1.2 your first build version/tag would be v2.1.2+1, the next would be v2.1.2+2 and so on. Setting the ENVIRONMENT param to development, or whatever is configured in your buildConfig.json for non-release builds, is what tells the scripts in the job to utilize build versions rather than bumping the major/minor/patchversion.\nThis is also sometimes referred to as a snapshot version.\nRelease Version Release versions will create release tags based on the following:\n By default, it will add 1 to the minor version number; i.e. v2.1.2 becomes v2.1 If using the commit strategy to link commits to tracker stories, the job will determine if only bug stories were involved. If this is the case, the patch version is incremented by 1; i.e. v2.1.2 becomes v2.1.3  Example Job Config This would trigger the development build. Setting the ENVIRONMENT to release would trigger a minor/patch increase.\njobs: - name: Version max_in_flight: 1 plan: - get: your-code-repo trigger: true - get: ci - task: Version and Tag file: ci/concourse/github_version_and_tag.yml input_mapping: {code-repo: your-code-repo} params: ENVIRONMENT: \u0026#34;development\u0026#34; GITHUB_PRIVATE_KEY: {{github-private-key}} GITHUB_TOKEN: {{github-token}} TRACKER_TOKEN: {{tracker-token}} SLACK_WEBHOOK_URL: {{slack-webhook-url}} It is based on the development field in the buildConfig.json:\n\u0026#34;environments\u0026#34;: { \u0026#34;development\u0026#34;: { \u0026#34;associatedBranchName\u0026#34;: \u0026#34;development\u0026#34;, }, \u0026#34;release\u0026#34;: { \u0026#34;associatedBranchName\u0026#34;: \u0026#34;master\u0026#34;, } }  Unit Testing and Test Results There are a few common scripts for executing tests. The following will be some suggestions.\nJava Maven: maven_test.yml\nGradle: gradle_test.yml\nNode Gulp is the only provided solution for node.\nGulp: gulp_test.yml\nRegardless of language/testing framework you use, output of the results should be generated in an XUnit format. These results can then be submitted to SQH and/or shipped to artifactory.\nArtifactory Zip and Ship Task Some teams like to store test results along with their artifacts. This can be accomplished using the zipitshipit_artifactory.yml\nRequired Envioronment Variables\n ARTIFACTORY_USER ARTIFACTORY_TOKEN ZIP_NAME  The ARTIFACTORY_TOKEN can now be generated using the Artifactory Token Generator UI or the API.\nFor more information on this service, please see the official api guide.\nSoftware Quality Hub (SQH) Task This is a required step for approved pipelines. While not a requirement, a SQH task can be submitted for various steps of your pipeline if needed.\nRequest a token from the sqhub site. You can log-in with Google, using your HomeDepot email address.\nThe following will need to be provided for each token:\n   Field Description     Application Name The name of your application. This should match what you provided in your buildConfig.json   Experience Name The experience your application is under. This is not the subexperince.   Manager\u0026rsquo;s Email Address Email of the manager that is responsible for the application    You will need to provide the generated token to your pipeline.\nRequired Environment Variables\n SQH_JOB_NAME — Top level name for the report SQH_BUILD_NAME — Each section can be made up of multiple sections SQH_STATUS QUALITYHUB_TOKEN  EXAMPLE:\nIf the following are set:\nSQH_JOB_NAME=UNIT-TEST SQH_BUILD_NAME=unit SQH_STATUS=Compleated Quality Hub will report the results for UNIT-TEST:\nQuestions around quality hub can be asked in the #qualityhub channel on Slack.\n Security Scan Code security scans are required for approved pipelines. You will need to request a token.\n To obtain a token, just send a message to IT_Security_PSD@homedepot.com.\n Most languages use fortify. However, golang uses checkmarx for security scans. For a full list on setting up both, see this HOWTO.\nThere is no concourse-common component for Checkmarx. You will need to create a script to submit your results there.\nFor fortify accepted langagues, you can use the fortify_security_scan.yml in the concourse-common repo.\nNote: There is no solution currently for react. Check the documentation for updates.\nAdditional updates and questions can be found in the #productsecurity channel on slack.\n Build \u0026amp; Artifact Storage Building\nAs with testing, there are a few build scripts for Java, Python, and JavaScript using Gulp, but other languages will require you to build your artifact using your own scripts.\nJava Maven: maven_build.yml\nGradle: gradle_build.yml\nJavaScript Gulp: gulp_build.yml\nArtifact Storage The output of your build scripts should save the built artifact in a specific folder. If you are utilizing the concourse-common, these are already provided for you. You can utilize the artifactory_upload-artifact.yml job to assist with the upload regardless of build type.\nRequired Environment variables for Artifactory UploadGITHUB_PRIVATE_KEY GITHUB_TOKEN ENVIRONMENT SLACK_WEBHOOK_URL ARTIFACTORY_TOKEN ARTIFACTORY_USER You must also add the artifact section to your buildConfig.json\n\u0026#34;artifact\u0026#34;: { \u0026#34;artifactoryDomain\u0026#34;: \u0026#34;https://maven.artifactory.homedepot.com/artifactory\u0026#34;, \u0026#34;artifactoryRepoKey\u0026#34;: \u0026#34;libs-release\u0026#34;, \u0026#34;artifactoryRepoKeySnapshot\u0026#34;: \u0026#34;libs-snapshot\u0026#34;, \u0026#34;artifactoryGroup\u0026#34;: \u0026#34;com/thd/your-group\u0026#34;, \u0026#34;artifactTypes\u0026#34;: [\u0026#34;jar\u0026#34;, \u0026#34;xml\u0026#34;] } The artifactTypes field should be the file extension of what is being uploaded. For example, if you compress your built react app into a tar file, you\u0026rsquo;d want to specify the artifactTypes: [tar].\n Labeling Stories Part of the requirements to have a pipeline approved is to label the stories associated with any release with the release version to which they belong. The concourse-common has the tracker_label_stories.yml to label your stories as a part of any release build.\nGetting a Tracker API Key  Log into Pivotal Tracker Click the arrow next to your Profile picture -\u0026gt; Profile Look for the API TOKEN section and click CREATE NEW TOKEN  Required Environment Variables\nENVIRONMENT GITHUB_PRIVATE_KEY GITHUB_TOKEN TRACKER_TOKEN You will need to add the tracker field to your buildConfig.json with your project id\n\u0026#34;tracker\u0026#34;: { \u0026#34;projectId\u0026#34;: 123456 } You can get your tracker project id when you are viewing a project from the url\nFor example, given the URL https://www.pivotaltracker.com/n/projects/123456\n123456 is the project ID\nAssociating Stories With Versions   You will need to set up the Pivotal Tracker GitHub service hook on your repo.\n  Ensure your commit messages are using the tracker format\n[finishes #1234567] added the rm -rf / functionality.\nSee the documentation in the link above for all commit format options.\n   Pushing to Cloud Foundry You can follow the documentation here to use the concourse-common cf-push job, or create your own scripts optionally using flow to push.\nConsiderations In either case, you need to consider how to store the credentials for the user pushing the cloud foundry. There is currently not an official way of storing user credentials for pipelines. Some teams utilize service accounts for non-production pushes; others use vault with only one person having access to the credentials.\nDocumentation on how to set up vault with concourse can be found here.\nProduction Before you can automate pushing to production you must have an approved pipeline. See the following section on getting a pipeline approved.\n Getting a Pipeline Approved Note this was taken from the #it_governance channel. The information is still being validated. For updated information and questions, please check that channel.\nNew process for requesting and submitting CICD Pipeline (Revised 05.16.18) Login to ServiceNow (must be a licensed user)\n Navigate to the Continuous Delivery Applications module\n  Click on the New Button at the Top of the page\n  Fill out the form with the appropriate information\n  Attach the completed CD Template\n  Request Approval\na. Manager must approve prior to the approvals being sent to Inspectors\nb. Inspectors approval/reject\n  If approved, integrate/automate pipeline via Snowfield.\n  Begin executing CD changes (edited)\n  "
},
{
	"uri": "/python/relational-db/",
	"title": "Relational Databases",
	"tags": [],
	"description": "",
	"content": "Welcome to OM\u0026rsquo;s Python Relational Databases Pillars "
},
{
	"uri": "/path-to-production/before-you-build/subexp/",
	"title": "Requesting a Sub-Experience",
	"tags": [],
	"description": "",
	"content": "At The Home Depot, a group of related products falls under what we call an Experience\nFrom our technology playbook:\n An Experience is a group of software offerings and systems that align with enterprise business functions (e.g., Pricing), is governed by an executive sponsor, and has one or more product managers. An experience may be comprised of one or more products.\n A Sub-Experience is a similar to a small experience within an experience. A Sub-Experience is more likely to be tied to a single team working on a few services within the overall experience. If your team does not already have a Sub-Experience your new app falls into, you will need to request a new one. A Sub-Experience is required in order to move forward with many of the steps in the path to production. Some of these include:\n Creating an Architecture Security Assessment (ASA) Entering your app into the Configuration Management Database (CMDB) Requesting a Database through DBaaS Getting tokens for various required CICD jobs, such as quality hub  While not having a Sub-Experience can\u0026rsquo;t stop you from developing, or preparing to develop your app, you will soon run into blockers with out one.\nTo request a Sub-Experience you will need the following information:\n  A unique Sub-Experience Name\n  A new SAP-ID\n SAP-ID is the unique number assigned by Finance to your Experience to track all the charges for financial accounting. We use that same identifier when putting in the RFCs to change PCF to provision a new Org so we know what Experience that Org is supporting.\n   LDAP ID of the owner (typically a SE Manager)\n  LDAP ID of the director for the Sub-Experience\nTo locate the LDAP ID of a Home Depot employee, do the following:\n Search for the employee by name, or by clicking through the employee hierarchy, in https://nam.delve.office.com Insert the employee email at the end of the following URL: http://dapper.apps.homedepot.com/users/ e.g. http://dapper.apps.homedepot.com/users/homer@homedepot.com The first field in the response will be named \u0026ldquo;id\u0026rdquo;. This is the LDAP ID of the employee.    A description of the functionality provided by the sub-experience.\n  SLA Tier (Platinum/Gold/Silver or Bronze)*\n  A indication of the type of data being handled by your sub-experience, e.g. Customer Data, PII/Confidential Data and/or Restricted Data\n    Note: The tier names are in the process of being redefined. Work with the sub-experience team if you have any questions regarding the sub-experience under which your application falls. However, it should reflect the business need for the sub-experience versus the technical implementation.   Making a Request When you feel you have the information:\n go to and login into http://homedepotqa.service-now.com/ go to SubExperience  Type SubExp in the upper left navigation Choose Configuration \u0026raquo; Subexperiences    From the Sub-experience list view, click \u0026ldquo;New\u0026rdquo;  Fill in new sub-experience information required  Choose \u0026ldquo;Submit for Review\u0026rdquo; once complete  Next Steps Once the completed template is received and added to the agenda, a meeting invite will be forwarded for attendance.\n Reviews are held on Tuesday\u0026rsquo;s and Thursday\u0026rsquo;s at 9 am. Please post questions in the #it_governance channel  "
},
{
	"uri": "/react/foundations/syllabus/",
	"title": "Syllabus",
	"tags": [],
	"description": "",
	"content": "Preflight Checklist 🛫 Welcome to Foundations of React! 👋\n👩‍✈️Before the workshop starts, please go over this preflight checklist. This will help ensure you\u0026rsquo;re prepared to take this workshop.\nRequirements Strong grasp of JavaScript A strong grasp of JavaScript is essential to learning React. It\u0026rsquo;s important to understand JavaScript functions and execution context, as well as the new syntax and features of ES6/ES2015 JavaScript. Modern array methods are used liberally in React applications.\n🔗 JavaScript Variable Scope\n🔗 ES2015 Modules\n🔗 ES2015 Arrow Functions\n🔗 Modern Array Methods\n💻 NodeJS installation on machine Please try to have NodeJS installed on your machine 💻 prior to class.\n🔗 NPM\nor\n🔗 Node\nAccess to Home Depot Enterprise GitHub Requesting GHE access through ARP:\n🔗 Path to Production \u0026gt; Configure your Development Environment\n✏️ A text editor or IDE which you\u0026rsquo;re comfortable with. Orange Academy instructors use VS Code to write and edit React code. We exclusively use VS Code for React applications. In the workshop, you should use the text editor or IDE that you\u0026rsquo;re comfortable with. If you have text editor or IDE related problems during the workshop, we can help you if you\u0026rsquo;re using VS Code. If you\u0026rsquo;re using something different, we may not be able to help you with problems directly related to editor/IDE setup or config.\n🔗 The Home Depot App store \u0026gt; downloading VS Code\nLessons in this Series  React Intro Getting Started JSX Expressions Intro to Components Component Props Prop Types (optional lesson) Component State Component State with JS Classes (optional lesson) Events Forms Side Effects Styling Components Context API React Router v4 (legacy) React Router v5 (current) React Router v6 (beta)  Labs  Official React Tutorial React JS Koans Nodeschool - Learn you React Nodeschool - Thinking in React Budgeting App - React Fundamentals Review  Additional Resources   A great place to start, is the React Getting Started Documentation This has great descriptoins and code samples for the most important parts of React\n  The React Tutorial is an excellent resource for understanding how to build a simple React app\n  To learn more about how React works, check out the React \u0026lsquo;diffing\u0026rsquo; Algorithm. Which essentially compares the virtual DOM with the actual DOM and only updates the elements (and their children) that have been modified.\n  React Lists and Keys\n  React PropTypes\n  Controlled and uncontrolled form inputs in React don\u0026rsquo;t have to be complicated\n  React Docs on Component Lifecycle\n  Great explanation of the (pre v16.3) React Lifecycle\n  Evolution of Styling in React\n  Styled Components Enforcing Best Practices\n  Styled Components\n  Glamorous\n  CSS Modules\n  Adding a CSS Preprocessor to create-react-app projects\n  React style documentation\n  React Bootstrap\n  React Material UI\n  React + Foundation\n  "
},
{
	"uri": "/onboarding/cyber-security/cyber-associates/module-2-tooling/",
	"title": "The Cyber Tool Belt",
	"tags": [],
	"description": "",
	"content": "Archer Predominately leveraged by the Governance and Risk Compliance functions, this tool is leveraged to manage cyber risk such as remediation\n Who should Request Access: Anyone entering, owning or resolving security/compliance findings. Requesting Access: Access is granted through an ARP request Link: Archer Home Helpful Tips:  For additional assistance contact Blake Varner or Davina Harrell RSA Archer Personal Reporting User Manual    Project Management Central (PM Central) Commonly leveraged by Project Managers and Business Analysts, this portfolio management tool charts progress of strategic projects across all cyber services. PM central uses a combination of Tableau dashboards.\nThe PM Central Landing Screen Once you navigate to PM Central, with the link below, you will be met with this landing screen.      Who Should Request Access: ARP Entitlement associates should request to see reports: GG_TBLU_DEFAULT_READ • All Cyber associates can/should request the above entitlement in ARP Mangers, Sr. Managers, Principals, Directors and PMO Members (including BAs) should/must request the above entitlement     Role: ARP Entitlement Needed Rights     Project Manager (PMO Team) GG_Cloud_PM_PMs Users who are allowed to view all projects across all PM Central and edit their own projects   Technology Coordination Managers (PMO Team) GG_Cloud_PMCentral_PMO Users who are allowed to view/edit all projects across all PM Central   Upper Management GG_Cloud_PMCentral_Team Members Users who are allowed to write Risk, Issues, Decisions entries and have read only access for project schedules   Business Analysts (BA team currently within PMO Team- currently all contractors but will have some Associates hired in 2020) GG_Cloud_PMCentral_Team Members GG_Cloud_PMCentral_Team Members     Requesting Access: Navigate to the Access Request Portal and request a group based on the roles table above Link: Project Management Central Helpful Tips: Be sure to use the support section of the site to submit feedback and see a list of frequently asked questions  Cybersecurity Service Catalog The Service Catalog allows Cybersecurity to offer its various services to all of THD technology. It will have resources and contact information for the various services being offered, allowing Cybersecurity to enable the rest of home depot with its offerings.\n    Requesting Access: Available for everyone over VPN via SSO.\n  Who Should Request Access:\n  Link: Cybersecurity Service Catalog\n  Helpful Tips:\n The service catalog is very intuitive to navigate. Simply click on any section to see the service offerings available.     The navigation bar at the top will let you search, view a page with all of the services, and has a glossary with cybersecurity terms.      Cybersecurity Confluence Site One-stop shop for all things cyber from development blue prints to technical protocols.\nYour browser does not support the video tag.   Who Should Request Access: Requesting Access: Available by default to technology/cyber associates. If you access goes inactive for 90 days you may need to reactivate here Link: Cybersecurity Confluence Site Helpful Tips:  Be aware of the search bar and navigation of the particular site. Confluence can be viewed similar to wikipedia as it is managed by a community of admins and everyone can create pages so its good practice to search if it exists first before creating one    Deadbolt A tool with many functions, this site is leveraged to manage 3rd party contracts and finances as well as report out weekly updates from each cyber service.\nOn the homepage you will find links to the portfolio, weekly status report, and request headcount.\n  The portfolio dashboard is required for managers to view project details.\n  The weekly status report is required for managers to track project status.\n  Managers can request additional headcount for projects with the request headcount link.\n   Who Should Request Access: This tool is primarily leveraged by Managers and Project Managers, though anyone can request access. The chart below will list the different functions by job role.     Requesting Access: Access can be requested via ARP request, a guide is available here. Link:Deadbolt Helpful Tips: The Deadbolt Confluence page has FAQs and user guides.  Cyber myApron Site One-stop shop for associates across the enterprise to help answer their commonly asked questions. myApron contains many links to different resources, including policies and training.\n   Who Should Request Access: This tool is useful for everyone. Requesting Access: Everyone has access through the VPN via SSO. Link: Cyber myApron Site Helpful Tips:  This tool is easy to navigate. It is one of your primary resources for anything related to Cybersecurity that is non-technical. You can bookmark the page for easy access to resources you will need while working at The Home Depot.      How to make a difference     Cybersecurity Women\u0026rsquo;s Council (CWC)  Purpose: Business council to support the advancement of women within Cybersecurity How to get involved: Contact: Sherrie L’Amoreaux   Voice of the Associate Committee  Purpose: The VOA Committee is a representative group of associates who provide recommendations and feedback to their leadership on VOA Focus Areas. Leadership selects these Focus Areas based on the portfolio VOA results. This VOA Committee is one way that associates can provide insight to leaders on what motivates and engages them in their work at THD. How to get involved:  Ensure to provide feedback to open surveys to increase engagement. Contact Davina Harrell      Key Rituals  End User Community (EUC): Weekly tollgate meeting, held every friday from 2-3PM EST, to vet efforts impacting the end user infrastructure Monthly Portfolio Review: A business review with leadership to discuss the overall progress of each strategic project within Cyber.  Products that are reviewed from PM central are any that are considered by the status of yellow \u0026amp; red which are status\u0026rsquo; determined by on time delivery to have the Product Manager\u0026rsquo;s \u0026amp; their sponsors to improve this status. (POC the_office_cybersecurity@homedepot.com)   Product Solution Review Board (PSRB): Cross functional board that conducts workshops three times per week to review architecture and security designs to assure they meet business requirements  PSRB - Slides    "
},
{
	"uri": "/path-to-production/dev-environment/tools/",
	"title": "Tools and Editors",
	"tags": [],
	"description": "",
	"content": "Tools and Editors This section covers some of the most common tools that you will need to be immediately successful here at The Home Depot. Additionally, the Infrastructure of One site has a great catalog of the many other tools which we use.\nThe Home Depot App Store \u0026amp; Software Center The Home Depot App Store (Mac) and Software Center (App) provide a place to safely install and update commonly used tools and utilities. It is not required to install from here, but some installations may contain additional files, such as certs, to enable use on the THD network.\nThe Home Depot App Store (Mac) All Home Depot Macs should have The Home Depot App Store installed on them. You can access the app store by following these steps:\n  Click on Launch\n  Type Home in the search bar and you should see the icon\n  Open the app\n  Log in with your THD LDAP and password\n  You should now have access to search and browse for commonly utilized apps for the Mac.\nSome Useful Apps provided in THD App Sore:\n   App Name Section Description     IntelliJ Install \u0026amp; Featured IDE For Developing in Java   VS Code Install \u0026amp; Featured Powerful Text editor and lite IDE   PyCharm Install IDE for Developing in Python   Slack Install Team Communications   iTerm Featured Enhanced Terminal for Mac   Docker Install Installs everything needed to build and run Docker images and containers   THD Certs for Java Self Help Certs used within HD   THD QA Certs Self Help    THD Root CA \u0026amp; McAfee MWG Certs Self Help    Google Cloud SDK Install Installs the Google Cloud SDK with HD certs. You will want this tool if you are using any of the Google Cloud products. It includes utilities such as gcloud, gsutil and bq for interacting with cloud project, storage buckets, and Big Query respectively.    Software Center (Windows) All Home Depot Windows laptops should have Software Center installed on them. You can access the Software Center by following these steps:\n  Look for the Software Center icon\n  OR Press the windows key and start typing software\n  Double click Software Center\n  This will bring up the app store to allow you to install commonly used apps.\n  Editors Although it is mostly up to the individual (and sometimes team) to determine what code editors to use, if you are not familiar with the options available to you, here are code editors commonly used by THD Software Engineers:\n  Jetbrains IDEs (IntelliJ, Goland, Pycharm, etc)\n  Eclipse\n  VS Code\n  vi (because someone was going to ask)\n  Jetbrains License The Home Depot has an enterprise License for all Jetbrains products which is registered through a license server. You currently have to be on the network or connected to VPN to register. If you lose network connectivity, the products may prompt you for the license again. Once you are reconnected to The Home Depot network, you will be able to continue with the product.\nWhen you first open the product, you should be prompted with a License Activation window. When you do, just click the License server radio button and it will populate the server for you. After that, just click Activate.\nNote: You may see a warning about certs; you can accept these to continue.\nCommunication Tools Slack Slack can be downloaded from the official site, the Software Center (Windows) or, The Home Depot App Store (Mac).\nWhen you open slack you will need to join a team. The Home Depot Technology has a paid team for all of IT called thdengops. You should be prompted with a login similar to the following:\nYou should then been prompted to login to The Home Depot Single Sign on.\nMicrosoft Teams Microsoft Teams is available through The Home Depot\u0026rsquo;s Office 356 subscription/license. While there are no enterprise or organization-wide channels, there are some other benefits that you may find useful:\n Integration with Outlook to automatically set up video meetings that any invitee can join with a click of a link Live Events (allows presentations to be recorded with chat) Integrated with Calendar Easy access to other Microsoft Products such as Word  You can Download Teams from the official site, The Home Depot App Store, or Software Center\nWebEx Teams WebEx Teams is another tool that offers chat much like Slack. However, WebEx teams allows THD Associates to connect to the video conference rooms that contain the Cisco Video equipment (rooms are listed as [video] in outlook).\nPackage Managers Homebrew (mac) Brew is a popular command line package manager which allows you to install a lot of additional 3rd party tools with ease.\nPlease follow the official documentation for installation steps.\nChocolaty (Windows) Chocolatey is a package manager similar to Homebrew for mac. It allows you to install and manage applications from the command line.\nFind you more here.\nPivotal Tracker Pivotal tracker is the official agile board. You will need access to your team\u0026rsquo;s project board in order to be assigned stories. Before you can be invited to a project you will need to log into Tracker.\nWhen you sign into Tracker with your Home Depot email address, you will be redirected to The Home Depot Single Sign on.\nGit \u0026amp; GitHub A part of the 12 factor app is to have one code base tracked in revision control. THD has chosen git and GitHub to meet this requirement.\nGit The Home Depot uses git and Enterprise GitHub as a Source Code manager. To commit and push code, you will need to have git installed.\nChocolatey (Windows)\nc:\\\u0026gt; choco install git.install Brew Mac\nbrew install git For other install methods, see the official documentation.\nGitHub The HomeDepot uses Enterprise GitHub. It is the remote git repository used to maintain and review code as a team. You can find it here.\n"
},
{
	"uri": "/javascript/nodejs/advanced/",
	"title": "Advanced NodeJS",
	"tags": [],
	"description": "",
	"content": "Advanced NodeJS "
},
{
	"uri": "/python/automation/",
	"title": "Automation",
	"tags": [],
	"description": "",
	"content": "Welcome to Python Automation Pillars "
},
{
	"uri": "/javascript/nodejs/advanced/stdin-stdout-buffers-streams/",
	"title": "Buffers &amp; Streams",
	"tags": [],
	"description": "",
	"content": "STDIN / STDOUT Focusing on the process object in node, we\u0026rsquo;ll go over what stdin and stdout do.\n STDIN: Standard Input STDOUT: Standart Output  These two objects serve as a way to communicate with a process while it is running.\nUsing them to read and write data to the terminal We\u0026rsquo;ve been using stdin and stdout: The console.log actually uses it to both log the message and add in a line-space to write to the terminal!\nStandard process syntax: process.stdout Use the .write() method to write strings to the terminal (similar to console.log!)\nStep 1:\nCreate a file named ask.js\nAdd to ask.js file:\nprocess.stdout.write(\u0026#39;Hello \u0026#39;); // notice the space after the \u0026#34;o\u0026#34; process.stdout.write(\u0026#39;World! \\n\\n\\n\\n\u0026#39;); Step 2:\n// We will ask the questions from an array named `questions` var questions = [ \u0026#34;What is your name?\u0026#34;, \u0026#34;What is your favorite hobby?\u0026#34;, \u0026#34;What is your preferred programming language?\u0026#34; ]; // Then, we will save the answers to another array called `answers` var answers = []; // Our function will actually ask questions from our `questions` array using `stdout` function ask(i) { process.stdout.write(`\\n\\n\\n\\n ${questions[i]}`); process.stdout.write(\u0026#34; \u0026gt; \u0026#34;); }; // Call the function initially by asking the first question ask(0); Using them to communicate with a child process Step 3:\nvar questions = [ \u0026#34;What is your name?\u0026#34;, \u0026#34;What is your favorite hobby?\u0026#34;, \u0026#34;What is your preferred programming language?\u0026#34; ]; function ask(i) { process.stdout.write(`\\n\\n\\n\\n ${questions[i]}`); process.stdout.write(\u0026#34; \u0026gt; \u0026#34;); }; // Change `ask.js` in this way: process.stdin.on(\u0026#39;data\u0026#39;, function (data) { // When the `ask()` function is called, this callback function will fire and  process.stdout.write(\u0026#39;\\n\u0026#39; + data.toString().trim() + \u0026#39;\\n\u0026#39;); }); ask(0); Now, when we run the above code in our ask.js file, the process doesn\u0026rsquo;t stop. It continues running because we\u0026rsquo;re using Nodejs asynchronously. Since we\u0026rsquo;re waiting for some input, it\u0026rsquo;ll be handled with the asynchronous callback in our .on() method call.\nNodejs is using stdin process when we answer the question within the terminal.\nTo stop the application, we have to hit control+c\nSaving to the answers Array\nNow we can change the code within the child process .on() data callback to save the answers to our questions to the answers array.\nStep 4:\nvar questions = [ \u0026#34;What is your name?\u0026#34;, \u0026#34;What is your favorite hobby?\u0026#34;, \u0026#34;What is your preferred programming language?\u0026#34; ]; var answers = []; function ask(i) { process.stdout.write(`\\n\\n\\n\\n ${questions[i]}`); process.stdout.write(\u0026#34; \u0026gt; \u0026#34;); }; process.stdin.on(\u0026#39;data\u0026#39;, function (data) { answers.push(data.toString().trim()); if (answers.length \u0026lt; questions.length) { ask(answers.length); } else { process.exit(); } }); process.on(\u0026#39;exit\u0026#39;, function () { process.stdout.write(\u0026#34;\\n\\n\\n\u0026#34;); process.stdout.write(`Go ${answers[1]}${answers[0]}, you can finish writing ${answers[2]}later.`); process.stdout.write(\u0026#34;\\n\\n\\n\u0026#34;); }); ask(0); Lab 1 Practice for stdin \u0026amp; stdout\nBuffer and Streams   Streams   A stream is a sequence of data that flows over time from one place to another.\n  A stream flows into the buffer.\n  Once the buffer is full, the stream of data continues on to its destination.\n  We\u0026rsquo;ve used the STREAMS object already by using process.stdout\nWe use streams with Nodejs because using streams and buffers can improve performance. We can create streams that go through buffers so that we can control the data as it comes from our Nodejs server to our client.\n Stream types:\n  Readable: Allows Nodejs to read data from the stream\n  Writeable: Allows Nodejs to send data to the stream.\n  Duplex: Both reads and writes data to and from the stream.\n  Transform: Transform streams are a certain type of duplex stream (both readable and writable). The distinction is that in Transform streams, the output is in some way calculated from the input.\n  \u0026ldquo;Classic\u0026rdquo;: Classic streams are the old interface that first appeared in node 0.4. You will probably encounter this style of stream for a long time so it\u0026rsquo;s good to know how they work.\n  If the client is expecting data, that means Nodejs is writing to the stream because it\u0026rsquo;s writing to the stream.\nIf Nodejs is reading a file or receiving an HTTP request, then it would be reading data from the stream.\nBuffers Buffering is a thing that happens to a stream of data\nvs.\n  Temporary storage spot for a chunk of data that is being transferred from one place to another\n  The buffer is filled with data, then passed along\n  Trasfers small chunks at a time\n  As we\u0026rsquo;re streaming a movie online, sometimes it stops to buffer. This is when the buffer is filling up with the streaming data, and once the data is released from the buffer it begins streaming again and we may watch the movie.\nWhat does a buffer look like? The way our computers translate buffers looks something like this:\n\u0026lt;Buffer 4c 6f 72 65 6d 20 69 70 73 75 6d 20 64 6f 6c 6f 72 20 73 69 74 20 61 6d 65 74 2c 20 73 65 64 20 65 78 20 69 6c 6c 75 6d 20 76 6f 6c 75 70 74 61 74 75 ... \u0026gt; Buffers \u0026amp; Streams in action  The code below creates a readable stream that we will read data from.\n__dirname makes sure our file path starts at the current directory we\u0026rsquo;re working with.\nThe .createReadStream() method inherits from the Event Emitter. There\u0026rsquo;s an event called data that listens for any data from this stream.\n const http = require(\u0026#39;http\u0026#39;); const fs = require(\u0026#39;fs\u0026#39;); // In order to see the actual text from the data, add \u0026#39;utf8\u0026#39; as an argument below var myReadStream = fs.createReadStream(__dirname + \u0026#39;/random.txt\u0026#39;); // Listen for an event, data // Log it to see the data received myReadStream.on(\u0026#39;data\u0026#39;, function(dataChunk) { console.log(\u0026#39;New chunk recieved:\u0026#39;); console.log(dataChunk); }); Labs 2 \u0026amp; 3 Pairing exercise\nStream adventures\n"
},
{
	"uri": "/path-to-production/tech-stack/",
	"title": "Choosing a Tech Stack",
	"tags": [],
	"description": "",
	"content": "Objectives Once complete, you should be able to:\n Be familiar with the Paved Road site Know what tools and editors are available to you  Index "
},
{
	"uri": "/onboarding/cyber-security/cyber-associates/",
	"title": "Cyber Associates",
	"tags": [],
	"description": "",
	"content": "The Cyber mission – protect what matters most.  Module Success:  Have a general understanding of the following:  Cyber Mission Transformation 2020 Focus Areas Cyber Services     Mission Transformation 2020 Focus Areas Key Functions Requested Tactic(s):  Share a 2-3-minute video clip where Stephen Ward, Chief Information Security Officer, highlights the cyber mission our focus areas for the next year    What’s in my cyber tool belt   Module Success:\n Have a general understanding of the following: Key technologies leveraged within Cyber Key resources Key partners    Topic 1: Tools to stay in the know:\n Archer Project Management Central: Commonly leveraged by Project Managers and Business Analysts, this portfolio management tool charts progress of strategic projects across all cyber services (POC: Erin_Bowers@homedepot.com ) Cybersecurity Service Catalog Cybersecurity Confluence Site Deadbolt Cyber myApron Site Portfolio Review Knowledge Depot    Topic 2: How to make a difference:\n Women’s Council: Business council to support the advancement of women within Cybersecurity (POC: Sherrie L’Amoreaux) Voice of the Associate: Committee made up of cyber associates who aim to improve how the organization can support its associates (Davina_Harell@homedepot.com) Requested Tatic(s): Share in person testimonials from associates who are a part of these councils    Topic 3: Key partners/tollgates:\n End User Community: Weekly tollgate meeting to vet efforts impacting the end user infrastructure Product Solution Review Board: Cross functional board that conducts workshops three times per week to review architecture and security designs to assure they meet business requirements    Topic 4: Things to know by role/function (Verify in course proposal):\n  The next 30 days Module Success: Able to grasp the cyber org. and hit the ground running in a relatively effective and efficient manner\n Topic 1: What to expect:  Meet with onboarding peer Attend Welcome Lunch Setup \u0026ldquo;Get to know you\u0026rdquo; (GTKY) Sessions Meeting with Leader expectations Review documentation  Cyber roadmap Glossary FAQ’s Org Chart Slack Channels      "
},
{
	"uri": "/python/automation/charts/database-interaction/",
	"title": "Database Interaction",
	"tags": [],
	"description": "",
	"content": "Welcome to Python Automation Pillars "
},
{
	"uri": "/javascript/nodejs/getting-started/npm-modules/es2015-modules/",
	"title": "ES2015 Modules",
	"tags": [],
	"description": "",
	"content": "ES2015 introduced a cleaner syntax for modules which consist of export and import statements.\nAccording to Mozilla\u0026hellip;\n export - used to export functions, objects or primitives from a given file (or module). import - used to import functions, objects or primitives that have been exported from an external module, another script, etc.  The syntax to use for ES Modules:\nimport \u0026lt;module\u0026gt;\t//1 import {function, object} from \u0026lt;module\u0026gt;\t//2 ... export \u0026lt;object\u0026gt;\t//3 export \u0026lt;function\u0026gt;\t//4 export default \u0026lt;function\u0026gt;\t//5  import a whole module import exported functions and/objects from the module export a specific named object from a module export a specific named function from a module export a function as a default export  ES Modules and NodeJS NodeJS treats JavaScript code as CommonJS modules by default. In order to use ES Modules with NodeJS, we must tell NodeJS to treat JS code as ES Modules.\nSome Terminology   CommonJS Modules - the old way that uses module.exports and require\n  ESM or ECMAScript Modules - the new way that uses export and import\n  Scripts - JavaScript files that end in .js or .cjs and use CommonJS\n  Modules - JavaScript files that end in .mjs and use ESM\n  NodeJS recognizes the following as ES modules when passed to node as the initial input, or when referenced by import statements within ES module code.\n  Files ending with .js are loaded according to package scope, which means that the closest package.json file in the directory hierarchy defines the module system via ”type”: “commons” or ”type”: “module”.\n  Files ending with .mjs are always loaded as ES modules regardless of package scope.\n  Files ending with .cjs are always loaded as CommonJS regardless of package scope.\n  You can import scripts into modules but you cannot import modules into scripts unless you use the esm library (or similar) to wrap the module into a script.\n   It is NOT recommended to mix CommonJS modules and ES Modules, as this can produce dual package hazards - where two versions of the same package can be loaded within the same runtime environment. However, there are safe ways to have dual packages when necessary. Check out the NodeJS documentation on dual packages, as well as this Redfin article Node Modules at War for more information.\n Use  Create a new project called node-calculator Add two files: index.js and calculator.js Initialize the project  mdkir node-calculator cd node-calculator touch index.js calculator.js npm init Add the following code to calculator.js\nexport function add(...numbers) { let sum = 0; numbers.forEach(function (number) { sum += number; }); return sum; } Add the following code to index.js and execute the project by running node index.js from the shell.\nimport {add} from \u0026#39;./calculator\u0026#39;; console.log(add(1,2,3)); You may notice that this does not immediately work for us. That\u0026rsquo;s because, when using the import keyword, it has to be within an ES Module.\nNode warning and syntax error\n(node:63441) Warning: To load an ES module, set \u0026#34;type\u0026#34;: \u0026#34;module\u0026#34; in the package.json or use the .mjs extension. ... SyntaxError: Cannot use import statement outside a module There are two ways we can handle this:\n Adding the .mjs extension to our files  We can rename our files from index.js and calculator.js to index.mjs and calculator.mjs. This tells NodeJS that we are working within ES Modules and thus allows the new import syntax.\nnode-calculator ├── node_modules ├── calculator.mjs //--\u0026gt; changes the .js extension to .mjs ├── index.mjs\t//--\u0026gt; changes the .js extension to .mjs ├── package-lock.json └── package.json 2 . Updating the package.json to include \u0026quot;type\u0026quot; : \u0026quot; module\u0026quot;\nWe can leave our module extensions as .js and set the type in the package.json,\n{ \u0026#34;name\u0026#34;: \u0026#34;inquire-example\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;module\u0026#34;, ---\u0026gt; tells Node all .js files in the same directory as this package JSON are to be treated as ES Modules. ... } According to the NodeJS documentation on type:\n\u0026ldquo;The \u0026quot;type\u0026quot; field defines the module format that Node.js uses for all .js files that have that package.json file as their nearest parent. Files ending with .js are loaded as ES modules when the nearest parent package.json file contains a top-level field \u0026quot;type\u0026quot; with a value of \u0026quot;module\u0026quot;. The nearest parent package.json is defined as the first package.json found when searching in the current folder, that folder’s parent, and so on up until a node_modules folder or the volume root is reached.\u0026quot;\nSince index.js and calculator.js are in the same directory as our package.json, they will both be treated as ES Modules. We can now safely use the new import syntax in our .js files.\nWith ES Modules, you can import partials from a file using curly braces, unlike CommonJS where you have to require all of the file.\n NodeJS versions older than version 14.13 will need to install the Babel package to use ES Modules with Browsers and NodeJS. You can find instructions here.\n Exporting-multiple-items calculator.js\nexport function add(...numbers) { let sum = 0; numbers.forEach(function (number) { sum += number; }); return sum; }; export function subtract(x,y) { return x - y; }; index.js\nimport {add, subtract} from \u0026#39;./calculator\u0026#39;; console.log(add(1,2,3)); console.log(subtract(6,2)); Named Exports Variables and Constants can also be exported\ncalculator.js\nexport const numbersArray = [1,2,3,4,5]; index.js\nimport _ from \u0026#34;inquirer\u0026#34;; import {add, subtract, numbersArray} from \u0026#39;./calculator\u0026#39;; _.prompt({ type: \u0026#39;list\u0026#39;, name: \u0026#39;operation\u0026#39;, message: \u0026#39;What would you like to do?\u0026#39;, choices: [\u0026#39;add\u0026#39;, \u0026#39;subtract\u0026#39;], }).then((answer) =\u0026gt; { // Chooses random numbers from the imported array  let num1 = numbersArray[Math.floor(Math.random() * 10)] let num2 = numbersArray[Math.floor(Math.random() * 10)] console.log(`Numbers given: ${num1}and ${num2}will be ${answer.operation}ed` ) // Based on selection, calls the corresponding imported function  if (answer.operation === \u0026#34;add\u0026#34;) { console.log(add(num1, num2)); } else { console.log(subtract(num1,num2)); } }); Default Exports Default Exporting allows you to set one item as default. This is helpful with a module or class that returns a single value.\ncalculator.js\nexport default function add(...numbers) { let sum = 0; numbers.forEach(function (number) { sum += number; }); return sum; }; index.js\nimport add from \u0026#39;./calculator\u0026#39;; console.log(add(1,2,3)); Named and Default Exports Only one default can be clarified per module. Modules can, however, have default and named exports\ncalculator.js\nexport default function add(...numbers) { let sum = 0; numbers.forEach(function (number) { sum += number; }); return sum; }; export function subtract(x,y) { return x - y; }; index.js\nimport add, {subtract} from \u0026#39;./calculator\u0026#39;; console.log(add(1,2,3)); console.log(subtract(6,2)); Wildcard Import One final way to import is by using the * (all, wildcard) operator. This syntax will import all exports.\ncalculator.js\nexport function add(...numbers) { let sum = 0; numbers.forEach(function (number) { sum += number; }); return sum; }; export function subtract(x,y) { return x - y; }; index.js\nimport * as calculate from \u0026#39;./calculator\u0026#39;; console.log(calculate.add(1,2,3)); console.log(calculate.subtract(6,2)); The modular pattern is heavily when building Single Page Applications with React and other libraries.\nSummary ECMAScript (ES)modules are the official standard format to package JavaScript code for reuse. Using ES Modules provides us with an easier syntax for importing module objects, using the keywords import and export. They also allow us to do partial file imports with the use of curly braces.\nAdditional Resources NodeJS Documention - Modules: ECMAScript Modules\nMDN Documentation - JavaScript Modules\n"
},
{
	"uri": "/path-to-production/before-you-build/asa/",
	"title": "Getting Started With an Architecture Security Assessment",
	"tags": [],
	"description": "",
	"content": "Part of getting an application to production, or prior to significant changes in an application, is to have it reviewed and approved by security. You can start this process by submitting an Architecture Security Assessment (ASA) request. The ASA will ask for detailed information about your application, including data classification, external service requirements, and so on.\nYou can continue developing your application while the ASA is in progress, but must have a review complete prior to going to production.\nYou can start your ASA on the ASA Portal. Once logged in, select create request on the ASA tile. If you have already started one and need to continue editing, you can choose view requests and edit from there.\n Overview of the Sections Product Overview This contains information about your product, its owners, compliance and risk, and deployment architecture.\n General Details\n  Covers general questions about the product, such as name, sub-experience, etc.\n  Team Roles\n  This section covers defines the roles in your org. Roles are defined as Product Owner, Technical Lead and so on.\n  Compliance and Risk\n  Compliance and Risk covers information regarding risk of financial loss or impact to The Home Depot\u0026rsquo;s reputation (internal or external) if the app goes down, or is unavailable.\n  Deployment Architecture\n  Covered here is information about how your product is deployed, where it is deployed, and how it is accessed.\n  Network Connectivity The network connectivity tab gathers information about how your product communicates with other services (if at all). As with other questions, depending on how you respond, more detail may be requested.\n Data Protection The Data protection section requests information about the type of data you are using and how it is handled in flight and at rest. Based on the type of data and where it is, there may be additional security measures and deployment locations you will need to put into place.\n Identity \u0026amp; Access Management This tab will covered how users are accessing your product as well as how they will request access to it.\n Administration Indicate whether or not your product is in the Configuration Management Database (CMDB). Also, you may add any additional comments about your product to this section.\n Architecture Diagram Provides a template to download as well as an area to upload once you have your diagram completed.\nNext Steps Once completed you complete the form and submit it, someone will review the findings and potentially contact you about them.\nIf you have questions about the process or anything on the form in the #security_asa_team slack channel.\n"
},
{
	"uri": "/javascript/nodejs/advanced/postman/postman-getting-started/",
	"title": "Getting Started With Postman",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Postman App Use Explanation of API\u0026rsquo;s, SOAP, and REST Making a Simple Postman Request  Getting started with the Postman App What is Postman? Postman is an App used for interacting with APIs. Postman\u0026rsquo;s easy to navigate UI and functionality helps simplify communication with APIs. Postman supports testing both SOAP and REST APIs, however for this lesson we will focus on REST.\nWhat\u0026rsquo;s an API? You\u0026rsquo;ve probably heard the term API before, as it is the way the web-based applications communicate with each other and with us. Checking the score for your favorite sports team via ESPN.com? You\u0026rsquo;re interacting with the ESPN API. Posting a message on Facebook and seeing it \u0026ldquo;magically\u0026rdquo; appear in your Twitter feed? You are interacting with the Facebook API, which then sends communication to the Twitter API. API stands for Application Programming Interface and it is the \u0026ldquo;handshake\u0026rdquo; or data-exchange that happens between web-based applications. That data-exchange is governed by several design models for web services, but the two most dominant are Simple Object Access Protocol (SOAP) and Representation State Transfer (REST).\n SOAP is a protocol that follows very rigid rules for security and message handling. REST is an architectual style that offers a more flexible handshake using simple HTTP protocols to a URI (Uniform Resource Indentifier).  For a more thorough explanation about REST and SOAP, checkout the links in the \u0026laquo;Additional Resources\u0026raquo; section below.\nAgain, we will focus on using the RESTful APIs. With a RESTful API, communication done using HTTP verbs (GET, POST, PUT, PATCH, and DELETE). There are other verbs used, however, we will focus on these as they handle Create, Read, Update, Delete (CRUD),the most typical activities used with interacting with an APIs resource (database).\n POST - The POST verb is most-often utilized to create new resources GET - The GET verb is used to read (or retrieve) a representation of a resource PUT - The PUT verb is most-often utilized for update capabilities, PUT-ing to a known resource, with the request body containing the newly-updated representation of the original resource. PATCH - PATCH is used for modify capabilities. Unlike PUT, The PATCH verb request only needs to contain the changes to the resource, not the complete resource. DELETE - The DELETE verb is used to delete a resource  Installing Postman Getting Postman is super easy! From the Home Depot App Store, select the Postman App and click install. Once the app finishes installing, click the icon to open.\n You may sign up for a free Postman account, but it is not required.\n Work performed in Postman is divided into Workspaces. Individuals can organize their work in personal workspaces and teams can collaborate in team workspaces. Initially we will work in the in our default workspace My Workspace.\nMaking HTTP Request Making a Simple API Call One of the simplest calls to make to an API is a GET call. This call retreives data from the URI. This will look a lot like a URL. This URL is know as an Endpoint.\n An Endpoint is a unique URL that represents an object or collection of objects. The endpoint is what you\u0026rsquo;ll point your HTTP client at to interact with data resources. It is very important to read the documentation associated with an API to understand the requirements and the data set that is returned.\n Based on the entry you provide, the API will return a data set response. The most popular response formats are XML and JSON.\nExample of JSON response\nHTTP headers\nPOST /api/2.2/auth/signin HTTP/1.1 HOST: my-server Content-Type:application/json Accept:application/json HTTP response body\n{ \u0026#34;credentials\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Joe Smith\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;Atlanta, GA\u0026#34;, \u0026#34;building\u0026#34;: { \u0026#34;Headquarters\u0026#34;: { \u0026#34;floor\u0026#34;: 15, \u0026#34;section\u0026#34;: 213 } } } } Example of XML response\n?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;root\u0026gt; \u0026lt;credentials\u0026gt; \u0026lt;building\u0026gt; \u0026lt;Headquarters\u0026gt; \u0026lt;floor\u0026gt;15\u0026lt;/floor\u0026gt; \u0026lt;section\u0026gt;213\u0026lt;/section\u0026gt; \u0026lt;/Headquarters\u0026gt; \u0026lt;/building\u0026gt; \u0026lt;location\u0026gt;Atlanta, GA\u0026lt;/location\u0026gt; \u0026lt;name\u0026gt;Joe Smith\u0026lt;/name\u0026gt; \u0026lt;/credentials\u0026gt; \u0026lt;/root\u0026gt; Both responses contain the same data, just presented in differents ways. Depending on your needs and the standard response of the API, it may be necessary to parse/convert the response to fit your development requirements.\nAt the top of the workspace, you will find the Request Builder toolbar. We\u0026rsquo;ll talk about more the toolbar a little later on. For now, find the button that says GET and the input box next to it. This is where we will provide our URL. For simplicity, we will use the MARTA Bus Realtime RESTful API.\n It is common for APIs to require an authorization key to interact with them. These keys are provided by the administrator of the API.\n The MARTA Api does not require an authorization key, making it very easy to interact with. For information about the MARTA API, check out the MARTA Bus Realtime RESTful API documentation. There are two endpoints associated with this API. We will use http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetAllBus. This will return a JSON response that list all real-time travel information for all buses in the MARTA system.\nPress the SEND button.\nIn the lower portion of the page, you will see the Response Header. In the header, there are two sections of importance, the return status code and the response format. First, let look at the status code. Status codes have different meanings, depending on the first digit in the 3-digit return code. The most common status codes are:\n 1xx - Informational 2xx - Success (200 is a common return code for communication the request was received successfully) 3xx - Redirection 4xx - Client Error (404 is a common return code for when the information requested is not found) 5xx - Server Error (500 is a common code for stating an error with the API server)   To see a complete list of status codes and definitions, check out the Additional Resources below.\n Next, lets look at the response format. Choose the Body tab. The Postman Body tab gives you several tools to help you understand the response quickly. You can view the body in one of three views - pretty, raw, and preview.\n Pretty - formats JSON or XML responses so they are easier to view. Raw - raw view is a large text area within the response body. It can be difficult to read as it used little \u0026ldquo;white space\u0026rdquo;. Preview - renders the response as it would be seen in the browser.  We will view the pretty version of the response.\nYou\u0026rsquo;ll see our response resembles an array of objects, where each object is information about a bus. Scroll through the window and you will see the list is long. Let\u0026rsquo;s take a look at the second endpoint from MARTA. The second endpoints returns a list of buses based on the route number. We will take a look at route 14. Place the following url in the in the URI box and press send: http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetBusByRoute/14 .\nAs you can see, this returned a smaller response. While MARTA only offers two endpoints, other APIs like Yelp and Google offer an array of endpoints giving you access to large amounts and variations of their data.\nAuthorizations As mentioned previously, there are times when you are required to enter authorization credentials to interact with an API. This process verifies whether you have permission to access the data you want from the APIs server.\nWhen you select the “Authorization” tab in the request builder, you see the authorization TYPE drop down menu:\n Inherit Auth From Parent - indicates that every request in this folder by default uses the authorization type from the parent. No Auth - by default, \u0026ldquo;No Auth\u0026rdquo; is set initially. Use this when authorization is not required. Bearer Token - A bearer token is a security token used to access data. This does not require a cryptographic key. Basic Auth - this requires a verified username and password to access the data resource. Digest Auth - an authorization process where the client sends a request to a server, which sends back nonce and realm values for the client to authenticate. The client sends back a hashed username and password with the nonce and realm. The server then sends back the requested data. OAuth 1.0 and OAuth 2.0 - These authorizations type that enables you to approve an application that contacts another application for you without exposing your password. Hawk Authentication - Hawk authentication enables you to make authenticated requests with partial cryptographic verification of the request. AWS Signature - AWS is the authorization workflow for Amazon Work Services requests. NTLM Authentication [Beta] - Windows Challenge/Response (NTLM) is the authorization flow for the Windows operating system and for stand-alone systems.  For more information see the Additional Resources list below.\nAdditional Resources  Stackify: SOAP vs. REST Understanding SOAP and REST basics SOAP vs. REST: A Look at Two Different API Styles^ Postman Authorizations REST API Tutorial: HTTP Status Codes  "
},
{
	"uri": "/path-to-production/tech-stack/messaging/",
	"title": "Messaging Options",
	"tags": [],
	"description": "",
	"content": "PubSub Through Service Catalog What is Pub/Sub?\n Cloud Pub/Sub is a scalable, durable, event ingestion and delivery system that supports the publish-subscribe pattern at large and small scales. Cloud Pub/Sub makes your systems more robust by decoupling publishers and subscribers of event data.\n Google Cloud Pub/Sub\nIf you require asynchronous communication between your applications, Google Cloud Pub/Sub is a supported option and can be requested through the service catalog\nSome additional use-cases:\n Establish a queue for a workload Asynchronously communicate between services Distributing event notifications Multiple data sources can stream to the same topic  Requesting a Topic   Navigate to service catalog pub-sub request form\n  Fill out the form with your LDAP, a manager or above\u0026rsquo;s name and your experience.\n  Select your options in the Request Details\n  Hit submit and you should get dialog box\n  Follow the instructions in the email to get access.\n  Accessing your Google PubSub Topic To access your google cloud bucket, you can use the gsutil command that can be installed with gcloud, which in turn can be installed from the Google Cloud SDK. While you can install through the official site, it is recommended that you install through THD App Store on mac, or the Software Center if you are using Windows.\nOnce the SDK is installed, you should be able to open a terminal, PowerShell or command prompt, and run the following command:\n$ gcloud components install pubsub PubSub Support For support of questions see the official page or join the #Io1-Cloud slack channel.\n"
},
{
	"uri": "/python/nonrelational-db/",
	"title": "Nonrelational Databases",
	"tags": [],
	"description": "",
	"content": "Welcome to Python Nonrelational Database Pillars "
},
{
	"uri": "/application-security/api-security/02_human_to_service_oidc/",
	"title": "OIDC / Human to Service",
	"tags": [],
	"description": "",
	"content": "Introduction to Human to Service API Security Using OpenID Connect (OIDC) Goals  Learn about the OAuth2 Auth Code Grant Understand how OpenID Connect (OIDC) extends the OAuth2 Auth Code Grant Different Tokens and their purposes Understand how to use OIDC for client (human/user) to server authorization  "
},
{
	"uri": "/software-eng-essentials/fundamentals-of-regex/python/",
	"title": "Regex in Python",
	"tags": [],
	"description": "",
	"content": "Regex in the context of Python Skills  Basics of Regex Intermediate Regex  Basics of Regex Anchors    ^ $     ^Harry : Starts with the word \u0026lsquo;Harry\u0026rsquo;. Potter$ : Ends with \u0026lsquo;Potter\u0026rsquo;. ^Harry Potter$ : Starts with \u0026lsquo;Harry\u0026rsquo; and ends with \u0026lsquo;Potter\u0026rsquo;. Exact match to \u0026lsquo;Harry Potter\u0026rsquo;. magic : Matches any string with the word magic in it.  Prints out the first line.\n# TBD Exercise\nQuantifiers    * + ? {} ()    For the following, we\u0026rsquo;re going to use possible serial numbers to express the quantity of c\u0026rsquo;s we want to match on. The ex: provides serials numbers that would match.\n   Pattern Description Examples     ABc* Has AB and followed by 0 or any number of cs 0123AB45, 0123ABc45, 0123ABcc45   ABc+ Has AB and followed by 1 or more cs 0123ABc45 , 0123ABcc45 , 0123ABccc456   ABc? Has AB and followed by 0 or 1 cs 0123ABc45 , 0123AB45   ABc{3} Has AB and followed by 3 cs 0123ABccc56;   ABc{4,} Has AB and followed by 4 or more cs 0123ABcccc456 , 0123ABccccc456   ABc{2,5} Has AB and followed by 2 up to 5 cs 0123ABcc456 , 0123ABccccc456   A(bc)* Has A followed by zero or more of the sequence bc 0123A456 , 0123Abcbcbc456   A(bc){4,6} Has e followed by 4, or 5 bc sequences 0123Abcbcbcbc456 , 0123Abcbcbcbcbc456    Example TBD Prints out just the hardware using a known pattern of ending with at least 2 P\u0026rsquo;s.\nPrints out just the garden items using a known pattern of having E4 followed by at least one 6.\n$ cat serials.csv | egrep \u0026#39;E46+\u0026#39; E4660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 E460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 Exercise\nOR operator | \\| | [] | |:-:|:-:|\n   Pattern Description     A(b\\|c) Has A and followed by a b or a c.   e[bc] Has e and followed by a b or a c.    Let\u0026rsquo;s say we have the following text file of email addresses.\n$ printf \u0026#34;test@email.com\\nfake@gmail.com\\nlearning@bash.edu\\nfun@commandline.gov\\n\u0026#34; \u0026gt;\u0026gt; emails.csv $ cat emails.csv test@email.com fake@gmail.com learning@bash.edu fun@commandline.gov If we wanted to print out the emails that contain either @email or @gmail we could use this pattern: @[eg]mail\n$ cat emails.csv | egrep \u0026#39;@[eg]mail\u0026#39; test@email.com fake@gmail.com Exercise\n Using the above CSV file, print to the screen only those that end in \u0026ldquo;.gov\u0026rdquo; OR \u0026ldquo;.edu\u0026rdquo;.  Character Classes    \\d \\w \\s .       Pattern Description Examples     \\d Is a single digit. $ls \\| grep -E '/d' would list any file that starts with a number in your current directory.   \\w Is WORD character, i.e. alphanumeric or underscore $ls \\| grep -E '^\\w\\w\\w\\w-' would list files that start with four alpha characters, then a dash.   \\s Is a whitespace character, including tabs and line breaks ls \\| grep -E '\\w\\w\\s..\\d\\d' would list files that contains a letter, letter, a space, any character, any character, followed by two digits. Such as ec 1983.png   . Is ANY character As shown in the above example.    Inverse options\n/D gives the inverse option of /d, ex: /D matches to any one NON Digital character.\nExercise\nCreate a text file with digits, alpha, and alphanumeric keys for the following exercises. +\nprintf \u0026#34;abcdef + 123456 + abc123\u0026#34; \u0026gt;\u0026gt; testkeys.txt Exercise\n Print to the screen only the keys that include 3 consecutive digits. hint: Use qauntifiers. Print to the screen only the keys that have 3 consecutive non digit characters.  Bracket Expressions    []       Pattern Example     [emc] String can have either an \u0026lsquo;e\u0026rsquo;, \u0026rsquo;m\u0026rsquo;, or a \u0026lsquo;c\u0026rsquo;.   [a-m] String can have any letter a through m.   [a-fA-F0-9] String represents a hexadecimal number, case insensitive because we are allowing a-f lowercase, and upper.   [0-9]% String has a digit that is zero or higher, and not greater than 9, followed by a percent sign.   [^a-zA-Z] String that does NOT contain a letter a-z or A-Z. In this case the carrot is a negator.    So if we had the following text file with wood types and their tensile strength\nWood Species\tBending Strength (psi)\tAlder, Red\t9,800 Ash 15,000 Aspen 8,400 Basswood\t8,700 Beech\t14,900 Birch, Yellow\t16,600 Butternut\t8,100 Cherry\t12,300 Chestnut\t8,600 Elm\t11,800 Hickory\t20,200 Maple, Hard\t15,800 Maple, Soft\t13,400 Oak, Red\t14,300 Oak, White\t15,200 Poplar\t10,100 Sassafras\t9,000 Sweetgum\t12,500 Sycamore\t10,000 Walnut\t14,600 In order to print out just the wood types that can handle at least 15k psi, one could do:\n$ cat woodstrength.txt | egrep \u0026#39;1[5-9],[0-9]{3}\u0026#39; Ash 15,000 Birch, Yellow\t16,600 Maple, Hard\t15,800 Oak, White\t15,200 Exercise\nThis exercise is to be performed in a terminal. Execute the following to create a csv file that contains cities and their temperatures.\n$ printf \u0026#34;City\\tTemperature\\n\\rMiami\\t100deg\\n\\rAtlanta\\t95deg\\n\\rRichmond\\t90deg\\n\\r\u0026#34; \u0026gt; citytemps.csv Exercise\n Print out the lines that have temperatures 95 degrees and higher.  Resources  https://regexr.com/ https://www.regular-expressions.info/  "
},
{
	"uri": "/onboarding/cyber-security/general/module-3-responsibility/",
	"title": "Security - A Shared Responsibility",
	"tags": [],
	"description": "",
	"content": "Topics  Understand how each role has a different responsibility for securing information Examples based on job role. Associates should be able to identify risks associated with their job role.  Its important to note we’re working on a culture shift. A culture shift that MUST begin with everyone in our company. We all have a responsibility to drive incremental change in protecting our enterprise.\nUnderstand when to engage Cybersecurity  In module 2, we looked at general cyber hygiene practices that everyone can do to improve their security. In this module we will focus on how Cybersecurity will impact your job role.\n As we continue on our Orange Path journey, here are seven best practices to secure every step:\n  Click Securely: Think twice before clicking on email links or attachments that appear suspicious. Immediately forward suspicious emails as an attachment to Cybersecurity@homedepot.com\n  Connect Securely: Connect to a secure network via Virtual Private Network (VPN) as well as a password protected Wi-Fi before accessing THD systems while on the go\n  Log In Securely: Avoid using work credentials for logons on external sites. Keep them separate. Remember to create complex passwords\n  Share Securely: Always confirm the identity and authority of a contact before sharing any information on a ‘need to know’ basis\n  Shred Securely: Print and dispose of hard copy documents using company-provided printers and shred it bins\n  Report Immediately: Report suspicious emails, calls or persons immediately to cybersecurity@homedepot.com\n  Update Frequently: Ensure THD devices are running the latest versions of software and patches\n  Understand how each role has a different responsibility for securing information Examples based on job role. Associates should be able to identify risks associated with their job role\nCONTACT  Approved Software: For questions about approved software, contact your department’s Technology partner or email: technology_partner@homedepot.com Suspicious Email: If you receive a suspicious email, immediately report it to Cybersecurity via PhishAlarm by clicking the “Report Phish” icon on your Outlook home ribbon or email cybersecurity@homedepot.com.  Managing Personal Information:   Manage What You Share: Be mindful of the personal information you share online. The more detail you share online (date of birth, phone number or when and where you are going on vacation), the easier it may be for someone to access your data to commit cybercrimes like identity theft.\n  Review Account Settings: For apps and accounts, security settings may default to opt-in – allowing data like location, contacts, and photos to be accessed and shared with third parties. Review these to ensure information is restricted and guarded.\n  Browse Websites Privately: Turn on private browsing to prevent websites from collecting and storing information about you like credentials and search histories.\n  Safeguard Your Information: Prevent anyone but you from accessing your information. Create complex passwords making it tough to crack. If possible, setup two factor authentication, which requires an extra security code when you sign in from a device that isn’t trusted.\n  Store Data Securely: When storing files such as pictures and documents, be sure to use the strongest data protection level to ensure information doesn’t fall into the wrong hands. Restrict access to a need-to-know basis and immediately purge information once no longer needed.\n  Monitor Personal Information Frequently: Check personal accounts (e.g. banking, social media, emails, etc.) regularly for any unfamiliar activity and monitor credit reports for new inquires or accounts that appear unfamiliar.\n  Approved Cloud Storage: FAQs: Staying Cyber Safe with Approved Software   How do I know if the tool I am using is secure and using single sign-on (SSO)?\n Internet Third-party software that has been reviewed and approved will ask you to log in via The Home Depot single sign-on (SSO) page (below). If the software you access does not require SSO, contact your technology partner. Technology_partner@homedepot.com      An external partner uses a non-approved platform to conduct virtual meetings. Can I still participate?\n Whenever Home Depot information is being shared, associates should use approved means of collaboration. The preferred methods are Webex, Microsoft Teams and OneDrive for Business. Please work with your vendor partners to utilize Home Depot approved collaboration tools.    How do I get tools added to the approved list? * Please partner with your technology business partner to determine the best way to add the appropriate security to your business tool. Reminder: Be sure to connect to a secure network via Virtual Private Network (VPN) as well as a password protected Wi-Fi before accessing company systems and networks.\n   "
},
{
	"uri": "/javascript/nodejs/getting-started/node-core-modules/os-module/",
	"title": "The OS Module",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Retrieving information from the underlying system using Node  Skills  Learn to use the os module and its objects  Operating system module The Node.js os module provides us with information about the computer’s operating system. For example, the os module can tell us more specific details about the machine we’re using including memory and users.\nWe will cover a few of the os module objects, but for more info access the Node.js OS Module Documentation: Node OS documentation.\nSystem info True to its name, the os module interfaces with the underlying operating system and makes the system information available.\n We can use the os objects in a script or in the Node REPL.\n // Running in the Node REPL os.platform(); // Returns the platform Node was compiled for. \u0026#39;darwin\u0026#39; os.type(); // Identifies the operating system. \u0026#39;Darwin\u0026#39; os.arch(); // Identifies the underlying architecture. \u0026#39;x64\u0026#39; os.freemem(); // Returns the total amount of free system memory in bytes. 1599995904 os.totalmem(); // Returns the total amount of system memory in bytes. 17179869184 os.uptime(); // Returns the system uptime in number of seconds. 113229 os.cpus(); /* Returns an array of objects containing information about each logical CPU core. */ [ { model: \u0026#39;Intel(R) Core(TM) i7-7820HQ CPU @ 2.90GHz\u0026#39;, speed: 2900, times: { user: 4592240, nice: 0, sys: 3932340, idle: 32333170, irq: 0 } }, // ... seven more cores listed in the array as objects... ] User info The os module lets us find user information with the os.userInfo() object.\nos.userInfo(); { uid: 501, gid: 20, username: \u0026#39;KJQ0BXK\u0026#39;, homedir: \u0026#39;/Users/KJQ0BXK\u0026#39;, shell: \u0026#39;/bin/zsh\u0026#39; } We see that os.userInfo() returns an object with five values or properties. We can call any of those values using dot notation or bracket notation like we would with any other JavaScript object.\nos.userInfo().uid; 501 os.userInfo()[\u0026#34;username\u0026#34;]; \u0026#39;KJQ0BXK\u0026#39;  Windows users will see that their system uid and gid fields are -1, and shell is null.\n Constants Node allows us to interact with system constants by using the os.constants object. These constants include (but are not limited to) signals and errno.\nSignals We can find constants related to handling process signals with os.constants.signals.\n A signal is an asynchronous notification sent to a process or to a specific thread within the same process in order to notify it of an event that occurred.\n const signals = os.constants.signals; signals; // Returns object with signal constant values. ... signals.SIGTERM; // Sent to a process to request termination. 15 signals.SIGINT; // Sent to indicate when a user wishes to interrupt a process. 2 signals.SIGHUP; /* Sent to indicate when a controlling terminal is closed or a parent process exits. */ 1 signals.SIGKILL; // Sent to a process to terminate it immediately. 9  See the os.signal.constants documentation for more.\n Errors We can use Node to interact with system errors using the constants available in os.constants.errno.\n errno means \u0026ldquo;number of the last error\u0026rdquo; where a system error is represented by an integer value.\n const errno = os.constants.errno; errno; // Returns object with error constant values. ... errno.EPERM; // Indicates that the operation is not permitted. 1 errno.ENOENT; // Indicates that there is no such file or directory. 2 Labs OS Module Labs\n"
},
{
	"uri": "/onboarding/cyber-security/cyber-associates/module-3-going-forward/",
	"title": "What is next?",
	"tags": [],
	"description": "",
	"content": "The next 30 days   What to expect:\n Meet with onboarding peer Attend Welcome Lunch Setup \u0026ldquo;Get to know you\u0026rdquo; (GTKY) Sessions Meeting with Leader expectations    Review documentation\n Cyber road map Glossary FAQ’s Org Chart Slack Channels    "
},
{
	"uri": "/onboarding/general/module-3-balanced-teams/",
	"title": "What is next?",
	"tags": [],
	"description": "",
	"content": "The next 30 days   What to expect:\n Meet with onboarding peer Attend Welcome Lunch Setup \u0026ldquo;Get to know you\u0026rdquo; (GTKY) Sessions Meeting with Leader expectations    Review documentation\n Cyber road map Glossary FAQ’s Org Chart Slack Channels    "
},
{
	"uri": "/python/apis/",
	"title": "APIs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/path-to-production/tech-stack/cicd-options/",
	"title": "Choosing a CICD Solution",
	"tags": [],
	"description": "",
	"content": "CICD Options In addition to delivering value, we want to be able to be able to deliver quickly. Automating the test, build and deployment processes can speed up our delivery significantly if done well.\nBefore we get into the tools that help us implement CICD, lets go over what it is.\n What is CICD? With software teams made up of multiple people, often working on multiple features in parallel, it is necessary to be able to move fast and get feedback quickly. Applications need to have the ability to be constantly modified and delivered to their customers so that a continuous feedback loop can exist. Teams need to be able to frequently show users what they have designed and built, while still providing a stable and reliable product. The principles of CICD provide a foundation to effectively add features to your product, while quickly delivering those features and getting it in front of your users faster and safer than a manual process.\nLet’s dive a little deeper into what CICD actually stands for and means\n  CI which means continuous integration\n  CD which means continuous deployment or delivery\n   What Is CI Continuous Integration is a process where software engineers frequently integrate code into a product\u0026rsquo;s codebase. Each integration can then be verified by automated tests and other automated processes, such as linting. Some of the key benefits of this process are that it is reproducible, viewable, and auditable.\nTo understand what problems this solves and the opportunities it enables, let’s consider a scenario that does not leverage CI as a software engineering practice.\nTeams working on an application could potentially grow very large, and as a result there might need to be a method to allow for multiple individuals to work on features in parallel. The common method used to be to branch off a single master or trunk version of the code, commonly what was said to match what was in production, and work on a feature to completion. The disadvantage of this was that, due to the lengthy iterations and large changes being made, it would be a tremendous task to finally merge all these features back together at once for a release. In some cases, the process of integrating the features back into the \u0026ldquo;master\u0026rdquo; version of the codebase was a task of itself. This led to a lot of wasted time and large risk of encountering bugs when the code was finally consolidated. Continuous integration aims to make this process an integral and common part of the development cycle instead of an infrequent and monolithic chore.\nSo what can we do to enable CI on a team?\n  All code is integrated into a single code repository\n  The code is built on every change\n  An artifact is generated of that state of the code\n  Tests are run every time a change of committed\n  These may include\n  Unit tests\n  Functional tests\n  Security scans\n  Code quality scans\n  Every build should be easily viewable by anyone\n  But what problems do these practices solve?\n  Manual integration of features in code means higher risk of error\n  Teams don’t have to wait to get feedback about changes\n How do new changes affect existing ones? If something breaks, the team can find it fast before it impacts users    It’s easier to work on more than one feature at a time\n  The process is scalable to size and scope of the project and team\n   What is CD? CD can be broken up into two distinct definitions, both involving the constant readiness of a version of an application codebase to be deployed to production.\nContinuous Deployment → the code WILL be deployed once a criteria has been met\nContinuous Delivery → the code CAN be deployed at will\nConsider the rapidity at which customer expect features to be implemented in the application they use. Consider how fast they expect issues to be fixed. Software teams cannot expect to be successful by continuing to work in the waterfall model of doing few deployments at very wide intervals. The principles of continuous integration can be extended to enable seamless delivery of changes to software to customers.\nSome considerations that need to be taken into account when considering implementations of CD include:\n How robust is the CI process to ensure that software is ready to be delivered straight to production? What are the business concerns around sending software into production like audit compliance? Does the CD process have an effect on the end user experience with the software?  The Tools For Building and Running Pipelines You will hear the term cicd pipeline a lot. Without talking about tools, a pipeline can be explained as a series of steps, most often scripts, that automate the processes mentioned above.\nYou don\u0026rsquo;t need a tool to make a cicd pipeline. In fact, most tools still require you to script at some point. What the tools do for us is provide a runtime environment to help us execute the steps as well as how and when to build.\nThere are 3 popular products currently in use at The Home Depot to aid in the CICD process.\n Concourse Jenkins TeamCity  All options have server on demand blueprints that you can use to quickly stand up the run-time part of your CICD process.\n Concourse Concourse is an open source tool that was originally developed by pivotal as a tool they used internally.\nConcourse was one of the first tools in The Home Depot to gain community support, and continues to be well supported by that community. A concourse pipeline is configured using a yaml file that describes how each step is to run. Additionally the config allows you to:\n Define multiple external resources, such as code or script repositories Define jobs and tasks for various stages of your pipelines Allows you to pull in your own docker containers for builds  Pipelines are deployed using a cli tool called fly that you can download after standing up a server.\nA nice addition you get with concourse server is a browser view that shows the status of all of your deployed pipelines, as well as the ability to navigate down into your pipeline at various levels of detail.\nJenkins Jenkins can also be built from Server on Demand blueprint. It offers you the ability to configure steps through a GUI rather than a yaml file and also includes a visual status.\nTeamCity As with the others, TeamCity has the ability to be stood up from a blueprint. It offers you the ability to configure steps through a GUI, but lacks any visual status.\n"
},
{
	"uri": "/path-to-production/platforms/",
	"title": "Configure Your Runtime Environment",
	"tags": [],
	"description": "",
	"content": "Objectives Once complete, you should be able to:\n Request access you need Know what tools and editors are available to you  Index "
},
{
	"uri": "/javascript/nodejs/getting-started/node-core-modules/os-module-labs/",
	"title": "Labs for OS Module",
	"tags": [],
	"description": "",
	"content": "This lab will have you use the os module and its objects to retrieve and interact with system information.\n Create a file called os-module-exercise.js.  Don’t forget to put const os = require('os'); at the top of your file!   Copy and paste the following code into the os-module-exercise.js file and complete the exercise.   Each step of exercise instruction is preceded by a console.log() statement that simply serves to visually format the program and facilitate the lab exercises.\n console.log(\u0026#34;🔶🔸🔸\u0026#34;); // Print the system uptime in seconds.  // Your code here  console.log(\u0026#34;🔸🔸🔶\u0026#34;); // Print out the total memory in bytes.  // Your code here  console.log(\u0026#34;🔷🔹🔹\u0026#34;); // Print out the free memory in bytes.  // Your code here  console.log(\u0026#34;🔹🔹🔷\u0026#34;); // Print out the host name of the operating system you\u0026#39;re using.  // Your code here  console.log(\u0026#34;🔶🔸🔸\u0026#34;); // Print out the platform you\u0026#39;re using.  // Your code here  console.log(\u0026#34;🔸🔸🔶\u0026#34;); // Print out the system architecture of the machine you\u0026#39;re using.  // Your code here  console.log(\u0026#34;🔷🔹🔹\u0026#34;); /* Print out the network interface for localhost. Hint: the key for localhost is \u0026#34;lo0\u0026#34; within the network interface object. Just print out the whole value for \u0026#34;lo0\u0026#34; within the object returned by the call to fetch the network interface. */ // Your code here  console.log(\u0026#34;🔹🔹🔷\u0026#34;); /* Print out IPv4 localhost address. Hint: this comes to you as an object and you must find the \u0026#34;address\u0026#34; key. */ // Your code here  console.log(\u0026#34;🔸🔸🔸\u0026#34;); /* Print out your computer\u0026#39;s home directory within user info. Hint: `user info` comes to you as an object, so you can first print out the object to find the home directory key, and then print out the computer\u0026#39;s home directory. */ // Your code here  "
},
{
	"uri": "/javascript/nodejs/advanced/stdin-stdout-buffers-streams-labs/",
	"title": "Labs for stdin/stdout with Buffers &amp; Streams",
	"tags": [],
	"description": "",
	"content": "Lab 1 – stdin \u0026amp; stdout We\u0026rsquo;ll create a number guessing game for our lab.\n  Create a file named random-guess.js\n  Set a variable to a random secret number between 1-10 at the beginning of each round\n To get you started, we will provide the random number generator:\nconst randomNumber = Math.floor(Math.random() * 10) + 1 This uses the Math library .random() function which generates a random floating point number between 0 and 1 (but not inclusive of 1). Next the number is multiplied by 10 so that we have a number between 1 and 10 . The decimals are removed with the Math.floor() function and finally 1 is added to it to prevent a result of 0.\n   Have a user guess the random secret number by typing it into the command line\n  Print out whether or not the user guessed correctly\n  Make sure the program exits after the correct number is guessed\n  Lab 2 – Streams \u0026amp; Buffers Exercise Instructions\n Get into pairs Read these sections of the Stream Handbook:  Introduction Why you should use streams Basics   Write down any questions you have  Lab 3 – Stream Adventures Exercise Instructions\n Locate (or create) a directory titled nodeschool-exercises In the command line, paste the following code: +  docker container run -it --rm -v ${PWD}:/usr/app/nodeschool-exercises shanebarringer/nodeschool-exercises  Once inside the container  Create a directory named stream-adventure and cd into it (this is also addressed in exercise 1 of the stream-adventure module) Type stream-adventure to start the exercises. When finished with a challenge run stream-adventure verify \u0026lt;your-file.js\u0026gt; to verify your solution Then run stream-adventure again to move on to the next challenge    Detailed instructions for this exercise can be found here.\n"
},
{
	"uri": "/javascript/nodejs/getting-started/npm-modules/",
	"title": "NPM",
	"tags": [],
	"description": "",
	"content": "Working with NPM "
},
{
	"uri": "/software-eng-essentials/fundamentals-of-regex/java/",
	"title": "Regex in Java",
	"tags": [],
	"description": "",
	"content": "Regex in the context of Java Skills  Basics of Regex Intermediate Regex  Basics of Regex Anchors    ^ $     ^Harry : Starts with the word \u0026lsquo;Harry\u0026rsquo;. Potter$ : Ends with \u0026lsquo;Potter\u0026rsquo;. ^Harry Potter$ : Starts with \u0026lsquo;Harry\u0026rsquo; and ends with \u0026lsquo;Potter\u0026rsquo;. Exact match to \u0026lsquo;Harry Potter\u0026rsquo;. magic : Matches any string with the word magic in it.  Prints out the first line\nQuantifiers    * + ? {} ()    For the following, we\u0026rsquo;re going to use possible serial numbers to express the quantity of c\u0026rsquo;s we want to match on. The ex: provides serials numbers that would match.\n   Pattern Description Examples     ABc* Has AB and followed by 0 or any number of cs 0123AB45, 0123ABc45, 0123ABcc45   ABc+ Has AB and followed by 1 or more cs 0123ABc45 , 0123ABcc45 , 0123ABccc456   ABc? Has AB and followed by 0 or 1 cs 0123ABc45 , 0123AB45   ABc{3} Has AB and followed by 3 cs 0123ABccc56;   ABc{4,} Has AB and followed by 4 or more cs 0123ABcccc456 , 0123ABccccc456   ABc{2,5} Has AB and followed by 2 up to 5 cs 0123ABcc456 , 0123ABccccc456   A(bc)* Has A followed by zero or more of the sequence bc 0123A456 , 0123Abcbcbc456   A(bc){4,6} Has e followed by 4, or 5 bc sequences 0123Abcbcbcbc456 , 0123Abcbcbcbcbc456    Prints out just the hardware using a known pattern of ending with at least 2 P\u0026rsquo;s\nPrints out just the garden items using a known pattern of having E4 followed by at least one 6\n$ cat serials.csv | egrep \u0026#39;E46+\u0026#39; E4660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 E460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 OR operator | \\| | [] | |:-:|:-:|\n   Pattern Description     A(b\\|c) Has A and followed by a b or a c.   e[bc] Has e and followed by a b or a c.    Let\u0026rsquo;s say we have the following text file of email addresses.\n$ printf \u0026#34;test@email.com\\nfake@gmail.com\\nlearning@bash.edu\\nfun@commandline.gov\\n\u0026#34; \u0026gt;\u0026gt; emails.csv $ cat emails.csv test@email.com fake@gmail.com learning@bash.edu fun@commandline.gov If we wanted to print out the emails that contain either @email or @gmail we could use this pattern: @[eg]mail\n$ cat emails.csv | egrep \u0026#39;@[eg]mail\u0026#39; test@email.com fake@gmail.com Exercise\n Using the above CSV file, print to the screen only those that end in .gov OR .edu.  Character Classes    \\d \\w \\s .       Pattern Description Examples     \\d Is a single digit. $ls \\| grep -E '/d' would list any file that starts with a number in your current directory.   \\w Is WORD character, i.e. alphanumeric or underscore $ls \\| grep -E '^\\w\\w\\w\\w-' would list files that start with four alpha characters, then a dash.   \\s Is a whitespace character, including tabs and line breaks ls \\| grep -E '\\w\\w\\s..\\d\\d' would list files that contains a letter, letter, a space, any character, any character, followed by two digits. Such as ec 1983.png   . Is ANY character As shown in the above example.    Inverse options\n/D gives the inverse option of /d, ex: /D matches to any one NON Digital character.\nExercise\nCreate a text file with digits, alpha, and alphanumeric keys for the following exercises. +\nprintf \u0026#34;abcdef + 123456 + abc123\u0026#34; \u0026gt;\u0026gt; testkeys.txt  Perform the following exercises:  Print to the screen only the keys that include 3 consecutive digits. hint: Use quantifiers. Print to the screen only the keys that have 3 consecutive non digit characters.    Bracket Expressions    []       Pattern Example     [emc] String can have either an \u0026lsquo;e\u0026rsquo;, \u0026rsquo;m\u0026rsquo;, or a \u0026lsquo;c\u0026rsquo;.   [a-m] String can have any letter a through m.   [a-fA-F0-9] String represents a hexadecimal number, case insensitive because we are allowing a-f lowercase, and upper.   [0-9]% String has a digit that is zero or higher, and not greater than 9, followed by a percent sign.   [^a-zA-Z] String that does NOT contain a letter a-z or A-Z. In this case the carrot is a negator.    So if we had the following text file with wood types and their tensile strength\nWood Species\tBending Strength (psi)\tAlder, Red\t9,800 Ash 15,000 Aspen 8,400 Basswood\t8,700 Beech\t14,900 Birch, Yellow\t16,600 Butternut\t8,100 Cherry\t12,300 Chestnut\t8,600 Elm\t11,800 Hickory\t20,200 Maple, Hard\t15,800 Maple, Soft\t13,400 Oak, Red\t14,300 Oak, White\t15,200 Poplar\t10,100 Sassafras\t9,000 Sweetgum\t12,500 Sycamore\t10,000 Walnut\t14,600 In order to print out just the wood types that can handle at least 15k psi, one could do:\n$ cat woodstrength.txt | egrep \u0026#39;1[5-9],[0-9]{3}\u0026#39; Ash 15,000 Birch, Yellow\t16,600 Maple, Hard\t15,800 Oak, White\t15,200 Exercise\nThis exercise is to be performed in a terminal. Execute the following to create a csv file that contains cities and their temperatures.\n$ printf \u0026#34;City\\tTemperature\\n\\rMiami\\t100deg\\n\\rAtlanta\\t95deg\\n\\rRichmond\\t90deg\\n\\r\u0026#34; \u0026gt; citytemps.csv Exercise\n Print out the lines that have temperatures 95 degrees and higher.  Regex in VIM VIM search and replace    Command Description     :range s[ubstitute]/pattern/string/cgiI For each line in the range replace a match of the pattern with the string where:   c Confirm each substitution   g Replace all occurrences in the line (without g - only first).   i Ignore case for the pattern.   I Don\u0026rsquo;t ignore case for the pattern.    Regex with SED Answers to the exercises  cat quotes.txt | grep ^It cat quotes.txt | grep fleas$ cat quotes.txt | grep dreams cat serials.csv | egrep '0123Z{1,5} cat emails.csv | egrep 'gov|edu' cat testkeys.txt | egrep '\\d{3}' cat testkeys.txt | egrep -E '\\D{3}' cat citytemps.csv | grep -E '9[5-9]|100'  Resources  https://regexr.com/ https://www.regular-expressions.info/  "
},
{
	"uri": "/python/testing/",
	"title": "Testing",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/javascript/nodejs/advanced/postman/postman-sports-team-api/",
	"title": "Testing with Postman",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Using the Postman App to exchange data with a local API Create collections of multiple API requests  Skills  Perform CRUD activities with and API resource Bundle several API requests together to create a collection  Review of CRUD Besides reading the data from a API interaction, if the APIs endpoint allow, we can also create data objects, update data objects and delete data objects from an APIs resource. This is done using the other HTTP verbs -\n POST PUT GET DELETE  Interacting with the Sports Teams API. Local environment set-up To get a real sense of how Postman can be a powerful tool for interacting and testing the endpoints of an API, we will use it to test the endpoints of the Sports Teams API. This API has 8 endpoints used to view the data in the resource in several ways - by team, team index number, league, state or by combination of league and state. There are also endpoints for modifying a team, adding a team, and for deleting a team for the resource.\nWe will load the API on onto our local environment. To begin, run the following commands in the terminal:\nmkdir postman_exercises cd postman_exercises git clone https://github.com/one-thd/om_labs_postman.git postman This will create a new directory on your system request postman_exercises. This is where we will keep all work associated with this lesson. After creating the directory, cd into the directory and run the git clone command. This will bring the Postman project down from the Github remote repository to our local machine.\nAfter cloning the repository, run:\ncd postman You should now be in your local postman repository which includes the code for the Sports Teams API.\nSports Team API Database Local database set-up Enter the following in your terminal to install the necessary database packages for the API:\nbrew install postgres npm install -g knex brew services start postgresql createdb sports_teams npm install To migrate the database into the project, run:\nknex migrate:latest We need to fill our data base with data in order to have a proper test. Run the command below to add data:\nknex seed:run Sports Teams API endpoints Our API has 8 endpoints. Below is a description of what each one does.\nGET - Read data from the database (resource)\nAll Teams\n/api/teams By Team\n/api/teams/:id By Sport League - SportLeagues include: MLB, NBA, NFL, NHL\n/api/teams/league/:sportLeague By State - States are case agnostic.\n/api/state/:stateName By State and Sport League\n/api/state/:stateName/:sportLeague PUT - modifying a record based on it\u0026rsquo;s index (id) number.\n/api/teams/:id POST\n/api/teams DELETE\n/api/teams/:id You can also view these instruction in the ReadMe.md file in project in your local environment or the ReadMe section of the Postman repository.\nMaking requests to the Sports Team API GET Requests Since we have loaded the project on our local environment, our URI requests will be the localhost URL, followed by the endpoint we want to interact with. To start, we\u0026rsquo;ll make several GET requests to the our API.\nTo run the program, in your terminal, type:\nnpm start This will make our program accessible through the URL http://localhost:3000, followed by our endpoint. For example, if we want to see all the teams in our database, we make a GET request to\nhttp://localhost:3000/api/teams In the Postman App, create a GET request by selecting GET from the request builder dropdown, add http://localhost:3000/api/teams in the input box and press SEND.\nThis request will return all the teams in our database. Along the top of the response header, you will see that we are returned a status code 200 OK, which signifies that our request was received and responded to successfully.\nNext, we can see in the response body the data returned from our request. This response is in JSON format, which is simply an array of objects, where the data within the [] is the full response and the data within each {} is an individual record, or in our case, a single team.\n{ \u0026#34;id\u0026#34;: 1, \u0026#34;team_name\u0026#34;: \u0026#34;Celtics\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Boston\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;Massachusetts\u0026#34;, \u0026#34;venue\u0026#34;: \u0026#34;TD Garden\u0026#34;, \u0026#34;sport_league\u0026#34;: \u0026#34;NBA\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2018-09-21T19:24:16.960Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2018-09-21T19:24:16.960Z\u0026#34; } Each record contains information about a teams id, team name, city, state, venue, and sport league.\nLet\u0026rsquo;s try another GET endpoint and see how the data differs. Let\u0026rsquo;s look at teams based on sport league. We will use NBA:\nhttps://localhost:3000/api/teams/:NBA Notice all the teams returned have the sport_league attribute equal to NBA. Practice making GET requests using the other GET endpoints.\nPOST Requests POST requests are used to add data to the API resource. Let\u0026rsquo;s say we want to add a new team to the database. We start by accessing the endpoint for POST-ing and adding data:\n/api/teams While this looks very similar to the same endpoint used for our GET request, because we will be doing a POST request to the endpoint, there are different expectations for communication.\nAs a POST request is meant to add data to a resource, it is expected that additional information will be sent with the request. In the request builder header, click the Body tab to reveal options for building a POST request and the Request Body Edit, which is where you will add the data object that will be sent to the API.\nThere are 4 areas with different controls for sending data:\n Form-data - similates filling aform on a website and submitting it x-www-form-urlencoded - uses the same encoding as the one used in URL parameters. raw - can contain any format. Postman does not modify this strings in the editor for this format. binary - allows you to send things which you can not enter in Postman, for example, image, audio, or video files, including text files.  We will use the raw option to send our data over to the API. In addition, we can choose the format:\nWe will choose JSON as our format. In the body editor, enter the following object:\n{ \u0026#34;team_name\u0026#34;: \u0026#34;Michigan Wolverines\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Ann Arbor\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;Michigan\u0026#34;, \u0026#34;venue\u0026#34;: \u0026#34;The Big House\u0026#34;, \u0026#34;sport_league\u0026#34;: \u0026#34;NCAA\u0026#34; } This object contains the data that we want to add to the database. It is mapped to the attributes of the database that is associated to the API. Your request should look like the following:\nClick SEND to make the request. In the response body, you see the data the API returned and the status code of the communication. Our data was added to the database with as index number 134 (your index number may be different).\nA quick GET request using the new ID number will confirm our data was added.\nPUT Requests PUT requests allow us to replace the infomation in a data object. The endpoint we use is:\n/api/team/:id where :id is the index number of the object you want to update. Let\u0026rsquo;s update the record we just created. We will change the team name to \u0026ldquo;The University of Michigan Wolverines\u0026rdquo;.\nTIP: PUT and PATCH methods are similar, but not the same and should not be used interchangeably. See Additional Resources for more information.\nPUT requests are set up similarly to POST requests. Select PUT from the request dropdown and enter the following endpoint:\nhttp://localhost:3000/api/teams/134 Again, your index number may be different, so enter the one that corresponds to your data object. In the request body editor, we enter the attributes of our object, including the one we want to change, team_name. Press Send.\nAs you can see, the return status is 201 Created and the object now reflects our modification:\nDELETE Requests DELETE requests are made using the index number of the object that will be deleted:\n/api/teams/:id Again, looks similar to the PUT, however we are using the DELETE request and no other data about the object is needed.\nUse the request header dropdown to select DELETE, and add the endpoint with the index number to be deleted. The request body will remain empty.\nHit SEND. Although there is no message that confirms the action from the API, you can tell by the status code that the request is successful, and a quick GET using the index number will not return any data.\nCollections Building Collections allow us to group our requests together, rather than running them one at a time. One of the benefits of using collections is being able to test your endpoints all at once and getting the results of those tests bundled.\n Collections offer many useful tools for testing your API. Check out the Additional Resources to learn more about using test scripts and code generators with Postman Collections.\n Creating a collection for the Sports Teams API Instead of doing each request separately, we can roll them all up into a collection and run the requests all together, cutting testing time down considerably.\nTo begin let\u0026rsquo;s create a new collection. There are two ways to create a collection. At the top left corner of Postman workspace, click the New button to reveal a dropdown.\nSelect Collection. You can also click the Collections tab along the left side of the page to add a new collection.\nA dialog box will appear. This box allow you to customize your collection by adding a Description, Authorization, Pre-requests Scripts, Tests, Variables. We will be running simple tests. At this time, we are only going to add a description.\nOnce you\u0026rsquo;ve added a name and description for your collection, click the Create button at the bottom of the dialog box.\nYou\u0026rsquo;ll notice in the left panel of the screen, your new collection is listed. We can now add request. Let\u0026rsquo;s start with a GET method. We begin as usual by selection GET from dropdown in the request builder menu. In the URI box, input http://localhost:3000/api/teams. This time, click the arrow next to the SEND button and Save As:\nIn the dialog box, add a name and description of the request.\nClick Save to Sports Teams API and you\u0026rsquo;ll see the request has been added to the collection.\nFilling the Collection Let\u0026rsquo;s add the other requests to the collection using the same process. Make sure to name the requests so that it is clear what the request should return:\nGET requests:\n /api/teams/10 /api/teams/league/NBA /api/state/Texas /api/state/Texas/MLS  We will also add a PUT and a POST request.\nPUT request:\n /api/teams/10  request body should include:    { \u0026#34;id\u0026#34;: 10, \u0026#34;team_name\u0026#34;: \u0026#34;Robins\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Milwaukee\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;Wisconsin\u0026#34;, \u0026#34;venue\u0026#34;: \u0026#34;Bradley Center\u0026#34;, \u0026#34;sport_league\u0026#34;: \u0026#34;NBA\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2018-09-21T19:24:16.960Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2018-09-21T19:24:16.960Z\u0026#34; }  On January 22, 1968, the NBA awarded a franchise to Milwaukee Professional Sports and Services, Inc. (Milwaukee Pro), a group headed by Wesley Pavalon and Marvin Fishman; A fan contest was held to name the new team, with over 40,000 fans participating. While the most-voted fan entry was the Robins, named for Wisconsin\u0026rsquo;s state bird, the contest judges went with the second-most popular choice, the Bucks, which was a reference to Wisconsin\u0026rsquo;s official wild animal, the white-tailed deer. (Source: Wikipedia)\n POST request:\n /api/teams/  request body should include:    { \u0026#34;team_name\u0026#34;: \u0026#34;Michigan State Spartans\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;East Lansing\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;Michigan\u0026#34;, \u0026#34;venue\u0026#34;: \u0026#34;Spartan Stadium\u0026#34;, \u0026#34;sport_league\u0026#34;: \u0026#34;NCAA\u0026#34; } DELETE request:\n /api/teams/10  Running the Collection Once you\u0026rsquo;ve added all the requests, click the arrow next to the collection name and choose the Run option. A dialog box will appear. Click the Run Sports Teams\u0026hellip; button.\nA new Postman collection window will open and display the results of the run. If all went well, we should have success status codes returned to us.\nYou can also export the results in JSON format. Here\u0026rsquo;s an example of the postman_test_run.jsonexported run result.\nLab Practice with Postman\nAdditional Resources  JSON.org Reading JSON files Medium: PUT vs. PATCH Postman Collections  "
},
{
	"uri": "/python/web-framework/",
	"title": "Web Frameworks",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/react/pillars/testing/common/",
	"title": "Common Lessons",
	"tags": [],
	"description": "",
	"content": "Lessons "
},
{
	"uri": "/path-to-production/cicd/",
	"title": "Configure CI/CD",
	"tags": [],
	"description": "",
	"content": "Objectives Once complete, you should be able to:\n Have the knowledge to go and create a pipeline using Concourse Understand the steps required to have an approved pipeline to push to production.  Index "
},
{
	"uri": "/golang/databases/database-intro/",
	"title": "Databases and Golang",
	"tags": [],
	"description": "",
	"content": "We are going to go over how to interact with multiple databases in Go. Throughout the lessons, we are going to use a Hexagonal architecture. This architecture limits the need to rewrite logic when an external resource has changed.\nThe Go community prefers the Hex architecture over an ORM(Object-relational mapper) because:\n The built-in database/sql package already gives a lot of functionality without adding complexity ORMs tend to mask what is going on just enough to let bad things slip through the cracks. Why learn something new when we already know SQL?  Hex Architecture isolates the logic from the inputs and outputs, decreasing the possibility of code duplication or bugs in the code.\nIn order to do this, an abstract layer is needed to be created between the data and any inputs asking for the data.\nThe following lessons build a Tool Rental system that will allow users to create, read, update and delete tools in the database.\nModel Create a directory called tool_rental and initialize it as a go module.\nWithin tool_rental create the following file structure:\ntool_rental ├── go.mod └── tools └── model.go 1 directory, 2 files Inside the tools/model.go file, we will create a struct that will correctly describe the Tool model.\npackage tools import \u0026#34;time\u0026#34; type Tool struct { ID string `json:\u0026#34;id\u0026#34; db:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34; db:\u0026#34;name\u0026#34;` Description string `json:\u0026#34;description\u0026#34; db:\u0026#34;description\u0026#34;` Price float64 `json:\u0026#34;price\u0026#34; db:\u0026#34;price\u0026#34;` Quantity int `json:\u0026#34;quantity\u0026#34; db:\u0026#34;quantity\u0026#34;` Created time.Time `json:\u0026#34;created\u0026#34; db:\u0026#34;created\u0026#34;` Updated time.Time `json:\u0026#34;updated\u0026#34; db:\u0026#34;updated\u0026#34;` }  The db struct tags match the column names in the database. The json struct tags are to match if the data from the database has already been marshaled.  Abstracting Actions Now we need to add the necessary actions to interact with the model, independent of a specific data store. This defines what kind of interactions to make, just not the how.\nAn interface will provide the abstraction layers we need since we don\u0026rsquo;t know the how of these methods.\nAdd a new file called data_store.go to hold this interface. The file structure should now look like the following:\ntool_rental ├── go.mod └── tools ├── data_store.go └── model.go 1 directory, 3 files Inside tools/data_store.go, add a ToolDataStore interface that defines the necessary methods to interact with data:\npackage tools type ToolDataStore interface { Create(tool *Tool) error FindByID(id string) (*Tool, error) FindAll() ([]*Tool, error) Update(tool *Tool) error Delete(id string) error } Business Logic Now we need to write the business logic that is a concrete implementation of how a service will interact with the ToolDataStore methods.\nAdd a new file called service.go to hold this struct. The file structure should now look like the following:\ntool_rental ├── go.mod └── tools ├── data_store.go ├── model.go └── service.go 1 directory, 4 files In tools/service.go, add a toolService struct with a required field of type ToolDataStore.\npackage tools import ( \u0026#34;time\u0026#34; \u0026#34;github.com/google/uuid\u0026#34; ) type ToolService interface { //1 \tCreateTool(tool *Tool) error FindToolByID(id string) (*Tool, error) FindAllTools() ([]*Tool, error) UpdateTool(tool *Tool) error DeleteTool(id string) error } type toolService struct { //2 \tdataStore ToolDataStore } func NewToolService(dataStore ToolDataStore) ToolService { //3 \treturn \u0026amp;toolService{ dataStore, } } Implement the methods of toolService to help with the interaction of the repository.\nfunc (s *toolService) CreateTool(tool *Tool) error { tool.ID = uuid.New().String()\t//1 \ttool.Created = time.Now()\t//2 \ttool.Updated = time.Now()\t//2  return s.dataStore.Create(tool) } func (s *toolService) FindToolByID(id string) (*Tool, error) { tool, err := s.dataStore.FindByID(id) return tool, err } func (s *toolService) FindAllTools() ([]*Tool, error) { tools, err := s.dataStore.FindAll() return tools, err } func (s *toolService) UpdateTool(tool *Tool) error { tool.Updated = time.Now() return s.dataStore.Update(tool) } func (s *toolService) DeleteTool(id string) error { return s.dataStore.Delete(id) }  Forces the use of \u0026quot;github.com/google/uuid\u0026quot; for the id Forces the use of the system date for created and updated fields  Implementation ToolService creates a layer that does not care what kind of data store you are using, just as long as you have a struct that satisfies the ToolDataStore interface.\nTo see what this implementation would look like, create a main.go at the root level:\n. ├── go.mod ├── main.go └── tools ├── data_store.go ├── model.go └── service.go 1 directory, 5 files Within main.go, we will set up how to interact with a data store:\npackage main import ( \u0026#34;github.homedepot.com/yourldap/tool_rental/tools\u0026#34; //replace yourldap with your ldap ) func main() { var toolDataStore tools.ToolDataStore // Connection to a data store will go here  toolDataStore = //Data store constructor implemented here  toolService := tools.NewToolService(toolDataStore) }  This will not compile until we have a data store to work with.\n Conclusion While we have not interacted with any database, we have set it up to where we could interact with a data store of any kind and not have to update any of the above code! Now that we have the business logic and the abstract layer of the repository, we can start our implementation.\n"
},
{
	"uri": "/software-eng-essentials/git-pillars/git-log/",
	"title": "Git Information with git log",
	"tags": [],
	"description": "",
	"content": "Git Logs git log provides the ability to see the history of commits on a repo. There are several flags to provide that will organize or filter the history.\nSeeing everything git log --graph --oneline will show all commits, with branches and messages.\nExample Output:\n* a8f97fb (HEAD -\u0026gt; 111-git-pillar-slides, origin/96-postgres, addressing-issues, 96-postgres) Fixes #96 * b0ce308 (origin/master, origin/HEAD, master) Reordering curriculum based on workshop finds (#108) * b9158a0 Adds content to getting started to Looker (#107) * e39c6ac Adds section on lookml structure breakdown (#106) * 907a754 Removes redundant link to external training (#105) * a64f2fb Convert to md (#104) * d491406 Comments out Notifier (#103) * 3e71fdf Looker lessons (#102) * d9e2ae5 Removes sql-joins in favor of sql-intro and sql-joins-multi (#101) * eaabbe3 184 joining tables (#100) |\\  | * 060466b adds additional code fences to lesson | * 8b1a4b8 adds code fences to lesson | * ccc15fe add front matter to the remote postgres setup instructionsmarkdown file. |/ * 5ae02c4 Merge pull request #93 from OM-Curriculum/remote-postgres-setup Seeing where the tips of branches are updated git reflog will show where branches:\n are updated switched from one branch to another occurred were reset  This is extremely powerful if a reset undid wanted changes.    Example Output:\na8f97fb (HEAD -\u0026gt; addressing-issues, origin/96-postgres, 96-postgres, 111-git-pillar-slides) HEAD@{3}: commit: Fixes #96 b0ce308 (origin/master, origin/HEAD, master) HEAD@{4}: checkout: moving from master to addressing-issues b0ce308 (origin/master, origin/HEAD, master) HEAD@{5}: checkout: moving from adv-lookml to master f196a24 (adv-lookml) HEAD@{6}: commit (amend): Adds queries from original training dced2c0 HEAD@{7}: commit: Adds queries from original training b0ce308 (origin/master, origin/HEAD, master) HEAD@{8}: checkout: moving from master to adv-lookml b0ce308 (origin/master, origin/HEAD, master) HEAD@{9}: clone: from https://github.com/one-thd/om_curriculum_software-eng-essentials.git git log -g gives a reflog with more detail.\nSee only commits made before or after a specific date git log --since=2021/08/18 will only show commits created after that date and git log --before=2021/08/18 will only show commits created before that date.\nSummary and more resources The possibilities of types and modification to information available on logs are nearly endless for more examples click the documentation here\n"
},
{
	"uri": "/golang/foundations/hello-go/",
	"title": "Hello Go",
	"tags": [],
	"description": "",
	"content": "What Is Go?    Go (aka Golang) was created by Google in 2007 and released to the public in 2009. Go is a modern, general purpose, open source language that was influenced by C. Go was designed to be simple, easy to read, developer friendly, and performant.  Language Goals  Simplicity - Go’s main motivation is to “keep things as simple as possible”. Fast - make coding fast and efficient via:  Fast compilation Fully compiled Strongly typed Concurrent by default Garbage collected  simpler     Developer Friendly - Go has built in:  linting rules testing framework documentation generator    Is Go an OOP or FP Language?  Go is neither an OOP nor an FP language Instead, Go is a primarily a procedural language (the same as C) Go does provide support for:  user defined types via structs polymorphism via interfaces and methods   Go also has rich support for concurrency and distributed computing  Aspects of Go Go:\n is statically typed compiles to native binary uses static linking (no DLLs) - resulting in better portability but larger executables provides garbage collection  Go Compared to Java    Feature Java Go     Architecture Compiled to Bytecode and then interpreted Compiled to binary   Paradigm OOP Procedural   Type System Statically typed Statically typed   Memory Mgmt Garbage Collection Garbage Collection   Maturity More mature language (released in 1995) Newer language (released in 2011)   Readability Medium High   Error Handling try / catch Errors as values with defer, panic, recover   Concurrency Runnables, critical sections, mutexes Goroutines and channels   Reflection Supported Supported    Applications Written in Go  Docker Kubernetes Fedora Core OS Hugo Web Site Generator Terraform Infrastructure Management  "
},
{
	"uri": "/custom-workshops/frontend-at-thd/react-crash-course/intro/",
	"title": "Intro to Hooks",
	"tags": [],
	"description": "",
	"content": "Concepts  Introduce React hooks and how they simplify your React code Understand the advantages of using hooks over writing JavaScript class components  What Are Hooks Hooks were added to React in v16.8. Hooks allow you to use state and lifecycle methods in your React components without writing a JavaScript class! Thus hooks are a more direct way to use the React features you already know — such as state, lifecycle, context, and refs.\n TIP: Hooks don’t fundamentally change how React works, therefore your knowledge of components, props, and top-down data flow remains relevant.\n Why are they called Hooks? Hooks are a way for function based components to hook into the React framework so that the function component can have some context and still remain a JavaScript function.\nWhy Hooks  We want to avoid writing JavaScript classes, because JavaScript classes:  are verbose are not purely functional introduce the this context, which often leads to explicit binding (i.e. cb = this.cb.bind(this)) and other confusion   The syntax is much shorter and that means less surface area for bugs to hide. Reuse logic between components  Hooks provide an easy way to reuse logic between components   You can write your own custom hooks!!!  Custom hooks combine existing hooks into new patterns for reuse.   You can use 3rd party hooks!!!  Why reinvent the wheel?    Here is an excellent video on the history of React components and why Hooks were added to React. The video is 14 minutes long so we will watch the first 9 minutes 30 seconds.\nHere is a quote from the video:\nAsking Fundamental Questions\n The first thing you should do whenever you are about to learn something new is to ask yourself 2 questions:\n Why does this thing exist? What problems does this thing solve?  If you never develop a convincing answer for both of those questions, you will not have a solid enough foundation to build upon when you dive into the specifics.\n Why react hooks? video\nA Quick Look at the Hooks Basic Hooks Basic Hooks The basic hooks are easy to understand and are the most frequently used hooks.\nuseState Adds state to a functional component. Acts as a replacement for this.state and this.setState.\nconst [state, setState] = useState(initialStateValue) The initialStateValue can be any JavaScript value, such as a string, number, boolean, array, or object.\nuseEffect Adds side-effect code to a function component.\nuseEffect(() =\u0026gt; { /* side-effect code goes here */ /* optionally return a cleanup function */ }, /* optional array of triggers */ } useContext Accepts a context object (the value returned from React.createContext) and returns the current context value.\nconst context = useContext(Context) Advanced Hooks There are some advanced hooks that you should be aware of.\nuseReducer An alternative to useState that is sometimes useful when managing complex state transitions.\nconst [state, dispatch] = useReducer(reducer, initialArg, init) useRef Returns a mutable ref object whose .current property is initialized to the passed argument (initialValue). The returned object will persist for the full lifetime of the component. This is a nice replacement for instance variables in a JavaScript class (i.e. this.intervalRef).\nconst refContainer = useRef(initialValue); useMemo Returns a memoized value. A replacement for React\u0026rsquo;s PureComponent.\nconst memoizedValue = useMemo(() =\u0026gt; computeExpensiveValue(a, b), [a, b]) useCallback Returns a memoized callback.\nconst memoizedCallback = useCallback( () =\u0026gt; { doSomething(a, b); }, [a, b], ) useImperativeHandle Customizes the instance value that is exposed to parent components when using ref.\nuseImperativeHandle(ref, createHandle, [deps]) useLayoutEffect Identical to useEffect, but fires synchronously after all DOM mutations.\nuseLayoutEffect(() =\u0026gt; { /* side-effect code goes here */ /* optionally return a cleanup function */ }, /* optional array of triggers */ } useDebugValue Used to display a label for custom hooks in React DevTools.\nuseDebugValue(value) Rules of Hooks Hooks are JavaScript functions, but they impose two additional rules:\n Only call Hooks at the top level.   Don’t call Hooks inside loops, conditions, or nested functions. Your hooks should always run in the same order.  Only call Hooks from React function components.   Don’t call Hooks from regular JavaScript functions. There is just one other valid place to call hooks — your own custom Hooks, which we will learn about later.   React provides a linter plugin to enforce these rules automatically. These rules might seem limiting or confusing at first, but they are essential to making hooks work well.\n Conclusion React hooks are a great addition to the React library. They allow us to:\n always use JavaScript functions to define React components (even stateful components or components with lifecycle events) reuse logic between React components keep separate business logic concerns in separate hooks even when they occur in the same lifecycle event  "
},
{
	"uri": "/react/pillars/hooks/intro/",
	"title": "Intro to Hooks",
	"tags": [],
	"description": "",
	"content": "Concepts  Introduce React hooks and how they simplify your React code Understand the advantages of using hooks over writing JavaScript class components  What Are Hooks Hooks were added to React in v16.8. Hooks allow you to use state and lifecycle methods in your React components without writing a JavaScript class! Thus hooks are a more direct way to use the React features you already know — such as state, lifecycle, context, and refs.\n Hooks don’t fundamentally change how React works, therefore your knowledge of components, props, and top-down data flow remains relevant.\n Why are they called Hooks? Hooks are a way for function based components to hook into the React framework so that the function component can have some context and still remain a JavaScript function.\nWhy Hooks   We want to avoid writing JavaScript classes, because JavaScript classes:  are verbose are not purely functional introduce the this context, which often leads to explicit binding (i.e. cb = this.cb.bind(this)) and other confusion   The syntax is much shorter and that means less surface area for bugs to hide. Reuse logic between components  Hooks provide an easy way to reuse logic between components   You can write your own custom hooks!!!  Custom hooks combine existing hooks into new patterns for reuse.   You can use 3rd party hooks!!!  Why reinvent the wheel?    Here is an excellent video on the history of React components and why Hooks were added to React. The video is 14 minutes long so we will watch the first 9 minutes 30 seconds.\nHere is a quote from the video:\nAsking Fundamental Questions\n The first thing you should do whenever you are about to learn something new is to ask yourself 2 questions:\n Why does this thing exist? What problems does this thing solve?  If you never develop a convincing answer for both of those questions, you will not have a solid enough foundation to build upon when you dive into the specifics.\n Tyler McGinnis, Why React Hooks?   A Quick Look at the Hooks Basic Hooks The basic hooks are easy to understand and are the most frequently used hooks.\nuseState Adds state to a functional component. Acts as a replacement for this.state and this.setState.\nconst [state, setState] = useState(initialStateValue) The initialStateValue can be any JavaScript value, such as a string, number, boolean, array, or object.\nuseEffect Adds side-effect code to a function component.\nuseEffect(() =\u0026gt; { /* side-effect code goes here */ /* optionally return a cleanup function */ }, /* optional array of triggers */ } useContext Accepts a context object (the value returned from React.createContext) and returns the current context value.\nconst context = useContext(Context) Advanced Hooks There are some advanced hooks that you should be aware of.\nuseReducer An alternative to useState that is sometimes useful when managing complex state transitions.\nconst [state, dispatch] = useReducer(reducer, initialArg, init) useRef Returns a mutable ref object whose .current property is initialized to the passed argument (initialValue). The returned object will persist for the full lifetime of the component. This is a nice replacement for instance variables in a JavaScript class (i.e. this.intervalRef).\nconst refContainer = useRef(initialValue); useMemo Returns a memoized value. A replacement for React\u0026rsquo;s PureComponent.\nconst memoizedValue = useMemo(() =\u0026gt; computeExpensiveValue(a, b), [a, b]) useCallback Returns a memoized callback.\nconst memoizedCallback = useCallback( () =\u0026gt; { doSomething(a, b); }, [a, b], ) useImperativeHandle Customizes the instance value that is exposed to parent components when using ref.\nuseImperativeHandle(ref, createHandle, [deps]) useLayoutEffect Identical to useEffect, but fires synchronously after all DOM mutations.\nuseLayoutEffect(() =\u0026gt; { /* side-effect code goes here */ /* optionally return a cleanup function */ }, /* optional array of triggers */ } useDebugValue Used to display a label for custom hooks in React DevTools.\nuseDebugValue(value) Rules of Hooks Hooks are JavaScript functions, but they impose two additional rules:\n Only call Hooks at the top level.   Don’t call Hooks inside loops, conditions, or nested functions. Your hooks should always run in the same order.  Only call Hooks from React function components.   Don’t call Hooks from regular JavaScript functions. There is just one other valid place to call hooks — your own custom Hooks, which we will learn about later.   React provides a linter plugin to enforce these rules automatically. These rules might seem limiting or confusing at first, but they are essential to making hooks work well.\n Conclusion React hooks are a great addition to the React library. They allow us to:\n always use JavaScript functions to define React components (even stateful components or components with lifecycle events) reuse logic between React components keep separate business logic concerns in separate hooks even when they occur in the same lifecycle event  "
},
{
	"uri": "/javascript/nodejs/advanced/express-and-bookshelf/knex/",
	"title": "Intro to Knex",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Explain how Knex simplifies access to a relational database Explain migration scripts Explain seeding a database  Skills  Writing a knexfile that defines how knex connects to a database Create database migrations scripts Create seed files Use the Knex API to create SELECT, INSERT, UPDATE, and DELETE SQL statements.  What is Knex.js? Knex.js is primarily an API for building SQL statements (a query builder). It has support for many different relational databases, including PostgreSQL, MySQL, MariaDB, SQLite3, and Oracle.\nKnex also provides the following:\n a configuration file for defining database connections to various environments, such as development, test, and production. a strategy for defining and applying migration scripts a strategy for defining and running seeds scripts  Using Knex in a simple CLI Application   For the rest of this lesson, we will be learning Knex by building a simple CLI application that uses Knex to communicate with a PostgreSQL database.\n  To get started, let\u0026rsquo;s create a simple NodeJS command line app.\nmkdir knex-vet-clinic cd knex-vet-clinic npm init -y Edit the package.json file and add the following line:\n\u0026#34;type\u0026#34;: \u0026#34;module\u0026#34;, Now let\u0026rsquo;s add knex as a dependency for our application:\nnpm install knex  NOTE: Knex.js supports many different databases, so be sure to install the database client for the database your application will be using. Since we will be using PostgreSQL, the command is:\n npm install pg  NOTE: pg is the PostgreSQL driver for NodeJS\n Creating the knexfile.js Config File Knex uses a configuration file to define database connection information for various environments, such as development, test, and production. The default name for this file is knexfile.js. Let\u0026rsquo;s create that file and update it to specify our database settings.\ntouch knexfile.js knexfile.js:\nconst knexConfig = { development: { client: \u0026#39;pg\u0026#39;, connection: { host: \u0026#39;127.0.0.1\u0026#39;, // user: \u0026#34;your_database_user\u0026#34;,  // password: \u0026#34;your_database_password\u0026#34;,  database : \u0026#39;knex_vet_clinic\u0026#39;, charset : \u0026#39;utf8\u0026#39; }, pool: { min: 2, max: 10, }, migrations: { tableName: \u0026#39;knex_migrations\u0026#39;, }, seeds: { directory: \u0026#39;./seeds/dev\u0026#39;, }, }, } export default knexConfig Observations:\n The above configuration sets up a single database for development. You can setup other databases for environments such as testingandproduction`. The client defines which driver to use to connect to the database. Here we use the pg driver for connecting to a PostgreSQL database. For this local database we will not need a user and password, but it depends on how you want to setup your database. The pool setting defines the size for the DB connection pool. The migrations and seeds settings configure how the migrations and seeds will work. Review the knexfile.js Environment Configuration info for more information.  Creating The Database Create the PostgreSQL database:\ncreatedb knex_vet_clinic Creating a Migration Script We can\u0026rsquo;t do anything interesting with our database until we create some tables. Knex provides a strategy for writing migration scripts that can make any schema changes we need.\nMigrations allow us to define sets of schema changes. This makes updating our database quite simple. Every migration will update our schema in some way, such as:\n Adding tables Alter tables Drop tables Add, rename, or modify columns Add indexes  To create a migration script simply run npx knex migrate:make \u0026lt;script_name\u0026gt;.\nFor our application, we will need a migration script to create our first table, the owners table:\nnpx knex migrate:make create_owners Using environment: development Using environment: development Using environment: development Created Migration: /Users/mah3093/knex-vet-clinic/migrations/20220312015039_create_owners.js This command created a migrations folder where all future migration files will go and created a migrations script for defining our first migration.\nNote that every migration script will have a filename with a timestamp prefix specifying the time when the migration script was created.\nSo, a migration is made called create_owners created at noon on January 1, 2021 the file created would be named: 20210101120000_create_owners.js. The timestamp follows the pattern YYYYMMDDHHMMSS.\n QUESTION: Why the timestamp? The timestamp enables Knex to run the migration scripts in the proper order, from oldest to newest.\n Edit the YYYYMMDDHHMMSS_create_owners.js file and replace its contents with the following:\nYYYYMMDDHHMMSS_create_owners.js:\nexport async function up(knex) { const exists = await knex.schema.hasTable(\u0026#39;owners\u0026#39;) if (!exists) { return knex.schema.createTable(\u0026#39;owners\u0026#39;, table =\u0026gt; { table.increments(\u0026#39;id\u0026#39;).primary() table.string(\u0026#39;first_name\u0026#39;).notNullable() table.string(\u0026#39;last_name\u0026#39;).notNullable() table.string(\u0026#39;phone\u0026#39;) table.timestamps(true, true) }) } } export function down(knex) { return knex.schema.dropTableIfExists(\u0026#39;owners\u0026#39;) } Observations:\n The up function tells Knex what to do for the migration. Here we are creating a table called owners with 5 columns. We are also specifying that we want Knex to add timestamp columns for tracking when each row was created and when it was last updated. Knex will automatically manage the values in these columns for us. The down function tells Knex what to do if we want to \u0026ldquo;back out\u0026rdquo; the migration. Here we simply remove the table.  Running the Migrations To run all migrations that have not yet been applied to the database, simply run:\nnpx knex migrate:latest We can create a script for this and put it inside our package.json file.\nLet\u0026rsquo;s define several scripts that will aid in the development of our application:\n\u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;NODE_ENV=development node index.js\u0026#34;, \u0026#34;db:create\u0026#34;: \u0026#34;createdb knex_vet_clinic\u0026#34;, \u0026#34;db:drop\u0026#34;: \u0026#34;dropdb knex_vet_clinic\u0026#34;, \u0026#34;db:reset\u0026#34;: \u0026#34;npm run db:drop \u0026amp;\u0026amp; npm run db:create\u0026#34;, \u0026#34;db:migrate\u0026#34;: \u0026#34;knex migrate:latest --env development\u0026#34;, \u0026#34;db:seed\u0026#34;: \u0026#34;knex seed:run --env development\u0026#34; }, Now to run the migrations, simply type:\nnpm run db:migrate \u0026gt; knex-vet-clinic@1.0.0 db:migrate \u0026gt; knex migrate:latest --env development Using environment: development Batch 1 run: 1 migrations All migration files (1 for now) have been executed and the database schema is up to date.\nNow let\u0026rsquo;s use the PostgreSQL CLI to inspect the newly created owners table:\npsql -d knex_vet_clinic psql (14.2) Type \u0026#34;help\u0026#34; for help. knex_vet_clinic=# \\dt List of relations Schema | Name | Type | Owner --------+----------------------+-------+--------- public | knex_migrations | table | mah3093 public | knex_migrations_lock | table | mah3093 public | owners | table | mah3093 (3 rows) knex_vet_clinic=# \\d owners Table \u0026#34;public.owners\u0026#34; Column | Type | Collation | Nullable | Default ------------+--------------------------+-----------+----------+------------------------------------ id | integer | | not null | nextval(\u0026#39;owners_id_seq\u0026#39;::regclass) first_name | character varying(255) | | not null | last_name | character varying(255) | | not null | phone | character varying(255) | | | created_at | timestamp with time zone | | not null | CURRENT_TIMESTAMP updated_at | timestamp with time zone | | not null | CURRENT_TIMESTAMP Indexes: \u0026#34;owners_pkey\u0026#34; PRIMARY KEY, btree (id) knex_vet_clinic=# \\q Creating the Pets Migration Script Now let\u0026rsquo;s add another table, this one named pets that has the following columns:\n id (integer) - the primary key that increments automatically name (string) - the name of the pet species (string) - the species of the pet (cat, dog, etc.) age (integer) - the age of the pet in years  npx knex migrate:make create_pets YYYYMMDDHHMMSS_create_pets.js:\nexport async function up(knex) { const exists = await knex.schema.hasTable(\u0026#39;pets\u0026#39;) if (!exists) { return knex.schema.createTable(\u0026#39;pets\u0026#39;, table =\u0026gt; { table.increments(\u0026#39;id\u0026#39;).primary() table.string(\u0026#39;name\u0026#39;) table.string(\u0026#39;species\u0026#39;) table.integer(\u0026#39;age\u0026#39;) table.timestamps(true, true) }) } } export function down(knex) { return knex.schema.dropTableIfExists(\u0026#39;pets\u0026#39;) } Now run the migration with:\nnpm run db:migrate \u0026gt; knex-vet-clinic@1.0.0 db:migrate \u0026gt; knex migrate:latest --env development Using environment: development Batch 2 run: 1 migrations Updating Schemas Let\u0026rsquo;s create a migration that adds a new column.\nAdding a Migration to Add a Column to a Table We will create a migration script that adds the gender column to the pets table.\nnpx knex migrate:make add_gender_to_pets Add the following to the newly created file:\nexport function up(knex) { return knex.schema.table(\u0026#39;pets\u0026#39;, table =\u0026gt; { table.string(\u0026#39;gender\u0026#39;) }) } export function down(knex) { return knex.schema.table(\u0026#39;pets\u0026#39;, table =\u0026gt; { table.dropColumn(\u0026#39;gender\u0026#39;) }) } Run the migration with:\nnpm run db:migrate Use psql to verify the changes:\npsql -d knex_vet_clinic psql (14.2) Type \u0026#34;help\u0026#34; for help. knex_vet_clinic=# \\d pets Table \u0026#34;public.pets\u0026#34; Column | Type | Collation | Nullable | Default ------------+--------------------------+-----------+----------+------------------- name | character varying(255) | | | species | character varying(255) | | | age | integer | | | created_at | timestamp with time zone | | not null | CURRENT_TIMESTAMP updated_at | timestamp with time zone | | not null | CURRENT_TIMESTAMP gender | character varying(255) | | | knex_vet_clinic=# \\q Adding a Migration to Add a FK To add a foreign key in pets that creates a relationship to owners, run:\nnpx knex migrate:make add_pets_owner_fk Inside the newly created file, update the content to:\nexport function up(knex) { return knex.schema.table(\u0026#39;pets\u0026#39;, function(table) { table.integer(\u0026#39;owner_id\u0026#39;).references(\u0026#39;id\u0026#39;).inTable(\u0026#39;owners\u0026#39;) }) } export function down(knex) { return knex.schema.table(\u0026#39;pets\u0026#39;, function(table) { table.dropColumn(\u0026#39;owner_id\u0026#39;) }) } Run the migration with:\nnpm run db:migrate Use psql to verify the changes.\nSeeding the database We can use Knex to run our seeds files.\nThe Owners Seed File First let\u0026rsquo;s create a seeds file for the owners table:\nnpx knex seed:make owners The file was created in the seeds/dev directory (as specified in our knexfile.js). Let\u0026rsquo;s edit that file and change the contents to the following:\n/** * @param { import(\u0026#34;knex\u0026#34;).Knex } knex * @returns { Promise\u0026lt;void\u0026gt; } */ export async function seed(knex) { // Delete ALL existing entries  await knex(\u0026#39;owners\u0026#39;).del() // Insert seed entries  await knex(\u0026#39;owners\u0026#39;).insert([ { id: 1, first_name: \u0026#39;Homer\u0026#39;, last_name: \u0026#39;Depot\u0026#39;, phone: \u0026#39;1234567890\u0026#39; }, { id: 2, first_name: \u0026#39;Charlie\u0026#39;, last_name: \u0026#39;Brown\u0026#39;, phone: \u0026#39;9876543210\u0026#39; }, { id: 3, first_name: \u0026#39;Susan\u0026#39;, last_name: \u0026#39;Smith\u0026#39;, phone: \u0026#39;4561237890\u0026#39; }, ]) // update the PK sequence to max(id) + 1  await knex.raw(` SELECT setval(\u0026#39;owners_id_seq\u0026#39;, coalesce(max(id), 0) + 1, false) FROM owners `) } To run the seeds file:\nnpm run db:seed Use psql to verify the seed data:\npsql -d knex_vet_clinic psql (14.2) Type \u0026#34;help\u0026#34; for help. knex_vet_clinic=# select * from owners; id | first_name | last_name | phone | created_at | updated_at ----+------------+-----------+------------+-------------------------------+------------------------------- 1 | Homer | Depot | 1234567890 | 2022-03-11 22:58:43.128113-05 | 2022-03-11 22:58:43.128113-05 2 | Charlie | Brown | 9876543210 | 2022-03-11 22:58:43.128113-05 | 2022-03-11 22:58:43.128113-05 3 | Susan | Smith | 4561237890 | 2022-03-11 22:58:43.128113-05 | 2022-03-11 22:58:43.128113-05 (3 rows) knex_vet_clinic=# \\q The Pets Seed File To seed the pets table, do:\nnpx knex seed:make pets Update the content of the newly created file to:\n/** * @param { import(\u0026#34;knex\u0026#34;).Knex } knex * @returns { Promise\u0026lt;void\u0026gt; } */ export async function seed(knex) { // Delete ALL existing entries  await knex(\u0026#39;pets\u0026#39;).del() // Insert seed entries  await knex(\u0026#39;pets\u0026#39;).insert([ { id: 1, name: \u0026#39;Felix\u0026#39;, species: \u0026#39;cat\u0026#39;, age: 12, gender: \u0026#39;male\u0026#39;, owner_id: 1 }, { id: 2, name: \u0026#39;Tweetie\u0026#39;, species: \u0026#39;bird\u0026#39;, age: 3, gender: \u0026#39;female\u0026#39;, owner_id: 1 }, { id: 3, name: \u0026#39;Snoopy\u0026#39;, species: \u0026#39;dog\u0026#39;, age: 7, gender: \u0026#39;male\u0026#39;, owner_id: 2 }, ]) // update the PK sequence to max(id) + 1  await knex.raw(` SELECT setval(\u0026#39;pets_id_seq\u0026#39;, coalesce(max(id), 0) + 1, false) FROM pets `) } Now check out all of the seeds data with:\npsql -d knex_vet_clinic psql (14.2) Type \u0026#34;help\u0026#34; for help. knex_vet_clinic=# select * from owners; id | first_name | last_name | phone | created_at | updated_at ----+------------+-----------+------------+-------------------------------+------------------------------- 1 | Homer | Depot | 1234567890 | 2022-03-11 23:08:20.344739-05 | 2022-03-11 23:08:20.344739-05 2 | Charlie | Brown | 9876543210 | 2022-03-11 23:08:20.344739-05 | 2022-03-11 23:08:20.344739-05 3 | Susan | Smith | 4561237890 | 2022-03-11 23:08:20.344739-05 | 2022-03-11 23:08:20.344739-05 (3 rows) knex_vet_clinic=# select * from pets; id | name | species | age | created_at | updated_at | gender | owner_id ----+---------+---------+-----+-------------------------------+-------------------------------+--------+---------- 1 | Felix | cat | 12 | 2022-03-11 23:08:20.353141-05 | 2022-03-11 23:08:20.353141-05 | male | 1 2 | Tweetie | bird | 3 | 2022-03-11 23:08:20.353141-05 | 2022-03-11 23:08:20.353141-05 | female | 1 3 | Snoopy | dog | 7 | 2022-03-11 23:08:20.353141-05 | 2022-03-11 23:08:20.353141-05 | male | 2 (3 rows) knex_vet_clinic=# select first_name, last_name, name, species, age from owners inner join pets on pets.owner_id = owners.id; first_name | last_name | name | species | age ------------+-----------+---------+---------+----- Homer | Depot | Felix | cat | 12 Homer | Depot | Tweetie | bird | 3 Charlie | Brown | Snoopy | dog | 7 (3 rows) knex_vet_clinic=# \\q Now that we have created the database, used migration scripts to define the schema, and added seed data, it\u0026rsquo;s finally time to use Knex in our application to do our DML / CRUD statements.\nGetting a Configured Knex Object Before we can use Knex for CRUD operations, we need to import and configure the Knex object.\nFirst, create the main script file for the CLI application:\ntouch index.js Next add the following lines to index.js to import the Knex library and create the knex object:\nimport knexLib from \u0026#39;knex\u0026#39; import knexConfigs from \u0026#39;./knexfile.js\u0026#39; const knexEnvConfig = knexConfigs[process.env.NODE_ENV] const knex = knexLib(knexEnvConfig) There is a lot going on here, so let\u0026rsquo;s break it down. This code:\n Line 1 imports the knex library (using the default export) and names it knexLib Line 2 imports the knex configuration file and names it knexConfigs Line 4 uses the process.env.NODE_ENV environment variable to select which configuration to use Line 5 passes the knexEnvConfig object to knexLib to create the knex object that will be used as the SQL builder.  Setting the NODE_ENV Environment Variable There are 2 ways to set the value for NODE_ENV.\n Each time the application is run:  NODE_ENV=development node index.js # will receive the value from the shell for this specific execution One time for the shell  export NODE_ENV=development # sets the value for the life of the current shell process node index.js # will inherit the value from the shell Using Knex for CRUD Operations The primary purpose of using Knex is to simplify how we can write the DML (data manipulation language) SQL statements that perform the CRUD operations on our data.\nNext we will look at how to use Knex to do each of the following:\n Read all of the rows from a table. Read all of the rows from 2 tables using a join. Read some rows from a table using a where clause. Insert a row Update a row Delete a row  Reading Data Let\u0026rsquo;s start by reading and printing all of the owners. Add the following to index.js:\nasync function printOwners() { const owners = await knex.select(\u0026#39;*\u0026#39;).from(\u0026#39;owners\u0026#39;) console.log(owners) } console.log(\u0026#39;=== Owners ===\u0026#39;) await printOwners() knex.destroy() // closes the DB connections Lab - Printing All Pets Write a function called printPets() that prints all of the pets.\nPrinting Pets with a Where Clause What if we only want to print the pets with an age \u0026gt; 5?\nasync function printPetsWithMinAge(minAge) { const pets = await knex .select(\u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;, \u0026#39;gender\u0026#39;) .from(\u0026#39;pets\u0026#39;) .where(\u0026#39;age\u0026#39;, \u0026#39;\u0026gt;\u0026#39;, minAge) console.log(pets) } console.log(\u0026#39;=== All Pets age 5 or greater ===\u0026#39;) await printPetsWithMinAge(5) Lab - Print Only the Pets with the Specified Gender Write a function called printPetsWithGender(gender) that prints only the pets with the specified gender.\n HINT: You can pass an object to .where() that matches the values you want from the database, for example: .where({ gender }).\n Call your function with await printPetsWithGender('female')\nReading Data with Joins Let\u0026rsquo;s write a function that prints all of the pets and their owners using a join:\nasync function printPetsAndOwners() { const petsAndOwners = await knex(\u0026#39;pets\u0026#39;) .join(\u0026#39;owners\u0026#39;, \u0026#39;pets.owner_id\u0026#39;, \u0026#39;owners.id\u0026#39;) .select( \u0026#39;pets.name\u0026#39;, \u0026#39;pets.species\u0026#39;, \u0026#39;pets.gender\u0026#39;, \u0026#39;pets.age\u0026#39;, \u0026#39;owners.first_name\u0026#39;, \u0026#39;owners.last_name\u0026#39; ) console.log(petsAndOwners) } console.log(\u0026#39;=== Pets and Owners ===\u0026#39;) await printPetsAndOwners()  NOTE: There are several ways to structure a join in Knex.\n Creating Data Let\u0026rsquo;s see how knex creates new rows.\nTo add a new pet, add the following to index.js:\nasync function createNewPet(petData) { try { const [saved] = await knex(\u0026#39;pets\u0026#39;).insert(petData).returning(\u0026#39;*\u0026#39;) console.log(saved) } catch (err) { console.error(err) } } console.log(\u0026#39;=== Creating a new Pet ===\u0026#39;) await createNewPet({ name: \u0026#39;Biscuit\u0026#39;, species: \u0026#39;dog\u0026#39;, age: 10, gender: \u0026#39;male\u0026#39;, owner_id: 1 }) Observations:\n By adding .returning('*') we can get the fully populated pet that was saved to the database. Knex returns an array when doing insert statements (because knex supports inserting more than one row). Here we use array destructuring to unpack the created pet from the array. We wrap the code in a try / catch block to handle any errors reported from knex.  Updating Data The following code shows how to update a pet.\nasync function updatePet(id, petData) { try { const [saved] = await knex(\u0026#39;pets\u0026#39;).where({ id }).update(petData).returning(\u0026#39;*\u0026#39;) return saved } catch (err) { console.error(err) } } console.log(\u0026#39;=== Updating a new Pet ===\u0026#39;) console.log(await updatePet(2, { age: 4 })) Observations:\n By adding .returning('*') we can get the fully populated pet that was saved to the database. Knex returns an array when doing update statements (because knex supports updating more than one row). Here we use array destructuring to unpack the updated pet from the array. Knex .update merges any data we provide with the data in the database (thus doing an incremental update). We wrap the code in a try / catch block to handle any errors reported from knex.  Deleting Data The following code shows how to update a pet.\nasync function deletePet(id) { try { await knex(\u0026#39;pets\u0026#39;).where({ id }).delete() } catch (err) { console.error(err) } } console.log(\u0026#39;=== Deleting a new Pet ===\u0026#39;) await deletePet(4) Observations:\n We wrap the code in a try / catch block to handle any errors reported from knex. This code will not report a 404 error if the pet with the specified id does not exist. Extra logic would be required to do that check.  Summary  Knex.js is a NodeJS module for connecting server-side JavaScript programs to a relational DB. Knex provides several features:  a knexfile.js for configuring your project\u0026rsquo;s database connections for several environments (dev, test, prod, etc.). a strategy for defining and managing migration scripts that define and update the database schema. a strategy for defining and running seed scripts. a SQL builder that converts the Knex SQL API to the proper SQL for your database (PostgreSQL, Oracle, MySQL, etc.).   Knex provides a CLI (command line interface) application for creating a knexfile, creating and running migration scripts, and creating and running seeds files.  Additional Resources  Knex Quick Reference The Official Knex.js Website Knex Cheat Sheet  "
},
{
	"uri": "/javascript/nodejs/advanced/postman/postman-lab/",
	"title": "Labs for Postman",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Use Postman to test the endpoints of the Store Data API  Loading the Store Data API Clone the following repository from Github:\nhttps://github.com/one-thd/om_labs_JavaScript-store-data-api.git The root URI of our call will be http://localhost:3000/.\n  Click here to follow the set-up instructions found in the ReadMe.md.\n  In Postman, test the endpoints of the Store Data API\n Send a GET request to see:  All stores A single store by ID All Stores in a specific state   Send a PUT request and change the attributes of a single record Send a POST request to add a new record to the table Send a DELETE request to delete a record from the table.    Set up a Collection to perform all the function at once.\n  "
},
{
	"uri": "/javascript/nodejs/getting-started/node-core-modules/",
	"title": "Node Core Modules",
	"tags": [],
	"description": "",
	"content": "Working with Node Core Modules "
},
{
	"uri": "/javascript/pillars/restful-api-express-node/node-refresher/",
	"title": "Node Refresher",
	"tags": [],
	"description": "",
	"content": "1. Learning Objectives 1.1. Concepts   Understand that Node.js is basically just a runtime environment that can run JavaScript\n  Compare synchronous and asynchronous code execution\n  Explain the advantages of asynchronous I/O\n    1.2. Skills   Refresh on how to use HomeBrew or the Node.JS to install node.\n  Write a simple JavaScript program and execute it with Node.js\n      2. What is Node.JS? \n   Node is really just a way to write server side JavaScript that leverages the Google V8 JS engine. There are now several packages written to help us in the Node Environment.\n  Node was originally written by Ryan Dahl in 2009 address the need to handle concurrent connections without getting blocked.\n     3. How do we get started with Node.js? 3.1. Before we can use node we have to install it.   Before we install of course we should check to see if we already have Node\n   typing\u0026#8230;\u0026#8203;\n node --version   in the terminal should result in something like\u0026#8230;\u0026#8203;\n \n     The above output tells us that we do have node installed and that we have version 12.8.1.       If you don\u0026#8217;t have Node installed yet\u0026#8230;\u0026#8203;\n  Node can be installed with brew\u0026#8230;\u0026#8203;\n      brew install node       Using brew install will give you the beta version of Node but usually won\u0026#8217;t cause problems       Or we can go straight to the source\u0026#8230;\u0026#8203;\n   Click the link to go to Nodejs.org\n Follow the helpful directions to get node going on your machine.\n   Once we\u0026#8217;ve gone through brew or the download just run the node --version in your terminal again to make sure the install went smoothly.\n    3.2. Once Node is installed we can actually run our javascript in the terminal. By creating a directory for practice with the file .node-demo.js\u0026#8230;\u0026#8203;\n node-demo.js const secretToLife = (x, y) =\u0026gt; { return x * y; } console.log(\"How many roads must a man walk down?\", secretToLife(6,7));   We can actually run our javascript by typing the following in our terminal\u0026#8230;\u0026#8203;\n node node-demo.js   And find out the answer to the ultimate question in the universe\n \n  3.3. Cool! But what else can Node do?   So glad you asked!\n   We can make a server!\n app.js const http = require('http'); // The 'require' method give access to node modules const port = 3030; // This just gives us local 3030 as our port value const server = http.createServer((req, res) =\u0026gt; { // Here we create our server function res.statusCode = 200; // This sets a status code for 200 (success!) res.setHeader('Content-type', \"text/plain\"); // Creates a header with our content type res.end(\" Hello World! \"); // Responds with putting our text on local 3000 }); server.listen(port, () =\u0026gt; // listens on our port console.log(`server running at port ${port}`) // logs a message if we are successful );     And what else else can node do? Frankly it can mess us up\u0026#8230;\u0026#8203;\n   node-demo.js const ultimateQuestion = (message) =\u0026gt; { setTimeout(() =\u0026gt; { console.log(message); }, 1000) }; const secretToLife = (x, y) =\u0026gt; { console.log(x * y); }; ultimateQuestion('How many roads must a man walk down?'); secretToLife(6, 7);       What will be the output of the above code? If you know that the code will return our output in the same order as was seen in \"Hitchikers Guide\" you\u0026#8217;re right but also a nerd.       Why does this happen?\n   \n The image above gives us a hint as the the reason we get our output in the opposite order we call our functions. Node uses the event loop to be able to handle I/O in a non-blocking function. This is helpful in many ways and by handling the loop with callbacks we can avoid strange behavior.\n A slight refactor of our code\u0026#8230;\u0026#8203;\n node-demo.js const ultimateQuestion = (message, callback) =\u0026gt; { setTimeout(() =\u0026gt; { console.log(message); callback(6, 7); // call the sectretToLife function only after we get our message }, 1000, ) }; const secretToLife = (x, y) =\u0026gt; { console.log(x * y); }; ultimateQuestion('How many roads must a man walk down?', secretToLife);   Now we get the correct order of question then answer.\n     This will become more important with more complex Node.JS API creation, as not all data will come back at the same rate. We can use callbacks or some of the more modern aspects of JavaScript like Promises or Await to make sure that functions will wait their turn when appropriate.      3.4. Quick Practice Hands on Node.JS Server\n RESTful API leson\n    "
},
{
	"uri": "/python/nonrelational-db/nosql-vs-sql/",
	"title": "NoSQL vs SQL Databases",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Understanding the key differences between relational and nonrelational databases Understanding the use cases for relational vs. nonrelational databases  Relational vs. Nonrelational Databases Relational and nonrelational databases both have the goal of storing data, but do so in very different ways. One of the key ways these databases are different is the way data is structured, or in the case of nonrelational databases, unstructured.\nRelational databases (RDBMS) are structured. Data objects are stored in tables that use Stuctured Query Language (SQL) to define and manipulate the schema and the data stored in the database. While SQL is the standard for RDBMS, there are several flavors of SQL. However, they all support the same major commands - SELECT, UPDATE, DELETE, INSERT and WHERE - in a similar manner to interact with the data.\nThe tables are made up of columns (fields) and rows (individual record).\nTables are stand-alone, with relationships defined via primary keys and foreign keys.\nNonrelational databases are unstructured, or rather they have a more flexible structure that can be defined based on the needs of the business. There are 4 main types of NoSQL databases:\n Columnar Database - which can be row oriented or column oriented  example of row-oriented\ntools,\u0026#34;hammer\u0026#34;,\u0026#34;screws\u0026#34;,\u0026#34;nails\u0026#34; price,13.99,18.99,14.50 example of column-oriented\ntools,price \u0026#34;hammer\u0026#34;,13.99 \u0026#34;screws\u0026#34;,18.99 \u0026#34;nails\u0026#34;,14.50  Document Database - which has a JSON like format, consisting of documents  { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;5ece65929b750325c5849877\u0026#34;), \u0026#34;name\u0026#34; : \u0026#34;shop apron\u0026#34;, \u0026#34;vendor\u0026#34;: \u0026#34;name\u0026#34;: \u0026#34;ShopStuff\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;123 Main St.\u0026#34; \u0026#34;contact\u0026#34;: \u0026#34;Joan Taylor\u0026#34; \u0026#34;description\u0026#34; : \u0026#34;keeps shop messes off clothes\u0026#34; } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;5ece65939b750325c5849878\u0026#34;), \u0026#34;name\u0026#34; : \u0026#34;mop\u0026#34;, \u0026#34;description\u0026#34; : \u0026#34;picks up the messiest spills\u0026#34; } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;5ece65939b750325c5849879\u0026#34;), \u0026#34;name\u0026#34; : \u0026#34;laminate flooring\u0026#34;, \u0026#34;description\u0026#34; : \u0026#34;durable and easy to maintain\u0026#34; } The fields in each document can be different, which is part of the flexibility of NoSQL.\n Graph Database - which uses a graph model where data is stored as properties of the nodes and relationships are represented by the edges between those nodes.  Source\n Key Value Database - which saves data as a group of key-value pairs, made up of two data items that are linked. The link between the items is a “key” (such as “id”), which acts as an identifier for an item within the data and the “value” that is the data (or content) that has been identified, in the form of a stringified array or hash.  127.0.0.1:6379\u0026gt; hgetall \u0026#34;products\u0026#34; 1) \u0026#34;50903141-28f7-4520-afba-e086ad14e221\u0026#34; 2) \u0026#34;{\\\u0026#34;id\\\u0026#34;:\\\u0026#34;50903141-28f7-4520-afba-e086ad14e221\\\u0026#34;,\\\u0026#34;name\\\u0026#34;:\\\u0026#34;Lawn Mower\\\u0026#34;,\\\u0026#34;description\\\u0026#34;:\\\u0026#34;Powerful mower that mulches. Clean fuel.\\\u0026#34;,\\\u0026#34;vendor\\\u0026#34;:\\\u0026#34;Green Mower Company\\\u0026#34;,\\\u0026#34;price\\\u0026#34;:1500,\\\u0026#34;created\\\u0026#34;:\\\u0026#34;0001-01-01T00:00:00Z\\\u0026#34;,\\\u0026#34;updated\\\u0026#34;:\\\u0026#34;2019-11-18T11:40:49.063798-05:00\\\u0026#34;}\u0026#34; 3) \u0026#34;1fe2d9c4-107f-4617-8898-8ef9bbc68fd2\u0026#34; 4) \u0026#34;{\\\u0026#34;id\\\u0026#34;:\\\u0026#34;1fe2d9c4-107f-4617-8898-8ef9bbc68fd2\\\u0026#34;,\\\u0026#34;name\\\u0026#34;:\\\u0026#34;Kitchen Smoker\\\u0026#34;,\\\u0026#34;description\\\u0026#34;:\\\u0026#34;Indoor Meat Smoker.\\\u0026#34;,\\\u0026#34;vendor\\\u0026#34;:\\\u0026#34;Smoke Bros\\\u0026#34;,\\\u0026#34;price\\\u0026#34;:100,\\\u0026#34;created\\\u0026#34;:\\\u0026#34;2019-11-18T10:58:55.169652-05:00\\\u0026#34;,\\\u0026#34;updated\\\u0026#34;:\\\u0026#34;2019-11-18T10:58:38.169652-05:00\\\u0026#34;}\u0026#34; 5) \u0026#34;da93749f-4b3c-4fb6-9804-517c1ce108b4\u0026#34; 6) \u0026#34;{\\\u0026#34;id\\\u0026#34;:\\\u0026#34;da93749f-4b3c-4fb6-9804-517c1ce108b4\\\u0026#34;,\\\u0026#34;name\\\u0026#34;:\\\u0026#34;Real Hay Broom\\\u0026#34;,\\\u0026#34;description\\\u0026#34;:\\\u0026#34;Broom made with authentic hay bristles.\\\u0026#34;,\\\u0026#34;vendor\\\u0026#34;:\\\u0026#34;Natural Clean\\\u0026#34;,\\\u0026#34;price\\\u0026#34;:40,\\\u0026#34;created\\\u0026#34;:\\\u0026#34;2019-11-18T10:59:15.169652-05:00\\\u0026#34;,\\\u0026#34;updated\\\u0026#34;:\\\u0026#34;2019-11-18T10:58:38.169652-05:00\\\u0026#34;}\u0026#34; Use cases for Relational vs. Nonrelational databases There are advantages and disadvantages to both types of databases.\nSome advantages of Relational Databases:\n Supports a very powerful query language that is standardized across many RDBMS systems It has a fixed, reliable schema Follows ACID (Atomicity, Consistency, Isolation, and Durability) to insure data integrity Handles complex queries well  Some advantages of Nonrelational Databases:\n Flexible schema, data doesn\u0026rsquo;t have to be structured in any particular way Faster, since NoSQL supports a denormalized data model, allowing for better performance Easy to store all different types of data together without the need to define the data type beforehand Easier to control cost if your data needs to scale up, down, or out, depending on the business needs  Some considerations:\nIf your data set:\n is reliably structured requires the use of complex queries requires complex transactions needs to be reliably consistent and follow ACID  A RDBMS system, offering reliability and predictability, will work best.\nIf your data set:\n is large and/or has no defined structure is not required to be 100% consistent immediately needs to scale up, out, or down often need the abiility to change your schema without creating a huge impact or downtime  NoSQL and it\u0026rsquo;s flexibiliy will work best.\nSummary Choosing the best database system will largely depend on the problem that is being solved, and finding the right balance between flexibility, reliablity, and cost.\n"
},
{
	"uri": "/react/pillars/",
	"title": "Pillars",
	"tags": [],
	"description": "",
	"content": "Welcome to React Pillars! "
},
{
	"uri": "/javascript/nodejs/advanced/postman/",
	"title": "Postman",
	"tags": [],
	"description": "",
	"content": "Advanced NodeJS "
},
{
	"uri": "/software-eng-essentials/fundamentals-of-regex/javascript/",
	"title": "Regex in JavaScript",
	"tags": [],
	"description": "",
	"content": "During this course, feel free to use the console of a browser, jsfiddle, codepen, repl.it or a JS file in your favorite text editor.\nRegex methods in context of JavaScript In JavaScript, regular expressions are objects. We can use regex with exec and test methods. We can also use them on string methods like match, replace, search and split.\nWhich comes first? The chicken or the egg?\nWe\u0026rsquo;re going to cover the above mentioned exec and test methods, as well as the string methods before we get into the basics of regex patterns.\nEXEC Execute searches for a match in a string and will provide the portion of the string that matches, if any, followed by the index, the original string, and groups if parens are used in the regex OR null if none are found.\nMatch digits that are not followed by a period\n/\\d+(?!\\.)/.exec(\u0026#34;3.141\u0026#34;) =\u0026gt; \u0026#34;141\u0026#34;, index: 2, input: \u0026#34;3.141\u0026#34;, groups: undefined] Exercise\nUse the exec method and the regular expression, /RY\\d{3}/ (Has \u0026ldquo;RY\u0026rdquo; followed by 3 digits), to get the product id from the following string:\n\u0026#34;The product ID for the RYOBI Weed Wacker is RY234.\u0026#34; TEST Test is a method that tests for a match on a string and returns a boolean.\nMatches the word \u0026ldquo;home\u0026rdquo;, a space, followed by the word \u0026ldquo;depot\u0026rdquo;\n/home\\sdepot/.test(\u0026#34;home depot\u0026#34;) =\u0026gt; true Exercise\nUse the test method and the following regular expression to test:\n your home depot email address an invalid email address  var re = /^(([^\u0026lt;\u0026gt;()\\[\\]\\\\.,;:\\s@\u0026#34;]+(\\.[^\u0026lt;\u0026gt;()\\[\\]\\\\.,;:\\s@\u0026#34;]+)*)|(\u0026#34;.+\u0026#34;))@((\\[[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\])|(([a-zA-Z\\-0-9]+\\.)+[a-zA-Z]{2,}))$/; MATCH Match is similar to exec, /regex/.exec() returns only the first match found, while \u0026ldquo;string\u0026rdquo;.match() returns all of them if you use the g flag in the regex. If your regex is global, and you are capturing, then you must use exec. \u0026hellip; (match will behave in a manner of giving the full match followed by captures, only when the regex is not global).\n(\u0026#34;me me me\u0026#34;).match(/me/) =\u0026gt; [ \u0026#39;me\u0026#39;, index: 0, input: \u0026#39;me me me\u0026#39;, groups: undefined ] /me/.exec(\u0026#34;me me me\u0026#34;) =\u0026gt; [ \u0026#39;me\u0026#39;, index: 0, input: \u0026#39;me me me\u0026#39;, groups: undefined ] (\u0026#34;me me me\u0026#34;).match(/me/g) =\u0026gt; [ \u0026#39;me\u0026#39;, \u0026#39;me\u0026#39;, \u0026#39;me\u0026#39; ] Exercise\nIterate over the following array of strings to find the products that are on sale. Create a new array of strings called onSale. Specifically look for the word \u0026ldquo;discount\u0026rdquo;.\nconst marketingStrings = [ \u0026#39;Treat yourself to a Vibrant Home Garden\u0026#39;, \u0026#39;Terracota pots are dicounted by 5%\u0026#39;, \u0026#39;Use our soil and mulch calculator to know how much you need\u0026#39;, \u0026#39;Do it yourself, see how\u0026#39;, \u0026#39;No one has a better selection of indoor and outdoor plants and planters. \u0026#39; + \u0026#39;Get crafty with easy-to-care succulents or brighten up your life with healthy \u0026#39; + \u0026#39;and colorful perennial and annual flowers. All discounted by 10%.\u0026#39; ]; REPLACE The Replace method searches for a match and replaces with a given replacement string.\nTo remove html tags, do \u0026lt; followed by at least one character that is NOT \u0026gt;, followed by a \u0026gt;, with i and g flags.\n i is case insensitve, and g is global.\n \u0026#34;\u0026lt;h2\u0026gt;MY Header\u0026lt;/h2\u0026gt;\u0026#34;.replace(/(\u0026lt;([^\u0026gt;]+)\u0026gt;)/ig, \u0026#34;\u0026#34;); =\u0026gt; \u0026#39;MY Header\u0026#39; Exercise\nCreate a string variable set to a paragraph of Lorem Ipsum. Remove the paragraph tags from your string.\nSEARCH The Search method tests for a match in a string. It returns the index of the match, or -1 if the search fails.\nvar orangeLife = \u0026#34;Living the orange life.\u0026#34;; var isOrange = orangeLife.search(/orange/); console.log(isOrange); =\u0026gt; 11 var isBlue = orangeLife.search(/blue/); console.log(isBlue); =\u0026gt; -1 Exercise\nDiscover if the word \u0026ldquo;succulents\u0026rdquo; exits in any of the strings in the following array.\nconst marketingStrings = [ \u0026#39;Treat yourself to a Vibrant Home Garden\u0026#39;, \u0026#39;Terracota pots are dicounted by 5%\u0026#39;, \u0026#39;Use our soil and mulch calculator to know how much you need\u0026#39;, \u0026#39;Do it yourself, see how\u0026#39;, \u0026#39;No one has a better selection of indoor and outdoor plants and planters. \u0026#39; + \u0026#39;Get crafty with easy-to-care succulents or brighten up your life with healthy \u0026#39; + \u0026#39;and colorful perennial and annual flowers. All discounted by 10%.\u0026#39; ]; SPLIT The split method uses regular expressions to break a string into an array of substrings.\nvar mySuperLongString = \u0026#34;This, is it! This, is amazing. We\u0026#39;ve made it, ya\u0026#39;ll. This.\u0026#34;; var myarr = mySuperLongString.split(/this/i); console.log(myarr) =\u0026gt; [ \u0026#39;\u0026#39;, \u0026#39;, is it! \u0026#39;, \u0026#39;, is amazing. We\\\u0026#39;ve made it, ya\\\u0026#39;ll. \u0026#39;, \u0026#39;.\u0026#39; ] Exercise\nFind the word that occurs the most in the following paragraph.\nHINT: Split the paragraph into an array of string, and use new RegExp method, with the match method to get a count.\nvar replace = \u0026#34;regex\u0026#34;; var re = new RegExp(replace,\u0026#34;g\u0026#34;); let count = incomingString.match(re).length; var fromTheStart = \u0026#34;BUILT FROM ALL THE RIGHT MATERIALS \u0026#34; + \u0026#34;When The Home Depot was founded in 1978, Bernie Marcus and Arthur Blank had no \u0026#34; + \u0026#34;idea how revolutionary this new “hardware store” would be for home improvement \u0026#34; + \u0026#34;and the retail industry. \u0026#34; + \u0026#34;Today, we’re proud to be the world’s largest home improvement retailer. \u0026#34; + \u0026#34;In more than 2,200 stores across North America, we aspire to excel in service – \u0026#34; + \u0026#34;to our customers, associates, communities and shareholders. That’s what leadership \u0026#34; + \u0026#34;means to us. That\u0026#39;s The Home Depot difference.\u0026#34;; Basics of Regex Patterns Anchors    ^ $       Example Description     ^Home The line starts with Home.   veterans.$ Ends with \u0026lsquo;veterans\u0026rsquo;.   ^Home Depot supports its veterans.$ This is the exact line.   paint Matches any line with the word paint in it.    Prints out the first line\nvar oneHomeDepot = \u0026#34;The front door of our store is no longer at the front door of our stores. It\u0026#39;s in the customer\u0026#39;s pocket. It\u0026#39;s on the job site. It\u0026#39;s in their home. Developing the One Home Depot experience by bringing the physical and digital worlds together, with ability to handle the scale of Home Depot, required us to complete a re-platform of our website. This re-platform gives us the ability to create differentiated experiences for the customers going forward.\u0026#34;; console.log((/^The\\sfront\\sdoor/).test(oneHomeDepot)); =\u0026gt; true (yes, it starts with \u0026#34;The front door\u0026#34;, otherwise it would return -1.) Exercise\nCreate a string variable set to: Today, The Home Depot is the world’s largest home improvement retailer with nearly 400,000 orange-blooded associates and more than 2,200 stores in the U.S., Canada and Mexico.\nWrite an expression that will match to the end of the variable you just created, using the test method.\nQuantifiers    * + ? {} ()    For the following, we\u0026rsquo;re going to use possible serial numbers to express the quantity of c\u0026rsquo;s we want to match on. The ex: provides serials numbers that would match.\n   Pattern Description Examples     ABc* Has AB and followed by 0 or any number of cs 0123AB45, 0123ABc45, 0123ABcc45   ABc+ Has AB and followed by 1 or more cs 0123ABc45 , 0123ABcc45 , 0123ABccc456   ABc? Has AB and followed by 0 or 1 cs 0123ABc45 , 0123AB45   ABc{3} Has AB and followed by 3 cs 0123ABccc56;   ABc{4,} Has AB and followed by 4 or more cs 0123ABcccc456 , 0123ABccccc456   ABc{2,5} Has AB and followed by 2 up to 5 cs 0123ABcc456 , 0123ABccccc456   A(bc)* Has A followed by zero or more of the sequence bc 0123A456 , 0123Abcbcbc456   A(bc){4,6} Has e followed by 4, or 5 bc sequences 0123Abcbcbcbc456 , 0123Abcbcbcbcbc456    Prints out just the hardware using a known pattern of ending with at least 2 P\u0026rsquo;s.\nvar depotProducts = { \u0026#34;G6780123PPP\u0026#34;: \u0026#34;Smart Door Locks\u0026#34;, \u0026#34;G7750123PPQ\u0026#34;: \u0026#34;Deadbolts\u0026#34;, \u0026#34;04660123ZZ1\u0026#34;: \u0026#34;Encore Azalea\u0026#34;, \u0026#34;04660123ZZ2\u0026#34;: \u0026#34;Jubilation Gardenia\u0026#34;, \u0026#34;E4560123ZZZ\u0026#34;: \u0026#34;Truely Tulips\u0026#34; }; function getHardwareProducts(allProds){ let retArr = []; for(key in allProds){ if(/P{2,}/.test(key)) retArr.push(allProds[key]); } return retArr; } console.log(getHardwareProducts(depotProducts)); =\u0026gt; [ \u0026#39;Smart Door Locks\u0026#39;, \u0026#39;Deadbolts\u0026#39; ] Exercise\nUse the above json object and pull out the names of products that are garden products. Garden products are known to have at least two \u0026lsquo;Z\u0026rsquo;s.\nSpecial JS case for ? If the ? is immediately following any of the quantifiers *, +, ? or {}, it makes the quantifier non-greedy. (Matching as many characters as possible). For example, applying /\\d+/ which means one or more digits. For example, in 123abc, it matches 123. But if you applied /\\d+?/ to that same string, it only matches the 1.\nvar string = \u0026#34;123abc\u0026#34;; console.log(string.match(/\\d+/)); =\u0026gt; [ \u0026#39;123\u0026#39;, index: 0, input: \u0026#39;123abc\u0026#39;, groups: undefined ] console.log(string.match(/\\d+?/)); =\u0026gt; [ \u0026#39;1\u0026#39;, index: 0, input: \u0026#39;123abc\u0026#39;, groups: undefined ] The question mark in JS can also mean non-capturing groups, which will be discussed in the grouping section.\nOR operator | \\| | [] | |:-:|:-:|\n   Pattern Description     A(b\\|c) Has A and followed by a b or a c.   e[bc] Has e and followed by a b or a c.    If we had an array of email address and wanted to print out just the ones that end in email or gmail, we could do the following:\nvar emails = [\u0026#34;test@email.com\u0026#34;, \u0026#34;fake@gmail.com\u0026#34;, \u0026#34;learning@bash.edu\u0026#34;, \u0026#34;fun@commandline.gov\u0026#34;]; emails.forEach(function(email){ if(/[eg]mail/.test(email)){ console.log(email); } }); Exercise\nUsing the above array of emails, print to the console only those that end in \u0026ldquo;.gov\u0026rdquo; OR \u0026ldquo;.edu\u0026rdquo;.\nCharacter Classes    \\d \\w \\s .       Pattern Description Examples     \\d Is a single digit. $ls \\| grep -E '/d' would list any file that starts with a number in your current directory.   \\w Is WORD character, i.e. alphanumeric or underscore $ls \\| grep -E '^\\w\\w\\w\\w-' would list files that start with four alpha characters, then a dash.   \\s Is a whitespace character, including tabs and line breaks ls \\| grep -E '\\w\\w\\s..\\d\\d' would list files that contains a letter, letter, a space, any character, any character, followed by two digits. Such as ec 1983.png   . Is ANY character As shown in the above example.    Inverse options\n/D gives the inverse option of /d, ex: /D matches to any one NON Digital character.\nExercise\nPrints out just the product name that starts with 5 letters.\nvar depotProducts = { \u0026#34;G6780123PPP\u0026#34;: \u0026#34;Smart Door Locks\u0026#34;, \u0026#34;G7750123PPQ\u0026#34;: \u0026#34;Deadbolts\u0026#34;, \u0026#34;04660123ZZ1\u0026#34;: \u0026#34;Encore Azalea\u0026#34;, \u0026#34;04660123ZZ2\u0026#34;: \u0026#34;Jubilation Gardenia\u0026#34;, \u0026#34;E4560123ZZZ\u0026#34;: \u0026#34;Truely Tulips\u0026#34; }; for(serial in depotProducts){ if(/^\\w{5}\\s/.test(depotProducts[serial])){ console.log(depotProducts[serial]); } } Exercise\nvar keys = [\u0026#34;abcdef\u0026#34;,\u0026#34;123456\u0026#34;,\u0026#34;abc123\u0026#34;];  Perform the following exercises:  Print to the screen only the keys that include 3 consecutive digits. hint: Use quantifiers. Print to the screen only the keys that have 3 consecutive non digit characters.    Bracket Expressions    []       Pattern Example     [emc] String can have either an \u0026lsquo;e\u0026rsquo;, \u0026rsquo;m\u0026rsquo;, or a \u0026lsquo;c\u0026rsquo;.   [a-m] String can have any letter a through m.   [a-fA-F0-9] String represents a hexadecimal number, case insensitive because we are allowing a-f lowercase, and upper.   [0-9]% String has a digit that is zero or higher, and not greater than 9, followed by a percent sign.   [^a-zA-Z] String that does NOT contain a letter a-z or A-Z. In this case the carrot is a negator.    Let\u0026rsquo;s say we had the following json object with wood types and their tensile strength,\nIn order to print out just the wood types that can handle at least 15k psi, one could do:\nvar tensilStrengths = { \u0026#34;Alder, Red\u0026#34;:\t9800, \u0026#34;Ash\u0026#34; : 15000, \u0026#34;Aspen\u0026#34; : 8400, \u0026#34;Basswood\u0026#34; :\t8700, \u0026#34;Beech\u0026#34; :\t14900, \u0026#34;Birch, Yellow\u0026#34; :\t16600, \u0026#34;Butternut\u0026#34; : 8100, \u0026#34;Cherry\u0026#34; : 12300, \u0026#34;Chestnut\u0026#34; :\t8600, \u0026#34;Elm\u0026#34; :\t11800, \u0026#34;Hickory\u0026#34; : 20200, \u0026#34;Maple, Hard\u0026#34; : 15800, \u0026#34;Maple, Soft\u0026#34; :\t13400, \u0026#34;Oak, Red\u0026#34; :\t14300, \u0026#34;Oak, White\u0026#34;:\t15200, \u0026#34;Poplar\u0026#34;:\t10100, \u0026#34;Sassafras\u0026#34;:\t9000, \u0026#34;Sweetgum\u0026#34;:\t12500, \u0026#34;Sycamore\u0026#34;:\t10000, \u0026#34;Walnut\u0026#34;:\t14600 }; for(lumber in tensilStrengths){ if(/1[5-9][0-9]{3}/.test(tensilStrengths[lumber])){ console.log(lumber + \u0026#39; - \u0026#39; + tensilStrengths[lumber]); } } Exercise\nPrint out the lines that have temperatures 95 degrees and higher using the below json object.\nvar cityTemps = { \u0026#34;Miami\u0026#34; : \u0026#34;100deg\u0026#34;, \u0026#34;Atlanta\u0026#34; : \u0026#34;95deg\u0026#34;, \u0026#34;Richmond\u0026#34; : \u0026#34;90deg\u0026#34; }; Flags var re = /pattern/flags;  g - Global search i - Case Insensitive m - Multiline search s - Allows . to match newline characters u - unicode; treat a pattern as a sequence of unicode code points y - Perform a \u0026ldquo;sticky\u0026rdquo; search that matches starting at the current position in the target string.  var aboutUs = \u0026#34;The home depot Inc. or home depot is an American home improvement supplies retailing company that sells tools, construction products, and services. The company is headquartered at the Atlanta Store Support Center in unincorporated Cobb County, Georgia.\u0026#34;; aboutUs = aboutUs.replace(/home\\sdepot/g, \u0026#34;Home Depot\u0026#34;); console.log(aboutUs); =\u0026gt; The Home Depot Inc. or Home Depot is an American home improvement supplies retailing company that sells tools, construction products, and services. The company is headquartered at the Atlanta Store Support Center in unincorporated Cobb County, Georgia. var aboutUs = \u0026#34;The home depot Inc. or home depot is an American home improvement supplies retailing company that sells tools, construction products, and services. The company is headquartered at the Atlanta Store Support Center in unincorporated Cobb County, Georgia.\u0026#34;; var re = /home/y; console.log(re.sticky); =\u0026gt; true re.lastindex = 4; console.log(\u0026#34;Has Home Depot at index 4?\u0026#34;, re.test(aboutUs)); =\u0026gt; Has Home Depot at index 4? true re.lastindex = 1; console.log(\u0026#34;Has Home Depot at index 1?\u0026#34;, re.test(aboutUs)); =\u0026gt; Has Home Depot at index 1? false Exercise\nUse the global flag to split the above sentences into an array of words.\nGrouping We can use parenthesis to group substrings, and refer to them later as $1 for the first group and $2 as the second group, and so on.\nvar re = /(\\w+)\\s(\\w+)/; var str = \u0026#39;John Smith\u0026#39;; var newstr = str.replace(re, \u0026#39;$2, $1\u0026#39;); console.log(newstr); =\u0026gt; \u0026#34;Smith, John\u0026#34; var re = /(\\w+)\\s(\\w+)/; var str = \u0026#39;John Smith\u0026#39;; var nameArr = re.exec(str); console.log(nameArr); =\u0026gt; [ \u0026#39;John Smith\u0026#39;, \u0026#39;John\u0026#39;, \u0026#39;Smith\u0026#39;, index: 0, input: \u0026#39;John Smith\u0026#39;, Exercise\nFill out the following JSON object with groupings pulled from the following phone number: 1 (800) 606-8619\nvar number = { countryCode : \u0026#39;\u0026#39;, areaCode : \u0026#39;\u0026#39;, prefix : \u0026#39;\u0026#39;, lineNumber : \u0026#39;\u0026#39; }; As mentioned before, using a question mark (?) in a grouping will make it a non-capturing group. This means it will match on the pattern in the group but will not remember it, and cannot be referred to later.\nvar string = \u0026#34;foozball\u0026#34;; console.log(string.replace(/foo{1,2}/, \u0026#34;XXX\u0026#34;)); =\u0026gt; XXXzball console.log(string.replace(/(?:foo){1,2}/, \u0026#34;X$1XX\u0026#34;)); =\u0026gt; X$1XXzball console.log(string.replace(/(foo){1,2}/, \u0026#34;X$1XX\u0026#34;)); =\u0026gt; XfooXXzball Look Ahead Looking ahead means match on this pattern if followed by a specific phrase. For example:\nAdd \u0026ldquo;Pepe\u0026rdquo; after Jose, but only if followed by Rodriguez.\nvar re = /(Jose)\\s(?=Rodriguez)/ var joseBlurb = \u0026#34;Jose Rodriguez is responsible for the sales and operations of The Home Depot Mexico’s 124 stores, online platforms and 15,500 associates. The Home Depot is Mexico’s largest home improvement retailer. \u0026#34; + \u0026#34;Jose Barra is senior vice president of Merchandising, Décor, at The Home Depot. He oversees the company’s strategy to provide customers with innovative and exclusive products across flooring, paint, kitchen, bath, appliances, décor, storage and organization. \u0026#34;; console.log(joseBlurb.replace(re, \u0026#39;$1 \u0026#34;Pepe\u0026#34; \u0026#39;)); =\u0026gt; Jose \u0026#34;Pepe\u0026#34; Rodriguez is responsible for the sales and operations of The Home Depot Mexico’s 124 stores, online platforms and 15,500 associates. The Home Depot is Mexico’s largest home improvement retailer. Jose Barra is senior vice president of Merchandising, Décor, at The Home Depot. He oversees the company’s strategy to provide customers with innovative and exclusive products across flooring, paint, kitchen, bath, appliances, décor, storage and organization. Exercise\nCreate a function called pluralize that will properly pluralize an incoming word.\nIf ends with y, replace y with \u0026ldquo;ies.\u0026rdquo; Anything else gets an \u0026ldquo;s\u0026rdquo;. Do a foreach on the following array of strings, sending each word to your function.\nvar singulars = [\u0026#34;bunny\u0026#34;, \u0026#34;rabbit\u0026#34;, \u0026#34;dog\u0026#34;, \u0026#34;cat\u0026#34;, \u0026#34;emu\u0026#34;, \u0026#34;giraffe\u0026#34;, \u0026#34;antelope\u0026#34;]; Negative Look Ahead Negative looking ahead means match on this pattern if NOT followed by a specific phrase. For example:\nCheck if number is NOT a decimal\nvar re = /\\d{1,2}(?!.)/; console.log(\u0026#34;3.14\u0026#34;.match(re)); =\u0026gt; [ \u0026#39;14\u0026#39;, index: 2, input: \u0026#39;3.14\u0026#39;, groups: undefined ] console.log(\u0026#34;3\u0026#34;.match(re)); =\u0026gt; [ \u0026#39;3\u0026#39;, index: 0, input: \u0026#39;3\u0026#39;, groups: undefined ] Look Behind Looking behind means match on this pattern if proceeded by a specific phrase. For example:\nvar re = /(?\u0026lt;=Jack)\\sSparrow/; if((re).test(\u0026#34;Jack Sparrow\u0026#34;)){ console.log(\u0026#34;Yes, its a pirate.\u0026#34;) } =\u0026gt; Yes, its a pirate. if(!(re).test(\u0026#34;Jim Sparrow\u0026#34;)){ console.log(\u0026#34;Must be Jack\u0026#39;s cousin, who\u0026#39;s a merchant.\u0026#34;) } =\u0026gt; Must be Jack\u0026#39;s cousin, who\u0026#39;s a merchant. Exercise\nIn the following string, add \u0026ldquo;Dr. \u0026quot; before \u0026ldquo;Drake Ramoray\u0026rdquo;, but not in front of \u0026ldquo;Matt Ramoray.\u0026quot;;\n\u0026#34;Matt LeBlanc played a fictional character Joey Tribbiani in the show friends, who played a character Drake Ramoray. Not to be confused as Matt Ramoray.\u0026#34; Negative Look Behind Negative looking behind means match on this pattern if NOT proceeded by a specific phrase. For example:\nIs NOT a negative number\nre = /(?\u0026lt;!-)\\d+/ console.log(re.test(\u0026#39;3\u0026#39;)); console.log(re.test(\u0026#39;-3\u0026#39;)); Exercise\nIterate through an array of numbers, adding dollar signs to a number string that doesn\u0026rsquo;t start with a dollar sign.\nvar prices = [\u0026#34;39.50\u0026#34;, \u0026#34;$75.25\u0026#34;, \u0026#34;102.03\u0026#34;]; Specific use cases in JavaScript Changing order in an input string // The name string contains multiple spaces and tabs, // and may have multiple spaces between first and last names. var names = \u0026#39;Craig Menear; Ann-Marie Campbell; Matt Carey; Ted Decker; Mark Holifield\u0026#39;; var output = [\u0026#39;---------- Original String\\n\u0026#39;, names + \u0026#39;\\n\u0026#39;]; // Prepare two regular expression patterns and array storage. // Split the string into array elements.  // pattern: possible white space then semicolon then possible white space var pattern = /\\s*;\\s*/; // Break the string into pieces separated by the pattern above and // store the pieces in an array called nameList var nameList = names.split(pattern); // new pattern: one or more characters then spaces then characters. // Use parentheses to \u0026#34;memorize\u0026#34; portions of the pattern. // The memorized portions are referred to later. pattern = /(\\w+)\\s+(\\w+)/; // Below is the new array for holding names being processed. var bySurnameList = []; // Display the name array and populate the new array // with comma-separated names, last first. // // The replace method removes anything matching the pattern // and replaces it with the memorized string—the second memorized portion // followed by a comma, a space and the first memorized portion. // // The variables $1 and $2 refer to the portions // memorized while matching the pattern.  output.push(\u0026#39;---------- After Split by Regular Expression\u0026#39;); var i, len; for (i = 0, len = nameList.length; i \u0026lt; len; i++) { output.push(nameList[i]); bySurnameList[i] = nameList[i].replace(pattern, \u0026#39;$2, $1\u0026#39;); } // Display the new array. output.push(\u0026#39;---------- Names Reversed\u0026#39;); for (i = 0, len = bySurnameList.length; i \u0026lt; len; i++) { output.push(bySurnameList[i]); } // Sort by last name, then display the sorted array. bySurnameList.sort(); output.push(\u0026#39;---------- Sorted\u0026#39;); for (i = 0, len = bySurnameList.length; i \u0026lt; len; i++) { output.push(bySurnameList[i]); } output.push(\u0026#39;---------- End\u0026#39;); console.log(output.join(\u0026#39;\\n\u0026#39;)); Exercise\nReorder the following products in alphabetical order based on the last word.\nvar products = \u0026#34;Ellen DeGeneres Brianna Chandelier, Ellen DeGeneres Apollo Sconce, Ellen DeGeneres Caroline Lamp\u0026#34;; Using special characters to verify input \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=ISO-8859-1\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Script-Type\u0026#34; content=\u0026#34;text/javascript\u0026#34;\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; var re = /(?:\\d{3}|\\(\\d{3}\\))([-\\/\\.])\\d{3}\\1\\d{4}/; function testInfo(phoneInput) { var OK = re.exec(phoneInput.value); if (!OK) window.alert(phoneInput.value + \u0026#39; isn\\\u0026#39;t a phone number with area code!\u0026#39;); else window.alert(\u0026#39;Thanks, your phone number is \u0026#39; + OK[0]); } \u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Enter your phone number (with area code) and then click \u0026#34;Check\u0026#34;. \u0026lt;br\u0026gt;The expected format is like ###-###-####.\u0026lt;/p\u0026gt; \u0026lt;form action=\u0026#34;#\u0026#34;\u0026gt; \u0026lt;input id=\u0026#34;phone\u0026#34;\u0026gt;\u0026lt;button onclick=\u0026#34;testInfo(document.getElementById(\u0026#39;phone\u0026#39;));\u0026#34;\u0026gt;Check\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Exercise\nCreate an input mask for a zip code. Feel free to use repl.it, codepen.io, jsfiddle, or your local.\nSearch in code with Visual Studio Code Exercise\nCreate a text file with the following text.\nCreate and estimate your perfect garage door installation with our online design tool,complete with special offer details.Choose from hundreds of garage styles including traditional,carriage house and contemporary. Hit Cmd + F, Click on the .* to enable regex search.\nEnter the following regex:\n[\\.,](?!\\s) Hit the arrow to the left of the input box, and enter the following into the Replace input\n$1 ($1, the first grouping followed by a space).\nSome Answers Split Exercise\nvar fromTheStart = \u0026#34;BUILT FROM ALL THE RIGHT MATERIALS \u0026#34; + \u0026#34;When The Home Depot was founded in 1978, Bernie Marcus and Arthur Blank had no \u0026#34; + \u0026#34;idea how revolutionary this new “hardware store” would be for home improvement \u0026#34; + \u0026#34;and the retail industry. \u0026#34; + \u0026#34;Today, we’re proud to be the world’s largest home improvement retailer. \u0026#34; + \u0026#34;In more than 2,200 stores across North America, we aspire to excel in service – \u0026#34; + \u0026#34;to our customers, associates, communities and shareholders. That’s what leadership \u0026#34; + \u0026#34;means to us. That\u0026#39;s The Home Depot difference.\u0026#34;; console.log(fromTheStart); function getHighestCount(incomingString){ var arrCounts = []; var words = incomingString.replace(\u0026#34;.\u0026#34;,\u0026#34;\u0026#34;).split(\u0026#34; \u0026#34;); var highestWord; var highestCount = 0; for(var i=0; i \u0026lt; words.length; i++){ var re = new RegExp(words[i],\u0026#34;g\u0026#34;); let count = incomingString.match(re).length; if(count \u0026gt; highestCount){ highestWord = words[i]; highestCount = count; } } return {\u0026#39;count\u0026#39; : highestCount, \u0026#39;word\u0026#39;: highestWord}; } var mostOccuring = getHighestCount(fromTheStart); console.log(mostOccuring); =\u0026gt; { count: 7, word: \u0026#39;to\u0026#39; } Grouping Exercise\nvar number = { countryCode : \u0026#39;\u0026#39;, areaCode : \u0026#39;\u0026#39;, prefix : \u0026#39;\u0026#39;, lineNumber : \u0026#39;\u0026#39; }; var formattedPhoneNumber = \u0026#34;1 (800) 606-8619\u0026#34;; numArr = /(\\d)\\s\\((\\d{3})\\)\\s(\\d{3})-(\\d{4})/.exec(formattedPhoneNumber); console.log(numArr); number.countryCode = numArr[1]; number.areaCode = numArr[2]; number.prefix = numArr[3]; number.lineNumber = numArr[4]; console.log(number); =\u0026gt; { countryCode: \u0026#39;1\u0026#39;, areaCode: \u0026#39;800\u0026#39;, prefix: \u0026#39;606\u0026#39;, lineNumber: \u0026#39;8619\u0026#39; } Resources  https://regexr.com/ https://www.regular-expressions.info/  "
},
{
	"uri": "/react/pillars/advanced-state-mgmt/syllabus/",
	"title": "Syllabus",
	"tags": [],
	"description": "",
	"content": "Advanced State Management in React\n Topics 1. Lessons 2. Labs \u0026amp; Exercises 3. Additional Resources   1. Lessons  A Review of setState: Component State with setState\n  Using React Hooks for Managing Local State:\n  useState - The useState Hook\n  useReducer - The useReducer Hook\n     Using the Context API for Sharing State: The Context API\n  Combining the Context API and React Hooks: Context API and Hooks\n  Redux:\n  Intro to Redux\n  React and Redux\n  Redux: Beyond the Basics\n            2. Labs \u0026amp; Exercises   link:https://github.com/one-thd/om_labs_react-context-lab1\n  LAB: Flexbox Cats\n         3. Additional Resources   CSS Complex Selector\n         "
},
{
	"uri": "/react/pillars/testing/react-testing-library/syllabus/",
	"title": "Syllabus",
	"tags": [],
	"description": "",
	"content": "Learn how to test React components with the React Testing Library\n Lessons Testing and Tools  Intro to Testing\n  Getting Started with Jest\n  Mocking External Dependencies\n        React Testing Library  Introduction to RTL\n  Getting Started with RTL\n  Testing Presentational Components\n  Testing Generic Components\n  Testing Forms\n  Testing Custom Hooks\n  Testing Routes\n        Resources   Introducing the React Testing Library\n  RTL FAQ\n  Write tests. Not too many. Mostly integration.\n  RTL Cheat Sheet\n  dom-testing-library\n          "
},
{
	"uri": "/react/pillars/testing/tdd/syllabus/",
	"title": "Syllabus",
	"tags": [],
	"description": "",
	"content": "Learn how to do test-driven development (TDD) of React components with Enzyme.\n Lessons  Intro to Testing\n  Intro to Test-Driven Development\n  Getting Started with Jest\n  Mocking External Dependencies\n  Getting Started with Enzyme\n         Gift List Lab  Set Up\n  Choose Your Adventure\n Adventure Option A\n  Adventure Option B\n     Testing Routing\n         "
},
{
	"uri": "/javascript/nodejs/getting-started/node-core-modules/path-module/",
	"title": "The Path Module",
	"tags": [],
	"description": "",
	"content": "Path module  The path module provides a way of working with directories and file paths.  Access the documentation for the path module here: https://nodejs.org/api/path.html\nExample 1\nconst path = require(\u0026#39;path\u0026#39;); const filename = path.basename(\u0026#39;/Users/myFolder/demo_path.js\u0026#39;); console.log(filename);  Example 2\nconst isItAbsolute = path.isAbsolute(\u0026#39;/Users/myFolder/demo_path.js\u0026#39;); const extensionName = path.extname(\u0026#39;/Users/myFolder/demo_path.js\u0026#39;); console.log(isItAbsolute); console.log(extensionName);  Example 3\n// root is ignored since dir was given. // you can specify an extenstion by using ext: and name of file by using name: // base will be ignored if you use ext and name. const format = path.format({ root: \u0026#39;/User\u0026#39;, dir: \u0026#39;/home/user\u0026#39;, base: \u0026#39;myFile.txt\u0026#39; }); console.log(\u0026#34;FORMATTED: \u0026#34; + format); // Parse thru a constructed path, will return an object const parse = path.parse(format); const stringedParse = JSON.stringify(parse); console.log(\u0026#34;PARSE returns objects: \u0026#34; + parse); console.log(\u0026#34;STRINGIFIED object: \u0026#34; + stringedParse);   åIMPORTANT: In the previous operating system exercise, where did we see a system file path in our output?\n Lab Practice with Path Module\n"
},
{
	"uri": "/software-eng-essentials/topic-cheatsheets/",
	"title": "Topic Specific Cheatsheets",
	"tags": [],
	"description": "",
	"content": "Welcome to Cheatsheets! "
},
{
	"uri": "/web-essentials/cheatsheets/",
	"title": "Topic Specific Cheatsheets",
	"tags": [],
	"description": "",
	"content": "Topic Specific Cheatsheets "
},
{
	"uri": "/python/bots/",
	"title": "Bots",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/path-to-production/change-management/",
	"title": "Change Management",
	"tags": [],
	"description": "",
	"content": "Objectives Index "
},
{
	"uri": "/javascript/nodejs/advanced/axios-and-fetch/",
	"title": "HTTP Requests",
	"tags": [],
	"description": "",
	"content": "Concepts  Sending HTTP Requests Handling HTTP Responses  Skills  Using the Fetch API for sending HTTP requests and handling HTTP responses Using the axios library for sending HTTP requests and handling HTTP responses Handling errors with either the Fetch API or axios  API Communications  Making external calls to other apps and services is very common  Each call has a request from your app and a response from the external service There are helpful tools to handle these requests and responses: axios and fetch api    Fetch  Fetch is \u0026ldquo;an easy, logical way to fetch resources asynchronously across the network.\u0026rdquo; All calls have the same basic make-up using the fetch() method  fetch(url, options)\nwhere:\n url: string, the endpoint to access options: object, check out the init object for a full list of options  { \u0026#39;method\u0026#39;: \u0026#39;GET\u0026#39;|\u0026#39;POST\u0026#39;|\u0026#39;PUT\u0026#39;|\u0026#39;DELETE\u0026#39;, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39; // add others as needed  }, \u0026#39;body\u0026#39;: // stringified data object  }  fetch() returns a promise that will resolve to a response object  response.status will give you the status code of the response response.json() will return a promise that will resolve to the json data returned by a successful call     NOTE: Fetch API was added in ES2015 and so is included natively in the browser.\nFor server side (NodeJS) development you will have to include node-fetch, although in future NodeJS versions fetch will be provided out-of-the-box.\n Axios  Axios \u0026ldquo;is a simple promise-based HTTP client that can run in the browser and nodejs with the same codebase\u0026rdquo;. All calls have the same basic format using the axios({ config }) method.  At the command line, install the Axios library:\nnpm install axios --save import axios from \u0026#39;axios\u0026#39; axios({ url: \u0026#39;/user/12345\u0026#39;, method: \u0026#39;get | post | put | delete\u0026#39;, data: { // data object  } });  NOTE: The Request Config has many options available for request. Only the url property is required. The HTTP method defaults to get if no specific method is given.\n  Axios has alias methods that allows for an easier syntax  axios.get(url,[config]) axios.post(url,[config]) axios.put(url,[config]) axios.delete(url,[config])     When using the alias methods url, method, and data properties don\u0026rsquo;t need to be specified in config.\n  axios() returns a promise that resolves to a response object  data is the response from the server (automatically transformed to a JSON object) status gives the status code from the server response statusText returns the status message from the server headers are the HTTP headers the server responded with     NOTE: Error handling in axios is simplified by automatically triggering the .catch() block if there is an error or the response.status code falls in the 4xx or 5xx error code range.\n Common Uses  NOTE: For these examples, we will be using a mock todo api.\nconst apiURL = `https://605a5f0927f0050017c04d80.mockapi.io/todos`  For these examples, axios() short-hand aliases will be used. Please see this GitHub repos with long-hand axios() statements. You can find the fetch() examples in this GitHub repo   GET fetch:\nasync function getTodos() { const response = await fetch(apiURL); // uses default options (GET) when none passed  const data = response.json(); return data; } axios:\nasync function getTodos() { const response = await axios.get(apiURL) return response.data; } For retrieving a specific record, you can pass the id of the record with the request URL as a route parameter\nfetch:\nasync function getTodoById(id) { const response = await fetch(`${apiURL}/${id}`); // id passed as part of the url route  return response.json(); } axios:\nexport async function getTodoById(id) { const response = await axios.get(`${apiURL}/${id}`); // id passed as part of the url route  return response.data; } POST fetch:\nasync function createTodo(todo) { const options = { method: \u0026#34;POST\u0026#34;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39; }, body: JSON.stringify(todo) } const response = await fetch(apiURL, options); const data = response.json(); return data; } axios:\nasync function createTodo(todo) { const response = await axios.post(apiURL, todo); return response.data; } PUT fetch:\nasync function updateTodo(todo) { const options = { method: \u0026#34;PUT\u0026#34;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39; }, body: JSON.stringify(todo) } const response = await fetch(`${ apiURL }/${ todo.id }`, options); const data = response.json(); return data; } axios:\nasync function updateTodo(todo) { const response = await axios.put(`${ apiURL }/${ todo.id }`, todo); return response.data; } DELETE fetch():\nasync function deleteTodo(id) { const response = await fetch(`${ apiURL }/${ id }`, { method: \u0026#34;DELETE\u0026#34; }); return response.json() } axios():\nasync function deleteTodo(id) { const response = await axios.delete(`${apiURL}/${id}`); return response.data; } Error Handling A significant difference between the Fetch API and Axios is in how to check for and handle errors.\nfetch() with error handling:\n The promise returned from fetch() will not reject if it encounters an error from the server. It will only reject if it cannot make the request or it does not get any response. Thus you must manually check the status of the response to investigate any errors returned from the server.  async function deleteTodo(id) { const response = await fetch(`${ apiURL }/${ id }`, { method: \u0026#34;DELETE\u0026#34; }); if (!response.ok) { const err = response.text(); throw new Error(\u0026#34;Error deleting todo:\u0026#34; + err.message) } } axios() with error handling:\n Promise returned from axios() will automatically be rejected if there is an error  async function deleteTodo(id) { try { const response = await axios.delete(`${apiURL}/${id}`); return response; } catch (err) { throw new Error(err) } } Summary  The Fetch API and Axios provide an API for making HTTP requests. The Fetch API is built into modern browsers. The Fetch API can be added to NodeJS via the node-fetch npm module. Axios is a 3rd party library that can be used in the browser or in a NodeJS application. While the Fetch API is the JavaScript standard way of doing HTTP requests, Axios may be preferred due to it\u0026rsquo;s simpler API and better error handling.  Additional Resources  Intro to Fetch - Excellent resource on the basics of fetch CSS Tricks - Fetch Overview - Excellent article that tackles all aspects of fetch, including Error handling It\u0026rsquo;s fetch time Why I won\u0026rsquo;t be using fetch axios  "
},
{
	"uri": "/software-eng-essentials/fundamentals-of-regex/sql/",
	"title": "Regex in SQL",
	"tags": [],
	"description": "",
	"content": "Regex in the context of SQL Skills  Basics of Regex Intermediate Regex  Basics of Regex Anchors    ^ $     ^Harry : Starts with the word \u0026lsquo;Harry\u0026rsquo;. Potter$ : Ends with \u0026lsquo;Potter\u0026rsquo;. ^Harry Potter$ : Starts with \u0026lsquo;Harry\u0026rsquo; and ends with \u0026lsquo;Potter\u0026rsquo;. Exact match to \u0026lsquo;Harry Potter\u0026rsquo;. magic : Matches any string with the word magic in it.  Examples:\nIf we have a file titled harrypotter.txt that contains the following text:\nIt takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends. Fear of a name only increases fear of the thing itself. Prints out the first line.\n$ cat harrypotter.txt | grep ^It It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends. Exercise\nPrepare for the exercise by doing the following.\n$ echo \u0026#34;It does not do to dwell on dreams and forget to live.\u0026#34; \u0026gt; quotes.txt + $ echo \u0026#34;Lay down with dogs. Rise with fleas.\u0026#34; \u0026gt;\u0026gt; quotes.txt  Using a starting Anchor cat the first line from quotes.txt to the terminal. Using an enging Anchor cat the second line from quotes.txt to the terminal. Using any word unique to the first line in quotes.txt, cat the first line to the terminal.  Quantifiers    * + ? {} ()    For the following, we\u0026rsquo;re going to use possible serial numbers to express the quantity of c\u0026rsquo;s we want to match on. The ex: provides serials numbers that would match.\n   Pattern Description Examples     ABc* Has AB and followed by 0 or any number of cs 0123AB45, 0123ABc45, 0123ABcc45   ABc+ Has AB and followed by 1 or more cs 0123ABc45 , 0123ABcc45 , 0123ABccc456   ABc? Has AB and followed by 0 or 1 cs 0123ABc45 , 0123AB45   ABc{3} Has AB and followed by 3 cs 0123ABccc56;   ABc{4,} Has AB and followed by 4 or more cs 0123ABcccc456 , 0123ABccccc456   ABc{2,5} Has AB and followed by 2 up to 5 cs 0123ABcc456 , 0123ABccccc456   A(bc)* Has A followed by zero or more of the sequence bc 0123A456 , 0123Abcbcbc456   A(bc){4,6} Has e followed by 4, or 5 bc sequences 0123Abcbcbcbc456 , 0123Abcbcbcbcbc456    So let\u0026rsquo;s say we have the following csv file named serials.csv that contains products and their serial numbers.\nG6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G7750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 E4660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 E460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 Prints out just the hardware using a known pattern of ending with at least 2 P\u0026rsquo;s.\n$ cat serials.csv | egrep \u0026#39;0123P{2,}\u0026#39; G6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G7750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25  NOTE: We start using egrep here to utilize Bash\u0026rsquo;s Extended Grep Functionality.\n Prints out just the garden items using a known pattern of having E4 followed by at least one 6.\n$ cat serials.csv | egrep \u0026#39;E46+\u0026#39; E4660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 E460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 Exercise\n Using the above CSV file, print out the items that contain 0123 followed by at least one and no more than 5 Z\u0026rsquo;s.  OR operator | \\| | [] | |:-:|:-:|\n   Pattern Description     A(b\\|c) Has A and followed by a b or a c.   e[bc] Has e and followed by a b or a c.    Let\u0026rsquo;s say we have the following text file of email addresses.\n$ printf \u0026#34;test@email.com\\nfake@gmail.com\\nlearning@bash.edu\\nfun@commandline.gov\\n\u0026#34; \u0026gt;\u0026gt; emails.csv $ cat emails.csv test@email.com fake@gmail.com learning@bash.edu fun@commandline.gov If we wanted to print out the emails that contain either @email or @gmail we could use this pattern: @[eg]mail\n$ cat emails.csv | egrep \u0026#39;@[eg]mail\u0026#39; test@email.com fake@gmail.com Exercise\n Using the above CSV file, print to the screen only those that end in \u0026ldquo;.gov\u0026rdquo; OR \u0026ldquo;.edu\u0026rdquo;.  Character Classes    \\d \\w \\s .       Pattern Description Examples     \\d Is a single digit. $ls \\| grep -E '/d' would list any file that starts with a number in your current directory.   \\w Is WORD character, i.e. alphanumeric or underscore $ls \\| grep -E '^\\w\\w\\w\\w-' would list files that start with four alpha characters, then a dash.   \\s Is a whitespace character, including tabs and line breaks ls \\| grep -E '\\w\\w\\s..\\d\\d' would list files that contains a letter, letter, a space, any character, any character, followed by two digits. Such as ec 1983.png   . Is ANY character As shown in the above example.    Inverse options\n/D gives the inverse option of /d, ex: /D matches to any one NON Digital character.\nExercise\nCreate a text file with digits, alpha, and alphanumeric keys for the following exercises. +\nprintf \u0026#34;abcdef + 123456 + abc123\u0026#34; \u0026gt;\u0026gt; testkeys.txt Exercise\n Print to the screen only the keys that include 3 consecutive digits. hint: Use qauntifiers. Print to the screen only the keys that have 3 consecutive non digit characters.  Bracket Expressions    []       Pattern Example     [emc] String can have either an \u0026lsquo;e\u0026rsquo;, \u0026rsquo;m\u0026rsquo;, or a \u0026lsquo;c\u0026rsquo;.   [a-m] String can have any letter a through m.   [a-fA-F0-9] String represents a hexadecimal number, case insensitive because we are allowing a-f lowercase, and upper.   [0-9]% String has a digit that is zero or higher, and not greater than 9, followed by a percent sign.   [^a-zA-Z] String that does NOT contain a letter a-z or A-Z. In this case the carrot is a negator.    So if we had the following text file with wood types and their tensile strength\nWood Species\tBending Strength (psi)\tAlder, Red\t9,800 Ash 15,000 Aspen 8,400 Basswood\t8,700 Beech\t14,900 Birch, Yellow\t16,600 Butternut\t8,100 Cherry\t12,300 Chestnut\t8,600 Elm\t11,800 Hickory\t20,200 Maple, Hard\t15,800 Maple, Soft\t13,400 Oak, Red\t14,300 Oak, White\t15,200 Poplar\t10,100 Sassafras\t9,000 Sweetgum\t12,500 Sycamore\t10,000 Walnut\t14,600 In order to print out just the wood types that can handle at least 15k psi, one could do:\n$ cat woodstrength.txt | egrep \u0026#39;1[5-9],[0-9]{3}\u0026#39; Ash 15,000 Birch, Yellow\t16,600 Maple, Hard\t15,800 Oak, White\t15,200 Exercise\nThis exercise is to be performed in a terminal. Execute the following to create a csv file that contains cities and their temperatures.\n$ printf \u0026#34;City\\tTemperature\\n\\rMiami\\t100deg\\n\\rAtlanta\\t95deg\\n\\rRichmond\\t90deg\\n\\r\u0026#34; \u0026gt; citytemps.csv Exercise\n Print out the lines that have temperatures 95 degrees and higher.  Answers to the exercises  cat quotes.txt | grep ^It cat quotes.txt | grep fleas$ cat quotes.txt | grep dreams cat serials.csv | egrep '0123Z{1,5} cat emails.csv | egrep 'gov|edu' cat testkeys.txt | egrep '\\d{3}' cat testkeys.txt | egrep -E '\\D{3}' cat citytemps.csv | grep -E '9[5-9]|100'  Resources  https://regexr.com/ https://www.regular-expressions.info/  "
},
{
	"uri": "/javascript/nodejs/getting-started/node-core-modules/path-module-labs/",
	"title": "The Path Module Labs",
	"tags": [],
	"description": "",
	"content": "Path module exercise  Create a new path-exercise.js file. Copy and paste the code below into the new file:  const userObj = JSON.stringify(os.userInfo()); console.log(\u0026#39;View user info object: \u0026#39; + userObj); console.log(\u0026#39;Home Directory: \u0026#39; + os.userInfo().homedir); It is a best practice to require modules at the top of a program file and assign them to a variable to avoid a ReferenceError. Use the const to formally declare the variable so it cannot be reassigned.\nconst path = require(\u0026#39;path\u0026#39;); const os = require(\u0026#39;os\u0026#39;); /* Always include required modules at the top! ☝️ ... The rest of your program... 👇 */ Exercise instructions   Get both the base and directory name and print out the concatenated result in your terminal.\n  Use the same base and directory name as the previous example, but join them using the appropriate path module method and print out the result in your terminal.\n   BONUS: Now separate the paths you just joined by using the appropriate path method (hint: Also uses another JavaScript method we’ve reviewed before) and print out the result in terminal.  Copy and paste this code snippet into your path-exercise.js file and use the Nodejs documentation to complete the following exercises:\n/* 1. Get both the base and directory name and print out the concatenated result in your terminal. */ // Your code goes here  /* 2. Use the same base and directory name as the previous example, but join them using the appropriate `path` module method and print out the result in your terminal. */ // Your code goes here  /* BONUS: Now separate the paths you just joined by using the appropriate path method and print out the result in terminal. HINT: The solution uses another JavaScript method we\u0026#39;ve reviewed before. */ // Your code goes here  "
},
{
	"uri": "/software-eng-essentials/fundamentals-of-regex/basicsed/",
	"title": "Basic Sed",
	"tags": [],
	"description": "",
	"content": "indexduction SED stands for Stream editor. It was created exclusively for executing scripts. Thus all the input you feed into it passes through and goes out to STDOUT unless piped to another command. It does not change the original file.\nSED\u0026rsquo;s general syntax\n/pattern/action Patterns If no pattern is passed then the action will occur on all lines of the source text.\nPattern is a regular expression and action is one of the commands in the following table.\nSED Actions\n   Action Description     P Prints the line, from the pattern space (sometime you get double.)   d Deletes the line   s/pattern1/pattern2/ Substitutes the first occurance of pattern1 with pattern2    No pattern example\n$sed \u0026#39;d\u0026#39; sometext.txt $ It deleted all the text and output to STDOUT\nSubstitution Example\n$ cat lines.txt This is line one. This is line two. This is line three. This is line four. $ cat lines.txt | sed \u0026#39;s/ is / is a /g\u0026#39; This is a line one. This is a line two. This is a line three. This is a line four. Exercise\nTake the following text and change flooring to laminate flooring.\nMost DIYers can install an entire room with flooring in one day. Planks can be cut with a hand saw or circular saw, and most laminate flooring comes in planks that simply snap together with a tongue-and-groove system. Addresses Address are the line affected by the change. This can be one line or a range of lines.\n$ cat lines.txt This is line one. This is line two. This is line three. This is line four. $ cat lines.txt | sed \u0026#39;1d\u0026#39; ## It deleted line one and printed out the contents. This is line two. This is line three. This is line four. $ cat lines.txt | sed \u0026#39;2p\u0026#39; ## Print just line two. Wait something went wrong? This is line one. This is line two. This is line two. This is line three. This is line four. $ cat lines.txt | sed -n \u0026#39;2p\u0026#39; ## Using the -n option keeps it from printing all the lines. This is line two. Exercise\nTake the following test and print out to STDOUT only line one without repeats.\nMost DIYers can install an entire room with laminate flooring in one day. Planks can be cut with a hand saw or circular saw, and most laminate flooring comes in planks that simply snap together with a tongue-and-groove system. $ cat lines.txt This is line one. This is line two. This is line three. This is line four. $ cat lines.txt | sed \u0026#39;1,3d\u0026#39; This is line four. This deleted lines 1 through 3, and printed out the results.\nMore complicated deletes.\nAddress Patterns\n   Pattern Description     n,md Lines n through m are deleted.   n,+md Deletes line n, continues to delete the next m lines, then ceases deletion.   n,m!d Deletes all lines but n through m   n~md Not avail in BSD version. Deletes n line, steps over the next m lines, then deletes the next line, continues this pattern to the end of the file.   2~2d Not avail in BSD version. Deletes the second line, steps over the next, deletes the next, steps over, etc. to the end of the file.    Deletes all but line one.\n$ cat lines.txt | sed \u0026#39;1!d\u0026#39; This is line one. Deletes all but lines 2 through 3\n$ cat lines.txt | sed \u0026#39;2,3!d\u0026#39; This is line two. This is line three. Nth Occurrence You can specify which occurrence of match to apply Substitution to by following the last slash with the occurrence, like: s/searched/replaced/n\n$ echo \u0026#34;Save up to 30% off on Appliances and 30% off on Bed and Bath\u0026#34; | sed \u0026#34;s/30%/25%/2\u0026#34; Save up to 30% off on Appliances and 25% off on Bed and Bath Exercise\nTake the following text and delete all lines except line one.\nMost DIYers can install an entire room with laminate flooring in one day. Planks can be cut with a hand saw or circular saw, and most laminate flooring comes in planks that simply snap together with a tongue-and-groove system. Flags    Flag Description     g Replaces all matches, not just the first match   NUMBER Replaces only NUMBERth match   p If substitution was made, then prints the pattern space   w FILENAME If substitution was made, then writes result to FILENAME   I or i Matches in a case-insensitive manner   M or m In addition to the normal behavior of the special regular expression characters ^ and $, this flag causes ^ to match the empty string after a newline and $ to match the empty string before a newline    $ echo \u0026#34;Save up to 30% off on Appliances and 30% off on Bed and Bath\u0026#34; | sed \u0026#34;s/30%/25%/w sedthis.txt\u0026#34; Save up to 25% off on Appliances and 30% off on Bed and Bath $ cat sedthis.txt Save up to 25% off on Appliances and 30% off on Bed and Bath Exercise\nEcho the following text, change \u0026ldquo;tongue and groove\u0026rdquo; to \u0026ldquo;tongue and groove\u0026rdquo; and save any matching line of text to a txt file with a name of your chosing.\nMost DIYers can install an entire room with laminate flooring in one day. Planks can be cut with a hand saw or circular saw, and most laminate flooring comes in planks that simply snap together with a tongue and groove system. "
},
{
	"uri": "/javascript/pillars/restful-api-express-node/node-refresher-lab/",
	"title": "Create a Node Server",
	"tags": [],
	"description": "",
	"content": "Create a Node.JS server hosted on local host 3000   Use the patterns you see on Node Refresher 3.3 with the following Acceptance Criteria\n   Use the http module.\n   Set the content to plain text.\n   Return the response of 'Hello World' or text of your choice.\n   Log to the console an appropriate message for successful start of server.\n   Go to your local host to see the response from your Node.JS server.\n     "
},
{
	"uri": "/javascript/nodejs/advanced/ajax-and-fetch-lab/",
	"title": "Labs for AJAX and Fetch",
	"tags": [],
	"description": "",
	"content": "LAB - Working with AJAX and Fetch Use fetch to get the following data from the JSON Placeholder API\n Get all albums Get the photo with id of 72 Get the comments from the post with an id of 10 Get all the todos from user with id of 3 Create a new post and render the response Update the title of post #9 and render the response Delete photo #11 and render a success message   Each operation should be use a separate fetch request_\n "
},
{
	"uri": "/javascript/nodejs/getting-started/node-core-modules/fs-module/",
	"title": "The FS Module",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Using Node to interact with the file system.  Skills  Learn to use the fs module Reading Receiving arguments  File system module Node can interact with files on your system. This includes:\n Reading files Writing files Making directories Deleting files  A basic part of I/O is writing to and reading from disk. These tasks are easily accomplished with the Node fs module.\nReading Let’s start by simply reading a file and logging it’s contents to the console. Following along with the code below, create a directory with a couple of files\n$ mkdir node-intro $ cd node-intro $ touch app.js first-file.txt Open first-file.txt and add some basic information, e.g.:\nHello World from first-file.txt Write the following code into app.js.\nconst fs = require(\u0026#39;fs\u0026#39;) // 1  fs.readFile(\u0026#39;first-file.txt\u0026#39;, (err, data) =\u0026gt; { // 2  if (err) throw err; // 3  console.log(data); // 4 }); console.log(\u0026#39;getting file!\u0026#39;);   Require fs and assign the return value to the fs variable.\n  Call the readFile method passing in the following arguments:\n Filename as a string: 'first-file.txt'. Callback function with err and data arguments.    Check for an error.\n  Log contents of file to the console.\n  You’ll notice a couple of things in running this file.\nFirst, this operation is happening asynchronously. This should be a given considering that I/O bound operations take time to complete. Once the file has been read, the callback is initiated.\nSecond, the content is not what we expected. Instead of getting the text, we got a Buffer instance. This is the raw binary data. A quick fix to this solution is to simply invoke the toString() method.\nconst fs = require(\u0026#39;fs\u0026#39;) fs.readFile(\u0026#39;first-file.txt\u0026#39;, (err, data) =\u0026gt; { if (err) throw err; console.log(data.toString()); // Using `toString()` }); console.log(\u0026#39;getting file!\u0026#39;); Running this operation yields the results we would expect.\nprocess.argv Manually passing the filename to our readFile function does not feel very dynamic. Thankfully, we can take add extra arguments to the node startup command and use them in our program.\nThis is accomplished by using the Process Argument Vector aka process.argv.\nAccording to the Node documentation documentation\n The process.argv property returns an array containing the command line arguments passed when the Node.js process was launched. The first element will be process.execPath. See process.argv0 if access to the original value of argv[0] is needed. The second element will be the path to the JavaScript file being executed. The remaining elements will be any additional command line arguments.\n This means that the startup arguments for our program are evaluated as an array-like object. Meaning that we can pass in additional arguments and they will be evaluated at the appropriate index position.\nFor example, by running\n$ node app.js first-file.txt and console.log'ing the contents of process.argv, we’ll get an array with 3 values.\nBuilding on this logic, we can now dynamically pass the value of process.argv[2] to our readFile method.\nconst fs = require(\u0026#39;fs\u0026#39;) const filename = process.argv[2] // 1  fs.readFile(filename, (err, data) =\u0026gt; { // 2  if (err) throw err; console.log(data.toString()); }); console.log(\u0026#39;getting file!\u0026#39;);  Create a variable containing the filename. Use the variable as an argument.  Writing Wow can we create a file with Node?\nAs you may have guessed we can use the writeFile method. We will walk through the documentation and then show what it looks like to use the asynchronous writeFile method\nwriteFile Reading the documentation on writeFile method Before using writeFile let’s take a look at the method signature and documentation. The Node Documentation shows us the method signature:\nfs.writeFile(file, data[, options], callback) Below is a table which models the arguments that writeFile takes.\n   Argument Type Type Type Type     file \u0026lt;string\u0026gt; \u0026lt;Buffer\u0026gt; \u0026lt;URL\u0026gt; \u0026lt;integer\u0026gt; filename or file descriptor   data \u0026lt;string\u0026gt; \u0026lt;Buffer\u0026gt; \u0026lt;TypedArray\u0026gt; \u0026lt;DataView\u0026gt;   options \u0026lt;Object\u0026gt; \u0026lt;string\u0026gt;     callback \u0026lt;Function\u0026gt;       The options and callback arguments merit their own tables. options may come in a few different forms, and callback is typically a function for handling errors.\n    Argument Type Type     options \u0026lt;Object\u0026gt; \u0026lt;string\u0026gt;     encoding \u0026lt;string\u0026gt; \u0026lt;null\u0026gt; Default: 'utf8'    mode \u0026lt;integer\u0026gt; Default: 0o666     flag \u0026lt;string\u0026gt; Default: 'w'    callback \u0026lt;Function\u0026gt;      err \u0026lt;Error\u0026gt;     Using writeFile Now that we have looked at the documentation for writeFile, let\u0026rsquo;s see how it may translate to a Node program. Let\u0026rsquo;s start by deciding what arguments to pass to the method.\n file— We’ll pass a filename using process.argv[2]. data— Data can be a string, buffer or uint8array. In our case, we’ll be using a string. options— Options include encoding (we’ll use the default utf8), mode (again we’ll use the default), and additional flags for reading, writing, etc. In this case we’ll leave the default of w.   File System Flags are useful for reading and writing methods. The default 'w' flag will open a file for writing. The file is created (if it does not exist) or truncated (if it exists). If we wanted to add nuance or constraints to a write method, the fs flags give us options. For example, 'wx' performs like 'w' except the operation fails if the path exists.\n  callback— as you have already seen with in other various applications, once, the initial operation of writeFile is complete, we’ll execute a callback function passing in the appropriate values.  const fs = require(\u0026#39;fs\u0026#39;) const filename = process.argv[2] fs.writeFile(filename, \u0026#39;Writing some important info to file!\u0026#39;, (err) =\u0026gt; { if (err) throw err console.log(\u0026#39;operation complete!\u0026#39;) }) console.log(\u0026#39;writing to file!\u0026#39;); Now, we can check the contents of the file by running opening the file in our text editor:\n$ cat \u0026lt;filename\u0026gt; or running our readFile method, passing in the appropriate filename.\nfs.readFile(filename, (err, data) =\u0026gt; { if (err) throw err; console.log(data.toString()); }); $ node app.js written-file.txt It is worth noting that the writeFile method will create a new file or overwrite existing content if the file exists.\nappendFile In the event that you simply want to add to an existing file, you’ll probably want to try using appendFile.\nfs.appendFile(filename, `\\nAdding more info to ${filename}`, (err) =\u0026gt; { if (err) throw err console.log(\u0026#39;operation complete!\u0026#39;) }) console.log(\u0026#39;writing to file!\u0026#39;); Reviewing the contents of our written-file.txt will reveal that the new data has been appended.\nOne interesting thing we can do is tie this all together by nesting a call to readFile in writeFile’s callback.\nfs.writeFile(filename, `Hellooooo From ${filename}!`, (err) =\u0026gt; { if (err) throw err console.log(\u0026#39;writing complete!\u0026#39;) console.log(\u0026#39;now reading from file\u0026#39;); fs.readFile(filename, (err, data) =\u0026gt; { if (err) throw err; console.log(data.toString()); }); }) console.log(\u0026#39;writing to file!\u0026#39;); Working with streams Another useful option when working with the larger files or http request/response is to use Streams. In essence, a Node Stream is a collection of data that becomes available over time.\nAs an example, we can use Read and Write streams while interacting with the file system.\nconst wStream = fs.createWriteStream(filename); const rStream = fs.createReadStream(filename); const readIt = () =\u0026gt; { rStream.on(\u0026#39;readable\u0026#39;, () =\u0026gt; ( console.log(rStream.read().toString())) ) rStream.on(\u0026#39;end\u0026#39;, () =\u0026gt; (console.log(\u0026#39;finished reading file!\u0026#39;))) } wStream.on(\u0026#39;open\u0026#39;, (fd) =\u0026gt; { wStream.write(\u0026#34;first line\\n\u0026#34;) wStream.write(\u0026#34;Second line\\n\u0026#34;) wStream.write(\u0026#34;third line\\n\u0026#34;) wStream.write(\u0026#34;fourth line\\n\u0026#34;) wStream.end(); }) wStream.on(\u0026#39;close\u0026#39;, readIt); console.log(\u0026#39;writing data\\n\u0026#39;); As you can see, this behavior is non-blocking allowing Node to work asynchronously with each stream of data. We then pass our readIt function as a callback to the wStream close event.\nWatch Another nifty feature is fs.watch. By using watch, we can listen for changes to a specific file and print the event and filename to the console.\nconst wStream = fs.createWriteStream(filename); const rStream = fs.createReadStream(filename) fs.watch(filename, (eventType, file) =\u0026gt; console.log(`${eventType}to ${file}`)) // ... Lab Practice with stdin \u0026amp; stdout\nUsing fs.promises to read and write files As of NodeJS version 10.0, we can now use the FS.Promises API to easily read from and write to files. No other dependencies are needed.\nTo read from the file first-file.txt\nconst fs = require(\u0026#39;fs\u0026#39;) const fsPromises = fs.promises; // promises API added in NodeJS version 10  fsPromises.readFile(\u0026#39;first-file.txt\u0026#39;).then(data =\u0026gt; { console.log(\u0026#39;\\n=== WITH A PROMISE ===\u0026#39;); console.log(data.toString()) // don\u0026#39;t forget the `.toString()` }).catch(err =\u0026gt; { console.log(err); process.exit(-1); }); For a cleaner syntax, we can incorporate async/await\nasync function readFirstFile() { // must wrap `await` inside an `async` function  try { const data = await fsPromises.readFile(\u0026#34;first-file.txt\u0026#34;); console.log(\u0026#39;\\n=== WITH PROMISES VIA ASYNC/AWAIT ===\u0026#39;); console.log(data.toString()); // don\u0026#39;t forget the `.toString()`  } catch (err) { console.log(err); process.exit(-1); } } readFirstFile(); To write to a file, we can use the .writeFile() function.\nfs.promises.writeFile(\u0026#39;second-file.txt\u0026#39;, \u0026#34;Hello from second file!\u0026#34;).then(() =\u0026gt; { console.log(\u0026#39;Created second-file.txt\u0026#39;); }).catch(err =\u0026gt; { console.log(err); process.exit(-1); }); Use with async/await, which offers a very clean syntax.\nasync function writeSecondFile() { // must wrap `await` inside an `async` function  try { const data = await fs.promises.writeFile(\u0026#39;second-file.txt\u0026#39;, \u0026#34;Hello from second file!\u0026#34;); console.log(\u0026#39;Created file second-file.txt\u0026#39;); } catch (err) { console.log(err); process.exit(-1); } } writeSecondFile(); To append to a file, we can use the .appendFile() method.\nasync function appendFile() { // must wrap `await` inside an `async` function  try { const data = await fs.promises.appendFile(\u0026#39;second-file.txt\u0026#39;, \u0026#34;\\nHere\u0026#39;s another line for the second file!\u0026#34;); console.log(\u0026#39;added to second-file.txt\u0026#39;); } catch (err) { console.log(err); process.exit(-1); } } appendFile(); Lab Redo the previous lab from above, using the FS Promise API.\nConclusion There are plenty of other useful methods in the fs module that are worth investigating, and these are just a few important ones to get you started as a Node developer.\n"
},
{
	"uri": "/python/web_scraping/",
	"title": "Web Scraping",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/javascript/pillars/restful-api-express-node/cumulative-lab/",
	"title": "Cumulative Lab for Node and Express API Pillar",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts   RESTful routing using Express\n  Happy path and Sad path return codes\n    Skills   Build a RESTful API\n  Create routes for all endpoints\n  Create middleware to demonstrate usage of return codes\n  Use NPM to download and install packages into an Node application\n  Follow these instructions to install a very helpful package that will listen for changes and restart your server\n         Instructions   1. To get started with this lab clone the following repo. git clone https://github.com/one-thd/om_labs_thd-stores-api.git\n   You will be using the above json-server which creates a fake full REST API. Your task is to make an RESTful API in node.js that has all the REST endpoints. You will have to use Postman to test POST, PUT, PATCH, and DELETE.\n     2. Check out the readme.   Get the shape of the data and then create a RESTful API that will hit the json-server using Node and Express that has the following:\n       Full MVC philosophy may be overkill for this one, this could be done all on one file, but you could leverage custome middle ware to use a different file for each route.     2.1. GET Routes   Get a single store based on id\n  Get a single store based on city or state\n  Provide the appropriate return code for an entry that can\u0026#8217;t be found\n    2.2. POST Route   Create a new store\n  Provide a return code if the entry exists\n  Bonus: indicate that a store has been created\n    2.3. PUT Route   Update the data for a store\n  Bonus: indicate if updating or creating\n    2.4. PATCH Route   Update the data for a store\n  Provide a return code if the store doesn\u0026#8217;t exist\n   And everyone\u0026#8217;s favorite\u0026#8230;\u0026#8203;\n \n  2.5. DELETE Route   Remove a store\n  Provide a return code if the store doesn\u0026#8217;t exist\n  Bonus: Indicate that a store has been removed\n    2.6. Hint In general your routes will look similar to the following:\n app.js let urlRoute = localhost:3000 just creates a variable for url route to save some typing. app.get('/', (req, res) =\u0026gt; { console.log('get one'); //here we need to call localhost:3000 to hit the route to get the data you want let options = { // this simplifies our request by saving all the things as an options object method: 'GET', url: urlRoute, }; request(options, (error, response, body) =\u0026gt; { res.status(200).json(JSON.parse(body)); // this simply returns all the data }); });    2.7. Other Hint You can use PostMan to get a little hint at what your requests could look like\u0026#8230;\u0026#8203;\n   Start the json-server, start your api that hits the json-server (you don\u0026#8217;t need routes yet just an app that listens) and type in your local host for your server.\n  Then click on the drop down on the left to use a GET.\n   \n   Then click where you see 'Code\n  Then click the dropdown to get the Node.js code\n   \n And Bam! a little editing is needed but you get a big hint.\n    "
},
{
	"uri": "/javascript/nodejs/advanced/inquirer/",
	"title": "InquirerJS",
	"tags": [],
	"description": "",
	"content": "What is Inquirer.js?  A collection of common interactive command line user interfaces. It eases the process of asking end user questions, parsing, validating answers, managing hierarchical prompts and providing error feedback. It is written with promises. Until this point we have created applications that execute without awaiting additional input from a user. For more information consult the Documentation Here  Awaiting Input: const inquirer = require(\u0026#34;inquirer\u0026#34;); inquirer .prompt([ { type: \u0026#34;input\u0026#34;, name: \u0026#34;name\u0026#34;, message: \u0026#34;What is your name?\u0026#34; }, { type: \u0026#34;input\u0026#34;, name: \u0026#34;hobby\u0026#34;, message: \u0026#34;What is your favorite hobby?\u0026#34; }, { type: \u0026#34;input\u0026#34;, name: \u0026#34;language\u0026#34;, message: \u0026#34;What is your preferred programming language?\u0026#34; } ]) .then(function(answers) { console.log(JSON.stringify(answers, null, \u0026#34; \u0026#34;)); console.log(\u0026#34;Answers is an\u0026#34;, typeof answers); }); What other ways can we capture input? For detailed information on all the different types of prompt types please visit: Inquirer Prompt Types\nHere is an example of two new types:\nconst inquirer = require(\u0026#34;inquirer\u0026#34;); inquirer .prompt([ { type: \u0026#34;list\u0026#34;, name: \u0026#34;shoppingHelp\u0026#34;, message: \u0026#34;Welcome to The Home Depot, how can I help you?\u0026#34;, choices: [ \u0026#34;I\u0026#39;m looking for a new stove\u0026#34;, \u0026#34;I have a broken sink, and I have no idea how to fix it\u0026#34;, \u0026#34;Can you show me to the ceiling fans please?\u0026#34; ] }, { type: \u0026#34;checkbox\u0026#34;, name: \u0026#34;notJackson5\u0026#34;, message: \u0026#34;Who is NOT apart of the Jackson 5\u0026#34;, choices: [\u0026#34;Michael\u0026#34;, \u0026#34;Randy\u0026#34;, \u0026#34;Chamon\u0026#34;, \u0026#34;Tito\u0026#34;, \u0026#34;Jackie\u0026#34;], validate: function(input) { // let done = this.async();  if (input[0] !== \u0026#34;Chamon\u0026#34;) { // done(\u0026#34;That is incorrect, try again\u0026#34;);  return \u0026#34;That is incorrect, try again\u0026#34;; } else { console.log(input); // done(true);  return true; } } } ]) .then(function(answers) { console.log(JSON.stringify(answers, null, \u0026#34; \u0026#34;)); }); Promises, Inquirer, and Fetching So far we\u0026rsquo;ve covered a few major topics in Promises, inquirer and fetch. Now lets see how these things can be combined to in Node to produce something of value.\nMain entry point for our CLI application\nconst inquirer = require(\u0026#34;inquirer\u0026#34;), questions = require(\u0026#39;./questions/questions\u0026#39;), {getUserInfo,getManagerInfo} = require(\u0026#39;./services/userinfo\u0026#39;) let userdata = {}, userout = {} inquirer.prompt(questions.baseuser).then(answer =\u0026gt; { // 1.  return getUserInfo(answer.User) 2. }) .then(response =\u0026gt; response.json()) // 3.  .then(data =\u0026gt; { console.log(\u0026#39;Got user info \u0026#39;) userdata = data userout = { // 4.  name: `${userdata.first_name}${userdata.last_name}`, email: userdata.email } return getManagerInfo(userdata.manager.links.href) // 5.  }) .then(response =\u0026gt; response.json()) // 6.  .then(managerdata =\u0026gt; { userout.manager_name = `${managerdata.first_name}${managerdata.last_name}` userout.manager_email = managerdata.email return userout // 7.  }) .then(console.log) // 8.  We ask for the user\u0026rsquo;s ID, using the imported options from the questions module. Use the input to fetch the user details from the services module using the getUserInfo() function. Once this resolves, we need to parse the json. Using the parsed object, we build the userout object We then use the managers user endpoint from the user data to make a call to getManagerInfo Again, get the json object Compleat the userout object using the managers info and return it Log the result  Questions Module\nconst baseuser = [{ type: \u0026#34;input\u0026#34;, name: \u0026#34;User\u0026#34;, message: \u0026#34;What is the users id?\u0026#34; }] module.exports = { baseuser } Questions is setting up the options to pass to inquirer. You could potenitally have more work to do and it everything related to it could be defined here.\nServices Module with fetch\nconst fetch = require(\u0026#34;node-fetch\u0026#34;) const getUserInfo = (id) =\u0026gt; { return fetch(`http://dapper.apps-zb.homedepot.com/users/${id}`) } const getManagerInfo = (path) =\u0026gt; { return fetch(`http://dapper.apps-zb.homedepot.com/${path}`) } module.exports = { getUserInfo, getManagerInfo } Services Module with axios\nconst axios = require(\u0026#34;axios\u0026#34;) const getUserInfo = (id) =\u0026gt; { return axios(`http://dapper.apps-zb.homedepot.com/users/${id}`) } const getManagerInfo = (path) =\u0026gt; { return axios(`http://dapper.apps-zb.homedepot.com/${path}`) } module.exports = { getUserInfo, getManagerInfo } It is typical to separate out calls to external API\u0026rsquo;s by creating functions that will return the Promises that fetch and axios returns.\nLabs   Your turn from scratch\n  Pizza.js\n  "
},
{
	"uri": "/javascript/nodejs/getting-started/node-core-modules/fs-module-labs/",
	"title": "Labs for FS Module",
	"tags": [],
	"description": "",
	"content": "Lab 1 - I/O with fs In your main.js (or app.js) file of the car module from our previous lab…​\n Create a new car. The car object should be serialized, e.g. JSON.stringify(myCar). Save the serialized car object to a new .txt file. Create a new file named print-results.js, that prints the results of your file to the console.  Lab 2 - I/O with Rock Paper Scissors  Clone down your trusty old Rock Paper Scissors app Append the winning results to the a file named winner.txt Create another script that can print the results of winner.txt  bonus\n Make your code modular Create a new file containing a Player constructor function  The Player constructor function should create a new object with the following properties:  name score chooseHand function     Export the constructor and use it in your main application file   prompt() will not work in this context, for now, hardcode the user data.\n "
},
{
	"uri": "/javascript/nodejs/getting-started/node-core-modules/error-handling/",
	"title": "Error Handling",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Error handling in Node.  Skills  Learn to write an error-first callback.  Error first callbacks Proper error handling is essential to any application. A common pattern in Node is to pass an error as your first argument. We can then immediately check for an error and handle it appropriately. While variations of this pattern exist, this is the most widely used concept.\n(err, data) =\u0026gt; { if (err) throw err; // do something with data }   If no error is present, often the calling function will simply pass null as the first argument.\nTry passing in an erroneous filename to see what happens.\nconst fs = require(\u0026#39;fs\u0026#39;) fs.readFile(\u0026#39;first.txt\u0026#39;, (err, data) =\u0026gt; { if (err) throw err; console.log(data.toString()); }); console.log(\u0026#39;getting file!\u0026#39;); The following error will halt execution of the program.\nError: ENOENT: no such file or directory, open \u0026#39;first.txt\u0026#39; "
},
{
	"uri": "/golang/fromjava/",
	"title": "If you&#39;re coming from Java...",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/software-eng-essentials/command-line-bash/intro/",
	"title": "Intro",
	"tags": [],
	"description": "",
	"content": "Objectives  Understand why the Unix Command Line and bash scripting are important skills What we are going to do How we are going to do it  Why learn the Unix Command Line and Bash Scripting? Automation begins at the Command Line\nA graphical user interface (GUI) may be easy to use, but for software engineering and IT operations the most powerful and flexible way to interact with computers is often through a command-line interface (CLI). The user may simply type commands that tell the computer to perform desired tasks. Aliases may be created to shorten the typing of commonly used commands, and executable bash scripts may be written and executed from the command line.\nWorking with APIs\nMany popular apps for software development have GUIs available, and modern text editors and IDEs have so much power and utility already baked in. But the developers of these external APIs and CI/CD tools understand that software engineers need command-line tools integrated into their efficient workflow that already centers around the command-line. Here is a list of some popular programs and APIs today that have their own CLI tools designed in the Unix tradition.\n Homebrew Git, GitHub Google Cloud Platform Docker NPM  Unix casts a large shadow\nThe Unix family includes macOS, Linux, iOS, and Android\u0026ndash;but not Windows. Even still it is useful for a Windows developer to learn the basics of the Unix command-line, since they may encounter a Linux server or a Docker container which they will need to issue commands on. Unix plays a central role in modern computing, and learning command-line basics is an essential skill for the modern developer.\nWhat we are going to do Basics\n Running a terminal Our first command Man pages Input/Output Editing the line Cleaning up  Manipulating Files\n Redirecting and appending Listing Renaming, copying, deleting  Inspecting Files\n Downloading a file Heads or tails Less is more Grepping  Directories\n Directory structure Making directories Navigating directories Renaming, copying, and deleting directories  Customization\n Bash profile Aliasing Commands Customizing the Prompt  Executable Bash Scripts\nBash Scripting Intro\n What is a bash script? Why should I write a shell script? Shell scripts vs compiled programs  Terminal Text Editing\n Nano Emacs Vim  Escalating kill Script\n A custom escalating kill script Choose your $PATH An enhanced version of the custom kill script  Scripting and Receiving Input\n Command line arguments Variables Arrays User input Reading from STDIN  Control Flow, Loops, and Functions\n Control Flow - if and case Statements Loops - while/until/for Functions select statements  Subshell\n Subshell Local variables Environment variables  Next Level Command Line\nRegEx\n Learn about Regular Expressions Anchors, Quantifiers, \u0026ldquo;Or\u0026rdquo; operator, Bracket Expressions, and Character Classes of RegEx  The SED Command and the AWK Programming Language\n She SED what? Introduction to the AWK Language  Wildcards and Brace Expansion\n Know how to play a single wildcard The wide ranging world of brackets Using brace expansion  How we are going to do it The command line\nWe will use the command line to do things in the terminal.\nThe Mac Terminal is a command line interface (CLI) for Mac OS X available in all OS X versions through Lion. It is also a gateway to Unix, or the underlying operating system of OS X. Terminal allows users to modify various characteristics of their Mac desktops, fonts, files and more beyond the standard OS X graphical user interface (GUI). It allows for total customization and command. However, if novice computer users apply modifications incorrectly, this can harm the system or lead to a loss of data.\nLocated in the Mac Utilities folder, Terminal has a black icon with a gray border.\nThe Mac Terminal is similar to the Windows Command Prompt. When accessed, a short message displays the user\u0026rsquo;s previous login, identity associated with the login and the Mac that is in use. There is also a gray vertical bar, where commands may be typed by the user. However, nothing may happen when a user clicks the area with a mouse; the gray bar shifts automatically when the user starts typing.\nText editing for the terminal\nWe will do as much as we can to edit files using the command line, but at a certain point (particularly when creating and editing bash scripts) it is prudent to use a full-fledged text editor. Fortunately, Unix-family operating systems often ship with one or more text editors.\nWe will briefly explore three popular options, but you are welcome to use your preferred text editor.\n Visual Studio Code is already installed on the classroom iMacs.\n "
},
{
	"uri": "/javascript/nodejs/advanced/inquirer-labs/",
	"title": "Labs for InquirerJS",
	"tags": [],
	"description": "",
	"content": "Lab 00 - Your Turn from Scratch  Create a repo on GitHub Create a new program using inquirer that will ask your neighbor 5 different questions using a minimum of 5 different prompt types. Share the link to your repository with the class. Ask at least 3 people to respond by running your code in their environment. Review \u0026amp; answer 3 other class members code and submit your OBJECT of responses as an issue on their repository  Lab 01 - Pizza.js  Copy the code at the bottom of this page into the repository used above in lab 00. Run this code and step through each question to understand how the validate functions work. After you receive this prompt:  Prepare your another set of questions Nest them to receive the outputs from the original set of questions. Prompt the user and ask them any additional question. Ex: \u0026ldquo;Why do you think it\u0026rsquo;s acceptable to put pineapple on pizza?\u0026rdquo;    const inquirer = require(\u0026#34;inquirer\u0026#34;); console.log(\u0026#34;Hi, welcome to Node Pizza\u0026#34;); let questions = [ { type: \u0026#34;confirm\u0026#34;, name: \u0026#34;toBeDelivered\u0026#34;, message: \u0026#34;Is it for a delivery\u0026#34;, default: false }, { type: \u0026#34;input\u0026#34;, name: \u0026#34;phone\u0026#34;, message: \u0026#34;What\u0026#39;s your phone number\u0026#34;, validate: function(value) { let pass = value.match( /^([01]{1})?[\\-\\.\\s]?\\(?(\\d{3})\\)?[\\-\\.\\s]?(\\d{3})[\\-\\.\\s]?(\\d{4})\\s?((?:#|ext\\.?\\s?|x\\.?\\s?){1}(?:\\d+)?)?$/i ); if (pass) { return true; } else { return \u0026#34;Please enter a valid phone number\u0026#34;; } } }, { type: \u0026#34;list\u0026#34;, name: \u0026#34;size\u0026#34;, message: \u0026#34;What size do you need\u0026#34;, choices: [\u0026#34;Large\u0026#34;, \u0026#34;Medium\u0026#34;, \u0026#34;Small\u0026#34;], filter: function(val) { return val.toLowerCase(); } }, { type: \u0026#34;input\u0026#34;, name: \u0026#34;quantity\u0026#34;, message: \u0026#34;How many do you need\u0026#34;, validate: function(value) { let valid = !isNaN(parseFloat(value)); return valid || \u0026#34;Please enter a number\u0026#34;; }, filter: Number }, { type: \u0026#34;expand\u0026#34;, name: \u0026#34;toppings\u0026#34;, message: \u0026#34;What about the toping\u0026#34;, choices: [ { key: \u0026#34;p\u0026#34;, name: \u0026#34;Peperonni and chesse\u0026#34;, value: \u0026#34;PeperonniChesse\u0026#34; }, { key: \u0026#34;a\u0026#34;, name: \u0026#34;All dressed\u0026#34;, value: \u0026#34;alldressed\u0026#34; }, { key: \u0026#34;w\u0026#34;, name: \u0026#34;Hawaian\u0026#34;, value: \u0026#34;hawaian\u0026#34; } ] }, { type: \u0026#34;rawlist\u0026#34;, name: \u0026#34;beverage\u0026#34;, message: \u0026#34;You also get a free 2L beverage\u0026#34;, choices: [\u0026#34;Pepsi\u0026#34;, \u0026#34;7up\u0026#34;, \u0026#34;Coke\u0026#34;] }, { type: \u0026#34;input\u0026#34;, name: \u0026#34;comments\u0026#34;, message: \u0026#34;Any comments on your purchase experience\u0026#34;, default: \u0026#34;Nope, all good!\u0026#34; }, { type: \u0026#34;list\u0026#34;, name: \u0026#34;prize\u0026#34;, message: \u0026#34;For leaving a comments, you get a freebie\u0026#34;, choices: [\u0026#34;cake\u0026#34;, \u0026#34;fries\u0026#34;], when: function(answers) { return answers.comments !== \u0026#34;Nope, all good!\u0026#34;; } } ]; inquirer.prompt(questions).then(function(answers) { console.log(\u0026#34;\\nOrder receipt:\u0026#34;); console.log(JSON.stringify(answers, null, \u0026#34; \u0026#34;)); //TODO: Modify the code here to accept answers and ask additional questions using inquirer.js }); "
},
{
	"uri": "/python/foundation/virt_env/",
	"title": "Virtual Environments",
	"tags": [],
	"description": "",
	"content": "What is a Virtual Environment? A virtual environment is a tool to maintain separate space for a project with its dependencies and libraries in one place. This environment is specific to the particular project and doesn\u0026rsquo;t interfere with other projects\u0026rsquo; dependencies.\nPipenv creates a Python environment that is segregated from your system wide Python installation. In this way, you can test your module without any external packages mucking up the result, add different versions of dependency packages and generally verify the exact set of requirements for your package.\nFor example, you can work on project X which is using version 1.0 of library Z and also maintain project Y which is using version 2.0 of library Z.\n If you are familiar with npm(yarn) the concept here is the same.\n  Pipenv Pipenv — the officially recommended Python packaging tool from Python.org, free (as in freedom).\nPipenv is a tool that aims to bring the best of all packaging worlds (bundler, composer, npm, cargo, yarn, etc.) to the Python world. Windows is a first-class citizen, in our world.\nIt automatically creates and manages a virtualenv for your projects, as well as adds/removes packages from your Pipfile as you install/uninstall packages. It also generates the ever-important Pipfile.lock, which is used to produce deterministic builds.\nPipenv solves seeks to solve multiple problems:\n You no longer need to use pip and virtualenv separately. They work together. Managing a requirements.txt file can be problematic, so Pipenv uses Pipfile and Pipfile.lock to separate abstract dependency declarations from the last tested combination. Hashes are used everywhere, always. Security. Automatically expose security vulnerabilities. Strongly encourage the use of the latest versions of dependencies to minimize security risks arising from outdated components. Give you insight into your dependency graph (e.g. $ pipenv graph). Streamline development workflow by loading .env files. Nice pipenv video tutorial here  Getting Started With Pipenv in Terminal First, we need to install pipenv\nbrew install pipenv  Create a Virtual Environment Now that pipenv is installed, lets create a virtual environment. In the terminal create a new project directory called virt_env and navigate to the diectory\nmkdir virt_env cd virt_env Now we have a project location run the pipenv \u0026ndash;three to create a Python 3 virtual environment. I\u0026rsquo;m sure you can guess the command to create a Python 2 virtual environment.\npipenv --three Your prompt should now look like the one in this:\nGreat! Now we have a virtual environment ready to rock for our application. To activate it we type:\npipenv shell This is a Python shell that runs python code and has access to all installed packages. Let\u0026rsquo;s install some packages to play around with.\n To make sure you are in the correct directory that you want to be in, your shell line should contain the name of your project sirectory name a dash and a random set alphanumeric charaters followed by bash. Like the (Python_Projects-_n3f_QqF) bash-3.2$ in the above images.\n  Managing the virtual environment Installing packages Lets install the common requests package to get our feet wet.\npipenv install requests  If you do not have pip installed globally on your machine, you will have to run pipenv run pip install packageName along with pip install packageName\n  Using pip commands inside pipenv pip freeze list all installed packages and their versions. If pip isn\u0026rsquo;t installed on your machine, to use it in pipenv environment place \u0026ldquo;pipenv run\u0026rdquo; in front of pip command:\n$ pipenv run pip freeze or $ pip freeze #if you have pip installed on your machine Pip Usage  Keep in mind if pip isn\u0026rsquo;t already installed on your computer globally you must type pipenv run\n $ pipenv run pip install simplejson [... progress report ...] Successfully installed simplejson Upgrading a package $ pipenv run pip install --upgrade simplejson [... progress report ...] Successfully installed simplejson Removing a package $ pipenv run pip uninstall simplejson Uninstalling simplejson: /home/me/env/lib/python2.7/site-packages/simplejson /home/me/env/lib/python2.7/site-packages/simplejson-2.2.1-py2.7.egg-info Proceed (y/n)? y Successfully uninstalled simplejson Searching a package $ pipenv run pip search \u0026#34;query\u0026#34; Checking status of a package #To get info about an installed package, including its location and files: $ pipenv run pip show packageName Exit Pipenv Environment To exit environment simply type exit and press return:\n$ exit  Using Pipenv in Pycharm If you are using Pycharm, it has the option to use pipenv when guilding projects. The Pipfile is placed in the project root directory. To enable this go to Pycharm \u0026gt; Preferences \u0026gt; Project: {your_project_name} \u0026gt; Project Interpreter.\nChoose the dropdown list and select Pipenv, if it\u0026rsquo;s an option.\nIf Pipenv is not an option select the gear beside the dropdown\u0026hellip;\nThen select Pipenv Environment on the left side and select OK\nYou should now see a Pipfile in your Project root directory!\n"
},
{
	"uri": "/application-security/",
	"title": "Application Security",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Application Security Offerings "
},
{
	"uri": "/python/automation/automating-python-interactions/",
	"title": "Automating Python Scripts",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Automate processes with crons using both the terminal and Python Create, read, update and delete cron jobs in Python  There are many times when you need to run a shell script or command at regular intervals. This can be to clean up your system or run maintenance tasks on your computer. For these jobs, you\u0026rsquo;ll want to use something called \u0026ldquo;Crons.\u0026rdquo;\nCron jobs A cron job is a simple way of specifying a command and run interval to the operating system. We\u0026rsquo;ll show you how to create these jobs, and how to remove them once they become unnecessary.\nTiming Sequences The timing sequence of a cron job looks like this:\n* * * * * \u0026lt;command to execute\u0026gt; | | | | | | | | | +-Day of week (0-6) (Sunday=0) or Sun, Mon, Tue,... | | | +- Month (1-12) or Jan, Feb,... | | +-Day of month (1-31) | +-Hour (0-23) +- Minute (0-59) Examples:\n   Cron Set Up Job Frequency     0 13 * * * Every day at 1:00 p.m.   30 * * * * Every 30 minutes   * * * * 3 Once a week on EVERY minute of Wednesday    Terminal Instructions Now that you\u0026rsquo;ve got the sequence down, then you are ready to create the job.\nThe command to edit the cron file is:\nenv EDITOR=code crontab -e\nAll of your cron jobs will be placed in this file, each on a new line.\nOnce the editor has loaded, you\u0026rsquo;ll type in the cron jobs like this:\n[timing sequence] commandToRun\nIf you wish to enter multiple cron jobs, enter each cron on a separate line in the file.\nListing Cron Jobs You can see how many jobs are currently scheduled from inside of cron by typing the following command:\ncrontab -l\nRemoving Cron Jobs There may come a time when you don\u0026rsquo;t wish to run a cron job any longer. When that time comes, open up crontab for editing.\nDelete the line that contains the command that you no longer wish to use, then re-save the file, then exit code.\nPython Instructions Python presents us with the crontab module to manage scheduled jobs via Cron.\nThe functions available in it allow us to:\n access Cron create jobs set restrictions remove jobs and more.  Set Up Create a new directory with three new files automate.py and access-log.py:\n access-log.py will be the Python file that we are going to schedule calling automate.py will schedule the execution of access-log.py requirements.txt has all needed imports for this lesson. Can be downloaded here  Within that new directory, create a virtual environment and install all needed dependencies with the following:\npython3 -m venv venv source venv/bin/activate pip3 install -r requirements.txt Contents of access-log.py:\nfrom datetime import datetime with open(\u0026#39;append.txt\u0026#39;, \u0026#39;a\u0026#39;) as my_file: my_file.write(\u0026#39;\\nAccessed on \u0026#39; + str(datetime.now())) When creating a cron with CronTab, you need to pass an argument to the CronTab constructor\n   Constructor Argument Description     No argument Default   user='username' Accesses cron by using the specified username   user=True Accesses cron by using the the username of the current user   tabfile='filename.tab' Calls a task defined in \u0026quot;filename.tab\u0026quot;   tab=\u0026quot;\u0026quot;\u0026quot;* * * * * command\u0026quot;\u0026quot;\u0026quot; Defines the task according to cron\u0026rsquo;s syntax    Creating Jobs Once we have created a cron instance, we can create a new task to be executed:\ncron.new(command=\u0026#39;my command\u0026#39;) We can also add a comment to our task:\ncron.new(command=\u0026#39;my command\u0026#39;, comment=\u0026#39;my comment\u0026#39;) Add the following to automate.py:\nfrom crontab import CronTab import os, sys cron = CronTab(user=True) # 1 curr_directory = os.path.dirname(os.path.abspath(__file__)) # 2 job = cron.new(command=f\u0026#34;cd {curr_directory} \u0026amp;\u0026amp; \u0026#34; f\u0026#34;{sys.executable} access-log.py\u0026#34;)# 3 job.minute.every(1) # 4 cron.write() Once cron is accessed, we can add more than one job.\nListing Jobs The following lists all cron jobs, including disabled jobs:\nfor job in cron: print(job) Example Output:\n* * * * * python /home/eca/cron/access-log.py You can find specific jobs by searching by command, comment or time frequency.\n# Search by command job = cron.find_command(\u0026#39;bar\u0026#39;) # like foobar1 job = cron.find_command(re.compile(r\u0026#39;b[ab]r$\u0026#39;)) # anything ending in bar or bbr # Search by comment iter = cron.find_comment(\u0026#39;ID or some text\u0026#39;) # eg \u0026#39;look for ID or some text\u0026#39; iter = cron.find_comment(re.compile(\u0026#39; or \\w\u0026#39;)) # \u0026#39; or \u0026#39; with a letter # Search by time iter = cron.find_time(2, 10, \u0026#39;2-4\u0026#39;, \u0026#39;*/2\u0026#39;, None) # == 2 10 2-4 */2 0 iter = cron.find_time(\u0026#34;*/2 * * * *\u0026#34;) # */2 * * * * Removing Jobs Each job can be removed separately.\njob = cron.find_command(\u0026#39;bar\u0026#39;) # finds a specific cron job cron.remove(job) # removes it cron.write() # updates the cron All cron jobs can be removed at once with: cron.remove_all()\nJobs can also be removed based on a condition, like a specific time or comment.\nFor example:\ncron.remove_all(comment=\u0026#39;my comment\u0026#39;) cron.write() This will remove all jobs where comment='my comment'.\nCreating Restrictions Once a new task is added, we can set restrictions for each of them. Such as:\njob.minute.every(minutes) # replace minutes with the frequency in minutes Similarly we could set up the hours:\njob.hour.every(hours) # replace hours with the frequency in hours We can also set up the task to be run on certain days of the week, such as just Sunday:\njob.dow.on(\u0026#39;SUN\u0026#39;) Schedule the task on Sundays and Fridays:\njob.dow.on(\u0026#39;SUN\u0026#39;, \u0026#39;FRI\u0026#39;) We can tell cron to run the task in specific months:\njob.month.during(\u0026#39;APR\u0026#39;, \u0026#39;NOV\u0026#39;) Each time we set a time restriction, we nullify the previous one:\njob.hour.every(5) job.hour.every(7) The above code will set the final schedule to run every seven hours, cancelling the previous schedule of five hours.\nWe can append a schedule to a previous one:\njob.hour.every(15) job.hour.also.on(3) This will set the schedule as every 15 hours, and at 3 AM.\nThe every condition can be a bit confusing at times.\n   CronTab Syntax Cron equivalent     job.hour.every(15) * /15 * * *   job.every(15).hours() 0 */4 * * *   job.every(2).month() 0 0 0 */2 *   job.month.every(2) * * * */2 *    Clear Restrictions To clear a task\u0026rsquo;s restrictions you use the clear function: job.clear()\njob = cron.find_command(\u0026#39;bar\u0026#39;) job.clear() cron.write() Enabling/Disabling a Job A task can be enabled or disabled.\njob.enable() # Enabling a job stored in `job` job.enable(False) # Disabling a job stored in `job` To verify whether a task is enabled or disabled, use the job.is_enabled() method\nEnvironment Variables We can also define environmental variables specific to our scheduled task and show them on the screen.\ncron.env[\u0026#39;MAILTO\u0026#39;] = \u0026#39;your_email@homedepot.com\u0026#39; # change where the output from a job to your email job.env[\u0026#39;MY_ENV1\u0026#39;] = \u0026#39;A\u0026#39; # set environment variables for a specific job To see all the values for all the environmental variables, use cron.env.\nSummary Cron allows you to schedule specific tasks at specific frequencies and times. It is possible to do this all from the terminal, but also with the Python library crontab. In this lesson, we learned how to create, read, update and delete cron jobs in Python.\n"
},
{
	"uri": "/javascript/foundations/cheatsheets/basicjs/basic-js/",
	"title": "Basic JavaScript Fact Sheet",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/software-eng-essentials/command-line-bash/basics/",
	"title": "Basics",
	"tags": [],
	"description": "",
	"content": "Objectives  Run a terminal session Enter commands in the terminal Input/Output Use the man command Edit the line Clean up the command line  Running a terminal For our first terminal session, we simply want to identify the prompt and parts of a typical command. Let\u0026rsquo;s get things moving by starting up the terminal.\nStarting the terminal\n Open a terminal window using the macOS application Spotlight. Once you’ve launched Spotlight, you can start a terminal program by typing \u0026ldquo;terminal\u0026rdquo; in the Spotlight Search bar, and then pressing return.   Here are a couple of different ways to access Spotlight type ⌘+space (Command-space) or click on the magnifying glass in the upper right part of your screen.\n Identifying the prompt:\n The prompt is supplied automatically by the terminal. Every command line starts with some symbol to \u0026ldquo;prompt\u0026rdquo; the user to action. The prompt is usually a $, and is preceded by system details dependent on default or custom settings.  Anatomy of a command line prompt\n[project]$ ls -l foobar.txt ␣ prompt: _[project]$_ command: _ls_ option: _-l_ argument: _foobar.txt_ cursor: _␣_ (blinking or not, depending on settings) Exercises\nWe want to identify things happening in our own terminal.\n Copy and paste this command into your terminal: ls -a Press return to run the command. Identify the prompt, command, options, arguments, and cursor in your terminal.  We want to open a new terminal tab without closing our current terminal session or opening a new window. We also want the ability to do this in the future without leaving our keyboard so to speak.\n Examine the menu items and select \u0026ldquo;Shell\u0026rdquo;. Hover over \u0026ldquo;New Tab\u0026rdquo;, and find the keyboard shortcut for opening a new tab. Use the keyboard shortcut to open a new tab.  Our first command We want to follow programming convention and print \u0026ldquo;hello world\u0026rdquo; to the screen for our first command. Our tool to accomplish this task is echo. The echo command takes a string of characters as an argument and prints them to the screen. Type \u0026ldquo;echo hello world\u0026rdquo; at the prompt, and then press return to enter the command.\nPrinting to screen\n$ echo hello world hello world echo does not require the string argument to be wrapped in quotation marks, but it certainly accepts these strings just the same.\nPrinting arguments with single or double quotes\n$ echo \u0026#39;hello, thd\u0026#39; hello, thd $ echo \u0026#34;hello, thd\u0026#34; hello, thd $ Stuck Leaving off a closing quotation mark will result in the following:\nLeaving off a closing quote\n$ echo \\\u0026#39;hello, Orange Academy \u0026gt; We\u0026rsquo;re stuck!\n Fix the problem by simply adding the matching quote and hitting return.\n Appending the matching quote\n$ echo \u0026#39;hello, Orange Academy \u0026gt; \u0026#39; hello, Orange Academy Getting out of trouble There are lots of things than can get you into trouble when using the command line. A command may be entered which starts an infinite loop, or simply leaves the terminal hanging or unresponsive.\n$ cat $ tail $ echo \\\u0026#34;hello $ grep foobar $ yes please Getting out of trouble is easy!\n Typing ⌃+ c (Ctrl-c) is most often the solution, and should be the first thing you try. When Ctrl-c fails, hitting esc should do the trick.  Exercises\n Write a command that prints out the string \u0026ldquo;hello, home depot\u0026rdquo;.  Extra Credit: Do it two different ways, both with and without using quotation marks.   Type the command echo 'hello (with a mismatched single quote), and then get out of trouble!  Input/Output Input and output in Bash is a complex topic, because there is a great deal of plasticity in how it\u0026rsquo;s done. Input and output are important in shell script programming. Understanding where your input comes from, what it looks like, and what you must do to it in order to produce the output you want are central requirements for almost all scripts.\nInput refers to any information that your program receives (or reads). Input to a Bash script can come from several different places:\n Command-line arguments (which are placed in the positional parameters) Environment variables, inherited from whatever process started the script Files Anything else a File Descriptor can point to (pipes, terminals, sockets, etc.). This will be discussed below.  Output refers to any information that your program produces (or writes). Output from a Bash script can also go to lots of different places:\n Files Anything else a File Descriptor can point to Command-line arguments to some other program Environment variables passed to some other program  Standard streams Computers are useful because we can send and receive signals or data to them,\nand we can also receive signals or data from computers. In computer programming, input/output (or I/O) is the communication between computers and the outside world. Input and output reference preconnected input and output channels between the computer and its environment.\nThese channels are called standard streams. There are three standard streams called standard input (stdin), standard output (stdout) and standard error (stderr).\n   Standard Stream Description     stdin Standard input is data going into a program. The program requests data transfers with read operation. This is usually associated with the keyboard.   stdout Standard output is where a program writes its output data. The program requests data transfers with the write operation. This is usually associated with the terminal screen.   stderr Standard error is an output program used by a program to output error messages or diagnostics.    Demonstration of how stdin and stdout work\n$ read -p \u0026#34;What is your name? \u0026#34; name; echo \u0026#34;Howdy, $name.\u0026#34; read is a command that reads information from stdin and stores it in a variable. We specified name to be that variable. Once read has read a line of information from stdin, it finishes and lets echo display a message. echo sends its output to stdout. stdin and stdout are connected to your terminal. When a program reads from a terminal, it receives keystrokes from your keyboard; when it writes to a terminal, characters are displayed on your monitor. As a result, you can type in your name and are then greeted with a friendly message on your monitor.\nDemonstration of stderr\n$ rm top-secret rm: \u0026#39;top-secret\u0026#39;: No such file or directory Unless you have a file called top-secret in your current directory, that rm command will fail and show an error message explaining what went wrong. Error messages like these are by convention displayed on stderr.\nstderr is also connected to your terminal\u0026rsquo;s output device, just like stdout. As a result, error messages display on your monitor just like the messages on stdout. However, the distinction between stdout and stderr makes it easy to keep errors separated from the application\u0026rsquo;s normal messages. For example, a script might wish to log stderr messages in a special place for long-term storage.\nMan pages The shell includes a powerful tool called man to learn more about available commands. To use man, state the command and pass as an argument another command you wish to learn more about. Your system\u0026rsquo;s details for the man page of echo might look like this:\nRunning man echo\n$ man echo ECHO(1) BSD General Commands Manual ECHO(1) NAME echo -- write arguments to the standard output SYNOPSIS echo [-n] [string ...] DESCRIPTION The echo utility writes any specified operands, separated by single blank (\\` \\\u0026#39;) characters and followed by a newline (\\n) character, to the stan- dard output. The following option is available: -n Do not print the trailing newline character. This may also be achieved by appending \u0026#39;\\c\u0026#39; to the end of the string, as is done by iBCS2 compatible systems. Note that this option as well as the effect of \u0026#39;\\c\u0026#39; are implementation-defined in IEEE Std 1003.1-2001 (POSIX.1\u0026#39;\u0026#39;) as amended by Cor. 1-2002. Applications aiming for maximum portability are strongly encouraged to use printf(1) to suppress the newline character. But wait\u0026ndash;there\u0026rsquo;s more!\nThe colon : at the bottom of the page indicates that there is more info below.\n You should be able to access following information by pressing ↓ to move down line by line touch space to move down one page at a time. Press q to quit or exit the man page.  Meta man\nSince man is itself a command, we can run man on man!\nRunning man on man\n$ man man man(1) man(1) NAME man - format and display the on-line manual pages SYNOPSIS man [-acdfFhkKtwW] [--path] [-m system] [-p string] [-C config_file] [-M pathlist] [-P pager] [-B browser] [-H htmlpager] [-S section_list] [section] name ... DESCRIPTION man formats and displays the on-line manual pages. If you specify sec- tion, man only looks in that section of the manual. name is normally the name of the manual page, which is typically the name of a command, function, or file. However, if name contains a slash (/) then man interprets it as a file specification, so that you can do man ./foo.5 or even man /cd/foo/bar.1.gz. See below for a description of where man looks for the manual page files. OPTIONS -C config_file The details in man pages can often be puzzling, but that is okay. Details aren\u0026rsquo;t always useful. The man command is a useful tool for quickly searching for a high-level overview of particular commands.\nExercises\n According to the man page, what are the official short and long descriptions of the echo command on your system? By default echo appends a newline (a special character that puts the string on a new line, often written in programming languages as \\n) to the string passed as an argument. Often in programs or executable scripts we want print out a sequence of strings not separated by newlines. Read the man page for echo to determine the command to print out the string \u0026ldquo;hello\u0026rdquo; without the trailing newline, and then test this by running the command with necessary options to accomplish this in the terminal.  Editing the line The command line includes several features to make it easy to repeat previous commands.\n   Key Symbol     Command ⌘   Control ⌃   Shift ⇧   Option ⌥   Up, down, left, right ↑ ↓ ← →   Enter/Return ↵   Tab ⇥   Delete ⌫s    The \u0026ldquo;up arrow\u0026rdquo; ↑ retrieves the previous command. Pressing up arrow again moves further up the list of commands, while \u0026ldquo;down arrow\u0026rdquo; ↓ does the opposite\u0026ndash;moving back down the list of commands.\nControl is key\nWe can use \u0026ldquo;left arrow\u0026rdquo; ← and \u0026ldquo;right arrow\u0026rdquo; → to move the cursor through the line. But we need a faster option for traversing lines. The control key (^ or Ctrl) gives us what we\u0026rsquo;re looking for.\nSuppose we want to print out a message (\u0026ldquo;hello home depot\u0026rdquo;) to standard output:\n$ hello home depot What is wrong here?\nWe forgot to include the echo command!\nWe could press and hold ← to get to the beginning of the line, but a better option is ⌃a (^+ a), which immediately moves the cursor there. Other essential ^-based shortcuts include:\n ⌃e moves to the end of the line. ⌃u clears to the beginning of the line from where the cursor is.  Complicated\nThe combination of ⌃a, ⌃e, and ⌃u will work on most systems, but suppose you are editing a longer line, such as this one containing the chorus of a hit song by a popular Canadian singer-songwriter of the early 2000s.\nPrinting the chorus of \u0026ldquo;Sk8er Boi\u0026rdquo;\n$ echo \u0026#34;He was a skater boy, She said see you later boy, He wasn\u0026#39;t good enough for her\u0026#34; Suppose we wanted to change the spelling of the lyrics to accurately reflect the skater punk persona of Avril Lavigne. The change we want to make is the \u0026ldquo;skater\u0026rdquo; to the phonetic \u0026ldquo;sk8er\u0026rdquo; stylized spelling. A quicker way to edit the line may be found in combining the keyboard and mouse via Option-click by holding down ⌥ and clicking the mouse pointer on the place in the command you want the cursor.\nExercises\n Using the up arrow, print to the screen the strings \u0026ldquo;do\u0026rdquo;, \u0026ldquo;re\u0026rdquo;, \u0026ldquo;mi\u0026rdquo;, \u0026ldquo;fa\u0026rdquo;, and \u0026ldquo;sol\u0026rdquo; without retyping echo each time. Starting with the chorus line of \u0026ldquo;Sk8ter Boi\u0026rdquo; above, use any combination of ⌃a, ⌃e, arrow keys, or ⌥-click to change the occurrences of \u0026ldquo;boy\u0026rdquo; to the stylized \u0026ldquo;boi\u0026rdquo; in order to complete the skater punk copy of the lyric. In other words, the argument to echo should read \u0026ldquo;He was a sk8ter boi, She said see you later boi, He wasn\u0026rsquo;t good enough for her\u0026rdquo;.  Cleaning up Two essential commands are clearing the terminal screen and exiting the terminal. Clearing the screen is a convenient practice, much like having a clean desk to work. Exiting is what Elvis Presley does after writing rock-n-roll code.\nA clean exit\n$ clear The keyboard shortcut for clear is ^l\n$ exit The keyboard shortcut for exit is ^d\nExercises\n Clear the contents of the current tab. Open a new tab, execute echo goodbye, and then exit.  Summary    Command Description Example     echo \u0026lt;string\u0026gt; Print string to screen $ echo hello   man \u0026lt;command\u0026gt; Display manual page for command $ man echo   ⌃c Get out of trouble $ tail ⌃c   ⌃a Move to beginning of line    ⌃e Move to end of line    ⌃u Delete to beginning of line    Option-click Move cursor to location clicked    ↑ or ↓ Scroll through previous commands    clear or ⌃l Clear screen $ clear   exit or ⌃d Exit terminal $ exit    Exercises\n Write a command to print the string Use \u0026quot;man echo\u0026quot;, including the quotes; i.e., take care not to print out Use man echo instead. Hint: Use double quotes in the inner string, and wrap the whole thing in single quotes. By running man sleep, figure out how to make the terminal \u0026ldquo;sleep\u0026rdquo; for 5 seconds, and execute the command to do so. Execute the command to sleep for 5000 seconds, realize that’s well over an hour, and then use the instructions from getting_out_of_trouble.  "
},
{
	"uri": "/application-security/api-security/01_service_to_service_oauth2/10_buying-beer/",
	"title": "Can I buy you a beer?",
	"tags": [],
	"description": "",
	"content": "Buying Beer with OAuth2 Buying Beer Slight Modifications From Real World  Tom starts with the license issuing station. The licenses are only good for a short amount of time (minutes to hours) The license is only good for 1 beer store.  Different Phases  (Not Shown) Onboarding Request a License Present a License Validate the License Provide the beer  Authentication vs Authorization Authentication / AuthN / Identity\n Who are you  Authorization / AuthZ / Privilege\n What are you allowed todo?  Another Mental Model: Going to the Movies For those that would like another mental model over than beer, you an think of a movie ticket:\n The Movie Buyer goes to the Ticket office and asks for a ticket for a certain movie, at a certain time. If conditions are met, then the movie ticket is issued. The ticket is self contained, it has all needed information on it. For a 100% complete example, we can imagine that the movie ticket also contains the buyer\u0026rsquo;s information such as name, etc The ticket is presented to the doorman. The doorman validates the ticket, and if good, allows entry.  "
},
{
	"uri": "/cloud/platforms/pcf-foundations/intro-to-pcf/",
	"title": "Deploying to PCF",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  What is PCF? The terms container and image in cloud technology The structure of Cloud Foundary: Foundations, Organizations, and Spaces. 12 Factor methodology for writing modern webapps Using a Platform-as-a-Service (PaaS) Managing an application on Pivotal Cloud Foundry (PCF)  Skills  How to use the cf-cli to interact with a Cloud Foundry space Configuring a manifest.yml file Creating a .cfignore file  The Twelve Factors To better understand why PCF functions the way it does, it helps to understand 12 Factor Applications.\n  Originally drafted by developers at Heroku, which is a platform-as-a-service.\n  Created as a recommendations for applications running in the cloud.\n  Apps that follow the 12 factors gain:\n Portability Resilience Scalability Maintainability  You can read more on the 12 Factors here.\nKeep these suggestions in mind when developing apps to be deployed in the cloud.\nPCF Pivotal Cloud Foundary is a distribution of the open-source Cloud Foundary platform.\nCloud Foundary is a platform-as-a-service to make application deployment simple.\nIt allows developers to focus on development by managing the following for them:\n Networking Logging Scaling Containerization Runtime Uptime  PCF creates images, which are like blueprints, instructions on how to build containers.\nContainers are instances of images. You can build many houses based off the same blueprint.\n Note: See more on containers here\n  Note: See more on the relationship of images to containers here\n Foundations, Orgs and Spaces PCF is broken down into:\n Foundations Orgs (Organizations) Spaces  The admins of a foundation can decide how to organize their foundations, orgs and spaces.\nFoundations \u0026lt; can have many orgs \u0026lt; can have many spaces.\nOrgs might be a department. Each department might have spaces for different applications or environments (staging vs. production).\nLogging Into PCF Visit https://apps.run-np.homedepot.com and log in.\nThe Instructor will create an org and space to practice in.\n Note: The apps that we deploy in this exercise cannot be expected to remain on the platform as we are deploying to a sandbox environment that gets wiped away periodically for updates and testing of the platform, itself.\n Installing the Cloud Foundry command line interface (CLI) \u0026amp; logging in If you don\u0026rsquo;t already have the cloud foundry CLI, then install it via brew with:\nbrew tap cloudfoundry/tap brew install cf-cli Ensure that it is working by running cf -h (for help) in the terminal\n Note: It doesn\u0026rsquo;t really matter from which directory you run this particular command.\n You should see a long list of commands that are worth taking some time to read through after you get your application deployed.\nLet\u0026rsquo;s login into our foundation of PCF from the command line:\ncf login -a https://api.run-np.homedepot.com\nAny cf commands you run after logging in will be executed in the foundation you provided as the API host argument above.\n Note: Email is your LDAP. Note: As you type the password, the terminal will NOT show what you\u0026rsquo;re typing.\n After you login, it will ask what to target:\n Org Space  Use the Org and Space provided by the instructor.\nTargeting Spaces and Orgs If you pressed enter without targeting an org and space, or need to change your target later, you can use the following:\n  cf target -o orgName where orgName is the name of the org you want to target.\n  cf target -s spaceName where spaceName is the name of the space you want to target.\n   Note: type cf help target in the terminal to see the manual for targeting.\n Deploying For demo purposes, we\u0026rsquo;ll use the following simple Express API\ngit clone https://github.homedepot.com/om-labs/sample-apps-pcf-deploy.git cd sample-apps-pcf-deploy cd api cf push express-api-LDAP Where LDAP is your LDAP\n Note: Be patient. This could take a few minutes.\n After a successful push, cf will report on your app, including the route to view your app.\nIn a browser, go to the route provided in the terminal and see something similar to below:\n!! Congrats, you just deployed your first remote app !!\nNow we\u0026rsquo;re going to attempt to push a static file application.\ncd ./html cf push If cf-cli failed to detect the correct buildpack, no worries. What\u0026rsquo;s a buildpack? I\u0026rsquo;m glad you asked!\nBuildpacks Buildpacks are like base images to start from. The tell CF about the environment, building, and deployment information about your app.\n Think of a buildpack as a \u0026ldquo;FROM\u0026rdquo; image in a dockerfile, if you\u0026rsquo;re familair with Docker.\n PCF will take this combination of buildpack and your custom application code and create an image. From this image, many containers can be built, thus making it easier to scale.\nNotice in the last cf push that CF attempted to autodetect the buildpack for you app.\nWe can specify the buildpack we need, which is the staticfile_buildpack.\nLet\u0026rsquo;s try pushing again, specifying the buildpack.\ncf push staticfile-LDAP -b staticfile_buildpack where LDAP is your LDAP.\n Note: to see a list of all buildpacks, visit the CF on github\n Visit the route in a browser specified after a successful push. You should see something similar to the following:\nRoutes In order to make sure we don\u0026rsquo;t conflict with others development spaces, we could use --random-route to host our app using some random words.\ncf push staticfile-LDAP-random -b staticfile_buildpack --random-route\nYou should see the random route generated in the success message in the terminal, similar to the following:\n Note: The name of the app must be changed in order for cf to accept the random-route flag\n You can visit the route given in your browser, and check the routes in PCF App Manager.\nRoute Paths There are several reason why you might have different paths on the same host application, including versioning.\nWe\u0026rsquo;re going to add a v2 version to our api.\ncd ./apiv2 cf push greeting-app-emc4jq2 -b nodejs_buildpack --route-path /api/v2 Users would now have a way to access version 1 and version 2 of our api.\nBy accessing: http://greeting-app-emc4jq2.apps-np.homedepot.com/api/v2 I can verify the path is working as expected.\nManifest.yml We can provide specific information to CF in a manifest.yml.\nLet\u0026rsquo;s add a manifest file to our static file app.\ncd ./html applications: - name: static-file-LDAP buildpack: https://github.com/cloudfoundry/staticfile_buildpack where LDAP is your LDAP.\nNow we can deploy using a simple cf push and cf will use the manifest we created to find the name of the app and the buildpack to use.\nSome other attributes you can add to your manifest.yml file:\n command - a custom start command (ie: node app.js) disk_quota - disk space to be allocated for your app instance docker - docker image being used by your app memory - memory to be allocated for all instances of your app routes - HTTP and TCP routes for your application   To see a complete list of optional attributes check out the Optional Attributes section in Cloud Foundry\u0026rsquo;s Deployment docs.\n .cfignore By default, when you cf push, all files in the application’s project directory tree are uploaded, except for the following:\n version control folders config files .cfignore _darcs .DS_Store .git .gitignore .hg manifest.yml .svn  For additional files and directories, we can use .cfignore\n.cfignore is:\n A plain text file Operates similar to a .gitignore file Causes CF to ignore patterns listed  To make our deployment cleaner, let\u0026rsquo;s add a .cfignore to our express api, and repush.\n CF will do a npm install by default. We don\u0026rsquo;t need to push up all the node_modules from our local system.\n Repush and verify the increase in speed.\nAdditional Resources  PCF Documentation PCF Checklist  "
},
{
	"uri": "/javascript/nodejs/advanced/express-and-bookshelf/",
	"title": "Express and Bookshelf",
	"tags": [],
	"description": "",
	"content": "Advanced NodeJS "
},
{
	"uri": "/javascript/foundations/",
	"title": "Foundations",
	"tags": [],
	"description": "",
	"content": "Welcome to JavaScript Foundations! "
},
{
	"uri": "/golang/foundations/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Installing Go Configuring Go Creating a Go Project Parts of a Go File Go Modes: Go Modules and GOPATH  Installation and Configuration Mac Installation brew install go or\nFollow the download instructions\nWindows Installation Follow the download instructions\nPrimary Go Environment Variables    Variable Description     GOROOT The variable that defines where your Go SDK is installed   GOPATH Run the command go help gopath for a full description   GOBIN The path that where executable binaries will be installed by default   GOOS The target OS that a go binary will be compiled for   GOARCH The target processor architecture type a go binary will be compiled for    Other Go Environment Variables To see a list of other variables execute the following command:\ngo env Get full descriptions here\nCreating a Go Project Using a command line:\n  Create a directory that you want to start your project in\nmkdir myproject   Navigate to that directory\ncd myproject   Initializing your Project The following section will be demonstrating initializing a project that will be eventually be shared on THD Github Enterprise.\nGithub Repository A Github repository can be initiated at any point in the processes. Follow your normal Github flow for creating a repository at any point before or after these steps.\nGo Mod Execute the following command, replacing \u0026lt;your-org\u0026gt; and \u0026lt;your github repo\u0026gt; with your values:\ngo mod init github.homedepot.com/\u0026lt;your org or users \u0026gt;/\u0026lt;your github repo\u0026gt; Example:\ngo mod init github.homedepot.com/om-labs/myproject What go mod init Does  Creates a file named go.mod Adds the module name to the file Sets the version of Go being used  The Module Name  Can be manually changed by editing the go.mod file Will be used by Go to determine how to import a package Will be used by Go to determine how to download your project as a dependency  Your First Go App  Create a file named main.go Open the file in your editor Add the following to your file:  package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Let\u0026#39;s Go!\u0026#34;) }  Execute command:\ngo run main.go    NOTE: go run compiles and runs the application in a single step!\n Go File Anatomy Source files all end with the extension .go and contain the following sections:\npackage main // package name: declares the package that this code belongs to  import \u0026#34;fmt\u0026#34; // import section: imports external packages to be used in the code  // Declaration section: declare variables, functions and other code for the application. const Stuff string = \u0026#34;things\u0026#34; var Greet = \u0026#34;hello\u0026#34; func main() { fmt.Println(\u0026#34;Are you ready to Go?\u0026#34;) } Main package and function  the main package  Only package that should not be named the same as its parent directory. Must contain a main function   the main function  Entry point of a go application All other code gets started from this point.    Summary In this lesson we covered:\n Installing Go Configuring Go and Go Environment Variables Creating a Go Project Creating the go.mod file The anatomy of a Go file  "
},
{
	"uri": "/javascript/performance/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "Agenda How to gather performance metrics Client-side rendering Server-side rendering Universal (isomorphic) rendering Why Universal Rendering? The current \u0026ldquo;modern\u0026rdquo; way to develop a web application uses client-side rendering. Client-side rendering allows web sites to act more like mobile applications, but can be slow.\nServer-side rendering is considered an older way to develop web applications, and offered limited interactivity. A browser had to go back to the server for every change to an application. This problem was solved by client-side rendering, but introduced a new problem: slow performance.\nThus, beginning in 2010 and entering a more stable \u0026ldquo;completed\u0026rdquo; state in 2013, Twitter and Airbnb introduced a new way to render web applications: Universal (or isomorphic) rendering. Universal rendering combines the fast performance of server-side rendering with the interactivity of client-side rendering to provide the best possible user experience for web applications which need to optimize for performance.\nWe\u0026rsquo;ll dive deeper into each rendering strategy later. First, we need a way to determine if one approach is objectively better than another. More specifically, we need a way to measure the performance of a web application.\nWhat is the \u0026ldquo;performance\u0026rdquo; of a web application? How do we define \u0026ldquo;performance\u0026rdquo;? When you visit a website, what are the events that happen that make you feel like the website has loaded?\nContent gets rendered to the page\nMany users look for content to be rendered on the page to tell them that the website has loaded. Indeed, you visit a website to view content, so it would make sense that one dimension of \u0026ldquo;performance\u0026rdquo; could be defined as the time it takes to see content on a webpage.\nThe time it takes for content to be rendered to the page is called the Time To First Paint.\nThere are many other dimensions of performance which we can measure, but for the purpose of this lesson, we will focus on Time To First Paint.\nHow do we measure performance? We are able to look at web applications and say \u0026ldquo;Gee, this is slow\u0026rdquo;, but such an analysis is subjective. What is slow to you may be considered fast by someone else.\nTime To First Paint gives us an objective measure of performance, and is broken up into two components: First Contentful Paint and First Meaningful Paint.\nFirst Contentful Paint (FCP) First Contentful Paint (hereafter referenced as FCP) is defined as the time from navigation to the time when the browser renders the first bit of content from the DOM. In simpler terms, FCP is the time that it takes for you to actually see something appear on a webpage.\nSource: https://developers.google.com/web/tools/lighthouse/audits/first-contentful-paint\nFirst Meaningful Paint (FMP) First Meaningful Paint (hereafter referenced as FMP) is defined as the time at which the user feels that the primary content of the page is visible. Essentially, the paint after which the biggest above-the-fold layout change has happened, and web fonts have loaded.\nFor example, sometimes the header of a page will load, but there will be a loading spinner in the body of the webpage. FMP measures the time that it takes for the loading spinner to disappear and be replaced by loaded content.\nSource: https://developers.google.com/web/tools/lighthouse/audits/first-meaningful-paint\nTo see the difference between First Contentful Paint and First Meaningful Paint more clearly, let\u0026rsquo;s look an example analysis of www.thehomedepot.com\nHow to measure FCP and FMP There are multiple web browsers which provide debugging tools, but will be focusing on Google Chrome for the scope of this lesson. Google Chrome has extensive documentation regarding web performance, as well as sophisticated developer tools: https://developers.google.com/web/fundamentals/performance\nMore importantly, Google Chrome currently holds a majority share of the web browser market: https://www.statista.com/statistics/544400/market-share-of-internet-browsers-desktop/\nIn the lab, we\u0026rsquo;ll practice measuring FCP and FMP for some popular web applications, as well as a web application created within The Home Depot.\n"
},
{
	"uri": "/react/performance/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "Agenda How to gather performance metrics Client-side rendering Server-side rendering Universal (isomorphic) rendering Why Universal Rendering? The current \u0026ldquo;modern\u0026rdquo; way to develop a web application uses client-side rendering. Client-side rendering allows web sites to act more like mobile applications, but can be slow.\nServer-side rendering is considered an older way to develop web applications, and offered limited interactivity. A browser had to go back to the server for every change to an application. This problem was solved by client-side rendering, but introduced a new problem: slow performance.\nThus, beginning in 2010 and entering a more stable \u0026ldquo;completed\u0026rdquo; state in 2013, Twitter and Airbnb introduced a new way to render web applications: Universal (or isomorphic) rendering. Universal rendering combines the fast performance of server-side rendering with the interactivity of client-side rendering to provide the best possible user experience for web applications which need to optimize for performance.\nWe\u0026rsquo;ll dive deeper into each rendering strategy later. First, we need a way to determine if one approach is objectively better than another. More specifically, we need a way to measure the performance of a web application.\nWhat is the \u0026ldquo;performance\u0026rdquo; of a web application? How do we define \u0026ldquo;performance\u0026rdquo;? When you visit a website, what are the events that happen that make you feel like the website has loaded?\nContent gets rendered to the page\nMany users look for content to be rendered on the page to tell them that the website has loaded. Indeed, you visit a website to view content, so it would make sense that one dimension of \u0026ldquo;performance\u0026rdquo; could be defined as the time it takes to see content on a webpage.\nThe time it takes for content to be rendered to the page is called the Time To First Paint.\nThere are many other dimensions of performance which we can measure, but for the purpose of this lesson, we will focus on Time To First Paint.\nHow do we measure performance? We are able to look at web applications and say \u0026ldquo;Gee, this is slow\u0026rdquo;, but such an analysis is subjective. What is slow to you may be considered fast by someone else.\nTime To First Paint gives us an objective measure of performance, and is broken up into two components: First Contentful Paint and First Meaningful Paint.\nFirst Contentful Paint (FCP) First Contentful Paint (hereafter referenced as FCP) is defined as the time from navigation to the time when the browser renders the first bit of content from the DOM. In simpler terms, FCP is the time that it takes for you to actually see something appear on a webpage.\nSource: https://developers.google.com/web/tools/lighthouse/audits/first-contentful-paint\nFirst Meaningful Paint (FMP) First Meaningful Paint (hereafter referenced as FMP) is defined as the time at which the user feels that the primary content of the page is visible. Essentially, the paint after which the biggest above-the-fold layout change has happened, and web fonts have loaded.\nFor example, sometimes the header of a page will load, but there will be a loading spinner in the body of the webpage. FMP measures the time that it takes for the loading spinner to disappear and be replaced by loaded content.\nSource: https://developers.google.com/web/tools/lighthouse/audits/first-meaningful-paint\nTo see the difference between First Contentful Paint and First Meaningful Paint more clearly, let\u0026rsquo;s look an example analysis of www.thehomedepot.com\nHow to measure FCP and FMP There are multiple web browsers which provide debugging tools, but will be focusing on Google Chrome for the scope of this lesson. Google Chrome has extensive documentation regarding web performance, as well as sophisticated developer tools: https://developers.google.com/web/fundamentals/performance\nMore importantly, Google Chrome currently holds a majority share of the web browser market: https://www.statista.com/statistics/544400/market-share-of-internet-browsers-desktop/\nIn the lab, we\u0026rsquo;ll practice measuring FCP and FMP for some popular web applications, as well as a web application created within The Home Depot.\n"
},
{
	"uri": "/react/pillars/advanced-react/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "Getting Started with React and Developer Tools for React.\n Topics 1. Learning Objectives 1.1. Concepts \u0026amp; Skills   2. Strategies for starting a React Project 2.1. Simple Experimental Projects 2.2. Production Worthy Projects   3. ESLint 3.1. The AirBnB Style Guide   4. Prettier 5. React DevTools - Chrome Plugin 6. Review of Stateless and Stateful Components 7. Summary 8. Resources   1. Learning Objectives 1.1. Concepts \u0026amp; Skills   List various strategies for starting a new React Project\n  Configure and use eslint for a React project\n  Configure prettier\n  Chrome Dev Tools - React Plugin\n  Review Stateless and Stateful Components\n      2. Strategies for starting a React Project 2.1. Simple Experimental Projects It is quite easy to start a simple, experimental, educational, or proof-of-concept React project. You don\u0026#8217;t need a fancy build if you are just messing around.\n     Let\u0026#8217;s use the following code to kick the tires with each of these options.\n hello-react.js const Greeting = ({name}) =\u0026gt; { return ( \u0026lt;h1\u0026gt;Hello {name}\u0026lt;/h1\u0026gt; ); } class App extends React.Component { render() { return ( \u0026lt;div\u0026gt; \u0026lt;Greeting name=\"React\" /\u0026gt; \u0026lt;/div\u0026gt; ); } } ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById('root'));         Option: Codepen\n  Codepen Example\n     Option: Stackblitz\n  Stackblitz Example\n     Option: Simple React App with No Build\n  Demo\n      Note: there are many other online tools as well.\n  2.2. Production Worthy Projects   Roll Your Own with Webpack \u0026amp; Babel\n  This is beyond our scope for now. We may revisit this later if time allows.\n     Recommended: Create React App\n      3. ESLint ESLint is a static code analyzer for JavaScript. ESLint supports hundreds of code formatting rules and can also identify potential bugs (such as unused variables) and other optimizations and best practices (such as using ES-2015 features when appropriate).\n       ESLint supports extensions for parsing, linting, and formatting (fixing) lint errors. There is an Atom ESLint plugin for reporting and fixing ESLint errors.     3.1. The AirBnB Style Guide     The best thing about standards is that there are so many of them to choose from.\n     You’re of course welcome to spend a few days exploring the JavaScript ecosystem and comparing different tools, but I’ll try and save you some time: ESLint is the most popular JavaScript linting tool, and AirBnB’s style guide is the most widely-used style guide.\n    Adding AirBnB\u0026#8217;s ESLint config is a simple process:\n yarn add -D eslint-config-airbnb   sample .eslintrc.js module.exports = { \"extends\": \"airbnb\", \"env\": { \"es6\": true, \"browser\": true, \"node\": true }, \"parser\": \"babel-eslint\", \"rules\": { \"no-console\": 0, \"no-plusplus\": 0, \"react/forbid-prop-types\": 0, \"comma-dangle\": 0, \"react/jsx-filename-extension\": [\"error\", { \"extensions\": [\".js\", \".jsx\"] }], 'arrow-parens': ['error', 'as-needed', { requireForBlockBody: false, }], \"object-curly-newline\": [\"error\", { \"ObjectExpression\": { \"consistent\": true }, \"ObjectPattern\": { \"consistent\": true } }] }, \"plugins\": [ \"react\", \"jsx-a11y\", \"import\" ] };      4. Prettier   Prettier Atom Plugin\n  install with apm install prettier-atom\n  Invoke manually using the keyboard shortcut Ctrl+Alt+F\n  If no selection, whole file is formatted\n     demonstrate examples w/o prettier first\n  how to config\n  how to setup with your editor\n     5. React DevTools - Chrome Plugin Demonstrate with Kitchen Timer component.\n   6. Review of Stateless and Stateful Components At the most basic level there are 2 types of React components: stateless (presentational) and stateful (container) components.\n Table 1. React Component Types     Type Description     Presentational / Stateless\n gets all of its data from props that are passed in from a parent component.\n   Container / Stateful\n manages internal state data as well as receiving props data from a parent component.\n    \n   7. Summary It\u0026#8217;s easy to get started with React. For quick experimentation you can use online sites like Codepen and Stackblitz. For more production worthy projects, it doesn\u0026#8217;t get any better than Create React App.\n Keeping source code consistent and well formatted is important for readability and collaboration. ESLint and the AirBnB style guide are a great start and also help with learning new JavaScript features and identifying potential bugs.\n For debugging, the React DevTools Chrome plugin is an excellent tool for inspecting component state and props and (as always) setting breakpoints and stepping through code.\n   8. Resources   Codepen\n  Stackblitz\n  Simple React App with No Build\n  Webpack\n  Babel\n  Create React App\n  eslint\n  airbnb styleguide for javascript and react\n  Atom eslint plugin\n  Prettier Atom Plugin\n     "
},
{
	"uri": "/software-eng-essentials/looker/getting-started/",
	"title": "Getting Started with Looker",
	"tags": [],
	"description": "",
	"content": "This lesson will cover the basics of finding and using reports in Looker.\nObjectives  Logging in and finding content How to find reports Filter the data you see in reports  Structure of Looker A LookML project is a collection of LookML files that describes a set of related models, views, Explores, and (optionally) LookML dashboards.\n  A LookML project can be made up of:\n views models LookML dashboards  Models A model contains information about which tables to use and how they should be joined together. The model is composed of:\n An Explore serves as the starting point for a query in the Looker application. Explores reference views and each Explore can contain joins to other views.  Explores are often defined within a model file, but sometimes you need a separate Explore file for a Native derived table (NDT), or to extend or refine an Explore across models.   A join is used to combine data from multiple views.  Views A view contains information about how to access or calculate information from each table (or across multiple joined tables).\nThe view is dimensions, measures, field sets:\n Dimensions (gray), which can be thought of as groups or buckets of data. This data can be:  an attribute, which has a direct association to a column in an underlying table a fact or numerical value a derived value, computed based on the values of other fields in a single row   Measures (orange), which tells information about those buckets. Measures:  use SQL aggregate functions, such as COUNT, SUM, AVG, MIN, or MAX can be fields computed based on the values of other measure values can be used to filter grouped values. For example, measures for a Sales view might include total items sold (a count), total sale price (a sum), and average sale price (an average).   Field Sets: a list of field (dimension, measure, and filter) names. Sets are used to tell Looker which fields:  You want to show when drilling into a count or other measure To import when joining a view Are indexed in an Explore    LookML Dashboards A Looker dashboard is a collection of queries displayed as visualizations on a page. Dashboards let you combine key queries and visualizations into a one page executive view.\n Here is the documentation on LookML dashboards\n Navigating Home Depot\u0026rsquo;s Looker To log into a user\u0026rsquo;s Home Depot\u0026rsquo;s Looker account, go to homedepot.looker.com.\n In order to get access to an account, submit an ARP request for gg_cloud_gcp-io1-datalake-views_user.\n Once logged in, a user is taken to a page with shared folders listed on the main part of the page and \u0026ldquo;quick links\u0026rdquo; to different folders, boards, and looks on the left.\nEach folder could have several layers of subfolders, depending on how the team has them set up. Clicking on a folder shows the dashboards and looks.\nPersonal Folder A user\u0026rsquo;s personal folder is where THD recommends users put in progress work before moving it to a team folder. The quick link on the left opens user\u0026rsquo;s personal folder.\n(In this previous image, this is called My folder)\nManaging Access It is possible to give read-only or editing access to others, such as a manager or a teammate, to a folder and its contents.\nIn folders that a user has editing rights to there is a manage access button at the top right.\nOnce a user is given access, any new boards, looks, dashboards or subfolders that are created inside that folder will be granted the same amount of access.\nTo create a new sub-folder or a dashboard, click the New button in the top right corner of a folder that a user has editing rights to.\nFoundational Terminology Looks Looks are the saved visualizations that can be created in the Explore section of Looker and are used to understand and analyze the data. These Looks can be shared and reused in multiple other dashboard implementations. More uses of Looks are going to be explained below.\nBoards Boards in Looker provide a way for teams to find curated dashboards and Looks. Dashboards and Looks, which are stored in folders, can be pinned to multiple boards.\nBoards provide a way for users to pin Looks and dashboards to boards to make it easier for users to find the information most relevant to them.\nTo create a board, click on the + next to Boards in the left menu.\n  A user would then be prompted to name the board.\nA board consists of one or more sections. Each section will contain Dashboards and/or Looks.\nDashboards Dashboards allow users to place multiple tables or graphs on one page, giving a quick view of related content. It is possible to make dashboards interactive, so that users can filter them down to the specific data they are interested in.\nTo use a filter that was enabled on a particular dashboard, click on a specific cell in a table or a part of a graph which will pop up a dropdown with filter options.\nFilter options can be either to show another dashboard with more specific details or a data set about the data that was clicked.\nData Set A set is a user-defined list of fields in one place that can be reused as many times as needed. Once a data set is saved, it is possible to reuse in the form of an Explore. (To be explained later)\nExample: Viewing an Existing Dashboard Click here to view an actual dashboard used at The Home Depot. This example dashboard has been set up to have the graphics on the left side and the tables with data on the right.\nClicking on a cell in the Role column of the Store Workstations By Day table will pop up Filter Results By Rollv2.\nClicking on Filter Results By Rollv2 is an example of a filter not technically \u0026ldquo;filtering\u0026rdquo; data, but showing a more specific dashboard about that data.\nIn this more specific dashboard, if a user clicks on any part of the graph, that user is now taken to a data set that created that graph.\nExplore An Explore is a starting point for a query, designed to explore a particular subject area.\nTo access the Explore page, click on the Explore menu at the left of any page on Looker:\n  This Explore menu is used to search for and select a pre-defined Explore. An example:\n  Spoke and Hub Model Throughout the lessons, the terms Spoke and Hub will pop up.\nThe general concept of spoke and hub is that there is a hub model which contains validated central business logic that can then be imported and further built upon in the spoke models. The spokes themselves utilize the central hub for their own liking and have the flexibility to quick build and prototype their own models while keeping the main hub under control and unaffected by their changes.\n The hub is used if there is a modification that needs to be made at the global level since it will automatically update the spoke level The spoke is used if an individual developer wants to just update data that they are using.  The examples in this lesson have been using the ITO (Information Technology Operations) hub for the CF (Cloud Foundry) App logs. This is the first or initial breakdown of the information that comes in. From there, the ITO spoke is provided so developers can develop the dimensions from there and add measures so that they individualize and update their information as they see fit.\nThese will be covered in more detail in the advanced class.\nLabs Use the following training and labs to get an introduction to Looker. This will give plenty of information and practice for finding and using already created reports in Looker:\nQwik labs: Exploring data with Looker Will need to register, it is free though\n At this point, just do Looker Data Explorer - Qwik Start and Filtering and Sorting Data in Looker  Once the above labs have been completed, go to the below sections to get some practice with Home Depot\u0026rsquo;s Looker.\nSummary This lesson covers:\n basic terminology for Looker was covered such as: Look, dashboard, and tile. basic usage for Looker by interacting with an existing Dashboards.  "
},
{
	"uri": "/software-eng-essentials/git-pillars/plumbing/",
	"title": "Git Plumbing",
	"tags": [],
	"description": "",
	"content": "Git Plumbing Just what does git do? What makes a git repository? Where is this “git database” you speak of…\nGit uses a Content-addressable file system - Method of storing information so that it may be retrieved based on its content.\n$ ls -la .git total 144 drwxr-xr-x 15 LDAP staff 480 Aug 30 16:12 . drwxr-xr-x 8 LDAP staff 256 Aug 30 10:15 .. -rw-r--r-- 1 LDAP staff 10 Aug 30 09:29 COMMIT_EDITMSG -rw-r--r-- 1 LDAP staff 278 Aug 30 09:25 FETCH_HEAD -rw-r--r-- 1 LDAP staff 34 Aug 30 16:12 HEAD -rw-r--r-- 1 LDAP staff 41 Aug 30 09:25 ORIG_HEAD -rw-r--r-- 1 LDAP staff 412 Aug 30 09:31 config -rw-r--r-- 1 LDAP staff 73 Aug 24 09:43 description drwxr-xr-x 14 LDAP staff 448 Aug 24 09:43 hooks -rw-r--r-- 1 LDAP staff 41760 Aug 30 16:12 index drwxr-xr-x 3 LDAP staff 96 Aug 24 09:43 info drwxr-xr-x 4 LDAP staff 128 Aug 24 09:43 logs drwxr-xr-x 19 LDAP staff 608 Aug 30 09:29 objects -rw-r--r-- 1 LDAP staff 300 Aug 24 09:43 packed-refs drwxr-xr-x 5 LDAP staff 160 Aug 24 09:43 refs  Be sure to run brew install tree on your machines as this is not a pre-packaged feature.\n Here\u0026rsquo;s a quick cheat sheet for you:\n   Name of Git Command Purpose Notes     git init initialize a git repository N/A   git hash-object -w \u0026lt;fileName\u0026gt; save given file to git database This is essentially what the git add \u0026amp; commit commands are doing under the hood   git cat-file -p \u0026lt;SHA Hash\u0026gt; inspect git file The argument -p stands for pretty, as in human readable   git cat-file -t \u0026lt;SHA Hash\u0026gt; inspect git file type The argument -t stands for type. It will return a blob, commit, tree or tag.   git update-index --add \u0026lt;path to file\u0026gt; add a file to the index This command will add the file to the staging area   git ls-files --stage examine all files in the staging area N/A   git write-tree Write a tree object based on the index file This will add the tree to the staging area   find .git/objects -type f List all of the objects in your git database This command, if run from the root of your repo, will show all objects in the git database.   git log --state \u0026lt;SHA HASH\u0026gt; run a git log on a commit object Show log information for a commit object   echo 'message here' git commit-tree  write a commit message and create commit    SHA1 why not be MORE secure?  Is Git Secure? Should it be MORE secure? What\u0026rsquo;s a SHA1 (and is it pronounced Sha-one or shown?)  In cryptography, SHA-1 (Secure Hash Algorithm 1) is a cryptographic hash function which takes an input and produces a 160-bit (20-byte) hash value known as a message digest - typically rendered as a hexadecimal number, 40 digits long.\nIt\u0026rsquo;s important to remember that GitHub did not come before Git\u0026hellip; Git was created to be a local version control system.\nWhat are the 4 git objects?\n Blob: A blob object actually contains the data that resides inside the file. Tree: A tree object defines which files were physically included in the commit when it was added to the database. Commit Objects: A commit object is an object that describes a specific point in time (a snap shot). Annotated Tag: Tagging message that allows a good amount of detail.   How git saves files Exercise Making tree objects Exercise  DAG vs DELTA A directed acyclic graph (DAG) is a directed graph that contains no cycles. A rooted tree is a special kind of DAG and a DAG is a special kind of directed graph.\nFor example, a DAG may be used to represent common subexpressions in an optimizing compiler.\nTo see the SHA of each commit, type git log.\nExample Output:\ncommit a8f97fb59060f6b2fc83d7dc8410512b031ff6ad (HEAD -\u0026gt; addressing-issues, origin/96-postgres, 96-postgres, 111-git-pillar-slides) Author: Homer \u0026lt;homer@homedepot.com\u0026gt; Date: Mon Aug 30 09:29:39 2021 -0500 Fixes #96 commit b0ce30861e4215bcdf5f873d62da2c09a64799f3 (origin/master, origin/HEAD, master) Author: Homer \u0026lt;homer@homedepot.com\u0026gt; Date: Fri Jul 30 07:27:26 2021 -0500 Reordering curriculum based on workshop finds (#108) git is essentially file storage. It uses ZLIB to compress file content:\nsha1( meta data commit message committer commit date author authoring date Hash-Of-Entire-Working-Directory ) Commit Objects Exercise\ngit Reference Exercise\n"
},
{
	"uri": "/javascript/foundations/labs/hello-js-lab/",
	"title": "Hello JavaScript Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Setup Create a directory for your labs for this course:\ncd $HOME mkdir js-foundations cd js-foundations mkdir labs cd labs Step 2: Create a JavaScript file and add some code touch hello.js With your text editor, add the following to hello.js:\nconsole.log(\u0026#39;Hello, JavaScript\u0026#39;); console.log(6+8); console.log(\u0026#39;The sum of 7 + 2 =\u0026#39;, 7+2); Step 3: Execute the program node hello.js You should see the following output:\nHello, JavaScript 14 The sum of 7 + 2 = 9 "
},
{
	"uri": "/react/foundations/labs/lab-hello-react/",
	"title": "Hello React",
	"tags": [],
	"description": "",
	"content": "Lab: Create your own \u0026ldquo;Hello World\u0026rdquo; React App Create a React app that introduces you.\n Use create-react-app to generate a new application Replace the existing code in src/App.js with:  A Header displaying your name An unordered list with your favorite movies, books, and/or tv shows    "
},
{
	"uri": "/web-essentials/internet/",
	"title": "How the Internet Works",
	"tags": [],
	"description": "",
	"content": "Computers and Network Communication "
},
{
	"uri": "/web-essentials/webmastery-foundations/html-intro/",
	"title": "HTML Intro",
	"tags": [],
	"description": "",
	"content": "  Learning Objectives Concepts  Explain the various parts of an HTML document, including:  the \u0026lt;head\u0026gt; and \u0026lt;body\u0026gt; tags container elements such as \u0026lt;div\u0026gt;, \u0026lt;header\u0026gt;, \u0026lt;footer\u0026gt;, \u0026lt;section\u0026gt;, and \u0026lt;article\u0026gt; common elements such as \u0026lt;h1\u0026gt;, \u0026lt;h2\u0026gt;, \u0026lt;p\u0026gt;, \u0026lt;ul\u0026gt;, and \u0026lt;li\u0026gt;   Explain the difference between HTML and the DOM  Skills  Build a simple web page using HTML Use Chrome\u0026rsquo;s Dev Tools to inspect the DOM  History   In November of 1989 Tim Berners-Lee connected Hypertext, the Transmission Control Protocol (TCP), and the domain name system ideas to create the World Wide Web to help facilitate the sharing and updating of information among researchers. He implemented the first successful communication between a Hypertext Transfer Protocol (HTTP) client and server via the Internet.\n  What is HTML? HTML stands for \u0026ldquo;Hyper Text Markup Language\u0026rdquo;. It is not a general purpose programming language like JavaScript or Ruby but rather a markup language, i.e. a language for representing structured text.\nHTML is the skeleton of a website. It is the structured content of the website. HTML uses tags and attributes to describe the document.\nSome tags in the HTML code, such as \u0026lt;head\u0026gt; and \u0026lt;body\u0026gt;, are not visible on the web page, but do contribute to the structure of the document.\nThe \u0026lt;head\u0026gt; section is for metadata and the \u0026lt;body\u0026gt; section is for the visible content of the web page.\n\u0026lt;!doctype html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;!-- document metadata goes here. --\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- document contents go here. --\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Basic Structure of an HTML Document  \u0026lt;!DOCTYPE html\u0026gt;: informs the browser that this file is an HTML file \u0026lt;html\u0026gt;...\u0026lt;/html\u0026gt;: contains your html content - it will tell the browser that everything within these tags should be interpreted as HTML.  Hierarchical Structure HTML Documents have a hierarchical structure, that can be compared to a family tree.\n \u0026lt;html\u0026gt; is considered the root element  \u0026lt;head\u0026gt; and \u0026lt;body\u0026gt; are the children of the \u0026lt;html\u0026gt; element   Children elements are nested inside of parent elements  Elements nested at the same level are called sibling elements In this case, \u0026lt;head\u0026gt; and \u0026lt;body\u0026gt; could be considered siblings     Proper indentation is vital in order to maintain a clear view and understanding of relationships between elements.\n HTML tags \u0026lt;head\u0026gt; tag The head tag is important for search engines, as it helps provide additional information about the website. Anything within the \u0026lt;head\u0026gt; and \u0026lt;/head\u0026gt; tags will NOT be displayed on the page.\n\u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Page\u0026#39;s title\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;description\u0026#34; content=\u0026#34;...\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;keywords\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;head\u0026gt; goes right after the opening \u0026lt;html\u0026gt; tag and before the opening \u0026lt;body\u0026gt; tag.\n\u0026lt;body\u0026gt; tag The \u0026lt;body\u0026gt; element contains the content that users will see and ultimately interact with.\nThe following is a body tag (that would go directly after the closing head tag \u0026lt;/head\u0026gt;) with a simple header (\u0026lt;h1\u0026gt;).\n\u0026lt;body\u0026gt; \u0026lt;h1\u0026gt; Hello World \u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; HTML Elements It\u0026rsquo;s important to understand the difference between a tag and element. Though the words are often interchangeable, there is a distinct difference.\nAn HTML Element is comprised of:\n opening html tag content closing html tag  Self-closing elements, such as \u0026lt;link/\u0026gt;, \u0026lt;img/\u0026gt;, \u0026lt;br/\u0026gt;, etc., are an exception to these requirements and do not need content to be considered an element.\n   Go to Create a Hello World Lab    Common HTML Elements Meta Tags    Element Description Example     \u0026lt;link\u0026gt; self closing element that loads a CSS file \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;/css/app.css\u0026quot;\u0026gt;   \u0026lt;script\u0026gt; loads a JavaScript file or for embedding JavaScript code. \u0026lt;script src=\u0026quot;/js/app.js\u0026quot; charset=\u0026quot;utf-8\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;    Containers    Element Description     \u0026lt;head\u0026gt; contains metadata about the page, including the title, links to external stylesheets, js files, google fonts, etc, and other meta tags.   \u0026lt;body\u0026gt; contains the body of the page; i.e. what gets displayed.   \u0026lt;div\u0026gt; a container used for grouping child elements. DIVs are block elements that take up the whole width of the page unless specific style is applied to them to do otherwise. They can contain paragraphs, headings, text, images, other divs, etc.   \u0026lt;ul\u0026gt;...\u0026lt;/ul\u0026gt; an unordered list of \u0026lt;li\u0026gt; elements (bullet points)   \u0026lt;ol\u0026gt;...\u0026lt;/ol\u0026gt; an ordered list of \u0026lt;li\u0026gt; elements (numbered)    Content    Element Description     \u0026lt;p\u0026gt;...\u0026lt;/p\u0026gt; a simple paragraph   \u0026lt;span\u0026gt;...\u0026lt;/span\u0026gt; inline element, allows us to isolate text   \u0026lt;h1\u0026gt;...\u0026lt;/h1\u0026gt; Level 1 heading (Largest header font)   \u0026lt;h6\u0026gt;...\u0026lt;/h6\u0026gt; Level 6 heading (Smallest header font)   \u0026lt;li\u0026gt;...\u0026lt;/li\u0026gt; elements within list tags   \u0026lt;img src=\u0026quot;url\u0026quot; alt=\u0026quot;description\u0026quot;/\u0026gt; self-closing image tag that includes the path of the image and a description (alt) for the search engines.   \u0026lt;a href=\u0026quot;url\u0026quot;\u0026gt;...\u0026lt;/a\u0026gt; hyperlink to another page; href is the url to link to. Adding target=\u0026quot;_blank will open the link in a new tab in the browser. Images can go within \u0026lt;a\u0026gt; tags to make it a link.    For a full list of HTML tags, see HTML Element Reference.\nPlacing an image element within an anchor element makes the image clickable. The following makes the image \u0026ldquo;clickable\u0026rdquo; and redirects to the W3 website:\n\u0026lt;a href=\u0026#34;www.w3.org\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;https://en.wikipedia.org/wiki/File:Sir_Tim_Berners-Lee.jpg\u0026#34; alt=\u0026#34;A picture of Tim Berners-Lee!\u0026#34; /\u0026gt; \u0026lt;/a\u0026gt; Styled Text These tags can be used to set a specific style to text in an HTML document.\n TIP: CSS should be used for styling, not these tags.\n    Element Description     \u0026lt;b\u0026gt;...\u0026lt;/b\u0026gt; makes the wrapped text bold   \u0026lt;strong\u0026gt;...\u0026lt;/strong\u0026gt; similar to bold, the browser interprets this as an important bit of text, directing the reader\u0026rsquo;s attention to it.   \u0026lt;i\u0026gt;...\u0026lt;/i\u0026gt; makes the wrapped text italic.   \u0026lt;em\u0026gt;...\u0026lt;/em\u0026gt; similar to italic, emphasizes on a word.   \u0026lt;br /\u0026gt; self-closing tag, breaking the content.       Go to Create a Simple Web Page Lab    Creating a table in HTML The \u0026lt;table\u0026gt; tags are used to display tabular data.\n   Element Description     \u0026lt;table\u0026gt;...\u0026lt;/table\u0026gt; contains the table data, and defines the table structure   \u0026lt;thead\u0026gt;...\u0026lt;/thead\u0026gt; the head of the table (bolder text) - optional   \u0026lt;tr\u0026gt;...\u0026lt;/tr\u0026gt; defines a row   \u0026lt;th\u0026gt;...\u0026lt;/th\u0026gt; defines a cell within that row   \u0026lt;tbody\u0026gt;...\u0026lt;/tbody\u0026gt; the body of the table    Table Example:\n\u0026lt;table border=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Date\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Weight\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Distance walked\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;September 15\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;75 kg\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;1.8 km\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;September 29\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;73 kg\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;2.1 km\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; In our browser, we get:\n   Date Weight Distance Walked     September 15 75 kg 1.8 km   September 29 73 kg 2.1 km    Avoid Using HTML Tables for Layout Don\u0026rsquo;t use tables to define the layout of a page!\n This is a very old and outdated technique. It results in a poor overall design that is not easily styled with CSS and is not responsive to varying screen sizes.  Google Chrome Developer Tools The Chrome Developer Tools is available as a console in Google Chrome. It can be used to get a lot of information about a webpage, providing a detailed look into the HTML structure of the page and the CSS styling, among other things.\nIn Chrome, you can access it with Cmd+Alt+i, or right-click an element on the web page and select \u0026ldquo;Inspect element\u0026rdquo;.\nThe \u0026ldquo;Elements\u0026rdquo; tab shows the page structure and specific elements within the page.\nCSS properties that are currently applied to the elements can also be seen and temporarily changed \u0026ldquo;live\u0026rdquo; (changes only apply to the page as displayed - it will not be saved anywhere, and all these changes disappear on the next page reload).\nMore on this in the CSS chapter.\nSummary  HTML is a markup language for representing structured text The two primary children of the html element are:  \u0026lt;head\u0026gt; - Metadata for search engines, linked files, etc. \u0026lt;body\u0026gt; - Content that is visible to the user   The HTML tag is used to define how your web browser will format and display content An HTML element is a combination of tags and content     Go to HTML Intro Labs    "
},
{
	"uri": "/web-essentials/internet/how-internet-works/",
	"title": "Inner Workings of the Web",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Describe the basics of how computers communicate Name 4 ways that computers share data Define the following concepts:  Internet IP Address  IPv4 and IPv6 addresses static and dynamic dotted decimal notation   port socket Internet Domain URL Messages and Packets Communication protocols  IP TCP UDP HTTP lots of others   Routes LAN and WAN ping command ifconfig / ipconfig commands DNS MIME Types RESTful Web Services    What is the Internet?  The internet is a network of interconnected computers that communicate over a given set of communication protocols. So what is a communication protocol?\n Communication Protocol\nA communication protocol is a standard set of rules that allow electronic devices to \u0026gt; communicate with each other.\nThe protocol defines the rules, syntax, semantics and synchronization of communication and possible error recovery methods.\n How Do Computers Share information / Communicate? In general, computers can communicate in one or more of the following ways:\n Shared file systems Shared databases Remote Procedure Calls (RPC) - sync Messages - async  With the internet, computers are generally using methods 3 (less common) or 4 (more common).\nFor computers to communicate directly (for RPCs or sending Messages), they need to have a addresses.\nComputer Addresses Computer addresses are similar to addresses we use for sending mail, packages, or even calling someone\u0026rsquo;s phone.\nIf you want to send someone a letter or a package, you need their shipping (street) address. If you want to call someone\u0026rsquo;s phone, you need to know their phone number. In both of these examples the address must uniquely identify the destination of the letter, package, or phone call.\nA computer connected to the internet must have a numeric addresses called IP (Internet Protocol) address. An example IP address is: 74.125.21.113. This address is in dotted-decimal notation but can also be represented in binary notation or hexadecimal notation.\nExample of IP Address:\n   Notation Example     dotted-decimal 74 . 125 . 21 . 113   binary 01001010 01111101 00010101 0111001   hexadecimal 4A 7D 15 71    IPv4 and IPv6 Given that every computer connected to the internet needs to have a unique address, how many addresses do we need?\nIPv4 (version 4 of the Internet Protocol standard) defines an IP address to have 32 bits, which gives us 2^32 or roughly 4 billion unique addresses (2^32 = 2^10 * 2^10 * 2^10 * 2*2 = 1024 * 1024 * 1024 * 4 = 4294967296).\nBut we now have more than 4 billion computing devices! Just think how many computing devices you have (laptops, desktops, smart phones, streaming devices such as Apple TV, etc.). Also think about how many computing devices we have at The Home Depot. You can easily see how the world now has more than 4 billion computing devices connected to the internet.\nSo we need more bits to address all of these devices.\nEnter IPv6 IPv6 (version 6 of the Internet Protocol standard) increases the number of bits for addresses to 128 bits. That means we now have 2^128 unique addresses! That is a huge number equal to:\n2^10 * 2^10 * 2^10 * 2^10 * 2^10 * 2^10 * 2^10 * 2^10 * 2^10 * 2^10 * 2^10 * 2^10 * 2^8 This means that using IPv6 we can assign 100 unique addresses to every atom on the surface of the earth. So it looks like we have enough bits now.\nTry running the following command on your Mac to see what your IP addresses are:\nifconfig | grep inet You should see output that looks similar to the following:\ninet 127.0.0.1 netmask 0xff000000 inet6 ::1 prefixlen 128 inet6 fe80::1%lo0 prefixlen 64 scopeid 0x1 inet6 fe80::faab:c1c:efae:f6ca%utun0 prefixlen 64 scopeid 0x11 inet6 fe80::aede:48ff:fe00:1122%en5 prefixlen 64 scopeid 0x8 inet6 fe80::10c2:d0f6:403:b25a%en9 prefixlen 64 secured scopeid 0x7 inet 172.19.24.138 netmask 0xffffff00 broadcast 172.19.24.255 The inet addresses are IPv4 (32 bit) addresses shown in dotted-decimal notation. The inet6 addresses are IPv6 (128 bit) addresses (however in the above example the IPv6 addresses are link-local addresses that do not have the full 128 bits, for more information see: Link-local address).\nStatic vs. Dynamic IP Addresses When a device is assigned a static IP address, the address does not change. Most devices use dynamic IP addresses that are assigned by the network when they connect and can change over time.\nServers often need a static IP address so that clients can communicate with them. Conversely the client devices (such as laptops and smart phones) can use a dynamic IP address because they will send their address to the server when they initiate a request.\nWhat is a URL? The term URL is short for Uniform Resource Locator. A URL is a globally unique name for a resource (often a web page) on the world wide web. Sometimes a URL are also referred to as a \u0026ldquo;web address\u0026rdquo;.\nThe structure of a URL is: scheme://domain:port/path?query_string#fragment_id\nHere is an diagram showing the parts of a URL:\nTry the following example in your browser: http://www.google.com:80/search?q=taylor+swift\nThis example shows that Google has chosen to represent all searches as URLs (which is nice because the search can be shared or bookmarked).\nLAN vs. WAN  Local Area Networks  can have a private set of addresses: 16-bit LAN addresses: 192.168.0.0 24-bit LAN addresses: 10.0.0.0    ping google.com ifconfig | grep inet PING google.com (74.125.196.101): 56 data bytes 64 bytes from 74.125.196.101: icmp_seq=0 ttl=44 time=15.184 ms Browser URL - http://74.125.196.101/\nIP = Internet Protocol Lab Time - Play the IP and TCP Game (Meet Ivan Pakkitz) Ivan is a postal worker who can travel at the speed of light. He\u0026rsquo;s happy to relay thousands of messages per second between you and a friend. However, he can only transport one message at a time and each message has to fit on a single index card.\nUnfortunately Ivan is incredibly inattentive, so there are a few minor limitations in his service:\n Reliability: He cannot guarantee that every message will be delivered successfully. Order: He cannot guarantee delivered messages will arrive in the same order that they were sent. Integrity: He cannot guarantee that all messages will arrive in their entirety. Recipient: He cannot guarantee that messages will always be delivered to the correct recipient.  For our lab, we will assume that Ivan:\n shuffles the cards before delivering them sometimes drops a card on the floor (maybe 1 out of 10 cards) may rip the card in half before delivering it (maybe 1 out of 20 cards) may deliver the card to the wrong person (maybe 1 out of 20)  Debbie N. Smith  She knows the numeric address of everyone  Circuit vs. Packet Switching   Circuit Switching\n think making a phone call what does it mean to get a \u0026ldquo;fast busy\u0026rdquo; signal?    Packet Switching\n think sending packages via FedEx Question: If I send 5 packages to Gerry, will all 5 packages a. arrive in the order I sent them? b. arrive via the same truck? c. arrive via the same route? d. does it matter?    Which is Faster?\n  Which is More Fault Tolerant?\n  Messages and Packets  Packets have a fixed maximum size (no 18 wheelers please)  theoretical maximum size of a TCP packet = 64KB but usually the limit is smaller the MTU (Maximum Transmission Unit) for Ethernet, for instance, is 1500 bytes   Thus a single message is often split across several packets For example, the request for a 300KB image would require 300 * 1024 / 1500 = 205 packets.  What is a route? DNS - It\u0026rsquo;s similar to the Yellow Pages Phone Numbers I know your name but need to lookup your phone number.\nMapping Names to Phone Numbers =\u0026gt; Phone Book, Rolodex, Contact List\nExample: (1) 404-1234567\n1 = country code 404 = area code 1234567 = phone number Internet Addresses I know your DNS name (google.com) but need to lookup your IP address\nMapping domains to IPs =\u0026gt; Domain Name Service\nExample: mail.google.com\nmail = subdomain google = 2nd level domain com = top level domain The Protocols TCP = Transmission Control Protocol Builds upon the foundation of IP:\n Adds reliability (handshakes to confirm receipt, can resend on failure) Reorders out-of-order packets Checks message integrity Controls network congestion  TCP is great for plain text messages like web content, e-mails, and IMs.\nUDP = User Datagram Protocol  Favors speed over integrity Uses ports, but eliminates TCP\u0026rsquo;s integrity checks.  UDP is great for streaming videos and game data feeds where bulk speed is more important than occasional packet loss.\nHTTP - HyperText Transport Protocol  Leverages TCP for sending text and file content with integrity. Defines a new format for addressing higher-level applications. HTTP Requests (verbs) - GET, PUT, POST, DELETE, PATCH  Packets  Packet: a discrete chunk of data transferred over an IP-based protocol. Header: meta data to address and define the packet content. Body: the data payload of the packet.  Ports - like a telephone extension Some Common Default Ports:\nFTP: 20 SSH: 22 TELNET: 23 SMTP: 25 Simple Mail Transfer Protocol (email) DNS: 53 HTTP: 80 POP2: 109 Post Office Protocol (email) POP3: 110 Post Office Protocol (email) SQL: 118 IMAP: 220 Internet Message Access Protocol (email) LDAP: 389 Lightweight Directory Access Protocol SHTTP: 443 Secure HTTP (HTTP over SSL) RSH: 514 Remote Shell IPP: 631 Internet Printing Protocol Socket: the combination of an IP address and a Port Hint: think of an IP address as something like a telephone number and the port as an extension\nExamples:\n127.0.0.1:3000 port 3000 on the internal loopback address localhost:3000 port 3000 on the internal loopback address 74.125.196.101:80 port 80 (the HTTP port) at google.com Asynchronous Request / Response   Synchronous: phone conversation\n establishes a dedicated connection (circuit switching)    Asynchronous: email, text message\n sends messages back and forth (packet switching)    MIME Types (Multipurpose Internet Mail Extensions) Examples  Text (document) XML JSON  MIME Type Categories  Application - pdf, javascript, json, zip Audio - mp3, mp4 Image - jpg, gif, png Text - css, csv, html, plain, xml Video - avi, mpeg, mp4, quicktime Vendor - prefix with vnd - vnd.ms-excel  The RESTful approach The RESTful approach is a methodology for for using HTTP and URLs to create modern and easy-to-use Server APIs. REST stands for Representational State Transfer and was created by Roy Fielding for his Ph.D. thesis. It was a response to the over-engineering of creating custom protocols (CORBA, SOAP) for creating server APIs. Roy was basically saying \u0026ldquo;you can do what you need with HTTP and URLs, you don\u0026rsquo;t need to invent another protocol on top of that.\u0026rdquo;\nSince the internet provides:\n Packetized TCP/IP messages with guaranteed delivery and integrity checks. HTTP methods such as CREATE, PUT, POST, DELETE (and sometimes PATCH). URLs for defining the address of a specific resource (such as a list of movies playing at the local movie theater).  Then REST is an approach for using HTTP to do CRUD-like operations between a web client and a web server.\nWith REST we have:\n client/server separation of responsibilities  client manages user state and user interface server keeps persistent data and provides security   stateless: all of the needed state is transferred to the client so that the server can be stateless the URL represents the unique identity of the resource the client can send specific HTTP requests to the server with a payload of the state needed to fulfill the request   It may help to think of the HTTP method (GET, PUT, POST, DELETE) as the verb or action being performed and the URL as the noun (i.e. the address of the object being acted upon).\n RESTful Routing for CRUD Operations    Resource GET PUT POST DELETE     Collection /todos/ get a list of items replace the entire collection add an item to the collection delete the entire collection   /todos/3 get an item replace an item (i.e. save) NA delete the item    Notes:\n The cells with gray backgrounds are seldom used GET is immutable PUT and DELETE are idempotent PATCH is the new kid on the block and allows for partial updates (i.e. the client can send only the parts of the item that need to be updated and the server merges these with the current item state)  Related Topics  The Internet of Things Browsers, Web Servers, and Database Servers  Tracing a request / response through the 3 tiers: browser, web server, and database    Summary The internet rocks! It\u0026rsquo;s awesome because it is the backbone of the World Wide Web, connecting billions of people to each other and to an incredible amount of information unprecedented in human history.\nFirst there was the printing press, then there was the Internet and the WWW!\nAdditional Resources  How The Internet Works How the Domain Name System (DNS) works and how you can make it better.  "
},
{
	"uri": "/cloud/containers/developing-with-docker/int-testing/",
	"title": "Integration Testing",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Integration Testing with Docker Course Offerings "
},
{
	"uri": "/cloud/containers/docker-fundamentals/containers-and-virtualization/",
	"title": "Intro to Containers and Virtualization",
	"tags": [],
	"description": "",
	"content": "Concepts    Explain the purpose of a Virtual Machine Explain the purpose of a Container Identify the differences between Virtual Machines and Containers List some advantages of using Containers over Virtual Machines  A Little History To best understand containers we need to first look at the history of virtualization, data centers, and cloud computing.\nDedicated Servers Before virtualization, applications were deployed directly to physical servers, often running in a data center. Thus specific severs were dedicated to running specific applications.\nHere is an illustration of how small, medium, and large applications were deployed to dedicated servers in a data center.\n  The advantage of this approach is that it was simple to get up and running. But there were several challenges, such as:\n under-utilized servers difficulty of high availability, site reliability, and scalability  Virtual Machines became popular in the early 2000s as a way to address these challenges. Let\u0026rsquo;s look at VMs next.\nVirtual Machines   Virtual Machines, or VMs were introduced as a way of abstracting the physical server from the software.\nThrough the magic of a hypervisor each application \u0026ldquo;thinks\u0026rdquo; it is running on a dedicated machine with its own resources\nWhat is a hypervisor?\nA hypervisor is a program that:\n provides a virtualized view of a physical server manages the VMs ensures that VMs are isolated from one another  VM cons:\n consumed resources to store and run the OS long start up and shut down times required a lot of maintenance expensive  These inefficiencies prompted the next innovation in virtualization, containers!\nContainers A container defines an operating system and contains one or more applications to run.\n VMs abstract the hardware to make it appear dedicated while actually being shared Containers abstract the operating system to make it appear dedicated while actually being shared.  What is the Docker Engine?\nIn a nutshell, the Docker Engine is a program that manages Docker images and containers.\nAdvantages of Containers Containers gain several advantages by sharing the same underlying operating system, such as:\n being more efficient due to leveraging a shared operating system starting up and shutting down much faster than VMs not requiring OS licenses, upgrades, or patches  VMs vs Containers\n   VMs Containers     Heavyweight Lightweight   Limited performance Native performance   Each VM runs in its own OS All containers share the host OS   Hardware-level virtualization OS virtualization   Startup time in minutes Startup time in milliseconds   Allocates required memory Requires less memory space   Fully isolated and hence more secure Process-level isolation, possibly less secure    How Containers Work Containers safely and securely run multiple applications on a single physical server and a single operating system because of two important features of the Linux kernel: namespaces and cgroups.\nWhile container support has been added to certain versions of Windows, Linux remains the dominant operating system for running containers. And the dominant container technology is Docker, which we will learn about soon.\nA Fun Demo Here is a fully automated script that runs a simple demo of using Docker to run a container. It requires that you have Docker Desktop running.\nPlace all of the following into a shell script, run-simple-container.sh:\n#!/bin/sh docker run --name simple-nginx -p 8080:80 -d nginx # downloads the nginx image, then creates and runs a container curl localhost:8080 # test the container running nginx via curl docker stop simple-nginx # stops the container docker rm simple-nginx # removes the container Try timing the execution of the shell script by running it with the time command. You should see the script run in about 0.1 seconds.\ntime run-simple-container.sh This demonstrates that creating, starting, testing, stopping, and removing a container happen in 100ms.\nPretty impressive!\nContainers, Micro-Services, and Cloud Computing   While you can run monolithic applications inside of containers, the real gains come when partitioning large applications into several micro-services.\nFor example, a merchandise web site could consist of several micro-services working together to provide a full shopping experience.\nThe advantages of splitting features into multiple, loosely coupled micro-services include:\n Independent releases of each service Easier to debug, tune, and enhance each service Easier to independently test each service By running each service in its own container, each service can be independently:  scaled logged secured (as services may have differing security requirements) tuned for best performance    Summary  The emergence of cloud computing and the need to best utilize data center and cloud resources has led to an evolution in virtualization technologies. For most applications, containers are a vast improvement over virtual machines due to their smaller footprint, faster startup times, and easier maintenance. While Virtual Machines still have a place in modern virtualization, Docker and it’s container model have become the primary means to how virtualization is done in data centers and cloud computing.  Questions to Consider  Why are containers essential to cloud computing? How do containers differ from virtual machines? Which of the following statements is false:  Linux provides support for running containers Containers are more efficient than VMs because they share a host operating system Containers, like VMs, require a hypervisor to run on a host machine A container wraps an application and specifies a list of dependencies needed to run the application    For Further Reading  What is a Container? OS-level virtualization Docker and Kubernetes: The Big Picture (PluralSight Course)  "
},
{
	"uri": "/react/foundations/react-intro/",
	"title": "Intro to React",
	"tags": [],
	"description": "",
	"content": "An introduction to the concepts of ReactJS.\nConcepts  Describe the React Framework Explain JSX List some advantages of building and using Components  What is React?  React is a simple, yet powerful, open source web framework developed by Facebook. React is used to create dynamic web applications with JavaScript. React can also be used to build native (smart phone or desktop) applications. React is component based. React is rather light-weight. There are hundreds of libraries that add new features to React. React apps can be written with JavaScript or TypeScript.  Components  In the UI world, components are the key to true reusability. Each component represents a \u0026ldquo;piece\u0026rdquo; of UI (such as a button, a text input, a date chooser, a navbar, etc.). Components should often be reusable across different contexts (user stories, projects). Components should be composable - i.e. you can combine components to make bigger components.   In React, everything that is rendered (appears visually) is managed by a component.\n When building web applications with React, you can think of a component as:\n A custom HTML tag The code behind that tag used to define the view and the behavior of the tag  The view is composed of the DOM elements that make up the tag. The behavior is how the component responds to events, such as keyboard events, mouse events, or the arrival of new data.    Example:\n// define a simple Greeting Component function Greeting(props) { return ( // return a JSX expression  \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Hello {props.name}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ); } ReactDOM.render( \u0026lt;Greeting name=\u0026#34;Homer\u0026#34; /\u0026gt;, {/* Greeting is a React Component */} document.getElementById(\u0026#39;root\u0026#39;) {/* More about this later */} ); For Discussion Can you identify potential components in the following UI?\nHow might these components be used in other applications?\nComponent Hierarchy  Components can be structured with a hierarchical parent/child relationship in mind. For example, a TodoList component might contain a child component of Tasks  import Task from \u0026#39;./Task\u0026#39; // Assume a `Task.js` file contains a Task component.  function TodoList() { return ( \u0026lt;div\u0026gt; \u0026lt;Task title=\u0026#34;Learn JavaScript\u0026#34; /\u0026gt; {/* Render each Task as a child of TodoList */} \u0026lt;Task title=\u0026#34;Learn React\u0026#34; /\u0026gt; \u0026lt;Task title=\u0026#34;Have fun\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; ) } Virtual DOM  As you begin to explore React, you\u0026rsquo;ll see the term Virtual DOM thrown around. When a component is rendered, React updates a JavaScript representation of the DOM known as the Virtual DOM. React creates a virtual representation of the DOM interface in memory. Then, by using the virtual DOM, the state of the interface can be rendered to any number of clients, including the browser\u0026rsquo;s DOM, an HTML canvas, a mobile device, a VR device, or a Desktop app, etc.  Why Have a Virtual DOM? There are multiple benefits of using a Virtual DOM:\n The main purpose of having a virtual DOM is performance.  React uses the Virtual DOM to detect changes and then perform incremental updates to the physical DOM in an efficient manner.   The Virtual DOM also provides an abstraction of the physical DOM such that the rendering may not be to a DOM at all.  This is what makes React Native such an elegant solution for building native UIs with React.    ReactDOM  When building web based applications, we can use the ReactDOM library to convert our React application state into HTML. ReactDOM increases performance by managing the HTML and event handlers for us, so that subsequent renderings of the application make the fewest possible changes to the actual DOM.  JSX Consider this example again:\n// define a simple Greeting Component function Greeting(props) { return ( // return a JSX expression  \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Hello {props.name}\u0026lt;/p\u0026gt; {/* JSX can embed JavaScript expressions */} \u0026lt;/div\u0026gt; ); }  The funny looking HTML-ish code you see being returned is known as JSX. React components return a JSX expression that defines how the component will look on the screen. JSX is a superset of JavaScript and HTML. JSX is a declarative language for defining the visual aspects of a component.  JSX is Not HTML  Keep in mind that JSX is not HTML. It\u0026rsquo;s also not really JavaScript. JSX is a domain-specific language that is a hybrid of HTML and JavaScript. JSX needs to be compiled (usually by babel) into a .js file that a browser can process. This is similar to the use of other web preprocessors such as CoffeeScript, TypeScript, SASS, Less, etc.   NOTE: We will learn more about JSX in an upcoming lesson.\n Uni-Directional Data Flow   React uses Uni-Directional Data flow, meaning that data always \u0026lsquo;flows\u0026rsquo; one way. Therefore:\n A React component does not directly change its own data To change state, a component notifies React of the desired state change React does the magic to update the state and re-render all affected components  Unidirectional dataflow has many advantages, including:\n Notifying React when data updates are needed Letting React optimize the state and visual updates Keeping our code simple and letting React handle the heavy lifting  We\u0026rsquo;ll discuss this idea more when we get into state and props.\nSummary  React is a light-weight web framework. React is component based. React uses JSX for declaratively defining the visual aspects of a component. React uses a functional, unidirectional data flow approach to state updates.  "
},
{
	"uri": "/software-eng-essentials/patterns/resiliency/intro-to-resiliency/",
	"title": "Intro to Resiliency",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Define resiliency Discuss the growing need for software system resiliency Explain resiliency patterns and what they do  What is Resiliency? \u0026ldquo;Resiliency is the ability of a system to gracefully handle and recover from failures.\u0026rdquo; \u0026ndash; Resiliency Patterns | Microsoft Azure Docs\nResiliency has become a vital aspect of software engineering due to:\n distributed computing, especially the emergence of cloud computing and microservices the sharing of services across several applications the critical Importance of software applications to overall business operations  The Growing Importance of Resiliency Our software systems continue to grow in complexity and connectivity due to trends in:\n cloud computing microservices mobile clients IoT  Thus the probability of both transient and persistent failures continues to increase, and detecting and recovering quickly from these failures is necessary to maintaining resiliency.\nWhat are Faults Faults are unexpected problems in the system that can generate errors or failures. An error is an incorrect result or behavior, and a failure is when the system cannot process a request.\nCauses of Faults Faults can occur due to:\n Hardware failures Software failures (bugs) Network failures Limited resources (CPU, memory, network, etc.) Unexpected loads Malicious attacks (such as DDoS)  Can you think of others?\nTypes of Faults Faults can be transient, intermittent or persistent:\n transient: a fault that happens once or very rarely intermittent: a fault that occurs, then disappears, then reoccurs at a frequency that suggests an underlying problem persistent\u0026rdquo; a fault that occurs and remains for a significant amount of time    Resiliency vs. Fault Tolerance Is there a difference between Resilience and Fault Tolerance?\nYes, there is a subtle but important difference:\n Fault tolerance: Users do not see any impact except for some delay during which failover occurs. Fault resilience: Users may observe failures, but the rest of the system continues to function normally.  Essentially resilience means that the system should handle faults with a graceful degradation of service.\nWhat is a Resiliency Pattern? A Resiliency Pattern is a kind of Software Design Pattern. So let\u0026rsquo;s start by defining what a software design pattern is:\n A Software Design Pattern is a general, reusable solution to a commonly occurring problem.\n So if we apply that definition to resiliency:\n A Resiliency Pattern is a general, reusable solution to a commonly occurring resiliency problem (such as a specific kind of system fault).\n Common Resiliency Patterns Examples  Health Monitoring - perform functional checks at regular intervals and respond to observed failures Timeout - preserve responsiveness independent of upstream latency Bulkhead - isolate components of a system so that failures in one component do not cause other components to fail Retry - handle transient errors by transparently retrying an operation that failed Circuit Breaker - fail fast when an upstream service is persistently failing Queue-Based Load Leveling - Use a queue to buffer the inbound load in order to smooth intermittent heavy loads Bounded Queues - limit request queue size to fail fast when request load becomes too high  Summary In this lesson we have defined resiliency, discussed the growing need for resilient software systems, and introduced resiliency patterns as solutions to common resiliency problems. Next we can look deeper into some of these resiliency patterns and see how they solve a specific resiliency problem.\nAdditional Resources  Resiliency Patterns | Microsoft Azure Docs Fantastic Faults and What to Call Them Resilience design patterns: retry, fallback, timeout, circuit breaker  "
},
{
	"uri": "/python/bots/slackbot_intro/",
	"title": "Intro to Slackbot",
	"tags": [],
	"description": "",
	"content": "Learning Objectives This is an introduction to using the Slack Client Python API to create a simple bot. This lesson will walk you through the set up process before coding any type of logic into your bot.\nConcepts  Bots Slack Client API  Skills  Python Slackbot Creation   What is a Bot? A bot is nifty way to run code and automate tasks. In Slack, a bot is controlled programmatically via a bot user token that can accesses one or more of Slack\u0026rsquo;s APIs. What can bots do? Monitor and help process channel activity Post messages in channels and react to members’ activity Make channel messages interactive with buttons\nBots can do a lot of the same things in Slack that regular members can:\nThey have names, profiles, profile photos, and exist in the Directory. They can be @mentioned and sent direct messages. They can post messages and upload files. They can be invited or removed from both public and private channels.\nBots can only do what you program them to do in a specific channel. So, someone can’t “sign in” as the bot and do things that other members of your workspace can do in Slack. Bots also can\u0026rsquo;t be set as Workspace Owners or Admins. Ways that bots can impact your workspace 👀 Monitor and process channel activity A bot can help monitor and process activity in the public and private channels it’s been invited to, as well as messages sent to it via direct message.\n📝 Post messages and react to members In addition to receiving messages, a bot can also post messages in channels it’s a member of.\n🎯 Make messages interactive with buttons When attached to a Slack app, bots can add interactive components (such as buttons) to messages that members can interact with. These interactive components trigger specific actions on your servers, so that you can perform certain tasks.\n Our Bot Our bot, which we will name \u0026ldquo;StarterBot\u0026rdquo;, requires Python and the Slack API. To run our Python code we need:\n Python 3, or 2 pip and a virtual environment to handle Python application dependencies Free Slack account - you need to be signed into at least one workspace where you have access to building apps. It is also useful to have the Slack API docs handy while you\u0026rsquo;re building this tutorial.   Python \u0026amp; Slack Slack has a Developer Kit for Python, Documentation here.\nWhether you’re building a custom app for your team, or integrating a third party service into your Slack workflows, Slack Developer Kit for Python allows you to leverage the flexibility of Python to get your project up and running as quickly as possible.\nSlack APIs and App Configuration If you don’t already have a Slack organization to work with, first create that. To make this tutorial more interesting, I also recommend adding some people to it! Since we’ll be using the Slack API, click the “Create a Slack App” button circled below:\nThis will return this web page, where you can enter your app’s name. For this tutorial, I named mine adispotting, but feel free to adjust for your own organization! Once you fill out the information, click “Create App”.\nSeveral options will appear that you can add to your application, including “Bots” which is circled below\nOnce you click the “Bots” option, there will be an “Add a Bot User” which you’ll need to click to continue the process.\nJust as you’ve done before, fill out the needed fields and select “Add Bot User”.\nNext, on the left sidebar click the option ‘OAuth \u0026amp; Permissions’, then click ‘Install App to Workspace’. These are your API keys — make sure to save the second key for later. We will use these values later.\n Creating Our Py Environment We now know what tools we need for our project so let\u0026rsquo;s get our development environment set up. Go to the terminal and change into the directory,or create new directory, where you want to store this project.\nmkdir starterBot Navigate to new directory\ncd starterBot Once inside the directory, run the pipenv \u0026ndash;three command to create your virtual environment.\npipenv --three After creation, if you list the files in the directory you will see a new file:\n Pipfile - Contains a list of your installed packages for this project - We have no packages installed yet so it\u0026rsquo;s empty   After we install a Python package we will generate a second file:\n Pipfile.lock - Contains all dependencies for installed packages and hashes needed to run them - Let\u0026rsquo;s install a package and see this in action  First activate a Pipenv virtual environment shell:\npipenv shell  Install Slackclient The official slackclient API helper library built by Slack can send and receive messages from a Slack channel. Install the slackclient library with a pipenv or pip command within your virtual environment:\npipenv install slackclient OR pip install slackclient You should see output like this and you\u0026rsquo;ll be back at the prompt.\nIf you see a output like below when installing packages, this may be a result of the permissions allowed on your network.\nTry the following command to fix this, remember to make sure you\u0026rsquo;re in the virtual environment:\npip install --trusted-host pypi.org slackclient Now that we have the slackclient installed let\u0026rsquo;s make a bot!\n"
},
{
	"uri": "/react/pillars/testing/tdd/intro/",
	"title": "Intro to TDD",
	"tags": [],
	"description": "",
	"content": "Test Driven Development\n Topics 1. In this lesson you will learn: 2. Why Write Tests?? 3. What is Test-Driven Development? 4. Where Do I Begin? 5. Exercise: Getting Your Feet Wet 5.1. Acceptance criteria: Story 1 5.2. Explore: Hello CodeSandbox React App (5-10 min) 5.3. Acceptance criteria: Story 2   6. Resources   1. In this lesson you will learn:   Purpose of writing tests\n  What is test driven development?\n  How to start writing tests\n     2. Why Write Tests?? Think about this scenario: You complete feature 1, feature 2, then feature 3. You\u0026#8217;re feeling pretty confident that the app is flawless! Eventually there are too many features to count. One day, BAM feature 2 stops working. You haven\u0026#8217;t touched the feature 2 code in months, yet something has caused it to break. Where do you start looking? You get lucky and figure out how to \"fix\" the bug, but soon discover that the \"fix\" created a domino effect of more application failures. This is where panic sets in.\n The scenario above is one of the primary reasons why writing tests is so important.\n   Reasons to test drive code:\n   Ensures that the end result meets the business and user requirements\n  Provides documentation for the app\n  Forces developers to slow down and think about implementation\n  Improves design resulting in higher quality software\n  Reduces fear and anxiety while building new features\n     3. What is Test-Driven Development? Test-Driven development is an incremental way to build a feature. When you look at a wireframe, it is made up of components with functions that support component behavior. What test-driven development does is provide a repetitive pattern for developers to follow. This pattern is commonly known as Red, Green, Refactor.\n  Red: Write a test that describes how the app should behave with user interaction.\n  Green: Write the code that makes a feature work.\n  Refactor: Update the code to improve the implementation.\n   This process helps developers focus on building only ONE feature at a time. Write a failing test\u0026#8230;\u0026#8203;.Implement the code to make the test pass\u0026#8230;\u0026#8203;.Refactor the implementation\u0026#8230;\u0026#8203;.Repeat.\n     4. Where Do I Begin? One of the most common questions new engineers ask when given a wireframe, acceptance criteria or a prototype is, \"Where do I begin?\" And the answer is, write a failing test for a feature. You do not need to concern yourself with building the entire application.\n Steps to Begin Test Driven Development:\n  If you are given a wireframe, study it. If you have a clickable prototype, play with it. Familiarize yourself with how the app should behave.\n  Review the acceptance criteria. If you do not have acceptance criteria, create your own list by recording the actual behavior as you interact with each feature of the app.\n  Once you know how each piece of the app should behave, you can write your first failing test for one feature.\n     5. Exercise: Getting Your Feet Wet Below is our mock up of the \"Hello CodeSandbox\" app. Currently it only has a header and subheader.\n   What would the tests look like in order to create this app?\n  Let\u0026#8217;s take a look at the acceptance criteria and how it was converted into tests.\n     5.1. Acceptance criteria: Story 1  the user should see an h1 header\n  the header should read \"Hello CodeSandbox\"\n    5.2. Explore: Hello CodeSandbox React App (5-10 min)  Examine the code for the \"Hello CodeSandbox\" app. Click here.\n  When you open the app, split the screen and open the App.js and App.test.js.\n To split the screen, click View \u0026#8594; Editor Layout. Select how you prefer to split your screens.\n     Take a few minutes and study the code independently. Then discuss with a neighbor the relationship between the acceptance criteria story 1 and the test suite.\n    5.3. Acceptance criteria: Story 2 Instructions: Write a new test FIRST that completes the acceptance criteria for story 2 below. Do not modify the first test!\n  the user should see an h2 subheader\n  the subheader should read \"Start editing to see some magic happen!\"\n     In the next lesson we will dive into the React testing tools.\n    6. Resources   Red, Green, Refactor\n  5 Questions Every Unit Test Must Answer\n  Software Testing Methodologies.\n  Types of Software Testing: Different Testing Types with Details\n  Functional Testing VS Non-functional Testing\n     "
},
{
	"uri": "/software-eng-essentials/agile-lean/intro-to-agile/",
	"title": "Intro to the Agile Process",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Describe the Waterfall Process and why it isn\u0026rsquo;t suitable for most software products. Describe the Agile Process and why it is better for software development. Describe how Agile helps teams adapt to changes in technology and in user expectations.  The Waterfall Process  Invented in 1970 Revolutionary because it brought discipline to software development Ensured that there was a clear spec to follow Based on the waterfall manufacturing method derived from Henry Ford’s 1913 assembly line innovations  Provided certainty to each step in the production process Guarantees that the final product matched the original specifications      Why Waterfall Does Not (Usually) Work For Software Development  The Waterfall process introduces problems when applied to certain fields of Technology and specifically to Software Development. This is due to the volatility of the Software Development industry.  What is Volatility? Volatility: prone to rapid and unpredictable changes.\n  Volatility in Software Development The volatility of Software Development can be broken up into:\n rapid changes in technology  languages, libraries, frameworks devices and platforms (Cloud) computational power, memory capacity, network/communication capacity, etc.   rapid changes in customer expectations - often derived from changes in the underlying technologies. rapid changes in what is market trends - trends such as social media  Waterfall Resists Change The Waterfall process does not handle change well. In fact it resists change because it:\n locks down key design decisions early in the waterfall process requires a lot of effort to make changes in the initial design does most of the testing and verification of the design and implementation at the end   Thus the risk of using waterfall is that the team may build a product that, once completed, is no longer relevant!\n The Agile Methodology  Agile differs from Waterfall in that Agile embraces change instead of resisting it.\nAgile:\n describes an iterative approach to project management and software development helps teams deliver value to their customers faster and with fewer surprises. delivers work in small, but consumable, increments. continuously re-evaluates requirements, priorities, plans, designs, and schedules.  Thus with an Agile process, teams have a natural mechanism for responding quickly to change.\nAgile: A Brief History The Agile methodology was formally launched in 2001 when 17 technologists published The Agile Manifesto.\nThe main principles are given as follows:\n  Breaking this down:\n Individuals and Interactions over Processes and Tools - People do the work, people have the brains, so people are more important Working Product over Comprehensive Documentation - Developing and maintaining documentation can become a huge time sink. How much value does it provide? Customer Collaboration over Contract Negotiation - Contracts (like Waterfall) are resistent to change. It\u0026rsquo;s better to have a collaborative relationship with all stakeholders. Responding to Change over Following a Plan - To stay relevant and competitive, we must accept change and respond to it quickly.   As Scott Ambler elucidated:\n Tools and processes are important, but it is more important to have competent people working together effectively. Good documentation is useful in helping people to understand how the software is built and how to use it, but the main point of development is to create software, not documentation. A contract is important but is no substitute for working closely with customers to discover what they need. A project plan is important, but it must not be too rigid to accommodate changes in technology or the environment, stakeholders\u0026rsquo; priorities, and people\u0026rsquo;s understanding of the problem and its solution.   A Caveat Even with Agile we must be careful to manage changes.\n We simply cannot constantly change everything. All potential reactions to change must be evaluated to determine the best plan moving forward given all currently known risk factors (time, expense, effort, future changes, etc.). As with all engineering disciplines, tradeoffs will need to be made.  Agile\u0026rsquo;s 12 Principles The Manifesto for Agile Software Development is based on 12 principles:\n Customer satisfaction by early and continuous delivery of valuable software. Welcome changing requirements, even in late development. Deliver working software frequently (weeks rather than months) Close, daily cooperation between business people and developers Projects are built around motivated individuals, who should be trusted Face-to-face conversation is the best form of communication (co-location) Working software is the primary measure of progress Sustainable development, able to maintain a constant pace Continuous attention to technical excellence and good design Simplicity — the art of maximizing the amount of work not done — is essential Best architectures, requirements, and designs emerge from self-organizing teams Regularly, the team reflects on how to become more effective, and adjusts accordingly  Question: Do you have any favorites from the list above?\nIs Agile A Process? Agile itself is not a process but a set of principles and methods (best practices) for developing software.\nAgile is often referred to as a framework or a methodology.\nThere are several Agile processes that fall underneath the \u0026ldquo;Agile Umbrella\u0026rdquo;, such as:\n Scrum - characterized by User Stories, Story Points, and Sprints that time-box work Kanban - characterized by limiting WIP (Work in Progress) and pulling in work as needed Scrumban - a hybrid of Scrum and Kanban  There is also Extreme Programming or XP, a set of software development methodologies that can be used within any Agile process.\nSome of the common XP methodologies are:\n Test Driven Development (TDD) Pair Programming User Stories Continuous Integration and Continuous Delivery (CI/CD)  Agile at The Home Depot Let\u0026rsquo;s take into consideration Home Depot\u0026rsquo;s Curbside Pickup, where customers can:\n make a purchase online pull up to a parking spot go online or on the app and input their location have an associate bring their purchase to the car  Here is how the Curbside Pickup feature was developed:\n Curbside pickup was scheduled to be delivered in Q2 2021. Then the pandemic triggered lockdowns and our priorities changed. To adapt, we moved the curbside feature to the front of the line while moving other features down the line. The result was THD rolling out the curbside pickup feature a couple of weeks later in Q2 2020.  Thus THD iterated over the process many times and were able to quickly deliver a functional feature that provided value to the customer and the company.\nUnder the waterfall process, this process of multiple iterations and discovery would have not been possible.\nSummary   Additional Resources  Learn about Agile The Agile Manifesto Agile Software Development | Wikipedia Extreme Programming  "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/intro-to-unix/",
	"title": "Intro to Unix (optional)",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Explain the advantages of the UNIX operating systems Compare and contrast CLIs to GUIs Explain how command line usage can increase efficiency Explain the difference between the Terminal and the Shell  What is an Operating System?   An operating system (O.S.) is system software that manages computer hardware and software resources and provides common services for computer programs.\nAn O.S. is a Resource Manager An O.S. is essentially a resource manager that allow users and application programs to access system resources in a safe, efficient and abstract way.\nThese system resources include:\n CPU Memory Storage Printers Network cards  The History of UNIX  The UNIX OS was originally created at Bell Labs by Ken Thompson and Dennis Ritchie back in 1969. Ken Thompson and Dennis Ritchie invented the C Programming Language in order to make UNIX portable to other computer hardware (specifically the PDP-11). It was released to the public in 1975.  Ken Thompson and Dennis Ritchie:\n  The History of UNIX (cont\u0026rsquo;d)  Linux is a free open source UNIX OS for PCs that was originally developed in 1991 by Linus Torvalds Linus Torvalds also created the git version control system. Linux is now used world-wide as a secure and robust O.S. for personal computers, embedded devices, data centers, and cloud computing. Linux is also the foundation of the Docker container system.  UNIX and Apple macOS In 1985 Steve Jobs founded the NeXT Computer Company after being ousted at Apple.\n A new Operating System called NeXTSTEP was developed. NeXTSTEP was based on UNIX and eventually became the foundation for macOS (formerly known as Mac OS X). Therefore all Mac computers are running an operating system based on the fundamental design principles of UNIX! In 2007 OSX became a certified UNIX.  Why UNIX? The UNIX Operating System (or family of operating systems) has stood the test of time. UNIX was engineered to be:\n Portable (can run on lots of different hardware platforms) Fast Modular (kernel + libraries + shells + window systems) Multi-tasking Multi-user Secure Networked  Flavors of UNIX  System 5 BSD IBM AIX HP UX SUN Solaris (now owned by Oracle) Linux (many distributions, including Debian, Ubuntu, Fedora, and RedHat) macOS (formerly Mac OS X) lots of others\u0026hellip;  Summary  An Operating System manages computer hardware and software resources. The UNIX Operating System pioneered many innovations and is at the heart of MacOS. As we learn how to use the Command Line Interface (the shell), we will grow to appreciate the productivity and efficiency that is provided to us by MacOS and modern UNIX shells such as bash and zsh.  "
},
{
	"uri": "/cloud/containers/developing-with-docker/int-testing/intro/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Concepts  Review TDD and BDD concepts Define Integration Testing Demo integration testing from app in container to a dependent app in a different container Demo integration testing from app in container to a database in a container  Introduction In this course we will be learning about how Docker and docker-compose can assist us with integration testing. Specifically we will be learning about:\n using multiple Docker containers to run the services that make up our applications ensuring that these containers can communicate streamlining the configuration, startup, and shutdown of the containers  Review of TDD and BDD Test-driven development (TDD) and Behavior-driven development (BDD) are best practices for building software applications.\n TDD is a test-first approach where the unit tests are written before the code is developed. This aids in ensuring that the code performs the desired actions. BDD is also a test-first approach but focuses more on the higher-level behavior of the system from the end users perspective.  These two methodologies are complimentary and beneficial to developing high-quality software applications.\n For a review of TDD, see Test Driven Development. For a review of BDD, see Behavior Driven Development.  Integration Testing Integration testing is used to verify that multiple components or services that make up an application are working together correctly. For example, we can run integration tests to ensure that a RESTful API service and a database service are working correctly. We can even test all of the services together, such as the client, the server, and the database.\nDocker is a great tool to aid in integration testing. With Docker (and docker-compose) we can run each service in a separate container and test that they work together to perform as expected.\nDemo of Integration Testing with Docker Let\u0026rsquo;s see a demo of running a React client, a RESTful API server, and a database running in containers and being integration tested. This is a demo of what we will be testing in the final lab for this course.\n"
},
{
	"uri": "/react/pillars/perf-opt-strategies/intro/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Welcome to React Performance Optimization Strategies.\nConcepts and Skills  Learn how to profile React applications to learn about the performance characteristics Eliminate redundant renders of components Choose the best patterns for application state management to optimize components by default Manage CPU intensive operations with memoization and web workers Learn about React’s built-in features such as React.memo, useMemo, and useCallback Learn about strategies for managing and rendering large data sets  Introduction First of all, React is fast, very fast.\nThis is due to it\u0026rsquo;s use of\n immutability to quickly determine when state or props have changed (via shallow comparisons) a virtual DOM to efficiently update the actual DOM with only the DOM elements that have changed.  That being said, anything can get slow due to:\n expensive computations slow network responses complex renderings (such as SVG charts and graphs), and displaying large data sets.  In this workshop we will be looking at common performance problems and how to resolve them.\nWhat is Performance Analysis and Optimization? Performance analysis is the measuring of performance to determine if all performance goals are met. This can include:\n fast initial loads fast user response times (generally under 250ms to either render the final output or respond to the user that something is happening) acceptable CPU and memory footprints acceptable network loads  Performance optimization is the identification and resolution of specific performance problems.\nAvoid Premature Optimization Humans are not good at predicting where performance problems will occur.\nTherefore, do not spend a lot of time and effort optimizing for performance until you have a fully working application or feature and have done performance testing to determine if there are performance problems that need to be resolved.\nSome Terminology Virtual DOM The Virtual DOM (aka the Fiber Tree) is React\u0026rsquo;s in-memory representation of the (physical) DOM tree.\nReact first renders components to the Virtual DOM and then diffs this tree with the physical DOM tree to determine which nodes need to be updated.\nQUESTION: What makes this faster? Why is it faster to update the Virtual DOM than the actual (physical) DOM?\nReact hooks React hooks were added to React in version 16.8\n Hooks provide a way for JavaScript functions to have \u0026ldquo;memory\u0026rdquo; across function invocations. Previously you had to use a JavaScript object to remember state and other data across renders. With hooks, we can use simple JavaScript functions (which compose very well) and add hooks to them as needed to remember things. Each React component has its own hook instances, so hook instances are not shared across components.  Reconciliation Reconciliation is the process React uses to determine what DOM nodes to update (diffing) and then updating them (rendering).\nReact\u0026rsquo;s Reconciliation Workflow:\n Determine which components need to be rendered (all of them the first time). Render Phase - render the components to the Virtual DOM / Fiber Tree - this work can be done asynchronously (it can be interrupted to handle other events). Commit Phase - update the DOM and process any other side-effects - this work must be done synchronously as it updates the DOM which is visible to the user.  UI Performance UI performance is how quickly the UI reacts to user interactions\n Jank - when the UI becomes unresponsive, sluggish, or jerky  Flame Graph / Flame Chart Flame graphs and flame charts are a visual representation of the time spent (on CPU) for each function and/or component.\n Flame Graphs - have no time axis. Functions (or components) are ordered alphabetically and grouped to show aggregate time spent. Flame Charts - have a time axis that allows for time-based patterns to be studied but does not allow for aggregate grouping of time spent.  For React, we can use Flame Graphs or Flame Charts to visually represent which components are taking the longest aggregate time to render.\nResources on Flame Graphs and Flame Charts:  Profiling Performance with React Dev Tools | Pluralsight Guide Detailed Description of Flame Graphs | Brendan Gregg Miha Rekar - What Are Flame Graphs and How to Read Them, RubyConfBY 2017 | Youtube   Great analogy to your work day Quiz Time    Screenshots from Miha Rekar\u0026rsquo;s Talk on Flame Graphs      Memoization  Memoization is a technique where a function or component remembers (i.e. caches) a previous calculations to prevent unnecesssary recalculations. Memoization avoids recalculation (or re-rendering) when the inputs have not changed. React uses the memo-one pattern to simply remember the previous inputs and output.  Getting Started with the React Performance Playground App The React Performance Optimization Playground App is custom built for this workshop!\nHere are the steps to setup and run the React Performance Playground App\nStep 1: Clone the GitHub Repo and install Dependencies\ngit clone https://github.com/one-thd/om_labs_react-perf-opt.git cd om_labs_react-perf-opt yarn Step 2: Run the server and the client\nIn a terminal session, start the server listening on PORT 4000:\nyarn server In a separate terminal session, start the client web server listening on PORT 3000:\nyarn start Test it out by pointing your browser to http://localhost:3000.\nFor starters, most of the After solutions have not been completed. We will be fixing the performance problems as code-alongs in class or as lab assignments.\nUsing React Dev Tools and Flame Graph Charts To install React Dev Tools for Chrome, see: React Developer Tools | Chrome Plugin.\nOnce you have it installed, you can open Chrome\u0026rsquo;s Developer Tools and you should see 2 additional tabs labeled Components and Profiler\nComponents Tab You can use the Components tab to inspect which components are currently mounted and each component\u0026rsquo;s props and state values.\nProfiler Tab The Profiler tab can record your React applications performance and show you a Flame Chart or a Ranked Chart.\nDevelopment vs. Production Builds There are differences in how Development and Production builds perform:\n If you’re benchmarking or seeing performance problems in your React apps, make sure you’re testing with the minified production build. The development build includes extra warnings that are helpful when building your apps, but it is slower due to the extra bookkeeping it does. However, the perf tools described on this page (i.e. React Dev Tools) only work when using the development build of React. Therefore, the profiler only serves to indicate the relatively expensive parts of your app.\n "
},
{
	"uri": "/javascript/foundations/intro-to-js/",
	"title": "Introduction to JavaScript",
	"tags": [],
	"description": "",
	"content": "An introduction to the JavaScript language.\nLearning Objectives Concepts  Discuss the history of JavaScript Describe JavaScript as both an OOP and a FP language  Background  JavaScript should not be confused with Java. They are fundamentally two completely different programming languages. JavaScript is a high-level, general purpose programming language. JavaScript was created in 10 days in May 1995 by Brendan Eich In 1996 - 1997 JavaScript was taken to ECMA to carve out a standard specification JavaScript has become the de facto standard language for Web pages running in a browser JavaScript has evolved greatly since 2015. Many features were added in the ES-2015 specification. JavaScript continues to evolve. JavaScript often tops lists of most popular programming languages on platforms like GitHub and Stack Overflow.  JavaScript Features JavaScript:\n uses just-in-time compilation is multi-paradigm uses curly-bracket syntax for code blocks is dynamically typed provides prototype-based object-orientation has first-class functions, meaning functions can be assigned to variables, passed as arguments to functions, and returned as values from functions.  We will be learning more about these features in this course.\nProgramming Paradigms JavaScript supports the two most common programming paradigms:\n Object Oriented Programming (OOP) - code and data are encapsulated into objects Functional Programming (FP) - code and data are managed using (mostly) pure functions  ECMAScript  ECMAScript is the official language specification for the JavaScript language. ECMAScript is meant to ensure the interoperability of Web pages across different Web browsers. You can read more about ECMAScript by reading the ECMAScript Language Specification.  NodeJS Thanks to NodeJS (based on the V8 JavaScript engine developed at Google), JavaScript can now be used outside of the browser as a general purpose, full featured programming language.\nSummary  JavaScript is not Java JavaScript is a full featured, general purpose programming language JavaScript is the language of browsers JavaScript can run outside the browser via NodeJS  "
},
{
	"uri": "/react/pillars/testing/react-testing-library/rtl-intro/",
	"title": "Introduction to RTL",
	"tags": [],
	"description": "",
	"content": "Introduction to the React Testing Library Kent C. Dodds created the React Testing Library to address one problem:\n Other testing libraries encouraged developers to write tests that were too tightly coupled to the implementation details.\n Kent believed that the tests should only verify the end results (the behavior) of the components.\nTests Should  focus on the user\u0026rsquo;s perspective (how the component looks and behaves in the DOM) avoid dependencies on the implementation details of your components are easy to maintain, i.e. refactoring the component implementation does not break the tests avoids shallow mounting as we want to test how components integrate to solve a user problem  The problem with unit testing and shallow mounting:\nexpect(umbrellaOpens).toBe(true) tests: 1 passed, 1 total **all tests passed** pic.twitter.com/p6IKO7KDuy \u0026mdash; Erin 🐠 (@erinfranmc) July 10, 2019   What is RTL?  The React Testing Library is a very light-weight solution for testing React components. It provides light utility functions on top of react-dom and react-dom/test-utils, in a way that encourages better testing practices.  Interesting Aspects of React Testing Library:  Focuses on verifying actual DOM nodes rather than verifying instances of rendered React components Provides utilities for querying the DOM in the same way the user would:  finding elements by their label text (just like a user would) finding links and buttons from their text (just like a user would)    RTL also provides a way to find elements by a data-testid as an \u0026ldquo;escape hatch\u0026rdquo; for elements where the text content and label do not make sense or is not practical.\nRTL vs. Enzyme  React Testing Library is a replacement for **Enzyme_. Most of the problems with Enzyme are caused by its features that encourage testing implementation details:  shallow rendering (mocking out component dependencies and their interactions which depends on how the components are implemented) APIs which allow you to get and interact with component instances and their state/properties     Thus Enzyme promotes testing a component\u0026rsquo;s internal implementation details 😔, while RTL promotes testing a component\u0026rsquo;s external behavior 😀.\n RTL and Async Operations Another big advantage of React Testing Library is it\u0026rsquo;s simple but powerful support for verifying DOM updates that happen asynchronously.\nConsider writing a test for the following user interaction:\n user sees a list of items user clicks on a delete button on an item in the list user sees a confirmation popup asking to confirm the deletion user clicks the \u0026ldquo;Confirm Delete\u0026rdquo; button user sees an updated list and the deleted item is no longer displayed  Note that between steps 4 and 5 an asynchronous operation is happening, but this async behavior is part of the implementation details and our test should not be too concerned about those.\nBut the test does need to wait for the component to be re-rendered.\nWaiting for DOM Updates  When a user interacts with a web application he/she will naturally wait a reasonable period of time to see the results displayed on the screen. Our tests should naturally wait as well!  Therefore, React Testing Library has built in support for waiting for a DOM update to occur.\nAsync Utilities RTL leverages the async utilities found in Kent C. Dodds\u0026rsquo; dom-testing-library which includes the following utilities:\n various find queries, such as findByText and findByDisplayValue waitFor waitForElementToBeRemoved  See: findBy API Queries and Async Utilities.\nExample example using findByText\n// wait for text to be displayed findByText(\u0026#39;Learn React Hooks\u0026#39;) Below is the same example as above but using waitForElement and getByText:\n// wait for data to load and then be displayed await waitForElement(() =\u0026gt; getByText(\u0026#39;Learn React Hooks\u0026#39;)) How long should a test wait?  We want our tests to run (and pass or fail) quickly. But if a test waits too long, it can make running our test suite too slow. Therefore, RTL is configured by default to wait up to 4.5 seconds before it gives up and throws an exception. This should be more than enough time for any promises to be resolved (especially if any network requests are mocked out).  NOTE: Why 4.5 seconds? It turns out that jest will timeout a test after 5 seconds so we want RTL to report the timeout before jest intercedes and kills the test.\nBoth the jest timeout and the RTL timeout values can be customized if needed for a particular test.\nRTL and its Supporting Cast RTL is a light-weight library that leverages or works well with the following libraries:\njest  Author: Facebook Description: Jest is both a test runner and an assertion and mocking library. It is automatically included in create-react-app.  react-dom/test-utils  Author: Facebook Description: Provides some utilities for testing, such as act, isElement, and Simulate. We will rarely use this directly.  react-test-renderer  Author: Facebook Description: Provides in-memory rendering of React components as pure JavaScript objects without the need for a browser or jsdom. Useful for React Native testing or testing custom hooks that don\u0026rsquo;t render DOM nodes.  @testing-library/jest-dom  Author: Kent C. Dodds Description: Extends jest by adding a set of custom matchers such as toBeDisabled, toBeInTheDocument, and toBeChecked.  @testing-library/dom-testing-library  Author: Kent C. Dodds Description: Provides DOM queries, support for firing events, and async utilities with the philosophy that testing a component should be as similar as possible to how a user will find content on a web page.  @testing-library/user-event  Author: OSS Community Description: Provides a better abstraction for firing user events than fireEvent.  @testing-library/react-hooks  Author: Kent C. Dodds and OSS Community Description: Provides support for testing custom hooks.  Get to Know the Documentation There is very good documentation on DOM Testing Library (DTL) and React Testing Library (RTL) at Testing Library Docs.\nLet\u0026rsquo;s take a minute to browse that website and also read the Guiding Principles.\nGet to Know the API Rendering RTL provides a render function to render our component under test. Usage:\nimport { render, screen } from \u0026#39;@testing-library/react\u0026#39; it(\u0026#39;renders without crashing\u0026#39;, () =\u0026gt; { render(\u0026lt;MyComponent greeting=\u0026#34;Hello\u0026#34;/\u0026gt;) await screen.findByText(\u0026#39;Welcome to the React Product Browser\u0026#39;) }) Once we have rendered the component under test, we can query the DOM via the dom-testing-library queries to verify that the rendering was as expected.\nQueries RTL uses DTL for querying the DOM. You can easily access these queries via the screen object imported from RTL:\nimport { render, screen } from \u0026#39;@testing-library/react\u0026#39; // ... const button = screen.getByText(\u0026#39;Submit\u0026#39;) 3 types of queries (Singular):    Type No Match 1 Match 1+ Match Await? Best for     getBy throw return throw No synchronous DOM renders and expecting 1 match   findBy throw return throw Yes asynchronous DOM renders and expecting 1 match   queryBy null return throw No synchrounous DOM renders and expecting 0 matches    3 Types of Queries (Plural)    Type No Match 1 Match 1+ Match Await? Best for     getAllBy throw array array No synchronous DOM renders and expecting 1 or more matches   findAllBy throw array array Yes asynchronous DOM renders and expecting 1 or more matches   queryAllBy [] array array No synchrounous DOM renders and expecting 0 or more matches    The specific queries    Query Description     ByText find by element text content   ByLabelText find by label or aria-label text content   ByPlaceholderText find by input placeholder value   ByDisplayValue find by form element current value   ByAltText find by img alt attribute   ByTitle find by title attribute or svg title tag   ByRole find by aria role   ByTestId find by data-testid attribute    For more information, see: DTL Cheatsheet\nExpectations We will use the jest, jest-extended, and jest-dom expect \u0026ldquo;matchers\u0026rdquo; to verify the results of the DOM queries. For example:\nexpect(submit).toBeDisabled()  You can find a list of jest matchers at jest expect You can find a list of jest-extended matchers at jest extended You can find a list of jest-dom matchers at jest-dom  Mocking Functions At times we will need to mock callback functions via jest. For example:\nit(\u0026#39;removes an item from the cart\u0026#39;, () =\u0026gt; { const removeItemFromCart = jest.fn() // create a mock function for the callback  render(getCartItem( cartItemData, jest.fn(), removeItemFromCart )) // interact with the DOM here.  expect(removeItemFromCart.mock.calls.length).toBe(1) // verify that the mocked callback was called  expect(removeItemFromCart).toHaveBeenCalledWith(cartItemData.id) // with the proper arguments }) Mocking Modules  Jest can mock out entire npm modules by creating a mock implementation in the src/__mocks__ folder. For our application we wil mock our axios calls by creating a mock axios service in the file client/src/__mocks__/axios.js. We can then mock any HTTP requests we want and return test data as needed. For example:  SomeComponent.test.js:\nimport mockAxios from \u0026#39;axios\u0026#39; mockAxios.get.mockImplementation(url =\u0026gt; { return Promise.resolve({ data: [ \u0026#39;apple\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;banana\u0026#39; ] }) }) Async / Await We will make extensive use of JavaScripts async / await keywords to wait for promises to be resolved. For example:\nawait userEvent.click(cartNavButton) Conclusion React Testing Library offers a lightweight library for writing React integration tests that:\n focus on verifying the correct behavior from the user\u0026rsquo;s perspective avoid dependencies on the implementation details of your components are easy to maintain provide support for easily verifying asynchronous DOM updates  Resources  Introducing the React Testing Library RTL FAQ Write tests. Not too many. Mostly integration. RTL Cheat Sheet dom-testing-library  "
},
{
	"uri": "/react/pillars/testing/common/intro/",
	"title": "Introduction to Testing",
	"tags": [],
	"description": "",
	"content": "Introduction to testing React applications.\n Topics 1. In this lesson you will learn: 2. The Myriad of Testing Methods 2.1. Functional Testing 2.2. Non-functional Testing   3. Unit vs Integration vs End-to-End Tests 3.1. Unit Tests 3.1.1. Read this later!   3.2. Integration Tests 3.3. End-to-End Tests     1. In this lesson you will learn:   Functional vs Non-functional Testing\n  The differences between Unit and Integration tests\n     2. The Myriad of Testing Methods If you asked technologists to list all of the software testing methodologies, it would be rather lengthy. The exhaustive collection of tests can be divided into two primary categories: Functional and Non-functional. Functional tests, test the business specifications, whereas non-functional tests check the quality.\n Listed below are some of the more common testing types with a brief description. To find out more in-depth information here are some resources. Software Testing Methodologies and The different types of software testing.\n 2.1. Functional Testing Testing the business specifications or requirements. Input is given and the output is evaluated.\n Table 1. Types of Functional Tests     Unit\n very low level, close to the source of your application.\n   Integration\n verify that different modules or services used by your application work well together.\n   End-to-end\n replicates a user behavior with the software in a complete application environment.\n   Regression\n re-running functional and non-functional tests to ensure that previously developed and tested software still performs after a change.\n   Positive\n determines that your application works as expected. Sometimes refered to as the \"happy path.\"\n   Negative\n ensures that your application can gracefully handle invalid input or unexpected user behavior. Sometimes refered to as the \"sad path.\"\n     2.2. Non-functional Testing Testing to \"reflect the quality of the product.\"\n Table 2. Types of Non-Functional Tests     Performance\n checks the behaviors of the system when it is under significant load. (See load and stress testing.)\n   Usability\n measures an application’s ease-of-use from the end-user perspective and is often performed during the system or acceptance testing stages.\n   Compatibility\n used to gauge how an application or piece of software will work in different environments. It is used to check that your product is compatible with multiple operating systems, platforms, browsers, or resolution configurations.\n   Reliability\n checks whether the software can perform a failure-free operation for a specified period of time in a specified environment.\n   User Acceptance\n does the product do what the user wants or expects.\n   Security\n check how the software or application or website is secure from internal and external threats.\n       3. Unit vs Integration vs End-to-End Tests There is a debate as to what is the preferred method for testing. Some argue that integration test verify that the components are working together. Others argue that unit tests allow components to be tested in isolation to validate the output based on a given input. Both are valid and they complement each other.\n It is up to you and your team which camp you fall into. To find out more information about the unit vs integration test debate, here are a few articles to help you make the decision.\n   Team Integration: Write tests. Not too many. Mostly integration.\n  Team Unit: What should we test (ReactJS Components)\n   3.1. Unit Tests  Definition  A level of software testing where individual units or components are tested and mocks out ANY external dependencies (including API calls, database calls, and dependent classes/modules). It\u0026#8217;s like a test with blinders on so that it only tests the inputs and outputs of the component being tested.\n Goals  To cover all positive and negative workflow within a discrete unit of work. Ensure code is actually testable and reasonably documented by test.\n Benefits    A safety net that helps developers find software bugs early\n  Provide documentation by telling a living story about your application\n  Foster simplicity by forcing you to write code that is decoupled, flexible, and configurable\n      3.1.1. Read this later! In the blog 5 Questions Every Unit Test Must Answer, Eric Elliott describes how unit tests are used. Here is a snippet from that post.\n     3.2. Integration Tests  Definition  Tests the interaction between multiple components to make sure that they play together nicely and work the way we expect them to work. These tests may run slower and usually mock out external dependencies such as external APIs or databases.\n Goals  Ensure all layers of the application fundamentally work together. Also give confidence that business critical workflows still work.\n Benefits    Tests user scenarios that touch multiple components, ensuring that the components work together to accomplish a goal\n  Easier to identify app failures caused by interactions between components\n       3.3. End-to-End Tests  Definition  Test the app\u0026#8217;s functionality as it will run in production, ensuring that all components and external dependencies are working as designed.\n   Example User logs in, adds items to a shopping cart, checkouts out which includes selection of shipping and payment methods.\n   Though they provide useful information, there are downsides to e2e tests. They can take a long time to run and will fail when the required external services are not available.\n  Goals  Ensures the application functions in its entirety from a user\u0026#8217;s start to finish. It verifies that all the code is working together and acts as a super integration test.\n Benefits    Detect problems in the application\n  Verifies the overall health of the application\n  Reduces future application breaks and outages\n         "
},
{
	"uri": "/software-eng-essentials/text-editors/intro-to-text-editors/",
	"title": "Introduction to Text Editors",
	"tags": [],
	"description": "",
	"content": "One of the most important tools a software developer uses is the text editor: where they write their software programs.\nDevelopers like to customize their text editors: making them visually appealing and more productivity by familiarizing ourselves with time saving shortcuts.\nIn this lesson we will teach you how to use a text editor, with emphasis on increasing code writing efficiency.\nLearning Objectives Concepts  Proper set up of coding environment Coding efficiently  Skills  Modify the configuration of a text editor to set the theme, font, tab settings, etc. Launch text editor from the command line Use find to search the current file or all of the files Change the layout to 2up, 3up, 4up, etc. Install plugins Use cool editing tricks such as:  select and edit several lines at once select and edit in \u0026ldquo;column mode\u0026rdquo; move the selected line up or down   Use keyboard shortcuts to save time  What is a Text Editor?  Provides an interface for viewing and modifying text files, which contain human readable text There are different kinds of text editors:  terminal / command line: vim, emacs, nano window based: VS Code, Atom, Sublime, TextMate, Notepad++    Modern Text Editors   Can open a file or a directory\n  Can understand context:\n context sensitive help may highlight errors or bad practices in your code adapt to different file formats provide syntax highlighting    extensions \u0026amp; plugins - used to add additional features to the editor\n  Types of Text Files  Plain text Markdown CSV Various Programming Languages  HTML CSS JavaScript Ruby BASH SQL   Each programming language has a set of rules, keywords, operators, and syntax  Additional Resources  VS Code Atom  "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/supplemental/mac-shortcuts/",
	"title": "Mac Shortcuts",
	"tags": [],
	"description": "",
	"content": "Mac keyboard shortcuts  Save: command + s Quit: command + q Copy: command + c Paste: command + v Force Quit: command + option +escape  Mac commands review When you need to open a program on a Mac, simply type command + spacebar and the Spotlight Search bar will appear. Type the name of the program and press return to open it.\nTo save a file in a text editor such as VS Code, press command + s to save.\nIn order to quit a program, use command + q\nIn the event a program has frozen, use the Force Quit option (similar to Control-Alt-Delete) which is command + option +escape\nTo right click on the Mac\u0026rsquo;s mouse, let\u0026rsquo;s first open the System Preferences to view the default settings. Do command + spacebar and type mouse and hit enter\nYou can enable the two-finger right-click in these settings.\n"
},
{
	"uri": "/application-security/api-security/02_human_to_service_oidc/10_modern-webapps/",
	"title": "Modern Web Applications",
	"tags": [],
	"description": "",
	"content": "Two In One These days WebApp are really two different apps shoved together:\n SPA - Single Page Apps. Usually React or Angular, and to a lesser extent jQuery or Vue. But they operate as an independent ephemeral app. BFF - Backend For the Frontend. The server side code that is responsible for facilitating the SPA. Serving the files and managing Identity and operating as a Proxy.  The SPA and the BFF have different responsibilities to be individually secure, but also secure in their connectivity with each other.\nConnected by Miles of Cable So the SPA may be in Guam but the BFF is in Austin, how do we secure their communications?\n OpenID Connect (OIDC) using the OAuth2 Auth Code Grant is the answer.  "
},
{
	"uri": "/python/nonrelational-db/mongo/",
	"title": "MongoDB and Python",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Installing the pymongo database adapter Using pymongo to connect to/disconnect from a database Executing MongDB CRUD statements in Python to interact with database resources  Set Up We are going to show how to connect and work with MongoDB and Python.\nYour instructor will be giving you the necessary credentials to connect to a Mongo database. Store these credentials as environment variables with the following keys:\n M_USER M_PASSWORD M_HOST  Create a new directory called mongo-python. Download and add the following files to this new directory:\n mongo_connect.py requirements.txt  Making your file structure look like:\nmongo-python |── requirements.txt └── mongo_connect.py Within that new directory, create a virtual environment and install all needed dependencies with the following:\npython3 -m venv venv source venv/bin/activate pip3 install -r requirements.txt Database Connection In mongo_connect.py, there is a MongoConnect class. This class is used to handle connecting, interacting, and disconnecting with a MongoDB server. The methods currently in the class are:\n __init__: this will create the connection to the database __del__: this will handle when the program ends and disconnect from the database  Once a database connection is established, it is possible to interact with and manipulate the database.\nIn order to do this, we need to create methods in the MongoConnect class.\nBecause MongoDB uses a database/collection/document data model, the methods used will reflect the some of the more common manipulative actions.\n create_collection: For creating collections within the database to store documents drop_collection: For removing collections within a database insert: For inserting documents into a collection find: For reading documents in a collection projection_find: For reading documents in a collection, returning only a subset of information from a document update: For updating a single document or documents in a collection delete: For deleting a single document or documents in a collection  Creating Mongo Collections The first step will be to create a collection. Collections store documents, similar to the way a table stores rows of data, just a different structure. Collections belong to databases. With an instance of a database opened, we can create a new collection by simply specifying the name of the collection. In MongoDB, if the collection does not exist, it will be created.\ncreate_collection will have one parameter called collection to hold the name of the collection to be created if it doesn\u0026rsquo;t exist.\nIn your mongo_connect.py file, add the following method in the MongoConnect class:\ndef create_collection(self,collection): success = False #1 if isinstance(collection, str) and collection != \u0026#34;\u0026#34;: #2 try: collection_connect = self.database[collection] #3 except Exception as e: print(\u0026#34;Error: \u0026#34;, e) #4 else: print(\u0026#34;Using collection \u0026#34;, collection_connect) #5  success = True else: print(f\u0026#34;Problem creating collection \u0026#39;{collection}\u0026#39;. Must be of type string and not empty.\u0026#34;) #6 return success #7 To test out this new method, create a new collection called Products. Add the following to your main function:\ndbcollection = \u0026#34;products\u0026#34; dbConnect.create_collection(dbcollection) Just as a collection can be created, a collection can also be dropped.\ndef drop_collection(self,collection): success = False if isinstance(collection, str) and collection != \u0026#34;\u0026#34;: try: drop_collection = self.database[collection] #1 drop_collection.drop() #2  except Exception as e: print(\u0026#34;Error: \u0026#34;, e) else: print(\u0026#34;Collection \u0026#34;, collection, \u0026#34; has been dropped\u0026#34;) success = True else: print(f\u0026#34;Problem dropping collection \u0026#39;{collection}\u0026#39;. Must be of type string and not empty.\u0026#34;) return success Insert To place documents into a table, execute insert statements to create a single documents into products collection with insert_one() function from pymongo.\nTo place multiple documents into a table at the same time, you use the insert_many() function.\nBoth of these tasks can be accomplished by calling creating the insert method and using parameters to determine with function to call.\ninsert will have three parameters:\n collection to specify the collection the query will run in query to hold the query for the document. If inserting a single document, the query must be in the form of a dictionary. If inserting multiple documents, query must be in the form of a list of dictionaries. multi will be an optional parameter that will specify if one or many documents are being inserted. By default, it is set to false  Insert the following in the MongoConnect class:\ndef insert(self, collection, query,multi=False): success = False if (isinstance(query, dict) and multi == False and (isinstance(collection, str) and collection != \u0026#34;\u0026#34;)) or (isinstance(query, list) and multi == True and (isinstance(collection, str) and collection != \u0026#34;\u0026#34;)): #1 try: insert_collection = self.database[collection] if multi == False: #2 success = insert_collection.insert_one(query) else: success = insert_collection.insert_many(query) #3  except Exception as e: print(\u0026#34;Error: \u0026#34;, e) else: if multi == False: #4 print(\u0026#34;The following ID has been inserted: \u0026#34;, success.inserted_id) else: print(\u0026#34;The following IDs has been inserted: \u0026#34;, success.inserted_ids) else: print(\u0026#34;Error: Query must be of type dictionary for single insert and list for multiple insert, and collection must be an unempty string.\u0026#34;) return success #5 To test out this new method, add the following to your main function:\n# Insert 1 document new_document = {\u0026#34;name\u0026#34;:\u0026#34;shop towels\u0026#34;, \u0026#34;description\u0026#34;:\u0026#34;picks up any shop mess quickly\u0026#34;} dbConnect.insert(dbcollection, new_document) # Insert multiple documents new_documents = [ {\u0026#39;_id\u0026#39;: ObjectId(\u0026#39;5ebda7bc649ebf02929de639\u0026#39;), \u0026#39;name\u0026#39;: \u0026#39;rake\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;removes all the leaves\u0026#39;}, {\u0026#39;_id\u0026#39;: ObjectId(\u0026#39;5ebda7bc649ebf02929de63a\u0026#39;), \u0026#39;name\u0026#39;: \u0026#39;toolbox\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;holds all the tools\u0026#39;}, {\u0026#39;_id\u0026#39;: ObjectId(\u0026#39;5ebeda1fd20203cbb9784dd5\u0026#39;), \u0026#39;name\u0026#39;: \u0026#39;drill\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;pushes through any material\u0026#39;}, {\u0026#39;_id\u0026#39;: ObjectId(\u0026#39;5ec1ac60d20203cbb9784de0\u0026#39;), \u0026#39;name\u0026#39;: \u0026#39;lawnmower\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;cuts the grass\u0026#39;}, {\u0026#39;_id\u0026#39;: ObjectId(\u0026#39;5ec1acb9d20203cbb9784de1\u0026#39;), \u0026#39;name\u0026#39;: \u0026#39;big lawnmower\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;cuts the really tall grass\u0026#39;}, {\u0026#39;_id\u0026#39;: ObjectId(\u0026#39;5ec1acb9d20203cbb9784de2\u0026#39;), \u0026#39;name\u0026#39;: \u0026#39;vice grips\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;grips and hold your stuff\u0026#39;}, {\u0026#39;_id\u0026#39;: ObjectId(\u0026#39;5ec588049b75032f2a856e75\u0026#39;), \u0026#39;name\u0026#39;: \u0026#39;mop\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;soaks up everything and wrings dry\u0026#39;}, {\u0026#39;_id\u0026#39;: ObjectId(\u0026#39;5ec588049b75032f2a856e76\u0026#39;), \u0026#39;name\u0026#39;: \u0026#39;laminate flooring\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;looks like wood, performs like vinyl\u0026#39;}, {\u0026#39;_id\u0026#39;: ObjectId(\u0026#39;5ec588049b75032f2a856e77\u0026#39;), \u0026#39;name\u0026#39;: \u0026#39;berber carpet\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;soft underfoot and kid friendly.\u0026#39;}] dbConnect.insert(dbcollection, new_documents,True) Read The reading operation on any database means to fetch some useful information from the database. Once our connection is established, you are ready to make a query with the find() function from pymongo. The find() function has many options available. We will use it to perform 2 common tasks - finding specific documents and finding all documents.\nIn the MongoConnect class, the find() method will take two parameters.\n collection parameter to specify the collection the query will run in query parameter is initially set to None, which is execute the without a query and return all documents. Otherwise, with a value for query, the documents returned will only satifisfy the specified query.  Add the following to the MongoConnect class:\ndef find(self, collection, query=None): success = False # The find query returns a cursor. The \u0026#34;success\u0026#34; variable will be set to the value of the query and returned. result = None if (isinstance(query,dict) or query == None) and (isinstance(collection, str) and collection != \u0026#34;\u0026#34;): try: find_collection = self.database[collection] if isinstance(query,dict): result = find_collection.find(query) elif query == None: result = find_collection.find() except Exception as e: print(\u0026#34;Error: \u0026#34;, e) else: success = [] #1 for r in result: success.append(r) #2 else: print(\u0026#34;Error: query must be a dictionary or empty, and collection must be an unempty string.\u0026#34;) return success To test out this new method, add the following to your main function:\n# find all documents dbConnect.find(dbcollection) # find a specific document by name dbConnect.find(dbcollection, {\u0026#34;name\u0026#34;:\u0026#34;lawnmower\u0026#34;}) # find a specific document by id id = ObjectId(\u0026#39;5ec1acb9d20203cbb9784de2\u0026#39;) dbConnect.find(dbcollection, {\u0026#34;_id\u0026#34;: id}) The find() function from pymongo also allows for projection, the ability to return only certain fields from a document(s).\nWe will create a new method called projection_find() that will take in three arguments:\n collection to specify the collection we will query query which works just as in the find() method from our class fields which take in the fields to be displayed, in dictionary form where the key is the field to return and the value is either 1 (to include the field) or 0 (to exclude the field).  def projection_find(self, collection, query=None, fields=None): success = False results = None if (isinstance(query,dict) or query == None) and isinstance(fields,dict) and (isinstance(collection, str) and collection != \u0026#34;\u0026#34;): try: find_collection = self.database[collection] if (isinstance(query,dict) and isinstance(fields,dict)): results = find_collection.find(query, fields) else: results = find_collection.find({},fields) except Exception as e: print(\u0026#34;Error: \u0026#34;, e) else: success = [] for r in results: success.append(r) else: print(\u0026#34;Error: \u0026#39;fields\u0026#39; argument must be in dictionary form, and collection must be an unempty string.\u0026#34;) return success To test this new method, all the following to your main function:\n# Return all documents, only specific fields dbConnect.projection_find(dbcollection, None, {\u0026#34;name\u0026#34;:1, \u0026#34;_id\u0026#34;:0}) # Return specific document, only specific fields dbConnect.projection_find(dbcollection, {\u0026#34;name\u0026#34;:\u0026#34;lawnmower\u0026#34;},{\u0026#34;name\u0026#34;:1, \u0026#34;description\u0026#34;:1, \u0026#34;_id\u0026#34;:0}) Update The update operation on any database means to update one or more records, which are already available in the database. pymongo provides update_one() and update_many() functions. To simplify, we will create a single update method that will carry out both functions. The update method will have four parameters:\n collection to specify the collection for the query filter which will specify the query for the values to be updated new_value which will be the values, in dictionary format, that will used to update multi will specify if one value is being updated or many values are being update, default is False  def update(self, collection, filter, new_value, multi=False): success = False if isinstance(filter, dict) and isinstance(new_value, dict) and (isinstance(collection, str) and collection != \u0026#34;\u0026#34;): old = filter new = {\u0026#34;$set\u0026#34;: new_value} try: update_collection = self.database[collection] if multi == False: update_collection.update_one(old, new) else: update_collection.update_many(old, new) except Exception as e: print(\u0026#34;Error: \u0026#34;, e) else: print(f\u0026#34;Updates has been made to all documents matching {filter} to {new_value}\u0026#34;) success = True else: print(\u0026#34;Error updating: parameters old_value and new_value must be in dictionary format, and collection must be an unempty string.\u0026#34;) return success To test out this new method, add the following to your main function:\n# Update one record dbConnect.update(dbcollection, {\u0026#34;name\u0026#34;:\u0026#34;lawnmower\u0026#34;}, {\u0026#34;description\u0026#34;:\u0026#34;cuts the grass at many level. Self propelled.\u0026#34;}) #Update many records dbConnect.update(dbcollection, {}, {\u0026#34;description\u0026#34;:\u0026#34;really good item\u0026#34;}, True) Delete The delete operation is required when you want to delete documents from your collection. pymongo provides delete_one() and delete_many(). For simplification, we will use delete_many() for our class. The delete() method will have two parameters:\n collection to specify the collection for the query query default is none. With no value, all documents in the collection will be deleted. With a value, only those documents that satisfy the query will be deleted.  def delete(self, collection, query=None): success = False if isinstance(collection, str) and collection != \u0026#34;\u0026#34; and (query == None or isinstance(query, dict)): try: delete_collection = self.database[collection] if isinstance(query,dict): success = delete_collection.delete_many(query) elif query == None: success = delete_collection.delete_many({}) except Exception as e: print(\u0026#34;Error: \u0026#34;, e) else: print(f\u0026#34;{success.deleted_count} document(s) deleted\u0026#34;) else: print(\u0026#34;Error deleting: Collection must be an unempty string.\u0026#34;) return success To test out this new method, add the following to your main function to delete all students that have a hotmail email:\n# delete a document dbConnect.delete(dbcollection, {\u0026#34;name\u0026#34;:\u0026#34;lawnmower\u0026#34;}) # delete all documents dbConnect.delete(dbcollection) To test dropping a collection, add the following to the main function:\n# drop a collection dbConnect.drop_collection(dbcollection) Summary Database adapters like pymongo provide many useful functions that allow a straight-forward connection to a database and easy schema and resource creation. The code base requires a minimal amount of imports and allows the use of pure Python code with recognizable statements. To see more useful functions, visit the Pymongo documentation.\nLab Clone down the repo for the Mongo Python lab with the following instructions:\ngit clone https://github.homedepot.com/om-labs/python-nonrelational-databases.git cd python-nonrelational-databases/mongodb-python Follow the instructions in the README\n"
},
{
	"uri": "/javascript/pillars/restful-api-express-node/",
	"title": "Node Pillar: Build a RESTful API with NodeJS and Express",
	"tags": [],
	"description": "",
	"content": "Welcome to RESTful API with NodeJS and Express! "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/labs/lab-paths/",
	"title": "Paths Lab",
	"tags": [],
	"description": "",
	"content": "Using the below directory structure, answer the following with a neighbor:\n What is the absolute path for pic4.png? If you are in the Users/homer directory, what is the relative path for pic4.png? If you are in the Users/homer/Pictures directory, what is the relative path for lol-cat3.jpg?  . └── Users ├── homer │ ├── Applications │ │ └── Chrome │ │ └── VSCode │ ├── Desktop │ │── Documents │ │ └── Resume.pages │ │ └── Resume.pdf │ ├── Music │ └── Pictures │ └── 2017 │ │ └── pic1.jpg │ │ └── pic2.png │ │ └── pic3.gif │ └── 2018 │ │ └── pic4.png │ │ └── pic5.png │ │ └── pic6.jpg │ └── 2019 │ │ └── lol-cat1.jpg │ │ └── lol-cat2.jpg │ │ └── lol-cat3.jpg │ └── 2020 └── Guest ├── Applications ├── Orange Academy │ └── fun-cat.jpg ├── Desktop ├── Documents ├── Music └── Pictures "
},
{
	"uri": "/software-eng-essentials/postman-foundations/getting_started/",
	"title": "Postman Essentials",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Postman App Use Explanation of API\u0026rsquo;s, SOAP, and REST Making a Simple Postman Request  Postman Intro Postman is an App used for interacting with APIs. Postman\u0026rsquo;s easy to navigate UI and functionality helps simplify communication with APIs. Postman supports testing both SOAP and REST APIs, however for this lesson we will focus on REST.\nWhat\u0026rsquo;s an API? Application Programming Interface, APIs, are the way the web-based applications communicate with each other and with us.\n Checking the score for your favorite sports team via ESPN.com? You\u0026rsquo;re interacting with the ESPN API. Posting a message on Facebook and seeing it \u0026ldquo;magically\u0026rdquo; appear in your Twitter feed? You are interacting with the Facebook API, which then sends communication to the Twitter API.  API is the \u0026ldquo;handshake\u0026rdquo; or data-exchange that happens between web-based applications. That data-exchange is governed by several design models for web services, but the two most dominant are:\n Simple Object Access Protocol (SOAP) is a protocol that follows very rigid rules for security and message handling. Representation State Transfer (REST) is an architectural style that offers a more flexible handshake using simple HTTP protocols to a URI (Uniform Resource Identifier).  For a more thorough explanation about REST and SOAP, checkout the links in the Additional Resources section below.\nThis lessons focuses on RESTful APIs, communication done using HTTP verbs:\n POST - most-often utilized to create new resources GET - used to read (or retrieve) a representation of a resource PUT - most-often utilized for update capabilities with the request body containing the newly-updated representation of the original resource. PATCH - used for modify capabilities. Unlike PUT, The PATCH verb request only needs to contain the changes to the resource, not the complete resource. DELETE - used to delete a resource  There are other verbs used, however, we will focus on these as they handle:\n Create Read Update Delete*  or CRUD, the most typical activities used with interacting with an APIs resource (database).\nSign up for Postman To get Postman from the Home Depot App Store, select the Postman App and click install. Once the app finishes installing, click the icon to open.\nIMPORTANT: You can download the Postman Native app directly from the Postman website. Refer to Postman App documentation for instructions.\nIf you already have a Postman account, just login with your credentials. Otherwise, you will need to sign up for an account.\n  Once you are logged in, you\u0026rsquo;ll be taken to your workspace.\nWork performed in Postman is divided into Workspaces. Individuals can organize their work in personal workspaces and teams can collaborate in team workspaces.\nThe default workspace is My Workspace.\nMaking an API Call One of the simplest RESTful calls is a GET call to retrieves data from a URI, that will look a lot like a URL. This URL is know as an Endpoint.\nAn Endpoint is a unique URL that represents an object or collection of objects that an HTTP client uses to interact with data resources.\nAn API\u0026rsquo;s documentation can help to understand the API requirements and the data set that is returned. Based on the entry you provide, the API will return a data set response. The most popular response formats are XML and JSON.\nJSON HTTP headers\nPOST /api/2.2/auth/signin HTTP/1.1 HOST: my-server Content-Type:application/json Accept:application/json\tJSON HTTP response body\n{ \u0026#34;credentials\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Joe Smith\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;Atlanta, GA\u0026#34;, \u0026#34;building\u0026#34;: { \u0026#34;Headquarters\u0026#34;: { \u0026#34;floor\u0026#34;: 15, \u0026#34;section\u0026#34;: 213 } } } } Example of XML response\n?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;root\u0026gt; \u0026lt;credentials\u0026gt; \u0026lt;building\u0026gt; \u0026lt;Headquarters\u0026gt; \u0026lt;floor\u0026gt;15\u0026lt;/floor\u0026gt; \u0026lt;section\u0026gt;213\u0026lt;/section\u0026gt; \u0026lt;/Headquarters\u0026gt; \u0026lt;/building\u0026gt; \u0026lt;location\u0026gt;Atlanta, GA\u0026lt;/location\u0026gt; \u0026lt;name\u0026gt;Joe Smith\u0026lt;/name\u0026gt; \u0026lt;/credentials\u0026gt; \u0026lt;/root\u0026gt; Both responses contain the same data, just presented in different ways. Depending on your needs and the standard response of the API, it may be necessary to parse/convert the response to fit your development requirements.\nDemo The Request Builder toolbar, found at the top of the workspace, has a button that says GET and an input box next to it. The input box is where you provide the API Endpoint.\nFor simplicity, we will use the MARTA Bus Realtime RESTful API.\nFor information about the MARTA API, check out the MARTA Bus Realtime RESTful API documentation. There are two endpoints associated with this API. We will use http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetAllBus.\nPress the SEND button.\nThis will return a JSON response that list all real-time travel information for all buses in the MARTA system.\nThe Response Header, found lower portion of the page, has two sections of importance:\n the return status code the response format.  Status codes have different meanings, depending on the first digit in the 3-digit return code. The most common status codes are:\n 1xx - Informational 2xx - Success (200 is a common return code for communication the request was received successfully) 3xx - Redirection 4xx - Client Error (404 is a common return code for when the information requested is not found) 5xx - Server Error (500 is a common code for stating an error with the API server)   To see a complete list of status codes and definitions, check out the Additional Services below.\n It is possible to look at the response format in the Body tab. This tab gives you several tools to help you understand the response in one of three views - pretty, raw, and preview.\n Pretty - formats JSON or XML responses so they are easier to view. Raw - raw view is a large text area within the response body. It can be difficult to read as it used little \u0026ldquo;white space\u0026rdquo;. Preview - renders the response as it would be seen in the browser.  The pretty version of the response will look like:\n[ { \u0026#34;ADHERENCE\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;BLOCKID\u0026#34;: \u0026#34;76\u0026#34;, \u0026#34;BLOCK_ABBR\u0026#34;: \u0026#34;12-7\u0026#34;, \u0026#34;DIRECTION\u0026#34;: \u0026#34;Eastbound\u0026#34;, \u0026#34;LATITUDE\u0026#34;: \u0026#34;33.8151923\u0026#34;, \u0026#34;LONGITUDE\u0026#34;: \u0026#34;-84.180358\u0026#34;, \u0026#34;MSGTIME\u0026#34;: \u0026#34;9/7/2021 9:43:50 PM\u0026#34;, \u0026#34;ROUTE\u0026#34;: \u0026#34;120\u0026#34;, \u0026#34;STOPID\u0026#34;: \u0026#34;902336\u0026#34;, \u0026#34;TIMEPOINT\u0026#34;: \u0026#34;Ponce de Leon Ave \u0026amp; Hairston Rd\u0026#34;, \u0026#34;TRIPID\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;VEHICLE\u0026#34;: \u0026#34;1615\u0026#34; }, { \u0026#34;ADHERENCE\u0026#34;: \u0026#34;-16\u0026#34;, \u0026#34;BLOCKID\u0026#34;: \u0026#34;237\u0026#34;, \u0026#34;BLOCK_ABBR\u0026#34;: \u0026#34;194-5\u0026#34;, \u0026#34;DIRECTION\u0026#34;: \u0026#34;Eastbound\u0026#34;, \u0026#34;LATITUDE\u0026#34;: \u0026#34;33.7624866\u0026#34;, \u0026#34;LONGITUDE\u0026#34;: \u0026#34;-84.3405363\u0026#34;, \u0026#34;MSGTIME\u0026#34;: \u0026#34;9/7/2021 9:44:02 PM\u0026#34;, \u0026#34;ROUTE\u0026#34;: \u0026#34;102\u0026#34;, \u0026#34;STOPID\u0026#34;: \u0026#34;904308\u0026#34;, \u0026#34;TIMEPOINT\u0026#34;: \u0026#34;Ponce De Leon @ Ponce City Mkt\u0026#34;, \u0026#34;TRIPID\u0026#34;: \u0026#34;7004832\u0026#34;, \u0026#34;VEHICLE\u0026#34;: \u0026#34;1613\u0026#34; }, ... ] This response resembles an array of objects, where each object is information about a bus.\nAnother endpoint from MARTA returns a list of buses based on the route number. The following url will show route 14 and press send: http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetBusByRoute/14.\n[ { \u0026#34;ADHERENCE\u0026#34;: \u0026#34;-2\u0026#34;, \u0026#34;BLOCKID\u0026#34;: \u0026#34;108\u0026#34;, \u0026#34;BLOCK_ABBR\u0026#34;: \u0026#34;132-1\u0026#34;, \u0026#34;DIRECTION\u0026#34;: \u0026#34;Westbound\u0026#34;, \u0026#34;LATITUDE\u0026#34;: \u0026#34;33.7879355\u0026#34;, \u0026#34;LONGITUDE\u0026#34;: \u0026#34;-84.4156469\u0026#34;, \u0026#34;MSGTIME\u0026#34;: \u0026#34;9/7/2021 10:13:52 PM\u0026#34;, \u0026#34;ROUTE\u0026#34;: \u0026#34;14\u0026#34;, \u0026#34;STOPID\u0026#34;: \u0026#34;213386\u0026#34;, \u0026#34;TIMEPOINT\u0026#34;: \u0026#34;14th St \u0026amp; Howell Mill Rd\u0026#34;, \u0026#34;TRIPID\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;VEHICLE\u0026#34;: \u0026#34;1904\u0026#34; }, { \u0026#34;ADHERENCE\u0026#34;: \u0026#34;-4\u0026#34;, \u0026#34;BLOCKID\u0026#34;: \u0026#34;107\u0026#34;, \u0026#34;BLOCK_ABBR\u0026#34;: \u0026#34;126-4\u0026#34;, \u0026#34;DIRECTION\u0026#34;: \u0026#34;Eastbound\u0026#34;, \u0026#34;LATITUDE\u0026#34;: \u0026#34;33.8014018\u0026#34;, \u0026#34;LONGITUDE\u0026#34;: \u0026#34;-84.429685\u0026#34;, \u0026#34;MSGTIME\u0026#34;: \u0026#34;9/7/2021 10:15:15 PM\u0026#34;, \u0026#34;ROUTE\u0026#34;: \u0026#34;14\u0026#34;, \u0026#34;STOPID\u0026#34;: \u0026#34;901680\u0026#34;, \u0026#34;TIMEPOINT\u0026#34;: \u0026#34;Chattahoochee Av \u0026amp; Southland Cir\u0026#34;, \u0026#34;TRIPID\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;VEHICLE\u0026#34;: \u0026#34;1907\u0026#34; } ] As you can see, this returned a smaller response. While MARTA only offers two endpoints, other APIs like Yelp and Google offer an array of endpoints giving you access to large amounts and variations of their data.\nAuthorizations It is common for APIs to require an authorization key to interact with them. These keys are provided by the administrator of the API. This process verifies whether you have permission to access the data you want from the APIs server.\nWhen you select the “Authorization” tab in the request builder, you see the authorization TYPE drop down menu:\n   Inherit Auth From Parent - uses the authorization type from the parent. No Auth - (default) used when authorization is not required. Bearer Token - A bearer token is a security token used to access data. Basic Auth - requires a verified username and password to access the data resource. Digest Auth - the client sends a request to a server, which sends back nonce and realm values for the client to authenticate. The client sends back a hashed username and password with the nonce and realm. The server then sends back the requested data. OAuth 1.0 and OAuth 2.0 - These authorizations type that enables you to approve an application that contacts another application without exposing your password. Hawk Authentication - Hawk authentication enables you to make authenticated requests with partial cryptographic verification of the request. AWS Signature - the authorization workflow for Amazon Work Services requests. NTLM Authentication [Beta] - Windows Challenge/Response (NTLM) is the authorization flow for the Windows operating system and for stand-alone systems.  For more information see the Additional Resources list below.\nAdditional Resources  Stackify: SOAP vs. REST Understanding SOAP and REST basics SOAP vs. REST: A Look at Two Different API Styles Postman Authorizations REST API Tutorial: HTTP Status Codes  "
},
{
	"uri": "/software-eng-essentials/comp-sci/programming-languages/",
	"title": "Programming Languages Fundamentals",
	"tags": [],
	"description": "",
	"content": "Introduction The primary goal for all programming languages is to provide a language that is both:\n easy for humans to read, write, maintain, and understand precise, non-ambiguous, and deterministic - so that computers can execute the code without any surprises  There are many other goals as well, such as:\n support for high performance execution efficient resource usage (memory, CPU, etc.) security ensure correctness (static typing, compilation, linting rules)  Characteristics of Programming Languages Programming languages have several characteristics that help to define the design of the language, such as:\n compiled vs. interpreted Static vs. dynamic typing OOP vs. FP Garbage collected vs. manual managed memory  Understanding these characteristics is helpful when learning a programming language or comparing various programming languages.\nIn this lesson we are going to define each of these characteristics and get an idea of the advantages and disadvantages of each.\nCompiled vs. Interpreted When a computer executes code, it can only execute the binary representation that matches the CPU\u0026rsquo;s instruction set and data encoding. All program source code must be converted in some way to this native binary representation.\n The main goal of both compilation and interpretation is to transform the human-readable source code into machine code that can be executed directly by a CPU. The difference between compilation and interpretation is in how the language is converted into this machine code.   NOTE: Technically speaking, a programming language itself does not define whether it is a compiled or interpreted language. It\u0026rsquo;s the implementation of the language that decides whether to use compilation or interpretation. In fact, there are many programming languages that have been implemented using both compilers and interpreters. But in practice most languages are designed with features that either favor a compiled or an interpreted implementation.\n For a compiled implementation, the program source code (what we type into our text editor) must first run through a compiler to be converted into the target machine code. This machine code is usually saved to an executable file that is ready for direct execution on the target machine\u0026rsquo;s CPU.\nCompiled Languages A compiled language is a programming language that is typically implemented using compilers rather than interpreters. A compiler is a program that translates statements written in a particular programming language into another language, usually machine code. Compilers translate the source code to machine code ahead of execution time (instead of during execution time).\n  The benefits of compiled languages are:\n performance as the executable that contains machine code can be directly executed on the target machine without any additional steps compile time code verification - the compiler can verify that the source code does not violate many of the rules of the programming language  The main drawbacks are:\n reduced portability as programs have to be compiled for a specific CPU architecture potentially long compilation times  Examples of popular compiled languages are C, C++, Go, Rust, and Haskell.\n Question: What language is a language\u0026rsquo;s compiler written in? For instance, what language is the gcc C compiler written in 🤔? And how do you compile the compiler?\n Interpreted Languages An interpreted language (sometimes called a scripting language) is a programming language that is typically implemented using interpreters and thus doesn’t compile source code directly into machine code ahead of execution.\nThe interpreter executes a program by translating each statement into a sequence of one or more subroutines that themselves have already been compiled into machine code. We can say that the interpreter translates programs on the fly instead of focusing on the whole program at once.\n  The main benefits of using an interpreted language are:\n portability as programs don’t have to be compiled for a specific CPU architecture no compilation stage.  The main drawbacks are:\n slower execution speed reduced static code analysis (no compile time may result in more runtime errors) the potential for leaking source code if the non-obfuscated source code is sent to the client  Examples of popular interpreted languages are JavaScript, Python, Ruby, and PHP.\nCombining Compiled and Interpreted - Virtual Machines There is also a hybrid approach that leverages some of the advantages of being both compiled and interpreted where the program source code is compiled into a byte code that targets a virtual machine.\nThe virtual machine can then interpret the byte code in a more highly efficient manner than a fully interpreted language.\nJava is an example of this approach. The javac compiler converts the Java source code into Java byte code that is then executed by the Java Virtual Machine (JVM).\n  JIT Compilation Finally some interpreters also use JIT or just-in-time compilation to compile the source code during runtime (while executing the application).\n The purpose of JIT compilation is to improve runtime performance. The interpreter may apply JIT compilation for longer running sections of the source code, such as nested loops. The JIT compiler can profile (monitor) the code while it is executing to determine when JIT compilation will be beneficial. The Java JVM does a lot of JIT compilation, resulting in a reasonably fast execution environment. The JavaScript V8 engine also does JIT compilation. In fact, V8 has an internal compiler called TurboFan that compiles JavaScript directly to native machine code before executing it.  Static vs. Dynamic Typing Often languages that favor compilation will also have static typing, while languages that favor interpreters will use dynamic typing. So what is static and dynamic typing?\nFirst let\u0026rsquo;s define data types. A data type is a way of describing what a piece of data is. Since all data is internally represented as zeros and ones, we need a way to specify what those zeros and ones represent. The common primitive data types are:\n a number (which may be subdivided into integer and floating point) a single character (such as a \u0026ldquo;t\u0026rdquo;, \u0026ldquo;m\u0026rdquo; or \u0026ldquo;?\u0026quot;) a string - a sequence of characters a boolean - a value of \u0026lsquo;true\u0026rsquo; or \u0026lsquo;false\u0026rsquo;  Composite data types can be defined that consists of groupings of these primitive data types. Examples include:\n An Array - an ordered collection of (usually similar in type) data values An Object - a named group of data values  Back to our original question: \u0026ldquo;What is static and dynamic data typing?\u0026rdquo;\nStatic Typing Static Typing is when a variable is assigned both a value and a specific data type. The value can usually be modified (mutation) but the data type must be preserved.\nExample:\nString greeting = \u0026#34;Hello\u0026#34;; // greeting is a String variable  // with a value of \u0026#34;Hello\u0026#34;  System.out.println(greeting); greeting = 23; // this line generates a compiler error as `greeting` can only be assigned  // to a String value. Advantages of Static Typing:\n Compile time verification - also known as \u0026ldquo;type safety\u0026rdquo;, the compiler can verify that the variables and function parameters are being assigned values consistent with their declaration. For example, assigning a string value to a numeric variable would result in a compile-time error. Self-documenting code - by declaring each variable\u0026rsquo;s data type, it becomes more clear what values are expected to be assigned to the variable (or passed to a function or method). Tooling - since all variables and function parameters are declared with a specific data type, code editors and IDEs can provide assistance while coding in the form of code completion and popup documentation.  Dynamic Typing Dynamic Typing is when a variable can be reassigned both its value and its data type. Thus a variable that is assigned a numeric value could later be reassigned to a string value.\nExample:\nlet greeting = \u0026#34;Hello\u0026#34;; // greeting is assigned to the string value of \u0026#34;Hello\u0026#34; console.log(greeting); greeting = 23; // greeting is now assigned to the numeric value of 23. Note that while this  // is valid code it is NOT RECOMMENDED. (just because you CAN do this doesn\u0026#39;t mean you should). Advantages of Dynamic Typing:\n Simplicity - defining the proper data types, especially for function parameters, can become difficult to maintain over time. Less Verbose - dynamic typing avoids all of the verbosity of defining data types for all variables and function parameters. This is especially true when using higher-order functions.  Consider the following example in Go:\nfunc makeAdder(x int) func(int) int { return func(y int) int { return x + y } } func main() { add3 := makeAdder(3) fmt.Println(add3(7)) } Note the first line in the example above that reads:\nfunc makeAdder(x int) func(int) int { The way to read this is:\n makeAdder is a function that takes a single parameter x which is an int and returns a function that takes a single int parameter that itself returns an int.\n Here is the same example in JavaScript:\nconst makeAdder = x =\u0026gt; y =\u0026gt; x + y const add3 = makeAdder(3) console.log(add3(7)) The JavaScript code is much shorter (less verbose) but loses the type safety that comes with static typing.\nOOP vs. FP vs. Procedural The history of OOP and FP is complex and interesting and include many topics such as Turing Machines and Lambda Calculus.\nAt its simplest we can say that:\n OOP is based on modeling the real world in software FP is based on precise mathematical concepts, such as higher-order functions, set theory, referential transparency, etc.  Often it seems that OOP is more intuitive to learn but can lead to verbose and overly complex code that is difficult to maintain.\nFP (at least in its pure form) provides more strict rules but these rules can help you to write cleaner code that performs better and is easier to maintain. While learning FP is a steeper, slower path, many profess that it leads to\nWhat is OOP? Alan Kay, The inventor of OOP and the SmallTalk language, stated:\n I\u0026rsquo;m sorry that I long ago coined the term \u0026ldquo;objects\u0026rdquo; for this topic because it gets many people to focus on the lesser idea. The big idea is messaging. ~Alan Kay\n He also said this:\n OOP to me means only messaging, local retention and protection and hiding of state-process, and extreme late-binding of all things. ~Alan Kay\n Regardless of Alan Kay\u0026rsquo;s original intent, most OOP languages focus on the following features:\n Objects that encapsulate both state (via object properties) and behavior (via object methods) Inheritance - Objects can inherit common traits from either Classes or Prototype objects Abstraction and Polymorphism - Objects that have similar interfaces but varying implementations can be treated in a similar fashion. For example, calling dog.speak() or cat.speak() does something similar but the results are not the same.  See The Forgotten History of OOP | Eric Elliot\n NOTE: Perhaps the truest OOP language that follows the original intent of Alan Kay\u0026rsquo;s research is the Erlang programming language. Due to its reliability and fault tolerance, Erlang remains very popular today in certain sectors such as telecommunications.\n The Promise of OOP OOP grew in popularity as it promised to solve the scalability / complexity problem, which is that as programs grow in size (their feature set scales) they also gro in complexity, becoming more and more difficult to maintain and ensure correctness.\nWhile OOP did help to solve the scalability / complexity problem to a degree, it did not solve it completely, and OOP introduced some new problems along the way.\nProblems with OOP  In recent years OOP has fallen under scrutiny as introducing many problems even as it claims to solve others.\nThe problems generally discusses are:\n fragile inheritance relationships - resolved with favoring composition over inheritance the fragile base class problem - resolved by not putting implementation in parent classes (only use interfaces for inheritance) promoting shared mutable state - partially resolved by avoiding public setter methods promoting too much coupling  While following best practices in using OOP does help, at some point following the OOP paradigm becomes questionable.\nThe Banana, Gorilla, Jungle Problem  The biggest problem with OOP has been that the encapsulation of both state and behavior leads to a lot of coupling that becomes difficult to reason about and maintain.\nHere is a famous quote that describes this problem:\n I think the lack of reusability comes in object-oriented languages, not functional languages. Because the problem with object-oriented languages is they’ve got all this implicit environment that they carry around with them. You wanted a banana but what you got was a gorilla holding the banana and the entire jungle.\nIf you have referentially transparent code, if you have pure functions — all the data comes in its input arguments and everything goes out and leave no state behind — it’s incredibly reusable.\n~Joe Armstrong, creator of Erlang, on software reusability.\n This is now commonly referred to as the \u0026ldquo;Banana, Gorilla, Jungle\u0026rdquo; problem.\nThe Inheritance Problem Inheritance promises to provide both abstraction and code reuse. For example, having a Dog extends Pet and a Cat extends Pet means that both dogs and cats can be treated as pets and may even share some behavior.\nThe problem with inheritance is that often the inheritance relationships start to break down. These isA relationships are not as clear cut as we would like them to be.\nTo address this problem, Composition is often used as an alternative to Inheritance\nFor more information on this, see Composition over Inheritance | Youtube.\nWhat is FP?  In its purest form, Functional Programming is programming without side-causes or side-effects.\n side-causes - environmental factors that affect the behavior of the function, such as global variables, timers, random number generators, etc. side-effects - changes to the environment, such as creating a file, updating a database, or writing to the console.  Pure functions are function that take data as input and return data as output without any dependence on outside factors such as global variables, file systems, databases, or even user input.\nBy avoiding side-effects, pure functions are easy to understand, test, and reuse. If written correctly, pure functions can be easily composed to build complex programs from simple parts where each part can stand on its own.\n \u0026ldquo;Sometimes, the elegant implementation is just a function. Not a method. Not a class. Not a framework. Just a function.\u0026rdquo; \u0026ndash;John Carmack, creator of DOOM\n How Does FP Affect Anything  At some point a real program must have side-effects, such as:\n reading or writing to a database interacting with a user calling a server to get data updating a file  The point of FP isn\u0026rsquo;t to totally eliminate all side-effects, but rather to separate the side-effects from the main logic of the program.\nIs FP the Future? FP does seem to offer a lot of advantages, including:\n improved readability improved reusability easier testability better support for concurrency code compactness  Consider the following implementations of the quicksort algorithm:\nQuicksort in Java:\npublic static void quickSort(int[] arr, int s, int e) { if (s \u0026gt;= e) { return; } int m = (s + e) / 2; int pivot = arr[m]; int l = s; int r = e; while (l \u0026lt;= r) { while(arr[l] \u0026lt; pivot) l++; while(arr[r] \u0026gt; pivot) r--; if (l \u0026lt;= r) { swap(arr, l++, r--); } } quickSort(arr, s, r); quickSort(arr, l, e); } public static void swap(int[] arr, int i, int j) { int t = arr[i]; arr[i] = arr[j]; arr[j] = t; } Quicksort in Haskell:\nquicksort :: (Ord a) =\u0026gt; [a] -\u0026gt; [a] quicksort [] = [] quicksort (x:xs) = smaller ++ [x] ++ bigger where smaller = quicksort $ filter (\u0026lt;= x) xs bigger = quicksort $ filter (\u0026gt; x) xs Thus it seems that FP is emerging as a better way to build modern, scalable software programs.\nProcedural Programming Procedural programming is simply programming with procedures (aka subroutines) instead of functions.\nProcedural programming predates OOP and embraces side-causes and side-effects. It does not attempt to isolate them to different parts of the program.\nTo compare:\n function - takes data as input and returns data as output. pure function - a function with no side-causes or side-effects. Procedure - a function that may or may not take data as input, may or may not return data as output, and may or may not have side-causes or side-effects.  While procedural programming is not as elegant as FP, it is very simple to learn and practice.\nThe following are all procedural programming languages:\n Fortran ALGOL COBOL BASIC Pascal C Go  Hybrid Languages Many languages provide features that support both OOP and FP. Examples include:\n Java - predominately an OOP language but has added support for FP JavaScript - provides both OOP and FP features Ruby - predominately an OOP language but has added support for FP Scala - A true hybrid language that attempts to blend OOP and FP  Memory Management In programming languages, data is stored either in stack memory or heap memory.\n stack memory - memory used to store variables of fixed length that are local to the currently active functions (the call stack) heap memory - memory used for storing global variables or variables containing large or variable length data  While the stack memory is fast and easy to manage, it\u0026rsquo;s size is limited. So for large data or data that grows (or shrinks) over time, heap memory must be used.\nAllocating heap memory often requires a call to the operating system kernel. The program requests a certain amount of memory (from several kilobytes to several megabytes or more) and the operating system locates, reserves, and returns the memory to the program.\nIn order to avoid a memory leak the program must eventually free the memory via another call to the operating system kernel. If the program continues to request heap memory but never frees heap memory, it may exhaust all available memory and crash (the program exits early with an error code).\nThere are different strategies to allocating and freeing heap memory. The most common are:\n manual memory management - the programmer must call API methods to allocate and free heap memory at the appropriate times in the program. garbage collection - the program contains a runtime that monitors heap memory usage; when there are no more references to a block of allocated memory, it can be \u0026ldquo;garbage collected\u0026rdquo;, i.e. freed via a call to the O.S. kernel.   NOTE: the descriptions above are a bit oversimplified. For example, a garbage collected language runtime may manage it\u0026rsquo;s own heap memory pool to reduce the overhead of making frequent calls to the O.S. kernel.\n The advantage of manual memory management is that it does not require a runtime library to monitor heap memory usage, a process that incurs overhead. The disadvantage of manual memory management is that it requires the developer to ensure that all memory is properly managed.\nSpecial Purpose Languages Languages are generally separated into either general purpose or special purpose.\nUp to this point we have been discussing general purpose programming languages. But it should be noted that there are many special purpose or domain specific languages that are used to solve specific problems in a particular domain.\nExamples include:\n   Language Description Applications     HTML HyperText Markup Language Structuring a web page   CSS Cascading Style Sheets Styling a web page   SQL Structured Query Language Reading and Wrting to a relational DB   Regular Expressions (RegEx) For describing/searching/validating patterns of strings Searching text, parsing and validating string data   Prolog A logic or facts and rules based language A.I., pattern matching, natural language processing, expert systems   YACC A language for describing computer language grammars yes there is a language for defining programming languages    Resources  Programming Paradigm | Wikipedia Compiled vs Interpreted Programming Languages The Forgotten History of OOP | Eric Elliot Object-Oriented Programming — The Trillion Dollar Disaster  "
},
{
	"uri": "/javascript/performance/universal-rendering-lab/project-setup/",
	"title": "Project Setup",
	"tags": [],
	"description": "",
	"content": "Purpose: To get hands-on experience with the implementation of universal rendering.\nIn this lab, we will clone down a client-side rendered application from Github and convert it to leverage universal rendering. When we are finished, we will measure the impact of universal rendering on the performance of our application.\nTo save time, and to limit the scope of this exercise to \u0026ldquo;how to implement universal rendering\u0026rdquo; rather than \u0026ldquo;how to set up a web server in Node.js\u0026rdquo;, much of the initial setup has been completed for you.\nIf you wish to know how to set up a web server in Node.js, how to create a bundle with Webpack, or how to use Babel to leverage new JavaScript syntax in Node.js, you can view the commit history of the project here: https://github.com/one-thd/om_labs_performance-workshop/commits/master\nPull down the code from Github  Open up a new terminal window mkdir dev \u0026amp;\u0026amp; cd dev git clone https://github.com/one-thd/om_labs_performance-workshop.git performance-workshop When prompted, authenticate with Github using your LDAP and password cd performance-workshop  Build and run the code  Install dependencies:npm install Build the code: npm run build Start the development server: npm run start A development server should now be running at http://localhost:8080. When you make changes to the code, run npm run build and then npm run start again.  Open project in VSCode (or preferred code editor) In VSCode:\nFile -\u0026gt; Open\u0026hellip; Press command and shift and g at the same time Type ~/dev into the \u0026ldquo;Go to the folder\u0026rdquo; text input Press \u0026ldquo;Go\u0026rdquo; Click on the folder named \u0026ldquo;performance-workshop\u0026rdquo; Click \u0026ldquo;Open\u0026rdquo;  Folder structure / The root folder of the project contains all project-level configuration files.\n/src This folder contains all of the source files for our project, e.g. all files that are not the output of a build and all files that are not configuration files.\nNone of the files in this folder will be run directly. All files in this folder get built into a bundle via Webpack.\n/src/server This folder contains all of the code that will run exclusively on the server via Node.js.\n/src/client This folder contains all of the code that will run exclusively on the client (the user\u0026rsquo;s web browser).\n/public This folder contains all of the static files that are hosted on the Node.js server via Express, which are index.html, any css files that we need, and the JavaScript bundle that contains our client-side logic (the src/client files that get built via Webpack)\n/build This folder contains the results of our Webpack build, which is just the server bundle (server-bundle.js), since the client bundle gets copied directly to the /public folder.\nImplementing Universal Rendering Now that we\u0026rsquo;re familiar with our project, let\u0026rsquo;s move on to \u0026ldquo;Step 1\u0026rdquo;, where we will refactor our client-rendered demo application to use universal rendering, and then measure the impact on performance.\n"
},
{
	"uri": "/react/performance/universal-rendering-lab/project-setup/",
	"title": "Project Setup",
	"tags": [],
	"description": "",
	"content": "Purpose: To get hands-on experience with the implementation of universal rendering.\nIn this lab, we will clone down a client-side rendered application from Github and convert it to leverage universal rendering. When we are finished, we will measure the impact of universal rendering on the performance of our application.\nTo save time, and to limit the scope of this exercise to \u0026ldquo;how to implement universal rendering\u0026rdquo; rather than \u0026ldquo;how to set up a web server in Node.js\u0026rdquo;, much of the initial setup has been completed for you.\nIf you wish to know how to set up a web server in Node.js, how to create a bundle with Webpack, or how to use Babel to leverage new JavaScript syntax in Node.js, you can view the commit history of the project here: https://github.com/one-thd/om_labs_performance-workshop/commits/master\nPull down the code from Github  Open up a new terminal window mkdir dev \u0026amp;\u0026amp; cd dev git clone https://github.com/one-thd/om_labs_performance-workshop.git When prompted, authenticate with Github using your LDAP and password cd om_labs_performance-workshop  Copy API credentials to a .env file  code .env Visual Studio Code will open, with .env as the active file Credentials will be written on a whiteboard in the classroom. Copy the contents into the .env file. Save the file  Build and run the code  Install dependencies:npm install Build the code: npm run build Start the development server: npm run start A development server should now be running at http://localhost:8080. When you make changes to the code, run npm run build and then npm run start again.  Open project in VSCode  VSCode will have opened when you ran code .env. If it did not, press command and space at the same time, type \u0026ldquo;Visual studio code\u0026rdquo;, and press enter to open the editor. File -\u0026gt; Open\u0026hellip; Press command and shift and g at the same time Type ~/dev into the \u0026ldquo;Go to the folder\u0026rdquo; text input Press \u0026ldquo;Go\u0026rdquo; Click on the folder named \u0026ldquo;performance-workshop\u0026rdquo; Click \u0026ldquo;Open\u0026rdquo;  Folder structure Folders you definitely need to know / The root folder of the project contains all project-level configuration files.\n/src This folder contains all of the source files for our project, e.g. all files that are not the output of a build and all files that are not configuration files.\nNone of the files in this folder will be run directly. All files in this folder get built into a bundle via Webpack.\n/src/server This folder contains all of the code that will run exclusively on the server via Node.js.\n/src/client This folder contains all of the code that will run exclusively on the client (the user\u0026rsquo;s web browser).\n/public This folder contains all of the static files that are hosted on the Node.js server via Express, which are index.html, any css files that we need, and the JavaScript bundle that contains our client-side logic (the src/client files that get built via Webpack)\n/build This folder contains the results of our Webpack build, which is just the server bundle (server-bundle.js), since the client bundle gets copied directly to the /public folder.\nFolders you can probably ignore, but would be fun to investigate if you are curious /src/server/proxy Provided as a convenience. All files in this folder facilitate the proxying of requests to THD master data endpoints.\n/src/server/routes/location Provided as a convenience. This is an endpoint that provides store location data to our application. The endpoint uses the convenience functions in the /src/server/proxy directory to query data from the THD master data endpoints.\nImplementing Universal Rendering Now that we\u0026rsquo;re familiar with our project, let\u0026rsquo;s move on to \u0026ldquo;Step 1\u0026rdquo;, where we will refactor our client-rendered demo application to use universal rendering, and then measure the impact on performance.\n"
},
{
	"uri": "/python/foundation/pycharm-setup/",
	"title": "PyCharm Setup",
	"tags": [],
	"description": "",
	"content": "IDLE Idle is Python\u0026rsquo;s default Integrated DeveLopment Environment. It\u0026rsquo;s installed automatically when you download Python3 onto your computer. It is named after Eric Idle of Monty Python fame. Python, as it turns out is not in fact named after the snake, but after Monty Python!\nIDLE is written in Python using a Graphic User Interface wrapper called Tkinter. We will get more into this a little later on in the course.\nPyCharm For the majority of this course we\u0026rsquo;ll be using PyCharm. PyCharm was created specifically for Python development much like IDLE and it has some nice features. Python tends to be very opinionated around indentation and other syntax, and PyCharm will raise these errors for us before we even run the program! This helps with creating good habits around writing Python right off the bat.\nGetting Started We installed Python3 onto every iMac for this class. For your personal computer, you\u0026rsquo;ll want to visit the Python website to download the newest version of Python.\nPyCharm is an Integrated Development Environment used in computer programming, specifically for the Python language. Here at Home Depot, we have a dedicated license to use PyCharm Professional, Community and Edu versions. Just download PyCharm from the Home Depot App store.\nConfiguring Python Interpreters To access the interpreter settings:\n Go to PyCharm in the menu bar and click PyCharm \u0026gt; Preferences and then click the link for project interpreter Click the gear to the right of the Project Interpreter input. Click Add Click the radio button labeled Existing environment Click the three dots to the right of the Interpreter input. Choose this file path on your Mac: /usr/local/bin/python3 Check off Make available to all projects Click OK On the current window, you should see the path you chose in the Project Interpreter dropdown. You may also see a list of packages, including pip Click Apply and OK  Using Pipenv in Pycharm Pycharm has the option to use pipenv when building projects. The Pipfile is placed in the project root directory.\nTo enable this go to Pycharm \u0026gt; Preferences \u0026gt; Project: {your_project_name} \u0026gt; Project Interpreter.\nInstalling Packages  Make sure you\u0026rsquo;re in the Project Interpreter preferences panel. Click the + on the lower left hand corner of the packages list. Search for the packages you need to use for your project. Click Install Package in the lower left hand corner of the window. Click the red dot in the upper left hand corner of the window to close it, you should see your new package in the list on the following screen. Click Apply.  Connecting Project to GitHub For this section, make sure you\u0026rsquo;re on the bandsaw wifi network.\nConnecting PyCharm and GitHub\n  Log in to your Home Depot GitHub account at: GitHub at Home Depot\n  Open PyCharm to create repository on GitHub\n Go to Preferences Select Version Control | GitHub Select **Password * authentication Click the dropdown on the right hand side and select Login Type github.homedepot.com into the Host field Type your LDAP into the Login field Type your password into the Password field    Create a new project in PyCharm\n Open PyCharm and create a project called PythonFoundations Click VSC \u0026gt; Import Into Version Control \u0026gt; Share Project on GitHub Type in a description in the description box. Make sure that all boxes are checked Click OK In the box that says Remember, don't ask again Click Yes    Every time you\u0026rsquo;d like to push new changes to this GitHub repository do the following:\n Go to VCS in the menu bar Click Git \u0026gt; Commit File Check off all files you\u0026rsquo;d like to commit Click Commit Click Push    Creating a default template for PyCharm  Go to Pycharm \u0026gt; Preferences Click on Editor \u0026gt; File and Code Templates Click on Python Script Type the following into the text box  \u0026#34;\u0026#34;\u0026#34; title: ${NAME} author: ${USER} date: ${DATE} ${TIME} \u0026#34;\u0026#34;\u0026#34; Create a config file to store API keys So that we\u0026rsquo;re not sharing our API keys with the world of GitHub, follow these instructions to store your API keys in a config file in PyCharm.\n Create a config.py file in your root PyCharm project folder Put api_key_variable = \u0026quot;PASTE YOUR API KEY HERE\u0026quot; inside config.py Create a .gitignore file in your root PyCharm project folder Put the text: config.py inside your .gitignore file. GitHub will ignore the config.py file and your API keys will stay hidden. import config into any python file you need to use your API key in and then set a variable referencing config, such as this: api_key = config.api_key_variable Simply use your api_key variable within that file where your program calls for your API key.  Adding a GitHub repository to PyCharm  Clone your existing GiHub repository by clicking the green Clone or Download button and copying the URL (The URL should start with https and end with .git) Open PyCharm and go to VCS \u0026gt; Check Out From Version Control \u0026gt; Git Paste your GitHub repository URL in the space provided and click clone  Math Operators Lesson\n"
},
{
	"uri": "/software-eng-essentials/git-pillars/rebase-merge/",
	"title": "Rebase vs Merge",
	"tags": [],
	"description": "",
	"content": "Introduction A common question is when to rebase and when to merge?\nThis is a question that should be answered by your team. This lessons the basics of what each means though and how each will effect your history.\nRebase   Cons\n Changes history if there is a branch that is remote and it is rebased anyone following that branch will have different history does not avoid conflicts: one still must resolve conflicts that may exist between branches    Pros\n History of commits remains in the order of acceptance into production or master Clean line of history with no merge commit    Merge   Cons\n Adds extra commits (merge commit) Timeline based on chronology not acceptance Not as metal as rebase    Pros\n History is clean Easier to deal with conflicts    Merge vs. Rebase Here is a side by side what our history looks like with git log --graph --oneline after doing a merge or rebase respectively.\nBefore vs After Merge\nBefore vs After Rebase\nSummary git rebase and git merge each have their use, each have pros, each have cons. Ultimately it will be up to the team to determine the best workflow that fits preference and style as well as function.\n"
},
{
	"uri": "/golang/databases/relational-databases/",
	"title": "Relational Databases",
	"tags": [],
	"description": "",
	"content": "Golang and Relational Databases The standard Golang library package database/sql provides a generic interface around SQL (or SQL-like) databases.\nThis package must be used in conjunction with a database driver. There are many drivers that are included, such as:\n MySQL Postgresql Oracle Microsoft SQL Server   A full list of drivers can be found here\n Accessing Databases Accessing a database with the database/sql package requires the use of sql.DB. The type allows for creating statements and transactions, execute queries, and fetch results.\nsql.DB does the following behind the scenes:\n Opening and closing connections to the actual underlying database, via the driver Managing a pool of connections as needed  sql.DB allows the management of access to the datastore to remain in the background.\nIf a task is performed with an instance of this type, then the connection is marked in-use. Once the connection is no longer in use, it is returned to the pool.\nIt\u0026rsquo;s important that you release the connection back to the pool or else you might use up all available connections!\n"
},
{
	"uri": "/python/relational-db/relational-databases/",
	"title": "Relational Databases",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Introduce the Python Database API Discuss the various DB modules supported by the Python Database API  Python Database API You will find data in either memory, files or databases. Most Python database interfaces adhere to the same standards.\nThere are several choices for the correct database for your application. The Python Database API supports a wide range of database servers such as:\n  PostgreSQL - Python Database PostgreSQL\n  Oracle - Using Python with Oracle Database 11g\n  Microsoft SQL Server - Microsoft Docs on SQL Server with Python\n  Maria DB - How to connect Python to MariaDB\n  Microsoft Server 2010\n  Using Python DB Modules You must download a separate DB API module for each database you need to access.\nFor example: if you need to access an Oracle database as well as a MySQL database, you must download both the Oracle and the MySQL database modules.\nThe DB API provides a minimal standard for working with databases using Python structures and syntax wherever possible. This API includes the following:\n Importing the API module. Acquiring a connection with the database. Issuing SQL statements and stored procedures. Closing the connection  Summary Connecting to a database is easy using the Python Database API. There are many relational database modules supported by the API that can be used to interact with the database and the data using SQL statements.\n"
},
{
	"uri": "/software-eng-essentials/patterns/resiliency/",
	"title": "Resiliency Patterns",
	"tags": [],
	"description": "",
	"content": "Welcome to Resiliency Patterns "
},
{
	"uri": "/python/apis/flask/",
	"title": "RESTful API w/Flask",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Introduce Pythons Flask Package Discuss Flask RESTful Methods Showcase API built with Flask  Skills  Stand up an API using Flask Write handlers that support standard REST actions Authenticate a Flask API  Designing A Simple Web Service We are creating a todo application and we want to design a web service for it. The first thing to do is to decide what is the root URL to access this service. For example, we could expose this service as:\nhttp://[hostname]/todo/api/v1.0/ Here we\u0026rsquo;ve decided to include the name of the application and the version of the API in the URL.\n Including the application name in the URL is useful to provide a namespace that separates this servicefrom others that can be running on the same system. Including the version in the URL can help with making updates in the future, since new and potentially incompatible functions can be added under a new version, without affecting applications that rely on the older functions.  The next step is to select the resources that will be exposed by this service. This is an extremely simple application, we only have tasks, so our only resource will be the tasks in our to do list.\nHttp Methods Our tasks resource will use HTTP methods as follows:\n   HTTP Method URI Action     GET http://[hostname]/todo/api/v1.0/tasks Retrieve list of tasks   GET http://[hostname]/todo/api/v1.0/tasks/[task_id] Retrieve a task   POST http://[hostname]/todo/api/v1.0/tasks Create a new task   PUT http://[hostname]/todo/api/v1.0/tasks/[task_id] Update an existing task   DELETE http://[hostname]/todo/api/v1.0/tasks/[task_id] Delete a task    We can define a task as having the following fields:\n id: unique identifier for tasks. Numeric type. title: short task description. String type. description: long task description. Text type. done: task completion state. Boolean type.  And with this we are basically done with the design part of our web service. All that is left is to implement it!\n The Flask Web Framework Flask is a simple, yet very powerful Python web framework.\nLet\u0026rsquo;s begin by installing Flask in our pipenv environment.\n$ mkdir todo-api\t(1) $ cd todo-api (2) $ pipenv install flask (3) Installing flask... Collecting flask Using cached https://files.pythonhosted.org/packages/7f/e7/08578774ed4536d3242b14dacb4696386634607af824ea997202cd0edb4b/Flask-1.0.2-py2.py3-none-any.whl Collecting click\u0026gt;=5.1 (from flask) Using cached https://files.pythonhosted.org/packages/34/c1/8806f99713ddb993c5366c362b2f908f18269f8d792aff1abfd700775a77/click-6.7-py2.py3-none-any.whl Collecting Jinja2\u0026gt;=2.10 (from flask) Using cached https://files.pythonhosted.org/packages/7f/ff/ae64bacdfc95f27a016a7bed8e8686763ba4d277a78ca76f32659220a731/Jinja2-2.10-py2.py3-none-any.whl Collecting Werkzeug\u0026gt;=0.14 (from flask) Using cached https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl Collecting itsdangerous\u0026gt;=0.24 (from flask) Collecting MarkupSafe\u0026gt;=0.23 (from Jinja2\u0026gt;=2.10-\u0026gt;flask) Installing collected packages: click, MarkupSafe, Jinja2, Werkzeug, itsdangerous, flask Successfully installed Jinja2-2.10 MarkupSafe-1.0 Werkzeug-0.14.1 click-6.7 flask-1.0.2 itsdangerous-0.24 Adding flask to Pipfile\u0026#39;s [packages]... Pipfile.lock not found, creating... Locking [dev-packages] dependencies... Locking [packages] dependencies... Updated Pipfile.lock (662286)! Installing dependencies from Pipfile.lock (662286)...🐍 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0/6 — 00:00: 🐍 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1/6 — 00:00: 🐍 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 2/6 — 00:00: 🐍 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 3/6 — 00:00: 🐍 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 4/6 — 00:00: 🐍 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 5/6 — 00:00: 🐍 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 6/6 — 00:00: 🐍 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 6/6 — 00:00:00 To activate this project\u0026#39;s virtualenv, run pipenv shell. Alternatively, run a command inside the virtualenv with pipenv run.  Create a directory /todo-api that will be host our web service. Change to the /todo-api directory Install the Flask package to our app using Pipenv  Now that we have Flask installed let\u0026rsquo;s create a simple web application, which we will put in a file called app.py:\nfrom flask import Flask\t# (1) app = Flask(__name__)\t# (2) @app.route(\u0026#39;/\u0026#39;)\t# (3) def index():\t# (4) return \u0026#34;Hello, World!\u0026#34;\tif __name__ == \u0026#39;__main__\u0026#39;:\tapp.run(debug=True)\t# (5)   Import flask module into app.py module\n  Assign a variable app to a new Flask object instance.\n Flask constructor takes the name of current module (__name__) as argument.\n   The route() function of the Flask class is a decorator, which tells the application which URL should call the associated function.\n app.route(rule,options) The rule parameter represents URL binding with the function. The options is a list of parameters to be forwarded to the underlying Rule object.\n   The / URL is bound with the index() function.\n  The app.run(host, port, debug, options) method of Flask class runs the application on the local development server.\n      Parameter Description     host Hostname to listen on. Defaults to 127.0.0.1 (localhost). Set to ‘0.0.0.0’ to have server available externally   port Defaults to 5000. Used to explicitly set a port.   debug Defaults to false. If set to true, provides a debug information, and hot reloads on code updates.   options To be forwarded to underlying Werkzeug server.      Execute app.py to run the application: # Start pipenv shell $ pipenv shell # Make sure you are in the right directory and run $ python app.py * Serving Flask app \u0026#34;app\u0026#34; (lazy loading) * Environment: production WARNING: Do not use the development server in a production environment. Use a production WSGI server instead. * Debug mode: on * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) * Restarting with stat * Debugger is active! * Debugger PIN: 115-900-290 127.0.0.1 - - [17/Sep/2018 09:54:32] \u0026#34;**`GET`** / HTTP/1.1\u0026#34; 200 - And now you can launch your web browser and type http://localhost:5000 to see this tiny application in action.\nSimple, right? Now we will convert this app into our RESTful service!\nRESTful Services w/Flask Building web services with Flask is surprisingly simple.\nThere are a couple of Flask extensions that help with building RESTful services with Flask, but the task is so simple that there is no need to use an extension.\nThe clients of our web service will be asking the service to add, remove and modify tasks, so clearly we need to have a way to store tasks. The obvious way to do that is to build a small database, but because databases are not the topic of this article we are going to take a much simpler approach.\nIn place of a database we will store our task list in a list of dictionaries. This will only work when the web server that runs our application is single process and single threaded. This is okay for Flask\u0026rsquo;s own development web server. It is not okay to use this technique on a production web server, for that a proper database setup must be used.\nUsing the base Flask application we are now ready to implement the first entry point of our web service:\nfrom flask import Flask, jsonify\t# (1) app = Flask(__name__)\ttasks = [\t# (2) { \u0026#39;id\u0026#39;: 1, \u0026#39;title\u0026#39;: u\u0026#39;Buy groceries\u0026#39;, \u0026#39;description\u0026#39;: u\u0026#39;Milk, Cheese, Pizza, Fruit, Tylenol\u0026#39;, \u0026#39;done\u0026#39;: False }, { \u0026#39;id\u0026#39;: 2, \u0026#39;title\u0026#39;: u\u0026#39;Learn Python\u0026#39;, \u0026#39;description\u0026#39;: u\u0026#39;Need to find a good Python tutorial on the web\u0026#39;, \u0026#39;done\u0026#39;: False } ] @app.route(\u0026#39;/todo/api/v1.0/tasks\u0026#39;, methods=[\u0026#39;GET\u0026#39;])\t# (3) def get_tasks(): return jsonify({\u0026#39;tasks\u0026#39;: tasks})\t# (4) if __name__ == \u0026#39;__main__\u0026#39;: app.run(debug=True)   New import from flask jsonify\n jsonify is a function in flask that returns a flask.Response() object that already has the appropriate content-type header \u0026lsquo;application/json\u0026rsquo; for use with json responses. Whereas, the json.dumps() method, from the Python standard package libary, will just return an encoded string, which would require manually adding the MIME type header\n   Create a mock database of tasks using a Python list of dictionaries. Each entry in the list has the fields that we defined for our tasks earlier.\n  Instead of the index() entry point we now have a get_tasks() function that is associated with the /todo/api/v1.0/tasks URI, and only for the GET HTTP method.\n  Return JSON data generated from our list of dictionaries by Flask’s jsonify function.\n  Testing Our Web Service Using a web browser to test a web service isn\u0026rsquo;t the best idea since web browsers cannot easily generate all types of HTTP requests.\nInstead, we will use curl. If you don\u0026rsquo;t have curl installed, go ahead and install it now. (brew install curl)\nStart the web service in the same way we started the sample application, by running python app.py. Then open a new console window and run the following command:\n$ curl -i http://localhost:5000/todo/api/v1.0/tasks HTTP/1.0 200 OK Content-Type: application/json Content-Length: 294 Server: Werkzeug/0.8.3 Python/2.7.3 Date: Mon, 20 May 2013 04:53:53 GMT { \u0026#34;tasks\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Milk, Cheese, Pizza, Fruit, Tylenol\u0026#34;, \u0026#34;done\u0026#34;: false, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;Buy groceries\u0026#34; }, { \u0026#34;description\u0026#34;: \u0026#34;Need to find a good Python tutorial on the web\u0026#34;, \u0026#34;done\u0026#34;: false, \u0026#34;id\u0026#34;: 2, \u0026#34;title\u0026#34;: \u0026#34;Learn Python\u0026#34; } ] } We just have invoked a function in our RESTful service!\n GET a task Now let\u0026rsquo;s write a second version of the GET method for our tasks resource. If you look at the table abovethis will be the one that is used to return the data of a single task:\nfrom flask import abort\t# (1) @app.route(\u0026#39;/todo/api/v1.0/tasks/\u0026lt;int:task_id\u0026gt;\u0026#39;, methods=[\u0026#39;GET\u0026#39;])\t# (2) def get_task(task_id): task = [task for task in tasks if task[\u0026#39;id\u0026#39;] == task_id]\t# (3) if len(task) == 0:\t# (4) abort(404)\treturn jsonify({\u0026#39;task\u0026#39;: task[0]}) # (5)   Importing a new flask object called abort\n The abort() helper properly wraps errors into a HTTPException so it will have the same behavior.\n   \u0026lt;int:task_id\u0026gt; is added to the URL. This tells the URL to expect a value that will be used as an integer type at the end of the URL. Also, set the following function to only use HTTP GET functionality\n \u0026lt;float:task_id\u0026gt; expects a float \u0026lt;string:task_id\u0026gt; expects a string \u0026lt;task_id\u0026gt; could be used alone but task_id will have to be converted from a default string type to an integer    We assign task to a list comprehension  that should generate a list with one item unless we have multiple tasks with the same id in our list.\n  If the id that we were given does not exist in our database then we return the familiar error code 404, which means \u0026quot;Resource Not Found\u0026quot;.\n  If we find the task then we just package it as a JSON with jsonify and send it as a response, just like we did before for the entire collection.\n  Here is how this function looks when invoked from curl:\n$ curl -i http://localhost:5000/todo/api/v1.0/tasks/2 HTTP/1.0 200 OK Content-Type: application/json Content-Length: 151 Server: Werkzeug/0.8.3 Python/2.7.3 Date: Mon, 20 May 2013 05:21:50 GMT { \u0026#34;task\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Need to find a good Python tutorial on the web\u0026#34;, \u0026#34;done\u0026#34;: false, \u0026#34;id\u0026#34;: 2, \u0026#34;title\u0026#34;: \u0026#34;Learn Python\u0026#34; } } $ curl -i http://localhost:5000/todo/api/v1.0/tasks/3 HTTP/1.0 404 NOT FOUND Content-Type: text/html Content-Length: 238 Server: Werkzeug/0.8.3 Python/2.7.3 Date: Mon, 20 May 2013 05:21:52 GMT \u0026lt;!DOCTYPE HTML PUBLIC \u0026#34;-//W3C//DTD HTML 3.2 Final//EN\u0026#34;\u0026gt; \u0026lt;title\u0026gt;404 Not Found\u0026lt;/title\u0026gt; \u0026lt;h1\u0026gt;Not Found\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;The requested URL was not found on the server.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If you entered the URL manually please check your spelling and try again.\u0026lt;/p\u0026gt;  NOTE: When we ask for resource id #2 we get it, but when we ask for #3 we get back the 404 error.\n The odd thing about the error is that it came back with an HTML message instead of JSON, because that is how Flask generates the 404 response by default. Since this is a web service client applications will expect that we always respond with JSON, so we need to improve our 404 error handler:\nfrom flask import make_response\t# (1) @app.errorhandler(404)\t# (2) def not_found(error): return make_response(jsonify({\u0026#39;error\u0026#39;: \u0026#39;Not found\u0026#39;}), 404)\t# (3)   Importing the flask method make_response()\n  Using the errorhandler() decorator, which registers a function to handle errors by code or exception class.\n  Return the HTML generated response\n NOTE: make_response() converts to a HTML mimetype by default And we get a much more API friendly error response:\n   $ curl -i http://localhost:5000/todo/api/v1.0/tasks/3 HTTP/1.0 404 NOT FOUND Content-Type: application/json Content-Length: 26 Server: Werkzeug/0.8.3 Python/2.7.3 Date: Mon, 20 May 2013 05:36:54 GMT { \u0026#34;error\u0026#34;: \u0026#34;Not found\u0026#34; } Now our response is HTML friendly!  POST a task Next in our list is the POST method, which we will use to insert a new item in our task database:\nfrom flask import request\t# (1) @app.route(\u0026#39;/todo/api/v1.0/tasks\u0026#39;, methods=[\u0026#39;POST\u0026#39;])\t# (2) def create_task(): if not request.json or not \u0026#39;title\u0026#39; in request.json:\t# (3) abort(400) task = {\t# (4) \u0026#39;id\u0026#39;: tasks[-1][\u0026#39;id\u0026#39;] + 1, \u0026#39;title\u0026#39;: request.json[\u0026#39;title\u0026#39;], \u0026#39;description\u0026#39;: request.json.get(\u0026#39;description\u0026#39;, \u0026#34;\u0026#34;), \u0026#39;done\u0026#39;: False } tasks.append(task)\t# (5) return jsonify({\u0026#39;task\u0026#39;: task}), 201\t# (6)  Reminder: .get('description', \u0026quot;\u0026quot;) only gets a value if the description key exist else it will place what\u0026rsquo;s in the quotes as the value.\n   First, we import the request() method from Flask\n The request() method allows for our program to have access to a request object that holds all the processed incoming request data from users.\n   Set our URL and its accessibiltiy rules to only work with POST requests\n  If there\u0026rsquo;s no json returned in our request or the json doesnt have the key title we trigger a 400 Response\n  Create a new task dictionary object with the request json data object\n NOTE: We tolerate a missing description field, and we assume the done field will always start set to False.\n   Append the new task to current task list\n  Respond to the client with the added task and send back a status code 201, which HTTP defines as the code for \u0026ldquo;Created\u0026rdquo;.\n  To test this new function we can use the following curl command:\n$ curl -i -H \u0026#34;Content-Type: application/json\u0026#34; -X POST -d \u0026#39;{\u0026#34;title\u0026#34;:\u0026#34;Read a book\u0026#34;}\u0026#39; http://localhost:5000/todo/api/v1.0/tasks HTTP/1.0 201 Created Content-Type: application/json Content-Length: 104 Server: Werkzeug/0.8.3 Python/2.7.3 Date: Mon, 20 May 2013 05:56:21 GMT { \u0026#34;task\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;done\u0026#34;: false, \u0026#34;id\u0026#34;: 3, \u0026#34;title\u0026#34;: \u0026#34;Read a book\u0026#34; } }  NOTE: If you are on Windows and use the Cygwin version of curl from bash then the above command will work just fine. However, if you are using the native version of curl from the regular command prompt there is a little dance that needs to be done to send double quotes inside the body of a request:\n curl -i -H \u0026#34;Content-Type: application/json\u0026#34; -X POST -d \u0026#34;{\u0026#34;\u0026#34;\u0026#34;title\u0026#34;\u0026#34;\u0026#34;:\u0026#34;\u0026#34;\u0026#34;Read a book\u0026#34;\u0026#34;\u0026#34;}\u0026#34; http://localhost:5000/todo/api/v1.0/tasks  NOTE: On Windows you have to use double quotes to enclose the body of the request, and then inside it you escape a double quote by writing three of them in sequence.\n After this request completed we can obtain an updated list of tasks:\n$ curl -i http://localhost:5000/todo/api/v1.0/tasks HTTP/1.0 200 OK Content-Type: application/json Content-Length: 423 Server: Werkzeug/0.8.3 Python/2.7.3 Date: Mon, 20 May 2013 05:57:44 GMT { \u0026#34;tasks\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Milk, Cheese, Pizza, Fruit, Tylenol\u0026#34;, \u0026#34;done\u0026#34;: false, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;Buy groceries\u0026#34; }, { \u0026#34;description\u0026#34;: \u0026#34;Need to find a good Python tutorial on the web\u0026#34;, \u0026#34;done\u0026#34;: false, \u0026#34;id\u0026#34;: 2, \u0026#34;title\u0026#34;: \u0026#34;Learn Python\u0026#34; }, { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;done\u0026#34;: false, \u0026#34;id\u0026#34;: 3, \u0026#34;title\u0026#34;: \u0026#34;Read a book\u0026#34; } ] }  PUT \u0026amp; DELETE tasks The remaining two functions of our web service are shown below:\n\u0026#34;\u0026#34;\u0026#34;UPDATE TASK\u0026#34;\u0026#34;\u0026#34; @app.route(\u0026#39;/todo/api/v1.0/tasks/\u0026lt;int:task_id\u0026gt;\u0026#39;, methods=[\u0026#39;PUT\u0026#39;]) def update_task(task_id): task = [task for task in tasks if task[\u0026#39;id\u0026#39;] == task_id] if len(task) == 0: abort(404) if not request.json: abort(400) if \u0026#39;title\u0026#39; in request.json and type(request.json[\u0026#39;title\u0026#39;]) != unicode: abort(400) if \u0026#39;description\u0026#39; in request.json and type(request.json[\u0026#39;description\u0026#39;]) is not unicode: abort(400) if \u0026#39;done\u0026#39; in request.json and type(request.json[\u0026#39;done\u0026#39;]) is not bool: abort(400) task[0][\u0026#39;title\u0026#39;] = request.json.get(\u0026#39;title\u0026#39;, task[0][\u0026#39;title\u0026#39;]) task[0][\u0026#39;description\u0026#39;] = request.json.get(\u0026#39;description\u0026#39;, task[0][\u0026#39;description\u0026#39;]) task[0][\u0026#39;done\u0026#39;] = request.json.get(\u0026#39;done\u0026#39;, task[0][\u0026#39;done\u0026#39;]) return jsonify({\u0026#39;task\u0026#39;: task[0]}) \u0026#34;\u0026#34;\u0026#34;DELETE TASK\u0026#34;\u0026#34;\u0026#34; @app.route(\u0026#39;/todo/api/v1.0/tasks/\u0026lt;int:task_id\u0026gt;\u0026#39;, methods=[\u0026#39;DELETE\u0026#39;]) def delete_task(task_id): task = [task for task in tasks if task[\u0026#39;id\u0026#39;] == task_id] if len(task) == 0: abort(404) tasks.remove(task[0]) return jsonify({\u0026#39;result\u0026#39;: True}) For the update_task()function: we want to prevent bugs by doing exhaustive checking of the input arguments. We need to make sure that anything that the client provided is in the expected format before we incorporate it into our database, hence the need for checking for unicode values.\nThe delete_task() function should be easy to follow.\nA function call that updates task #2 as being done would be done as follows: $ curl -i -H \u0026#34;Content-Type: application/json\u0026#34; -X PUT -d \u0026#39;{\u0026#34;done\u0026#34;:true}\u0026#39; http://localhost:5000/todo/api/v1.0/tasks/2 HTTP/1.0 200 OK Content-Type: application/json Content-Length: 170 Server: Werkzeug/0.8.3 Python/2.7.3 Date: Mon, 20 May 2013 07:10:16 GMT { \u0026#34;task\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Need to find a good Python tutorial on the web\u0026#34;, \u0026#34;done\u0026#34;: true, \u0026#34;id\u0026#34;: 2, \u0026#34;title\u0026#34;: \u0026#34;Learn Python\u0026#34; } ] } Full Code from flask import Flask, jsonify, abort, make_response, request from idna import unicode app = Flask(__name__) tasks = [ { \u0026#39;id\u0026#39;: 1, \u0026#39;title\u0026#39;: u\u0026#39;Buy groceries\u0026#39;, \u0026#39;description\u0026#39;: u\u0026#39;Milk, Cheese, Pizza, Fruit, Tylenol\u0026#39;, \u0026#39;done\u0026#39;: False }, { \u0026#39;id\u0026#39;: 2, \u0026#39;title\u0026#39;: u\u0026#39;Learn Python\u0026#39;, \u0026#39;description\u0026#39;: u\u0026#39;Need to find a good Python tutorial on the web\u0026#39;, \u0026#39;done\u0026#39;: False } ] @app.errorhandler(404) def not_found(error): return make_response(jsonify({\u0026#39;error\u0026#39;: \u0026#39;Not found\u0026#39;})) @app.route(\u0026#39;/todo/api/v1.0/tasks\u0026#39;, methods=[\u0026#39;GET\u0026#39;]) def get_tasks(): return jsonify({\u0026#39;tasks\u0026#39;: tasks}) @app.route(\u0026#39;/todo/api/v1.0/tasks/\u0026lt;int:task_id\u0026gt;\u0026#39;, methods=[\u0026#39;GET\u0026#39;]) def get_task(task_id): task = [task for task in tasks if task[\u0026#39;id\u0026#39;] == task_id] if len(task) == 0: abort(404) return jsonify({\u0026#39;task\u0026#39;: task[0]}) @app.route(\u0026#39;/todo/api/v1.0/tasks\u0026#39;, methods=[\u0026#39;POST\u0026#39;]) def create_task(): print(request) print(request.data) if not request.json or not \u0026#39;title\u0026#39; in request.json: abort(400) task = { \u0026#39;id\u0026#39;: tasks[-1][\u0026#39;id\u0026#39;] + 1, \u0026#39;title\u0026#39;: request.json[\u0026#39;title\u0026#39;], \u0026#39;description\u0026#39;: request.json.get(\u0026#39;description\u0026#39;, \u0026#34;\u0026#34;), \u0026#39;done\u0026#39;: False } tasks.append(task) return jsonify({\u0026#39;task\u0026#39;: task}), 201 @app.route(\u0026#39;/todo/api/v1.0/tasks/\u0026lt;int:task_id\u0026gt;\u0026#39;, methods=[\u0026#39;PUT\u0026#39;]) def update_task(task_id): task = [task for task in tasks if task[\u0026#39;id\u0026#39;] == task_id] if len(task) == 0: abort(404) if not request.json: abort(400) if \u0026#39;title\u0026#39; in request.json and type(request.json[\u0026#39;title\u0026#39;]) != unicode: abort(400) if \u0026#39;description\u0026#39; in request.json and type(request.json[\u0026#39;description\u0026#39;]) is not unicode: abort(400) if \u0026#39;done\u0026#39; in request.json and type(request.json[\u0026#39;done\u0026#39;]) is not bool: abort(400) task[0][\u0026#39;title\u0026#39;] = request.json.get(\u0026#39;title\u0026#39;, task[0][\u0026#39;title\u0026#39;]) task[0][\u0026#39;description\u0026#39;] = request.json.get(\u0026#39;description\u0026#39;, task[0][\u0026#39;description\u0026#39;]) task[0][\u0026#39;done\u0026#39;] = request.json.get(\u0026#39;done\u0026#39;, task[0][\u0026#39;done\u0026#39;]) return jsonify({\u0026#39;task\u0026#39;: task[0]}) @app.route(\u0026#39;/todo/api/v1.0/tasks/\u0026lt;int:task_id\u0026gt;\u0026#39;, methods=[\u0026#39;DELETE\u0026#39;]) def delete_task(task_id): task = [task for task in tasks if task[\u0026#39;id\u0026#39;] == task_id] if len(task) == 0: abort(404) tasks.remove(task[0]) return jsonify({\u0026#39;result\u0026#39;: True}) if __name__ == \u0026#39;__main__\u0026#39;: app.run(debug=True)  Pivotal Deployment If you would like to deploy your new API to PCF, you need to update your app.py file to include the following changes.\nimport os ... port = int(os.getenv(\u0026#39;PORT\u0026#39;, \u0026#39;3000\u0026#39;)) if __name__ == \u0026#39;__main__\u0026#39;: app.run(host=\u0026#39;0.0.0.0\u0026#39;, port=port) Also create a manifest.yml file for cloud foundry to make your environment. Make sure this file is in the same directory as your project Pipfile:\n--- applications: - name: flask_todo_api memory: 128MB disk_quota: 512MB buildpack: python_buildpack command: python app.py instances: 1 random-route: true and last create a runtime.txt file, also in the same directory to tell Cloud Foundry what version of python to install.\npython-3.7.4 Then push your app using the CF CLI commands\n NOTE: If you\u0026rsquo;re using Pipenv, make sure that the Python version matches what\u0026rsquo;s in your requirement.txt. Currently, Cloud Foundry goes all the way up to Python 3.7.4.\n  Exercise: Flask Book API Setup\n If you have not already, Fork https://github.homedepot.com/om-labs/Python-API to your Home Depot profile Clone down your newly forked repo cd into the resources/Flask_Examples directory  Using flask and the test data below, build an API with the following RESTful urls \u0026amp; commands:\n   HTTP Method URI Action     GET http://[hostname]/api/resources/books/all Retrieve all of books in JSON object   GET http://[hostname]/api/resources/books/[book_id] Retrieve a book   POST http://[hostname]/api/resources/books/ Add a new book   PUT http://[hostname]/api/resources/books/[book_id] Delete a book   DELETE http://[hostname]/api/resources/books/[book_id] Delete a book    from flask import Flask, request, abort, jsonify from functools import wraps import json books = [ {\u0026#39;id\u0026#39;: 0, \u0026#39;title\u0026#39;: \u0026#39;A Fire Upon the Deep\u0026#39;, \u0026#39;author\u0026#39;: \u0026#39;Vernor Vinge\u0026#39;, \u0026#39;first_sentence\u0026#39;: \u0026#39;The coldsleep itself was dreamless.\u0026#39;, \u0026#39;year_published\u0026#39;: \u0026#39;1992\u0026#39;}, {\u0026#39;id\u0026#39;: 1, \u0026#39;title\u0026#39;: \u0026#39;The Ones Who Walk Away From Omelas\u0026#39;, \u0026#39;author\u0026#39;: \u0026#39;Ursula K. Le Guin\u0026#39;, \u0026#39;first_sentence\u0026#39;: \u0026#39;With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.\u0026#39;, \u0026#39;published\u0026#39;: \u0026#39;1973\u0026#39;}, {\u0026#39;id\u0026#39;: 2, \u0026#39;title\u0026#39;: \u0026#39;Dhalgren\u0026#39;, \u0026#39;author\u0026#39;: \u0026#39;Samuel R. Delany\u0026#39;, \u0026#39;first_sentence\u0026#39;: \u0026#39;to wound the autumnal city.\u0026#39;, \u0026#39;published\u0026#39;: \u0026#39;1975\u0026#39;} ] app = Flask(__name__) #your code here... if __name__ == \u0026#34;__main__\u0026#34;: app.run() "
},
{
	"uri": "/cyber-security/static-dynamic-analysis/0-sast-fundamentals/",
	"title": "SAST Fundamentals",
	"tags": [],
	"description": "",
	"content": "Course Introduction This course is designed to be an introduction to security scanning for Software Developers. In order to keep Home Depot\u0026rsquo;s application ecosystem healthy, developers are required to perform regular scanning on their applications and remediate any security vulnerabilities. This course will show you how to use Fortify to scan your applications and how to approach fixing the security issues it finds.\nHow to Get the Most Out of this Course This course is best taken in an interactive manner. You will be introduced to several tools and it is highly recommended you test them out during the course. Guidance will be provided on how to properly demo the tools .\nCourse Modules Static and Dynamic Analysis Fundamentals This chapter introduces the concepts needed for the rest of the course.\nSAST Overview and Tools Provides an overview of the scanning tools we use to find vulnerabilities in our code.\nScanning Set-up and Execution Outlines how to prepare for a scan begin the scanning process.\nFortify SSC Overview Provides a look at the features of Fortify, our primary tool for finding vulnerabilities.\nTriaging Scan Results Gives you details on how to investigate your scan results.\nSecurity Weakness Remediation Shows you how to fix the vulnerabilities you find in your code.\nReview and Resources Recaps on the concepts learned and provides some additional resources for learning.\nNecessary Software Access Please request access to the following software before beginning the course:\n  Fortify: ARP Request     Viper: Verify you can access the viper portal. If not, send an e-mail to CyberSecurity_ApplicationSecurityEngineering@homedepot.com\n  Secure Code Warrior: ARP Request     Resources Used in this Course Fortify: https://fortify-ssc.homedepot.com/ssc\nViper: https://viper-ui-qa.apps-np.homedepot.com/\nSecure Code Warrior: https://securecodewarrior.net/\n"
},
{
	"uri": "/golang/api/go-webserver/",
	"title": "Standing up a Webserver with Go",
	"tags": [],
	"description": "",
	"content": "Objectives  Introduce Go\u0026rsquo;s net/http package Discuss Handlers and Handler Functions Work with the Default Serve Multiplexor Handle Request/Response cycle within an application  Skills  Get Experience with the DefaultServeMux How to write HTTP\u0026rsquo;s Handler and HandlerFuncs Handle incoming (GET) requests Use Environment Variables to set your webserver\u0026rsquo;s port  Go\u0026rsquo;s net/http Package If you\u0026rsquo;re coming to Go from another language, like: JavaScript, Python, Java, etc., you are probably familiar with using an external library or framework to stand up a web server. While these languages do offer core support for http servers, your code can quickly become verbose, brittle and difficult to maintain. Often leading us to look for viable solutions in the form of 3rd party libraries and frameworks.\nConsidering that Golang is relatively new compared to other languages. Coupled with the fact that web technologies have changed greatly in the past 10 years, Go\u0026rsquo;s core team was able to include excellent support for web services, right out of the box. That\u0026rsquo;s correct! Go\u0026rsquo;s net/http package is technically all you need to build a RESTful API.\nPlease note, there is nothing inherently wrong with using external libraries and frameworks. Golang was created to be a minimalist language, allowing you only pull in extra functionality when needed. To that end, the next few lessons will dig into building an API with the standard net/http package. As the lessons progress, and the API examples becomes more complex, additional packages will be introduced to show how to make the code more clean, robust, and manageable.\nListenAndServe To start a server, only ListenAndServe is required.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { fmt.Println(\u0026#34;Starting server on port: 3001\u0026#34;) //1  http.ListenAndServe(\u0026#34;:3001\u0026#34;, nil) //2 }  Indicate that the server is running (optional) Call http.ListenAndServe passing a port as the first argument   The server can be started with: $ go run main.go.\nplease note: for demonstration purposes we\u0026rsquo;ll be using the fresh package: $ fresh main.go. Fresh is a command line tool that builds/restarts your web app on each save.\nBy using cURL, or navigating to http://localhost:3001/ in a browser, you\u0026rsquo;ll receive a 404 message.\ncurl http://localhost:3001 404 page not found Don\u0026rsquo;t worry! This will be fixed momentarily. However, before moving on, take a look at the function signature for ListenAndServe\n ListenAndServe Signature func ListenAndServe(addr string, handler Handler) error Breaking this down, you\u0026rsquo;ll see that ListenAndServe takes 2 arguments and returns an error\nArguments\n addr: a string type, that indicates the port your app is running on handler: a Handler type that handles incoming requests  Return\nBecause an error is returned, it is fairly common practice to wrap ListenAndServe in Log.Fatal to log any potential errors. In this case, log.Fatal will return an exit code of 1.\nlog.Fatal(http.ListenAndServe(\u0026#34;:3001\u0026#34;, nil))  Why nil? Looking at the snippet above, it\u0026rsquo;s fair to ask: why is nil passed as the second argument?\nBy design, the DefaultServeMux is used when no handler is provided. We\u0026rsquo;ll cover this in more detail shortly. However, before we move on, let\u0026rsquo;s create a working route!\nHandling Requests To create a functioning endpoint, you\u0026rsquo;ll need to create a handler function\nfunc rootHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;welcome to %s from OM!\u0026#34;, r.URL.Path) } http\u0026rsquo;s ResponseWriter \u0026amp; Request You may be asking yourself about the arguments supplied to our rootHandler. What are they? We\u0026rsquo;ll start by looking at the ResponseWriter.\nGo\u0026rsquo;s ResponseWriter docs state:\n A ResponseWriter interface is used by an HTTP handler to construct an HTTP response\n The ResponseWriter interface contains 3 methods:\n Header() Header - Returns a map of headers that will be sent with the response Write([]byte) (int, error) - An implementation of io.Writer used to create a response for the client WriteHeader(statusCode int) - Sends an HTTP response header with the provided status code  In our example, the ResponseWriter (represented by the w variable) handles generating a \u0026ldquo;welcome from OM!\u0026quot; response for the client.\n When it comes to Request it\u0026rsquo;s worth noting that, while ResponseWriter is an interface, Request is a struct.\nGo\u0026rsquo;s Request docs state:\n A Request represents an HTTP request received by a server or to be sent by a client\n This representation can be used gather information about the request, such as:\n Headers Request Body URL info etc.  At this point, If you\u0026rsquo;re saying: Okay, I get it, but why are we using a pointer?\nIt turns out that the Request struct is considerably large. Copying it would be an expensive operation. Instead, we can just point to the Request in memory and gather the necessary information.\n Activating the Handler Function To activate that handler at / we\u0026rsquo;ll use http.handleFunc in our main function.\nfunc main() { http.HandleFunc(\u0026#34;/\u0026#34;, rootHandler) // ... } The two arguments supplied to HandleFunc are:\n / - indicates the route we want to activate rootHandler - the handler function that we want to register when our route is triggered   Now, cURLing or navigating to http://localhost:3001 should result in a welcome message! Yay! 🎉\n$ curl http://localhost:3001 welcome to / from OM!  All together, the current code is:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func rootHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;welcome to %s from OM!\u0026#34;, r.URL.Path) } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, rootHandler) fmt.Println(\u0026#34;Starting server on port: 3001\u0026#34;) log.Fatal(http.ListenAndServe(\u0026#34;:3001\u0026#34;, nil)) } Considering that we now having a working application, let\u0026rsquo;s dig into the handlers to gain a better understanding.\nHandler \u0026amp; Handler Functions Handlers are responsible for managing the request/response cycle. To aid in this effort, Go gives us the Handler interface, as well as a couple of methods that are useful for handling incoming HTTP requests.\nThe Handler Interface The Handler itself, is an interface supplied by the net/http package.\nThe source for Handler is as follows:\ntype Handler interface { ServeHTTP(ResponseWriter, *Request) } According to the docs on Handlers:\n A Handler responds to an HTTP request.\nServeHTTP should write reply headers and data to the ResponseWriter and then return\u0026hellip;\n It\u0026rsquo;s worth noting that any type can be a handler, so long as it satisfies the http.Handler interface. This can be accomplished by providing a ServeHTTP method. The handler can then be passed to ListenAndServe, which will call the ServeHTTP method on each incoming request.\nHandle According to the documentation on Handle:\n Handle registers the handler for the given pattern\u0026hellip;\n Handle's function signature is as follows:\nfunc Handle(pattern string, handler Handler) We can see that Handle takes two arguments\n pattern - a string type with the pattern (path) that you want to match (ie: /, /foo, /bar) handler - a type that satisfies the Handler interface  Let\u0026rsquo;s refactor the previous example code to use this pattern (shortened for clarity).\npackage main // ...  type rootHandler struct{} //1  func (rh rootHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { //2 \tfmt.Fprintf(w, \u0026#34;welcome to %s from OM!\u0026#34;, r.URL.Path) } func main() { rh := rootHandler{} //3  http.Handle(\u0026#34;/\u0026#34;, rh) //4  // ... } Several Modifications were required:\n Create a rootHandler struct Re-write function to be a method on the rootHandler object and implement the ServeHTTP method (satisfying the Handler interface) Instantiate roothandler object as rh Call http.Handle passing in the path of / and the rh Handler  Running this code, will result in very similar output as our first example.\nWhile this is extremely powerful, it\u0026rsquo;s a bit much for our simple web-server. So we\u0026rsquo;re going to look at the previously used HandlerFunc method\nHandlerFunc According to the HandlerFunc documentation:\n The HandlerFunc type is an adapter to allow the use of ordinary functions as HTTP handlers.\n The documentation goes on to say:\n If f is a function with the appropriate signature, HandlerFunc(f) is a Handler that calls f.\n This indicates that the HandlerFunc is essentially a helper function, that wraps a normal function with the func(http.ResponseWriter, *http.Request) signature, and returns a Handler\nLet\u0026rsquo;s look at an example:\npackage main // ...  func rootHandler(w http.ResponseWriter, r *http.Request) { //1 \tfmt.Fprintf(w, \u0026#34;welcome to %s from OM!\u0026#34;, r.URL.Path) } func main() { http.Handle(\u0026#34;/\u0026#34;, http.HandlerFunc(rootHandler)) //2  // ... }  Create a function with the correct signature Pass the function to your http.HandlerFunc  Behind the scenes, HandlerFunc attaches the ServeHTTP method to the function in question, therefore satisfying the Handler interface.\nHandleFunc While the name is very similar, HandleFunc has a slight difference.\nThe documentation for HandleFunc states:\n HandleFunc registers the handler function for the given pattern\n Before moving forward, take a look at the difference between the signatures of Handle and HandleFunc.\nHandle\nfunc Handle(pattern string, handler Handler) HandleFunc\nfunc HandleFunc(pattern string, handler func(ResponseWriter, *Request)) The major difference is that Handle requires a Handler type, while HandleFunc only requires a function with the func(ResponseWriter, *Request) signature.\nWith that in mind, HandleFunc takes the following arguments:\n pattern - A string type with the pattern (route/endpoint) func(ResponseWriter, *Request) - a function that makes use of http\u0026rsquo;s ResponseWriter interface, and Request struct.  If we look back to our original code sample, you\u0026rsquo;ll see this in action.\npackage main // ...  func rootHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;welcome to %s from OM!\u0026#34;, r.URL.Path) } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, rootHandler) //1 \t// ... }  Call HandleFunc passing the rootHandler function.  What should I use? If you\u0026rsquo;re wondering whether to use HandleFunc or HandlerFunc consider these points.\n HandleFunc is a nice shortcut that registers a function and let\u0026rsquo;s you handle requests HandlerFunc makes an actual http.Handler that could be used in various cases. ie: middleware  404 Currently, any URI provided to the application will work. For example, you can navigate to http://localhost:3001/foo/bar or http://localhost:3001/hello/world and data will be rendered.\nThis immediately poses the question: how can we render valid routes only, and serve a 404 response when the route is invalid?\nAt the moment, all routes contain a / character, which means that there will always be a match. A quick fix is to inspect the URL.Path in the rootHandler\n// ... func rootHandler(w http.ResponseWriter, r *http.Request) { if r.URL.Path != \u0026#34;/\u0026#34; { fmt.Fprintf(w, \u0026#34;The resource you\u0026#39;re looking for cannot be found\u0026#34;) return } fmt.Fprintf(w, \u0026#34;Landing Page!\u0026#34;) } // ... Alternatively, we can use the NotFound method from net/http\n// ... func rootHandler(w http.ResponseWriter, r *http.Request) { if r.URL.Path != \u0026#34;/\u0026#34; { http.NotFound(w, r) return } fmt.Fprintf(w, \u0026#34;Landing Page!\u0026#34;) } // ... Now, all requests that don\u0026rsquo;t match a given route supplied by a handler will return a Not Found message.\nSubtree \u0026amp; Fixed paths Two types of URL patterns exist when using the standard net/http package.\n Fixed Paths - ie: /widgets, /widgets/new, /foo etc. Subtree Paths- ie: /products/, /bar/, etc  Before digging in to the major difference, we\u0026rsquo;ll create another route handler.\nfunc omHandler(w http.ResponseWriter, r *http.Request) { //1 \tfmt.Fprintf(w, \u0026#34;Hello from Orange Academy\u0026#34;) } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, rootHandler) http.HandleFunc(\u0026#34;/om\u0026#34;, omHandler) //2 \t// ... }  Create the route handler Trigger the handler when the request URI matches \u0026quot;/om\u0026rdquo;  Fixed paths are pretty common in web development. The route is only triggered with an exact match. Navigating to http://localhost:3001/om should result in the Hello from Orange Academy message because there is an exact match.\nSubtree paths end with a trailing /, and act similar to a wildcard (*) operator. Unless there is a specific handler for a given route, any request containing the matching URI (at the beginning) will match and trigger the route handler.\nFor example, add a trailing / to om\nhttp.HandleFunc(\u0026#34;/om/\u0026#34;, omHandler) Any request beginning with /om should trigger the omHandler. Now, try a couple of routes\n http://localhost:3001/om/go http://localhost:3001/om/go/day1  As you can see, instead of getting a 404, the omHandler is invoked.\n Lab 1 - Build a Web Server Using the previous material, create a simple application that returns information about Home Depot\u0026rsquo;s core values. You\u0026rsquo;ll find 2 links below with more info on THD\u0026rsquo;s core values.\n  Create a new project\n  Use ListenAndServe to open a port and start the server\n  Create a root handler\n This can say virtually anything, we recommend something short and to the point ie: Learn more about THD\u0026rsquo;s Core Values, or simply: Hello!    Add a second handler displaying one of the 8 core values, along with a summary\n  When a user navigates to /excellent-customer-service the following should be displayed:\n Excellent Customer Service: Along with our quality products, service, price and selection, we must go the extra mile to give customers knowledgeable advice about merchandise and to help them use those products to their maximum benefit.\n     Add a third handler and display info about another core value\n  Ensure that a 404 message is displayed if a request is made to non-existing endpoints\n  Lab Resources  Built From Scratch - Core Values Culture - Core Values   Mux The net/http package includes an HTTP request Multiplexer, most often referred to as mux.\nWhat is a Multiplexer? This presents a question: What, exactly, is a Multiplexer?\nAccording to the Multiplexing definition on Wikipedia:\n multiplexing\u0026hellip; is a method by which multiple analog or digital signals are combined into one signal over a shared medium.\n In our context this can be easily translated to routing.\nMeaning, the Go standard library gives us a router (mux) to handle incoming HTTP requests.\nServeMux The multiplexer in net/http is known as the ServeMux type.\nServeMux is a struct that maps (routes) incoming requests to the appropriate HTTP handler in your application.\nTo create a locally scoped instance of ServeMux, we can call the NewServeMux function\nmux := http.NewServeMux() note: mux := \u0026amp;http.ServeMux{} may be used as an alternative.\nLooking at the signature for NewServeMux() you\u0026rsquo;ll notice the return value is a pointer to ServeMux: func NewServeMux() *ServeMux.\nBy scrolling a little further in the docs, you\u0026rsquo;ll notice that ServeMux implements some familiar methods:\n Handle HandleFunc ServeHTTP  This means, after creating the ServeMux object, the handlers can be registered by swapping out http.HandleFunc() in favor of mux.HandleFunc().\n// ... \tmux := http.NewServeMux() mux.HandleFunc(\u0026#34;/\u0026#34;, rootHandler) mux.HandleFunc(\u0026#34;/om/\u0026#34;, omHandler) // ... Now, the locally scoped instance of ServeMux is set to handle requests to / and /om/.\nUnfortunately, after spinning up the server, you\u0026rsquo;ll only get 404 errors. :man_facepalming:\nWhat went wrong?\n Earlier, while setting up ListenAndServe, nil was supplied as the second argument: http.ListenAndServe(\u0026quot;:3001\u0026quot;, nil).\nThe method signature for ListenAndServe indicates that the second argument is of type Handler. This leads to the question: what qualifies as a type of Handler?\nIn order to satisfy the Handler interface, your type must implement the ServeHTTP method. Thankfully, ServeMux implements the the ServeHTTP method, therefore satisfying the Handler interface.\nMeaning, the ServeMux object (mux) can be passed to ListenAndServe, and the application should behave as expected.\nhttp.ListenAndServe(\u0026#34;:3001\u0026#34;, mux) Now, restarting the server, our routes should work as expected.\n Before moving on, let\u0026rsquo;s review the updates to our main function.\n// ... func main() { mux := http.NewServeMux() mux.HandleFunc(\u0026#34;/\u0026#34;, rootHandler) mux.HandleFunc(\u0026#34;/om/\u0026#34;, omHandler) fmt.Println(\u0026#34;Starting server on port: 3001\u0026#34;) log.Fatal(http.ListenAndServe(\u0026#34;:3001\u0026#34;, mux)) } DefaultServeMux This brings us back to the question, what happens when nil is passed to ListenAndServe?\nWhen using nil, Go provides a global instance of ServeMux, also known as DefaultServeMux.\nThe DefaultServeMux is instantiated on application startup and provided as the default Handler to ListenAndServe. Which explains why the application failed to operate as intended after creating a local instance of ServeMux.\nIn this situation, once the handlers were registered with mux, the DefaultServeMux was no longer aware of them.\nWhile it\u0026rsquo;s pretty nifty that a Default Mux is provided, it\u0026rsquo;s not recommended for use in production applications. This is due to the fact that DefaultServeMux is a global variable, making it potentially available to third-party packages used in your project. If one of those packages were to be compromised, they could potentially use the DefaultServeMux to expose your application to vulnerabilities. Instead, it\u0026rsquo;s best to opt for using a locally scoped ServeMux.\nSetting a Port Currently, the port is hardcoded to :3001, while this works, a better practice is to set the port as environment variable. This allows for more flexibility in development, and helps with the transition to deployment.\nFirst, add the following in main()\nfunc main() { var port string //1  if port = os.Getenv(\u0026#34;PORT\u0026#34;); port == \u0026#34;\u0026#34; { //2  port = \u0026#34;3001\u0026#34; } // ...  fmt.Println(\u0026#34;Starting server on port:\u0026#34;, port) //3  log.Fatal(http.ListenAndServe(\u0026#34;:\u0026#34;+port, mux)) //4 }  Assign an empty string to the port variable Use os.GetEnv() to check for a PORT environment variable, and ensure it is not an empty string Inform the user about the port currently in use Replace the hardcoded value with the port  Testing the server should yield the same results.\nTo export a PORT environment variable, run: $ export PORT=\u0026lt;PORT_NUMBER\u0026gt;.\nTry it with port 5000.\n$ export PORT=5000 Starting the server, the application will now run on port 5000.\n Lab 2 - Refactor Refactor the code from your previous exercise to:\n Use a locally scoped instance of http\u0026rsquo;s ServeMux Set the port through an environment variable   Summary Go\u0026rsquo;s standard library provides everything needed for standing up a web-server. In fact, there are many applications in production that exclusively utilize the net/http package. Because net/http is a part of the standard library, you can rest assured that the code is well-maintained, tested, and reliable.\nWith that in mind, there are limitiations around only using the standard net/http pacakge. As you continue to build web applications and services, the time may come to look for alternative packages that offer more flexibilty and ease of use.\nAs always, it\u0026rsquo;s important to choose the right tool for the job, thankfully Go has provided excellent built-in tooling.\nAdditional Resources  Understanding Go Standard HTTP Libraries So You Wanna Start Developing Web Apps With Go, Huh? — Handle, Handler \u0026amp; HandleFunc Dissecting Golang\u0026rsquo;s HandlerFunc, Handle and Default Serve Mux  "
},
{
	"uri": "/react/pillars/testing/tdd/",
	"title": "TDD with Enzyme",
	"tags": [],
	"description": "",
	"content": "Lessons "
},
{
	"uri": "/onboarding/general/",
	"title": "Technology",
	"tags": [],
	"description": "",
	"content": "Who is Orange Academy and what do they do   Module Success:\n Understand who Orange Academy is Technology Onboarding Orange Academy Workshops Orange Academy Apprenticeships    Requested Tactic(s):\n Share a 2-3-minute video demo of how to use and register via launch    Company Performance, Strategy, \u0026amp; Transformation   Module Success:\n Have a general understanding of the following: How THD has performed in the past What the vision is for the future How we plan to get there    Topic 1: THD Performance:\n A brief THD Overview A Review of 2019 Previous Quarter Performance    Topic 2: THD Strategy:\n One Home Depot Technology Investment Enterprise Priorities Enduring Strategies    Topic 3: Modern Technology Transformation:\n Experiences Where we started: on time and on budget User Focused Approach Intro to Agile    Balanced Teams \u0026amp; The Tools They Use   Module Success:\n Understand the parts of a balanced team Their roles and responsibilities What tools they may use    Topic 1: Intro to Balanced Teams:\n Who is on a Balanced Team Rituals for a Balanced Team    Topic 2: Balanced Team Roles\n Overview of Software Engineer Role within the team Overview of UX Designer Role within the team Overview of Product Manager Role within the team Tips for effective communication    Topic 3:Balanced Team Tools\n Product Planning Tools Development Tools    What\u0026rsquo;s Next  Path to MVP Discipline Specific Onboarding  "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/",
	"title": "Terminal &amp; Shell",
	"tags": [],
	"description": "",
	"content": "Welcome to Terminal \u0026amp; Shell! "
},
{
	"uri": "/javascript/nodejs/testing/testing-basics/",
	"title": "Testing Basics",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Why we test Types of testing Behavior Driven Development  Why We Test Testing in software is crucial, but often overlooked or misunderstood part of the process. Testing can be hard and it can add a great deal of time to the development release process. However, testing also cuts down on time developers spend debugging, rewriting, and understanding code. So while it is true it can add time to the development process, it will more than likely save a greater deal of time just by reducing the time spent on these issues.\nTesting in software can have several different meanings and approaches base on what you are testing, or even who is testing it. In the end, there are several reasons we test. The following are just some:\n Ensure that the code works Ensure that the code meets compliance Ensure that the application works with other applications it is intended to work Detect potential vulnerabilities Ensure Coding standards are met Discover bugs, defects and other edge cases Give developers confidence to change code Documentation  Types of Testing As you could probably guess, there are many types of testing:\n Unit Integration User Acceptance End to End Performance/Stress  Unit Testing Unit Testing is the testing of a specific implementation or behavior of block of code. Typically this is a function or method. They should run fast and, for the most part, be the quickest to set up. It should cover only the code within that unit of work. Developers assume that any external pieces have their own tests.\nSome common traits of a Unit Test:\n No external connectivity Small and fast Dependencies,such as external libraries, I/O, functions are mocked  Integration Testing Integration Tests can cover a broad range of tests. Integration tests are testing that all the units of an application are functioning as expected together.\nThe set up an execution of integration tests can much longer. This is because we are testing outside of the confines of the unit. For example, you may need to start up and initialize a clean data base before you can execute the test.\nAn example of an integration test may be testing the entire flow of an endpoint. The test would cover, the application exposing the endpoint. The function that executes when the endpoint is called, and perhaps the read/write of a database.\nAcceptance Testing Acceptance Testing, or User Acceptance Testing, is a test that will ensure the feature begin developed meets the asks of the user or system. Many times, integration tests can meet the needs of acceptance testing and are often interchanged.\nAn acceptance test should be based off acceptance criteria gathered from a product manager and/or user. For example:\nWhen a user clicks the start button, the timer should start to count down.\nIn this simple example, a test would cover the click of a button and determine if the \u0026ldquo;timer\u0026rdquo; was in fact counting down.\nEnd to End Testing Modern systems tend to be made of of many applications, services, and middleware and databases. These test can take much longer than integration or unit tests. This is due to the fact that you are testing the entire system, from the front to the back, or start to finish.\nPerformance/Stress Testing Performance and Stress testing are tests that ensure an application or system is meeting performance standards and or can handle peak loads. These tests can cover individual application deployments, or entire systems.\nThese tests are typically based off service level agreements and objectives that define expectations on how the application or service should perform. For example, an application may be expected to handle 200 requests a min as well as having an average response time of 100ms.\nThe Testing Pyramid \u0026amp; Test Coverage Testing coverage and order can often be represented as a pyramid.\nThe percentage of each test represents the percent of total tests that it should make up. As you go up they pyramid, the longer the tests tend to take.\nCode Coverage Code coverage is a term used to describe the percentage of your code that have been included in tests. There are different breakdowns of code coverage:\n Function: % of functions in the code that have been tested. Line: % of lines ( with code ) that have been tested Path/Branch: % of statements that have been covered. This means if you have an if-then-else statements, both possibilities are accounted for in tests.  Most modern testing frameworks are able to generate some sort of coverage report\nFor example this is very simple example of a coverage report for a javascript application:\n----------|----------|----------|----------|----------|-------------------| | File | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s | | ---------- | ---------- | ---------- | ---------- | ---------- | ------------------- | | All files | 100 | 100 | 100 | 100 | | | sum.js | 100 | 100 | 100 | 100 | | | ---------- | ---------- | ---------- | ---------- | ---------- | ------------------- |  A common pitfall on development teams is that they will demand a specific code coverage. This can actually cause poorly written tests that are more to meet the goal than to test.\nIn other words, don\u0026rsquo;t write tests just to meet test coverage goals, write tests to test code. Use test coverage as an aid to determine if anything may have been missed. If you are writing good tests, then you should have naturally high code coverage.\n Behavior Driven Development Behavior Driven Development (BDD) is a development approach that focuses on the behavior of the code rather than a specific implementation.\nTests are often written with the following thought process:\nGherkin style\nGiven a specific context When an action is taken Then this is the expected result Given 2and 2as input to Add When the function is invoked Then it should return 4A simplified format is often used in unit testing when describing the behavior of a function.\nSimple \u0026ldquo;Unit\u0026rdquo; Style\n#addTwoNumbers context: when 2 and 2 are passed as input it should return 4 You do not need and specific framework or library to use a BDD approach to testing, however, there are many out there for various languages:\n javascript: Jest and Mocha/Chai Go: ginkgo/gomega Java: Cucumber*  *Cucumber actually has frameworks for many other languages including javascript.\nMore on BDD\n"
},
{
	"uri": "/custom-workshops/frontend-at-thd/react-crash-course/usestate/",
	"title": "The useState Hook",
	"tags": [],
	"description": "",
	"content": "Concepts and Skills  Understand how useState allows for local state management in a function component. Apply the useState hook to manage local state in a React component.  Introduction The useState hook is a simple hook that proves to be very powerful for managing local state in a React component.\nThe primary advantages of useState are:\n avoids JavaScript classes: it provides a way to add local state to a function component (thus there is no need for a JavaScript class) composition and reuse: it can be placed in a custom hook and then reused across multiple components  Usage To add state to a component using the useState hook:\nconst [state, setState] = useState(initialState); where state and setState can be any variable names you want, for example:\nconst [color, setColor] = useState(\u0026#39;blue\u0026#39;); Notice that:\n useState takes a single argument which is the initial value we want stored in the state variable. the return value of useState is an array containing the stateful value and a function to update it.  The Initial Value and the State Variable During the initial render, the returned state (state) is the same as the value passed as the first argument (initialState). This is only true for the initial render! During subsequent re-renders, the first value returned by useState will always be the most recent state.\n Performance Tip\nIf calculating the initial value is an expensive operation, you can prevent unnecessary recalculations by using a function that returns the initial value. React will only call that function on the initial render.\nconst [answerToEverything, setAnswerToEverything] = useState(() =\u0026gt; getTheAnswerToEverything(props));  The setState function The setState function is used to update the state. It accepts a new state value and enqueues a re-render of the component.\n Calculating State from Previous State\nIf the new state is computed from the previous state, you can pass a function to setState. The function will receive the previous value, and return an updated value.\nconst [count, setCount] = useState(0); //...  setCount(prevState =\u0026gt; prevCount + 1);  An Example of a Counter Component Let\u0026rsquo;s look at an example of a Counter component using setState and then we will see how to refactor it to use useState:\nA Counter Component using setState (no hooks)\nimport React from \u0026#34;react\u0026#34; class Counter extends React.Component { constructor(props) { super(props) this.state = { count: props.initialCount } } increment = () =\u0026gt; { this.setState({ count: this.state.count + 1 }) } decrement = () =\u0026gt; { this.setState({ count: this.state.count \u0026gt; 1 ? this.state.count - 1 : 0 }) } reset = () =\u0026gt; { this.setState({ count: 0 }) } render() { return ( \u0026lt;article\u0026gt; \u0026lt;h2\u0026gt;Counter with setState\u0026lt;/h2\u0026gt; \u0026lt;button onClick={this.decrement}\u0026gt;-\u0026lt;/button\u0026gt; \u0026lt;button onClick={this.increment}\u0026gt;+\u0026lt;/button\u0026gt; \u0026lt;button onClick={this.reset}\u0026gt;0\u0026lt;/button\u0026gt; \u0026lt;p\u0026gt;The count is {this.state.count}\u0026lt;/p\u0026gt; \u0026lt;/article\u0026gt; ) } } export default Counter We can refactor this code from a class component into a function component using the useState hook:\nA Counter component using the useState hook\nimport React, { useState } from \u0026#34;react\u0026#34; // 1  const Counter = ({initialCount}) =\u0026gt; { const [count, setCount] = useState(initialCount) // 2  const increment = () =\u0026gt; setCount(count + 1) const decrement = () =\u0026gt; setCount(count \u0026gt; 1 ? count - 1 : 0) const reset = () =\u0026gt; setCount(0) return ( \u0026lt;article\u0026gt; \u0026lt;h2\u0026gt;Counter with useState Hook\u0026lt;/h2\u0026gt; \u0026lt;button onClick={decrement}\u0026gt;-\u0026lt;/button\u0026gt; \u0026lt;button onClick={increment}\u0026gt;+\u0026lt;/button\u0026gt; \u0026lt;button onClick={reset}\u0026gt;0\u0026lt;/button\u0026gt; \u0026lt;p\u0026gt;The count is {count}\u0026lt;/p\u0026gt; \u0026lt;/article\u0026gt; ) } export default Counter  import useState use the hook to create the state variable and a setter for updating the state variable.   Improvements\nObserve the following improvements in the refactored version:\n We no longer need a JavaScript class. No more worrying about this binding (look Ma, no this anywhere)! A reduction in the number of lines of code from 33 lines to 18 lines.   Lab: Refactor the Color Slider To get some practice with useState refactor the ColorBrowser app to use the useState hook.\nInstructions  Clone the setState code from Color Browser. Run yarn and then yarn start and test that the code is working. Use your favorite text editor or IDE to search for occurrences of setState. Where you found uses of setState, refactor the code to use JavaScript functions instead of classes and the useState hook instead of setState. Manually test your solution.  Conclusion The useState hook provides a mechanism for:\n Adding state to a function component, thus avoiding the need for a JavaScript class. Encapsulating and reusing state update logic across multiple components (using a custom hook that wraps useState)  "
},
{
	"uri": "/react/pillars/hooks/usestate/",
	"title": "The useState Hook",
	"tags": [],
	"description": "",
	"content": "Concepts and Skills  Understand how useState allows for local state management in a function component. Apply the useState hook to manage local state in a React component.  Introduction The useState hook is a simple hook that proves to be very powerful for managing local state in a React component.\nThe primary advantages of useState are:\n avoids JavaScript classes: it provides a way to add local state to a function component (thus there is no need for a JavaScript class) composition and reuse: it can be placed in a custom hook and then reused across multiple components  Usage To add state to a component using the useState hook:\nconst [state, setState] = useState(initialState); where state and setState can be any variable names you want, for example:\nconst [color, setColor] = useState(\u0026#39;blue\u0026#39;); Notice that:\n useState takes a single argument which is the initial value we want stored in the state variable. the return value of useState is an array containing the stateful value and a function to update it.  The Initial Value and the State Variable During the initial render, the returned state (state) is the same as the value passed as the first argument (initialState). This is only true for the initial render! During subsequent re-renders, the first value returned by useState will always be the most recent state.\n Performance Tip\nIf calculating the initial value is an expensive operation, you can prevent unnecessary recalculations by using a function that returns the initial value. React will only call that function on the initial render.\nconst [answerToEverything, setAnswerToEverything] = useState(() =\u0026gt; getTheAnswerToEverything(props));  The setState function The setState function is used to update the state. It accepts a new state value and enqueues a re-render of the component.\n Calculating State from Previous State\nIf the new state is computed from the previous state, you can pass a function to setState. The function will receive the previous value, and return an updated value.\nconst [count, setCount] = useState(0); //...  setCount(prevState =\u0026gt; prevCount + 1);  An Example of a Counter Component Let\u0026rsquo;s look at an example of a Counter component using setState and then we will see how to refactor it to use useState:\nA Counter Component using setState (no hooks)\nimport React from \u0026#34;react\u0026#34; class Counter extends React.Component { constructor(props) { super(props) this.state = { count: props.initialCount } } increment = () =\u0026gt; { this.setState({ count: this.state.count + 1 }) } decrement = () =\u0026gt; { this.setState({ count: this.state.count \u0026gt; 1 ? this.state.count - 1 : 0 }) } reset = () =\u0026gt; { this.setState({ count: 0 }) } render() { return ( \u0026lt;article\u0026gt; \u0026lt;h2\u0026gt;Counter with setState\u0026lt;/h2\u0026gt; \u0026lt;button onClick={this.decrement}\u0026gt;-\u0026lt;/button\u0026gt; \u0026lt;button onClick={this.increment}\u0026gt;+\u0026lt;/button\u0026gt; \u0026lt;button onClick={this.reset}\u0026gt;0\u0026lt;/button\u0026gt; \u0026lt;p\u0026gt;The count is {this.state.count}\u0026lt;/p\u0026gt; \u0026lt;/article\u0026gt; ) } } export default Counter We can refactor this code from a class component into a function component using the useState hook:\nA Counter component using the useState hook\nimport React, { useState } from \u0026#34;react\u0026#34; // 1  const Counter = ({initialCount}) =\u0026gt; { const [count, setCount] = useState(initialCount) // 2  const increment = () =\u0026gt; setCount(count + 1) const decrement = () =\u0026gt; setCount(count \u0026gt; 1 ? count - 1 : 0) const reset = () =\u0026gt; setCount(0) return ( \u0026lt;article\u0026gt; \u0026lt;h2\u0026gt;Counter with useState Hook\u0026lt;/h2\u0026gt; \u0026lt;button onClick={decrement}\u0026gt;-\u0026lt;/button\u0026gt; \u0026lt;button onClick={increment}\u0026gt;+\u0026lt;/button\u0026gt; \u0026lt;button onClick={reset}\u0026gt;0\u0026lt;/button\u0026gt; \u0026lt;p\u0026gt;The count is {count}\u0026lt;/p\u0026gt; \u0026lt;/article\u0026gt; ) } export default Counter  import useState use the hook to create the state variable and a setter for updating the state variable.   Improvements\nObserve the following improvements in the refactored version:\n We no longer need a JavaScript class. No more worrying about this binding (look Ma, no this anywhere)! A reduction in the number of lines of code from 33 lines to 18 lines.   Lab: Refactor the Color Slider To get some practice with useState refactor the ColorBrowser app to use the useState hook.\nInstructions  Clone the setState code from Color Browser. Run yarn and then yarn start and test that the code is working. Use your favorite text editor or IDE to search for occurrences of setState. Where you found uses of setState, refactor the code to use JavaScript functions instead of classes and the useState hook instead of setState. Manually test your solution.  Conclusion The useState hook provides a mechanism for:\n Adding state to a function component, thus avoiding the need for a JavaScript class. Encapsulating and reusing state update logic across multiple components (using a custom hook that wraps useState)  "
},
{
	"uri": "/golang/concurrency/introduction/",
	"title": "Understanding Concurrency",
	"tags": [],
	"description": "",
	"content": "Concurrency Concurrency is the DESIGN or the managing of multiple processes that could occur at the same time but is not necessarily happening at the same time.\nConcurrent applications:\n could leads to better performance of an application or script increased efficiency of resources, such as processor cores and memory are NOT parallelism.  Parallelism is processes (or signals), actually occurring at the same time.\nA concurrent application could have parallel execution if:\n the hardware could support it had enough workload the signals are triggered at the same time  Concurrent applications tell the system which pieces of work could be worked on at the same.\nConcurrency Vs. Asynchronicity Other languages talk about making applications asynchronous. This is the same idea as concurrency.\nExample: Javascript is running off an event loop, allowing for Asynchronicity to unblock a process, and use signals to have something occur when an asynchronous process has finished.\nBenefits of Concurrency Concurrency allows resources to be executing other things while waiting on other work to finish.\nSome examples of this are:\n Requesting data and drawing on the DOM (Document Object Model) of a webpage while waiting for that data to return. Batching work on large amounts of data at the same time. Sending http requests into a concurrent process to unblock a port.  In the above batch process example, it displays ten cars being worked on at the same time.\n In the first scenario: all of the cars are built, wheels put on and then painted individually. In the second scenario: it shows that it would take the same amount of time if all ten cars are getting that process (body, wheels, and paint).  Therefore, if there were ten cars being processed at the same time, there would be ten times the output in the same amount of time.\nThe above image shows how 5 servers could process a chunk of the Big Data at the same time, allowing for dividing and conquering.\nIt would take more time to process each chunk one at a time, serially.\nActivity - Batching Required Material\n 20 flat items, like coins per each group of 3 or more. A Timing mechanism.  Setup\n Break up into groups of 3 or more. Put your team members in a row and time how long it takes to:  Have each team member flip all 20 items before passing to the next person, and so on. Stop timing when the last item has been flipped by the last team member. Have each team member flip 5 before passing. Have each team member flip one before passing.    Discussion\nThe time difference from each team member flipping all 20, to only having to flip 5 before sending a \u0026ldquo;batch\u0026rdquo; to the next member should have been significant. Imagine each team member was a core of our server\u0026rsquo;s processor. By batching we were able to better utilize our resources.\nConcurrency Terms Process A process is a set of instructions, or program currently being processed by a computer processor.\nA process may be made up of multiple threads of execution that execute instructions concurrently. (Operating system, hardware, and programming language dependent)\nThreading Thread is short for a thread of execution. Threads are a way for a program to divide, AKA \u0026ldquo;split\u0026rdquo;, itself into two or more simultaneously (or pseudo-simultaneously) running tasks.\n Threads are contained inside a process Threads are lightweight, in terms of the system resources they consume, unlike processes. Different threads share the same resources in the same process vs. different processes in the same multitasking OS do not  A thread is a flow of execution through the process code, with its own program counter that keeps track of:\n which instruction to execute next system registers which hold its current working variables a stack which contains the execution history  A thread shares with its peer threads a few pieces of information like:\n Code segments Data segments Open files  When one thread alters a code segment memory item, all other threads see that.\nEach thread must belong to exactly one process. Each thread represents a separate flow of control.\nThreads:\n have been successfully used in implementing network servers and web servers provide a suitable foundation for parallel execution of applications on shared memory multiprocessors  The following shows a single-threaded vs a multithreaded process.\n A processor register (CPU register) is a part of the computer processor that holds a small set of data. A program counter (PC) is a CPU register in the computer processor which has the address of the next instruction to be executed from memory. A stack is a special area of computer\u0026rsquo;s memory which stores temporary variables created by a function. When the computing task is complete, the memory of the variable will be automatically erased.  Threads can either be:\n user-level threads (managed by user) kernel-level threads (managed by the OS acting on kernel, an os core)  Summary Concurrency is the design of allowing processes to possibly run in parallel. Designing our code to utilize concurrency, when appropriate, can increase the speed and efficiency of our applications.\nFurther Reading Resources  What is a Register? A Great image showing Registers Stack Vs. Heap Memory  "
},
{
	"uri": "/golang/fromjava/intro/",
	"title": "Welcome to Golang",
	"tags": [],
	"description": "",
	"content": "Good Choice! If you\u0026rsquo;re a Java developer and your interest was piqued enough to come look at this page, then congratulations. You\u0026rsquo;re about to see how easy it is to transition your development into Golang. It\u0026rsquo;s not just easy (because everything about Go is simple), but chances are, you\u0026rsquo;re going to enjoy it too.\nWhy is it easy to convert to Golang from Java? Golang is a strongly data typed backend language that serves the same purposes and can be built to run on all the same platforms.\nWhy would you want to use Go?  Concurrency is Go is easier and more performant. See our concurrency content Go is compiled down to machine code. Making it faster (outperforming languages that are interpreted or have virtual runtimes), more flexible in its thread management, and more lightweight by pushing a single binary file with NO production environment setup and nothing to pre-install. Running code is as simple as ./ running of the binary. Minimalist design means you have most of what you need out of the box. Testing, debugging, http functionality, concurrency, and much more are all available with no external imports. No implicit type conversions. Go is actually even more type secure than Java helping you cut out more runtime error opportunities. Interfaces are implicit and defined by type structure which allows for runtime polymorphism with no explicit implementations. Open Source. Go became a public open source project on November 10, 2009. Countless people from the community have contributed ideas, discussions, and code. Amazing documentation. All code is self documented via go doc. Build artifacts are 100x smaller. This means that Go is cheaper when running in the cloud. We built a greeter API in both Spring Boot and Golang, put them in a docker container. Here are the size differences:  docker.artifactory.homedepot.com/Orange Academy/docker/go-greet 5.82MB docker.artifactory.homedepot.com/Orange Academy/docker/springboot-example 427MB  Note: Java could be compressed down to smaller artifacts via third party libraries, such as the following:\n Tomee Microprofile Quarkus Micronaut Graalvm  Which could bring the Java app size down closer to Go out of the box.\n Principles of Go When Go was designed, Java and C++ were the most commonly used languages for writing servers, at least at Google. We felt that these languages required too much bookkeeping and repetition. Some programmers reacted by moving towards more dynamic, fluid languages like Python, at the cost of efficiency and type safety. We felt it should be possible to have the efficiency, the safety, and the fluidity in a single language. Go attempts to reduce the amount of typing in both senses of the word. Throughout its design, we have tried to reduce clutter and complexity. There are no forward declarations and no header files; everything is declared exactly once. Initialization is expressive, automatic, and easy to use. Syntax is clean and light on keywords. Stuttering (foo.Foo* myFoo = new(foo.Foo)) is reduced by simple type derivation using the := declare-and-initialize construct. And perhaps most radically, there is no type hierarchy: types just are, they don\u0026rsquo;t have to announce their relationships. These simplifications allow Go to be expressive yet comprehensible without sacrificing, well, sophistication. Another important principle is to keep the concepts orthogonal. Methods can be implemented for any type; structures represent data while interfaces represent abstraction; and so on. Orthogonality makes it easier to understand what happens when things combine. - Excerpt from the Official Go FAQ\nSetup There\u0026rsquo;s no need to install a JVM, or JRE. Simply use brew to install Golang.\nbrew install go\nOrganizing Files and Folders Start in a new directory called calculator . Type the following command: go mod init github.homedepot.com/LDAP/calculator where LDAP is your LDAP. This will create a go.mod file which is like a maven file. It will hold a list of all third party libraries, and their versions.\nThis calculator app will be a module, which is a container of packages. Packages is how golang code is organized.\nCreate a main.go file. touch main.go . In that main.go file, add the following code:\npackage main import \u0026#34;fmt\u0026#34; func main(){ fmt.Println(\u0026#34;Welcome Gophers!~\u0026#34;) } The main function of the main package is the entry point of the application. When the main function exits, the application exits.\nThe top of the file must start with the name of the package. All other packages can have any name, but should be one word, if at all possible, and lower cased.\nBuild and Run Build and run this file, then we\u0026rsquo;ll create the other two packages for examples.\ngo build will create the production artifact binary file. By default it will take the name of the directory or module name. Now you can run this binary via ./calculator . You can also do a go run main.go which will create the binary (if your code is compilable) and run it, then delete the binary. This command is best as you develop.\nPackages Create two directories off the root directory. One add and the other subtract, so that your directory looks like the following:\ncalculator |-- add |-- subtract In the add directory, create a add.go file. In that file place the following content:\npackage add func Do(num1, num2 int) int{ return num1 + num2 } In the subtract directory, create a subtract.go file. In that file place the following content:\npackage subtract func Do(num1, num2 int) int{ return num1 - num2 } Note: Sneak peak into functions. These function signatures specify that they will accept two integers and return one integer.\nNow in the main.go file, we\u0026rsquo;ll utilize these two packages we\u0026rsquo;ve just created.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.homedepot.com/LDAP/calculator/add\u0026#34; \u0026#34;github.homedepot.com/LDAP/calculator/subtract\u0026#34; ) func main(){ fmt.Println(add.Do(2, 3)) fmt.Println(subtract.Do(20, 13)) } Note: In order to import local packages, we preface with the name of the module.\nBy default we the name of the package is referenced by its name, i.e. add.Do to call the Do function within the add package.\nFor more information on importing or giving packages aliases, see the [./gomods/gomods/](modules lesson).\nVariables In Java we put the data type first.\nString department = \u0026quot;Lumber\u0026quot;; \nIn Go, we place the data type after the name of the variable.\nvar department string = \u0026quot;Lumber\u0026quot;\nIf inside of a function, the keyword \u0026lsquo;var\u0026rsquo; is not required. The symbol := may be used instead.\ndepartment string := \u0026quot;Lumber\u0026quot;\nNote: := is referred to as both the gopher and the walrus.\nIf initializing a variable with a value, the data type can be inferred from the value.\ndepartment := \u0026quot;Lumber\u0026quot;\nNote: We do not need to place a semicolon at the end of our expressions unless we\u0026rsquo;re putting more than one expression on a line, as in \u0026ldquo;short if\u0026rdquo; statements, switch, or for loops. Ex: if x:=add(y, z); x \u0026gt; 3 { // ... }\nWe can put an expression in front of the conditional. This code means, create a new variable x, initialize its value equal to what is returned from the function add. Then in the conditional, check that it is greater than 3.\nUnlike Java, Uninitialized variable in Golang will not error when used. They are simply initialized to a default value.\n   Data Type Default Value     Numbers 0   Strings \u0026quot;\u0026rdquo; (empty strings)   Booleans false   Errors nil    Golang Documentation on data types\nClass Modifiers Java has four class modifiers of scope and privacy: Private, Protected, Package Private, and Public. In Golang there is only Exported or Unexported.\nExported : The first letter must be uppercased. Is accessible outside the package. (e.g. MyFunc) Unexported : The first letter must be lowercased. Is NOT accessible outside the package. (e.g. myFunc)\nThis applies for variables, functions and custom datatypes.\nCollections In Java there are many collection types, arrays, sets, lists, queues, and maps. In Golang, there are only arrays, slices (based on arrays), and maps.\nArrays In Java: int arr[] = new int[] (1, 2, 3, 4);\nIn Golang: arr := [4]int{1, 2, 3, 4}\nArrays in Golang are never resized. Slices are pointers to arrays. They can be resized as needed. They can be based off existing arrays or get its own right at birth.\nSlices based off existing arrays. arr := [4]int{1, 2, 3, 4} sli := arr[1:3] // 2, 3 Note: When creating slices based on existing arrays, you pass a low index and a high index. The high number is not inclusive. When left out they default to lowest and highest. Example: `sli := arr[:] // 1, 2, 3, 4\nSlice gets its own array sli := []int{1, 2, 3, 4} Slices can grow and shrink via the append and copy methods.\nMaps Maps work similar to Java\u0026rsquo;s Hash Maps, where the keys and values can be any data type, but must remain consistent throughout the map.\nm := map[string]int{ \u0026#34;one\u0026#34; : 1, \u0026#34;two\u0026#34; : 2, } m[\u0026#34;three\u0026#34;] = 3 fmt.Println(m[\u0026#34;one\u0026#34;]) Note: The lagging comma is required when breaking each element into a newline.\nSee more in the collections lesson\nIterating Iterating can be done via old fashioned for loop, or using the range built-in method. It can be used on the following:\n strings (which is a byte slice) arrays slices maps channels (see concurrency)  arr := [4]string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;} for ind, val := range arr { fmt.Println(ind, val) } // 0 a // 1 b // 2 c // 3 d Range returns two values, the index (or key for maps), and the value. The index or key can be negated by putting an underscore instead of a variable name.\narr := [4]string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;} for _, val := range arr { fmt.Println(val) } Functions Function signatures in Golang are close to that of Java. The return types are places at the back end instead of in front. Its like translating Spanish to English. El coche rojo (The car red) = The red car.\nJava public double getTax(double subtotal){} A public function that returns a double precision float named getTax and accepts a parameter named subtotal that is a double data type.\nGolang func GetTax(subtotal float64) float64 {} An exported function named GetTax that accepts a float named subtotal as a parameter and returns a float. This reads in a more streamlined way: type =\u0026gt; name =\u0026gt; input =\u0026gt; output.\nFunctions work the same, except that Golang functions can return more than one value.\nfunc EvenAndOdd(allNums []int) ([]int, []int) { var evens, odds []int // declare 2 slices \tfor _, val := range allNums { // loop over input \tif val%2 == 0 { // check for even \tevens = append(evens, val) } else { // else odd \todds = append(odds, val) } } return evens, odds // return both slices } Structs and Methods Structs and methods are similar in concept to a Java Class and its methods. However, they have a very different implementation because Go is a procedural (or functional) language while Java is Object oriented. You define a struct and then you can create multiple instances of it, like you do with classes in Java.\ntype Car struct { cmake string model string year int } func main() { mycar := Car{ cmake: \u0026#34;Ford\u0026#34;, model: \u0026#34;Shelby GT500\u0026#34;, year: 1967, } fmt.Println(mycar.year) yourcar := Car{ cmake: \u0026#34;Tesla\u0026#34;, model: \u0026#34;Model S\u0026#34;, year: 2020, } fmt.Println(yourcar.cmake) } Once an instance has been created, you can reference fields via dot notation. This should feel very familiar.\nAdding methods is easy. After you define a struct, or any custom data type, you can attach methods to them as in the below example:\ntype Car struct { cmake string model string year int fuel int fuelUnit string } func (c *Car) Drive(){ c.fuel = 0 } func main() { yourcar := Car{ cmake: \u0026#34;Tesla\u0026#34;, model: \u0026#34;Model S\u0026#34;, year: 2020, fuel: 312, fuelUnit: \u0026#34;chargeMiles\u0026#34;, } fmt.Println(yourcar.cmake) yourcar.Drive() fmt.Println(yourcar.fuel) // 0 } Notice the func Drive is defined as being attached to the type Car, before the name of the function. *Car means it is a pointer to a car, allowing it to change the instance in memory directly, therefore, not needing to accept or return any values.\nMethods are invokes via dot notation.\nInterfaces Go maintains the idea of an interface in order to enable polymorphism just like Java. However, interfaces in Go have a more purely declarative nature with an implied implementation (Duck typing). In other words, interface declaration itself is more flexible and there is no explicit implements keyword for implementing an interface on a Go struct. Rather, the compiler simply checks to make sure that all necessary methods defined in the interface are available on the struct.\nHere\u0026rsquo;s an example (remember, Go is procedural and not Object oriented, so this may look weird at first)\n// Logger is an interface with 2 stubbed methods type Logger interface { Write(string) WriteList([]string) int } // FmtLogger is an empty struct (no fields) type FmtLogger struct{} // Write is a method available on an FmtLogger func (l *FmtLogger) Write(event string) { fmt.Println(event) } // WriteList is a method available on an FmtLogger func (l *FmtLogger) WriteList(events []string) int { for _, event := range events { fmt.Println(event) } return len(events) } As far as the Go compiler is concerned, FmtLogger implements Logger. Even though we never explicitly declared it, FmtLogger has all the necessary methods available.\nErrors, Panics, and Exceptions Here you have to change the way you think about errors. In Golang, Errors are expected to happen, and should be caught.\nThey are like Java Exceptions. In Golang, Panics are for extreme cases only (like errors in Java). Panics will crash a go app if not recovered.\nErrors are the norm\nfunc queryDB(query) (*sql.Row, error) { row, err := db.QueryRow(query) if err != nil { return nil, fmt.Errorf(\u0026#34;query failed in db.Query %v: %v\u0026#34;, query, err) } else { return row, nil } } The above function returns two values, a Row database defined in the sql package, and an error. If all goes well, returns the default database for errors, nil. Otherwise it wraps the error it receives. Wrapping errors allows you to trace where the error came from.\nPanics are Extreme\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sql\u0026#34; ) func main() { defer func(){ panicMsg := recover() // Unable to ping database \tlog(panicMsg) // Send error message to user. \t}() db := connectDB() checkConnection(db) query(db, \u0026#34;select * from students;\u0026#34;) } func checkConnection(db *sql.DB) { err = db.Ping() if err != nil { Panic(\u0026#34;Unable to ping database\u0026#34;) } } Panics should never leave a module boundary. Panics should only be used if the app has reached a critical failure and cannot go on.\nNote: Defer will run code before a function is allowed to exit, even if there is a panic.\nConcurrency Concurrency is acheived through goroutines. A goroutine is created by prefacing a function execution with the word go.\nfor customer, _ := range newCustomers { go service.Create(customer) } The above will create each customer concurrently.\nNote: Functions executed via go routines cannot return data. They are also non-blocking and will not stop the main thread from exiting, thus end the program. For this reason communication among go routines is required via channels.\nTo see more on channels see our channels lesson\nAdditional resources  \u0026ldquo;Go at Google\u0026rdquo; Transcript An \u0026ldquo;Effective Java\u0026rdquo; Example in Go Pro/Con List from WillowTree Consulting  Contact Us    Medium Detail     Slack #Orange Academy   Email Orange Academy@homedepot.com   Website Orange Academy.homedepot.com    "
},
{
	"uri": "/java/foundations/what-is-java/",
	"title": "What is Java",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Describe the various aspects of Java as a language, a runtime environment, and an ecosystem Explain the process of compiling a Java program into bytecode List some advantages of compiling a language to a bytecode Describe the roles of the JVM, the JRE, and the JDK Define the concept of Garbage Collection?  What is Java? There are several sides to Java. One side, the side you probably expect, is a programming language. It\u0026rsquo;s what you generally imagine we would be discussing (and what we will discussing for most of our time). However, the Java language by itself is nothing special. Just another programming language with a lot of hard opinions on life and how it should work (we all know the type), useful but finicky. Java is also an environment, known as the Java Runtime Environment (JRE). A JRE consists of a Java Virtual Machine (JVM) and the base set of Java libraries necessary to run an application. A JVM is an abstract machine that meets specs to run Java Bytecode. The definition is vague because there is no set format, only a set of specifications that have to be met. Java is also a set of tools known as the Java Development Kit (JDK), which contains everything you need to create a java program (namely a JRE + a compiler).\nJava Tar Files The way Java apps are compiled, they should be self contained applications. Meaning you should end up with a set of files that can be placed in any JVM, hosted anywhere, and run. There are several common formats you may have heard of to accomplish this.\n JAR: Java ARchive is platform independent zip file of JDK software WAR: Web Application ARchive is a JAR with web related files (servlets, HTML, web.xml, etc)  Requires container to run   EAR: Enterprise Application ARchive only contains Enterprise application related files like XML  Why is Java so popular? Java was originally released to the public in 1995 authored by James Gosling, Mike Sheridan, and Patrick Naughton. The original intention when they started development in 1991 was to be utilized for interactive television\u0026hellip;however, it was too complex to be handled by the tools the cable industry had to work with. They used a syntax inspired by C/C++ (the main languages of the industry at the time) so that developers would find it familiar. Other than that, the philosophy behind Java was revolutionary at the time.\nPortability Java was the first language approached with the idea of Write Once Run Anywhere. We hinted at this before with the idea of JVMs. The process goes something like this:\n You develop a Java application Your code is compiled into Java bytecode that can be read by any JVM (.class files) At runtime, the JVM compiles the bytecode to native machine language  What made this special is that your application is now entirely neutral when it comes to hosting and architecture. It doesn\u0026rsquo;t care where it is, what tools you used, or how its being served. As long as it has a JVM (which again, comes in all shapes and sizes) it can work its magic.\nPerformance Threading Java is also highly performant. One way this is accomplished is through concurrency. You may have heard the term multi-threaded in relation to Java. What this means is that you can have more than one thread of Java (more than one line of action) operating at the same time. Its true multi-tasking, where your application can take two independent task and delegate them across available memory. When one completes, it is freed up to be reassigned another task. All of this comes together to reduce idle time because it doesn\u0026rsquo;t have to wait for one action to complete while another is still processing.\nJust In Time Compilation Prior to Java (and currently) most application must be interpreted, meaning the language it\u0026rsquo;s written in is not readily understandable by the machine running the task. This causes delayed performance. Imagine everyday when you came to work (or even in this lesson) and your tasks for the day were written in some form of gibberish you couldn\u0026rsquo;t understand\u0026hellip;that might slow you down. The same is true for machines. Java overcomes this obstacle with Just In Time Compilers. As opposed to simply compiling before deploying and leaving it there, JVMs have compilers that will run during runtime right before a method is called. This gives the compiler more information about the machine its running on to make more informed decisions on optimization and compilation into machine language allowing for a more efficient usage of processor time and memory. The closer the JIT compilers get to 0 runtime, the closer Java applications will get to running as a truly native app (which, as you recall, was the main competition at the time).\nThis is why Java, while getting up there in age, stays relevant. Compare this with JavaScript, a modern, very popular language which is interpreted. While it is a light weight in comparison to stand up the app and deploy, it cannot compete with the performance found in Java. This is why it\u0026rsquo;s important to know the demand of your app before you make a decision on a tech stack.\nObject Oriented One of the first things you\u0026rsquo;ll hear people say about Java as a language is it\u0026rsquo;s Object Oriented. Sure enough it is all but the poster child for Object Oriented Programming. The goal here is security, reusable and efficient code, and intuitive design. The power of OOP and its more intricate ideas will be discussed in depth later.\nRobust We all hate debugging (probably), and we hate broken apps more. It\u0026rsquo;s frustrating, mind-numbing, and (if it is deployed) downright embarrassing. Java does its best to give you the best chance to succeed by catching as much as it can during compilation (largely through its extensive type system). Issues that get through are handled through a robust exception handling process.\nMemory Management Lastly, a big issue at the time of native apps was memory management. You\u0026rsquo;ve felt these pains if you\u0026rsquo;ve ever coded a native running application. Even with today\u0026rsquo;s advancements, a processor only has so much memory to offer and everything you do in a program needs memory. This used to mean tracking your variables held in memory, knowing when they were no longer needed, and explicitly releasing the memory that houses it.\nJava solves this through a process aptly named: Garbage Collection. This process is defined by the JVM and, like JVMs, there are many ways that this process can be implemented and it may vary between machines. At its core, however, it has to accomplish a few things:\n Mark unreferenced objects for deletion (see our lesson on Classes and Objects for more about dereferencing objects) Delete marked objects from memory Memory Compaction  Summary Java is a self-contained application in and of itself. From language, to compilation, to the JVM running the app, it is controlled the whole way. This setup demands a lot of specifications and is very opinionated when it comes to how its implemented, but it all comes together to create a powerful solution for highly demanding applications.\n"
},
{
	"uri": "/golang/testing/why/",
	"title": "Why Do We Test?",
	"tags": [],
	"description": "",
	"content": "Goals Gain an understanding why testing code is important and its benefits.\nLearning Objectives  Explore misconceptions about testing Understand the goals of testing Review the benefits of testing correctly  Misconceptions of Testing  too difficult not worth the time  Actual Benefits Reduces time to:\n debug refactoring understanding code  After code has made it to production, testing can:\n make finding bugs faster reduce downtime  It is less costly to find defects before code has been released.\nGoals and Benefits of Testing Improve the quality of our software\nThe easier it is to test code, the more modular it tends to be. This lends itself to less technical debt, which also provides the ability to add new features more quickly.\nEnsure more uptime in production\nIn testing, we can catch issues before they make it to production.\nIncrease reliability further downstream\nApplications that rely on your code base as a dependency can benefit from the increased reliability granted from testing.\nUncover bugs, defects, and uncommon edge cases\nIt is far easier to create edge cases, and failures in a test than in real life. More scenarios can be tested, and done so in a faster way.\nExpand ability to detect race conditions\nRace conditions are the most difficult of issues to troubleshoot. Testing for these issues will save countless hours.\nDetect security vulnerabilities\nIt is far better to catch security weak spots while in development, rather than after the application has been hacked. Once hacked the company could take a monetary and reputation hit.\nEnsure coding standards are met\nCoding standards are a set of guidelines, best practices, programming styles and conventions that developers adhere to when writing source code for a project.\nThese guidelines and Best Known Methods (BKMs) :\n make the code easier to read add predictability decrease the chance for bugs  Provide confidence to make on-going changes\nA passing test can add confidence to a developer making changes. It may not always be easy to know all the consumers of a piece of code.\nCreates documentation for the code\nTesting can provide documentation for how a piece of software is expected to behave.\nConclusion It may take more time up front in the development cycle to write tests, but the benefits of testing far out-weigh the initial investment. They are not optional. They are mandatory.\n"
},
{
	"uri": "/python/testing/why/",
	"title": "Why Do We Test?",
	"tags": [],
	"description": "",
	"content": "Goals Gain an understanding why testing code is important and its benefits.\nLearning Objectives  Explore misconceptions about testing Understand the goals of testing Review the benefits of testing correctly  Misconceptions of Testing  too difficult not worth the time  Actual Benefits Reduces time to:\n debug refactoring understanding code  After code has made it to production, testing can:\n make finding bugs faster reduce downtime  It is less costly to find defects before code has been released.\nGoals and Benefits of Testing Improve the quality of our software\nThe easier it is to test code, the more modular it tends to be. This lends itself to less technical debt, which also provides the ability to add new features more quickly.\nEnsure more uptime in production\nIn testing, we can catch issues before they make it to production.\nIncrease reliability further downstream\nApplications that rely on your code base as a dependency can benefit from the increased reliability granted from testing.\nUncover bugs, defects, and uncommon edge cases\nIt is far easier to create edge cases, and failures in a test than in real life. More scenarios can be tested, and done so in a faster way.\nExpand ability to detect race conditions\nRace conditions are the most difficult of issues to troubleshoot. Testing for these issues will save countless hours.\nDetect security vulnerabilities\nIt is far better to catch security weak spots while in development, rather than after the application has been hacked. Once hacked the company could take a monetary and reputation hit.\nEnsure coding standards are met\nCoding standards are a set of guidelines, best practices, programming styles and conventions that developers adhere to when writing source code for a project.\nThese guidelines and Best Known Methods (BKMs) :\n make the code easier to read add predictability decrease the chance for bugs  Provide confidence to make on-going changes\nA passing test can add confidence to a developer making changes. It may not always be easy to know all the consumers of a piece of code.\nCreates documentation for the code\nTesting can provide documentation for how a piece of software is expected to behave.\nConclusion It may take more time up front in the development cycle to write tests, but the benefits of testing far out-weigh the initial investment. They are not optional. They are mandatory.\n"
},
{
	"uri": "/software-eng-essentials/testing/why/",
	"title": "Why Do We Test?",
	"tags": [],
	"description": "",
	"content": "Goals Gain an understanding why testing code is important and its benefits.\nLearning Objectives  Explore misconceptions about testing Understand the goals of testing Review the benefits of testing correctly  Misconceptions of Testing  too difficult not worth the time  Actual Benefits Reduces time to:\n debug refactoring understanding code  After code has made it to production, testing can:\n make finding bugs faster reduce downtime  It is less costly to find defects before code has been released.\nGoals and Benefits of Testing Improve the quality of our software\nThe easier it is to test code, the more modular it tends to be. This lends itself to less technical debt, which also provides the ability to add new features more quickly.\nEnsure more uptime in production\nIn testing, we can catch issues before they make it to production.\nIncrease reliability further downstream\nApplications that rely on your code base as a dependency can benefit from the increased reliability granted from testing.\nUncover bugs, defects, and uncommon edge cases\nIt is far easier to create edge cases, and failures in a test than in real life. More scenarios can be tested, and done so in a faster way.\nExpand ability to detect race conditions\nRace conditions are the most difficult of issues to troubleshoot. Testing for these issues will save countless hours.\nDetect security vulnerabilities\nIt is far better to catch security weak spots while in development, rather than after the application has been hacked. Once hacked the company could take a monetary and reputation hit.\nEnsure coding standards are met\nCoding standards are a set of guidelines, best practices, programming styles and conventions that developers adhere to when writing source code for a project.\nThese guidelines and Best Known Methods (BKMs) :\n make the code easier to read add predictability decrease the chance for bugs  Provide confidence to make on-going changes\nA passing test can add confidence to a developer making changes. It may not always be easy to know all the consumers of a piece of code.\nCreates documentation for the code\nTesting can provide documentation for how a piece of software is expected to behave.\nConclusion It may take more time up front in the development cycle to write tests, but the benefits of testing far out-weigh the initial investment. They are not optional. They are mandatory.\n"
},
{
	"uri": "/software-eng-essentials/git-pillars/plumbing-labs/",
	"title": "Git Plumbing Labs",
	"tags": [],
	"description": "",
	"content": "Exercise 1: How Git Saves Files  Create a new folder and initialize git on it Use a text editor to create \u0026amp; save a new file. Write a 1-line bio in it. Save the file to your git database using plumbing: git hash-object -w \u0026lt;filename\u0026gt; Use resulting hash to inspect the file using a plumbing command: git cat-file -p \u0026lt;SHA hash\u0026gt; Edit the file: underneath your bio, add 1 additional line about how you love coding \u0026amp; then save the file to your database. List the contents of your objects folder - you should see two items. You now have two versions of your file. Turn to your neighbor, and discuss what you think you will see. Inspect the resulting Object  Exercise 2: Making Tree Objects  Add the file you created to the Index using plumbing: git update-index --add \u0026lt;path to file\u0026gt; ls your .git folder - you should now see an index appear examine the contents of your index file, aka \u0026ldquo;staging\u0026rdquo;: git ls-files --stage run a porcelain git status: git status write your tree: git write-tree list all objects in your database: find .git/objects -type f  Optional Exercise 2 Challenge: Trees in Trees\n try making a subdirectory in your repo. Inside, create a new file with content add the file to your index(aka staging area). write your tree and inspect the resulting tree object. You\u0026rsquo;ll see a reference to another tree   Note: if you are getting a message like: \u0026ldquo;fatal: This operation must be run in a work tree\u0026rdquo; it means that you are trying ot run a command that requires you to be inside the working directory, but you have cd\u0026rsquo;ed into the .git folder. To fix this, cd back to your root directory and try running the command from there instead\n Exercise 3: Commit Objects  Create a commit object using the recently created tree: echo 'your commit message here' | git commit-tree \u0026lt;tree hash\u0026gt; take a look at your git database: find .git/object -type f inspect the commit object: git cat-file -p \u0026lt;SHA hash\u0026gt; add a new file add a new file to the index: git update-index - -add \u0026lt;path to file\u0026gt; update your index and write your tree: git write-tree create another commit object, chaining it to the one previous: echo 'your commit message here' | git commit-tree \u0026lt;tree hash\u0026gt; -p \u0026lt;previous commit hash\u0026gt; inspect this new commit object: git log --stat[commit hash]  Optional Exercise 3 Challenge Discussion\nHave you ever done a git commit --amend to edit your commit message?\nIf so, discuss with a neighbor: what do you think will happen when you amend a commit? Will a new commit object be created, or will we have simply edited the pre-existing commit object for the commit in question. Why?\nExercise 4: Git References  List everything in your git references folder. You\u0026rsquo;ll see nothing because you don\u0026rsquo;t have any branches: ls .git/refs/heads use a plumbing command to manually create a branch: git update-ref refs/heads/master \u0026lt;commit hash\u0026gt; list your refs folder again to see the result cat your master branch: cat .git/refs/heads/\u0026lt;branch name\u0026gt; run a porcelain command to create \u0026amp; checkout to a new branch : git checkout -b list your .git/refs/heads folder again now cat the new branch to inspect the commit hash: cat .git/refs/heads/\u0026lt;branch name\u0026gt; now edit some files in your new branch. Add and commit the changes using porcelain like you would normally. cat the branch again.  Optional Exercise 4 Challenge\n Remember how git keeps track of what branch you\u0026rsquo;re on via. git/HEAD? Cat the file to look at it. What if you change this file to point to another branch? Discuss with your neighbor, then implement/explore. Run a git status and a git log. What would happen if you just go in and change a branch file in .git/refs/heads so that the commit is different? Discuss with a neighbor and then implement/explore/break stuff/ have fun messing around.  Additional Resources  Gits \u0026ldquo;Guts\u0026rdquo; Repo  "
},
{
	"uri": "/web-essentials/webmastery-foundations/html-intro-labs/",
	"title": "HTML Intro Labs",
	"tags": [],
	"description": "",
	"content": "Create a Hello World Page  Create a new directory Create a basic html file Add a \u0026ldquo;Hello World\u0026rdquo; Header Open the html document in your browser Change \u0026ldquo;Hello World\u0026rdquo; to say \u0026ldquo;Hello World from your name\u0026rdquo;     Go to Common HTML Elements Lessons    Build a Simple Web Page Use HTML and a browser to recreate the webpage shown below. Use the following URL in an HTML img tag: http://www.fillmurray.com/200/200\nThe background color of the web page can be set using the following CSS inline style on the body tag:\n\u0026lt;body bgcolor=\u0026#34;#CCC\u0026#34;\u0026gt;\u0026lt;/body\u0026gt;    Go to Creating a table in HTML Lesson    HTML Lab Create an HTML page on a topic of your choosing (weekend plans, favorite hobbies, future vacation ideas, recipes, favorite movies, etc.) and include the steps below.\n  Create an empty directory and create your HTML file. (BONUS - create a CSS file and link it).\n  Include doctype and the other 3 basic section tags that a proper HTML page must have.\n  Include a title\n  Include the following tags:\n p 3 different h tags at least 1 div or section or article at least 1 span    Make a piece of text bold\n  Make a piece of text italicized\n  Include one unordered list with at least 3 items\n  Include one ordered list with at least 3 items\n  Include an image with an alt attribute\n  When you click on the image it should redirect to some other URL\n  Percipio Lab for extra practice if needed.  Percipio HTML 5 lab  Precipio Reference  HTML 5: Tag and Attribute  ** The lab will have you use a windows emulator but there are very good instructions.\nAdditional Resources  w3schools HTML Tutorial HTML element reference HTML Elements by Category HTML5 element reference Tim Berners-Lee Evolution of the Web - Great Link Semantic HTML More info on HTML5  "
},
{
	"uri": "/javascript/nodejs/getting-started/node-core-modules/streams/",
	"title": "Streams",
	"tags": [],
	"description": "",
	"content": "Working with streams An option when working with the larger files or http request/response is to use Streams. In essence, a Node Stream is a collection of data that becomes available over time.\nStreams are actually used in the background of node for much of its functionality. Creating an HTTP server with node uses streams.\nconst http = require(\u0026#39;http\u0026#39;); const server = httpCreateServer((req, res) =\u0026gt; { // res here is a Readable Stream  // req here is a Writable Stream }) As an example, we can use Read and Write streams while interacting with the file system.\nconst fs = require(\u0026#34;fs\u0026#34;); const wStream = fs.createWriteStream(\u0026#34;./file.txt\u0026#34;); const rStream = fs.createReadStream(\u0026#34;./file.txt\u0026#34;); const readIt = () =\u0026gt; { rStream.on(\u0026#34;readable\u0026#34;, () =\u0026gt; { console.log(rStream.read().toString()); }); rStream.on(\u0026#34;end\u0026#34;, () =\u0026gt; { console.log(\u0026#34;finished reading file\u0026#34;); }); }; wStream.on(\u0026#34;open\u0026#34;, fd =\u0026gt; { wStream.write(\u0026#34;first line\\n\u0026#34;); wStream.write(\u0026#34;second line\\n\u0026#34;); wStream.write(\u0026#34;third line\\n\u0026#34;); wStream.write(\u0026#34;fourth line\\n\u0026#34;); wStream.end(); }); wStream.on(\u0026#34;close\u0026#34;, readIt); console.log(\u0026#34;writing data\\n\u0026#34;); As you can see, this behavior is non-blocking allowing Node to work asynchronously with each stream of data. We then pass our readIt function as a callback to the wStream close event. This means we can use Streams when we know our data will be in large asynchronous chunks.\nWatch Another nifty feature is fs.watch. By using watch, we can listen for changes to a specific file and print the event and filename to the console.\nconst fs = require(\u0026#34;fs\u0026#34;); const wStream = fs.createWriteStream(\u0026#34;./file.txt\u0026#34;); const rStream = fs.createReadStream(\u0026#34;./file.txt\u0026#34;); const fileTest = \u0026#34;./file.txt\u0026#34;; const readIt = () =\u0026gt; { rStream.on(\u0026#34;readable\u0026#34;, () =\u0026gt; { console.log(rStream.read().toString()); }); rStream.on(\u0026#34;end\u0026#34;, () =\u0026gt; { console.log(\u0026#34;finished reading file\u0026#34;); }); }; wStream.on(\u0026#34;open\u0026#34;, fd =\u0026gt; { wStream.write(\u0026#34;first line\\n\u0026#34;); wStream.write(\u0026#34;second second line\\n\u0026#34;); wStream.write(\u0026#34;third line\\n\u0026#34;); wStream.write(\u0026#34;fourth line\\n\u0026#34;); wStream.end(); }); wStream.on(\u0026#34;close\u0026#34;, readIt); console.log(\u0026#34;writing data\\n\u0026#34;); fs.watch(fileTest, (eventType, file) =\u0026gt; console.log(`This is the watch report ${eventType}to ${file}`), );  Watch actually checks for changes to a file at increments of time (default is 5 seconds) if you need to monitor a file or keep a log of changes watch can allow you to automate your processes.\n "
},
{
	"uri": "/javascript/nodejs/getting-started/command-line-tutorial/",
	"title": "CLI Tutorial",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  The ability to follow online tutorials and documentation is essential to the modern software engineer. This exercise will introduce you to this skill with a bite-size tutorial.  Skills  Read documentation for a third-party API Integrate a third-party API into an app  Instructions For this assignment you will be working independently to complete an outside tutorial on creating a command line weather app. Here is a great one you can use. You can certainly find another to use if you like.\n Follow the tutorial to build the app/cli Take your app/cli past the tutorial Push to GitHub In your repo create a readme that:  Gives instructions how to run or interface with your app/cli Includes any installation requirements Describes how you went past the instructions from the tutorial    "
},
{
	"uri": "/javascript/nodejs/getting-started/command-line-project/",
	"title": "CLI Project Ideas",
	"tags": [],
	"description": "",
	"content": "Project Guidelines You will build a command line application using Node. Below you will find a list of project ideas and requirements for each app.\nUpon selecting a project, create a project on pivotal, (alternatively you can use GitHub issues). Log the tasks/stories/issues that you are aiming to solve. Afterwards, schedule 5 minutes with an instructor discuss your project and plan to gain approval.\nAdditional app ideas are welcome as well. If you have an idea for a different application, please speak with an instructor.\nAll applications have the following requirements:\n  Work on a branch off master in git\n  Make use of I/O\n  Have user interface in command line\n  Read and Write Files\n  Write two tests and write code to pass\n  Write a commit when the test is written\n  Write a commit when the test passes\n  Pushed to GitHub\n  Contain a readme explaining how to use the application\n  A backlog of tasks/stories\n  App Ideas The following are a list of ideas for your CLI project. You may create them with your own features, but each idea has a few feature requirements listed with it.\nInventory Management App Write an inventory management application that allows the user to view a product catalogue.\nFeature Ideas:\n Add/Remove items from inventory Modify quantity List products in a category See individual items in detail  Blackjack Create a game of blackjack that follows the basic rules\nFeature Ideas:\n Keep track of wins/losses Allow betting with points Saving/Continuing a game Allow app to continue until user is done  Mad Libs Create a Mad Libs game!\nFeature Ideas:\n Random lib selection Allow user to select lib Allow user to save libs Allow user to add libs Take input then display the final results in a single run of the application  Wordle Game Create a Wordle game that can be run from the command line.\nFeature Ideas:\n Randomly choose a word for the user to guess Prompt the user for a guess Determine if the guess is correct Provide feedback to the user regarding how close their guess is to the answer. Let the user guess up to 6 times. If the user doesn\u0026rsquo;t get the answer, provide the answer after 6 failed guesses.  Bonus Feature:\n See if you can write a solver and let the user choose the option \u0026ldquo;solve it for me\u0026rdquo;.  Banking Application Create a basic \u0026ldquo;banking\u0026rdquo; application\nFeature Ideas:\n Add accounts Check balance Deposit funds Withdraw funds Send funds to Erik Transfer between accounts Select accounts  Sample Apps Below you\u0026rsquo;ll find a list of sample command line applications, feel free to experiment with them to get insight and direction for how you want your application to function.\n taskbook carbon now cli football cli quote cli googler cash-cli autojump emoj empty-trash speed-test  Project Submission  Push to GitHub. Create a readme that:  Includes a brief description of your application Gives instructions on how to run and interface with your application   Add a link to the repo in your Schoology account Under the correct tech check assignment.  "
},
{
	"uri": "/javascript/nodejs/getting-started/node-core-modules/http-module/",
	"title": "The HTTP Module",
	"tags": [],
	"description": "",
	"content": "HTTP Server Node comes with a module specific to creating an http server. The basic server consists of a server object created by doing the following.\nconst http = require(\u0026#39;http\u0026#39;); // require the http module  // The server object: http.createServer((req, res) =\u0026gt; { // use the `createServer` method that comes with the module  //write response  res.write(\u0026#39;Hello World\u0026#39;); // so something with the server  res.write(req.url); res.end(); }) .listen(5000, () =\u0026gt; console.log(\u0026#39;Server running\u0026#39;)); // this is not part of the object but a listener method to tell us the server is running.  The server object gets a function that takes in two arguments req (or request) and res (or response).\nThe request builds an internal ClientRequest object that has several methods for connecting and monitoring requests.\nThe response comes as a ServerResponse object that also has several methods for identifying the type of response and ways to write a response.\nSetting up the server With Node standing up a web server is a fairly straight forward task. In a file called server.js we can create a node server.\nconst http = require(\u0026#39;http\u0026#39;) //1  const handleRequest = (req, res) =\u0026gt; { //2  console.log(`INCOMING REQUEST ${req.method}${req.url}`); res.writeHead(200, { //3  \u0026#39;Content-Type\u0026#39; : \u0026#39;application/json\u0026#39;, //4  }) res.end(JSON.stringify({\u0026#34;message\u0026#34;: \u0026#34;hello world!\u0026#34;})) //5 } let server = http.createServer(handleRequest) //6 server.listen(3000) //7  require the http module write a function that takes request and response arguments supply a response header with the status code of 200 supply a Content-Type Header send a response create the server by setting the create server object equal to a variable tell the server to listen at a specific port  We can start our server in the terminal by typing node server.js and then going to your browser and typing localhost:3000.\nHere is another version of the same code returning html.\nserver.js\nconst http = require(\u0026#39;http\u0026#39;) const handleRequest = (req, res) =\u0026gt; { console.log(`INCOMING REQUEST ${req.method}${req.url}`); res.writeHead(200, { \u0026#39;Content-Type\u0026#39; : \u0026#39;text/html\u0026#39;, }) res.end( `\u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt; Hello World! \u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;` ) } const server = http.createServer(handleRequest) server.listen(3000) Labs HTTP Module Labs\nAdditional Resources  For more information and examples of methods available within the http module go here.  "
},
{
	"uri": "/javascript/nodejs/getting-started/node-core-modules/http-module-labs/",
	"title": "Labs for HTTP Module",
	"tags": [],
	"description": "",
	"content": "5.1. Lab 3 - Working with a server  Using the previous Car example Create a file named server.js In server.js:  Create at least 5 new cars (using the constructor function) Store those cars in an array Create a server when a user queries at a certain endpoint, iterate over the cars and use the req.url to only match the appropriate criteria. In this case only use car make for the comparison. For example: http://localhost:3000/nissan should only return cars made by nissan. send the array of cars as your response.    hint: you\u0026rsquo;ll need to strip the / off your request using req.url.replace()\n6. Lab 4 - Learn you Node  Complete the learnyounode module from nodeschool This should already be installed on your machine.  simply create a directory named learnyounode and cd into it. once in the directory, you can run learnyounode to start the challenges if you have any trouble, check out the GitHub repo    "
},
{
	"uri": "/javascript/nodejs/testing/di-and-mocks/",
	"title": "Dependency Injection &amp; Mocks",
	"tags": [],
	"description": "",
	"content": "Dependency Injection Dependency Injection (DI) is a pattern in software development that says you should separate dependencies form the code that uses them. Rather than configuring/initializing them inside the code that uses them, this pattern says you should do this externally and pass them as parameters to the the function or object using them.\nLet\u0026rsquo;s take this example in javascript\nconst db = require(\u0026#34;cool-sql-package\u0026#34;) class ShoppingCart { constructor(name, custId){ this.name = name this.custId = custId } getCustomerTotal(){ let total =0 const qrystr = \u0026#34;select price from customer_transactions where customer_id=? and transactionId=?\u0026#34; const results = db.Query(qrystr, this.custID) // `db.Query` is a dependency of `ShoppingCart`  total = results.map(v =\u0026gt;{ return v.price }).reduce((acc, cur)=\u0026gt;{ return acc + cur }) return total } } How would we apply DI to this?\nclass ShoppingCart { constructor(name, custId, db){ //2.  this.name = name this.custId = custId this.db = db //3.  } getCustomerTotal(transactionId){ let total =0 const qrystr = \u0026#34;select price from customer_transactions where customer_id=? and transactionId=?\u0026#34; const results = this.db.Query(qrystr, this.custID) // 4.  total = results.map(v =\u0026gt;{ return v.price }).reduce((acc, cur)=\u0026gt;{ return acc + cur }) return total } }  Removed the import Added an parameter called db to the constructor Assigned db to the object variable db Added this to the db call to access the db that was passed in.  We could probably refactor this a step further and require that qrystr be passed in as well.\nApplying the DI pattern to you code gives us several benefits:\n Code separation Code that is easier to understand because we advertise the dependencies Code that is easier to test Enables you to code toward interfaces.  Mocking Mocking is a testing technique where you overwrite the behavior of a dependence so that you can focus on the unit test. When we unit test, we do not want the external call to really happen (such as where db is exposed as a dependency in the above example), because that is beyond the scope of an a unit test.\nMost languages have a way to create mocks, but for the most part, you can create them yourself. The tools tend to do a lot of the tedious work for you. Languages that allow interfaces also make this a lot easier by not strictly calling for an exact implementation.\nHow can we apply this to the example above? Again, we want to apply our own behavior to the db dependency, but we do not want to have to change our code, or the way that it utilized the dependency.\nCreating a Mock\nclass MockDB { Query(qs,...params){ /* Add assertions and/or other code that can test for expectations here if needed and possibly return staged results. */ } } Here we\u0026rsquo;ve defined a mock class that mimics the methods that we know our external db component has. The real implementation may have more methods associated with it, but we know our code will only call the Query function. In javascript this works fine. In a statically type language be aware you may need to define other functions as well. That is where the mocking tools tend to become handy.\nWithout getting to deep into detail about specific test frameworks let\u0026rsquo;s look at how we could instantiate this mock in order to pass it to our production code for purposes of testing.\nUsing a Mock\nconst mockdb = new MockDataBase() // 1. const sc = ShoppingCart(\u0026#34;Bob\u0026#34;,1,mockdb) // 2.  const result = sc.getCustomerTotal(1) // 3.  // Assert he results are what you expected based on the  Create and instance of \u0026ldquo;MockDataBase\u0026rdquo;, which gives us an object with the Query method. Create an instance of ShoppingCart and passing our mock as an argument in place of a real implementation. Invoke the function we want to test.  From there, depending on how your language asserts results, we could take determine if everything ran as expected inside of that function.\nOther Testing Terms There are a few other testing terms that you may come across, and are similar to mocks.\n Dummy objects are passed around but never actually used. Usually they are just used to fill parameter lists. Fake objects actually have working implementations, but usually take some shortcut which makes them not suitable for production (an in memory database is a good example). Stubs provide canned answers to calls made during the test, usually not responding at all to anything outside what\u0026rsquo;s programmed in for the test. Spies are stubs that also record some information based on how they were called. One form of this might be an email service that records how many messages it was sent.  Source, and additional resource for the differences between mocks, stubs, and spies\n"
},
{
	"uri": "/react/pillars/testing/react-testing-library/rtl-getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "Getting Started If you are using the latest version of create-react-app and its react-scripts dependency then jest and react-testing-library are already setup for you.\nIf you need to add react-testing-library to an existing project, it\u0026rsquo;s as easy as:\nnpm install --save-dev @testing-library/react # for npm users yarn add -D @testing-library/react # for yarn users You may also be interested in installing @testing-library/jest-dom so you can use the custom jest matchers:\nnpm install --save-dev @testing-library/jest-dom # for npm users yarn add -D @testing-library/jest-dom # for yarn users Scripts for Running Tests The package.json file should have a script for easily running your tests. Below we have 3 different ways to run the tests:\npackage.json:\nscripts { \u0026#34;test\u0026#34;: \u0026#34;react-scripts test\u0026#34;, \u0026#34;ci-test\u0026#34;: \u0026#34;CI=true react-scripts test --verbose\u0026#34;, \u0026#34;coverage\u0026#34;: \u0026#34;CI=true react-scripts test --verbose --coverage\u0026#34; } Here is what each of these scripts will do:\n the test script will run jest in watch mode. the ci-test script will run jest and print an ASCII report (useful for both CI/CD pipeline builds). the coverage script will run all tests and generate a code coverage ASCII report.  Adding Additional Dependencies You may find the following dependencies helpful when testing React components and hooks with RTL:\nyarn add -D @testing-library/jest-dom # or npm install -D @testing-library/jest-dom yarn add -D @testing-library/react-hooks # or npm install -D @testing-library/react-hooks yarn add -D @testing-library/user-event # or npm install -D @testing-library/user-event yarn add -D react-test-renderer # or npm install -D react-test-renderer Best Practices As we dive into using jest and react-testing-library we will be applying some best practices.\nProject Structure Keep test code close to the code it tests. This will greatly improve the organization of your code as your project gets BIG! For example:\n├── src/ │ ├── components/ │ │ ├── app/ │ │ │ ├── App.jsx │ │ │ ├── App.module.scss │ │ │ └── App.test.js │ │ ├── home/ │ │ │ ├── Home.jsx │ │ │ ├── Home.module.scss │ │ │ └── Home.test.js │ │ ├── navbar/ │ │ │ ├── Navbar.jsx │ │ │ ├── Navbar.module.scss │ │ │ └── Navbar.test.js Do Bottom-Up Testing  Test the simpler presentational components before testing the container and stateful components. This will make it easier to know where to test various features and avoid duplicating tests between presentational components and their containers.  Keep things organized Write helper functions in your tests and externalize mocking and test data when appropriate.\nIntroducing our App Under Test - The Product Browser App For the rest of this course we will be adding tests to a Product Browser app. The source code can be found at React Product Browser app.\nThe Product Browser app is a React web client with a simple RESTful web server.\nCloning The Repository Let\u0026rsquo;s clone that repository and then walk through the code that we will be testing.\ngit clone https://github.com/one-thd/om_labs_React-Product-Browser-With-Routes.git cd om_labs_React-Product-Browser-With-Routes cd server yarn # or npm install cd ./client yarn # or npm install cd .. Running the App Now let\u0026rsquo;s run the entire app and see what it does.\nYou will need 2 terminal windows or tabs: one to run the RESTful server and another to run the React client app.\nRunning the RESTful Server:\ncd server yarn start Running the React Client:\ncd client yarn start Now you can open your browser to http://localhost:3000 to see the app. Try browsing the different departments, adding products to the cart, and viewing and updating the cart.\nScreen Shot Running the Tests From the shell, try running the following scripts from the client folder:\nyarn test # press q to quit yarn ci-test yarn coverage Component Diagram Important Files Let\u0026rsquo;s take a look at the following files to get more familiar with how this application is structured.\nserver/package.json  Contains a dependency on json-server, a simple RESTful API server that\u0026rsquo;s is handy for prototyping RESTful client applications. We will not be hitting this server in our test code as we will mock those out, but the server is useful for demonstrating the React Client app. The start script starts the json-server on port 4000 and uses db.json for persisting data. You can read more about json-server at json-server. Once the server is running, you can see what data it returns by pointing your browser to http://localhost:4000/products.  server/db.orig.json and server/db.json  By default json-server uses a file called db.json. This file will get modified as we do CRUD operations against the RESTful API that json-server provides us. To reset back to a known state, we use db.orig.json as the starting point for this file and copy it to db.json whenever we start the json-server.  Feel free to open either file in your text editor and note that it\u0026rsquo;s just JSON data structured for our React client app.\nAnother nice feature of json-server is that it will create unique id values for us whenever we POST to any of the server RESTful endpoints.\nserver/.gitignore node_modules db.json client/package.json The important sections of this file are:\n \u0026quot;proxy\u0026quot;: \u0026quot;http://localhost:4000\u0026quot;, // allows our React axios calls to be proxied to our json-server the various scripts that we have already discussed.  client/src/index.js  The entry point for our React app. Note that the path for the App component has been moved into a folder called src/components/app.  client/src/app/App.jsx This is where things get interesting. Our main App component is responsible for defining and rendering all routes and managing state (via two custom hooks: useProducts and useCart, which we will come back to later).\nThere are 4 routes:\n Home Product Lists per Department - a set of dynamic routes that for our data set resolve to /departments/1 for Hardware, /departments/2 for Paint, and /departments/3 for Plumbing. Cart - our shopping cart New Product Form - a form for adding new products  Keeping Things Organized  Observe that we have App.module.scss and App.test.js in the same folder as App.jsx. This is a best practice as we can keep related code together for easier readability, maintenance and refactoring. You will see this file structure for all of our React components.  client/src/components/navbar/Navbar.jsx  The Navbar contains NavLinks for navigating to different react-router routes. It also contains a count of the number of items in the shopping cart.  Other Interesting Files   client/src/components/home/Home.jsx\n Renders a welcome message and a Link button to the New Product Form route.    client/src/components/product/Product.jsx\n Renders a single product.    client/src/components/home/Home.jsx\n Renders a welcome message and a Link button to the New Product Form route.    client/src/components/product/Product.jsx\n Renders a single product.    client/src/components/product/ProductList.jsx\n Renders a list of products.    client/src/components/product-form/ProductForm.jsx\n Renders a form of controlled inputs.    client/src/components/cart/CartItem.jsx\n Renders an item in the cart with callbacks for updating / removing an item.    client/src/components/cart/Cart.jsx\n Renders the cart and the cart totals.    client/src/components/numeric-input/NumericInput.jsx\n Used by the CartItem to update the quantity in the cart.    client/src/utils/format-price.js\n Used by Product, Cart, and CartItem to format a price.    client/src/utils/handle-request-error.js\n Generic error handler for axios calls.    client/src/hooks/useProducts.js\n A custom hook that makes all axios calls for managing department and product data    client/src/hooks/useCart.js\n A custom hook that makes all axios calls for managing the cart data    client/src/__mocks__/axios.js\n Simple mock config for axios calls    client/src/mock-utils/dataSet1.js\n Defines test data and a method for configuring the mock axios calls    client/src/mock-utils/configureMockAxios.js\n Provides a function for configuring mock axios calls with the specified dataSet    client/src/setupTests.js\n Contains common imports and configuration for all tests    Summary  Congratulations for looking at all that code. Don\u0026rsquo;t worry if you don\u0026rsquo;t understand it all. We will continue to discuss the code under test as we write automated tests for each function, React component, and React custom hook.  "
},
{
	"uri": "/software-eng-essentials/db-sql/intro-to-rdbms/",
	"title": "Intro to RDMS",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Describe why we use Databases Describe the following terms:  RDBMS Database   Define CRUD Explain DB Transactions, commit, and rollback Define the ACID properties of transactions  Why Do We Use Databases?   Memory vs. Persistent Storage\n CPU / Registers / Cache → Memory → Hard Drive → Server / Cloud    Files vs Databases\n Databases are optimized for speed and expressiveness Databases provide for ACID properties    Databases are fault tolerant\n Databases are designed with special features that prevent data loss or corruption    Scalability\n Databases are designed to maximize throughput and parallel access    Database Concepts Types of Databases  Relational - stores data in a set of tables where each table has rows and columns  Examples: Oracle, MS SQL Server, MySQL, PostgreSQL, SQLite   Object-oriented NoSQL  Document-based Store - stores documents made up of tagged elements  Examples: MongoDB, CouchDB   Column-based - Each storage block contains data from only one column  Examples: HBase, Cassandra   Key-Value Store - stores data in a Big Hash Table of keys \u0026amp; values  Examples: Riak, Amazon S3 (Dynamo)   Graph-based - Uses edges and nodes to represent and store data  Example: Neo4J      Other Categories for Databases  Persistent vs. In-Memory vs. In-Network ACID Compliant Clustered  What Makes A Good Database  Reliable Storage of Data High Performance and Scalable  Lots of data Lots of transactions   ACID Transactions Fault-tolerant / Highly Available A Very Good Query Language  RDBMS A Relational Database Management System (RDBMS) consists of:\n a set of databases - finances, nba_stats, favorite_movies a set of database processes that manage the databases and provide services for client connections  Client / Server A RDBMS is a server that you can connect to via:\n a command line client (for DBAs, developers, QA) a GUI client (for DBAs, developers, QA) an application  CRUD CRUD is an acronym for describing the basic operations for managing database records:\n Create \u0026ndash; Creates a new record. Read \u0026ndash; Reads an existing record (or records). Update \u0026ndash; Updates an existing record (or records). Delete \u0026ndash; Deletes an existing record (or records), and may cascade on to delete all related records.  Relational Databases  Data stored in tables that contain rows and columns Stores relationships between data across tables  ACID Most relational databases support transactions that can be committed or rolled back. These transactions have ACID properties to ensure that the data is always in a good state.\nFurther explanation link: here\nThe following talks about how ATOMic properties apply to a transfer of funds between two bank accounts\nAtomic This property requires that each transaction be \u0026ldquo;all or nothing\u0026rdquo;: if one part of the transaction fails, the entire transaction fails, and the database state is left unchanged.\nExample: one account isn\u0026rsquo;t debited without the other account being credited.\nConsistent Guarantees that each transaction will bring the database from one valid state to another valid state. The resultant data must abide by the rules of the database.\nExample: transactions that would take an account below zero must be preemptively aborted.\nIsolated Ensures that the concurrent execution of transactions results in a system state that would be obtained if transactions were executed serially\nExample: one after the other\nDurable Guarantees that all confirmed transactions are recorded and thus reproducible in the event of a system failure (power loss, crash, or other error).\nData Types Generic:\n VARCHAR BOOLEAN INTEGER NUMBER MONEY DATE  For more information see PostgreSQL Data Types.\nPrimary Keys  Every Table defines a Primary Key (PK).\nPKs tend to follow these rules:\n PKs are stored in a column that contains a unique identifier for each row  No two rows can have the same PK value   Primary keys should not have any business or real world meaning  Data that has business meaning can change A person\u0026rsquo;s name can change An email address can change   Primary keys are generated and sequential or pseudo-random The Database System can generate the PK values for you when you insert new rows  Foreign Keys  A foreign key (FK) is simply a column value in one table that contains the PK value from another table, meaning FKs relate one row to another row.\nThe column name should describe the relationship.\nGiven a Movies table, each movie row would contain a title, genre, yearReleased, and perhaps a FK to the person that directed the movie.\nExample Here is an example of some tables with primary and foreign key values. See if you can determine who ordered what.\nSuperhero Supplies Database Tables Summary  Relational Database Systems provide a robust and high-performance solution for managing large volumes of structured data. Relational databases provide ACID transactions for ensuring that data is always in a verified state. Data is stored in tables that consist of rows and columns. Each Column has a data type. Each table has a Primary Key column used to store a unique identifier for each row in the table. A DB schema consists of the table definitions and other DB objects that define the structure of the database.  "
},
{
	"uri": "/java/foundations/",
	"title": "Java Foundations",
	"tags": [],
	"description": "",
	"content": "Welcome to Java Foundations! "
},
{
	"uri": "/javascript/nodejs/advanced/express-and-bookshelf/knex-movies/",
	"title": "Knex Movies Guided Lab",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Setting up Express and Knex  Skills  Building an applications with Express that connects to a Postgres Database using Knex Creating migration scripts Creating seeds files Calling Knex functions from route handlers  Step 0 - Getting Started In this lesson, we are going to build a sample application using:\n Express Knex.JS PostgreSQL  The starter code used for this application can be found here.\nTo get up and running:\n clone the repo $ git clone https://github.com/one-thd/om_labs_express-movies-knex.git install dependencies with npm start the server with npm start test it out by running the test-root-routes.sh script:  ./test-root-routes.sh Testing Health Check Route HTTP/1.1 200 OK Connection: keep-alive Content-Length: 39 Content-Type: application/json; charset=utf-8 Date: Fri, 11 Mar 2022 18:58:27 GMT ETag: W/\u0026#34;27-WAACcsMEekNPv58h4/ad98f7Vuk\u0026#34; Keep-Alive: timeout=5 X-Powered-By: Express { \u0026#34;message\u0026#34;: \u0026#34;Welcome to the Movies API\u0026#34; } Testing Error Handling / 404 Route HTTP/1.1 404 Not Found Connection: keep-alive Content-Length: 23 Content-Type: application/json; charset=utf-8 Date: Fri, 11 Mar 2022 18:58:28 GMT ETag: W/\u0026#34;17-SuRA/yvUWUo8rK6x7dKURLeBo+0\u0026#34; Keep-Alive: timeout=5 X-Powered-By: Express { \u0026#34;message\u0026#34;: \u0026#34;Not Found\u0026#34; }  NOTE: This application includes 3 initial routes: /api, /api/movies and /api/actors. Throughout the lesson, additional routes will be added.\n Step 1 - Setting Up Knex and PostgreSQL To add knex and postgresql to an Express application, first install the dependencies:\nnpm install knex npm install pg Next lets update our package.json with some helpful scripts:\npackage.json:\n\u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;NODE_ENV=production node server.js\u0026#34;, \u0026#34;dev\u0026#34;: \u0026#34;NODE_ENV=development PORT=3000 nodemon server.js\u0026#34;, \u0026#34;db:create\u0026#34;: \u0026#34;createdb knex_movies_dev\u0026#34;, \u0026#34;db:drop\u0026#34;: \u0026#34;dropdb knex_movies_dev\u0026#34;, \u0026#34;db:reset\u0026#34;: \u0026#34;npm run db:drop \u0026amp;\u0026amp; npm run db:create\u0026#34;, \u0026#34;db:migrate\u0026#34;: \u0026#34;knex migrate:latest --env development\u0026#34;, \u0026#34;db:seed\u0026#34;: \u0026#34;knex seed:run --env development\u0026#34; }, We will be using these scripts in the following steps to create our database, create tables, and seed the database with data.\nStep 2 - Creating the Database For this lab we will create a simple database with no custom user/role. Simply run the following command to create the database:\nnpm run db:create Then test it out with:\npsql -d knex_movies_dev psql (14.2) Type \u0026#34;help\u0026#34; for help. knex_movies_dev=# \\q Step 3 - Creating the Knex Configuration File Knex uses a configuration file to connect to the database. The name for this file is usually knexfile.js.\nCreate this file with touch knexfile.js and then put the following contents inside the file:\nconst knexConfig = { development: { client: \u0026#39;pg\u0026#39;, connection: { host: \u0026#39;127.0.0.1\u0026#39;, // user: \u0026#34;your_database_user\u0026#34;,  // password: \u0026#34;your_database_password\u0026#34;,  database: \u0026#39;knex_movies_dev\u0026#39;, }, pool: { min: 2, max: 10, }, migrations: { tableName: \u0026#39;knex_migrations\u0026#39;, }, seeds: { directory: \u0026#39;./seeds/dev\u0026#39;, }, }, } export default knexConfig Observations:\n The above configuration sets up a single database for development. You can setup other databases for environments such as testingandproduction`. The client defines which driver to use to connect to the database. Here we use the pg driver for connecting to a PostgreSQL database. For this local database we will not need a user and password, but it depends on how you want to setup your database. The pool setting defines the size for the DB connection pool. The migrations and seeds settings configure how the migrations and seeds will work. Review the knexfile.js Environment Configuration info for more information.  Step 4 - Database Migrations Now that we have created our database and we have a knex configuration file, we can create our migration scripts.\nnpx knex migrate:make create_movies The knex migrate:make command will create a migration script in the migrations folder. The name of the script is prefixed with a datetime stamp which knex uses to determine the correct order to run all of the migration scripts (oldest to newest).\nOpen the newly created migration script and edit it to have the following content:\nexport async function up(knex) { const exists = await knex.schema.hasTable(\u0026#39;movies\u0026#39;) if (!exists) { return knex.schema.createTable(\u0026#39;movies\u0026#39;, table =\u0026gt; { table.increments(\u0026#39;id\u0026#39;).primary() // adds an auto incrementing PK column  table.string(\u0026#39;title\u0026#39;).notNullable() table.string(\u0026#39;genre\u0026#39;) table.date(\u0026#39;release_date\u0026#39;) table.timestamps(true, true) // adds created_at and updated_at  }) } } export function down(knex) { return knex.schema.dropTableIfExists(\u0026#39;movies\u0026#39;) } Take some time to read this code and understand what each line is doing.\nRunning the Migration Scripts To run the migration scripts, simply use npm run db:migrate. Try this now to see if the above script runs successfully.\nYou can also inspect your DB tables with psql:\npsql -d knex_movies_dev psql (14.2) Type \u0026#34;help\u0026#34; for help. knex_movies_dev=# \\dt List of relations Schema | Name | Type | Owner --------+----------------------+-------+--------- public | knex_migrations | table | mah3093 public | knex_migrations_lock | table | mah3093 public | movies | table | mah3093 (3 rows) knex_movies_dev=# \\d movies Table \u0026#34;public.movies\u0026#34; Column | Type | Collation | Nullable | Default --------------+--------------------------+-----------+----------+------------------------------------ id | integer | | not null | nextval(\u0026#39;movies_id_seq\u0026#39;::regclass) title | character varying(255) | | not null | genre | character varying(255) | | | release_date | date | | | created_at | timestamp with time zone | | not null | CURRENT_TIMESTAMP updated_at | timestamp with time zone | | not null | CURRENT_TIMESTAMP Indexes: \u0026#34;movies_pkey\u0026#34; PRIMARY KEY, btree (id) knex_movies_dev=# \\q  NOTE: knex has created the knex_migrations and knex_migrations_lock tables to track which migration scripts have been applied to this database.\n Lab - Actors Migration  Create a migration for the actors table using the knex migration CLI). Your actors migration should include the following columns:  an id - the primary key that increments automatically a first_name string property that is non-nullable a last_name string property that is non-nullable timestamps   Once complete, update the database schema by running your migrations: npm run db:migrate  Solution   Click here to see the solution   export async function up(knex) { const exists = await knex.schema.hasTable('actors') if (!exists) { return knex.schema.createTable('actors', table = { table.increments('id').primary() table.string('first_name').notNullable() table.string('last_name').notNullable() table.timestamps(true, true) }) } } export function down(knex) { return knex.schema.dropTable('actors') }      Step 5 - Seeding the Database In this step we will create a data.js file containing several movies and actors. Then we will create a seeds script that knex can execute to insert the data into the database.\nFirst create the data.js file in a folder named seeds:\nmkdir seeds touch seeds/data.js Next edit data.js and insert the following code:\nexport const movies = { Raiders: { id: 1, title: \u0026#39;Raiders of the Lost Ark\u0026#39;, genre: \u0026#39;action\u0026#39;, release_date: \u0026#39;1981-06-01\u0026#39;, }, ET: { id: 2, title: \u0026#39;ET\u0026#39;, genre: \u0026#39;sci-fi\u0026#39;, release_date: \u0026#39;1982-06-11\u0026#39;, }, Schindlers: { id: 3, title: \u0026#34;Schindler\u0026#39;s List\u0026#34;, genre: \u0026#39;drama\u0026#39;, release_date: \u0026#39;1993-12-15\u0026#39;, }, StarWars: { id: 4, title: \u0026#39;Star Wars\u0026#39;, genre: \u0026#39;sci-fi\u0026#39;, release_date: \u0026#39;1977-05-25\u0026#39;, }, AirForceOne: { id: 5, title: \u0026#39;Air Force One\u0026#39;, genre: \u0026#39;action\u0026#39;, release_date: \u0026#39;1997-07-25\u0026#39;, }, IndianaJones: { id: 6, title: \u0026#39;Indiana Jones\u0026#39;, genre: \u0026#39;action\u0026#39;, release_date: \u0026#39;1997-07-25\u0026#39;, }, } export const actors = { harrisonFord: { id: 1, first_name: \u0026#39;Harrison\u0026#39;, last_name: \u0026#39;Ford\u0026#39;, }, karenAllen: { id: 2, first_name: \u0026#39;Karen\u0026#39;, last_name: \u0026#39;Allen\u0026#39;, }, drewBarrymore: { id: 3, first_name: \u0026#39;Drew\u0026#39;, last_name: \u0026#39;Barrymore\u0026#39;, }, liamNeeson: { id: 4, first_name: \u0026#39;Liam\u0026#39;, last_name: \u0026#39;Neeson\u0026#39;, }, benKingsley: { id: 5, first_name: \u0026#39;Ben\u0026#39;, last_name: \u0026#39;Kingsley\u0026#39;, }, markHamill: { id: 6, first_name: \u0026#39;Mark\u0026#39;, last_name: \u0026#39;Hamill\u0026#39;, }, carrieFisher: { id: 7, first_name: \u0026#39;Carrie\u0026#39;, last_name: \u0026#39;Fisher\u0026#39;, }, glennClose: { id: 8, first_name: \u0026#39;Glenn\u0026#39;, last_name: \u0026#39;Close\u0026#39;, }, } Next create the folder seeds/dev and the file seeds/dev/movies-and-actors.js:\nmkdir seeds/dev touch seeds/dev/movies-and-actors.js Put the code below into the movies-and-actors.js file:\nimport { movies, actors } from \u0026#39;./data.js\u0026#39; export async function seed(knex) { // Delete existing entries  await knex(\u0026#39;actors\u0026#39;).del() await knex(\u0026#39;movies\u0026#39;).del() await knex(\u0026#39;movies\u0026#39;).insert([ movies.Raiders, movies.ET, movies.Schindlers, movies.StarWars, movies.AirForceOne, movies.IndianaJones, ]) await knex.raw(` SELECT setval(\u0026#39;movies_id_seq\u0026#39;, coalesce(max(id), 0) + 1, false) FROM movies `) // const currentValue = await knex.select(\u0026#39;last_value\u0026#39;).from(\u0026#39;movies_id_seq\u0026#39;).first()  // console.log(currentValue)  await knex(\u0026#39;actors\u0026#39;).insert([ actors.harrisonFord, actors.karenAllen, actors.drewBarrymore, actors.liamNeeson, actors.benKingsley, actors.markHamill, actors.carrieFisher, actors.glennClose, ]) await knex.raw(` SELECT setval(\u0026#39;actors_id_seq\u0026#39;, coalesce(max(id), 0) + 1, false) FROM actors; `) // const currentValue2 = await knex.select(\u0026#39;last_value\u0026#39;).from(\u0026#39;actors_id_seq\u0026#39;).first()  // console.log(currentValue2)  console.log(\u0026#39;success\u0026#39;) } Run the seeds file:\nnpm run db:seed \u0026gt; express-movies-knex@0.0.0 db:seed \u0026gt; knex seed:run --env development Using environment: development success Ran 1 seed files Validating the Seeds Data Once complete you should be able to log into your database from the command line and run a few SQL queries to validate the data has been successfully added.\nTry it out!\npsql -d knex_movies_dev psql (14.2) Type \u0026#34;help\u0026#34; for help. knex_movies_dev=# select * from movies; id | title | genre | release_date | created_at | updated_at ----+-------------------------+--------+--------------+-------------------------------+------------------------------- 1 | Raiders of the Lost Ark | action | 1981-06-01 | 2022-03-11 15:29:35.231065-05 | 2022-03-11 15:29:35.231065-05 2 | ET | sci-fi | 1982-06-11 | 2022-03-11 15:29:35.231065-05 | 2022-03-11 15:29:35.231065-05 3 | Schindlers List | drama | 1993-12-15 | 2022-03-11 15:29:35.231065-05 | 2022-03-11 15:29:35.231065-05 4 | Star Wars | sci-fi | 1977-05-25 | 2022-03-11 15:29:35.231065-05 | 2022-03-11 15:29:35.231065-05 5 | Air Force One | action | 1997-07-25 | 2022-03-11 15:29:35.231065-05 | 2022-03-11 15:29:35.231065-05 6 | Indiana Jones | action | 1997-07-25 | 2022-03-11 15:29:35.231065-05 | 2022-03-11 15:29:35.231065-05 (6 rows) knex_movies_dev=# select * from actors; id | first_name | last_name | created_at | updated_at ----+------------+-----------+-------------------------------+------------------------------- 1 | Harrison | Ford | 2022-03-11 15:29:35.235442-05 | 2022-03-11 15:29:35.235442-05 2 | Karen | Allen | 2022-03-11 15:29:35.235442-05 | 2022-03-11 15:29:35.235442-05 3 | Drew | Barrymore | 2022-03-11 15:29:35.235442-05 | 2022-03-11 15:29:35.235442-05 4 | Liam | Neeson | 2022-03-11 15:29:35.235442-05 | 2022-03-11 15:29:35.235442-05 5 | Ben | Kingsley | 2022-03-11 15:29:35.235442-05 | 2022-03-11 15:29:35.235442-05 6 | Mark | Hamill | 2022-03-11 15:29:35.235442-05 | 2022-03-11 15:29:35.235442-05 7 | Carrie | Fisher | 2022-03-11 15:29:35.235442-05 | 2022-03-11 15:29:35.235442-05 8 | Glenn | Close | 2022-03-11 15:29:35.235442-05 | 2022-03-11 15:29:35.235442-05 (8 rows) knex_movies_dev=# \\q Lab - Discussion Take a few minutes to review the movies-and-actors.js file and discuss the following questions with a partner:\n Where is the data coming from? Why is the del() function being called first? Why and how is the insert() method being used?  Read over the Seeds CLI Documentation^.\nStep 6 - Adding Movies Routes Now that we have a database with tables and seed data, we can begin to define routes that do CRUD operations on the database. Let\u0026rsquo;s start with the movies INDEX route.\nCreating the Knex Object For our router file to use Knex, we must import the Knex module and then create a Knex object with the correct configuration:\nAdd the following to the routes/movies.js file:\nimport knexLib from \u0026#39;knex\u0026#39; import knexConfigs from \u0026#39;./knexfile.js\u0026#39; const knex = knexLib(knexConfigs[process.env.NODE_ENV]) There is a lot going on in these files so let\u0026rsquo;s break it down:\n first we import the default export from knex and give it the name knexLib then we import our configuration information from ./knexfile.js finally we get the specific configuration (development, test, or production) from knexConfigs and pass it as a parameter to knexLib, giving us the knex object we need for executing knex commands.  Defining the Movies INDEX Route The index route will simply return all of the movies from the database. Here is the code:\nrouter.get(\u0026#39;/\u0026#39;, async (req, res, next) =\u0026gt; { try { const movies = await knex.select(\u0026#39;*\u0026#39;).from(\u0026#39;movies\u0026#39;) res.status(200).json(movies) } catch (err) { next(err) } }) That was easy! All of our hard work in setting up Knex is finally paying off.\nObservations:\n We are using an async function for our route handler. We are using await with the knex statement. We have wrapped all of our route handler code in a try/catch block. If knex reports an error, it will result in a rejected promise that will be caught and reported to Express via the next callback. The knex statement uses .select('*') to select all of the columns from the movies table.  Testing the INDEX Route You can test this route with HTTPie:\nhttp localhost:3000/api/movies HTTP/1.1 200 OK Connection: keep-alive Content-Length: 1030 Content-Type: application/json; charset=utf-8 Date: Fri, 11 Mar 2022 20:48:03 GMT ETag: W/\u0026#34;406-VinnQjfQbl+wd+as88owbxE26KE\u0026#34; Keep-Alive: timeout=5 X-Powered-By: Express [ { \u0026#34;created_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34;, \u0026#34;genre\u0026#34;: \u0026#34;action\u0026#34;, \u0026#34;id\u0026#34;: 1, \u0026#34;release_date\u0026#34;: \u0026#34;1981-06-01T04:00:00.000Z\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Raiders of the Lost Ark\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34; }, { \u0026#34;created_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34;, \u0026#34;genre\u0026#34;: \u0026#34;sci-fi\u0026#34;, \u0026#34;id\u0026#34;: 2, \u0026#34;release_date\u0026#34;: \u0026#34;1982-06-11T04:00:00.000Z\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;ET\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34; }, { \u0026#34;created_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34;, \u0026#34;genre\u0026#34;: \u0026#34;drama\u0026#34;, \u0026#34;id\u0026#34;: 3, \u0026#34;release_date\u0026#34;: \u0026#34;1993-12-15T05:00:00.000Z\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Schindler\u0026#39;s List\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34; }, { \u0026#34;created_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34;, \u0026#34;genre\u0026#34;: \u0026#34;sci-fi\u0026#34;, \u0026#34;id\u0026#34;: 4, \u0026#34;release_date\u0026#34;: \u0026#34;1977-05-25T04:00:00.000Z\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Star Wars\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34; }, { \u0026#34;created_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34;, \u0026#34;genre\u0026#34;: \u0026#34;action\u0026#34;, \u0026#34;id\u0026#34;: 5, \u0026#34;release_date\u0026#34;: \u0026#34;1997-07-25T04:00:00.000Z\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Air Force One\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34; }, { \u0026#34;created_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34;, \u0026#34;genre\u0026#34;: \u0026#34;action\u0026#34;, \u0026#34;id\u0026#34;: 6, \u0026#34;release_date\u0026#34;: \u0026#34;1997-07-25T04:00:00.000Z\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Indiana Jones\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34; } ] Defining the Movies SHOW Route The show route will return a single movie specified by the id URL parameter.\nAdd the following code to the routes/movies.js file:\nrouter.get(\u0026#39;/:id\u0026#39;, async (req, res, next) =\u0026gt; { try { const id = Number(req.params.id) const movie = await knex.select(\u0026#39;*\u0026#39;).from(\u0026#39;movies\u0026#39;).where({ id }).first() if (movie) { res.status(200).json(movie) } else { const error = new Error(`Movie with id ${id}not found.`) error.statusCode = 404 next(error) } } catch (err) { next(err) } }) Observations:\n We are using an async function for our route handler. We are using await with the knex statement. We have wrapped all of our route handler code in a try/catch block. If knex reports an error, it will result in a rejected promise that will be caught and reported to Express via the next callback. We can get the value of the :id URL parameter from the req object via req.params.id. The knex statement uses:  .select('*') to select all of the columns .where({ id }) to return only the row with the matching id .first() to return only the first row - there will only be one row but it will be inside an array so .first() unpacks it from the array.   If we don\u0026rsquo;t find the movie we report a 404 error.  Testing the SHOW Route You can test this route with HTTPie. Try testing the happy path (positive testing) and the sad path (negative testing):\nhttp localhost:3000/api/movies/4 HTTP/1.1 200 OK Connection: keep-alive Content-Length: 167 Content-Type: application/json; charset=utf-8 Date: Fri, 11 Mar 2022 21:03:43 GMT ETag: W/\u0026#34;a7-u+D3LlvULOsH3ryVAcxykNArzc0\u0026#34; Keep-Alive: timeout=5 X-Powered-By: Express { \u0026#34;created_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34;, \u0026#34;genre\u0026#34;: \u0026#34;sci-fi\u0026#34;, \u0026#34;id\u0026#34;: 4, \u0026#34;release_date\u0026#34;: \u0026#34;1977-05-25T04:00:00.000Z\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Star Wars\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2022-03-11T20:29:35.231Z\u0026#34; } ❯ http localhost:3000/api/movies/123 HTTP/1.1 404 Not Found Connection: keep-alive Content-Length: 42 Content-Type: application/json; charset=utf-8 Date: Fri, 11 Mar 2022 21:03:53 GMT ETag: W/\u0026#34;2a-8uF++gvwaOxS5VtwUNrZJgZ4ERw\u0026#34; Keep-Alive: timeout=5 X-Powered-By: Express { \u0026#34;message\u0026#34;: \u0026#34;Movie with id 123 not found.\u0026#34; } Defining the Movies CREATE Route The CREATE route will use an HTTP POST to receive JSON data defining a movie and INSERT it into the DB. Here is the code:\nrouter.post(\u0026#39;/\u0026#39;, async (req, res, next) =\u0026gt; { try { const { title, genre, release_date } = req.body const [saved] = await knex(\u0026#39;movies\u0026#39;).returning(\u0026#39;*\u0026#39;).insert({ title, genre, release_date, }) res.status(201).json(saved) } catch (err) { next(err) } }) Observations:\n We are using an async function for our route handler. We are using await with the knex statement. We have wrapped all of our route handler code in a try/catch block. If knex reports an error, it will result in a rejected promise that will be caught and reported to Express via the next callback. We destructure the req.body parameters into the title, genre, and release_date variables. This will only work if the json body-parser middleware is enabled. We cannot use the knex .first() method with inserts and updates, but we can use JavaScript array destructuring to unpack the data returned from the insert() method.  We can test it out with:\nhttp POST localhost:3000/api/movies title=\u0026#34;The Terminator\u0026#34; genre=\u0026#34;sci-fi\u0026#34; release_date=\u0026#34;1985-01-11\u0026#34; We can also test the DB non-nullable constraint on the movie title:\nhttp POST localhost:3000/api/movies genre=\u0026#34;sci-fi\u0026#34; release_date=\u0026#34;1985-01-11\u0026#34; HTTP/1.1 500 Internal Server Error Connection: keep-alive Content-Length: 199 Content-Type: application/json; charset=utf-8 Date: Fri, 11 Mar 2022 23:13:35 GMT ETag: W/\u0026#34;c7-1x/8GAQdnwKxJR0sxYGgk3jTdqI\u0026#34; Keep-Alive: timeout=5 X-Powered-By: Express { \u0026#34;message\u0026#34;: \u0026#34;insert into \\\u0026#34;movies\\\u0026#34; (\\\u0026#34;genre\\\u0026#34;, \\\u0026#34;release_date\\\u0026#34;, \\\u0026#34;title\\\u0026#34;) values ($1, $2, DEFAULT) returning * - null value in column \\\u0026#34;title\\\u0026#34; of relation \\\u0026#34;movies\\\u0026#34; violates not-null constraint\u0026#34; } Defining the Movies UPDATE Route The UPDATE route will use an HTTP PUT to receive JSON data defining a movie and UPDATE it in the DB. Here is the code:\nrouter.put(\u0026#39;/:id\u0026#39;, async (req, res, next) =\u0026gt; { try { const id = Number(req.params.id) const movie = await knex.select(\u0026#39;*\u0026#39;).from(\u0026#39;movies\u0026#39;).where({ id }).first() if (!movie) { const error = new Error(`Movie with id ${id}not found.`) error.statusCode = 404 next(error) } else { const { title, genre, release_date } = req.body const [saved] = await knex(\u0026#39;movies\u0026#39;) .where({ id: req.params.id }) .returning(\u0026#39;*\u0026#39;) .update({ title, genre, release_date, }) res.status(200).json(saved) } } catch (err) { next(err) } }) Observations:\n We are using an async function for our route handler. We are using await with the knex statement. We have wrapped all of our route handler code in a try/catch block. If knex reports an error, it will result in a rejected promise that will be caught and reported to Express via the next callback. Before executing the UPDATE statement, we check to see if the movie exists. If it isn\u0026rsquo;t found we report a 404 error. We destructure the req.body parameters into the title, genre, and release_date variables. This will only work if the json body-parser middleware is enabled. We cannot use the knex .first() method with inserts and updates, but we can use JavaScript array destructuring to unpack the data returned from the update() method.  We can test it out with:\nhttp PUT localhost:3000/api/movies/7 title=\u0026#34;Terminator 2: Judgment Day\u0026#34; genre=\u0026#34;sci-fi\u0026#34; release_date=\u0026#34;1991-07-03\u0026#34; Defining the Movies DELETE Route The DELETE route will use an HTTP DELETE to DELETE the specified movie from the DB. Here is the code:\nrouter.delete(\u0026#39;/:id\u0026#39;, async (req, res, next) =\u0026gt; { try { const id = Number(req.params.id) const movie = await knex.select(\u0026#39;*\u0026#39;).from(\u0026#39;movies\u0026#39;).where({ id }).first() if (!movie) { const error = new Error(`Movie with id ${id}not found.`) error.statusCode = 404 next(error) } else { await knex(\u0026#39;movies\u0026#39;).where({ id: req.params.id }).del() res.status(200).json({ message: \u0026#39;The movie has been deleted\u0026#39; }) } } catch (err) { next(err) } }) Observations:\n We are using an async function for our route handler. We are using await with the knex statement. We have wrapped all of our route handler code in a try/catch block. If knex reports an error, it will result in a rejected promise that will be caught and reported to Express via the next callback. Before executing the DELETE statement, we check to see if the movie exists. If it isn\u0026rsquo;t found we report a 404 error. We return a 200 status and a message wrapped in an object.  We can test it out with:\nhttp DELETE localhost:3000/api/movies/3  Lab - Create the Actor Routes Using the Movie Routes as a guide, complete the actor routes in the file routes/actors.js.\nYou can find test commands in the file test-actor-routes.js.\nRemember to do the following:\n Wrap your route handler code in try/catch blocks. On success, return a 200 or 201 HTTP status. For the SHOW, UPDATE, and DELETE routes, return a 404 status if the actor is not found.  "
},
{
	"uri": "/javascript/nodejs/getting-started/node-core-modules/event-module/",
	"title": "The Event Module",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Event Driven Programming The Events Module Creating Events Triggering Events Cleaning up Events  Event Driven Programming What is event driven programming?  In computer programming, event-driven programming is a programming paradigm in which the flow of the program is determined by events such as user actions (mouse clicks, key presses), sensor outputs, or messages from other programs/threads. Wikipedia\n Event Driven programming is not anything unique to JavaScript or Node. In fact, \u0026ldquo;Event Driven\u0026rdquo; isn\u0026rsquo;t limited to just software. To begin to understand event driven anything, lets take a look at what an Event is.\nWhat is an Event? An event can be described as something that occurs which trigger an action that will modify the state or output of something else.\n.Examples of Events\n Mouse Click Pressing down on a keyboard key Navigating to a URL in your browser Receiving a Text message or phone call  All of these examples are events, because they can potentially trigger some action to take place.\n Generic Event Loop  Event Triggers\n Something (like a message, key press, mouse click, etc..) generates/triggers the event and sends it to the event loop The event is picked up by an event listener, and determines how it should be handled The event Handler actually executes the action Once the handler is done, the loop begins listening for additional events  So how does this apply to Node.js? Node is almost completely driven by events with its built-in event loop allowing for its single-threaded asynchronous behavior. In addition the the built-in event-loop, node also has a built-in module to allow you to build your own events, listeners, and handlers as well as an event-emitter to trigger them. This module is called the events module.\nThe Node Events Module By default the events emitter exports an EventEmitter object constructor when you import it. This object will give you access to create and trigger your own event handlers and events.\nImporting EventEmitter\nconst events = require(\u0026#39;events\u0026#39;); Once you have events imported to a variable, you can construct your event emitter object.\nConstructing the EventEmitter\neventEmitter = new events.EventEmitter(); If you look at the documentation you\u0026rsquo;ll see that with the EventEmitter class gives you access to several methods.\nWe will focus on:\n Creating a handler Adding our handler to the event listener Emitting an event to trigger our handler Cleaning up ( removing ) an event listener  Event Handling and Listening To generate a listener we call the on method of the EventEmitter class. The on method takes 2 arguments:\n The name of your event as a string A callback function to be executed when the event is detected.  The event handler is simply the callback that is passed to the on function.\nThe following example will create a simple event listener named greet that will log a greeting when called:\nSetting up a basic Listener\nconst events = require(\u0026#39;events\u0026#39;); eventEmitter = new events.EventEmitter(); eventEmitter.on(\u0026#34;greet\u0026#34;,()=\u0026gt;{ console.log(\u0026#34;Hello\u0026#34;); }); If you were to log the eventEmitter object out, you\u0026rsquo;d see an object with our greet name as a key:\nConsole log output of the EventEmitter\nEventEmitter { _events: { greet: [Function] }, _eventsCount: 1, _maxListeners: undefined } You can see an example of this here by copying the code in addingevent.js to the index.js.\nSo now that we have an event lister, with an event handler registered, we can now use the eventEmitter to trigger the event.\nEmitting An Event It does not do any good to simply register a custom event. If there is nothing emitting (triggering) the event, then the event will never get called.\nWe can use the EventEmitter class, as its name hints, to emit an event that will invoke our event handler callback function. This is done by calling the emit method with the name of the event we defined. In our case, that would be the string greet.\nTriggering greet\neventEmitter.emit(\u0026#34;greet\u0026#34;) Try it by copying the code in emitevents.js to index.js and running it\nRemoving Listeners The EventEmitter Class will allow us to remove listeners as well. For example, if an event, or an object it uses, is no longer needed, it should be removed. It is possible to run into memory and/or performance issues if the number of listeners is allowed to grow with no clean up.\nThere are two methods on the EventEmitter class that will allow us to do this. removeListener and removeAllListeners. As the name implies, removeAllListeners will simply remove all listeners that are registered when invoked. removeListener on the other hand, requires the name of the event, along with the function that was set as the event handler callback.\n To remove a specific listener, you must call it with the exact function that it was set up with. This means that if you intend to remove a listener, you should not use anonymous functions.\n Because we created our listener with an anonymous function in the previous examples, we would not be able to remove it by name. Therefore, we will refactor the code and define the function that we will pass to the on method instead.\n.Removing Greet\nconst events = require(\u0026#39;events\u0026#39;); eventEmitter = new events.EventEmitter(); // Standard Function called greet  function Greet(){ console.log(\u0026#34;Hello\u0026#34;); } // Add a listener that will be triggered with \u0026#34;greet\u0026#34; and call Greet()  eventEmitter.on(\u0026#34;greet\u0026#34;, Greet); //Trigger the event  eventEmitter.emit(\u0026#39;greet\u0026#39;); //Remove the listener by using the name \u0026#34;greet\u0026#34; and  eventEmitter.removeListener(\u0026#39;greet\u0026#39;, Greet); Try it here by copying the code you will find in removeevent.js to index.js and running it.\nLab  Max/Min Number  "
},
{
	"uri": "/javascript/nodejs/advanced/express-and-bookshelf/knex-todo-app/",
	"title": "Knex Todo App",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Setting up knex Migrations and seeding data Using knex in with express  Skills  Using knex in your RESTful routing Learning how to build RESTful APIS Full CRUD with a database  Big goal Your goal is to create a server that will let make calls to a database for a todo app. You are making a todo api.\nYou will use node, express, knex and postgres. To execute full CRUD you will use Postman. You will create this api from scratch so look at previous lessons and labs.\nYou will seed your data. So think about what your todo object should look like. It should have an id, name, due date, priority, and if it is completed.\nYou will be responsible for 5 routes, although feel free to write some custom routes, like maybe one for getting all uncompleted todos.\nGET /todos GET /todos/:id POST /todos PUT /todos/:id DELETE /todos/:id Installing Packages After making a directory the first step is run npm init. With a partner make a list of all the dependencies you\u0026rsquo;ll need. Remember to use --save or --save-dev when installing them.\nRemember to add to the scripts object in your package.json, an npm script to start up our application:\n\u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;nodemon app.js\u0026#34;, \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34; } If you forget to add a package, it\u0026rsquo;s okay, you can always add one later.\nSetting Up Knex. Look at your previous lesson to set up knex.\nWrite your knexfile.js file.\nRun a migration for todos\nUse this todos data to get seed your data.\n Go here to get an explanation of what setval does in todos.sql.\n Server.js Create a server.js file. (In some lessons we called this app.js.) Here is the place where we set up the server (hence the name), choose a port, etc\u0026hellip; This is also where we handle urls and send them to a router.\nRoutes Here is where you will handle your /todos routes. Remember you have the five basic ones that match CRUD. Start with GET for an INDEX, make sure that works and then your\u0026rsquo;re on your way.\n hand-paper-o[] Avoid copy \u0026amp; paste. Don\u0026rsquo;t rob yourself of getting comfortable with the syntax. Muscle memory is real! Type it out.\n CHALLENGE Challenge yourself to write a route that gets all completed tasks and another for all uncompleted tasks. Try another route that sorts tasks by due date.\nAdditional Resources  The Express website  "
},
{
	"uri": "/javascript/nodejs/getting-started/node-core-modules/event-module-lab/",
	"title": "Labs for Event Module",
	"tags": [],
	"description": "",
	"content": "Lab  Create 2 functions that will print out the largest, and smallest representable number.  Number.MAX_VALUE will give you the largest representable number. Number.MIN_VALUE will give you the smallest representable number.   Create 2 event listeners:  The first will be called \u0026ldquo;max\u0026rdquo; and take your max number function as an event handler callback The second will be called \u0026ldquo;min\u0026rdquo; and take your min number function as an event handler callback   Emit each event independently Remove both events by using the removeListener method.  "
},
{
	"uri": "/python/apis/apis/",
	"title": "APIs",
	"tags": [],
	"description": "",
	"content": "This tutorial walks through how to GET data from APIs requiring data or header values.\nFor example to use the any of the THD APIs you must get a Client Secret \u0026amp; Client ID that you then use to request a token.\nClient credentials will be provided for this workshop, but you can learn how to get your own on the THD Security API Guide.\nEnvironment Variables Python\u0026rsquo;s os package reads the systems bash and allows Python access to environment variables:\n- AUTH_CLIENT_ID - AUTH_CLIENT_SECRET Terminal Set Up System Set Up In the terminal type:\n$ open ~/.bashrc If nothing happens, create the file first then open\n$ touch ~/.bashrc $ open ~/.bashrc Inside the bash file variables are set like so:\nexport AUTH_CLIENT_ID=\u0026#39;AUTH_CLIENT_ID_HERE\u0026#39;  Do not put spaces before or after the = sign  Inside your bash profile add the following (Replace the xxxxXXXXxxxxXXXX's with the given credentials by the instructor):\n############ THD Token Generation for Python pillar ################## # Environment variables export AUTH_DOMAIN=\u0026#39;master-data-security.apps-np.homedepot.com\u0026#39; export AUTH_PATH=\u0026#39;/security/oauth/token\u0026#39; export AUTH_CLIENT_ID=\u0026#39;AUTH_CLIENT_ID_HERE\u0026#39; export AUTH_CLIENT_SECRET=\u0026#39;AUTH_CLIENT_SECRET_HERE\u0026#39; # Token Generation export R=$(curl \u0026#39;https://master-data-security.apps-np.homedepot.com/security/oauth/token\u0026#39; -u $AUTH_CLIENT_ID:$AUTH_CLIENT_SECRET -X POST -H \u0026#39;Accept: application/json\u0026#39; -d \u0026#39;grant_type=client_credentials\u0026#39;) export TOKEN=$(echo $R | jq .access_token) export TOKEN=$(echo \u0026#34;$TOKEN\u0026#34; | sed -e \u0026#39;s/^\u0026#34;//\u0026#39; -e \u0026#39;s/\u0026#34;$//\u0026#39;)  Save your bashrc and open another terminal window \u0026amp; type  $ echo $AUTH_CLIENT_ID You should get a response back with the value of AUTH_CLIENT_ID.\nYou have successfully created environment variables for your machine!\npipenv Set Up If you are using a virtual env (like pipenv) you might need to create this file in a slightly different way.\nPyCharm allows you to do this by clicking on the configuration dropdown \u0026gt; Edit Configurations on the top right of the window .\nIn the Run/Debug Configurations window, click on the folder icon on the right of the Environment Variables:.\nIn the Environment Variables window, click on the + on the bottom left and add each of the above variables one at a time. (Do not put quotes around strings)\nTo read the values of your bash variables, you can do this via a terminal curl command or a Python script.\npython code The below example GETs a JSON object returned from the THD Security API, the JSON object that holds the token to be used to access THD APIs using the requests and os packages.\n requests documentation os documentation  import requests, os data = [ (\u0026#39;grant_type\u0026#39;, \u0026#39;client_credentials\u0026#39;), ] try: response = requests.post(\u0026#39;https://master-data-security.apps-np.homedepot.com/security/oauth/token\u0026#39;, data=data, auth= ( os.environ[\u0026#39;AUTH_CLIENT_ID\u0026#39;], # Tells python to search your machines environment for a variable with that name os.environ[\u0026#39;AUTH_CLIENT_SECRET\u0026#39;] ) ) response_json =response.json() token = response_json[\u0026#34;access_token\u0026#34;] head = {\u0026#39;Authorization\u0026#39;: \u0026#39;Bearer \u0026#39; + token} except: print(\u0026#34;Error\u0026#34;)  Secret Variables In some cases, you might not want to use environment variables, so you would want to store the variables in a python file that is easily accessible.\nCreate a secrets.py file and put the following in it (Replacing the values in the strings with the corresponding values):\nAUTH_CLIENT_ID=\u0026#39;AUTH_CLIENT_ID_HERE\u0026#39; AUTH_CLIENT_SECRET=\u0026#39;AUTH_CLIENT_SECRET_HERE\u0026#39; But wait! We don\u0026rsquo;t want to share our keys in plain text with every one!\nThat is where .gitignore comes into play.\nCreate another file called .gitignore. Place the relative path to your secrets file in here.\nThis will make it to when you push up to GitHub, the secrets file will not be push up as well.\npython code import requests, os from .secrets import AUTH_CLIENT_ID, AUTH_CLIENT_SECRET data = [ (\u0026#39;grant_type\u0026#39;, \u0026#39;client_credentials\u0026#39;), ] try: response = requests.post(\u0026#39;https://master-data-security.apps-np.homedepot.com/security/oauth/token\u0026#39;, data=data, auth= ( AUTH_CLIENT_ID, AUTH_CLIENT_SECRET ) ) response_json =response.json() token = response_json[\u0026#34;access_token\u0026#34;] head = {\u0026#39;Authorization\u0026#39;: \u0026#39;Bearer \u0026#39; + token} except: print(\u0026#34;Error\u0026#34;) "
},
{
	"uri": "/javascript/nodejs/advanced/express-and-bookshelf/bookshelf/",
	"title": "Bookshelf",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Object Relational Mapping Entity relationship diagramming  Skills  How to create a model using Bookshelf.js Using Bookshelf in an Express application  What is Bookshelf? Bookshelf is a JavaScript ORM which provides an API to abstract a database schema into application-side models. It is built on the Knex.js SQL query builder and works well with the databases that are compatible with Knex.js. Bookshelf builds on top of the query building component and has functionality to create data models, relations and other common database query needs.\nInstalling Bookshelf You know the drill by now! Bookshelf is a Node package but there is one slight difference in it than most. When it is installed, it does not install all of the dependencies it needs\u0026hellip;you must manually install knex.\nnpm install --save knex bookshelf\nFinally, we must install the database client that we will be using. We have the same choices as before but we will stick with Postgre.\nnpm install --save pg\nConnecting to a database Remember the knexfile?! We are going to use Knex to let Bookshelf know which database to perform operations on.\nbookshelf.js\nconst knex = require(\u0026#39;knex\u0026#39;)(require(\u0026#39;./knexfile\u0026#39;)); const bookshelf = require(\u0026#39;bookshelf\u0026#39;)(knex); bookshelf.plugin(\u0026#39;registry\u0026#39;) module.exports = bookshelf; What\u0026rsquo;s going on on line 3? This is a bookshelf plugin that lets us specify the relations between models using strings as opposed to variable, otherwise we almost certainly run into circular dependencies with our models because of how require works. Here is quite a thorough explanation of how the plugin works.\nSee that knexfile reference way up on line 1? It\u0026rsquo;s going to look just like it always has, we\u0026rsquo;ve just put it in a separate file to keep everything modular. Here it is:\nknexfile.js\nmodule.exports = { client: \u0026#39;postgresql\u0026#39;, connection: { host : \u0026#39;127.0.0.1\u0026#39;, database : \u0026#39;pets\u0026#39;, charset : \u0026#39;utf8\u0026#39; } }; The database schema Bookshelf depends on there already being a database schema. So, we set up our database just as we did with Knex.js - using migrations. We will assume that we have set up a table called owners with the fields first_name, last_name, \u0026amp; phone. If you need a refresher on how to set a database schema using Knex migrations please re-visit the Knex lesson.\nCreating a Bookshelf model models/owner.js\nconst Bookshelf = require(\u0026#39;./bookshelf\u0026#39;); require(\u0026#39;./pet\u0026#39;); const Owner = Bookshelf.Model.extend({ tableName: \u0026#39;owners\u0026#39;, pets: function() { return this.hasMany(\u0026#39;Pet\u0026#39;, \u0026#39;owner_id\u0026#39;); } }); // module.exports = Owner; module.exports = Bookshelf.model(\u0026#39;Owner\u0026#39;, Owner); The only required property when creating a model is tableName. This property tells the model from where to save and load data in the database. The reason this file is so minimal is because the schema for this model is represented elsewhere, namely directly in the database itself or in the migrations from Knex.\nNow, we are able to operate directly on the Owner model;\napp.js\nOwner.fetchAll().then(function(owners) { console.log(owners.toJSON()); }); That will fetch all of the Users from our database\nAssociations One-to-one One-to-one associations can be created with belongsTo, hasOne, and morphOne relation types.\nWe want to add the belongsTo relationship to the child model (the one having the foreign key) and a hasOne (or morphOne) relationship to the parent model (the target of the foreign key).\nExample of one-to-one relationship\nconst Book = bookshelf.Model.extend({ tableName: \u0026#39;books\u0026#39;, summary: function() { return this.hasOne(Summary); } }); const Summary = bookshelf.Model.extend({ tableName: \u0026#39;summaries\u0026#39;, book: function() { return this.belongsTo(Book); } }); One-to-many One-to-many associations can be created with belongsTo, hasMany, morphMany / morphTo, and some of the through relation types.\nWe want to add the belongsTo (or morphTo relationship to the child model (the one having the foreign key) and a hasMany (or morphMany) relationship to the parent model (the target of the foreign key).\nJavaScript\nconst Book = bookshelf.Model.extend({ tableName: \u0026#39;books\u0026#39;, pages: function() { return this.hasMany(Page); } }); const Page = bookshelf.Model.extend({ tableName: \u0026#39;pages\u0026#39;, book: function() { return this.belongsTo(Book); } }); Many-to-many Many-to-many associations can be created with belongsToMany, and through relation types.\nIn this association we use a belongsToMany relationship on both sides of the association.\nJavaScript\nconst Book = bookshelf.Model.extend({ tableName: \u0026#39;books\u0026#39;, authors: function() { return this.belongsToMany(Author); } }); const Author = bookshelf.Model.extend({ tableName: \u0026#39;authors\u0026#39;, books: function() { return this.belongsToMany(Book); } });  Bookshelf will create the many-to-many mapping table for us! Remember that for many-to-many associations we need a 3rd table to store all of those foreign keys. The mapping table will be named using the names of the associated tables (in alphabetical order). So for table names books and authors the mapping table will be named authors_books.\n Many-to-many Through A many-to-many through association is the same as a many-to-many association except that we also want to store some business data inside the mapping table. For example, we may want a many-to-many association between doctors and patients where the mapping table also holds appointment information (when and where the appointment occurs).\nWhen we create the through relationship, we use the through method to specify an intermediate Bookshelf Model that maps the two sides of the association.\nHere is an example:\ndoctors, patients, and appointments\nconst Doctor = bookshelf.Model.extend({ patients: function() { return this.belongsToMany(Patient).through(Appointment); } }); const Appointment = bookshelf.Model.extend({ patient: function() { return this.belongsTo(Patient); }, doctor: function() { return this.belongsTo(Doctor); } }); const Patient = bookshelf.Model.extend({ doctors: function() { return this.belongsToMany(Doctor).through(Appointment); } });  Summary  Bookshelf is an ORM (Object-Relational Mapper) library for JavaScript. Bookshelf used Knex to translate SQL statements into the proper dialect (Oracle, PostgreSQL, MySQL, etc.). Bookshelf Models are used to represent domain objects. Bookshelf provides support for one-to-one, one-to-many, many-to-many, and many-to-many through associations.  Additional Resources  The Official Bookshelf.js Website  "
},
{
	"uri": "/software-eng-essentials/looker/building-reports/",
	"title": "Building Reports",
	"tags": [],
	"description": "",
	"content": "This lesson will cover the creation of ad-hoc reports using the Explore interface.\nObjectives  Explains the concepts of dimensions and measures within Looker How to select fields from the field picker How to use filters to limit query results How to create dashboards  Example: Starting with an Explore Getting Set Up In this lesson, there are going to be examples applying the previous section using the Home Depot flavored Looker.\nTo help with organization, create a folder to save all of the Looks and Dashboards. To do this:\n Log in to homedepot.looker.com Click on your personal folder in the left menu Click New \u0026gt; Folder in the top right corner Name this folder Looker Workshop  Creating a Look Click on Explore at the left of the screen. Search for the term CF App Logs Spoke and click on it.\nThis will open up a new Explore that has been set up by another THD user with common data, filters and queries.\nSelect the desired data for a graph by expanding the Categories for the Fields. Once these are selected, the amount of data that will be processed is shown on the top left.\nTo lower the amount of data processed, add some filters. To use the filters, expand the Filters section that is in the middle of the screen.\nIn this particular example, the 3 predefined filters available will appear:\nSet the filters to:\n Cf App Logs Spoke Cf App Name is equal to markdownservice-v2.0 Cf App Logs Spoke Cf Org Name is equal to discounts Cf App Logs Spoke Timestamp Time is in the past 60 minutes   It is possible to type multiple entries into each single filter text box. For example, for the Cf App Logs Spoke Cf App Name, it is possible to type two strings in the single text box after \u0026ldquo;contains\u0026rdquo;, markdown and service. This would act as an OR statement like: \u0026ldquo;Find the Cf App Logs Spoke Cf App Names that contain the substrings markdown or service\u0026rdquo;\n In the Cf App Logs Spoke field category select the:\n Cf Src Instance dimension Location dimension Count measure    Once the above steps have been completed:\n Click Run Expand the Visualizations section to see the initial graph generated from the query. The graph should look similar to:  To save this query as a Look, do the following:\n Click Run. Click on the gear next to run and then click Save as Look. Title this Look: Current Hour Discount Counts. Click on your personal folder, then click on the Looker Workshop folder created earlier in this lesson Click Save.  There will be a green banner at the top showing that the Look and Dashboard have both been saved successfully.\nDashboards with Many Tiles As stated in the Getting Started with Looker lesson, dashboards allow users to place multiple tables or graphs on one page, giving a quick view of related content.\nExample: THD Dashboard with many Tiles  In order to add tiles to a dashboard, use the Explore menu to search for and select an Existing Explore called COM CF App Logs. Using the knowledge from the pre-work and the Getting Started with Looker lesson, apply the following filters:  Filter the timeframe for the logs with setting: Com Cf App Logs Timestamp Time is in the past 1 days Filter by a substring with setting: Com Cf App Logs Message contains Published CreateOrder-KafkaTopic:- OrderedId OR Time taken for addTopicName Filter the App name to look for with setting: Com Cf App Logs Cf App Name is equal to ordertransmit-proxy Filter Ot Proxy Profile by setting Com Cf App Logs Ot Proxy Profile is equal to BOPIS (BOPIS stands for buy online, pick up in store)   Apply the dimensions:  Com Cf App Logs Ot Proxy Profile Com Cf App Logs Distinct Count   Set the visualization to single value.  This will all look like:\n  To save this query as a tile on a dashboard, do the following:\n Click Run. Click on the gear next to Run and then click Save to Dashboard. Title this tile: BOPIS. Click on your personal folder \u0026gt; Looker Workshop folder created earlier in this lesson Click New Dashboard on the bottom left of the window. Name this new dashboard CF APP LOGS. Make sure that the newly created dashboard is selected and click Save to Dashboard.  There will be a green banner at the top showing that the Look has been saved successfully, that should like:\n  Editing Dashboards It is possible to access a dashboard either by:\n click on the link in the green success banner (This only works directly after a dashboard has been created) go to the folder structure menu on the left, then follow the file path to where the dashboard was saved. (Should be Folders \u0026gt; My Folder \u0026gt; Looker Workshop) Then clicking on the dashboard.  To start editing a dashboard, click on the three dots on the top right of the window and click Edit dashboard.\nEdit mode makes it possible to resize, move, duplicate or edit the tiles within the dashboard by clicking on the three dots in the top right corner of each tile.\nWhen a tile is duplicated, the new tile is a visualization that is representing the exact same query as the original.\nExample: Editing THD Dashboard  To access the dashboard created in the previous example, go to the folder structure menu on the left, then follow the file path to where the dashboard was saved. (Should be Folders \u0026gt; My Folder \u0026gt; Looker Workshop) Then click on CF APP LOGS. Start editing the dashboard by clicking on the three dots in the top right of the screen, then select Edit dashboard. Click on the three dots in the top right corner of the BOPIS tile, then click Duplicate tile. This will create a second tile titled BOPIS (copy). To edit the query for this new tile, click edit on BOPIS (copy). Update the filter for Com Cf App Logs Ot Proxy Profile to BOSS and change the title of the tile to BOSS. (BOSS stands for buy online, ship to store) Make sure to click run, then Save.    Repeat the above steps to add three more tiles that filters for Com Cf App Logs Ot Proxy Profile to equal:\n STH and the title of the tile to STH (STH stands for Ships to Home) MIX and the title of the tile to MIX (MIX means there are a combination of work orders and an enhanced FI order on it) BODFS and the title of the tile to BODFS (BODFS stands for Buys Online Delivers from Home)  Make sure to save the current state of the dashboard by clicking Save in the top right corner of the window.\nDashboard Filters Dashboard filters allow a viewer to narrow a dashboard’s results to only the data the viewer is interested in, without affecting any other users. Dashboard filters can apply to all tiles on a dashboard, or to only one dashboard tile.\nDashboard filters can be created in Edit dashboard mode by clicking on the Filters button on the top left of the window. From here you are given 2 options:\n Add Filter A cross filtering toggle: this allows users to click a data point in one dashboard tile to have all dashboard tiles automatically filter on that value. (This is not covered in this particular lesson)  Add Filter The adding filter window is automatically populated with the dimensions and measures from the original Explores the tiles were made from.\nOnce the dimension or measure to filter on is selected, a filter configuration window appears allowing customization for the filter settings:\n   Not all filters will have all of the below configurations\n  Title: The title of the filter to appear on the dashboard. By default this is the name of the filter-by field. Control: A list of control types, which vary depending on the type of data being filtered. Display: This selects how the filter will be displayed. If a control can be displayed only in one way, this option will not appear. Values: Sets specific value options for the filter, choose from the drop-down or enter the value options in this field. Leave blank to allow value options from the database to be surfaced, up to the maximum number of values available for that control. For numeric data, this field is replaced by Min and Max fields. Configure Default Value: (Optional) Sets the default value for the filter. Require a filter value: Toggles if a value is required for the filter. Select filters to update when this filter changes: Allows linking to other filters from this filter. If there are no other filters on the dashboard, this option will be disabled. Add and Cancel: These buttons to save or cancel the new filter.  The Tiles To Update tab configures which tiles listen to the filter. Looker begins by automatically applying the filter to any tiles created from the same Explore as the filter and sets the value of Field to Filter to the same field as the field chosen for the filter:\n   Select All or None to turn the filter on or off for all tiles. In the Field to Filter section, for each tile, choose which field will be affected by the filter, or choose not to apply the filter to an individual tile. If you select a field that is already used in an existing filter, any tiles filtered by the existing filter are unavailable to the new filter. Select Add or Cancel to save or cancel the new filter.  Once a filter has been added and saved, note that the dashboard now has the filter listed at the top.\nIt is possible to update a filter after it is created by clicking on the edit button (a pencil icon) next to the filter.\nExample: THD Dashboard Filters From the CF APP LOGS dashboard created in the above examples, click on Filters \u0026gt; Add Filter.\nClick on Timestamp Date \u0026gt; Timestamp Time.\nUpdate the following configurations for the filter in settings tab to:\n Control: Advanced Configure Default Value: In the last 1 days  In the Tiles to Update tab, note that all of the tiles are listed to be filtered by Timestamp Time.\nClick Add. Play around with different time durations and click Update in the top right corner to see the changes.\nLabs Use the following labs to get an introduction to Looker. This will give plenty of information and practice for finding and using already created reports in Looker:\nQwik labs: Exploring data with Looker Will need to register, it is free though\n At this point, do Merging Results from Different Explores in Looker, Looker Functions and Operators and Exploring Data with Looker: Challenge Lab  Summary In this lesson:\n basic terminology for Looker was covered such as: Look, dashboard, and tile. basic usage for Looker was covered such as scheduling notifications, creating Dashboards, and using existing Dashboards.  "
},
{
	"uri": "/golang/api/restful-api/",
	"title": "Building RESTful Services with the Go Standard Library",
	"tags": [],
	"description": "",
	"content": "Objectives  Showcase an API built with the Go Standard Library Demonstrate strategies for working with JSON Discuss working with URL \u0026amp; Query Params Working with standard CRUD actions  Skills  Stand up an API using only the standard library Write handlers that support standard REST actions Encode and Decode JSON Gracefully Handle Errors  The API We are going to continue to build on top of the previous lesson by setting up a tool rental API using Go\u0026rsquo;s net/http package.\nTo do so, clone the toolrental_api\nThe API will contain 3 resources:\n Tools - contains information about tools, including:  name description pricing quantity   Users - a simple user resource containing a user\u0026rsquo;s:  name email   Rentals - Updated records of tools rented by users  A few notes about this API  A link to the starter can be found in the lab section below A mock database has been provided for you, the following methods are exposed to your handlers for querying/mutating data:  All() - returns all items FindByID(id int) - returns a single item based on ID Create(resource *Resource) - Adds item to the database Update(id int, resource *Resource) - Updates items Delete(id int) - Deletes item based on ID   If no data is present, the database will be seeded upon startup. Your responsibility is to focus on writing handlers and building the API. You should not have to modify code found in the db directory  Setting up the First Endpoint For the first pass, we\u0026rsquo;ll create a route for showing all tools.\nStart by creating a tools directory along with a file named handlers.go\n$ mkdir tools \u0026amp;\u0026amp; touch tools/handlers.go Accessing the DB methods Inside tools/handlers.go we can start by ensuring that our handlers can connect to the database.\npackage tools import ( // ... ) // Tools provides a connection to the db. type Tools struct { db *db.Tool } The above struct contains a db field that is responsible for interactions with the database.\nThis means, we are now able to call the db methods mentioned earlier. For example, given an instantiation of tool, we can now call tool.db.All() to retrieve all tool records.\nTool Type The definition for the Tool struct can be found below, and is located in the database package under db/tools.go.\npackage database // ...  // Tool defines the tools data model. type Tool struct { ID int `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name,omitempty\u0026#34;` Desc string `json:\u0026#34;desc,omitempty\u0026#34;` Price float64 `json:\u0026#34;price,omitempty\u0026#34;` Quantity int `json:\u0026#34;quantity,omitempty\u0026#34;` }  Tools Root Handler Writing the first handler should feel pretty familiar at this point, the only major difference is that we are going to interact with the database package to fetch data.\n/tools/handlers.go\npackage tools // ...  func (t *Tools) Root(w http.ResponseWriter, r *http.Request){ // 1 \ttools, err := t.db.All() // 2 \tif err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) // 3 \t} fmt.Fprintf(w, \u0026#34;tools: %+v\u0026#34;, tools) // 4 }  Attach method to Tools Fetch data from DB using db.All() If an error is encountered send error message and status code to the client. Send a slice of tools to client  This handler is now available for export and use inside of the application\u0026rsquo;s main function.\n Generating Handlers Unfortunately in the present state, our Root handler will not work. This is because we need to instantiate a tools object that can invoke it\u0026rsquo;s Root method.\nOne potential solution, is to write a constructor function that creates and returns a Tools object.\n// ...  // Handlers generates a tools object. func Handlers() *Tools { return \u0026amp;Tools{db: \u0026amp;db.Tool{}} } The above function can be called in main.go to create an object with access to the db methods. ie: t := tools.Handlers().\nActivating the Handler Heading over to main.go , two things need to happen:\n Generate a tools object Create a route  main.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;toolrental_api/tools\u0026#34; // initialize mock DB with blank identifier. \t_ \u0026#34;github.homedepot.com/om-labs/toolrental_api/db\u0026#34; ) func main() { mux := http.NewServeMux() toolHandlers := tools.Handlers() // 1  mux.HandleFunc(\u0026#34;/api/tools\u0026#34;, toolHandlers.Root) // 2  fmt.Println(\u0026#34;API running on port :3000\u0026#34;) log.Fatal(http.ListenAndServe(\u0026#34;:3000\u0026#34;, mux)) } To view the output, restart the server and navigate to: http://localhost:3000/api/tools.\nnote: At this time, requests made from the client (cURL, postman, etc) must request /api/tools. Submitting a request to api/tools/ will result in a 404\nWorking with Request \u0026amp; Response Headers It may be noticeable that the output (in the browser) is closer to plain-text than JSON. To return JSON, we\u0026rsquo;ll need to appropriately set the Response Headers.\nBrief Overview of Headers HTTP header fields are key value pairs in the header section of a request and responses messages, to and from a server. They define the operating parameters of an HTTP transaction.\nSome common headers are found in the following table:\n   Name Purpose     Accept Accepted Media types   Accept-Charset Accepted character sets, i.e. utf8.   Authorization Credentials for HTTP authentication.   Set-Cookie Create and set value for a cookie.   Cookie Read a previously created cookie.   Host Domain name of the server and TCP port.    There are many headers, theses are just a few examples.\nSee the HTTP Protocol Spec for a list of all headers and how to use them: W3 Protocols\nRetrieving headers A Go server will receive header settings as part of an incoming request. In fact, Header is a field on the Request struct.\nThe Header is a map (key/value pair). As an example, inside a simple handlerFunc we can iterate over the request headers and print out each key \u0026amp; value. Using the code sample below, try sending a request to http://localhost:3000/ with your browser or the Postman app.\nmain.go\nmux.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { for k, v := range r.Header { fmt.Println(k, v) } fmt.Fprintf(w, \u0026#34;Hi! check your terminal\u0026#39;s output for more info on the request headers\u0026#34;) }) Setting Headers Response headers can be set by using the Response Writer\u0026rsquo;s Header().Set() method.\nA fairly common practice when building an API is to specify the Content-Type as application/json. This guarantees the client will receive data in the expected format.\nTo accomplish this task, we can declare w.Header().Set(\u0026quot;Content-Type\u0026quot;, \u0026quot;application/json\u0026quot;)\ntools/handlers.go\n// Root handles requests made to the /tools endpoint. // If a GET request is made, the data will be sorted in ascending ID order and sent to the client. func (t *Tools) Root(w http.ResponseWriter, r *http.Request) { w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // ... \tfmt.Fprintf(w, \u0026#34;tools: %+v\u0026#34;, tools) } Sending a request to http://localhost:3000/api/tools will now respond with JSON instead of plain text.\nWorking with JSON While this works, it would be better to send JSON, instead of a formatted response with fmt.Printf\nTo accomplish this task, we\u0026rsquo;ll use json.Marshal to convert our response into the appropriate format. Then, pass that data to ResponseWriter's Write method.\n/tools/handlers.go\nfunc (t *Tools) Root(w http.ResponseWriter, r *http.Request) { // ...  // Convert tools into byte slice. \tjsn, err := json.Marshal(tools) // 1 \tif err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) // 2 \t} // Set status of 200 \tw.WriteHeader(http.StatusOK) // 3 \t// Write JSON to response stream. \tw.Write(jsn) // 4 }  Use json.Marshal to convert tools into a byte slice ([]byte) Check for errors in marshaling/parsing the data Set a response status (200 in this case) using w.WriteHeader Use Write method to send a JSON response to the client  Submitting a request to http://localhost:3000/api/tools should give the expected response.\nEncoding the Response This is great! However, there is an alternative syntax that happens to be slightly more performant. Let\u0026rsquo;s take a look\ntools/handlers.go\nfunc (t *Tools) Root(w http.ResponseWriter, r *http.Request) { // Set a response header indicating content will be JSON. \tw.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // Fetch tool data from DB \ttools, err := t.db.All() if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) } // Set status of 200 \tw.WriteHeader(http.StatusOK) // Write JSON to response stream.  json.NewEncoder(w).Encode(tools) } In the above snippet, you\u0026rsquo;ll notice the call to json.Marshal has been removed. Additionally, on the final line, we\u0026rsquo;ve invoked two functions:\n NewEncoder : func NewEncoder(w io.Writer) *Encoder - A constructor function that takes a type of io.Writer as an argument, and returns an Encoder type. Encode : func (enc *Encoder) Encode(v interface{}) error - a method on Encoder that takes an argument, and writes that data to the stream.  Navigating to http://localhost:3000/api/tools should give the same response as previous successful requests.\nThe Encoder Type This brings us to the question: So, what exactly is encoding?\nThis article on Go\u0026rsquo;s Encoding package has an excellent description:\n In computer science we have fancy words for simple concepts\u0026hellip;Encoding is one of those words. Sometimes it’s referred to as serialization or as marshaling — it means the same thing: adding a logical structure to raw bytes.\nIn the Go standard library, we use the term encoding and marshaling for two separate but related ideas. An encoder in Go is an object that applies structure to a stream of bytes while marshaling refers to applying structure to bounded, in-memory bytes.\n The author goes on to point out that the encoding/json package has two sets of Encoders/Decoders.\n json.Encoder \u0026amp; json.Decoder - for working with io.Writer and io.Reader streams. json.Marshaler \u0026amp; json.Unmarshaler - for writing to, and reading from, byte slices.  What Should I Use? If you\u0026rsquo;re wondering about which set of methods to use, there is good news and bad news.\nThe good news: both Marshal and Encode are valid options\nThe bad news: both Marshal and Encode are valid options\nWhile both approaches are capable of appropriately performing the task of encoding your data, the major difference is that Marshal allocates a new byte slice each time it\u0026rsquo;s called. Whereas Encode writes directly to the io.Writer.\nA general principal to follow is this:\nIf you need to work with the data locally (in your handler) use Marshal/Unmarshal. However, if you\u0026rsquo;re just passing data along to the client, or writing to (or reading from) a stream, use Encode/Decode.\nPOSTing Data Next up, we can look into creating a new tool item. However, before writing the code, we need to analyze the handler function for /api/tools.\nUnfortunately, there is no way for the handler to separate out the different types of incoming http requests.\nMeaning, if we send a POST request to the /api/tools endpoint, we\u0026rsquo;ll receive the same response as our GET request. In addition, it\u0026rsquo;s apparent that nothing new was stored in the database. This makes sense, as we have yet to write any logic for handling a POST request.\nHowever, upon further inspection, it\u0026rsquo;s quite odd that our request was successful at all. At minimum, we should have received a 404 status code. In order to fix this issue, we\u0026rsquo;ll need to create some custom logic for our Root handler.\nhttp.Request.Method the Request object has a Method property that contains information about the type of incoming http Request. Using this knowledge, we can start by inspecting the request method by adding the following line of code to our Root Handler.\ntools/handlers.go\nfunc (t *Tools) Root(w http.ResponseWriter, r *http.Request) { // ... \tfmt.Println(\u0026#34;Request METHOD: \u0026#34; + r.Method) // ... } After issuing several types of requests (GET, POST, PUT, etc.), we can check our terminal\u0026rsquo;s output to find that the correct http verb is being logged each time.\nSwitching it Up One approach to solve this problem, is to use a switch statement on the http request method (r.Method).\ntools/handlers.go\nfunc (t *Tools) Root(w http.ResponseWriter, r *http.Request) { // ...  switch r.Method { case \u0026#34;GET\u0026#34;: // Fetch tool data from DB \ttools, err := t.db.All() if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) } // ... \t} } Above, we simply wrapped the majority of our existing logic in the switch statement, having the code only execute when the http method indicates this is a GET request.\nAdditionally, now issuing other types of requests will no longer execute the code meant for GET requests. Next we\u0026rsquo;ll need to add logic for handling POST requests.\n LAB 01 - POST A New Item Inside of Root Handler, write the logic for successfully handling \u0010POST requests.\nnote: Using an application like Postman (or similar tool), is encouraged for this exercise\n  App Setup:\n If you have not already: clone the toolrental_api Checkout the startup branch Make a data directory in the db folder    In Postman:\n  Create a new tool (item) with raw JSON, such as:\n{ \u0026#34;name\u0026#34;: \u0026#34;Buzzsaw\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;cuts things\u0026#34;, \u0026#34;price\u0026#34;: 219.99, \u0026#34;quantity\u0026#34;: 11 }   Set the request method to POST\n     In the Root Handler, add a case for evaluating the POST request method.  Create a new tool object with the following snippet: tool := \u0026amp;db.Tool{} Decode or Unmarshal the Request Body, storing the data in your newly instantiated tool object from the previous step Use the Create method found in the db package to add the item to your \u0026ldquo;database\u0026rdquo;  signature: func (db *Tool) Create(tool *Tool) error usage: err := t.db.Create(item_to_store_in_db)   Write a header that indicates an item was created Send a response to the client     Working with URL Parameters The next logical step is to start building out our resource-specific CRUD actions. Unfortunately, we\u0026rsquo;re going to immediately hit a snag. Let\u0026rsquo;s take a look.\nWe\u0026rsquo;ll start by writing a very simple handler that displays the Request URL.\ntools/handlers.go\n// ... func (t *Tools) Items(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Request URL: %+v\u0026#34;, r.URL) } Next, we\u0026rsquo;ll activate that handler when the client calls /api/tools/\nmain.go\n// ... func main() { // ... \tmux.HandleFunc(\u0026#34;/api/tools\u0026#34;, toolHandlers.Root) mux.HandleFunc(\u0026#34;/api/tools/\u0026#34;, toolHandlers.Items) // ... } TrimPrefix Now that our endpoints are working, we can focus on displaying individual resources.\nIn order to accomplish this, we\u0026rsquo;ll need to get the specified ID from the URL. Unfortunately, the net/http package does not provide a simple mechanism for operating on dynamic URL parameters, such as: /api/tools/{id}, where {id} is the id of a specific item in our data.\nInstead, we\u0026rsquo;ll need to manually parse the URL to get the correct information. Thankfully, the strings package provides the helpful TrimPrefix() function. With TrimPrefix, we can specify a portion of a string for easy removal. Let\u0026rsquo;s take a look.\ntools/handlers.go\nfunc (t *Tools) Items(w http.ResponseWriter, r *http.Request) { idParam := strings.TrimPrefix(r.URL.Path, \u0026#34;/api/tools/\u0026#34;) fmt.Fprintf(w, \u0026#34;idParam: %v\u0026#34;, idParam) } Sending a request to http://localhost:3000/api/tools/1 should result in the following output:\nidParam: 1 Displaying a Resource Now, we can use the FindByID method from our db package to locate the resource and send the data to our client.\nfunc (t *Tools) Items(w http.ResponseWriter, r *http.Request) { idParam := strings.TrimPrefix(r.URL.Path, \u0026#34;/api/tools/\u0026#34;) id, _ := strconv.Atoi(idParam) tool, _ := t.db.FindByID(id) fmt.Fprintf(w, \u0026#34;tool: %v\u0026#34;, tool) } Sending a request to http:// localhost:3000/api/tools/1 should now give us the data we were hoping for!\nID Errors We should handle any invalid IDs before moving forward.\nInvalid ID Starting with strconv.Atoi, we can add the following:\nid, err := strconv.Atoi(idParam) if err != nil { http.Error(w, \u0026#34;invalid ID please try again\u0026#34;, http.StatusBadRequest) } If, for some reason, a non-numerical param is added by the client, we\u0026rsquo;re now able to gracefully handle the error and display a friendly message.\nTo verify, we can send a request with a non-numerical value, which should result in an error.\nID Does Not Exist In the event the client requests an ID that does not exist, the FindByID method also returns an error. Let\u0026rsquo;s add proper error handling there as well.\ntool, err := t.db.FindByID(id) if err != nil || tool == nil { http.Error(w, err.Error(), http.StatusBadRequest) } With a small bit of code, we\u0026rsquo;re now able to handle common errors with incoming requests.\nQuery Params In addition to URL params, sometimes, you\u0026rsquo;ll want to provide functionality for accepting query params. Thankfully the http.Request object contains a Query method that returns a map of query parameters.\nLet\u0026rsquo;s say that we want to be able to sort by price in ascending order, we can add the following snippet to our Root handler:\ntools/handlers.go\nfunc (t *Tools) Root(w http.ResponseWriter, r *http.Request) { // ... \tswitch r.Method { case \u0026#34;GET\u0026#34;: // Fetch tool data from DB \t// ... \tq, ok := r.URL.Query()[\u0026#34;sort\u0026#34;] // 1 \tif ok { // 2 \torder := q[0] // 3 \tif order == \u0026#34;asc\u0026#34; { // 4 \tsort.SliceStable(tools, func(i, j int) bool { // 5 \treturn tools[i].Price \u0026lt; tools[j].Price }) } } // Set status of 200 \t// ... \t} }  Call r.URL.Query() specifically searching for a key of \u0026quot;sort\u0026quot; If the key exists, execute the sorting code Find the first (and only) value in the q Map If the order matches \u0026quot;asc\u0026quot; execute the sorting code Use SliceStable from the sort package  This pattern can be repeated for any query param you should choose to support.\nLab 02 - CRUD Actions Checkout the branch 02-crud-actions and complete the following 2 challenges.\nPart 1 - In the Items handler, write out the logic for handling incoming GET, PUT/PATCH, and DELETE requests. _note: feel free to borrow the logic from the Root handler.\n Instead of using fmt.Printf, return JSON to the client Write a switch statement that will handle the following:  GET - wrap the existing logic inside of this condition PUT/PATCH - Use the Update method found in the db package  Use the NewDecoder function to convert the request body into a tool object Use the t.db.Update function to persist the changes Update's signature: func (db *Tool) Update(id int, tool *Tool) error Upon success, send a friendly message to the client   DELETE - Use the Delete method found in the db package  Delete's signature: func (db *Tool) Delete(id int) error Upon success, send a friendly message to the client      Part 2 - In the Root Handler, add a query param for sorting by Price in descending order.\n Error Handling Good Error Handling is a must when building an API. Thankfully, the net/http package has a simple Error function that we can use to display helpful error messages.\nAs an example, we are going to fabricate a 500 server error that can be thrown when the server encounters an unexpected condition:\nmain.go\nfunc someDBcall() ([]byte, error) { return []byte(\u0026#34;Some data from db.\u0026#34;), errors.New(\u0026#34;Failed to connect.\u0026#34;) } func SomeHandler(w http.ResponseWriter, r *http.Request) { dbData, err := someDBcall() if err != nil { http.Error(w, fmt.Sprintf(\u0026#34;%v\u0026#34;, err), 500) return // Don\u0026#39;t forget to return or the function will attempt to keep going. \t} w.Write(dbData) return } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, SomeHandler) http.ListenAndServe(\u0026#34;:8000\u0026#34;, nil) } In the above example we fake a failed database connection and throw a 500 error.\nNotice in the image above that the string is still returned. This may occur if return is not placed after the http.Error call. The function will attempt to continue which could cause a runtime error.\nNotFoundHandler In addition, the net/http package includes a handful of built-in error handlers. Let\u0026rsquo;s take a look at the NotFoundHandler. Typically, a 404 (not found) error is typically thrown when a resource is requested that doesn\u0026rsquo;t exist.\nfunc ExampleServeMux_Handle() { mux := http.NewServeMux() mux.Handle(\u0026#34;/api/\u0026#34;, apiHandler{}) mux.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, req *http.Request) { // The \u0026#34;/\u0026#34; pattern matches everything, so we need to check \t// that we\u0026#39;re at the root here. \tif req.URL.Path != \u0026#34;/\u0026#34; { http.NotFound(w, req) return } fmt.Fprintf(w, \u0026#34;Welcome to the home page!\u0026#34;) }) } Above, we are invoking the NotFound error, when the request does not match the / endpoint. Take a look at the go docs for additional info on built-in error handling.\nConclusion As you can see, standing up an API with the Go standard library is entirely possible. Though it has a few quirks and can lend itself to being verbose, it is an excellent choice for a small API. However, there are third party solutions that exist to cut down on the verbosity and provide some helpful utilities and methods for building API\u0026rsquo;s. In the next lesson, we\u0026rsquo;ll introduce one of the most popular third party libraries for building API\u0026rsquo;s with Go.\n"
},
{
	"uri": "/python/nonrelational-db/cassandra/",
	"title": "Cassandra and Python",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Installing the Cassandra database adapter Using cassandra-driver to connect to/disconnect from a database Executing DDL to create a database schema Executing statements to interact with database resources  Set Up We are going to show how to connect and work with Cassandra and Python.\nYour instructor will be giving you the necessary credentials to connect to a Cassandra database. Store these credentials as environment variables with the following keys:\n C_USER C_PASSWORD C_HOST  Create a new directory called cassandra-python. Create the following files in this new directory:\n requirements.txt with a single line in it: cassandra-driver==3.23.0 Create a new file called connection.py.  Making your file structure look like:\ncassandra-python |── connection.py └── requirements.txt Within that new directory, create a virtual environment and install all needed dependencies with the following:\npython3 -m venv venv source venv/bin/activate pip3 install -r requirements.txt Database Connection The first step in interacting with Cassandra is to create an instance of Cluster which is found in the cassandra.cluster package.\nThe simplest way to connect to a Cluster is:\nfrom cassandra.cluster import Cluster cluster = Cluster() To specify the IP addresses of the nodes of the Cluster, add the addresses of the node(s) as an array:\ncluster = Cluster([\u0026#39;192.168.0.1\u0026#39;, \u0026#39;192.168.0.2\u0026#39;]) If another port besides 9042 is desired, add the port argument.\nThe following sets the port to 1234:\ncluster = Cluster([\u0026#39;192.168.0.1\u0026#39;, \u0026#39;192.168.0.2\u0026#39;], port=1234) Authentication Cassandra driver requires an implementation of PasswordAuthenticator to do authentication. There are a couple of options, one of those being PlainTextAuthProvider. Once an instance of PlainTextAuthProvider has been created, this can be passed in when connecting to a Cluster.\nfrom cassandra.auth import PlainTextAuthProvider import os username = os.getenv(\u0026#39;C_USER\u0026#39;) password = os.getenv(\u0026#39;C_PASSWORD\u0026#39;) auth_provider = PlainTextAuthProvider(username=username, password=password) cluster = Cluster([\u0026#39;127.0.0.1\u0026#39;], auth_provider=auth_provider) Database Interaction We need to create an instance of type Session in order to interact with the database. A Session is a collection of connection pools for each host in the cluster.\nWhen connection to a Cluster, while it is possible to specify the keyspace to connect to right away, although it is not necessary. It is only required as soon as you want to execute any query.\nBelow is creating a connection to a Cluster with the specified keyspace of cohort:\ncluster = # creates an instance of a Cluster session = cluster.connect(\u0026#39;cohort\u0026#39;) Executing Queries Once a session has been created, it is possible to execute a query with the execute method.\nIf you wanted to create a table called students you could use the execute method like so:\nsession = # session created session.execute(\u0026#34;\u0026#34;\u0026#34; CREATE TABLE IF NOT EXISTS students ( id UUID, name text, email text, PRIMARY KEY(id) ) \u0026#34;\u0026#34;\u0026#34;) # 1 session.shutdown() # 2 Reading When a select is used inside of an execute method, it will return a list of namedtuples with the results of the query.\nrows = session.execute(\u0026#39;SELECT * FROM students;\u0026#39;) for row in rows: # 1 print(row.id, row.name, row.email)  rows is a list of namedtuples that holds all of the data from the table  The information for each namedtuple representing each row can be retrieved as shown above or unpack the values like so:\nfor (id, name, email) in rows: print(id, name, email) It is also possible to retrieve the values by position:\nfor row in rows: print(row[0], row[1], row[2]) Filtering It is possible to use the WHERE clause, but in order for it to work you must add allow filtering to the end of the query.\nAn example of this is shown here:\nrows = session.execute(\u0026#34;SELECT * FROM students WHERE email LIKE \u0026#39;%hotmail%\u0026#39; allow filtering;\u0026#34;) SimpleStatements Every query you put in execute is a type of Statement, there are three types that we will go over in this lesson: SimpleStatements, PreparedStatements, and BatchStatements\nSo far the examples have only showed SimpleStatements, which are simple, unprepared queries. SimpleStatements can also be written like:\nfrom cassandra.query import SimpleStatement rows = session.execute(SimpleStatement(\u0026#34;SELECT * FROM students WHERE email LIKE \u0026#39;%hotmail%\u0026#39; allow filtering;\u0026#34;)) PreparedStatements It is common to want to reuse a Cassandra query multiple times with different values. This can be done with the prepare method. This method can be used in place of literal string queries inside of execute. Place holders for variables are represented with a ?.\nInserting multiple students into the students table without repeating the copied parts, could be accomplished with the following:\nstmt = session.prepare(\u0026#34;INSERT INTO students (id, name, email) VALUES (?,?,?)\u0026#34;) session.execute(stmt, [\u0026#39;1234\u0026#39;, \u0026#39;Sue\u0026#39;, \u0026#39;sue@work.com\u0026#39;]) session.execute(stmt, [\u0026#39;4321\u0026#39;, \u0026#39;Joe\u0026#39;, \u0026#39;joe@work.com\u0026#39;]) Updating all student\u0026rsquo;s names:\nstmt = session.prepare(\u0026#34;UPDATE students SET name=? WHERE name=\u0026#39;%?%\u0026#39; allow filtering\u0026#34;) session.execute(stmt, (\u0026#34;Sue\u0026#34;, \u0026#34;Sal\u0026#34;)) session.execute(stmt, (\u0026#34;Joseph\u0026#34;, \u0026#34;Joe\u0026#34;)) Deleting: to get rid of all students that have a hotmail or aol account:\nstmt = session.prepare(\u0026#34;DELETE students WHERE email LIKE \u0026#39;%?\u0026#39; allow filtering\u0026#34;) session.execute(stmt, (\u0026#34;hotmail.com\u0026#34;, )) session.execute(stmt, (\u0026#34;aol.com\u0026#34;, )) BatchStatements It is possible to execute multiple statements simultaneously with a BatchStatement. This usually is done with Update, Delete, and Insert statements. These statements will be made before the data is available, ensuring atomicity and isolation.\nfrom cassandra.query import BatchStatement students_to_insert = [(\u0026#39;1234\u0026#39;, \u0026#39;Sue\u0026#39;, \u0026#39;sue@work.com\u0026#39;), (\u0026#39;5678\u0026#39;, \u0026#39;Joe\u0026#39;, \u0026#39;joe@work.com\u0026#39;), (\u0026#39;9012\u0026#39;, \u0026#39;Cal\u0026#39;, \u0026#39;cal@work.com\u0026#39;)] insert_student = session.prepare(\u0026#34;INSERT INTO students (id, name, email) VALUES (?, ?)\u0026#34;) batch = BatchStatement() for (id, name, age) in students_to_insert: batch.add(insert_student, (id, name, age)) session.execute(batch) Summary Database adapters like cassandra-python provide many useful functions that allow a straight-forward connection to a database and easy schema and resource creation. The code base requires a minimal amount of imports and allows the use of pure Python code with recognizable statements.\nLab Clone down the repo for the Cassandra Python lab with the following instructions:\ngit clone https://github.homedepot.com/om-labs/python-nonrelational-databases.git cd python-nonrelational-databases/cassandra-python Follow the instructions in the README\n"
},
{
	"uri": "/python/automation/chart-creation/",
	"title": "Chart Creation",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Learn about Pandas and its data structures Generate charts based on data in a json using Pandas  Creating charts from data is a common task that Python is used for. This is going to be a quick lesson on how to use Pandas to generate these charts.\nPandas Pandas is an open-source Python library providing high-performance, easy-to-use data structures and data analysis tools.\nPandas is used in a wide range of fields including academic and commercial domains including finance, economics, Statistics, analytics, etc.\nmatplotlib Pandas plots graphs using the matplotlib library, a package used for data plotting and visualization.\nPandas Data Structures There are three data structures:\n Series Data Frames Panel  Pandas Data Structures\n   Data Structure Dimensions Size Mutable Value Mutable     Series 1  ✔   Data Frames 2 ✔ ✔   Panel 3 ✔ ✔    Series Series is a one-dimensional array like structure with homogeneous data. For example, the following series is a collection of integers:\n                 10 23 56 17 52 61 73 90 26 72    DataFrame DataFrame is a two-dimensional array with heterogenous data, like a table. For example:\n   Name Age Gender Rating     Steve 32 Male 3.45   Lia 28 Female 4.6   Vin 45 Male 3.9   Katie 38 Female 2.78    Panel Panel is a three-dimensional data structure with heterogeneous data. It is hard to represent the panel in graphical representation.\nBut a panel can be illustrated as a container of DataFrame.\nPython Set Up Install all needed libraries for this lesson using this file and running:\npython3 -m venv venv # only if you have not created a virtual environment yet source venv/bin/activate pip3 install -r requirements.txt An example of creating a dataframe from the information in this employees_added.json file:\nimport pandas as pd # 1 df = pd.read_json(\u0026#39;employees_added.json\u0026#39;) # 2 print(df) # 3  import the pandas library convert data from employees_added.json to a dataframe printing out the dataframe  Output:\nyear count 0 2016 500 1 2017 100 2 2018 50 3 2019 200 4 2020 115 To only see the year column from the data frame generated from employees_added.json:\ndf[[\u0026#39;year\u0026#39;]] Output:\nyear 0 2016 1 2017 2 2018 3 2019 4 2020 Types of Graphs Plotting methods allow for a handful of plot styles other than the default line plot.\nThese methods can be provided as a method to plot(), and include:\n .bar() for bar plots .line() for line graph .hist() for histogram .box() for boxplot .area() for area plots .scatter() for scatter plots .pie() for pie plots  Bar Graph The following creates a data frame from this job_counts.json file, filter creates a bargraph from the data frame, and saves the graph at the location provided:\nimport pandas as pd import matplotlib.pyplot as plt df = pd.read_json(\u0026#39;job_counts.json\u0026#39;) df.plot.bar() # 1 plt.savefig(\u0026#34;default_bar_graph.png\u0026#34;) # 2 The previous code snippet would create this image:\nThe following is an example of several bar arguments being used:\ndf.plot.bar(x=\u0026#34;title\u0026#34;, y=\u0026#34;count\u0026#34;, rot=15, legend=False, title=\u0026#34;Number of employees per job\u0026#34;) Output:\nLab\nClone down the repo for the Python Automation lab with the following instructions:\ngit clone https://github.homedepot.com/om-labs/python-automation.git cd python-automation/chart-creation  Follow the instructions in the README\n Line plot The following creates a data frame from this employees_added.json file, filter creates a linegraph from the data frame, and saves the graph at the location provided:\nimport pandas as pd import matplotlib.pyplot as plt df = pd.read_json(\u0026#39;employees_added.json\u0026#39;) df.plot.line(x=\u0026#34;year\u0026#34;, y=\u0026#34;count\u0026#34;, legend=False, xticks=df.year, title=\u0026#34;Number of employees added per year\u0026#34;) plt.savefig(\u0026#34;line_graph.png\u0026#34;) Output:\nLab\nIf you have not already, clone down the repo for the Python Automation lab with the following instructions:\ngit clone https://github.homedepot.com/om-labs/python-automation.git cd python-automation/chart-creation Pie Chart The following creates a data frame from this employees_added.json file, filter creates a pie chart from the data frame, and saves the graph at the location provided:\ncolors = [\u0026#34;#d2eaff\u0026#34;, \u0026#34;#dfffe4\u0026#34;, \u0026#34;#e9dafd\u0026#34;, \u0026#34;#fcffc8\u0026#34;, \u0026#34;#d8bcb5\u0026#34;] # 1 df.plot.pie(x=\u0026#34;year\u0026#34;, y=\u0026#34;count\u0026#34;, labels=df[\u0026#39;year\u0026#39;], colors=colors, autopct=\u0026#39;%1.1f%%\u0026#39;) # 2 plt.savefig(\u0026#34;pie_chart.png\u0026#34;) Lab\nIf you have not already, clone down the repo for the Python Automation lab with the following instructions:\ngit clone https://github.homedepot.com/om-labs/python-automation.git cd python-automation/chart-creation Summary Pandas is a super powerful tool that allows programmers to easily work with data. Pandas combined with matplotlib allows you to generate charts and graphs from this data easily.\n"
},
{
	"uri": "/python/bots/coding_first_bot/",
	"title": "Coding Our First Bot",
	"tags": [],
	"description": "",
	"content": "We\u0026rsquo;ve got everything we need to write the Starter Bot code. Navigate to starterBot directory.\ncd starterBot Create a new file named starterbot.py\ntouch starterbot.py Now open your new Python Project inside Pycharm. You may prefer creating your python(.py) files within Pycharm, that\u0026rsquo;s totally ok!\nCopy the following code at the top of your starterBot.py to import the slackclient API into you python program. We can\u0026rsquo;t use the API before we import it.\nfrom slackclient import SlackClient Now let\u0026rsquo;s see if we can connect to a slack channel!\nAdd the following code to starterBot.py\nslack_client = SlackClient print (help(slack_client)) Now run your program in the pipenv shell, with the following command.\npython starterBot.py What you should see is the list of methods available for use in the API. For now we will focus on 4 different methods:\n rtm_read() rtm_connect() api.call()   Test Bot Connection In starterBot.py and the new code and remove the old code, see below:\nslack_client = SlackClient(\u0026#34;Your Bot Token\u0026#34;) #update this line #print (help(slack_client)) #remove this line def slackConnect(): return slack_client.rtm_connect() print(slackConnect()) #Output  \u0026gt;\u0026gt; True Now save your file and run in the pipenv virtual environment, you should see \u0026ldquo;True\u0026rdquo; in the pipenv shell.\nWhat\u0026rsquo;s happening\n Connecting your code to your app bot by using your token slackConnect() function returns True or False on whether there\u0026rsquo;s a successful connection Prints what\u0026rsquo;s returned by slackConnect()  Great!, now we have a connection to our Bot, now lets create a backend that monitors the activity inside a slack channel and displays it on the console.\n Bot Channel Reading Add the current code to your starterBot.py file.\ndef slackReadRTM(): return slack_client.rtm_read() print slackReadRTM() #----- #Output \u0026gt;\u0026gt; True \u0026gt;\u0026gt; [u\u0026#39;type\u0026#39;: u\u0026#39;hello\u0026#39;] # list Once you run this code, you\u0026rsquo;ll get back a list, it may be empty don\u0026rsquo;t worry about that for now. This list represents the state of the channel at the particular moment the method is call. If we wanted to consistently monitor the activity we need some a loop. edit your code to include the following, notice the added import at the top\nimport time def slackReadRTM(): while True: print (slack_client.rtm_read()) time.sleep(1) print (slackReadRTM()) Now when you run your code you\u0026rsquo;ll see that the list updates every second. Go to the Slack Channel that your bot is in start typing and notice what happens in the terminal.\nAs you can see the rtm_read() method notices any type of activity inside the channel. Send a message inside the channel and see if you can find the actual message in the list returned by the rtm_read() method.\n#when a message is sent in the channel, the returned event will look like [ { \u0026#39;type\u0026#39;: \u0026#39;\u0026lt;Event Type\u0026gt;\u0026#39;, \u0026#39;channel\u0026#39;: \u0026#39;\u0026lt;Channel ID\u0026gt;\u0026#39;, \u0026#39;user\u0026#39;: \u0026#39;\u0026lt;User ID who triggered event\u0026gt;\u0026#39;, \u0026#39;text\u0026#39;: \u0026#39;\u0026lt;Tessage Text\u0026gt;\u0026#39;, \u0026#39;ts\u0026#39;: \u0026#39;\u0026lt;Timestamp\u0026gt;\u0026#39;, \u0026#39;source_team\u0026#39;: \u0026#39;\u0026lt;Channel Source Team\u0026gt;\u0026#39;, \u0026#39;team\u0026#39;: \u0026#39;\u0026lt;Channel Team\u0026gt;\u0026#39; } ] To learn more about all the different key values returned from a slack event, see documentation Here\u0026rsquo;s the message event explanation\nGreat! Now we have some python code that monitors our slack activity. Let\u0026rsquo;s clean our code up a little and make everything one\nfrom slackclient import SlackClient import time slack_client = SlackClient(\u0026#34;xoxb-XXXXXXXXXX-YYYYYYYYYYYYYYY\u0026#34;) def slackConnect_Read(): if slack_client.rtm_connect(): while True: #while slack client is connected print (slack_client.rtm_read()) time.sleep(1) else: print (\u0026#34;Connection Failed\u0026#34;) slackConnect_Read() "
},
{
	"uri": "/golang/databases/postgres-connection/",
	"title": "Connecting to a Postgres Database",
	"tags": [],
	"description": "",
	"content": " Before you follow the rest of this lesson, make sure:\n You have created a database called tool_rental. If you need help with this look here A user with granted access to the database has been created PostgreSQL is installed properly on your machine.   Create a table in tool_rental called tools in the tool_rental database:\nCREATE EXTENSION IF NOT EXISTS \u0026#34;uuid-ossp\u0026#34;; CREATE TABLE tools( ID uuid DEFAULT uuid_generate_v4(), NAME TEXT NOT NULL, DESCRIPTION TEXT NOT NULL, PRICE NUMERIC (5, 2) NOT NULL, QUANTITY INT NOT NULL, CREATED DATE default current_date, UPDATED DATE default current_date ); PostgreSQL Driver We will be using the recommend PostgreSQL driver: github.com/lib/pq.\nUpdate your file structure to look like:\ntool_rental ├── db │ └── psql │ └── set_up.go ├── go.mod ├── main.go └── tools ├── data_store.go ├── model.go └── service.go 3 directories, 6 files At the top of set_up.go, add the following imports:\npackage psql import ( \u0026#34;database/sql\u0026#34; \u0026#34;fmt\u0026#34; _ \u0026#34;github.com/lib/pq\u0026#34; )  The driver is using a blank identifier, meaning you are only importing the package for its side-effects. This registers the driver as being available to the database/sql package.\n Set Up A Postgres connection string set up is: postgres://user:password@host:port/dbname?sslmode=disable\n host: database host port: port the connection is hosted on, default 5432 user: db owner username password: db owner password dbname: database name sslmode: determines the security of the connection. The default is enable. If you place disable, you are using HTTP.  Create a function in db/psql/set_up.go that takes in a connection string for a PostgreSQL database and returns a connection to the database.\nfunc NewPostgresConnection(connection string) (db *sql.DB, err error) { // ... Rest of work will go here  return } Open a Database We now need to use database/sql \u0026rsquo;s Open function to open a database. This function takes in two arguments:\n The driver name, typically is the same name as the package name to avoid confusion. The driver specific configuration string.  sql.Open returns a *sql.DB that is safe for concurrent use by multiple goroutines and maintains its own pool of idle connections. Thus, the sql.Open function should be called just once.\nPlace the following line in place of the comment // ... Rest of work will go here in the NewPostgresConnection function:\ndb, err = sql.Open(\u0026#34;postgres\u0026#34;, connection) if err != nil { return nil, err } sql.Open does not establish any connections to the database OR validate driver connection parameters. This simply prepares the database abstraction for later use. The first actual connection to the underlying datastore will be established lazily for when it\u0026rsquo;s needed for the first time.\nChecking Connection Place the following above the return in the NewPostgresConnection function:\nerr = db.Ping() if err != nil { return nil, err } fmt.Println(\u0026#34;Ping successful\u0026#34;) The above checks that the database is available and accessible.\nThe whole NewPostgresConnection function is:\nfunc NewPostgresConnection(connection string) (db *sql.DB, err error) { db, err = sql.Open(\u0026#34;postgres\u0026#34;, connection) if err != nil { return } err = db.Ping() if err != nil { return nil, err } fmt.Println(\u0026#34;Ping successful\u0026#34;) return } Close a Database The sql.DB object is designed to be long-lived. Don\u0026rsquo;t Open() and Close() databases frequently. Instead, create one sql.DB object for each distinct datastore you need to access, and keep it until the program is done accessing that datastore.\nSo we will be closing the connection after implementation, not in NewPostgresConnection:\ndefer db.Close() Implementation To see if we successfully connected to the database, update main.go the following:\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.homedepot.com/yourldap/tool_rental/db/psql\u0026#34; //replace yourldap with your ldap \t\u0026#34;github.homedepot.com/yourldap/tool_rental/tools\u0026#34; //replace yourldap with your ldap ) func main() { var toolDataStore tools.ToolDataStore // --------- Credentials --------- \thost := os.Getenv(\u0026#34;DB_HOST\u0026#34;)\t//1 \tport := os.Getenv(\u0026#34;PORT\u0026#34;) user := os.Getenv(\u0026#34;DB_USERNAME\u0026#34;) password := os.Getenv(\u0026#34;DB_PASSWORD\u0026#34;) dbname := os.Getenv(\u0026#34;DB_NAME\u0026#34;) sslmode := os.Getenv(\u0026#34;SSL_MODE\u0026#34;) // --------- Create Connection --------- \tconnection := fmt.Sprintf(\u0026#34;postgres://%s:%s@%s:%s/%s?sslmode=%s\u0026#34;, user, password, host, port, dbname, sslmode) db, err := psql.NewPostgresConnection(connection)\t//2 \tif err != nil { fmt.Println(err) } defer db.Close() toolDataStore = //Data store constructor implemented here  toolService := tools.NewToolService(toolDataStore) }  Credentials should not be stored in plain text for safety reasons. Environment variables are safer. Creates a way to interact with your psql data store.  If you were to comment out the last two lines in main and you have set up your environment variables correctly, the above code should give you an output of Ping successful.\nConclusion To connect to a Postgres database, we imported the Postgres database and used the database/sql package to officially connect.\n"
},
{
	"uri": "/react/pillars/advanced-state-mgmt/context-and-hooks/",
	"title": "Context and Hooks",
	"tags": [],
	"description": "",
	"content": "How to combine the Context API and React Hooks for State Management\n Topics 1. Learning Objectives 1.1. Concepts 1.2. Skills   2. Resources   1. Learning Objectives 1.1. Concepts   one\n  two\n  three\n    1.2. Skills   one\n  two\n  three\n      2. Resources   State Management with React Hooks and Context API in 10 Lines of Code!\n  unstated-next\n     "
},
{
	"uri": "/react/pillars/context-api-and-hooks/",
	"title": "Context API and Hooks",
	"tags": [],
	"description": "",
	"content": " Intro to Hooks useState Hook useEffect Hook Context API useContext Hook useRef Hook useReducer Hook customHooks Hook  "
},
{
	"uri": "/web-essentials/webmastery-foundations/css-intro/",
	"title": "CSS Intro",
	"tags": [],
	"description": "",
	"content": "  Learning Objectives Concepts  Define CSS Describe the role of CSS in Building Web Sites List the 3 places where CSS code can go  Skills  Style an HTML element with inline, embedded, or external CSS  Separation of Concerns There is a fundamental principle in Software Engineering that code should be organized based on a separation of concerns. This design principle makes each section address a separate concern.\n To read more about Separation of Concerns, click here.\n In a web site, the source code defining the content should be separate from the source code defining the style. Thus we have:\n HTML - defines the content of the web page CSS - defines the presentation (style / look) of the web page JavaScript - defines the behavior of the web page  By keeping these 3 concerns separate we can more easily manage and modify one without affecting the others.\nWhat is CSS? CSS stands for cascading style sheets. CSS is a language for defining styles (colors, fonts, layout, etc.) that are applied specifically to various parts of an HTML page.\nIf we have the following HTML:\n\u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;News\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;The news goes here.\u0026lt;/p\u0026gt; \u0026lt;h2\u0026gt;Weather\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;The weather goes here.\u0026lt;/p\u0026gt; \u0026lt;h2\u0026gt;Sports\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;The sports goes here.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; We can set all of the \u0026lt;h2\u0026gt; headers to have a blue font with the following CSS:\nh2 { color: blue; } You can also see the results and experiment with this example via this codepen.\nWhat Does Cascading Style Sheets Mean?   Style Sheets - simply means a set of styles that can be applied to an HTML (or other markup) document.\n  Cascading - the CSS styling rules are applied to HTML elements and their children (descendants). For example, if you apply a font color to a div, all of the elements inside the div will inherit that font color (unless they override it).\n  The following will set the font color of all of the text inside the main section to blue (cascading from the section to its children) except the news-flash article will have a font color of red (overriding the cascading blue from its parent but cascading its own color of red to its children).\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Cascading Example\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;cascading-example.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to my Site!\u0026lt;/h1\u0026gt; \u0026lt;section class=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Main Section\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;A simple paragraph\u0026lt;/p\u0026gt; \u0026lt;article class=\u0026#34;news-flash\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;Severe weather alert!\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;Expect heavy rain tonight\u0026lt;/p\u0026gt; \u0026lt;/article\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; body { color: black; } .main { color: blue; background-color: #FFA; } .news-flash { color: red; } Output:\nBasic CSS Here are some of the settings you can control with CSS:\n font colors, sizes, and styles (italics, bold, weight, etc.) background colors and background images spacing (margin and padding) between elements borders around elements size (width and height) of elements table styling (header rows, rows, columns) layout of elements (horizontal, vertical) overflow (how scrolling works when content overflows) text alignment (left-justified, center, right-justified)  CSS 3 CSS 3 added the following capabilities to CSS:\n rounded corners gradients 2D and 3D transformations transitions animations flexbox media queries and many others\u0026hellip;  Where Does CSS Code Go? There are 3 places where you can put CSS Code:\n inline - inside the HTML tag via a style property. inside the HTML document via a \u0026lt;script\u0026gt; tag (usually placed inside the \u0026lt;head\u0026gt; section). in a separate file, called a CSS file, that is loaded from the HTML page.  Inline CSS Inline CSS puts the CSS code directly inside the HTML tags.\ninline CSS:\n\u0026lt;h2 style=\u0026#34;color: blue; font-size: 20px\u0026#34;\u0026gt;News\u0026lt;/h2\u0026gt; \u0026lt;h2 style=\u0026#34;color: red; font-size: 20px\u0026#34;\u0026gt;Weather\u0026lt;/h2\u0026gt; \u0026lt;h2 style=\u0026#34;color: green; font-size: 20px\u0026#34;\u0026gt;Sports\u0026lt;/h2\u0026gt; CSS inside a Style Tag CSS code can be placed inside a style tag in the head section of an HTML document.\nnews-weather-sports-with-style-tag.html:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; \u0026lt;!--1--\u0026gt; h2 { font-size: 20px; } .news { color: blue; } .weather { color: red; } .sports { color: green; } \u0026lt;/style\u0026gt; \u0026lt;!--2--\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h2 class=\u0026#34;news\u0026#34;\u0026gt;News\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;The news goes here.\u0026lt;/p\u0026gt; \u0026lt;h2 class=\u0026#34;weather\u0026#34;\u0026gt;Weather\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;The weather goes here.\u0026lt;/p\u0026gt; \u0026lt;h2 class=\u0026#34;sports\u0026#34;\u0026gt;Sports\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;The sports goes here.\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Start of style block End of style block  CSS in an External CSS File The most common (and modern) approach is to put CSS code in a separate .css file that is then loaded into the HTML page via a link tag. This loading occurs at runtime when the browser is processing the HTML document.\nnews-weather-sports-with-link.html:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34; href=\u0026#34;news-weather-sports-with-link.css\u0026#34;\u0026gt; \u0026lt;!--1--\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h2 class=\u0026#34;news\u0026#34;\u0026gt;News\u0026lt;/h2\u0026gt; \u0026lt;!--2--\u0026gt; \u0026lt;h2 class=\u0026#34;weather\u0026#34;\u0026gt;Weather\u0026lt;/h2\u0026gt; \u0026lt;!--2--\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Link tag that loads the CSS file A CSS class is used to assign a specific styling to the element  news-weather-sports-with-link.css:\nh2 { font-size: 20px; } .news { color: blue; } .weather { color: red; } Class Discussion Turn to your neighbor and discuss the advantages and disadvantages of placing the CSS Code:\n inline (inside the HTML element) inside a script tag in the HTML document in a separate CSS file  Summary  CSS stands for Cascading Style Sheets CSS describes how HTML elements are to be displayed on screen, paper, or in other media CSS saves a lot of work. It can control the layout of multiple web pages all at once External stylesheets are stored in CSS files  Additional References  CSS Tutorial from W3 Schools DEMO: Same Page with Many Stylesheets (taken from here)  "
},
{
	"uri": "/onboarding/cyber-security/",
	"title": "Cybersecurity",
	"tags": [],
	"description": "",
	"content": "General \u0026amp; Cyber Associate Onboarding "
},
{
	"uri": "/cloud/platforms/pcf-foundations/deploy-react-client-app/",
	"title": "Deploying a React client app",
	"tags": [],
	"description": "",
	"content": "Objectives  Deploy a front-end React app Learn to configure a React client app to proxy a Node.js server. Learn the steps to deploy a React app Push a React app to PCF  Configuring the App This is a client app, so we don\u0026rsquo;t have to be concerned with the same things as a Node/Express server like a database connection.\nDynamically resolve the Server RESTful URL We will be using a proxy configuration when running on localhost and accessing our deployed NodeJS server. We will be accessing the server directly when our client is deployed to PCF.\nTo accommodate both scenarios, we will need to adjust our RESTful URLs accordingly. Below is some sample code showing how to dynamically set the URL for AJAX calls.\nWe have a couple of options to do this: We can validate the environment variable, or we can validate using the window.location method.\nExample 1-a. Environment variable validation in a presentation component\nconst SingleTodoList = ({ title, completed, onEdit, id, history }) =\u0026gt; { const apiUrl = process.env.NODE_ENV === \u0026#34;production\u0026#34; // 1.  ? \u0026#34;https://react-knex-todos-wise-mandrill.apps-np.homedepot.com\u0026#34; : \u0026#34;http://localhost:3001\u0026#34; // ...  \u0026lt;button className=\u0026#34;btn btn-link text-white\u0026#34; onClick={() =\u0026gt; { axios.delete(`${apiUrl}/api/todos/${id}`) // 2.  .then(() =\u0026gt; { history.push(\u0026#39;/\u0026#39;); }) }}\u0026gt; Delete\u0026lt;/button\u0026gt;  Use the proxy config if the environment variable matches \u0026quot;production\u0026quot;. Use template literal to embed the apiUrl variable.  Example 1-b. Environment variable validation in a container component\nclass ItemsBody extends Component { constructor(props){ super(props) this.state = { loading: true, todos: {} } this.apiUrl = process.env.NODE_ENV === \u0026#34;production\u0026#34; // 1.  ? \u0026#34;https://react-knex-todos-wise-mandrill.apps-np.homedepot.com\u0026#34; : \u0026#34;http://localhost:3001\u0026#34; } // ...  componentDidMount(){ axios.get(this.apiUrl + \u0026#39;/api/todos\u0026#39;) // 2.  .then(todos =\u0026gt; { this.setState({ loading: false, todos: todos.data }) }) }  Use the proxy config if the environment variable matches \u0026quot;production\u0026quot;. Use string concatenation to embed the apiUrl variable.  Example 2. Window validation\nconst isLocalhost = Boolean( window.location.hostname === \u0026#39;localhost\u0026#39; || // 1.  // [::1] is the IPv6 localhost address.  window.location.hostname === \u0026#39;[::1]\u0026#39; || // 127.0.0.1/8 is considered localhost for IPv4.  window.location.hostname.match( /^127(?:\\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/ ) ); // choose between the full url or the proxy config in package.json // (which avoids cors errors when running the client on localhost) const apiUrl = isLocalhost ? \u0026#39;/api/todos\u0026#39; : \u0026#39;https://your-server-app-name.apps-np.homedepot.com/api/todos\u0026#39;;  window.location gets/sets the location, or current URL, of the window object.  Add a Proxy Add a proxy configuration to your client\u0026rsquo;s package.json file:\n\u0026#34;proxy\u0026#34;: \u0026#34;https://your-server-app-name.apps-np.homedepot.com\u0026#34;, Remember to use your server URL for the proxy.\nTest on localhost Test your client using yarn start and hitting your PCF deployed server via the proxy config.\nCreate manifest.yml file Create a manifest.yml file with the following content:\n--- applications: - name: your-client-app-name buildpack: staticfile_buildpack command: null path: build Remember to use your client name in the name field above!\nCreate a Staticfile If you create a file named Staticfile in the root directory of your app, Cloud Foundry automatically uses the Staticfile buildpack when you push your app.\nThe Staticfile file can be an empty file, or it can contain configuration settings for your app.\npushstate: enabled // 1. http_strict_transport_security: true // 2. http_strict_transport_security_include_subdomains: true // 3. http_strict_transport_security_preload: true // 4.   Pushstate routing: Keeps browser-visible URLs clean for client-side JavaScript apps that serve multiple routes. For example, pushstate routing allows a single JavaScript file to route to multiple anchor-tagged URLs that look like /some/path1 instead of /some#path1.\n  HTTP Strict Transport Security (HSTS): Causes NGINX to respond to all requests with the header Strict-Transport-Security: max-age=31536000. This forces receiving browsers to make all subsequent requests over HTTPS. This setting defaults to a max-age of one year. Note: Because this setting persists in browsers for a long time, only enable this setting after you ensure that you have completed your app configuration.\n  HSTS includes subdomains: Causes NGINX to respond to all requests with the following header: Strict-Transport-Security: max-age=31536000; includeSubDomains This forces browsers to make all subsequent requests over HTTPS including subdomains. This setting defaults to a max-age of one year. Note: Setting this property to true also makes http_strict_transport_security default to true.\n  HSTS preload: Causes NGINX to respond to all requests with the following header: Strict-Transport-Security: max-age=31536000; includeSubDomains; preload This forces browsers to make all subsequent requests over HTTPS including subdomains and requests inclusion in browser-managed HSTS preload lists. For more information, see https://hstspreload.org. This setting defaults to a max-age of one year. This setting defaults to a max-age of one year. Note: Setting this property to true also makes http_strict_transport_security and http_strict_transport_security_include_subdomains default to true.\n  Do a dist build and cf push yarn build cd build cp ./manifest.yml . cp ./Staticfile ./Staticfile cf push Test It Out  Verify that your client app is running via Pivotal Apps Manager (browser UI) Open your client in your browser and test it out  Summary  We configured our React client app to proxy a Node.js server. Prepared our React app for deployment by creating a manifest, Staticfile, and build. Pushed our app to PCF and tested it.  "
},
{
	"uri": "/python/web-framework/django_db/",
	"title": "Django Databases",
	"tags": [],
	"description": "",
	"content": "Next we\u0026rsquo;re going to create the database for our application, but first we will create the the Models or database tables our application will use.\nUse Case Diagram We are making a Store Finder application that will have a database of market and store information for the company.\n The app will also have the ability to get directions to stores from a given location and save them as trips, but you will do that part on your own 😁.\n Model Diagram Database setup¶ Navigate to store_finder/settings.py. It\u0026rsquo;s a normal Python module with module-level variables representing Django settings.\nBy default, the configuration uses SQLite. If you\u0026rsquo;re new to databases, or you\u0026rsquo;re just interested in trying Django, this is the easiest store. SQLite is included in Python, so you won\u0026rsquo;t need to install anything else to support your database. When starting your first real project, however, you may want to use a more scalable database like PostgreSQL, to avoid database-switching headaches down the road.\nIf you wish to use another database, install the appropriate database bindings and change the following keys in the DATABASES default item to match your database connection settings:\n ENGINE – Either 'django.db.backends.sqlite3', 'django.db.backends.postgresql', 'django.db.backends.mysql', or 'django.db.backends.oracle'. Other backends are also available. NAME – The name of your database. If you\u0026rsquo;re using SQLite, the database will be a file on your computer; in that case, NAME should be the full absolute path, including filename, of that file. The default value, os.path.join(BASE_DIR, 'db.sqlite3'), will store the file in your project directory.  If you are not using SQLite as your database, additional settings such as USER, PASSWORD, and HOST must be added. For more details, see the reference documentation for DATABASES.\nFor databases other than SQLite\nIf you\u0026rsquo;re using a database besides SQLite, make sure you\u0026rsquo;ve created a database by this point. Do that with \u0026ldquo;CREATE DATABASE database_name;\u0026rdquo; within your database\u0026rsquo;s interactive prompt.\nAlso make sure that the database user provided in store_finder/settings.py has \u0026ldquo;create database\u0026rdquo; privileges. This allows automatic creation of a test database which will be needed in a later tutorial.\nIf you\u0026rsquo;re using SQLite, you don\u0026rsquo;t need to create anything beforehand - the database file will be created automatically when it is needed.\nWhile you\u0026rsquo;re editing store_finder/settings.py, set TIME_ZONE to your time zone.\nAlso, note the INSTALLED_APPS setting at the top of the file. That holds the names of all Django applications that are activated in this Django instance. Apps can be used in multiple projects, and you can package and distribute them for use by others in their projects.\n Installed Apps By default, INSTALLED_APPS contains the following apps, all of which come with Django:\n django.contrib.admin – The admin site. You’ll use it shortly. django.contrib.auth – An authentication system. django.contrib.contenttypes – A framework for content types. django.contrib.sessions – A session framework. django.contrib.messages – A messaging framework. django.contrib.staticfiles – A framework for managing static files.  These applications are included by default as a convenience for the common case.\nSome of these applications make use of at least one database table, though, so we need to create the tables in the database before we can use them. To do that, run the following command:\n$ python manage.py migrate You should now see a file called db.sqlite3 at the same level as the manage.py file inside django_apps/storefinder/.\nThe migrate command looks at the INSTALLED_APPS setting and creates any necessary database tables according to the database settings in your store_finder/settings.py file and the database migrations shipped with the app (we\u0026rsquo;ll cover those later). You\u0026rsquo;ll see a message for each migration it applies. If you\u0026rsquo;re interested, run the command-line client for your database and type dt (PostgreSQL), SHOW TABLES; (MySQL), .schema (SQLite), or SELECT TABLE_NAME FROM USER_TABLES; (Oracle) to display the tables Django created.\n The default applications are included for the common case, but not everybody needs them. If you don\u0026rsquo;t need any or all of them, feel free to comment-out or delete the appropriate line(s) from INSTALLED_APPS before running migrate. The migrate command will only run migrations for apps in INSTALLED_APPS.\n Creating models¶ Now we\u0026rsquo;ll define your models – essentially, your database layout, with additional metadata.\n ####Philosophy A model is the single, definitive source of truth about your data. It contains the essential fields and behaviors of the data you\u0026rsquo;re storing. Django follows the DRY Principle. The goal is to define your data model in one place and automatically derive things from it.\n In our simple location app, we\u0026rsquo;ll create two models: Market and Store. A Market has a market and a publication date. A Store has two fields: the text of the store and a vote tally. Each Store is associated with a Market.\nThese concepts are represented by simple Python classes. Edit the locations/models.py file so it looks like this:\n\u0026#34;\u0026#34;\u0026#34; title: locations/models.py \u0026#34;\u0026#34;\u0026#34; from django.db import models class Market(models.Model): id = models.IntegerField(primary_key=True, editable=False) number = models.IntegerField(default=0) name = models.CharField(max_length=255) num_stores = models.IntegerField(default=0) # TODO: METHODS GO HERE class Store(models.Model): id = models.IntegerField(primary_key=True, editable=False) name = models.CharField(max_length=30) number = models.IntegerField(default=0) phone = models.CharField(max_length=20) date_opened = models.DateTimeField(\u0026#39;date opened\u0026#39;, null=True) address = models.CharField(max_length=255) market = models.ForeignKey(Market, on_delete=models.CASCADE) # TODO: METHODS GO HERE Each model is represented by a class that subclasses django.db.models.Model. Each model has a number of class variables, each of which represents a database field in the model.\nEach field is represented by an instance of a Field class – e.g., CharField for character fields and DateTimeField for datetimes. This tells Django what type of data each field holds.\nThe name of each Field instance (e.g. date_opened or address) is the field\u0026rsquo;s name, in machine-friendly format. You\u0026rsquo;ll use this value in your Python code, and your database will use it as the column name.\nYou can use an optional first positional argument to a Field to designate a human-readable name. That\u0026rsquo;s used in a couple of introspective parts of Django, and it doubles as documentation. If this field isn\u0026rsquo;t provided, Django will use the machine-readable name. In this example, we\u0026rsquo;ve only defined a human-readable name for Store.date_opened . For all other fields in this model, the field\u0026rsquo;s machine-readable name will suffice as its human-readable name.\nSome Field classes have required arguments. CharField, for example, requires that you give it a max_length. That\u0026rsquo;s used not only in the database schema, but in validation, as we\u0026rsquo;ll soon see.\nA Field can also have various optional arguments; in this case, we\u0026rsquo;ve set the default value of num_stores in Market to 0.\nFinally, note a relationship is defined, using ForeignKey. That tells Django each Store is related to a single Market. Django supports all the common database relationships: many-to-one, many-to-many, and one-to-one.\n Activating models¶ That small bit of model code gives Django a lot of information. With it, Django is able to:\n Create a database schema (CREATE TABLE statements) for this app. Create a Python database-access API for accessing Market and Store objects.  But first we need to tell our project that the locations app is installed.\n ####Philosophy Django apps are \u0026ldquo;pluggable\u0026rdquo;: You can use an app in multiple projects, and you can distribute apps, because they don\u0026rsquo;t have to be tied to a given Django installation.\n To include the app in our project, we need to add a reference to its configuration class in the INSTALLED_APPS setting. The LocationsConfig class is in the locations/apps.py file, so its dotted path is locations.apps.LocationsConfig. Edit the store_finder/settings.py file and add that dotted path to the INSTALLED_APPS setting. It\u0026rsquo;ll look like this:\n# store_finder/settings.py INSTALLED_APPS = [ \u0026#39;locations.apps.LocationsConfig\u0026#39;, \u0026#39;django.contrib.admin\u0026#39;, \u0026#39;django.contrib.auth\u0026#39;, \u0026#39;django.contrib.contenttypes\u0026#39;, \u0026#39;django.contrib.sessions\u0026#39;, \u0026#39;django.contrib.messages\u0026#39;, \u0026#39;django.contrib.staticfiles\u0026#39;, ] Now Django knows to include the locations app. Let\u0026rsquo;s run another command:\n$ python manage.py makemigrations You should see something similar to the following:\nMigrations for \u0026#39;locations\u0026#39;: store_finder/locations/migrations/0001_initial.py - Create model Market - Create model Store By running makemigrations, you\u0026rsquo;re telling Django that you\u0026rsquo;ve made some changes to your models (in this case, you\u0026rsquo;ve made new ones) and that you\u0026rsquo;d like the changes to be stored as a migration.\nMigrations are how Django stores changes to your models (and thus your database schema) - they\u0026rsquo;re just files on disk. You can read the migration for your new model if you like; it\u0026rsquo;s the file locations/migrations/0001_initial.py. Don\u0026rsquo;t worry, you\u0026rsquo;re not expected to read them every time Django makes one, but they\u0026rsquo;re designed to be human-editable in case you want to manually tweak how Django changes things.\nThere\u0026rsquo;s a command that will run the migrations for you and manage your database schema automatically - that\u0026rsquo;s called migrate, and we\u0026rsquo;ll come to it in a moment - but first, let\u0026rsquo;s see what SQL that migration would run. The sqlmigrate command takes migration names and returns their SQL:\n$ python manage.py sqlmigrate locations 0001 You should see something similar to the following (we\u0026rsquo;ve reformatted it for readability):\nBEGIN; -- -- Create model Market -- CREATE TABLE \u0026#34;locations_market\u0026#34; (\u0026#34;id\u0026#34; integer NOT NULL PRIMARY KEY AUTOINCREMENT, \u0026#34;number\u0026#34; integer NOT NULL, \u0026#34;name\u0026#34; varchar(255) NOT NULL, \u0026#34;num_stores\u0026#34; integer NOT NULL); -- -- Create model Store -- CREATE TABLE \u0026#34;locations_store\u0026#34; (\u0026#34;id\u0026#34; integer NOT NULL PRIMARY KEY AUTOINCREMENT, \u0026#34;name\u0026#34; varchar(30) NOT NULL, \u0026#34;number\u0026#34; integer NOT NULL, \u0026#34;phone\u0026#34; varchar(20) NOT NULL, \u0026#34;date_opened\u0026#34; datetime NULL, \u0026#34;address\u0026#34; varchar(255) NOT NULL, \u0026#34;market_id\u0026#34; integer NOT NULL REFERENCES \u0026#34;locations_market\u0026#34; (\u0026#34;id\u0026#34;) DEFERRABLE INITIALLY DEFERRED); -- -- Create model Trip -- CREATE TABLE \u0026#34;locations_trip\u0026#34; (\u0026#34;id\u0026#34; integer NOT NULL PRIMARY KEY AUTOINCREMENT, \u0026#34;date\u0026#34; datetime NULL, \u0026#34;starting_loc\u0026#34; varchar(255) NOT NULL, \u0026#34;destination\u0026#34; varchar(255) NOT NULL); CREATE INDEX \u0026#34;locations_store_market_id_8c2704e8\u0026#34; ON \u0026#34;locations_store\u0026#34; (\u0026#34;market_id\u0026#34;); COMMIT; Note the following:\n The exact output will vary depending on the database you are using. The example above is generated for PostgreSQL. Table names are automatically generated by combining the name of the app (locations) and the lowercase name of the model – market and store. (You can override this behavior.) Primary keys (IDs) are added automatically. (You can override this, too.) By convention, Django appends _id to the foreign key field name. (Yes, you can override this, as well.) The foreign key relationship is made explicit by a FOREIGN KEY constraint. Don\u0026rsquo;t worry about the DEFERRABLE parts; that\u0026rsquo;s just telling PostgreSQL to not enforce the foreign key until the end of the transaction. It\u0026rsquo;s tailored to the database you\u0026rsquo;re using, so database-specific field types such as auto_increment (MySQL), serial (PostgreSQL), or integer primary key autoincrement (SQLite) are handled for you automatically. Same goes for the quoting of field names – e.g., using double quotes or single quotes. The sqlmigrate command doesn\u0026rsquo;t actually run the migration on your database - it just prints it to the screen so that you can see what SQL Django thinks is required. It\u0026rsquo;s useful for checking what Django is going to do or if you have database administrators who require SQL scripts for changes.  If you\u0026rsquo;re interested, you can also run python manage.py check; this checks for any problems in your project without making migrations or touching the database.\nNow, run migrate again to create those model tables in your database:\n$ python manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, locations, sessions Running migrations: Applying locations.0001_initial... OK  migrate command The migrate command takes all the migrations that haven\u0026rsquo;t been applied (Django tracks which ones are applied using a special table in your database called django_migrations) and runs them against your database - essentially, synchronizing the changes you made to your models with the schema in the database.\nMigrations are very powerful and let you change your models over time, as you develop your project, without the need to delete your database or tables and make new ones - it specializes in upgrading your database live, without losing data. We\u0026rsquo;ll cover them in more depth in a later part of the tutorial, but for now, remember the three-step guide to making model changes:\n python manage.py migrate python manage.py makemigrations python manage.py migrate  The reason that there are separate commands to make and apply migrations is because you\u0026rsquo;ll commit migrations to your version control system and ship them with your app; they not only make your development easier, they\u0026rsquo;re also usable by other developers and in production.\nRead the django-admin documentation for full information on what the manage.py utility can do.\n"
},
{
	"uri": "/cloud/containers/docker-fundamentals/installation/",
	"title": "Docker Installation",
	"tags": [],
	"description": "",
	"content": "Concepts  Installing Docker Components on a Mac Installing Docker Components on Windows Installing Docker on Server on Demand Overview of the Components  Mac Installation You have 2 options for installing Docker on a Mac:\n Installation via Homebrew Installation of Docker Desktop for Mac  We will look at both options below.\nBrew Install Docker Client It is possible to install all the tools needed for Docker via Homebrew. To install the Docker CLI Client, you can use brew:\nbrew install docker Now you have access to the docker command. The CLI is the primary way that most users interact with the Docker daemon.\nYou can see that docker has been installed by typing:\ndocker version This should give you an output similar to:\nClient: Docker Engine - Community Version: 19.03.5 API version: 1.40 Go version: go1.12.12 Git commit: 633a0ea Built: Wed Nov 13 07:22:34 2019 OS/Arch: darwin/amd64 Experimental: false Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? Notice that the last line talks about a missing daemon! The CLI can interact with a daemon that is running on the same system or a remote Docker daemon. We will go in further depth about this later.\nDocker Desktop for Mac To install the other tools needed to properly run Docker locally on your machine, we are going to install Docker for Mac, a product made by Docker, Inc.\n When installing Docker for Mac you do not need to install anything via brew install since everything is included with Docker for Mac.\n Docker Desktop installs and runs a LinuxKit VM on your machine. This VM will run Linux with the Docker Engine running inside the VM. This Docker Engine will be exposed to your Mac. The Docker Engine is able to do this with HyperKit, a super lightweight hypervisor.\n⚠️⚠️⚠️\nIn order to install Docker Desktop for Mac, make sure:\n Mac hardware must be a 2010 or newer model macOS must be version 10.14 or newer. At least 4 GB of RAM. VirtualBox prior to version 4.3.30 must not be installed as it is not compatible with Docker Desktop.  ⚠️⚠️⚠️\nGo to https://docs.docker.com/docker-for-mac/install/ and click on Download from Docker Hub.\nWith the above installation, we have installed Docker Engine, Docker CLI client, Docker Compose, Notary, Kubernetes, and Credential Helper.\nWindows Installation ⚠️⚠️⚠️\nIn order to install Docker Desktop for Windows, make sure:\n Windows 10 64-bit Hyper-V and Containers Windows features must be enabled. The following hardware prerequisites are required to successfully run Client Hyper-V on Windows 10:  64 bit processor with Second Level Address Translation (SLAT) 4GB system RAM BIOS-level hardware virtualization support must be enabled in the BIOS settings. For more information, see Virtualization.    ⚠️⚠️⚠️\n Go to https://docs.docker.com/docker-for-windows/install/ and click on Download from Docker Hub. Double-click Docker Desktop Installer.exe to run the installer. Follow the instructions on the installation wizard to accept the license, authorize the installer, and proceed with the install. Click Finish on the setup complete dialog and launch the Docker Desktop application.  With the above installation, we have installed Docker Engine, Docker CLI client, Docker Compose, Notary, Kubernetes, and Credential Helper.\nInstalling Docker on Server on Demand Coming soon\u0026hellip;\nTesting Your Installation To test out your installation, try running the following command from a terminal window:\ndocker run hello-world You should see output similar to the following:\nHello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026#34;hello-world\u0026#34; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. For more Docker fun, you can try the following commands:\ndocker run --name simple-nginx -p 8080:80 -d nginx # downloads the nginx image, then creates and runs a container curl localhost:8080 # test the container running nginx via curl docker stop simple-nginx # stops the container docker rm simple-nginx # removes the container Components Explained You can describe Docker as a client/server application. The daemon is the server, and the CLI is 1 of many clients.\nThe below image shows the pieces of Docker:\nClient The client is a command line tool that uses Docker APIs to control or interact with the Docker daemon through scripting or direct CLI commands.\nDOCKER_HOST The docker_host is composed of:\n daemon: the background service running on the host that manages building, running and distributing Docker containers. images: The blueprint of our application which form the basis of containers. containers: Actual implementations of an Image and run the actual application.  Registry You can think of the registry as a directory of all available Docker images. If required, one can host their own Docker registries and can use them for pulling images.\nDocker Hub is a public, remote registry that anyone can use, and Docker is configured to look for images on Docker Hub by default. You can even run your own private registry. If you use Docker Datacenter (DDC), it includes Docker Trusted Registry (DTR).\nSummary  Installing Docker is very simple. Docker Desktop provides a powerful runtime environment for creating, downloading, publishing, and running your Docker containers. Docker integrates well with your Mac or Windows machine for rapid development and testing of images and containers.  "
},
{
	"uri": "/cloud/containers/developing-with-docker/int-testing/volumes/",
	"title": "Docker Volumes",
	"tags": [],
	"description": "",
	"content": "Concepts  Describe how volumes allow containers to persisting data Compare bind mounts vs. docker volumes Explain how to create a volume Describe how volumes can be shared between containers  Persisting Data For the most part docker containers are ephimeral. Their purpose to be consistent and only run as long as needed. It is impractical or impossible to persist such data as logs, databases, and custom created website content.\nData persistence is accomplished with Docker Volumes. Docker volumes can be created when containers are created, or independent of any container. Volumes can be attached to containers at a later time.\nVolumes vs. Bind Mounts Volumes are the preferred method to persist data over bind mounts. Volumes are NOT dependent on the directory structure of the host machine.\nThere are many benefits of Volumes over Bind Mounts:\n Volumes are easier to back up or migrate than bind mounts. You can manage volumes using Docker CLI commands or the Docker API. Volumes work on both Linux and Windows containers. Volumes can be more safely shared among multiple containers. Volume drivers let you store volumes on remote hosts or cloud providers, to encrypt the contents of volumes, or to add other functionality. New volumes can have their content pre-populated by a container.  Creating Volumes Independently The docker volume create can be used to create a volume independent of a container, as in the following example.\ndocker volume create --name NameOfVolume Using the -v flag can then be used to attach the volume to a container.\ndocker run -it -v NameOfVolume:/dataDir ubuntu Shelled into the container, you can then access (and possibly edit) data and files on that volume.\necho \u0026#34;Hello, World!\u0026#34; \u0026gt; /dataDir/hello.txt We can use the inspect command to view the volume.\ndocker volume inspect NameOfVolume # NameOfVolume is the name of your volume The print out will look similar to below:\nOutput [ { \u0026#34;CreatedAt\u0026#34;: \u0026#34;2020-06-12T11:57:54Z\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Labels\u0026#34;: {}, \u0026#34;Mountpoint\u0026#34;: \u0026#34;/var/lib/docker/volumes/NameOfVolume/_data\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;NameOfVolume\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34; } ] The volume can then be deleted using volume rm.\ndocker volume rm NameOfVolume Created with Container Creation The following command will create a volume at the same time as a container.\ndocker run -ti --name=Container2 -v NameOfVolume:/dataDir ubuntu The new volume will continue to exist even after the container is deleted.\nCreating based off existing directory We can create a docker volume from a pre-existing directory.\nThe following command will create the DataVolume3 from the var directory.\ndocker run -ti --rm -v DataVolume3:/var ubuntu Same Volume Multiple Containers The same volume can share persisted data among multiple containers.\nRead-Only In order to attach a volume to a container as read-only we need only to add :ro to the end of the volume name.\ndocker run -ti --name=Container6 --volumes-from Container4:ro ubuntu Conclusion We can persist data using volumes. We can keep logs, data files, and databases in volumes. The volumes can be created independently, with a container, or based-off a pre-existing directory. We can inspect them and delete them. We can also share volumes among many containers. Volumes can also be read-only.\nResources  Docker Docs Digital Ocean - Communicating Containers  "
},
{
	"uri": "/javascript/foundations/labs/expressions-lab/",
	"title": "Expressions Lab",
	"tags": [],
	"description": "",
	"content": "Let\u0026rsquo;s code a Temperature Converter.\nStep 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch expressions.js Add the following code to expressions.js:\nlet far = 77; // TODO: calculate farToCel by subtracting 32 from far, then multiply by 5, then divide by 9 let farToCel = null; // TODO: calculate celToFar by multiplying farToCel by 9, then divide by 5, then add 32 let celToFar = null; // the following should print \u0026#34;25 degrees Celsius is 77 degrees Fahrenheit\u0026#34; console.log(farToCel, \u0026#39;degrees Celsius is\u0026#39;, celToFar, \u0026#39;degrees Fahrenheit\u0026#39;); Step 2: Complete the Code and Test Complete the TODOs in the above code. Remember PeMDAS - parentheses, multiplication, division, addition, subtraction.\nTest your solution with:\nnode expressions.js The expected output is:\n25 degrees Celsius is 77 degrees Fahrenheit "
},
{
	"uri": "/java/foundations/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "Concepts  Installing the JVM, JRE, and JDK Setting your classpath IDE: IntelliJ  Skills  Configure the Java classpath Write a simple Java Program Compile and run a simple Java Program Install and run a Java IDE  Installing Java  ℹ️ The following instructions are for MacOS. For other instructions check these resources:\n Windows Linux    From your terminal, check for installation java -version  To download or update check out Java SE Downloads  Download appropriate JDK (\u0026gt;= v11)   Open the disk image and follow installation instructions From your terminal, run java -version and assure installation was successful    Setting up profiles  install gradle brew install gradle locate you Java home directory  usually /Library/Java/JavaVirtualMachines/\u0026lt;jdk-version\u0026gt;/Contents/Home/   open your shell profile  like ~/.bash_profile for bash like ~/.zshrc for zsh   add the line export JAVA_HOME=/Library/Java/JavaVirtualMachines/\u0026lt;jdk-version\u0026gt;/Contents/Home/  Configure IDE  ℹ️ The following instructions are for IntelliJ IDEA.\n  Open IntelliJ Idea On open dialogue, click Configure in the bottom right  Go to Project Defaults \u0026gt; Project Structure   Under Project SDK, check your java version  If no SDK is listed, click New... Generally, Java is installed correctly, it should open directly to your JDK home, which would have a path similar to /Library/Java/JavaVirtualMachines/jdk-11.0.4.jdk/Contents/Home. If not, navigate to your home Java folder (which again should be similar to said path), and click Open. Under Project SDK, it should now display your Java version   Click OK  Hello, Java - Writing Your First Java Program Open IntelliJ and follow these steps:\n click Create New Project click on Gradle in the left menu and make sure your Java version is listed at the top. Click Next. set GroupId to com.homedepot.om.student and ArtifactId to HelloJava. Click next. click Next (use default values) choose the parent folder and name the project HelloJava right click your src/main/java folder and create a new package com.homedepot.om.student right click your new package and create a Java Class SayHello create a class that looks like this:  package com.homedepot.om.student; public class SayHello { public static void main (String[] args) { System.out.println(\u0026#34;Hello World!\u0026#34;); } } Compiling and Running the Program Terminal  Open the terminal cd to your project src/main/java folder Compile your Class into Java Bytecode by running javac com/homedepot/om/student/SayHello.java run java com/homedepot/om/student/SayHello  JAR  create jar file jar cfe com/homedepot/om/student/SayHello.jar \u0026lt;package\u0026gt;.\u0026lt;Classname\u0026gt; \u0026lt;path to class file\u0026gt; run the jar java -jar com/homedepot/om/student/SayHello.jar  IntelliJ  Right click your main class and click run   NOTE: this will be standard for most development\n Additional Resources  IntelliJ  "
},
{
	"uri": "/react/foundations/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "Getting started with the create-react-app CLI.\nConcepts  Introduce React syntax and JSX Talk about Components  Skills  Use the React CLI to create a new React application Understand how to setup and configure a React app Become familiar with the React application structure Build a basic React Component  The create-react-app CLI  create-react-app is a simple CLI (Command Line Interface) program for creating new React projects. When using create-react-app, there is a lot going on behind the scenes:  creating a package.json file with all required dependencies creating initial source files and project folders configuration for Webpack, Babel, Jest, eslint, Typescript, SASS, and others.    You can find the documentation for using create-react-app here.\nUsing npx  We are going to use npx to ensure that we always run the latest version of create-react-app. npx is a utility for executing node packages without first needing to install them. npx comes with npm 5.2+ and higher.  Installing yarn  You will also need yarn as create-react-app uses yarn by default. If you don\u0026rsquo;t already have yarn installed, you can install it with:  npm i -g yarn I Don\u0026rsquo;t Want To (or cannot) Use yarn If you need to use npm instead of yarn you can skip installing yarn and instead use the following command to run create-react-app:\nnpx create-react-app hello-react --use-npm Our First React Project Now let\u0026rsquo;s create a React project with npx and create-react-app:\nnpx create-react-app hello-react # create the project cd hello-react # cd into the new project yarn start # start a dev server running your new React project You should now be able to see your React app running in your browser at http://localhost:3000.\nProject Walkthrough Open your text editor and navigate to src/App.js. You should notice something similar to the following code:\nimport React from \u0026#39;react\u0026#39;; import logo from \u0026#39;./logo.svg\u0026#39;; import \u0026#39;./App.css\u0026#39;; function App() { return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; \u0026lt;header className=\u0026#34;App-header\u0026#34;\u0026gt; \u0026lt;img src={logo} className=\u0026#34;App-logo\u0026#34; alt=\u0026#34;logo\u0026#34; /\u0026gt; \u0026lt;p\u0026gt; Edit \u0026lt;code\u0026gt;src/App.js\u0026lt;/code\u0026gt; and save to reload. \u0026lt;/p\u0026gt; \u0026lt;a className=\u0026#34;App-link\u0026#34; href=\u0026#34;https://reactjs.org\u0026#34; target=\u0026#34;_blank\u0026#34; rel=\u0026#34;noopener noreferrer\u0026#34; \u0026gt; Learn React \u0026lt;/a\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;/div\u0026gt; ); } export default App; The above is starter code that we can modify as needed. For example, let\u0026rsquo;s change this component to the following.\nimport React from \u0026#39;react\u0026#39;; // import logo from \u0026#39;./logo.svg\u0026#39;; // remove (or comment out) the logo import - we don\u0026#39;t need it import \u0026#39;./App.css\u0026#39;; function App() { return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; \u0026lt;-- keep the main div --\u0026gt; \u0026lt;h3\u0026gt;Hello World\u0026lt;/h3\u0026gt; \u0026lt;-- insert a level 3 header --\u0026gt; \u0026lt;/div\u0026gt; ); } export default App; // export the App component Hot Module Reloading  If your server is still running, you\u0026rsquo;ll notice that the page automatically refreshes when you update and save any source files. This is due to something known as hot module reloading which helps us to rapidly code our React app.  React Components Some rules about all React Components:\n Each component must return a JSX expression You can use parentheses to return multi-line JSX expressions There must be exactly 1 element being returned.  If you have sibling elements make sure to wrap them in a container (such as a div, section, article, nav, etc.).    How is this rendered? So, how exactly are components rendered to the DOM? To find out, first navigate to public/index.html and you\u0026rsquo;ll see something similar to:\n\u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; {/* The entire React application is mounted and rendered here */} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Note: the above example has been shortened for clarity\n Next navigate to src/index.js which should look similar to:\nimport React from \u0026#39;react\u0026#39;; // import the React library import ReactDOM from \u0026#39;react-dom\u0026#39;; // import the ReactDOM library for web applications import App from \u0026#39;./App\u0026#39;; // import our App component import \u0026#39;./index.css\u0026#39;; // import some CSS  ReactDOM.render( // Make a call to ReactDOM\u0026#39;s render method  \u0026lt;App /\u0026gt;, // Pass in the component you want to render - in our case, App  document.getElementById(\u0026#39;root\u0026#39;) // Attach our App component to this DOM node ); A few more things to note:\n We are importing React and ReactDOM separately. We are using ReactDOM to render an instance of our class to an element in the DOM. The root node in the HTML file is the same root node that we find in the index.js file.  This is how React loads our main App component into the DOM.    src vs public vs build The create-react-app CLI creates a project with 2 folders, src, and public and includes the build scripts (via the react-scripts module) for generating the build folder.\n   Folder Description     src Contains the src code for your React application.   public Contains boilerplate code and static files (/react, fonts, etc.).   build Contains the optimized src code ready for Production.    The build folder:\n is generated when you run yarn build or npm run build contains optimized files for deployment into Production  files are concatenated, minified, and have hashed / fingerprinted file names.   is usually included in the .gitignore file since it is generated and doesn\u0026rsquo;t need to be tracked in Git.  Recommended Project Structure  As a project grows in features it is important to keep things organized. Below is a recommended way to organize your React source files, CSS files, and test files.  $ tree . ├── .gitignore ├── README.md ├── package.json ├── public │ ├── favicon.ico │ ├── images │ │ ├── mountain.gif │ │ └── tiger.png │ ├── index.html │ └── manifest.json ├── src │ ├── components │ │ ├── app │ │ │ ├── App.css │ │ │ ├── App.js │ │ │ ├── App.test.js │ │ ├── navbar │ │ │ ├── Navbar.css │ │ │ ├── Navbar.js │ │ │ └── Navbar.test.js │ │ └── todo │ │ ├── Todo.css │ │ ├── Todo.js │ │ └── Todo.test.js │ ├── index.css │ ├── index.js │ ├── logo.svg │ └── serviceWorker.js └── yarn.lock  Here we have created a src/components directory to hold all of your React components. We have also created subdirectories under src/components for each component / responsibility, leaving only index.js at the root.  Project Configuration Next we need to discuss the package.json file, the react-scripts dependency, and ejecting.\nNotice that package.json is very concise, looking something like:\n{ \u0026#34;name\u0026#34;: \u0026#34;hello-react\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, \u0026#34;private\u0026#34;: true, \u0026#34;dependencies\u0026#34;: { \u0026#34;@testing-library/jest-dom\u0026#34;: \u0026#34;^4.2.4\u0026#34;, \u0026#34;@testing-library/react\u0026#34;: \u0026#34;^9.3.2\u0026#34;, \u0026#34;@testing-library/user-event\u0026#34;: \u0026#34;^7.1.2\u0026#34;, \u0026#34;react\u0026#34;: \u0026#34;^16.13.1\u0026#34;, \u0026#34;react-dom\u0026#34;: \u0026#34;^16.13.1\u0026#34;, \u0026#34;react-scripts\u0026#34;: \u0026#34;3.4.1\u0026#34; }, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;react-scripts start\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;react-scripts build\u0026#34;, \u0026#34;test\u0026#34;: \u0026#34;react-scripts test\u0026#34;, \u0026#34;eject\u0026#34;: \u0026#34;react-scripts eject\u0026#34; }, \u0026#34;eslintConfig\u0026#34;: { \u0026#34;extends\u0026#34;: \u0026#34;react-app\u0026#34; }, \u0026#34;browserslist\u0026#34;: { \u0026#34;production\u0026#34;: [ \u0026#34;\u0026gt;0.2%\u0026#34;, \u0026#34;not dead\u0026#34;, \u0026#34;not op_mini all\u0026#34; ], \u0026#34;development\u0026#34;: [ \u0026#34;last 1 chrome version\u0026#34;, \u0026#34;last 1 firefox version\u0026#34;, \u0026#34;last 1 safari version\u0026#34; ] } } This conciseness is due to the react-scripts dependency.\nWhat is react-scripts? Here are the advantages of having react-scripts:\n react-scripts hides a lot of complexity from us, for example:  all of the Webpack and Babel dependencies and configurations custom scripts for running our development server and running our Jest tests many other dependencies such as Jest, Typescript, ESLint, etc.   react-scripts can be upgraded as new versions come out.  There is one drawback, however. react-scripts may hinder us from modifying the configuration setup. If you do need to customize the project configuration, you may need to eject.\nEjecting To eject, you simply run yarn eject or npm run eject in the command line:\n WARNING: This is permanent as you cannot go back to the react-scripts magic later once you have ejected. Therefore, only eject if absolutely necessary.\n Once you eject, you\u0026rsquo;ll notice that 2 new directories are available: config and scripts.\n scripts contains our start, build, and test scripts. They are definitely worth a read, but rarely require adjustments. config is where the magic happens. Specifically within config/webpack.config.js. This file contains the logic for things like:  transpiling ES6 or above code to ES5 transforming sass, less, or post-css to css hot module reloading compiling, minifying, and concatenating source code splitting code into smaller bundles for faster load times    Webpack manages our entire project behind the scenes.\nLab Click here for the instructions to this lab.\nSummary  The create-react-app CLI is used to create new React projects.  create-react-app provides a good start for your project structure. create-react-app uses react-scripts to abstract the webpack config and other details from your project. You can eject, if needed, to customize the config.   You should follow best practices for keeping all of your source files organized.  We recommend keeping all source files for each component together in the same folder. This includes the Component\u0026rsquo;s JavaScript file, CSS file, and the unit test file.   You can package your React project for Production by running yarn build or npm run build.  "
},
{
	"uri": "/react/pillars/testing/tdd/enzyme/",
	"title": "Getting Started with Enzyme",
	"tags": [],
	"description": "",
	"content": "Let\u0026#8217;s get started with Enzyme\n Topics 1. In this lesson you will learn: 2. What Is Enzyme? 2.1. Enzyme\u0026#8217;s Shallow API 2.2. Enzyme\u0026#8217;s Mount API 2.3. Explore: Shallow vs Mount rendered wrapper (5 min) 2.4. Enzyme \u0026amp; the use of data-attributes 2.5. Enzyme \u0026amp; simulating DOM events   3. Resources 3.1. Testing \u0026amp; App Design     1. In this lesson you will learn:   What is Enzyme?\n shallow API\n  using data-attributes\n  simulating DOM Events\n        2. What Is Enzyme?   Enzyme is a library created by airbnb, that simplifies the \"rendering\" of React components for testing purposes. It gives you selectors to query specific elements. Enzyme has three API interfaces, shallow, mount and render.\n  For more information about the differences between the Enzyme APIs, read this.\n   Table 1. Enzyme APIs     shallow\n Used in unit testing. Shallow rendering is useful to constrain yourself to testing a component as a unit, and to ensure that your tests aren\u0026#8217;t indirectly asserting on behavior of child components.\n   mount\n Used in integration testing. Full DOM rendering is ideal for use cases where you have components that may interact with DOM APIs or need to test components that are wrapped in higher order components.\n   render\n enzyme\u0026#8217;s render function is used to render react components to static HTML and analyze the resulting HTML structure.\n    2.1. Enzyme\u0026#8217;s Shallow API   Shallow rendering is primarily used for unit testing a component\n  When a component is \"shallow\" rendered, only the component is rendered, and not any of its children.\n  The shallow API allows us to render and interact with React components in isolation and not test the component\u0026#8217;s children.\n  Shallow rendering can speed up the execution of the tests by only rendering the component being tested and not its children.\n       Shallow rendering can make your tests more brittle as any refactoring of a component\u0026#8217;s implementation (such as breaking up a large component into multiple smaller components) will usually break the tests as the new child components will not be rendered.      2.2. Enzyme\u0026#8217;s Mount API   Used for integration testing\n  The mount API offers full DOM rendering. This means we have full access to the DOM nodes within child components.\n  NOTE: full rendering actually mounts the component in the DOM, which means that tests can affect each other if they are all using the same DOM. Keep that in mind while writing your tests and, if necessary, use .unmount() or something similar as cleanup.\n    2.3. Explore: Shallow vs Mount rendered wrapper (5 min)     What is wrapper? Let\u0026#8217;s take a look.\n Visit this new codesandbox. Click here\n  Open the App.test.js file and compare the two child describe blocks. How are they different?\n  Run the test suite, then open the console tab\n  What do you see?\n  How would you describe wrapper when rendered with shallow vs mount?\n       2.4. Enzyme \u0026amp; the use of data-attributes   data-attributes are a way to store data. They give us the ability to embed custom data attributes on all HTML elements.\n       Why is this so important? In test-driven development, we add data-attributes to HTML elements so that we can find them on the page. This is an alternative method to using css selectors. CSS selectors, like classes and ids can change or be removed without your knowledge. This can unwhittingly cause tests to break. Using a data-attribute decouples your css from your tests. If using a data-attribute for testing, we separte styling from testing, thereby abiding by the \"separation of concerns\" philosphy in software development.       Characteristics of data-attributes:\n they start with the word data\n  they are hyphenated\n  they use only lower cased letters\n  Examples: data-store-address or data-product-table\n     For more information on using data-attributes in tests, here is a good blog post.\n    2.5. Enzyme \u0026amp; simulating DOM events     In tests we need to be able to mimic a user\u0026#8217;s interaction with DOM elements. A complete list can be found here. Common interactions include:\n typing in an input field\n  clicking a button\n     For these interactions, Enzyme has provided the simulate function. Click here to the simulate documentation.\n      3. Resources   Enzyme documentation\n  Enzyme Shallow API documentation\n  Simulate\n   3.1. Testing \u0026amp; App Design   Rethinking Unit Test Assertions\n  Happy, Sad, Evil, Weird: Putting Use Case Planning into Practice\n      "
},
{
	"uri": "/software-eng-essentials/git-pillars/hooks/",
	"title": "Git Hooks",
	"tags": [],
	"description": "",
	"content": "Git Life cycle hook Once a repo is initialized it takes the default template from the locations below and copies them to the hooks folder in the .git file.\nTypes of hooks The files in the hooks folder are naturally broken. To fix these scripts remove the .sample extension and add execute access.\nLocal Hooks  Pre-commit Prepare-commit-msg Commit-msg Postcommit Post-checkout Pre-rebase  Server Side Hooks Server-side hooks work just like local ones, except they reside in server-side repositories (e.g.: a central repository or a developer’s public repository).\nWhen attached to the official repository, some of these can serve as a way to enforce policy by rejecting certain commits.\nPre-receive You can use SHA1 hashes and lower-level Git commands to inspect the changes that are going to be introduced. Some common use cases include:\n Rejecting changes that involve an upstream rebase Preventing non-fast-forward merges Checking that the user has the correct permissions to make the intended changes (mostly used for centralized Git workflows) If multiple refs are pushed, returning a non-zero status from pre-receive aborts all of them. If you want to accept or reject branches on a case-by-case basis, you need to use the update hook instead.  Post-receive Potentially prevent a command from happening\nYou can\u0026rsquo;t PREVENT the event but you can respond to the event.\nScripting rules apply  If the script doesn\u0026rsquo;t exit with 0 (success) it failed to complete one or more of the tasks assigned. The output from server-side hooks are piped to the client’s console, so it’s very easy to send messages back to the developer. But, you should also keep in mind that these scripts don’t return control of the terminal until they finish executing, so you should be careful about performing long-running operations.  Use Cases Common use cases for Git hooks include:\n encouraging a commit policy altering the project environment depending on the state of the repository implementing continuous integration workflows.  Since scripts are infinitely customizable, Git hooks can be used to automate or optimize virtually any aspect of a development workflow.\nAll of the local hooks described in this lesson can be altered or completely un-installed—by the owner of a repository.\nIt\u0026rsquo;s entirely up to each team member whether or not they actually use a hook. With this in mind, it’s best to think of Git hooks as a convenient developer tool rather than a strictly enforced development policy.\nMaintenance Hooks are not cloned and updated or under version control. To counter this you can store hooks in a folder above the .git database and use symbolic links\nHooks don’t FORCE a developer to do certain things, instead they are more like hard suggestions.\nWebHook vs Git Hook vs API  Git Hook: Git has a way to fire off custom scripts when certain important actions occur.  API: Application Programming Interface (API) allows sharing data or functionality. WebHook: With most APIs there’s a request followed by a response. No request is required for a webhook, it just sends the data when it’s available.  With a partner, spend 15 minutes to:\n Research or create your own Local side hook for both a PRE and a POST git commands. Discuss with the class a fun use case you would like to use on your team.  Resources  Git Hooks Practical Uses Atlassian Descriptions  "
},
{
	"uri": "/golang/concurrency/goroutines/",
	"title": "Goroutines",
	"tags": [],
	"description": "",
	"content": "Goroutines vs. Threads In general, threads are components of a process. A Process can contain multiple threads.\n  Different threads running in the same proecess all share the same resources\n  For single threaded programs, only one thread will be running in a process.\n  Goroutines:\n  Are functions executing concurrently with other goroutines in the same address space.\n  Can be thought of as lightweight threads that have separate independent execution which can execute concurrently with other goroutines.\n  Are functions executing concurrently with other goroutines in the same address space.\n  Are multiplexed onto multiple OS threads so if one should block, such as while waiting for I/O, others continue to run.\n  Goroutines are NOT threads as they are managed by the Go runtime, while threads are managed by the kernel.\n  Golang is a concurrent language, with the main go routine being the main() function.\n The main Goroutine should be running for any other Goroutines to run. If the main Goroutine terminates, the program will be terminated and no other Goroutine will run.    Each goroutine is an independent execution\n  By design, the simplicity of Goroutine usage hides many of the complexities of thread creation and management.\n  Goroutines were given their name to give an accurate connotation of what they do, unlike existing terms: threads, coroutines, processes, and so on.\nBenefits of Goroutines Memory consumption:\n The creation of Goroutines require much less memory as compared to threads.  2kb of memory for Goroutines vs. 1Mb of memory for Threads   The stack size of Goroutines can grow and shrink according to the need of an application. There may be only one thread in the program, but it can have thousands of Goroutines.  Setup and Teardown cost:\n Threads have significant setups and teardown costs because it has to request resources from the OS and return it once it’s done. Goroutines are created and destroyed by the go runtime  It manages scheduling, garbage collection, and the runtime environment for Goroutines Those operations are pretty cheap, when compared with threads.    Creating a Goroutine A Goroutine is identified with the keyword go prefixing a function, making it non-blocking.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func say(s string, sec time.Duration) { time.Sleep(sec * time.Second) // Wait x second(s) \tfmt.Println(s) } func main() { go say(\u0026#34;world\u0026#34;, 1) // go invoke say, but then continue on. \tfmt.Println(\u0026#34;hello\u0026#34;) time.Sleep(2000 * time.Millisecond) // Wait 2 seconds to give the \u0026#34;say\u0026#34; time to execute } Multiple go routines can be created to complete several tasks without blocking the main routine.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func multiply(x,y int){ println(x*y) time.Sleep(3 * time.Second) return } func main(){ go multiply(9,8) go multiply(3990393988888, 9999388746748758) go multiply(4,100) fmt.Println(\u0026#34;started\u0026#34;) time.Sleep(5 * time.Second) //allows time for the routines to finish before exiting the program. This function is blocking processes. \tfmt.Println(\u0026#34;finished\u0026#34;) The go keyword can also be placed before an anonymous function and create the same non-blocking effect.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { go func(){ fmt.Println(\u0026#34;Hello!\u0026#34;) }() go func(){ fmt.Println(\u0026#34;Welcome\u0026#34;) }() go func(){ fmt.Println(\u0026#34;to\u0026#34;) }() go func(){ fmt.Println(\u0026#34;Orange\u0026#34;) }() go func(){ fmt.Println(\u0026#34;Method!\u0026#34;) }() time.Sleep(5 * time.Second) // allows time for the routines to return \tfmt.Println(\u0026#34;Done!\u0026#34;) } The output of the program is different for each execution, due to the nature of concurrent processing.\nYou can also have nested goroutines - go routines that spin off other goroutines.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func squareMath(num int){ fmt.Printf(\u0026#34;num %v squared is %v\\n\u0026#34;, num, num * num) } func cubeMath(num int){ fmt.Printf(\u0026#34;num %v cubed is %v\\n\u0026#34;, num, num * num * num) } func main(){ // calls the squareMath function with an anonymous function \tgo func() {for i := 0; i \u0026lt; 100; i++ { go squareMath(i) }}() // calls the cubeMath function with an anonymous function \tgo func() {for i := 0; i \u0026lt; 100; i++ { go cubeMath(i) }}() fmt.Println(\u0026#34;started\u0026#34;) time.Sleep(5 * time.Second) //allows time for the routines to finish before exiting the program. This function is blocking processes. \tfmt.Println(\u0026#34;finished\u0026#34;) } Lab goroutine  If you haven\u0026rsquo;t already, Clone down the exercise repo found at https://github.homedepot.com/om-labs/go-concurrency Complete the instructions in goroutines/README.md  Scheduling of Goroutines Goroutines are cooperatively scheduled,\n  there is no concept of a scheduler time slice, like you would find in a preemptive scheduler.\n scheduler time slice - the amount of time a process can use before the scheduler switches to another process at the same priority.\n   In cooperative scheduling, Goroutines yield the control periodically when they are idle or logically blocked in order to run multiple Goroutines concurrently. The switch between Goroutines happen only when an explicit call is made to the schedulers.\nA call is made if:\n channels send and receive blocking operations. a Go statement is hit. (Although there is no guarantee that the new Goroutine will be scheduled immediately.) a blocking syscall is hit like file and network operations. a garbage collection cycle stops.  The number of threads available for Goroutines is equal to the GOMAXPROCS, which by default is equal to the number of cores available for that application. Goroutines are scheduled over OS Threads which are scheduled over processors.\nGolang has an M:N scheduler that also utilizes multiple processors.\n  At any time, M goroutines need to be scheduled on N OS threads that runs on at most GOMAXPROCS number of processors (N \u0026lt;= GOMAXPROCS).\n  Go scheduler distributes runnable goroutines over multiple worker OS threads that runs on one or more processors.\n  The number of max processors will vary based on the equipment being used. You can find this by using the runtime package function NumCPU() to output the number of available cores:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; ) func main() { fmt.Println(runtime.NumCPU()) } Summary Goroutines are how Golang implements concurrency, just use the keyword go before a function to make it an asynchronous function. Goroutines are not green-threading, as goroutines scale over multiple cores.\n"
},
{
	"uri": "/javascript/foundations/hello-js/",
	"title": "Hello JavaScript",
	"tags": [],
	"description": "",
	"content": "Getting started with the JavaScript language.\nConcepts  Explain how to add JavaScript code to a web page Execute JavaScript code outside of the browser  JavaScript in the Browser The anatomy of a web site or web application consists of HTML, CSS and JavaScript.\n HTML is used to define the content of the website CSS is used to define the look of the website (fonts, colors, spacing, etc.). JavaScript is used to add dynamic behavior to the website, such as:  interacting with the user sending data to the server receiving data from the server updating the DOM (what the user sees on the screen)    JavaScript and HTML Web Pages  When placing JavaScript in a web page, the JavaScript is loaded via a \u0026lt;script\u0026gt; tag. The JavaScript can be inline or loaded from a separate file that comes from the web server.  The \u0026lt;script\u0026gt; tag can be placed in one of two locations:\n Inside the head section (for newer browsers) Inside the body section (for older browsers)  For modern browsers it is usually preferred to put the script tag in the header and add an async or defer property to control when the JavaScript code begins execution.\n async - download the script during page load; begin execution during page load defer - download the script during page load; begin execution after page load  TIP: For more information about JavaScript loading and performance, see Efficiently load JavaScript with defer and async.\nHere is an example:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Hello, JS\u0026lt;/title\u0026gt; \u0026lt;script\u0026gt; \u0026lt;!-- script tag in the head section containing inline code --\u0026gt; console.log(\u0026#34;I am in the head section.\u0026#34;); let x = 3; console.log(\u0026#34;The value of x is \u0026#34; + x); \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;app.js\u0026#34; defer\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- script tag loading separate file containing JS code --\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello, Orange Academy!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; The JavaScript Browser Console We can open a JavaScript console in Chrome by pressing Command + Option + J. The window that appears is an interactive JavaScript environment (a REPL).\nTry typing\nconsole.log(\u0026#34;Hello, World\u0026#34;); TIP: Often as a developer you will open the JavaScript Console to view console.log messages when debugging your application.\nOther Online Tools  The browser console is not the only REPL available to us. With Node you\u0026rsquo;re able to run a REPL in your terminal. There are also many web applications that provide REPL within your web browser. A few of our favorites include:  repl.it codepen jsfiddle jsbin    NodeJS  Thanks to NodeJS we can now run JavaScript outside of the browser. NodeJS is based on the V8 JavaScript engine. NodeJS adds features to V8 so that we can run full featured server applications and other CLI applications.  For example, we could have a program living in a file named app.js that prints \u0026quot;Hello World\u0026quot;:\nconsole.log(\u0026#34;Hello World\u0026#34;); To run this program we type the following into the terminal.\n$ node app.js Which will result in\nHello World In addition to that, we can run a REPL by only typing node into the terminal.\n$ node \u0026gt; 3 + 5 8 \u0026gt; .exit $  TIP: Node offers a robust set of modules for server side programming. Including the ability to interact with the file system, work with HTTP and a lot more.\nBasic Syntax Comments You can add single-line comments to JavaScript using // and multi-line comments using /\\* and */.\n// this is a single line comment.  let x = 3; // this is a comment at the end of a line.  /* This is a multi-line comment, good for longer comments that need to span multiple lines. */ let y = 4; Semicolons It is good practice to end every statement with a semi-colon.\nNOTE: More about this later but for now just understand that statements are lines of code that do actual work.\nExample:\nlet x = 3; // a declaration statement x = x + 1; // an assignment statement if (x \u0026gt; 10) { // control flow, not a statement  console.log(\u0026#39;x is big\u0026#39;); // a statement for writing to the console. } // end of if block, not a statement. Lab See instructions here.\nSummary  JavaScript is used to add dynamic behavior to web pages and web applications. JavaScript can be executed outside of a browser using NodeJS.  "
},
{
	"uri": "/software-eng-essentials/db-sql/intro-to-postgresql/",
	"title": "Intro to PostgreSQL",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Verify that PostgreSQL is installed Learn how to start and stop PostgreSQL Verify the status of the PostgreSQL server Create a PostgreSQL database Connect to a database via psql List the database names Delete a database  PostgreSQL Set Up Install PostgreSQL package with the following command:\nbrew update \u0026amp;\u0026amp; brew install postgresql Verify the installation of PostgreSQL:\nbrew list --formula | grep postgresql # should return postgresql which postgres # print the path to the executable postgres --version # should print \u0026#34;14.2\u0026#34; or similar Starting and Stopping PostgreSQL via brew services # Then start/stop/restart postgresql like this: brew services [start|stop|restart] postgresql # You can see a list of running services via: brew services list For more info, see: Starting and Stopping Background Services with Homebrew\n One possible problem:\nPostgreSQL not running and launchctl fails with the following error:\npostgresql.plist: Operation already in progress Possible Solution:\n view the PostgreSQL Server logs for potential errors: subl /usr/local/var/postgres/server.log Google the last error and fix One possible solution: rm -rf /usr/local/var/postgres \u0026amp;\u0026amp; initdb /usr/local/var/postgres Also may need to manually delete the pid file: rm /usr/local/var/postgres/postmaster.pid  References:\n Github: Homebrew Stackoverflow    Another Possible Problem:\n$ createdb hangs / never returns\nSolution:\n Mac OSX upgrades are known to remove empty directories under /usr/local/var which causes problems for PostgreSQL installations To fix, run the following statements from the bash shell:  mkdir -p /usr/local/var/postgres/{pg_tblspc,pg_twophase,pg_stat_tmp}/ touch /usr/local/var/postgres/{pg_twophase,pg_stat_tmp}/.keep pg_ctl start -D /usr/local/var/postgres  Open psql utility Postgres is pretty usable right out of the box with the psql utility.\nThe psql utility lets you carry out administrative functions without needing to know their actual SQL commands.\nStart by entering the following on the command line:\npsql By default, postgres automatically creates a user named postgres. So by default, this command is run as the user postgres.\n You may need to use sudo psql postgres for this command to work, depending on how your system is configured.\n  Ah! I cannot run psql! Symptoms: psql: FATAL: database \u0026quot;\u0026lt;user\u0026gt;\u0026quot; does not exist\nSolution: Run createdb with no arguments to create a default database: createdb\n psql Command Line You should see something like the following postgres=#\nThat’s the psql command line.\nWe can now enter a command to see what users are installed:\n\\du Output:\nRole name | Attributes | Member of -----------+------------------------------------------------------------+----------- rolename | Superuser, Create role, Create DB, Replication, Bypass RLS | {} Create Role Postgres doesn’t actually directly manage users or groups, like most standard permission models do. Instead, it directly manages what it calls roles.\nIt is a very bad idea to use the default roles for anything except local development because:\n they are very widely known and more importantly they are super user accounts, meaning they can do anything. This includes deleting databases. This is not safe for a production database—we need users with limited permissions.  Create the new role with replacing username with the desired name:\nCREATE ROLE username WITH LOGIN PASSWORD \u0026#39;Orange Academy\u0026#39;; Type \\du to see if the user was successfully created.\nWait. The attributes list for the new user is completely empty. Why?\nThis is how Postgres securely manages defaults. This user can read any database, table, or row it has permissions for, but nothing else—it cannot create or manage databases and has no admin powers.\nThis is a good thing! It helps keep your database secure.\nAlter Role Attributes So let\u0026rsquo;s add the CREATEDB permission to our new user to allow them to create databases (Replace username with the newly created user):\nALTER ROLE username CREATEDB; \\du; The output should look something like the following:\nList of roles Role name | Attributes | Member of -----------+------------------------------------------------------------+----------- username | Create DB | {} rolename | Superuser, Create role, Create DB, Replication, Bypass RLS | {} Quit postgres with \\q\nCreate Database Create a new database using the following:\ncreatedb clap Once this is done, you need to add at least one non-superuser who has permission to access the database.\nTo do that, type: (Replace username with your username)\npostgres=# GRANT ALL PRIVILEGES ON DATABASE clap TO username; GRANT The \\list command lists all the databases in Postgres\nOutput:\npostgres=# \\list List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+-----------+----------+-------------+-------------+------------------------- clap | username | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =Tc/username + | | | | | username=CTc/username clapdb | superuser | UTF8 | en_US.UTF-8 | en_US.UTF-8 | postgres | superuser | UTF8 | en_US.UTF-8 | en_US.UTF-8 | You can now create, read, update and delete data on the clap database with your user!\nQuit postgres with \\q.\nLog in to the clap database with the newly create user:\npsql clap -U username; You\u0026rsquo;ll notice the prompt is slightly different – the # has changed to a \u0026gt;. This indicates you’re no longer using a Super User account.\nDelete a Database If you no longer want a database, you can use the following instructions (Replace database_name_here with the desired database.)\ndropdb database_name_here Some PSQL Commands \\l # list all databases \\c \u0026lt;database\u0026gt; # connect to \u0026lt;database\u0026gt; \\d # list all tables and other objects \\dt # list all tables \\d \u0026lt;table_name\u0026gt; # list details about \u0026lt;table_name\u0026gt; \\h # show help \\q # quit Summary  PostgreSQL is a modern, mature, enterprise class, open source, and free relational database management system. PostgreSQL is easy to install, start, and stop via brew and brew services PostgreSQL provides a CLI tool called psql for creating and managing database schemas and data.  Additional Resources  PostgreSQL Official Website  "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/intro-to-cli/",
	"title": "Intro to the CLI",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Compare and contrast CLIs to GUIs Explain how command line usage can increase efficiency Explain the difference between the Terminal and the Shell  What is a Command Line Interface? A Command Line Interface, or CLI, is a text-based user interface used to manage computer files, processes, and other computer settings and operation. Using a CLI consists of:\n typing commands into a Terminal window having those commands interpreted and executed by an interpreter program (a Shell) reading the output displayed in the terminal window  Command Line Interface CLI vs. GUI In contrast a Graphical User Interface or GUI is a user interface consisting of text, images, menus, buttons, and many other visual components.\nOften we use a GUI to do things like create documents and spreadsheets, read email, and browse the world wide web.\n NOTE: Many tasks that software and systems engineers need to perform are more efficiently done using a CLI, as we will discuss below.\n Why Use A Command Line Interface (CLI)? The CLI has many benefits over a GUI:\n Speed Power and Precision Repeatability and Scriptability Tools Modularity / Composition  Speed  Most developers can achieve common tasks much faster using the command line. The following CLI features contribute to this speed:  tab completion history searching / modifying piping commands scripting    Power and Precision  Due to being a language / text-based interface, the command line provides us with a lot more power and precision. We can look at the commands we\u0026rsquo;re about to enter and understand exactly what they will do. Thus we can perform powerful operations such as those below.  Examples:\nls -als | sort -nr | head -5 # 1 find . -name \u0026#39;*.md\u0026#39; | xargs grep -i unix # 2  List the 5 largest files in the current directory Search for Markdown files containing \u0026ldquo;unix\u0026rdquo;  Repeatability / Scriptability  The precision of commands and their text-based nature means we can easily save them (as scripts) and re-use them or share them with others. Here is a script that creates a new project directory with several source files and a readme.md file:  .new-project.sh\n#!/bin/bash cd ~/projects mkdir new-project cd new-project touch index.html app.css app.js echo \u0026#34;# Welcome to my Project\u0026#34; \u0026gt; readme.md Tools  There are many tools available for the command line to help us achieve almost any task. Most of them are built in, but we can download many others using package managers such as Homebrew on MacOS, or apt-get on Linux.  Modularity / Composition Tools built for the command line usually follow something called the Unix Philosophy, which is that each tool should do 1 thing and do it well. Complex tasks can be achieved by chaining tools together.\nLooking at a previous example again:\nls -als | sort -nr | head -5 # List the 5 largest files in the current directory find . -name \u0026#39;*.md\u0026#39; | xargs grep -i unix # Search for Markdown files containing \u0026#34;unix\u0026#34;  The first line combines 3 UNIX commands (ls, sort and head) to accomplish a single goal of listing the 5 largest files in the current directory. The second line uses 3 UNIX commands (find, xargs and grep) to search all Markdown files containing the string \u0026ldquo;unix\u0026rdquo;).  Modularity / Composition (cont\u0026rsquo;d) Thus the modularity of these commands allows us to compose them to solve many problems without having to develop our own custom programs.\nTIP: Modularity and Composition are important concepts in Software Development. It is remarkable how well UNIX applied these concepts over 40 years ago.\nSome TERMinology  Terminal - the application that presents a command line interface to the user. Shell - a command line interpreter (a REPL) that executes the commands that the user types. Common shells are sh, bsh, csh, ksh, bash, and zsh. Process - a program that is currently running on the computer Application - a program that consists of one or more processes  Review  Why would a developer prefer the command line interface (CLI) over a GUI? What is the difference between the Terminal and the Shell?  More Resources  UNIX Tutorial for Beginners Unix Intro Course BASH Beginner’s Guide  "
},
{
	"uri": "/cyber-security/static-dynamic-analysis/1-intro-to-appsec/",
	"title": "Introduction to Application Security",
	"tags": [],
	"description": "",
	"content": "Introduction In every developers skill set there is the ability to identify and remediate bugs. Usually when you think of a bug, you think of some incorrectly written code that breaks functionality in some way or another.\nHowever, there is a class of bug that can be very costly to fix that doesn\u0026rsquo;t always make part of your app non-functional. These are security bugs, or bugs that allow end users to use your application in harmful ways you did not intend, such as accessing database records through a login form or injecting javascript through a url.\nSecurity bugs are more expensive the longer you wait to fix them. Even if the bug never gets exploited, it will have to be rectified after it is discovered in order for Home Depot to maintain compliance standards like PCI. This means that the more functionality you add on top of the security bug, the harder it is going to be to fix. It\u0026rsquo;s most cost effective and efficient to catch them as early as you can.\nWhile there are many types of security bugs, the good news is that we have tools to help you find them. In this course we will learn how to use automated scanning tools to find security bugs in our code. This will allow us to identify problems as soon as possible, and then we will look at how to remediate them.\nTo summarize:\n Security bugs are costly to fix. In many cases, we are required by law to fix them. We have tools to help identify the security bugs. Fixing the bugs may take research but we will show you how to get started. Doing the right thing to protect our customers is part of Home Depot\u0026rsquo;s values.    Before we begin scanning our applications and fixing any vulnerabilities, lets briefly review some security concepts and terminology.\nCIA Triad The CIA triad is a fundamental concept for understanding security. Understanding the three components of the triad will help you identify what is needed in your application for a baseline level of security.\n    Confidentiality: Ensuring that data remains private and is only accessed by authorized parties on an as-needed basis.\nExample: using encryption in order to ensure credentials are passed securely.\nIntegrity: Ensuring the accuracy, consistency and trust-worthiness of data against corruption.\nExample: confirming that a user has not altered the price of an item in a store.\nAvailability: Ensuring accessibility to and preventing the loss of data.\nExample: ensuring a site can handle a surge of traffic during peak hours.\nStatic and Dynamic Scanning (SAST/DAST) SAST: Static analysis software testing. Whitebox testing for security flaws by analyzing the source code. Code in question is not running.\nDAST: Dynamic analysis software testing. Blackbox scanning against running code, can be thought of as simulating a hack.\nSCA: Software Composition Analysis (SCA) is used to scan an application\u0026rsquo;s third party libraries for known vulnerabilities. Also called open source scanning.\n"
},
{
	"uri": "/custom-workshops/frontend-at-thd/intro-to-components/",
	"title": "Introduction to Harmony",
	"tags": [],
	"description": "",
	"content": "Concepts and Skills  Understand why Harmony was created Use Harmony UI to discover existing components  Introduction Harmony is a UI component design system created by The Home Depot.\nIt was created to address two important challenges:\n Helping teams re-use UI components that may have been created by other teams Driving consensus on design and functionality of UI components at every phase of the software development lifecycle  To solve these challenges, the Harmony system has been divided into two separate pieces:\n#Harmony UI#:: A web application that serves as live documentation for UI components, as well as serving as a centralized repository for team standards\n#Harmony CLI#:: A command line interface that facilitates the creation of new components, as well as the creation of pull-requests when modifying existing components.\nHarmony UI Walkthrough Navigate to harmony.homedepot.com and let\u0026rsquo;s take a walk through the Harmony UI.\nLanding Page\nYou will see the Harmony landing page, as pictured to the right (click for a larger view).| Component Catalog\nIn the middle-bottom of the page is a \u0026ldquo;Components\u0026rdquo; icon and link that, when clicked, will take you to the component landing page, as pictured to the right (click for a larger view).\nProfiles\nThis page contains all of the components for your organization, separated by category. When you create a new component in Harmony (via harmony make), it will appear on this page. You will notice a selection drop-down in the center of the page that is set to a value of \u0026ldquo;Online Default\u0026rdquo;. Because different parts of an organization may need to create their own set of components, Harmony allows for the creation of separate component \u0026ldquo;profiles\u0026rdquo;. Each profile has a separate component landing page, and thus a separate set of components.If you are not sure which profile is appropriate for your component, use \u0026ldquo;Online Default\u0026rdquo; Component Detail Page\nWhen you click on the name of a component, you will be taken to a screen similar to the one shown to the right. In this example, we have clicked on the \u0026ldquo;input\u0026rdquo; component, within the \u0026ldquo;Micro Elements\u0026rdquo; category.\nSearch\nAt the top of the window is a navigation bar which contains a search box in the center. Try typing the name of a component into the search box and pressing enter/return. A modal should be displayed that contains a list of matching components. Clicking one of the components will take you to a component detail page.\nFocus: The Component Detail Page The component detail page is the live documentation for an individual component. Let\u0026rsquo;s explore the different sections of this page.\nChapters\nAt the right of the page, you will notice a grey column titled \u0026ldquo;Table of contents\u0026rdquo;. Each item in this column is something called a \u0026ldquo;Chapter\u0026rdquo;. Each chapter represents a unique section of documentation. In a later module, we will explore how to add chapters of documentation to a component.\nTags\nIf you click the orange dropdown at the right side of the window, you will see a list of tags for the component that is currently being viewed. Clicking a tag will show that version of the component.\nNOTE: \u0026ldquo;tag\u0026rdquo; in this context refers to a git tag. Read for more details: https://git-scm.com/book/en/v2/Git-Basics-Tagging\nBranches\nIf you click the orange dropdown at the right side of the window, and then click on the \u0026ldquo;Branches\u0026rdquo; tab in the list that appears, you will see a list of branches for the component that is currently being viewed. Clicking a branch name will show that version of the component.\nTIP: This is useful for sharing development versions of a component without having to deploy to a lower-lifecycle.\nComponent example\nOccupying the left-center part of the window is live example of the rendered component.\nComponent example code\nDirectly beneath the live example of the component is the component source code.\nConclusion The Harmony UI allows developers to publish live documentation of components that they create, as well as discover existing components which can be used within their projects. In this lesson, we explored the pages and page components that facilitate this process.\n"
},
{
	"uri": "/javascript/nodejs/testing/javascript-testing/",
	"title": "JavaScript Testing",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Test Runners vs Assertion Common BDD test structure in JavaScript Writing tests in JavaScript \u0026amp; Jest  Test Runners vs Assertions Frameworks In modern JavaScript development (and most other languages as well) it is standard to use some tooling to assist with testing. The tools provide a standard implementation of testing that would otherwise be tedious, difficult to maintain, and extremely verbose. Before we discuss the tools, let\u0026rsquo;s get into the basic anatomy of a test:\n Create a test function, that typically hints at what the test is going to do. Set up the criteria for the test (create mocks, make connections, etc) Call the function under test Determine if the results of the function call are what are expected Clean up/tear down/reset any set up conditions that need to be cleaned up before running the next test, or the tests are completed.  These steps remain the same regardless of whether you are writing an integration test or a unit test. While not required, there are frameworks available that specialize on the various parts of the testing life cycle. Responsibilities are typically broken down into two major categories:\n Test Runner Test Assertions  Test Runner\nA test runner, also commonly referred to simply as a testing framework, has the widest range of responsibility. It is, as the name implies, what actually runs the tests. However, there are some additional responsibilities that a runner will have:\n Test environment configuration and standards Running the tests Reporting the test results  Test Assertion\nTest assertion libraries have a simple purpose: to \u0026ldquo;assert\u0026rdquo; or determine if the test passed or failed. There are numerous ways to do the assertion such as:\n determining if the value returned was the expected value determine if any exceptions were thrown determine if a callback function was called with the correct arguments determine if a promise was resolved or rejected  Popular JavaScript Test Runners There are currently two big players in the JavaScript testing world when it comes to test runners:\n Mocha Jest  Although both provide some of the own unique additions, you could easily look at a test written for Jest and assume it was written for Mocha.\nBDD and the Gherkin Language The majority of test structures follow a BDD style format that resembles a language called Gherkin. Recall that BDD stands for \u0026ldquo;Behavior Driven Development\u0026rdquo; and aims to specify the desired behavior of the application. By using a BDD style in our test code, we can write test code that is easy to read and describes the expectations of the code under test.\nBoth Mocha and Jest come with describe functions that are commonly used to describe what is under test, as well as provide a BDD style language for the code under test.\nDescribe function signature:\ndescribe(\u0026#34;Description goes here...\u0026#34;, function() { ... })  The description describes what aspect of the code under test we want to test. The function() represents a callback that the runner will call to determine what steps the test needs to take.  describe functions always have it functions nested inside them. Each it function tests a single scenario.\nIt function signature:\nit(\u0026#34;Description goes here\u0026#34;, function(done) { ... }) The it function accepts an optional done call back that can be used when testing asynchronous code. More on that later.\nThe it function body contains the assertions that verify that the expected behavior is being observed.\nA Simple Unit Test\nconst { add } = require(\u0026#39;./calculator\u0026#39;) describe(\u0026#34;add\u0026#34;, () =\u0026gt; { // let\u0026#39;s describe the behavior of the `add` function  // Positive testing  it(\u0026#34;should return 4 when given 2 and 2\u0026#34;, () =\u0026gt; { // our first behavior  const result = add(2, 2) const expected = 4 // still to do: verify the expected result here  }) // Negative testing  it(\u0026#34;should throw an error when given 2 and a string\u0026#34;, () =\u0026gt; { // our second behavior  add(2, \u0026#34;hello\u0026#34;) // still to do: verify that the proper error is thrown  }) })  A negative test is a test that purposely provides bad/unexpected conditions and verifies that the code fails gracefully and gives the appropriate response.\n JavaScript Assertion Libraries As with testing frameworks, there are a few popular assertion libraries.\n Chai: Most commonly used with Mocha, but it can be used with any testing framework. It provides several different approaches to writing assertions. Jest: As well being a test runner, it also has built in assertions.  Regardless of what you use, the goal is to provide more readable assertions. The common function between both tools is the expect function. After this, the end goal is the same, but the \u0026lsquo;chaining\u0026rsquo; we will see is slightly different.\nChai assertions\nconst expect = require(\u0026#39;chai\u0026#39;).expect , foo = \u0026#39;bar\u0026#39; , beverages = { tea: [ \u0026#39;chai\u0026#39;, \u0026#39;matcha\u0026#39;, \u0026#39;oolong\u0026#39; ] }; expect(foo).to.be.a(\u0026#39;string\u0026#39;); expect(foo).to.equal(\u0026#39;bar\u0026#39;); expect(foo).to.have.lengthOf(3); expect(beverages).to.have.property(\u0026#39;tea\u0026#39;).with.lengthOf(3); Jest assertions\nconst foo = \u0026#39;bar\u0026#39; , beverages = { tea: [ \u0026#39;chai\u0026#39;, \u0026#39;matcha\u0026#39;, \u0026#39;oolong\u0026#39; ] }; //Just has a simplified direct function call rather than chaining. expect(typeof foo).toBe(\u0026#39;string\u0026#39;); expect(foo).toEqual(\u0026#39;bar\u0026#39;); expect(foo).toHaveLength(3); expect(beverages).toHaveProperty(\u0026#39;tea\u0026#39;) expect(beverages.tea).toHaveLength(3); With either library it is easy to read the tests and understand what behavior is being tested.\nExample 1\n Test written as: expect(typeof foo).toBe('string'); Reads as: expect the type of foo to be a string Assert Equivalent: assert(typeof foo === 'string')  Example 2\n Test written as: expect(foo).toHaveLength(3); Reads as: expect foo to have a length of 3 Assert Equivalent: assert(foo.length === 3)  Asserting in tests Let\u0026rsquo;s take a look at the tests that were written for the sample output above to see how everything is tied together using Jest:\nconst { add } = require(\u0026#39;./calculator\u0026#39;) describe(\u0026#34;add\u0026#34;, () =\u0026gt; { // let\u0026#39;s describe the behavior of the `add` function  // Positive testing  it(\u0026#34;should return 4 when given 2 and 2\u0026#34;, () =\u0026gt; { // our first behavior  const result = add(2, 2) const expected = 4 expect(result).toEqual(expected) // verify the expected behavior  }) // Negative testing  it(\u0026#34;should throw an error when given 2 and a string\u0026#34;, () =\u0026gt; { // our second behavior  expect(() =\u0026gt; { add(2, \u0026#34;hello\u0026#34;) }).toThrow(\u0026#39;\u0026#34;hello\u0026#34; is not a number\u0026#39;); // verify the expected behavior  }) }) Reporting Test Results Test reporting (which tests passed, which tests failed, and why) is a common feature that you get with test runners. The following is an example of test output in Jest.\nOutput of running the above test\nPASS ./calculator.test.js add ✓ should return 4 when given 2 and 2 (3 ms) ✓ should throw an error when given 2 and a string (3 ms) Test Suites: 1 passed, 1 total Tests: 2 passed, 2 total Snapshots: 0 total Time: 0.488 s, estimated 1 s Ran all test suites matching /calculator.test.js/i. Watch Usage: Press w to show more. As you can see using a test framework not only provides more readable tests, but lets us have more readable output. However, even with how readable it is, is still up to you and how you write your descriptions.\nPutting it all Together Now that we know the different parts of the test, lets talk about setting up our tests. We will be using simple node examples.\nAdding Jest to your Project First let\u0026rsquo;s create a simple project:\nmkdir jest-testing cd jest-testing npm init -y # creates a `package.json` file npm install -D jest # installs the `jest` library Installing jest will add jest to the package.json's devDependencies section.\n\u0026#34;devDependencies\u0026#34;: { \u0026#34;jest\u0026#34;: \u0026#34;^23.6.3\u0026#34; }  devDependencies is where any of your testing modules should go. When you place dependencies in this section they will not get installed when you run an npm install with the NODE_ENV environment variable set to production.\nThis makes for much smaller deployments.\n Executing Jest with npm test Next, we want to set up our test command so that when we run npm test it executes jest.\nInside your package.json add the following:\n\u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;jest\u0026#34; }  You may already have a \u0026ldquo;test\u0026rdquo; property of \u0026ldquo;scripts\u0026rdquo;. If so, just replace what is assigned to \u0026ldquo;test\u0026rdquo; with \u0026ldquo;jest\u0026rdquo;\n Your package.json should look something similar to:\n{ \u0026#34;name\u0026#34;: \u0026#34;jest-testing\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;jest\u0026#34; }, \u0026#34;keywords\u0026#34;: [], \u0026#34;author\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34;, \u0026#34;devDependencies\u0026#34;: { \u0026#34;jest\u0026#34;: \u0026#34;^26.6.3\u0026#34; } } Now run npm test\nThis will result in some very ugly output.\n\u0026gt; jest-testing@1.0.0 test \u0026gt; jest No tests found, exiting with code 1 Run with `--passWithNoTests` to exit with code 0 In /Users/mah3093/playground/2021/bootcamp/cohort-2021/javascript-testing/jest-testing 2 files checked. testMatch: **/__tests__/**/*.[jt]s?(x), **/?(*.)+(spec|test).[tj]s?(x) - 0 matches testPathIgnorePatterns: /node_modules/ - 2 matches testRegex: - 0 matches Pattern: - 0 matches npm ERR! code 1 npm ERR! path /Users/mah3093/bootcamp/javascript-testing/jest-testing npm ERR! command failed npm ERR! command sh -c jest npm ERR! A complete log of this run can be found in: npm ERR! /Users/mah3093/.npm/_logs/2021-02-08T18_54_35_762Z-debug.log This may look a bit scary, but this output is giving some useful information if you pick it apart.\n Is telling us that we have no test files, which is true. Is telling us the regex pattern it used to search for test files.  Jest is working as intended at this point. We just do not have anything to run yet. So lets talk about setting up tests.\nTest files and Directories Lets say we already had some functions defined that we wanted to test in a file called calculator.js:\nfunction add(a, b) { if (isNaN(a)) { throw new Error(`${a}is not a number`) } if (isNaN(b)) { throw new Error(`\u0026#34;${b}\u0026#34; is not a number`) } return a + b } function subtract(a, b) { if (isNaN(a)) { throw new Error(`${a}is not a number`) } if (isNaN(b)) { throw new Error(`\u0026#34;${b}\u0026#34; is not a number`) } return a - b } module.exports = { add, subtract } Now we want to create some tests for these functions. When using jest, there are some default locations and filenames it searches to try to find any test files.\nGoing back to our npm test output, you may recall the strange **/__tests__/**/*.js?(x),**/?(*.)+(spec|test).js?(x). Without explaining regex, this it what that line means.\nIt is looking for any files that are named with the following patterns.\n filename.test filename.spec anydir/filename.test anydir/filename.spec __test__/*  In short, Jest, by default, is looking for your files to be named a .test suffix, or be contained in a directory named __test__ \nLets create a file named calculator.test.js and then run npm test again.\ntouch calculator.test.js Our output has now changed:\n\u0026gt; jest-testing@1.0.0 test \u0026gt; jest FAIL ./calculator.test.js ● Test suite failed to run Your test suite must contain at least one test. at onResult (node_modules/@jest/core/build/TestScheduler.js:175:18) at Array.map (\u0026lt;anonymous\u0026gt;) Test Suites: 1 failed, 1 total Tests: 0 total Snapshots: 0 total Time: 1.308 s Ran all test suites. npm ERR! code 1 npm ERR! path /Users/mah3093/playground/2021/bootcamp/cohort-2021/javascript-testing/jest-testing npm ERR! command failed npm ERR! command sh -c jest npm ERR! A complete log of this run can be found in: npm ERR! /Users/mah3093/.npm/_logs/2021-02-08T18_59_59_691Z-debug.log We still failed because Your test suite must contain at least one test.\nAdding tests Now add the following test code to calculator.test.js:\nconst { add, subtract } = require(\u0026#39;./calculator\u0026#39;) // import the code under test  describe(\u0026#34;add\u0026#34;, () =\u0026gt; { // let\u0026#39;s describe the behavior of the `add` function }) If you try to run npm test you will still get an error, because we have not added any tests. Jest will not be satisfied until it finds an it or test function. So lets get to that point.\nFist, because we are doing BDD and we have a good product manager that wrote some excellent acceptance criteria, we know exactly what we should be testing for.\nScenario:As a user of the calculator I need to get the sum of two numbers So that I do not have to count on my fingers Given two numbers are passed When the numbers are 2and 2Then it should return 4When the numbers are -3and 5Then it should return 2Now we can set up our test structure:\nconst { add, subtract } = require(\u0026#39;./calculator\u0026#39;) // import the code under test  describe(\u0026#34;add\u0026#34;, () =\u0026gt; { // let\u0026#39;s describe the behavior of the `add` function  it(\u0026#34;should return 4 when given 2 and 2\u0026#34;, () =\u0026gt; { // our first behavior  const result = add(2, 2) // calling the function under test  expect(result).toEqual(4) // verify the expected behavior  }) it(\u0026#34;should return 2 when given -3 and 5\u0026#34;, () =\u0026gt; { // our first behavior  const result = add(-3, 5) // calling the function under test  expect(result).toEqual(2) // verify the expected behavior  }) })  Notice the following pattern for each test:\n call the function under test and save the result verify that the result is the expected value   Now run npm test:\nyarn test yarn run v1.22.10 $ jest PASS ./calculator.test.js add ✓ should return 4 when given 2 and 2 (3 ms) ✓ should return 2 when given -3 and 5 Test Suites: 1 passed, 1 total Tests: 2 passed, 2 total Snapshots: 0 total Time: 1.071 s Ran all test suites. ✨ Done in 1.79s. Lab 1 Continuing with the example above, add tests for the subtract function.\nGiven two numbers When the first number is 10and the second number is 5Then it should return 5When the first number is 30and the second number 100Then it should return -70When the first number is -10and the second number is -5Then it should return -5Lab 2 We\u0026rsquo;ve delivered the basic sum and subtract feature of our calculator and the customer is happy. However, they now realize it would be helpful if they could multiply 2 numbers and get the result.\nImplement the code and the tests for the following criteria:\nGiven two numbers are passed When the numbers are 2and 3Then it should return 6When the numbers are -3and 7Then it should return -21Setup and Teardown Methods for Jest As part of a testing suite you will often hear the terms setup and teardown used. These are simply things you want to happen before and after a test or set of tests. Often this is where you instantiate, reset, or clean up objects, mocks, data, or connections used in integration testing.\nBoth Mocha and Jest have several functions that can be used for setting up or tearing down a test.\n   Function Description     beforeAll() Executes before all scoped tests   beforeEach() Executes before each scoped test   afterAll() Executes after all scoped tests   afterEach() Executes after each scoped test    Before/After scope rules These apply to all before*/`after*`` functions\n before/after functions outside any describe block are scoped to the entire test file before/after functions can be scoped to a describe block, including nested describe blocks You can have many before/after functions as you need.  Testing Async Code It is important to note that when dealing with functions that perform asynchronous operations special care needs to be taken when writing the tests.\nRecall that in JavaScript, asynchronous operations can be handled in one of 3 ways:\n Using a callback Using a Promise with .then() Using a Promise with async/await  Testing Async Code With Callbacks When testing async code with a callback, We need to use the done callback provided to the it or test function. We call done() when our test has completed verifying the expected behavior.\nSo if we want to test the following function:\n// do-something-with-callback.js const doSomethingWithACallback = cb =\u0026gt; { // do some async operations here  cb(\u0026#34;Your data has arrived\u0026#34;) } module.exports = doSomethingWithACallback Our test could be set up as follows:\nconst doSomethingWithACallback = require(\u0026#39;./do-something-with-callback\u0026#39;) describe(\u0026#34;Lets test a callback\u0026#34;, () =\u0026gt; { it(\u0026#34;It should resolve with \u0026#39;Your data has arrived\u0026#39;\u0026#34;, done =\u0026gt; { doSomethingWithACallback(data =\u0026gt; { expect(data).toBe(\u0026#34;Your data has arrived\u0026#34;); done(); }) }) }) Testing Promises Testing promises is a bit easier. First we declare the function we want to test as a function that returns a promise\n// do-something.js const promiseToDoSomething = () =\u0026gt; { return new Promise((res, rej) =\u0026gt; { // do some async operations here  res(\u0026#34;Your data has arrived\u0026#34;) }) } module.exports = promiseToDoSomething; Then we setup our test as follows:\nconst promiseToDoSomething = require(\u0026#39;./do-something\u0026#39;) describe(\u0026#34;Lets test a promise\u0026#34;, () =\u0026gt; { it(\u0026#34;It should resolve with \u0026#39;Your data has arrived\u0026#39;\u0026#34;, () =\u0026gt; { return promiseToDoSomething().then(r =\u0026gt; { // return the promise!  expect(r).toBe(\u0026#39;Your data has arrived\u0026#39;) }) }) }) The difference here is that instead of calling a done callback to alert jest that we are done, we can return the promise that will eventually be resolved or rejected.\nUsing Async/Await Another option when testing promises is using async await:\ndescribe(\u0026#34;Lets test a promise\u0026#34;, () =\u0026gt; { it(\u0026#34;It should resolve with a \u0026#39;Your data has arrived\u0026#39;\u0026#34;, async () =\u0026gt; { // add `async` keyword  const result = await promiseToDoSomething() // use `await` to wait for promise to be resolved  expect(result).toBe(\u0026#39;Your data has arrived\u0026#39;) }) }) NOTE: Here we need to remember to add the async keyword to the test function.\nNOTE: With async/await you will not need to return a promise because an async function always returns a promise.\nLab 3  Write 2 functions:   The first function should return a promise that resolves to a value of your choosing (such as a string or a number). The second function should take a callback as a parameter. The callback should be a function that takes a value of your choosing  Write a test for each of the functions above.  "
},
{
	"uri": "/react/pillars/testing/common/jest/",
	"title": "Jest",
	"tags": [],
	"description": "",
	"content": "Using jest to test React apps.\n 1. In this lesson you will learn:   JavaScript Testing Vocabulary\n  What is Jest?\n expect API\n  matchers\n        2. JavaScript Testing Tools Just as all things in the JavaScript world, the tools used for testing are plentiful. There are established categories for the testing tools and each one provides a specific role on the testing process. The categories are:\n   test runners\n  assertion libraries\n  testing frameworks\n  React DOM Testing Utilities\n   Keep in mind that many of these tools straddle more than one category. So when it comes to asking if a tool is a test runner, assertion library or testing framework, the answer could be… YES! It’s kind of like asking if Kyle Murray is a baseball or football player. The answer is both!\n 2.1. Test Runner   A tool that finds test files (usually ends in .test.js or .spec.js) and executes them against your source code. The results provide instant feedback to the console, browser or log files as to the veracity of the assertion in the test. Some common test runners are:\n   Jest - recommended, comes with create-react-app\n  Jasmine\n  Mocha\n  Karma\n  Ava\n  QUnit\n    2.2. Assertion Library A collection of verification + matchers that checks your code to see if behaves the way you expect it to. Think of an assertion library as a tool that evaluates an expression, then confirms it’s value. The test runner and the assertion library work together kind of like the battery in baseball; the pitcher + the catcher — one cannot work without the other.\n Test scenario: Let’s say you have an app that welcomes the user by name to the page after login. The user story may look something like this:\n   User logs into the app\n  Then, User sees \"Welcome, Maggie!\"\n    Figure 1. Assertion examples  In the test, the assertion library provides the verification language with keywords like expect, or should coupled with matchers like toBe, to.be.a and should.equal. The matchers are library specific. To find out what matchers are available, check the assertion library\u0026#8217;s documentation.\n Some common assertion libraries are:\n   Jest - it\u0026#8217;s a test runner but it also comes with expect and some matchers\n  Chai\n    2.3. Testing Framework What do you get when you combine a test runner + assertion library + test structure? A testing framework. They are designed to organize and run your tests. The term “testing framework” has a fluid definition for developers. It is often used interchangeably with any tool under the JavaScript testing umbrella which causes confusion. A testing framework allows you to structure your tests into blocks often divided into describe and context, it and test blocks.\n describe('my code must work', () =\u0026gt; { it ('should work', () =\u0026gt; { }) it ('should not work', () =\u0026gt; { }) })     Jest - it\u0026#8217;s a test runner but it also comes with expect and some matchers\n  Jasmine\n  QUnit\n    2.4. React DOM Testing Utilities And then there are the tools that are specific to testing React components. Their purpose is to provide access to virtual DOM nodes that live in a “browser-like” environment. They can be grouped under the category of utitiles since they are often referred to as libraries, modules and utilities. They can be used with any test runner or assertion library.\n The most popular DOM Testing utilities are:\n   Enzyme\n  React Testing Library\n  dom-testing-library - note that it is included in react-testing-library\n      3. Jest   Jest is a testing library that was created by Facebook. It is a test runner + assertion library. It is advertised as \"Delightful JavaScript Testing\" for a reason. It requires no configuration, is human readable and is one of the easiest testing libraries to set up and start using. It provides excellent error messages, runs quickly, and its use has been widely adopted by many prominent companies.\n     3.1. Jest \u0026amp; the Expect API   When you see Jest\u0026#8217;s keyword expect, this marks the beginning of an assertion. Assertions are statements that perform an actual check on the software\u0026#8217;s output. An assertion is read as, \"We expect thisThing to evaluate to thisValue.\" thisThing can be a component, a function, or anything that returns a value.\n       expect gives you access to several matchers which allow you to test the values of the inputs.\n    Figure 2. Anatomy of a Test   3.2. Explore: Jest\u0026#8217;s Matchers (5 min)   Let\u0026#8217;s take a look at the Expect API and its matchers. When you click on each matcher, it will show you a sample implementation. Read through the list familiarize yourself with 3-5 of them. The more common matchers are:\n toBe\n  toEqual\n  not\n  toContain\n     There are additional matcher libraries like jest-extended that provide additional matchers. To use them, they would need to be installed separately.\n      4. Jest and Create React App One great thing about jest is that it comes bundled with create-react-app. When you run create-react-app to create your React project, all of the dependencies and configuration for running jest is already there. To run your tests, you simply run:\n running your tests with jest $ yarn test # or if using npm you can type `npm test`     5. Resources   Jest Expect API documentation\n     "
},
{
	"uri": "/react/foundations/labs/lab-jsx-expressions/",
	"title": "JSX Expressions",
	"tags": [],
	"description": "",
	"content": "In this lab you will refactor a Shopping Cart App to better organize the JSX expressions.\nYou can find the instructions for the lab here.\n"
},
{
	"uri": "/javascript/performance/gathering-metrics-lab/",
	"title": "Lab: Measure FCP and FMP",
	"tags": [],
	"description": "",
	"content": "Purpose: To get hands-on experience with measuring the rendering performance of web applications.\nIn this lab, we will be using the performance measurement tools provided by Google Chrome to take a look under the hood of several web applications and observe the impact of different rendering strategies on performance.\nCapture a performance profile with Developer Tools To measure First Contentful Paint (FCP) and First Meaningful Paint (FMP), we will need to use the developer tools in Google Chrome to generate something called a performance profile.\nHow to generate a performance profile:\n  Navigate to www.homedepot.com in Google Chrome\n  Press command + option + i on your keyboard to open the developer tools\n  Navigate to the tab titled \u0026ldquo;Performance\u0026rdquo;\n  Click the “start profiling and reload page” button in the top left of the developer tools (it looks like a refresh button).  Wait for the profile to be generated. This process occurs automatically, and you will not need to click the “stop” button.\n  FCP and FMP will be tagged in the performance profile.   Legend for the tags that appear:\n FP - __F__irst __P__aint marks the point when the browser renders anything that is visually different from what was on the screen prior to navigation FCP - __F__irst __C__ontentful __P__aint is the point when the browser renders the first bit of content from the DOM, which may be text, an image, SVG, or even a \u0026lt;canvas\u0026gt; element FMP - __F__irst __M__eaningful __P__aint DCL - __D__OM __C__ontent __L__oaded fires when the initial HTML document has been completely loaded and parsed, without waiting for stylesheets, images, and subframes to finish loading L - __L__oaded is fired when the whole page has loaded, including all dependent resources such as stylesheets images  You’ve just created your first performance profile! Congratulations! At this point you may be thinking: This is a lot of data. Is there a simpler way to view FCP and FMP?\n Yes! Google Lighthouse provides a simplified view into performance data, while Chrome developer tools provides more detailed information.  Capture a performance profile with Google Lighthouse You can generate a simplified view of performance data by completing the following steps:\n Navigate to the tab titled \u0026ldquo;Audits\u0026rdquo;\n  In the section of the page titled \u0026ldquo;Device\u0026rdquo;, select \u0026ldquo;Desktop\u0026rdquo;\n  In the section of the page titled \u0026ldquo;Audits\u0026rdquo;, select \u0026ldquo;Performance\u0026rdquo; and \u0026ldquo;Best practices\u0026rdquo;\n  In the section of the page titled \u0026ldquo;Throttling\u0026rdquo;, ensure that \u0026ldquo;No throttling\u0026rdquo; is selected\n  Click the \u0026ldquo;Run Audits\u0026rdquo; button at the bottom of the page to begin gathering performance data. The entire process could take anywhere between a few seconds and a few minutes, depending on the speed of the website being tested.  After the performance data has been gathered, you should see a screen similar to the screenshot below. In the section titled \u0026ldquo;Metrics\u0026rdquo;, notice that we see two values called \u0026ldquo;First Contentful Paint\u0026rdquo; and \u0026ldquo;First Meaningful Paint\u0026rdquo;. These metrics directly map to the FCP and FMP that we gathered from Chrome developer tools.   Measure FCP and FMP for familiar websites Using the performance measurement skills that we just acquired in the previous sections, measure FCP and FMP for a few popular websites.\nClient-side rendered  https://music.amazon.com  Server-side rendered  https://www.nytimes.com/  Universally-rendered (A universally-rendered website is a website that is rendered by the server, but has event listeners attached by the client)\n https://www.reddit.com  "
},
{
	"uri": "/react/performance/gathering-metrics-lab/",
	"title": "Lab: Measure FCP and FMP",
	"tags": [],
	"description": "",
	"content": "Purpose: To get hands-on experience with measuring the rendering performance of web applications.\nIn this lab, we will be using the performance measurement tools provided by Google Chrome to take a look under the hood of several web applications and observe the impact of different rendering strategies on performance.\nCapture a performance profile with Developer Tools To measure First Contentful Paint (FCP) and First Meaningful Paint (FMP), we will need to use the developer tools in Google Chrome to generate something called a performance profile.\nHow to generate a performance profile:\n  Navigate to www.homedepot.com in Google Chrome\n  Press command + option + i on your keyboard to open the developer tools\n  Navigate to the tab titled \u0026ldquo;Performance\u0026rdquo;\n  Click the “start profiling and reload page” button in the top left of the developer tools (it looks like a refresh button).  Wait for the profile to be generated. This process occurs automatically, and you will not need to click the “stop” button.\n  FCP and FMP will be tagged in the performance profile.   Legend for the tags that appear:\n FP - __F__irst __P__aint marks the point when the browser renders anything that is visually different from what was on the screen prior to navigation FCP - __F__irst __C__ontentful __P__aint is the point when the browser renders the first bit of content from the DOM, which may be text, an image, SVG, or even a \u0026lt;canvas\u0026gt; element FMP - __F__irst __M__eaningful __P__aint DCL - __D__OM __C__ontent __L__oaded fires when the initial HTML document has been completely loaded and parsed, without waiting for stylesheets, images, and subframes to finish loading L - __L__oaded is fired when the whole page has loaded, including all dependent resources such as stylesheets images  You’ve just created your first performance profile! Congratulations! At this point you may be thinking: This is a lot of data. Is there a simpler way to view FCP and FMP?\n Yes! Google Lighthouse provides a simplified view into performance data, while Chrome developer tools provides more detailed information.  Capture a performance profile with Google Lighthouse You can generate a simplified view of performance data by completing the following steps:\n Navigate to the tab titled \u0026ldquo;Audits\u0026rdquo;\n  In the section of the page titled \u0026ldquo;Device\u0026rdquo;, select \u0026ldquo;Desktop\u0026rdquo;\n  In the section of the page titled \u0026ldquo;Audits\u0026rdquo;, select \u0026ldquo;Performance\u0026rdquo; and \u0026ldquo;Best practices\u0026rdquo;\n  In the section of the page titled \u0026ldquo;Throttling\u0026rdquo;, ensure that \u0026ldquo;No throttling\u0026rdquo; is selected\n  Click the \u0026ldquo;Run Audits\u0026rdquo; button at the bottom of the page to begin gathering performance data. The entire process could take anywhere between a few seconds and a few minutes, depending on the speed of the website being tested.  After the performance data has been gathered, you should see a screen similar to the screenshot below. In the section titled \u0026ldquo;Metrics\u0026rdquo;, notice that we see two values called \u0026ldquo;First Contentful Paint\u0026rdquo; and \u0026ldquo;First Meaningful Paint\u0026rdquo;. These metrics directly map to the FCP and FMP that we gathered from Chrome developer tools.   Measure FCP and FMP for familiar websites Using the performance measurement skills that we just acquired in the previous sections, measure FCP and FMP for a few popular websites.\nClient-side rendered  https://music.amazon.com  Server-side rendered  https://www.nytimes.com/  Universally-rendered (A universally-rendered website is a website that is rendered by the server, but has event listeners attached by the client)\n https://www.reddit.com  "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/supplemental/liquidprompt/",
	"title": "Liquid Prompt",
	"tags": [],
	"description": "",
	"content": "We can customize the appearance of our BASH prompt to include fun and/or useful information. We can do this manually but there is a very nice GitHub project called LiquidPrompt that contains all of the BASH code to provide us with a very powerful BASH prompt. Liquid Prompt is fully customizable but it does a great job right out of the box!\nHere is a screenshot of LiquidPrompt in action:\nInstall LiquidPrompt To install LiquidPrompt, type the following commands into your Terminal:\ncd ~ git clone https://github.com/nojhan/liquidprompt.git source liquidprompt/liquidprompt Configure your BASH Shell to Always Use LiquidPrompt If you like LiquidPrompt and you always want your Terminal sessions to use it, then add the following lines to your .bashrc file:\n# Only load Liquid Prompt in interactive shells, not from a script or from scp [[ $- = *i* ]] \u0026amp;\u0026amp; source ~/liquidprompt/liquidprompt References LiquidPrompt\n"
},
{
	"uri": "/software-eng-essentials/command-line-bash/manipulating-files/",
	"title": "Manipulating files",
	"tags": [],
	"description": "",
	"content": "Objectives  Redirecting and appending Listing Renaming, copying, deleting  Redirecting and Appending Let\u0026rsquo;s work with text from one of the oldest recorded epic poems.\nUse the echo command to print out the first line of Beowulf.\nPrinting the first line of Beowulf\n$ echo \u0026#34;So. The Spear-Danes in days gone by\u0026#34; Now we want to put this line in a file.\nWe can accomplish this in the command line without a text editor, using the redirect operator \u0026gt;:\nCreating a file using the redirect operator\n$ echo \u0026#34;So. The Spear-Danes in days gone by\u0026#34; \u0026gt; beowulf_1.txt Remember that you can use ↑ to retrieve the previous command.\nThe right angle bracket \u0026gt; takes the output from echo and redirects its contents to a file called beowulf_1.txt.\nWe can inspect the file to see if this redirect worked by using the cat command.\nInspecting a file with cat\n$ cat beowulf_1.txt So. The Spear-Danes in days gone by cat is short for \u0026ldquo;concatenate\u0026rdquo; and it is used to dump the contents of a file (or files) to standard output.\nWe can add the second line of the poem to the file by using the append operator \u0026gt;\u0026gt;:\nAppending echo output to a file\n$ echo \u0026#34;and the kings who ruled them had courage and greatness.\u0026#34; \u0026gt;\u0026gt; beowulf_1.txt Using cat again, we can see that the append operator simply added the line to the end of the file:\n$ cat beowulf_1.txt So. The Spear-Danes in days gone by and the kings who ruled them had courage and greatness. An epic diff\nWe have been using text from the Seamus Heaney translation of Beowulf. What if we wanted to compare a file of the Heaney translation with another translation and see the differences? Let\u0026rsquo;s create a file which will contain some lines from a fictional skater punk translation.\n$ echo \u0026#34;So. The Spear-Danes in days gone by\u0026#34; \u0026gt; beowulf_1_sk8er.txt $ echo \u0026#34;and the sk8ter bois who ruled them had courage and greatness.\u0026#34; \u0026gt;\u0026gt; beowulf_1_sk8er.txt Unix systems come with the diff command that shows us the differences in files that are similar but not equivalent.\n$ diff beowulf_1.txt beowulf_1_sk8er.txt 2c2 \u0026lt; and the kings who ruled them had courage and greatness. --- \u0026gt; and the sk8er bois who ruled them had courage and greatness. Dr. George Walkden, a University of Manchester lecturer, says the first line of Beowulf has been incorrectly translated for years. According to his research, the Old English word hwæt, which starts the English language\u0026rsquo;s oldest epic poem (\u0026ldquo;Hwæt! We Gar-Dena in gear-dagum…\u0026quot;), should not be read as a ryhtmic interjection distinct from the rest of the first line (e.g., \u0026ldquo;Listen! we have heard of the might of the kings\u0026rdquo;), instead it should be read as a single exclamatory sentence (e.g., \u0026ldquo;How we have heard of the might of the kings.\u0026quot;)\nThere is more to read following the link; it is clear that Heaney\u0026rsquo;s translation is closest to the original.\nExercise\nAt the end of each of the exercises below, use the cat command to verify your answer.\n Using echo and \u0026gt;, make files called line_1.txt and line_2.txt containing the first and second lines of Beowulf, respectively. Replicate the original beowulf_1.txt (containing the first two lines of the epic poem) by first redirecting the contents of line_1.txt and then appending the contents of line_2.txt. Call the new file beowulf_1_copy.txt, and confirm using diff that it\u0026rsquo;s identical to beowulf_1.txt. Hint: When there is no diff between two files, diff simply outputs nothing. Use cat to combine the contents of line_1.txt and line_2.txt in reverse order using a single command, yielding the file beowulf_1_reversed.txt. Hint: The cat command can take multiple arguments.  Listing A popular Unix command is ls, short for \u0026ldquo;list\u0026rdquo;.\nListing files and directories with ls. (Output will vary)\n$ ls Desktop Downloads beowulf_1.txt beowulf_1_reversed.txt The ls command will list all files and directories in the current directory. ls is a prevalent command for orienting oneself after changing directories.\nThe ls command can also be used to check if a file or directory exists. If the subject does not exist, an error message is returned.\nRunning ls on a nonexistent file.\n$ ls foo ls: foo: No such file or directory $ touch foo $ ls foo foo The touch command\u0026rsquo;s stated purpose is to change the modification timestamp on files or directories, but we used it above to create a new file. Unix users do this often.\nWildcard character\nThe wildcard character * is supported by ls. The wildcard character returns all files matching the string you pass. A common use is to search for strings matching a certain pattern (perhaps a file extension). For example, to list all files ending in \u0026ldquo;.txt\u0026rdquo;, we would type the following:\n$ ls *.txt beowulf_1.txt beowulf_1_reversed.txt Here *.txt automatically expands to all the filenames that match the pattern \u0026ldquo;any string followed by .txt\u0026rdquo;.\nThere are three especially important optional forms of ls, starting with the \u0026ldquo;long form\u0026rdquo;, using the option -l:\nLong form\n$ ls -l *.txt -rw-r—r-- 1 KXB0QJK staff 92 Sep 11 20:01 beowulf_1.txt -rw-r—r-- 1 KXB0QJK staff 92 Sep 11 20:04 beowulf_1_copy.txt -rw-r—r-- 1 KXB0QJK staff 92 Sep 11 20:05 beowulf_1_reversed.txt -rw-r—r-- 1 KXB0QJK staff 36 Sep 11 20:03 line_1.txt -rw-r—r-- 1 KXB0QJK staff 56 Sep 11 20:03 line_2.txt The long form lists a date and time indicating the last time the file was modified. The number before the date is the size of the file, in bytes. For now, you can safely ignore the rest of the information output by ls -l.\nList by reversed time of modification (long format)\nA second powerful ls variant is \u0026ldquo;list by reversed time of modification (long format)\u0026rdquo;, or ls -rtl, which lists the long form of each file or directory in order of how recently it was modified (reversed so that the most recently modified entries appear at the bottom of the screen for easy inspection). This is especially convenient when there are a lot of files in the directory but you really only care about seeing the ones that have been modified recently. We\u0026rsquo;ll see an example of this in the lesson on inspecting files, but you are free to try it now:\n$ ls -rtl \u0026lt;results system-dependent\u0026gt; -rtl is the commonly used compact form, but Unix allows the options to be passed individually, like this:\n$ ls -r -t -l Additionally, the order is irrelevant, so typing ls -trl gives the same result.\nHidden files\nUnix has the concept of \u0026ldquo;hidden files (and directories)\u0026rdquo;, which don\u0026rsquo;t show up by default when listing files. Hidden files and directories are identified by starting with a dot . like .secret_file, and are routinely used for things like storing user preferences. A common hidden file is .gitignore that tells a particular program (Git) to ignore files matching certain patterns.\nSay we create a .gitignore file which we want to ignore all files ending in \u0026ldquo;.txt\u0026rdquo;:\n$ echo \u0026#34;*.txt\u0026#34; \u0026gt; .gitignore $ cat .gitignore *.txt If we then run ls, the file won\u0026rsquo;t show up, because it\u0026rsquo;s hidden:\n$ ls beowulf_1.txt beowulf_1_reversed.txt \u0026ldquo;all\u0026rdquo; option\nThe final ls command we will cover in this lesson is the list all ls -a command.\n$ ls -a . .gitignore beowulf_1_reversed.txt .. beowulf_1.txt Now .gitignore shows up, as well as a couple of mystery dot . and double-dot .. items (which we will learn about later).\nExercise\n  What\u0026rsquo;s the command to list all the non-hidden files and directories that start with the letter \u0026ldquo;b\u0026rdquo;?\n  What is the command to list all the non-hidden files that contain the string \u0026ldquo;eowulf\u0026rdquo;, long-form by reverse modification time? Hint: Use the wildcard operator at both the beginning and the end.\n  What is the command to list all files (including hidden ones) by reverse modification time, in long form?\n  Renaming, Copying, Deleting Next to listing files, probably the most common file operations involve renaming, copying, and deleting them. As with listing files, most modern operating systems provide a graphical user interface to such tasks, but in many contexts it is more convenient to perform them at the command line.\nThe way to rename a file is with the mv command, short for \u0026ldquo;move\u0026rdquo;:\n$ echo \u0026#34;test text\u0026#34; \u0026gt; test $ mv test test_file.txt $ ls test_file.txt This renames the file called test to test_file.txt. The final step in the example runs ls to confirm that the file renaming was successful, but system-specific files other than the test file are omitted from the output shown. (The name \u0026ldquo;move\u0026rdquo; comes from the general use of mv to move a file to a different directory-we will learn more about working with directories later), possibly renaming it en route. When the origin and target directories coincide, such a \u0026ldquo;move\u0026rdquo; reduces to a simple renaming.)\nThe way to copy a file is with cp, short for \u0026ldquo;copy\u0026rdquo;:\n$ cp test_file.txt second_test.txt $ ls second_test.txt test_file.txt Finally, the command for deleting a file is rm, for \u0026ldquo;remove\u0026rdquo;:\n$ rm second_test.txt remove second_test.txt? y $ ls second_test.txt ls: second_test.txt: No such file or directory Note that, on many systems, by default you will be prompted to confirm the removal of the file. Any answer starting with the letter \u0026ldquo;y\u0026rdquo; or \u0026ldquo;Y\u0026rdquo; will cause the file to be deleted, and any other answers will prevent the deletion from occurring.\nBy the way, in the calls to cp and rm above, I would almost certainly not type out test_file.txt or second_test.txt. Instead, I would type something like test⇥ or sec⇥ (where ⇥ represents the tab, as we learned in the Editing the Line lesson), thereby making use of tab completion (see below).\nTab completion\nMost modern command-line programs (shells) support tab completion, which involves automatically completing a word if there\u0026rsquo;s only one valid match on the system. For example, if the only file starting with the letters \u0026ldquo;tes\u0026rdquo; is test_file, we could create the command to remove it as follows:\n$ rm tes⇥ where ⇥ is the tab key ⇥. The shell would then complete the filename, yielding rm test_file. Especially with longer filenames (or directories), tab completion can save a huge amount of typing. It also lowers the cognitive load, since it means you don\u0026rsquo;t have to remember the full name of the file—only its first few letters.\nIf the match is ambiguous, as would happen if we had files called foobarquux and foobazquux, the word will be completed only as far as possible, so\n$ ls foo⇥ would be completed to\n$ ls fooba If we then hit tab again, we would see a list of matches:\n$ ls fooba⇥ foobarquux foobazquux We could then type more letters to resolve the ambiguity, so typing the r after fooba and hitting ⇥ would yield\n$ ls foobar⇥ which would be completed to foobarquux. This situation is common enough that experienced command-line users will often just hit something like f⇥⇥ to get the shell to show all the possibilities:\n$ ls f⇥⇥ figure_1.png foobarquux foobazquux Additional letters would then be typed as usual to resolve the ambiguity.\nThe default behavior of rm on an unconfigured Unix system is actually to remove the file without confirmation, but (because deletion is irreversible) many systems alias the rm command to use an option to turn on confirmation. (As you can verify by running man rm, this option is -i, so in fact rm is really rm -i.) There are many situations where confirmation is inconvenient, though, such as when you\u0026rsquo;re deleting a list of files and don\u0026rsquo;t want to have to confirm each one. This is especially common when using the wildcard *. For example, to remove all the files ending with \u0026ldquo;.txt\u0026rdquo; using a single command, without having to confirm each one, you can type this:\n$ rm -f *.txt Here -f (for \u0026ldquo;force\u0026rdquo;) overrides the implicit -i option and removes all files immediately.\nExercise\n  Use the echo command and the redirect operator \u0026gt; to make a file called foo.txt containing the text \u0026ldquo;hello, world\u0026rdquo;. Then, using the cp command, make a copy of foo.txt called bar.txt. Using the diff command, confirm that the contents of both files are the same.\n  By combining the cat command and the redirect operator \u0026gt;, create a copy of foo.txt called baz.txt without using the cp command.\n  Create a file called quux.txt containing the contents of foo.txt followed by the contents of bar.txt. Hint: Recall that cat can take multiple arguments.\n  How do rm nonexistent and rm -f nonexistent differ for a nonexistent file?\n  Summary Important commands from this section summarized.\n   Command Description Example     \u0026lt; Redirect output to filename $ echo foo \u0026gt; foo.txt   \u0026gt;\u0026gt; Append output to filename $ echo bar \u0026gt;\u0026gt; foo.txt   cat \u0026lt;file\u0026gt; Print contents of file to screen $ cat hello.txt   diff \u0026lt;f1\u0026gt; \u0026lt;f2\u0026gt; Diff files 1 and 2 $ diff foo.txt bar.txt   ls List directory or file $ ls hello.txt   ls -l List long form $ ls -l hello.txt   ls -rtl Long by reverse modification time $ ls -rtl   ls -a List all (including hidden) $ ls -a   touch \u0026lt;file\u0026gt; Create an empty file $ touch foo   mv \u0026lt;old\u0026gt; \u0026lt;new\u0026gt; Rename (move) from old to new $ mv foo bar   cp \u0026lt;old\u0026gt; \u0026lt;new\u0026gt; Copy old to new $ cp foo bar   rm \u0026lt;file\u0026gt; Remove (delete) file $ rm foo   rm -f \u0026lt;file\u0026gt; Force-remove file $ rm -f bar    Important commands from this section summarized.\nA copy-and-pastable version of Beowulf\nSo. The Spear-Danes in days gone by\nand the kings who ruled them had courage and greatness.\nWe have heard of those princes\u0026rsquo; heroic campaigns.\nThere was Shield Sheafson, scourge of many tribes,\na wrecker of mead-benches, rampaging among foes.\nThis terror of the hall-troops had come far.\nA foundling to start with, he would flourish later on\nas his powers waxed and his worth was proved.\nIn the end each clan on the outlying coasts\nbeyond the whale-road had to yield to him\nand begin to pay tribute. That was one good king.\nExercise\n  By copying and pasting the text from the HTML version of Beowulf above, use echo to make a file called beowulf_1_complete.txt containing the first couple stanzas of Beowulf.\nHint: You may recall getting stuck when echo was followed by an unmatched double quote, as in echo \u0026quot;, but in fact this construction allows you to print out a multi-line block of text. Just remember to put a closing quote at the end, and then redirect to a file with the appropriate name. Check that the contents are correct using cat.\n  Type the sequence of commands needed to create an empty file called foo, rename it to bar, and copy it to baz.\n  What is the command to list only the files starting with the letter \u0026ldquo;b\u0026rdquo;?\nHint: Use a wildcard.\n  Remove both bar and baz using a single call to rm.\nHint: If those are the only two files in the current directory that start with the letter \u0026ldquo;b\u0026rdquo;, you can use the wildcard pattern from the previous exercise.\n  "
},
{
	"uri": "/python/foundation/math-operators/",
	"title": "Math Operators",
	"tags": [],
	"description": "",
	"content": "An introduction to IDLE and math in Python3\nMath! Arithmetic operators Arithmetic operators are used to perform mathematical operations like addition, subtraction, multiplication and division.\nArithmetic Operators\n   Name Operator     Addition +   Subtraction -   Multiplication *   Float Division /   Integer Division //   Negation -   Remainder %   Exponent **    Open IDLE by typing command + spacebar, type idle and hit return. Python is an interpreted language, and we can use the Python Console to type any numbers or commands just like a calculator.\nTry typing a few numbers, and view the output.\nWARNING: Python 2 treated division differently: the / symbol would default to integer division.\nNow, let\u0026rsquo;s try a few expressions with some of the arithmetic operators:\n35 + 5 45 - 5 8 * 5 400 / 10 400 // 10 -35 + -5 40 % 10000 Each of these expressions should evaluate to 40 in your python shell (except for the negation expression, which should evaluate to -40)\nOne thing to note is that when using the / operator, the result will return as a float. In the above example, 400 / 10 evaluates to 40.0 If you want a whole number returned, use the // double-slash operator. Just remember that whenever you see a number without a decimal point, python is interpreting it as an int, and when there is a number with a decimal point, it\u0026rsquo;s a float. This is important to note for now, because as we move on to learning about loops we\u0026rsquo;ll realize that Python is opinionated on which operator can be used in specific situations.\nAlso, let\u0026rsquo;s talk about the remainder operator, also called modulus. This will return a whole number which will be the remainder of the expression. For example, 10 % 3 will output 1, since 1 is the remainder when you divide 10 by 3\nOperator precedence All operators are not equal. Remember the PEMDAS rule from math class! Let\u0026rsquo;s take a look.\nWhen you take our expressions from the previous example, and put them into a more complex expression, we can see how operator precedence works.\nType the following into IDLE:\n10 + 5 / 3 - 4 * 12 If you go through this expression in order, as 10 + 5 is 15, dividing by 3 gives us 5 and subtracting 4 leaves us with 1 before dividing by 12. You may be lead to believe the answer is 12 when it is in fact -36.333333333333336 (We see the float because we used the single / divisor)\nWhen you look at an expression like this and use PEMDAS, we have to first use multiplication to get 4 * 12 = 48, then take the value for b and do 3/3 which is 1.0. Then add 12 + 1.0, and finally 13.0 - 48 which gives us -36.333333333333336\nPut your knowledge to work!\nUsing the same operators and numbers as the previous example, what does the following expression evaluate to when you put it into IDLE?\n(((10 + 5) / 3) - 4) * 12 Other operators There are other operators in Python, and we\u0026rsquo;ll list them briefly here and go into them in more detail later on:\n   Operators Description     Relational Operators Relational operators compare values. It either returns True or False according to the condition.   Logical operators Logical operators perform logical and, logical or and logical not operations.   Assignment operators Assignment operators are used to assign values to the variables.   Special operators There are some special types of operators like identity operators is and is not. The identity operators are used to check if two values are located on the same part of the memory. Two variables that are equal does not imply that they are identical.   Membership operators in and not in are the membership operators; used to test whether a value or variable is in a sequence.    First, Let\u0026rsquo;s Learn About Print\n"
},
{
	"uri": "/software-eng-essentials/agile-lean/mvp/",
	"title": "Minimum Viable Product (MVP)",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Define MVP Describe the benefits of building an MVP List some uses of building an MVP  Definition of MVP The concept of an MVP:\n gained popularity after Eric Ries described it in his book \u0026ldquo;The Lean Startup\u0026rdquo; in 2009 stresses the impact of learning in new product development is defined as that version of a new product which allows a team to collect the maximum amount of validated learning about customers with the least effort This validated learning comes in the form of whether your customers will actually purchase your product (or find it valuable).  We can further breakdown MVP:\n Minimum - design and develop the minimum features required to provide the essential value to the user. Viable - design and develop enough features that a user would want to use the product (don\u0026rsquo;t be too minimal). Product - something that provides value to the users.  Benefits The primary benefits of an MVP are:\n Gain understanding about your customers’ interest in your product without fully developing the product. Reduce the effort and expense you spend on a product that will not succeed in the market. Provide value sooner to your customers.  consider the illustration above and ask which roadmap provides more value sooner.    Uses Some of the most common uses of an MVP are:\n As the core piece of experimentation. Validate product ideas early in the process. Initiate a feedback loop to learn from your users.  Additional Resources  Eric Reis - Building the MVP  "
},
{
	"uri": "/javascript/foundations/cheatsheets/modernjs/modern-js/",
	"title": "Modern JavaScript Fact Sheet",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/golang/monorepo/monorepo/",
	"title": "Monorepo in Go",
	"tags": [],
	"description": "",
	"content": "MonoRepos This lesson covers how to create a monorepo in Go.\nLearning Objectives At the end of this lesson students will be able to do the following:\n Describe what a mono repo is List the purpose and benefits of a monorepo Reorganize a current project into a monorepo  What is a monorepo? A monorepo is one repository of code that holds the code for several smaller applications, such as microservices.\nEach smaller application would be independently compiled and deployable. Breaking each app into smaller deployable units reduces risk and allows deployments to be done faster, as you only deploy parts that are actually changed. Putting your smaller apps in one repository makes it easier to find the code you need instead of having to look in multiple repositories.\nThe following is an example of two microservices. Both productDisplay and register are independent applications.\nmonorepo |-- productDisplay |-- main.go |-- go.mod |-- productDisplay // The built binary |__ register |-- main.go |-- go.mod |-- register // The build binary Commons Any application in the monorepo would not be able to call on each other and cannot be a dependency to any other application. Instead a module (repository) of commons should be created, with each common package inside.\nFor example, see the below:\nmonorepo-commons |-- go.mod |-- tax |-- tax.go |-- tax_test.go |-- products |-- products.go |-- products_test.go In the above commons repo, tax and products would be internally created, dependencies for other applications.\nVersioning Commons Before releasing a new version to the common repo, integrated tests should be ran. Whereas when a microservice is being deployed, only the unit tests would be required.\nMark releases in github on the commons repo to make it available to each application.\nThen each application can update its go.mod when its ready.\nmodule github.homedepot.com/EMC4JQ2/monorepo/display require github.com/cookiemonster5/go-monorepo-commons v1.0.0 go 1.13 Point to a local commons The replace directive can be used to point to a local instance of commons while developing\nmodule github.homedepot.com/EMC4JQ2/monorepo/display require github.com/cookiemonster5/go-monorepo-commons v1.0.0 replace github.com/cookiemonster5/go-monorepo-commons =\u0026gt; /Users/EMC4JQ2/monorepo-parent/go-monorepo-commons go 1.13 Overall Structure The following is a final graphical representation of what a monorepo and a commons repo would look like.\n"
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/labs/lab-navigating-directories/",
	"title": "Navigating Directories Lab",
	"tags": [],
	"description": "",
	"content": "To practice navigating a directory, you will need to clone down a directory called command-line-kitchen-organizer. (If you do not know what clone means, no worries! We give you all of the steps you need!)\ncd ~/Downloads git clone https://github.com/one-thd/om_labs_command-line-kitchen-organizer.git cd om_labs_command-line-kitchen-organizer The file structure of this new directory is:\n. ├── kitchen │ ├── cans.txt │ ├── fridge │ │ ├── diapers.txt │ │ ├── freezer │ │ │ ├── couch.txt │ │ │ ├── frozenpeas.txt │ │ │ └── icecream.txt │ │ ├── milk.txt │ │ └── trashcan │ │ ├── banana-peels.txt │ │ ├── chicken-bones.txt │ │ ├── egg-shells.txt │ │ └── sink │ │ ├── clean-dishes.txt │ │ ├── delete-me.txt │ │ └── dirty-dishes.txt │ └── pantry │ ├── cans.txt │ ├── cereal.txt │ └── crisper-drawer │ └── lettuce.txt Using the newly created directory, do the following commands:\n Using relative file path, navigate to the freezer directory. Using relative file path, navigate to the crisper-drawer directory. Using absolute file path, navigate to the trashcan directory.  "
},
{
	"uri": "/javascript/nodejs/",
	"title": "NodeJS",
	"tags": [],
	"description": "",
	"content": "Welcome to NodeJS! "
},
{
	"uri": "/golang/foundations/packages/",
	"title": "Packages",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Understand how packages are used to organize code Package naming rules How to export from a package How to import and use packages Using external (3rd party) modules and packages  What are Packages? Packages are how code is modularized in go.\n They represent groups of related code. They can be made of one or many files. All Code in a package has the same level of access even if the code spans multiple files.  Package Naming Rules \u0026amp; Best Practices Rules\n lowercase no hyphens  Best Practices\n should be named after the directory they are in (not the full path), with the exception of main Avoid using generic package names such as utils and commons   ℹ️ Check out this go blog for a good explanation on how to name packages, and a bit more detail around the rules.\n Example Package \u0026amp; File  In your project, create a directory called messenger Inside that directory, create a file called firstpackage.go  Note: The file can be named anything you want it to be named.\nAdd the Following code to the file you created\npackage messenger import \u0026#34;fmt\u0026#34; func SayHello() { hello() } func hello() { fmt.Println(\u0026#34;Hello, World\u0026#34;) } You\u0026rsquo;ll be learning what this actually does later.\nYour First Package\nCongratulations, you\u0026rsquo;ve created your first package.\nNow lets learn how to use it!\nImporting Packages are imported from the import section of a go file.\nSyntax of a Go import\n[ module name ] + / + [ packagename ] Messenger package Full Import Path          Module: github.homedepot.com/om-labs/myproject   Package: messenger   Import Name: \u0026quot;github.homedpot.com/om-labs/myproject/messenger\u0026quot;    Note: If following along, remember to change your github org and repo sections to what you named them.\nUsing Packages In your code:\n Typically use the package name as the accessor to the code in the package code An alias can be set to avoid conflicts The module is versioned v2 or above  import ( \u0026#34;context\u0026#34; // package context  \u0026#34;fmt\u0026#34; // package fmt  \u0026#34;os/exec\u0026#34; // package exec  \u0026#34;github.homedpot.com/om-labs/myproject/messenger\u0026#34; // package messenger  // calculator is the accessor, but using v3 of the module.  \u0026#34;github.homedepot.com/someorg/somerepo/calculator/v3\u0026#34; // package messenger aliased with msgs  msgs \u0026#34;github.com/example-org/fakerepo/messenger\u0026#34; ) Note: Go has many built in packages that simply require the package name, or a simplified path.\nPackages Must Be Used!\nYour code will not compile unless you have done one of the following:\n used the package in your code prefixed the import with _ underscore  Use The messenger Package in you Main.go package main import \u0026#34;github.homedepot.com/om-labs/myproject/messenger\u0026#34; func main() { messenger.SayHello() } Visibility in Go: Exporting Keep it simple\nGo has no key words or methods for allowing access to a package\u0026rsquo;s contents.\nExported Names  Any Name (variable, type, function, etc) that begins with a capital letter Visible to the package and all external packages that import the package. Accessed externally by \u0026lt;package-name\u0026gt;.\u0026lt;Name\u0026gt;  Unexported names  Any Name (variable, type, function, etc) that begins with a lower case letter Can only be accessed within a package.  Example:\nIn the firstpackage.go file:\n SayHello is exported due to the uppercase S hello is unexported due to the lowercase h  func SayHello() { hello() } func hello() { fmt.Println(\u0026#34;Hello, World\u0026#34;) } Package Access  Packages can span 1 or many files. You do not need to import code that is in the same package if it is in another file Everything within the package has access to both the Exported and Unexported types  External Modules and Packages: AKA Dependencies  External packages are imported the same way as internal package Code will be automatically downloaded and compiled from the remote repository with the first test, run, or build commands. Versions of code are tracked in the go.mod and go.sum files when an imported is used.  Add an external Module: Let\u0026rsquo;s add the gofakeit module as an external module to our package:\n Navigate to the url and observe its contents In the same project above, open the main.go file for editing. Add in an import statement for gofakeit hint: github.com/brianvoe/gofakeit Add fmt.Println(gofakeit.Name()) somewhere within your main function Execute go run main.go  Your Dependencies are saved  Versions are tracked in the go.mod file Since gofakeit was found remotely it is stored inside $GOPATH/pkg/mod directory (module cache directory). A go.sum file is created that contains the expected cryptographic checksums of the content for specific module versions.  The \u0026ldquo;Latest\u0026rdquo; version is based on:\n Latest tagged stable, non-prerelease version Latest tagged prerelease version Latest untagged version  Summary In this lesson we covered:\n How Go uses packages to modularize code The naming rules for packages Importing and using packages Exporting from a package using capitalization Importing and using external modules and packages  "
},
{
	"uri": "/application-security/api-security/02_human_to_service_oidc/20_recap/",
	"title": "Quick Recap",
	"tags": [],
	"description": "",
	"content": "Roles in OAuth2  Resource Owner (Human, Optional :D ) Client (Browser, iPhone, FirstPhone, Server, etc) Resource Server (Service on PCF or GCP) Authorization Server (PingFed, AzureAD, etc)  Authorization Server (AS) / Identity Provider (IdP)  The Authorization Server\u0026rsquo;s job is to handle OAuth2 requests. It is always paired with an Identity Provided (IdP) whose job is to handle user authentication The IdP is usually invisible to the user. The Authorization Server is the trust broker between the client and the resource server  Grant Types The two main grants are:\n Client Credentials Grant (Servers) Authorization Code Grant (Humans)  Grants are sometimes referred to as flows\nJWT Tokens  Source of the JWT can be validated can be check for modification from original state Contains immutable claims about the Resource Owner/Client  Can you keep a secret? Private Clients  Service to Service Can hold a secret long term  Public Clients  Unable to hold a secret Browsers Native Mobile (Android, iOS, etc) CLI  "
},
{
	"uri": "/react/pillars/advanced-react/react-router-advanced/",
	"title": "React Router Advanced",
	"tags": [],
	"description": "",
	"content": "Advanced patterns with React Router v4 and the Marta API.\n Topics 1. Learning Objectives 1.1. Concepts 1.2. Skills   2. Application Scope and Setup 2.1. Purpose 2.2. Marta API 2.3. Semantic-UI-React 2.3.1. Installation   2.4. Application Structure 2.5. Lab 01 - Application Setup   3. Initial Route Setup 3.1. Switch 3.2. Lab 02 - Initial Route and Navigation   4. Semantic UI and Navbar Styling 4.1. Lab 03 - Semantic UI   5. Bus Container 5.1. Lab 04 - Bus Lines 5.2. Rendering Bus Routes 5.2.1. All Busses 5.2.2. Lines 5.2.3. Bus Line Presentation 5.2.4. All Busses Info   5.3. Bus Display Component 5.4. Lab 05 - Display Bus Line Info   6. One Bus 6.1. Lab 06 - Adherence   7. Displaying Maps 8. Summary   1. Learning Objectives 1.1. Concepts   Discuss Advanced Routing Techniques\n  Make use of the React Lifecycle for fetching data from an API\n  Introduce the Semantic React UI integration\n    1.2. Skills   Build complex and dynamic routes\n  Take a functional approach to building applications\n      2. Application Scope and Setup In this lesson, we are going to build a client side application for the real-time Marta API.\n Along with React, the technologies we\u0026#8217;ll be using include:\n   React Router v4\n  The Semantic UI React integration\n  MARTA Bus Realtime RESTful API\n   2.1. Purpose The aim of this application is to fetch data from the Marta API and give our users the ability to search by individual busses or bus line. We\u0026#8217;ll also give up to the minute reports on the bus schedule and provide a link to google maps for the next stop along the route.\n  2.2. Marta API Marta provides an open API for tracking bus information with 2 RESTful endpoints.\n   GetAllBus — returns all active buses with real-time data across the entire system http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetAllBus\n  GetBusByRoute — returns those active buses with real-time data for a given route http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetBusByRoute/{ROUTE}\n   We\u0026#8217;ll fetch data from the above endpoints inside the react lifecycle methods to populate our parent component\u0026#8217;s state.\n It\u0026#8217;s worth taking a moment to review sample JSON response (found in the Marta API documentation) to get a sense of the type of data we\u0026#8217;ll be working with.\n sample-json-response [ { \"ADHERENCE\":\"4\", \"BLOCKID\":\"31\", \"BLOCK_ABBR\":\"110-4\", \"DIRECTION\":\"Northbound\", \"LATITUDE\":\"33.8346347\", \"LONGITUDE\":\"-84.3824637\", \"MSGTIME\":\"5\\/14\\/2013 11:14:04 AM\", \"ROUTE\":\"110\", \"STOPID\":\"900456\", \"TIMEPOINT\":\"Peachtree Hills \u0026amp; Peachtree\", \"TRIPID\":\"3719918\", \"VEHICLE\":\"2853\" }, ]    2.3. Semantic-UI-React Semantic UI React is a css/js framework in the vein of Bootstrap, Material UI, Foundation, etc. We\u0026#8217;ll be using it on this project for it\u0026#8217;s simplicity and ease of use.\n 2.3.1. Installation Getting started is pretty straight-forward, install the JS and CSS packages from yarn/npm\n add-semantic-ui $ yarn add semantic-ui-react $ yarn add semantic-ui-css   We\u0026#8217;ll also need to import the semantic stylesheet in the index.js file\n src/index.js import React from 'react'; import ReactDOM from 'react-dom'; import 'semantic-ui-css/semantic.min.css'; import './index.css'; // ...     2.4. Application Structure We need to briefly discuss the structure of our application.\n   A User should be able to browse all current busses currently in service\n  The following information should be available at a glance\n  Bus Number\n  Bus Line\n  Next Stop\n     The user should be able to click on an individual bus and get up to date information\n  Next Stop\n  Information regarding if the bus is\n  on time\n  early\n  late\n           A User should be able to view all bus lines/routes\n  When the user clicks on a bus line/route they should be take to a view with all busses currently on that route\n     The user should be able to click on the bus stop and open a separate tab with the location loaded in Google Maps\n  Future implementations will include\n  User Authentication\n  Rail Info\n        For now, we\u0026#8217;re going to focus on the Bus Line as no API key is required. Based on the information above, we\u0026#8217;ll need the following components.\n   Bus Container - for managing the state of busses and lines\n  All Busses Component - for displaying all available busses\n  Single Bus Component - for displaying bus information\n  Bus Detail View Component - for displaying additional details\n  Bus Lines Component - for displaying all available bus lines\n  Navbar\n   The above is a simple outline, as we continue building we may add additional components and break components up into smaller pieces.\n  2.5. Lab 01 - Application Setup The repo for this lesson can be found here\n   clone the repo - git clone https://github.com/one-thd/om_labs_marta-client.git\n  check out branch 01-start\n  install and configure\n  eslint\n  prettier\n     run yarn\n  Setup components to match diagram found below\n  For now, create stateless/presentational components that will return a \u0026lt;div\u0026gt; with the component\u0026#8217;s name.\nie: \u0026lt;div\u0026gt; NavBar \u0026lt;/div\u0026gt;.\n      src ├── components │ ├── App.js │ ├── busses │ │ ├── AllBusses.js │ │ ├── Bus.js │ │ ├── BusContainer.js │ │ ├── Lines.js │ │ └── OneBus.js │ └── utils │ └── NavBar.js ├── index.js ├── registerServiceWorker.js └── styles ├── App.css └── index.css      3. Initial Route Setup Now it\u0026#8217;s time to setup our initial routes. The application flow that we are looking for should reflect the following patterns\n   Root route\n  proposed URI - /\n  this will eventually a landing/login page\n     Available Busses route\n  proposed URI - /busses\n  This component should show\n  All Busses currently operating\n  All Busses for a specific Bus line/route\n        Bus Detail View Route\n  proposed URI - /busses/:bus_id\n  Should show additional information about the bus and schedule\n     Bus Lines Route\n  proposed URI - /busses/lines\n  Should show all current Bus Lines/Routes\n     Bus Line Detail Route\n  proposed URI - /busses/lines/:line_id\n  Should show the available busses for this specific bus line/route\n     Rails route\n  proposed URI - /rails\n  Will eventually show the Marta Rail information\n            With this in mind, we\u0026#8217;ll first need to think about the root routes and navigation through the application.     We will setup a NavBar with 4 links/routes that load the corresponding components\n   Home - /\n  Available Busses - /busses\n  Bus Lines - /lines\n  Rails - /rails\n   Since we already installed react-router-dom we can jump right in. We\u0026#8217;ll start by setting up the application to use the BrowserRouter component\n src/index.js import React from 'react'; import ReactDOM from 'react-dom'; import { BrowserRouter as Router } from 'react-router-dom'; (1) import 'semantic-ui-css/semantic.min.css'; import './styles/index.css'; import App from './components/App'; import registerServiceWorker from './registerServiceWorker'; ReactDOM.render( \u0026lt;Router\u0026gt; (2) \u0026lt;App /\u0026gt; \u0026lt;/Router\u0026gt;, (2) document.getElementById('root') ); registerServiceWorker();     1 Import the BrowserRouter component from react-router   2 Wrap the Router around our application    If you\u0026#8217;re new to React Router v4, this still shouldn\u0026#8217;t be too unfamiliar. We are wrapping our entire application in the BrowserRouter.\n Next, we\u0026#8217;ll setup our root route\n src/components/App.js import React from 'react'; import { Switch, Route } from 'react-router-dom'; (1) import './styles/App.css'; const App = () =\u0026gt; ( \u0026lt;div className=\"App\"\u0026gt; \u0026lt;Switch\u0026gt; (2) \u0026lt;Route (3) exact (4) path=\"/\" (5) render={() =\u0026gt; \u0026lt;h1\u0026gt;Welcome to the real-time Marta React Client!\u0026lt;/h1\u0026gt;} (6) /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/div\u0026gt; ); export default App;     1 Import the Switch and Route components from React Router   2 Mount the Switch (details below)   3 Create a Route   4 declare exact for this route to avoid issues with loading the home component in every view   5 set the path to the root of your app   6 use the render prop to generate a simple component    3.1. Switch the Switch component will render the first Route that matches a location (href). The Documentation on Switch indicates that Switch renders routes exclusively\u0026#8230;\u0026#8203;\n  \u0026lt;Switch\u0026gt; is unique in that it renders a route exclusively. In contrast, every \u0026lt;Route\u0026gt; that matches the location renders inclusively. Consider this code:\n \u0026lt;Route path=\"/about\" component={About}/\u0026gt; \u0026lt;Route path=\"/:user\" component={User}/\u0026gt; \u0026lt;Route component={NoMatch}/\u0026gt;   If the URL is /about, then \u0026lt;About\u0026gt;, \u0026lt;User\u0026gt;, and \u0026lt;NoMatch\u0026gt; will all render because they all match the path. This is by design, allowing us to compose \u0026lt;Route\u0026gt; s into our apps in many ways, like sidebars and breadcrumbs, bootstrap tabs, etc.\n  \u0026#8212; React Router (web) Docs   While this is great! It\u0026#8217;s actually not the use case we are looking for at the moment. The documentation goes on to illustrate why we would be interested in using \u0026lt;Switch\u0026gt; at this point in our application.\n  Occasionally, however, we want to pick only one \u0026lt;Route\u0026gt; to render. If we’re at /about we don’t want to also match /:user (or show our “404” page). Here’s how to do it with Switch:\n import { Switch, Route } from 'react-router' \u0026lt;Switch\u0026gt; \u0026lt;Route exact path=\"/\" component={Home}/\u0026gt; \u0026lt;Route path=\"/about\" component={About}/\u0026gt; \u0026lt;Route path=\"/:user\" component={User}/\u0026gt; \u0026lt;Route component={NoMatch}/\u0026gt; \u0026lt;/Switch\u0026gt;   Now, if we’re at /about, \u0026lt;Switch\u0026gt; will start looking for a matching \u0026lt;Route\u0026gt;.\n \u0026lt;Route path=\"/about\"/\u0026gt; will match and \u0026lt;Switch\u0026gt; will stop looking for matches and render \u0026lt;About\u0026gt;. Similarly, if we’re at /michael then` \u0026lt;User\u0026gt;` will render.\n  \u0026#8212; React Router (web) Docs   Currently you can navigate to any URL in the application. Since we only have one route configured, any other URL will just show a blank page. However, with \u0026lt;Switch\u0026gt; we can setup a \u0026lt;Route\u0026gt; component that will render a generic (or fancy) 404 message when any unknown routes are accessed.\n We can create the 404 (or 'NoMatch') component when we setup the rest of our routes.\n  3.2. Lab 02 - Initial Route and Navigation   Checkout branch 02-initial-routes\n  Create a new component in utils named NoMatch\n  The component should tell the user the page/resource/however-you-want-to-word-it is unavailable\n  You should also provide a Link back to the hompage ie: \"The page you\u0026#8217;ve requested is unavailable, click here to go home\"\n     Set your router up to render the NoMatch component when the users types in an unknown route\n  Provide a \u0026lt;Route\u0026gt; for /busses that handles navigation to the BusContainer component\n  Create a \u0026lt;Route\u0026gt; for /rails that renders a simple \u0026lt;h1\u0026gt; that says Coming Soon!\n  Setup your NavBar to provide routes to:\n  Home\n  Available Busses\n  Lines - the route will be /busses/lines, however it currently won\u0026#8217;t work. We\u0026#8217;ll set it up shortly\n  Rails\n     Check to insure that Home, Available Busses, and Rails load the proper components\n   note: We will style the NavBar later, but feel free to add something like \u0026lt;span\u0026gt; | \u0026lt;/span\u0026gt; between each of your nav links to add some spacing.\n    4. Semantic UI and Navbar Styling Now that we have a functional Navbar, let\u0026#8217;s go ahead and add some styling to the application.\n The ideal scenario is to create a sidenav that persists through the application. We\u0026#8217;ll be using use several components from Semantic UI starting with Grid\n src/components/App.js import React from 'react'; import { Switch, Route } from 'react-router-dom'; import { Grid } from 'semantic-ui-react'; (1) // ... const App = () =\u0026gt; ( \u0026lt;Grid padded relaxed\u0026gt; (2) \u0026lt;Grid.Column width={2}\u0026gt; (3) \u0026lt;NavBar /\u0026gt; \u0026lt;/Grid.Column\u0026gt; (3) \u0026lt;Grid.Column only={('tablet', 'mobile')} tablet={2} mobile={2} /\u0026gt; (4) \u0026lt;Grid.Column computer={13} tablet={10} mobile={10}\u0026gt; (5) \u0026lt;Switch\u0026gt; \u0026lt;Route exact path=\"/\" render={() =\u0026gt; \u0026lt;h1\u0026gt;Welcome to the real-time Marta React Client!\u0026lt;/h1\u0026gt;} /\u0026gt; \u0026lt;Route path=\"/busses\" component={BusContainer} /\u0026gt; \u0026lt;Route path=\"/rails\" render={() =\u0026gt; \u0026lt;h1\u0026gt;Coming Soon!\u0026lt;/h1\u0026gt;} /\u0026gt; \u0026lt;Route render={() =\u0026gt; \u0026lt;h1\u0026gt;We were unable to locate this resource\u0026lt;/h1\u0026gt;} /\u0026gt; \u0026lt;Route component={NoMatch} /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/Grid.Column\u0026gt; (5) \u0026lt;/Grid\u0026gt; (2) ); export default App;     1 Import the Grid component from Semantic UI React   2 Wrap our application in the Grid specifying that we wan the padded and relaxed props set to be true   3 Wrap the Navbar in a Grid.Column specifying a width of 2 columns   4 Add a Grid.Column component that is present only on tablet and mobile for a bit of responsiveness   5 Wrap the remainder of the app in a Grid.Column specifying column widths at various breakpoints    To learn more about Grid and it\u0026#8217;s props checkout the Semantic UI Grid documentation\n Now we can make the NavBar function as a sidebar by using the Menu component.\n src/utils/NavBar.js import React from 'react'; import { NavLink } from 'react-router-dom'; import { Menu } from 'semantic-ui-react'; (1) const NavBar = () =\u0026gt; ( \u0026lt;nav className=\"navbar\"\u0026gt; \u0026lt;Menu fixed=\"left\" compact vertical inverted stackable\u0026gt; (2) \u0026lt;Menu.Item\u0026gt; (3) \u0026lt;NavLink to=\"/\"\u0026gt;Home\u0026lt;/NavLink\u0026gt; \u0026lt;/Menu.Item\u0026gt; (3) \u0026lt;Menu.Item\u0026gt; \u0026lt;NavLink to=\"/busses\"\u0026gt;Available Busses\u0026lt;/NavLink\u0026gt; \u0026lt;/Menu.Item\u0026gt; \u0026lt;Menu.Item\u0026gt; \u0026lt;NavLink to=\"/busses/lines\"\u0026gt;Bus Lines\u0026lt;/NavLink\u0026gt; \u0026lt;/Menu.Item\u0026gt; \u0026lt;Menu.Item\u0026gt; \u0026lt;NavLink to=\"/rails\"\u0026gt;Rails \u0026lt;/NavLink\u0026gt; \u0026lt;/Menu.Item\u0026gt; \u0026lt;/Menu\u0026gt; (2) \u0026lt;/nav\u0026gt; ); export default NavBar;     1 Import the Menu component from Semantic UI React   2 Wrap the Nav items in a Menu specifying the appropriate props   3 Wrap each NavLink in the Menu.Item component    4.1. Lab 03 - Semantic UI   Take a few minutes to add these changes or checkout branch 03-navbar-styling\n  Read up on the props we used for the Menu component in the Menu Documentation\n  Research the additional components we will be using, including:\n  Card\n  Divider\n  Feed\n         5. Bus Container Now we can start working on the API portion of the App. What we want to do is fetch data from the endpoint that will return all busses.\n This can be accomplished through making a call http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetAllBus\n By clicking on the link above, or sending a GET request through postman, you\u0026#8217;ll see that we get a huge list of JSON objects with their corresponding data.\n Our next step is to determine how we can make use of the React lifecycle to store this data in the state of our Bus Container.\n First, since we are going to be using the react lifecycle and state, we need to convert our Bus Container into an ES6 class.\n src/components/busses/BusContainer.js import React, { Component } from 'react'; (1) class BusContainer extends Component { constructor() { (2) super(); this.state = { busses: [], (3) lines: [] (4) }; } render() { return \u0026lt;div\u0026gt;Bus Container\u0026lt;/div\u0026gt;; } } export default BusContainer;     1 Import Component from React so we can extend the capabilities of our component   2 add a constructor so we can intialize state   3 add an empty array for busses   4 add an empty array for lines    We will need to think through how to properly parse the data and store it as state. A good starting place would be to make an ajax call to the endpoint in the componentDidMount lifecycle hook.\n Let\u0026#8217;s start by just making sure we can log the data.\n src/components/busses/BusContainer.js import React, { Component } from 'react'; class BusContainer extends Component { // ... componentDidMount = () =\u0026gt; { fetch( 'http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetAllBus' ) (1) .then(response =\u0026gt; response.json()) (2) .then(busses =\u0026gt; { (3) console.log(busses); (4) }); }; // ... }     1 make a fetch call to the API endpoint   2 parse the response   3 name the value being passed in as an argument (from our previous function)   4 log the value to the console    Unfortunately, we\u0026#8217;re hitting a snag. You\u0026#8217;ll see a CORS issue logged to the console. This is not uncommon. Unfortunately the API we are using does not know our identity. There are several workaround for this problem. One of the most simple approaches is to use CORS Anywhere which serves as a Node Proxy and attached CORS headers to our request.\n To implement, we\u0026#8217;ll prepend the URL to our fetch request\n src/components/busses/BusContainer.js import React, { Component } from 'react'; const proxyUrl = 'https://cors-anywhere.herokuapp.com/'; (1) // ... componentDidMount = () =\u0026gt; { const targetUrl = 'http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetAllBus'; (2) fetch(proxyUrl + targetUrl) (3) .then(response =\u0026gt; response.json()) .then(busses =\u0026gt; { console.log(busses); }); };     1 establish and define the proxy URL   2 store the API endpoint in a variable for convenience   3 prepend the proxy URL to our fetch request    Now we should be logging bus data to the console. Next we\u0026#8217;ll need to figure out how to get that data into the state.\n src/components/busses/BusContainer.js componentDidMount = () =\u0026gt; { const targetUrl = 'http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetAllBus'; fetch(proxyUrl + targetUrl) .then(response =\u0026gt; response.json()) .then(busses =\u0026gt; { this.setState({ busses }); }); };   5.1. Lab 04 - Bus Lines We have all of the Bus Line data in the response. Take a look at the example response\n example-response { \"ADHERENCE\": \"-13\", \"BLOCKID\": \"448\", \"BLOCK_ABBR\": \"71-5\", \"DIRECTION\": \"Eastbound\", \"LATITUDE\": \"33.7385109\", \"LONGITUDE\": \"-84.4243359\", \"MSGTIME\": \"1/7/2018 4:48:00 PM\", \"ROUTE\": \"71\", \"STOPID\": \"900247\", \"TIMEPOINT\": \"Cascade Ave \u0026amp; Beecher St\", \"TRIPID\": \"5818933\", \"VEHICLE\": \"1456\" }   The item that we want to work with is \"ROUTE\", we are going to change the name (in our app) to Line as to avoid confusion.\n   checkout branch 04-bus-container-setup\n  inside the last then function\n  iterate over the busses and produce a new array of bus lines/routes\nnote: the lines array only needs to consist of string values\n  merge the new data into the lines array in your component state\n       5.2. Rendering Bus Routes Now that we have bus information, we can start rendering our presentational (child) components.\n 5.2.1. All Busses We know that AllBusses will display all available busses. So we\u0026#8217;ll start by making sure the AllBusses component renders when the /busses path/URI is matched.\n JavaScript import React, { Component } from 'react'; import { Switch, Route } from 'react-router-dom'; (1) import AllBusses from './AllBusses'; (2) const proxyUrl = 'https://cors-anywhere.herokuapp.com/'; class BusContainer extends Component { // .. render() { const { busses, lines } = this.state; return ( \u0026lt;div\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route exact (3) path=\"/busses\" render={routeProps =\u0026gt; \u0026lt;AllBusses {...routeProps} busses={busses} /\u0026gt;} (4) /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/div\u0026gt; ); } }     1 Import Switch and Route components from React Router   2 Import the AllBusses component   3 set an exact prop on the /busses route/URI   4 render the AllBusses component, passing to it as props, the routeProps received from the Router and the busses array.    Now, when the BusContainer mounts at the /busses path/URI, the AllBusses component will be displayed.\n  5.2.2. Lines As you can see, the Available Busses component is being mounted. We\u0026#8217;ll come back and add data shortly, but\u0026#8217;s first, we need to fix that one last link on our navbar.\n JavaScript import React, { Component } from 'react'; import { Switch, Route } from 'react-router-dom'; import AllBusses from './AllBusses'; import Lines from './Lines'; (1) const proxyUrl = 'https://cors-anywhere.herokuapp.com/'; class BusContainer extends Component { // ... render() { const { busses, lines } = this.state; return ( \u0026lt;div\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route path=\"/busses/lines\" (2) render={routeProps =\u0026gt; \u0026lt;Lines {...routeProps} lines={lines} /\u0026gt;} (3) /\u0026gt; \u0026lt;Route exact path=\"/busses\" render={routeProps =\u0026gt; \u0026lt;AllBusses {...routeProps} busses={busses} /\u0026gt;} /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/div\u0026gt; ); } }     1 Import the Lines component   2 supply /busses/lines as the argument to the path prop   3 Render the Lines component passing the appropriate values as props    We have placed the new \u0026lt;Route\u0026gt; on top of the previously built \u0026lt;Route\u0026gt;. This is to ensure that the /busses route acts as a default if no other Route 's match.\n Clicking on the link to Bus Lines (in the navbar) should render the Lines component.\n  5.2.3. Bus Line Presentation Presenting Bus Line information is pretty straight-forward. We want to provide a list of all available Bus Lines and provide a link to show all busses running on that line.\n To start, we can just render all lines as text and then determine how to turn them into Links.\n src/components/busses/lines.js import React from 'react'; const Lines = ({ match, lines }) =\u0026gt; ( (1) \u0026lt;div className=\"allLines\"\u0026gt; (2) \u0026lt;h3\u0026gt; All Bus Lines \u0026lt;/h3\u0026gt; {lines.map(line =\u0026gt; \u0026lt;p key={line}\u0026gt;Bus Line: {line}\u0026lt;/p\u0026gt;)} (3) \u0026lt;/div\u0026gt; ); export default Lines;     1 destructure the incoming props - match comes from routeProps, use the spread operator to spread out the remaining props   2 Add the className of allLines to activate extra styling (found in App.css)   3 Iterate over the lines array (from props), and produce an array of paragraph elements showing the Bus Line info    Alright, so this works, but it\u0026#8217;s not very helpful. Let\u0026#8217;s turn those lines into Links.\n src/components/busses/Lines.js import React from 'react'; import { Link } from 'react-router-dom'; (1) const Lines = ({ match, lines }) =\u0026gt; ( \u0026lt;div className=\"allLines\"\u0026gt; \u0026lt;h3\u0026gt; All Bus Lines \u0026lt;/h3\u0026gt; {lines.map(line =\u0026gt; ( \u0026lt;Link key={line} to={`${match.path}/${line}`}\u0026gt; (2) {' '} Bus Line: {line} \u0026lt;/Link\u0026gt; ))} \u0026lt;/div\u0026gt; );     1 Import Link from React Router   2 Render a Link with the path/URI matching the exiting path and appending a line ID    Clicking on this link (at the moment) won\u0026#8217;t do anything other than change the URI. We still need to style this and make our component presentable. Then we\u0026#8217;ll focus on displaying the correct component.\n Unfortunately, this component is becoming a little cluttered. Let\u0026#8217;s make it a little easier to reason-about\n src/components/busses/Lines.js import React from 'react'; import { Link } from 'react-router-dom'; const displayLines = (match, lines) =\u0026gt; (1) lines.map(line =\u0026gt; ( \u0026lt;Link key={line} to={`${match.path}/${line}`}\u0026gt; {' '} Bus Line: {line} \u0026lt;/Link\u0026gt; )); const Lines = ({ match, lines }) =\u0026gt; ( \u0026lt;div className=\"allLines\"\u0026gt; \u0026lt;h3\u0026gt; All Bus Lines \u0026lt;/h3\u0026gt; {displayLines(match, lines)} (2) \u0026lt;/div\u0026gt; );     1 create a function named displayLines passing match and lines as arguments. Then move the existing render logic into the return value of the new function.   2 Invoke the displayLines function    Now, let\u0026#8217;s add some style\n src/components/busses/Lines.js import React from 'react'; import { Link } from 'react-router-dom'; import { Feed, Divider } from 'semantic-ui-react'; (1) const displayLines = (match, lines) =\u0026gt; lines.map(line =\u0026gt; ( \u0026lt;Feed.Content key={line}\u0026gt; (2) \u0026lt;Link to={`${match.path}/${line}`}\u0026gt; Bus Line: {line}\u0026lt;/Link\u0026gt; \u0026lt;/Feed.Content\u0026gt; (2) )); const Lines = ({ match, lines }) =\u0026gt; ( \u0026lt;div className=\"allLines\"\u0026gt; \u0026lt;Feed size=\"large\"\u0026gt; (3) \u0026lt;h3\u0026gt; All Bus Lines \u0026lt;/h3\u0026gt; \u0026lt;Divider /\u0026gt; (4) {displayLines(match, lines)} \u0026lt;/Feed\u0026gt; (3) \u0026lt;/div\u0026gt; ); export default Lines;     1 Import the Feed and Divider components from Semantic UI React   2 Wrap the Link in the Feed.Content component   3 Create the Feed   4 Create a Divider for style and spacing     5.2.4. All Busses Info In order to display Bus data when clicking on a Bus Line, we\u0026#8217;ll need to determine how to display data in the AllBusses component. There is a lot to unpack, so hang in there, we\u0026#8217;ll take it line by line.\n JavaScript import React from 'react'; import { Card, Divider } from 'semantic-ui-react'; (1) import Bus from './Bus'; (2) const busses = (path, busArray) =\u0026gt; (3) busArray.map((bus, index) =\u0026gt; ( (4) \u0026lt;Bus (5) key={index} (6) path={path} (7) busNumber={bus.VEHICLE} (8) busLine={bus.ROUTE} (9) nextStop={bus.TIMEPOINT} (10) /\u0026gt; )); const AllBusses = ({ match, ...props }) =\u0026gt; ( (11) \u0026lt;div className=\"allBusses\"\u0026gt; \u0026lt;h3\u0026gt; All Busses\u0026lt;/h3\u0026gt; \u0026lt;Divider /\u0026gt; (12) \u0026lt;Card.Group itemsPerRow={4} doubling stackable\u0026gt; (13) {busses(match.path, props.busses)} (14) \u0026lt;/Card.Group\u0026gt; \u0026lt;/div\u0026gt; ); export default AllBusses;     1 Import the Card and Divider components form Semantic UI React   2 Import the Bus component   3 create a function named busses passing in 2 arguments path and busArray that will be received as props in the presentational component.   4 iterate over the busArray passing the bus object, and index as arguments   5 return a \u0026lt;Bus\u0026gt; component   6 Give a key so that React can properly diff items on subsequent renders   7 pass along the path from our routeParams   8 pass along the bus vehicle number as a prop named busNumber   9 pass along the bus line/route as a prop named busLine   10 pass along the next intended stop (physical location) as a prop named nextStop   11 pass the routeProp 's match property and remaining props in as arguments for building the AllBusses presentational component   12 render a Divider for style   13 render a Card.Group passing props defining layout and responsiveness   14 invoke the busses function passing in the appropriate arguments    This pattern isn\u0026#8217;t drastically different from the steps we took with our Line component. Instead of rendering a pre-built \u0026lt;Link\u0026gt; component, we are rendering our own \u0026lt;Bus\u0026gt; component.\n Now, obviously, we\u0026#8217;ll need to properly display the information in the Bus component. But if you take a few minutes to inspect the props of \u0026lt;Bus\u0026gt; in the react dev tools, you\u0026#8217;ll see that all of the information we need is present.\n   5.3. Bus Display Component The bus info that we want to display will include\n   Bus Number\n  Bus Line\n  Next Stop\n   We can display this information in small cards to give a better look and feel.\n Simply displaying the information should be simple enough. We\u0026#8217;ll start there, and then work on styling\n src/components/busses/Bus.js import React from 'react'; import { Link } from 'react-router-dom'; (1) const Bus = ({ path, (2) busNumber, (2) busLine, (2) nextStop (2) }) =\u0026gt; ( \u0026lt;div\u0026gt; Bus \u0026lt;Link to={`${path}/${busNumber}`}\u0026gt;{busNumber}\u0026lt;/Link\u0026gt; (3) Line: \u0026lt;Link to={`${path}/lines/${busLine}`}\u0026gt;{busLine}\u0026lt;/Link\u0026gt; (4) Next Stop: {nextStop} (5) \u0026lt;/div\u0026gt; ); export default Bus;     1 Import Link from React Router   2 Use object destructuring for props being passed in to component   3 Render a \u0026lt;Link\u0026gt; pointing to the routeProps path (/busses) with the busNumber as the id. /busses/:id   4 Render a Link pointing to the specific Bus Line. /busses/lines/:line_id   5 Render the nextStop    Both busNumber and busLine are going to serve as URL params that we can use to display more specific and detailed information.\n Now, we just need to add some style!\n JavaScript // ... import { Card } from 'semantic-ui-react'; (1) const Bus = ({ // ... }) =\u0026gt; ( \u0026lt;Card\u0026gt; (2) \u0026lt;Card.Content\u0026gt; (3) \u0026lt;Card.Header\u0026gt; (4) Bus \u0026lt;Link to={`${path}/${busNumber}`}\u0026gt;{busNumber}\u0026lt;/Link\u0026gt; \u0026lt;/Card.Header\u0026gt; (4) \u0026lt;Card.Meta\u0026gt; (5) Line: \u0026lt;Link to={`${path}/lines/${busLine}`}\u0026gt;{busLine}\u0026lt;/Link\u0026gt; \u0026lt;/Card.Meta\u0026gt; (5) \u0026lt;Card.Description\u0026gt;Next Stop: {nextStop}\u0026lt;/Card.Description\u0026gt; (6) \u0026lt;/Card.Content\u0026gt; (3) \u0026lt;/Card\u0026gt; (2) );     1 Import Card from Semantic UI React   2 Render a Card component   3 Wrap the contents in \u0026lt;Card.Content\u0026gt;   4 Make the Bus Number the Card.Header   5 Make the Bus Line a subheading by using Card.Meta   6 Display the Next Stop in the body of the Card by using Card.Description    Alright! Now we\u0026#8217;re displaying Bus information and are even displaying Links. Next we need to figure out how to Render additional information when someone clicks on the info.\n  5.4. Lab 05 - Display Bus Line Info When a user clicks on the Specific Bus Line either from the Bus Card we just implemented, or the Bus Line component, they should be taken to a view containing only busses for the Bus Line.\n Thankfully, we\u0026#8217;ve already implemented the majority of the logic. We can actually use the AllBusses component with a smaller array of items. It\u0026#8217;s your turn to implement!\n   check out branch 05-display-bus-info\n  In BusContainer\n  Add a \u0026lt;Route\u0026gt; that renders AllBusses\n  Pass in the correct path\n  Pass in all necessary props\n     In AllBusses.js\n  Display only the busses that belong to the Bus Line the user has selected\n         6. One Bus It would be nice to display additional information about the Bus. Like whether the bus is running early or late. When the user clicks on a specific Bus. Let\u0026#8217;s make that happen\n We\u0026#8217;ll start by adding a Route to our OneBus component right above our /busses \u0026lt;Route\u0026gt;\n src/components/busses/BusContainer.js // ... import OneBus from './OneBus'; // ... class BusContainer extends Component { // ... render(){ // ... \u0026lt;Switch\u0026gt; // ... \u0026lt;Route path={`${this.props.match.path}/:busId`} render={routeProps =\u0026gt; ( \u0026lt;OneBus {...routeProps} busses={busses}/\u0026gt; )}/\u0026gt; // ... \u0026lt;/Switch\u0026gt; // ... } }   To display the content in OneBus, we\u0026#8217;ll need to some work. We can start by writing a function that searches for the specific Bus based on the params. Then we\u0026#8217;ll display the bus information. If no Bus is found, we\u0026#8217;ll also setup a Redirect back to all Busses.\n src/components/busses/OneBus.js import React from 'react'; import { Redirect } from 'react-router-dom'; (1) const OneBus = ({ match, busses }) =\u0026gt; { (2) const bus = busses.find(b =\u0026gt; match.params.busId === b.VEHICLE); (3) return ( \u0026lt;div className=\"oneBus\"\u0026gt; {bus ? ( (4) \u0026lt;div\u0026gt; Bus {bus.VEHICLE} is headed {bus.DIRECTION} toward {bus.TIMEPOINT} (5) \u0026lt;/div\u0026gt; ) : ( \u0026lt;Redirect to=\"/busses\" /\u0026gt; (6) )} \u0026lt;/div\u0026gt; ); };     1 Import Redirect from React Router   2 destructure the props being passed in as arguments   3 Use the find array method to find the correct bus   4 if a bus is found display the info   5 Display the Bus Number, Bus Direction, and Bus Stop   6 If no Bus is found, redirect the user automatically to the /busses endpoint    Let\u0026#8217;s add a little style to this component\n src/components/busses/OneBus.js import React from 'react'; import { Segment } from 'semantic-ui-react'; (1) const OneBus = ({ match, busses }) =\u0026gt; { const bus = busses.find(b =\u0026gt; match.params.busId === b.VEHICLE); return ( \u0026lt;div className=\"oneBus\"\u0026gt; {bus ? ( \u0026lt;Segment size=\"massive\"\u0026gt; (2) Bus {bus.VEHICLE} is headed {bus.DIRECTION} toward {bus.TIMEPOINT} \u0026lt;/Segment\u0026gt; (3) ) : ( \u0026lt;Redirect to=\"/busses\" /\u0026gt; )} \u0026lt;/div\u0026gt; ); };     1 Import Segment from Semantic UI React   2 Wrap the Segment component around the bus info    6.1. Lab 06 - Adherence   checkout branch 06-bus-info\n  write a function named adherence that\n  evaluates the ADHERENCE property on the bus object\nhint: you\u0026#8217;ll need to convert the string to a number\n  Returns the string on time if the ADHERENCE is 0\n  Returns a string indicating the bus is early if ADHERENCE is greater than 0\nie: '4 minutes ahead of schedule'\n  Returns a string indicating the bus is late if ADHERENCE is less than 0\nie: 3 minutes behind schedule\n     Render the result of the function inside of your SEGMENT component\nie: Bus 1117 is headed Southwest\u0026#8230;\u0026#8203; and is 5 minutes ahead of schedule\n      7. Displaying Maps The last order of business is to allow the user to click on the Next Stop and open a separate tab with Google Map preloaded. In the future, we may want display the information within our application. For now however, we can still provide a nice feature for our users without too much effort.\n To accomplish this task we need think through the various steps\n   determine how to display the actual location in google maps on load\n  write a function that\n  returns a link displaying the nextStop\n  opens in a separate tab\n     pass the function down as a prop to all components that may need it.\n   We can start by opening Google Maps and looking at the Google Maps URL Documentation which states that you can\u0026#8230;\u0026#8203;\n  launch a Google Map that displays a pin for a specific place, or perform a general search and launch a map to display the results\n  \u0026#8212; Google Maps URL Documentation   The endpoint for this operation is https://www.google.com/maps/search/?api=1\u0026amp;parameters, and the parameter we\u0026#8217;ll be using is query. ie: https://www.google.com/maps/search/?api=1\u0026amp;query=West+End+Station.\n Clicking this link opens a map and drops a pin on, or really close, to the station. All of this can all be done without an API key. So it\u0026#8217;s a quick (mvp) way to make this feature functional in our application.\n First, we\u0026#8217;ll write a function in the BusContainer component that will handle this operation.\n src/components/busses/BusContainer.js mapLocation = nextStop =\u0026gt; ( \u0026lt;a href={`https://www.google.com/maps/search/?api=1\u0026amp;query=${nextStop .split(' \u0026amp; ') .join('+@+') .split(' ') .join('+')}`} target=\"blank\"\u0026gt; {nextStop} \u0026lt;/a\u0026gt; );   In the example above, we are using split to create an array from string, separating the values at the specified identifier. We then use join to turn the array back into a string replacing the commas separated values with the specified identifier. We\u0026#8217;re also using target=\"blank\" to ensure that a new tab is opened on click.\n Now, we can pass the function down as a prop to our AllBusses component.\n src/components/busses/BusContainer.js //... class BusContainer extends Component { // ... render() { // ... \u0026lt;Route path=\"/busses/lines/:id\" render={props =\u0026gt; ( \u0026lt;AllBusses {...props} busses={busses} mapLocation={this.mapLocation} /\u0026gt; )} /\u0026gt; // ... \u0026lt;Route exact path=\"/busses\" render={routeProps =\u0026gt; ( \u0026lt;AllBusses {...routeProps} busses={busses} mapLocation={this.mapLocation} /\u0026gt; )} /\u0026gt; //... } }   From here, we\u0026#8217;ll the function down to our Bus component\n src/components/busses/AllBusses.js // ... const busses = (path, busArray, mapLocation) =\u0026gt; (1) busArray.map((bus, index) =\u0026gt; ( \u0026lt;Bus key={index} path={path} mapLocation={mapLocation} (2) busNumber={bus.VEHICLE} busLine={bus.ROUTE} nextStop={bus.TIMEPOINT} /\u0026gt; )); const AllBusses = ({ match, ...props }) =\u0026gt; { return match.params.id ? ( // ... {busses( match.path.replace('/lines/:id', ''), props.busses.filter(bus =\u0026gt; bus.ROUTE === match.params.id), props.mapLocation (3) )} // ... ) : ( // ... {busses(match.path, props.busses, props.mapLocation)} (3) // ... ); };     1 create an additional parameter for our busses function   2 pass the mapLocation argument down as a prop   3 pass in props.mapLocation the argument to our busses function    src/components/busses/AllBusses.js // ... const Bus = ({ // ... mapLocation (1) }) =\u0026gt; ( \u0026lt;Card\u0026gt; // ... \u0026lt;Card.Description\u0026gt;Next Stop: {mapLocation(nextStop)}\u0026lt;/Card.Description\u0026gt; (2) // ... \u0026lt;/Card\u0026gt; );     1 use destructuring to access the mapLocation prop   2 invoke the mapLocation function, passing in nextStop as the argument    We\u0026#8217;re now able to click on any of the bus stops and view a google map of the location.\n   8. Summary That wraps up our first pass at building a client side application that interacts with an API and makes use of some advanced routing techniques. If you would like to continue building out this application, please do! Just fork it and submit a PR.\n   "
},
{
	"uri": "/react/pillars/perf-opt-strategies/memo/",
	"title": "React.memo",
	"tags": [],
	"description": "",
	"content": "Use React.memo to avoid unnecessary renders of a complex component.\nBackground React.memo is React\u0026rsquo;s way of memoizing a function component.\nBefore React added hooks, components could be marked as pure by defining a class component that extends PureComponent.\nimport React from \u0026#39;react\u0026#39;; export default class Message extends React.PureComponent { render() { return ( \u0026lt;div\u0026gt;{this.props.message}\u0026lt;/div\u0026gt; ); } } Another approach with class components is to extend React.Component and then override the shouldComponentUpdate method:\nexport default class Message extends React.Component { shouldComponentUpdate(nextProps, nextState) { // render the component only if the props or state value has changed  // this logic could be customized for specific use cases  return nextProps !== this.props || nextState !== this.state } } This is essentially what React.PureComponent does for you. But defining your own shouldComponentUpdate method provides greater flexibility in determining exactly what conditions should cause a re-render.\nFunction Components and React.memo For function components, we can use React.memo to declare that a component is \u0026ldquo;pure\u0026rdquo; and should not be re-rendered unless it\u0026rsquo;s props or state has changed.\nfunction Message({ message }) { return \u0026lt;div\u0026gt;{message}\u0026lt;/div\u0026gt; } export default React.memo(Message) // use React.memo to memoize the function component With React.memo the Message component will only be rendered on initial load and when it\u0026rsquo;s props or state changes.\nShould We Always Use Component Memoization? The short answer is \u0026ldquo;No\u0026rdquo;.\n Memoizing a component (via PureComponent, shouldComponentUpdate, or React.memo), comes with its own overhead. With component memoization, React has to do the extra work of comparing props and state to determine if either has changed. Often it\u0026rsquo;s faster just to re-render the component to the virtual DOM and then let the reconciliation process determine if there are any changes to the physical DOM.  Another way to phrase this question is: \u0026ldquo;Why isn\u0026rsquo;t React.memo the default behavior for React components?\u0026rdquo;\nFor more discussion on this, see the following resources:\n Make stateless components “Pure” by default in React 17. Do functional components behave like React.Component or React.PureComponent? Also, using React.memo on a component assumes that all descendants of that component also do not need to be re-rendered (are they all also pure?).  Also, consider this quote from the React Docs:\n React.PureComponent’s shouldComponentUpdate() only shallowly compares the objects. If these contain complex data structures, it may produce false-negatives for deeper differences. Only extend PureComponent when you expect to have simple props and state, or use forceUpdate() when you know deep data structures have changed. Or, consider using immutable objects to facilitate fast comparisons of nested data.\nFurthermore, React.PureComponent’s shouldComponentUpdate() skips prop updates for the whole component subtree. Make sure all the children components are also “pure”.\n Summary  For class components, extend PureComponent or override shouldComponentUpdate to eliminate costly and unnecessary renders For function components, use React.memo to memoize the function component. Don\u0026rsquo;t apply these optimizations unless you know that the component is costly to re-render, such as when rendering charts, graphs, animations, or other visualizations that require a lot of CPU time.  Lab - Approximately 10 minutes  Use the React Performance Optimization Playground App for this lab. You will find a \u0026ldquo;React.memo\u0026rdquo; example and within that there are tabs for \u0026ldquo;Before\u0026rdquo; and \u0026ldquo;After\u0026rdquo;. The code for these tabs is found in the project source code under the folder src/pages/MemoEx. Currently the code in the Before folder and the After folder are identical. Make the necessary changes in the After folder to memoize the Counter and PI Calculator components. Test that when you interact with the parent component, the child components no longer re-render.  "
},
{
	"uri": "/javascript/pillars/resiliency-patterns/",
	"title": "Resiliency Patterns in JavaScript",
	"tags": [],
	"description": "",
	"content": "Welcome to Resiliency Patterns in JavaScript! "
},
{
	"uri": "/javascript/express/restful-apis/",
	"title": "RESTful APIs",
	"tags": [],
	"description": "",
	"content": "Restful APIs To learn about RESTful APIs, see: RESTful APIs\n"
},
{
	"uri": "/javascript/performance/universal-rendering-lab/step-1/",
	"title": "Step 1: Create a route handler",
	"tags": [],
	"description": "",
	"content": "First, we need to create a route handler with Express so that we can build the document dynamically, rather than serving a static index.html file.\nindex.html is currently being served out of the public/ directory. Let\u0026rsquo;s create a route handler in src/server/app.js for the / route and send the contents of public/index.html as a response.\n Copy/paste the contents of public/index.html into a route handler in src/server/app.js.  // src/server/app.js // rather than serve index.html as a static file, detect when the user // visits the root of the web app and construct a page dynamically app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;client-bundle.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); });   Delete public/index.html\n  Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and you should see the application rendering in the same way as it did previously\n  Remove the client-bundle script, so that it will not overwrite our server-generated markup which we will create later in the lab.\n  // src/server/app.js // rather than serve index.html as a static file, detect when the user // visits the root of the web app and construct a page dynamically app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); });   Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and you should now see a blank screen.\n  Next, we need to find a way to generate the markup for our application on the server.\n"
},
{
	"uri": "/react/performance/universal-rendering-lab/step-1/",
	"title": "Step 1: Create a route handler",
	"tags": [],
	"description": "",
	"content": "First, we need to create a route handler with Express so that we can build the document dynamically, rather than serving a static index.html file.\nindex.html is currently being served out of the public/ directory. Let\u0026rsquo;s create a route handler in src/server/app.js for the / route and send the contents of public/index.html as a response.\n Copy/paste the contents of public/index.html into a route handler in src/server/app.js.  // src/server/app.js // rather than serve index.html as a static file, detect when the user // visits the root of the web app and construct a page dynamically app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;client-bundle.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); });   Delete public/index.html\n  Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and you should see the application rendering in the same way as it did previously\n  Remove the client-bundle script, so that it will not overwrite our server-generated markup which we will create later in the lab.\n  // src/server/app.js // rather than serve index.html as a static file, detect when the user // visits the root of the web app and construct a page dynamically app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); });   Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and you should now see a blank screen.\n  Next, we need to find a way to generate the markup for our application on the server.\n"
},
{
	"uri": "/software-eng-essentials/postman-foundations/testing_api_endpoints/",
	"title": "Testing API Endpoints",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Using the Postman App to exchange data with a local API Create collections of multiple API requests  Skills  Perform CRUD activities with and API resource Bundle several API requests together to create a collection  Sports Teams API To get a real sense of how Postman can be a powerful tool for interacting and testing the endpoints of an API, we will use it to test the endpoints of the Sports Teams API.\nThis API has 8 endpoints used to view the data in the resource in several ways, by:\n team team index number league state by combination of league and state modifying a team adding a team deleting a team for the resource  Local environment set-up To set up our local environment, run the following commands in the terminal:\ngit clone https://github.com/one-thd/om_labs_postman.git cd om_labs_postman Local database set-up Enter the following in your terminal to install the necessary database packages for the API:\nbrew install postgres npm install -g knex brew services start postgresql createdb sports_teams npm install To migrate the database into the project, run:\nknex migrate:latest We need to fill our data base with data in order to have a proper test. Run the command below to add data:\nknex seed:run Sports Teams API endpoints Our API has 8 endpoints. Below is a description of what each one does.\nGET - Read data from the database (resource)\n All Teams: /api/teams By Team: /api/teams/:id By Sport League - SportLeagues include: MLB, NBA, NFL, NHL: /api/teams/league/:sportLeague By State - States are case agnostic.: /api/state/:stateName By State and Sport League: /api/state/:stateName/:sportLeague  PUT - modifying a record based on it\u0026rsquo;s index (id) number.\n/api/teams/:id POST\n/api/teams DELETE\n/api/teams/:id You can also view these instruction in the ReadMe.md file in project in your local environment or the ReadMe section of the Postman repository.\nSports Team API: GET Requests To run the API locally, type in your terminal:\nnpm start Since the API is running locally, if we can see all the teams in our database, we make a GET request to\nhttp://localhost:3000/api/teams In the Postman App, create a GET request by selecting GET from the request builder dropdown, add http://localhost:3000/api/teams in the input box and press SEND.\nThis will return all the teams in our database. Along the top of the response header, you will see that we are returned a status code 200 OK, which signifies that our request was received and responded to successfully.\nThis response is in JSON format:\n{ \u0026#34;id\u0026#34;: 1, \u0026#34;team_name\u0026#34;: \u0026#34;Celtics\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Boston\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;Massachusetts\u0026#34;, \u0026#34;venue\u0026#34;: \u0026#34;TD Garden\u0026#34;, \u0026#34;sport_league\u0026#34;: \u0026#34;NBA\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2018-09-21T19:24:16.960Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2018-09-21T19:24:16.960Z\u0026#34; } Each record contains information about a teams id, team name, city, state, venue, and sport league.\nThis GET endpoint looks at teams based on sport league like NBA:\nhttps://localhost:3000/api/teams/:NBA Notice all the teams returned have the sport_league attribute equal to NBA.\nSports Team API: POST Requests POST requests can be used to add a new team to the database.\nWe can add a team via:\n/api/teams We are doing a POST request to the endpoint, there are different expectations for communication than a Get.\nIn the request builder header, click the Body tab to reveal options for building a POST request and the Request Body Edit, which is where you will add the data object that will be sent to the API.\nThere are 4 areas with different controls for sending data:\n Form-data - simulates filling a form on a website and submitting it x-www-form-urlencoded - uses the same encoding as the one used in URL parameters. raw - can contain any format. Postman does not modify this strings in the editor for this format. binary - allows you to send things which you can not enter in Postman, for example, image, audio, or video files, including text files.  We will use the raw option to send our data over to the API. In addition, we can choose the format:\n  We will choose JSON as our format. In the body editor, enter the following object:\n{ \u0026#34;team_name\u0026#34;: \u0026#34;Michigan Wolverines\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Ann Arbor\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;Michigan\u0026#34;, \u0026#34;venue\u0026#34;: \u0026#34;The Big House\u0026#34;, \u0026#34;sport_league\u0026#34;: \u0026#34;NCAA\u0026#34; } This object contains the data that we want to add to the database. It is mapped to the attributes of the database that is associated to the API. Your request should look like the following:\n  Click SEND to make the request.\nIn the response body, the data the API returns data and the status code of the communication. Our data was added to the database with as index number 134 (your index number may be different).\nA quick GET request using the new ID number will confirm our data was added.\n  Sports Team API: PUT Requests The endpoint we use for PUT is:\n/api/team/:id where :id is the index number of the object you want to update.\nIn this case, we will change the team name to \u0026ldquo;The University of Michigan Wolverines\u0026rdquo;.\n PUT and PATCH methods are similar, but not the same and should not be used interchangeably.\n PUT requests are set up similarly to POST requests. Select PUT from the request dropdown and enter the following endpoint:\nhttp://localhost:3000/api/teams/134 Again, your index number may be different, so enter the one that corresponds to your data object.\nIn the request body editor, we enter the attributes of our object, including the one we want to change, team_name. Press Send.\n  The return status is 201 Created and the object now reflects our modification:\nSports Team API: DELETE Requests DELETE requests are usually made using the index number of the object that will be deleted:\n/api/teams/:id Again, looks similar to the PUT, however we are using the DELETE request and no other data about the object is needed.\nUse the request header dropdown to select DELETE, and add the endpoint with the index number to be deleted. The request body will remain empty.\nHit SEND. Although there is no message that confirms the action from the API, you can tell by the status code that the request is successful, and a quick GET using the index number will not return any data.\nCollections Building Collections allow us to group our requests together, rather than running them one at a time. One of the benefits of using collections is being able to test your endpoints all at once and getting the results of those tests bundled.\nSports Teams API Collection Instead of doing each request separately, we can roll them all up into a collection and run the requests all together, cutting testing time down considerably.\nTo create a new collection look at the top left corner of Postman workspace and click the New button to reveal a dropdown.\n  Select Collection. You can also click the Collections tab along the left side of the page to add a new collection.\n  A dialog box will appear.\nThis box allow you to customize your collection by adding a Description, Authorization, Pre-requests Scripts, Tests, Variables. We will be running simple tests. At this time, we are only going to add a description.\n  Once you\u0026rsquo;ve added a name and description for your collection, click the Create button at the bottom of the dialog box. This will create a collection in the left panel of the screen.\nA GET request can now happen. We begin as usual by selection GET from dropdown in the request builder menu. In the URI box, input http://localhost:3000/api/teams. This time, click the arrow next to the SEND button and Save As:\nIn the dialog box, add a name and description of the request.   Click Save to Sports Teams API and you\u0026rsquo;ll see the request has been added to the collection.   Filling the Collection Try the follow GET requests:\n /api/teams/10 /api/teams/league/NBA /api/state/Texas /api/state/Texas/MLS  PUT request:\n /api/teams/10 request body should include:  { \u0026#34;id\u0026#34;: 10, \u0026#34;team_name\u0026#34;: \u0026#34;Robins\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Milwaukee\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;Wisconsin\u0026#34;, \u0026#34;venue\u0026#34;: \u0026#34;Bradley Center\u0026#34;, \u0026#34;sport_league\u0026#34;: \u0026#34;NBA\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2018-09-21T19:24:16.960Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2018-09-21T19:24:16.960Z\u0026#34; } POST request:\n /api/teams/ request body should include:  { \u0026#34;team_name\u0026#34;: \u0026#34;Michigan State Spartans\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;East Lansing\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;Michigan\u0026#34;, \u0026#34;venue\u0026#34;: \u0026#34;Spartan Stadium\u0026#34;, \u0026#34;sport_league\u0026#34;: \u0026#34;NCAA\u0026#34; } DELETE request:\n /api/teams/10  Running the Collection Once you\u0026rsquo;ve added all the requests, click the arrow next to the collection name and choose the Run option. A dialog box will appear. Click the Run Sports Teams\u0026hellip; button.\n  A new Postman collection window will open and display the results of the run. If all went well, we should have success status codes returned to us.\nYou can also export the results in JSON format. Here\u0026rsquo;s an example of the exported run result.\nAdditional Resources  JSON.org Reading JSON files Medium: PUT vs. PATCH Postman Collections  "
},
{
	"uri": "/react/pillars/testing/react-testing-library/rtl-presentational-components/",
	"title": "Testing Presentational Components",
	"tags": [],
	"description": "",
	"content": "Introduction  The easiest and most common component to test is the presentational component. Recall that there are generally 2 kinds of React components:  Presentational Components - only depend on the props being passed into them Container Components - have state (memory) that is managed by React (setState, useState, or useReducer) or a 3rd party library such as redux or mobx    Testing the Product Component Our first component to test is the Product component at client/src/components/product/Product.jsx.\nLet\u0026rsquo;s create the test file:\ntouch client/src/components/product/Product.test.js Now open the file in your text editor and add the following:\nProduct.test.js:\nimport React from \u0026#39;react\u0026#39; // we always need React when testing React components import { render, screen } from \u0026#39;@testing-library/react\u0026#39; // screen defines many query functions import Product from \u0026#39;./Product\u0026#39; // our component under test import formatPrice from \u0026#39;./utils/format-price\u0026#39; // formatPrice is used to render a price in pennies to a USD amount import dataSet from \u0026#39;./mock-utils/dataSet1\u0026#39; // we will use data from this dataSet to test our component  const product = dataSet.products[0] // the product data for our component under test  /** * Define a function that creates and returns an instance of the Product component. * I usually define this function to take the same props as the component under test, * thus giving complete control over how the component is constructed. */ function getProduct(product, addItemToCart, getCartCountForProduct) { return ( \u0026lt;Product product={product} addItemToCart={addItemToCart} getCartCountForProduct={getCartCountForProduct} /\u0026gt; ) } describe(\u0026#39;Product\u0026#39;, () =\u0026gt; { it(\u0026#39;renders without crashing\u0026#39;, () =\u0026gt; { // our first test :-)  const { container } = render( // render our component under test  getProduct(product, jest.fn(), jest.fn()) ) expect(container).toBeTruthy() // if we get this far then the component was rendered  }) it(\u0026#39;renders the product title\u0026#39;, () =\u0026gt; { // our second test  render(getProduct(product, jest.fn(), jest.fn())) screen.getByText(product.name) // finds the DOM node with the specified text,  // waits up to 4.5 seconds and if not found will  // throw an exception  }) it(\u0026#39;renders the product brand\u0026#39;, () =\u0026gt; { // similar to previous test  render(getProduct(product, jest.fn(), jest.fn())) screen.getByText(product.brand) }) it(\u0026#39;renders the product price\u0026#39;, () =\u0026gt; { // similar to previous test  render(getProduct(product, jest.fn(), jest.fn())) screen.getByText(formatPrice(product.price)) }) it(\u0026#39;renders the product description\u0026#39;, () =\u0026gt; { // similar to previous test  // TODO: implement this test  }) it(\u0026#39;renders the product rating\u0026#39;, () =\u0026gt; { // similar to previous test  // TODO: implement this test  }) }) Where is the expect?  Notice that we don\u0026rsquo;t need expect in some of the tests above. That\u0026rsquo;s because when a react-testing-library query fails to find a matching DOM node, it will throw an exception thus failing the test.  Give it a try by changing one of the queries above to a value that will not be found in the DOM (for example: expect.getByText('banana')).\nWe could add the expect anyway, but it is superfluous. For example:\nexpect(screen.getByText(product.name)).toBe(product.name) // what else could it be? If you really want to be explicit with your expect, use this:\nexpect(screen.queryByText(product.name)).toBeInTheDocument(); See DTL Cheatsheet for more information.\nActivity - Complete the Test Complete the last 2 tests in the code above.\nRemember to start jest in watch mode and see how are tests are doing:\nyarn test # or npm test Testing Callbacks with Mocks We have two more tests we need to write:\n the test for the Add to cart button. the test for the badge that displays the current count in the cart.  Note that the Product component is a simple presentational component that really knows nothing about a shopping cart. It merely has:\n a button that, when clicked, makes a call to the addItemToCart callback prop a badge that displays a number that it gets from calling the getCartCountForProduct callback prop  Mocking the Callback Functions So when testing these features, we don\u0026rsquo;t need to implement a cart at all. We merely want to verify that clicking the button calls the callback function with the expected data passed as an argument.\nTo write these tests, we will use the jest.fn feature for creating mock functions. This will allow us to inspect whether the mock functions were called and what data was passed or received.\nProduct.test.js // ...  it(\u0026#39;renders the Add to cart button that when clicked makes a proper callback\u0026#39;, () =\u0026gt; { const addItemToCart = jest.fn(item =\u0026gt; item) // create a mock function for the callback  render(getProduct(product, addItemToCart, jest.fn())) // render the component under test  const button = screen.getByText(/add to cart/i).closest(\u0026#39;button\u0026#39;) // find the Add to Cart button  userEvent.click(button) // click the button  expect(addItemToCart.mock.calls.length).toBe(1) // verify that the mock callback was called  expect(addItemToCart).toHaveBeenCalledWith(product) // verify that the product data was passed  }) it(\u0026#39;renders a badge with the number of items in the cart\u0026#39;, () =\u0026gt; { const numInCart = 3 const getCartCountForProduct = jest.fn(() =\u0026gt; numInCart) // create a mock function for the callback  render(getProduct(product, jest.fn(), getCartCountForProduct)) // render the component under test  const badgeRegEx = RegExp(`${numInCart}in cart`, \u0026#39;i\u0026#39;) // define a regex for finding the badge  screen.getByText(badgeRegEx) // verify that the badge renders the proper count  }) That\u0026rsquo;s all there is to it! We have fully tested our first component, the Product presentational component.\nTesting the ProductList Component  Next we will test the ProductList component. Recall that this component simply renders a list of products organized by department. But the ProductList component doesn\u0026rsquo;t really know any of that. It simply renders the list of products given to it via its props.  Let\u0026rsquo;s create the test file:\ntouch client/src/components/product/ProductList.test.js Now open the file in your text editor and add the following:\nProductList.test.js:\nimport React from \u0026#39;react\u0026#39; import { cleanup, render, screen } from \u0026#39;@testing-library/react\u0026#39; import ProductList from \u0026#39;./ProductList\u0026#39; import dataSet from \u0026#39;./mock-utils/dataSet1\u0026#39; // A function that returns an instance of the ProductList component. function getProductList(products, addItemToCart, getCartCountForProduct) { return ( \u0026lt;ProductList products={products} addItemToCart={addItemToCart} getCartCountForProduct={getCartCountForProduct} /\u0026gt; ) } describe(\u0026#39;ProductList\u0026#39;, () =\u0026gt; { it(\u0026#39;renders without crashing\u0026#39;, () =\u0026gt; { // this should look familiar  const { container } = render( getProductList(dataSet.products, jest.fn(), jest.fn()) ) expect(container).toBeTruthy() }) it(\u0026#39;renders the product titles for each product\u0026#39;, () =\u0026gt; { render(getProductList(dataSet.products, jest.fn(), jest.fn())) dataSet.products.forEach(product =\u0026gt; { // simply iterate over the products in the dataSet  screen.getByText(product.name) // and verify that each one is rendered  }) }) })  Wow, that was easy. Often there isn\u0026rsquo;t much to testing a presentational component that merely renders a list of another presentational component. This should make sense as there isn\u0026rsquo;t much to the component under test either.  Testing the CartItem Component The CartItem component is responsible for rendering a single item in the cart and rendering 2 input controls: a Remove from cart button and a NumericInput control for updating the quantity of an item in the cart. The tests will need to verify that the item is rendered correctly and that interacting with the inputs will invoke the callbacks with the proper arguments.\nFirst let\u0026rsquo;s create the test file:\ntouch client/src/components/cart/CartItem.test.js Now open the file in your text editor and add the following:\nCartItem.test.js:\nimport React from \u0026#39;react\u0026#39; import \u0026#39;@testing-library/jest-dom\u0026#39; import { render, screen } from \u0026#39;@testing-library/react\u0026#39; import userEvent from \u0026#39;@testing-library/user-event\u0026#39; import CartItem from \u0026#39;./CartItem\u0026#39; import formatPrice from \u0026#39;./utils/format-price\u0026#39; import dataSet from \u0026#39;./mock-utils/dataSet1\u0026#39; const cartItemData = dataSet.cart[0] function getCartItem(item, updateItemInCart, removeItemFromCart) { return ( \u0026lt;CartItem item={item} updateItemInCart={updateItemInCart} removeItemFromCart={removeItemFromCart} /\u0026gt; ) } describe(\u0026#39;CartItem\u0026#39;, () =\u0026gt; { it(\u0026#39;renders item name, brand, description, and price\u0026#39;, () =\u0026gt; { render(getCartItem(cartItemData, jest.fn(), jest.fn())) screen.getByText(cartItemData.name) screen.getByText(cartItemData.brand) screen.getByText(cartItemData.description) screen.getByText(formatPrice(cartItemData.price)) }) it(\u0026#39;updates an item in cart\u0026#39;, () =\u0026gt; { const updateItemInCart = jest.fn(item =\u0026gt; item) render(getCartItem(cartItemData, updateItemInCart, jest.fn())) const incrementButton = screen.getByTestId(\u0026#39;numeric-increment\u0026#39;) userEvent.click(incrementButton) expect(updateItemInCart.mock.calls.length).toBe(1) expect(updateItemInCart).toHaveBeenCalledWith({ ...cartItemData, quantity: cartItemData.quantity + 1 }) }) it(\u0026#39;removes an item from the cart\u0026#39;, () =\u0026gt; { // TODO: implement this test  }) }) Activity - Complete the Test Complete the last test in the code above.\nTesting the Cart Component  The Cart component is similar to the ProductList Component in that it primarily renders a list of something, in this case it renders a list of CartItems. The Cart component is also responsible for rendering the cart totals (subtotal, tax, shipping, and grand total). Keep in mind that the Cart component does not do any calculations for these totals.  Instead it is provided a callback that returns an object containing all of the totals. This makes our testing easy as we can simply create a mock function for the callback that returns whatever totals we want.    Let\u0026rsquo;s create the test file:\ntouch client/src/components/cart/Cart.test.js Now open the file in your text editor and add the following:\nCart.test.js:\nimport React from \u0026#39;react\u0026#39; import \u0026#39;@testing-library/jest-dom\u0026#39; import { render, screen } from \u0026#39;@testing-library/react\u0026#39; import dataSet from \u0026#39;./mock-utils/dataSet1\u0026#39; import Cart from \u0026#39;./Cart\u0026#39; import formatPrice from \u0026#39;./utils/format-price\u0026#39; function getCart(cart, updateItemInCart, removeItemFromCart, getCartTotals) { return ( \u0026lt;Cart cart={cart} updateItemInCart={updateItemInCart} removeItemFromCart={removeItemFromCart} getCartTotals={getCartTotals} /\u0026gt; ) } const cartTotals = { // our test data for the cart totals  subTotal: 12345, tax: 234, shipping: 345, grandTotal: 12345 + 234 + 345 } describe(\u0026#39;Cart\u0026#39;, () =\u0026gt; { it(\u0026#39;renders the shopping cart title\u0026#39;, () =\u0026gt; { const getCartTotals = jest.fn(() =\u0026gt; cartTotals) render(getCart([], jest.fn(), jest.fn(), getCartTotals)) screen.getByText(\u0026#39;Shopping Cart\u0026#39;) // verify that the title is displayed  }) it(\u0026#39;renders the items in the cart\u0026#39;, () =\u0026gt; { const getCartTotals = jest.fn(() =\u0026gt; cartTotals) render(getCart(dataSet.cart, jest.fn(), jest.fn(), getCartTotals)) dataSet.cart.forEach(item =\u0026gt; { // for each cart item in the dataSet  screen.getByText(item.name) // verify that it\u0026#39;s properties were rendered  screen.getByText(item.brand) screen.getByText(formatPrice(item.price)) screen.getByText(formatPrice(item.price * item.quantity)) }) }) it(\u0026#39;renders cart totals\u0026#39;, () =\u0026gt; { // TODO: implement this test  }) }) Activity - Complete the Test Complete the last test in the code above.\n Hint: We want to make sure that the subtotal, tax, shipping, and grandTotal values are correct to their labels (for example: no confusing the shipping for the tax). The Cart component already has data-testid properties for each of the DOM nodes that render these values, so we can easily select a specific DOM node to inspect. Then we can use the handy toHaveTextContent() method from the jest-dom library to ensure that the proper value was rendered. For example:\n expect(screen.getByTestId(\u0026#39;myTestId\u0026#39;)).toHaveTextContent(myExpectedValue) Testing the Navbar  We already have the file client/src/components/navbar/Navbar.test.js but it isn\u0026rsquo;t fully complete. Consider that the Navbar component is responsible for rendering the following:  the THD logo a NavLink for each department a NavLink for the shopping cart the count of the items in the cart    But our test currently only verifies that the component is rendered without crashing. Let\u0026rsquo;s add tests for the rest of these responsibilities.\nOur updated Navbar.test.js looks like this:\nimport React from \u0026#39;react\u0026#39; import { BrowserRouter as Router } from \u0026#39;react-router-dom\u0026#39; import { render, screen } from \u0026#39;@testing-library/react\u0026#39; import dataSet from \u0026#39;./mock-utils/dataSet1\u0026#39; import Navbar from \u0026#39;./Navbar\u0026#39; function getNavbar(loading, updating, departments, cartCount) { return ( \u0026lt;Router\u0026gt; {/* we need a Router because the Navbar renders NavLinks */} \u0026lt;Navbar loading={loading} updating={updating} departments={departments} cartCount={cartCount} /\u0026gt; \u0026lt;/Router\u0026gt; ) } describe(\u0026#39;Navigation Header\u0026#39;, () =\u0026gt; { it(\u0026#39;renders without crashing\u0026#39;, async () =\u0026gt; { const { container } = render(getNavbar(false, false, dataSet.departments, 0)) expect(container).toBeTruthy() }) it(\u0026#39;renders a Home Depot logo\u0026#39;, () =\u0026gt; { render(getNavbar(false, false, dataSet.departments, 0)) screen.getByAltText(\u0026#39;The Home Depot\u0026#39;) // verify the image  }) it(\u0026#39;renders the department navigation buttons\u0026#39;, () =\u0026gt; { render(getNavbar(false, false, dataSet.departments, 0)) dataSet.departments.forEach(dept =\u0026gt; { // verify that each department  screen.getByText(dept.name) // is rendered by name  }) }) it(\u0026#39;renders a count of items in the cart\u0026#39;, () =\u0026gt; { render(getNavbar(false, false, dataSet.departments, 13)) // set the cartCount to 13  expect(screen.getByTestId(\u0026#39;cart-count\u0026#39;)).toHaveTextContent(\u0026#39;13\u0026#39;) // verify that 13 is rendered  }) })  NOTE: We do not test the routing in Navbar.test.js, but we could if we defined some test routes in the code above. Instead we opt to test the routes in the App.test.js integration test (coming soon).\n Summary Testing presentational components is fairly straight forward. We usually need to test the following:\n Did we get the rendered output we expected Do input controls (such as buttons) capture user actions and respond accordingly (usually calling a callback function with the expected data)  "
},
{
	"uri": "/software-eng-essentials/text-editors/",
	"title": "Text Editors",
	"tags": [],
	"description": "",
	"content": "Welcome to Text Editors! "
},
{
	"uri": "/javascript/pillars/resiliency-patterns/retry/",
	"title": "The Retry Pattern",
	"tags": [],
	"description": "",
	"content": "The Retry resiliency pattern.\n Topics 1. Learning Objectives 2. What is the Retry Pattern? 2.1. Where can the Retry Pattern be Used?   3. Retry Parameters 3.1. What is the Delay Factor?   4. Introducing the attempt Library 4.1. Library Features   5. Lab 6. Summary 7. Additional Resources   1. Learning Objectives   Review the characteristics of the retry pattern\n  List situations best suited for this pattern\n  Review parameters to tune this pattern\n  Show a third party library to help implement this pattern\n     2. What is the Retry Pattern? If at first you don\u0026#8217;t succeed..\n An application can be made more resilient by retrying a service that is having transient faults.\n   These retries are transparent to the user or client application\n  The number of retries is configurable\n  There is a \"backoff\" time between retries that is configurable\n   While retries can increase response time, the result is often a better user experience. Instead of receiving an error, the user might have to wait a certain amount of time that is possibly not perceivable to the user.\n    The Retry Pattern is retrying operations on remote resources over a network call a set number of times.\n    2.1. Where can the Retry Pattern be Used? The Retry Pattern can be used on the following:\n   Node scripts\n  front end (web-based) applications\n  back end services\n   The retry pattern is best suited to solve transient failures in a dependent service.\n     Transient failures can be very common since the technical landscape has moved to the cloud. Some of the reasons behind transient failures could be the following:\n   momentary losses of network connectivity\n  failure to respond from a third party API that is busy\n  temporary timeout from a database that is in a write cycle\n      3. Retry Parameters If the failures are not transient (i.e. they are persistent), then continuing to retry would not be helpful as the service will continue to fail. This could cause the application to have the appearance of hanging.\n   For this reason, the Retry pattern has configurable parameters, such as:\n   Maximum times to retry\n  Time to wait in between retries\n  Should the time between each request increase dynamically or be static?\n     The above demonstrates:\n   An initial delay of 200ms\n  delay to second request 100ms\n  a delay factor of 2, causing the delay between retries to grow exponentially by a factor of 2\n  max retries of 5 (though only 4 attempts were needed in this example)\n   3.1. What is the Delay Factor? The delay factor causes successive retry attempts to have exponentially increasing delays (pauses) between retries. This serves two purposes:\n   It gives the failing service more time to recover before the next attempt.\n  It prevents multiple clients from retrying the failed service in lockstep fashion, which could cause additional faults to occur.\n      4. Introducing the attempt Library While you could write your own retry code, there exists an easy to use, lightweight, and trusted third-part library, attempt.\n      This library can be added to your project via npm or yarn.\n The documentation can be found at: @lifeomic/attempt\n 4.1. Library Features The attempt library offers the following features:\n   Fixed delay between attempts\n  Exponential backoff\n  Exponential backoff with jitter\n  Abort retries early\n  Abort due to timeout\n  Error handler for each attempt\n       Jitter is a timing randomizer to help reduce the chances of services becoming busy because they being hit by multiple applications at the same time.     Its quite easy to implement with flexible settings.\n Example of a simple implementation. const retry = require('@lifeomic/attempt').retry; const options = { delay: 100, maxAttempts: 4, initialDelay: 0, factor: 2 } try { const result = await retry(async (context) =\u0026gt; { // some code that returns a promise or resolved value }, options); } catch (err) { // If the max number of attempts was exceeded then `err` // will be the last error that was thrown. // // If error is due to timeout then `err.code` will be the // string `ATTEMPT_TIMEOUT`. }   from the retry library documentation\n Thus to use retry, simply wrap it around a call to a service that may experience transient failures.\n    5. Lab For instructions see the Retry lab at Resiliency Cart Service.\n   6. Summary   The Retry Pattern can make an application more resilient if it uses a service that often has transient failures.\n  The Retry Pattern can provide for a better user experience.\n  There are third party libraries that can be utilized to make implementing retry pattern simple.\n     7. Additional Resources   https://docs.microsoft.com/en-us/azure/architecture/patterns/retry\n  https://pradeeploganathan.com/patterns/retry-pattern/\n  https://app.pluralsight.com/library/courses/azure-design-patterns-availability-resilience\n     "
},
{
	"uri": "/custom-workshops/frontend-at-thd/react-crash-course/useeffect/",
	"title": "The useEffect Hook",
	"tags": [],
	"description": "",
	"content": "Concepts and Skills  Understand how useEffect replaces componentDidMount, componentDidUpdate, and componentWillUnmount. Apply the useEffect hook to manage side effects in a React component.  Introduction If you’re familiar with React class lifecycle methods, you can think of useEffect Hook as componentDidMount (cDM), componentDidUpdate (cDU), and componentWillUnmount (cWU) combined. This is because useEffect gets called after the first render (cDM) and may also get called after every update (cDU). Additionally the provided function (the 1st argument) may itself return a function that will be called when the component is unmounted (cWU). So this is where you can put any cleanup code.\n Think of effects as an escape hatch from React’s purely functional world into the imperative world.\n Controlling when useEffect is executed By default, effects run after every render! The good news is that we don\u0026rsquo;t need to worry about stale data, but the bad news is that we probably don\u0026rsquo;t want all of our effects to run with every render. For example, if an effect is to make an HTTP request to the server, we probably don\u0026rsquo;t want to make that HTTP request on every render.\nThis is what the 2nd argument to the useEffect function is all about. The 2nd argument specifies a watch list of variables that trigger when the effect should run.\nHere is the structure for using useEffect:\nHere is an example:\nuseEffect(() =\u0026gt; { axios.get(apiUrl).then(res =\u0026gt; { setProducts(res.data) }).catch(error =\u0026gt; { toastr.error(error) }) }, []) // 2nd argument is an empty array (cDM)!!! In the above example the empty array for the 2nd argument to useEffect indicates that the effect should execute once after the component is mounted (similar to the componentDidMount lifecycle method).\nRules for the 2nd argument to useEffect Here are the rules for the 2nd argument:\n If the Array is empty, the effect only executes once (cDM). If the Array is not provided, the effect executes with every change to props or state (cDM + cDU). If the Array contains some variables, the effect executes whenever any of those variables are reassigned (cDM, cDU with dirty checks). For more information, see Optimizing Performance By Skipping Effects.   Pay careful attention to the 2nd argument\nBe careful to use the 2nd argument (the dependency list) correctly. Incorrect usage can result in subtle bugs or performance problems.\nNote that you may never find a reason to omit the 2nd argument (so far I haven\u0026rsquo;t).\n Comparing useEffect with React lifecycle methods Below compares the use of React lifecycle methods in a JS class to the equivalent in useEffect hooks:\ncDM Example with Lifecycle Method\nclass ProductBrowser extends React.Component { constructor(props) { super(props) this.state = { products: [] } } componentDidMount() { axios.get(this.apiUrl).then(res =\u0026gt; { this.setState({products: res.data}) }).catch(error =\u0026gt; { toastr.error(error) }) } render() { // JSX goes here  } } Example with useEffect hook\nconst ProductBrowser = props =\u0026gt; { const [products, setProducts] = useState([]) // useEffect replaces cDM  useEffect(() =\u0026gt; { axios.get(apiUrl).then(res =\u0026gt; { setProducts(res.data) }).catch(error =\u0026gt; { toastr.error(error) }) }, []) // note the empty braces for cDM  return ( // JSX goes here  ) } cDU Example with Lifecycle Method\nclass AmortizationChart extends React.Component { this.chart = null componentDidMount() { this.chart = Highcharts.chart(\u0026#39;chart\u0026#39;, getConfig(this.props.amortization) ) } componentDidUpdate() { if (this.chart) { this.chart.update(getConfig(this.props.amortization)) } } render() { return ( // JSX goes here  ) } } Example with useEffect hook\nconst AmortizationChart = props =\u0026gt; { const chartRef = useRef(null) useEffect(() =\u0026gt; { if (!chartRef.current) { chartRef.current = Highcharts.chart(\u0026#39;chart\u0026#39;, getConfig(amortization)) } else { chartRef.current.update(getConfig(amortization)) } }, [amortization, getConfig, id]) // cDM + cDU with deps  return ( // JSX goes here  ) } cWU Example with Lifecycle Method\nclass KitchenTimer extends React.Component { constructor(props) { super(props) this.state = { name: props.name, isRunning: false, timeRemaining: props.startTime * 10 } } toggle = () =\u0026gt; { if (isRunning) { clearInterval(this.timer) this.setState({ isRunning: false }) } else { this.timer = setInterval(() =\u0026gt; this.tick, 100) this.setState({ isRunning: true }) } } componentWillUnmount() { if (this.timer) { clearInterval(this.timer) } } render() { // JSX goes here  } } Example with useEffect hook\nconst KitchenTimer = props =\u0026gt; { const [name, setName] = useState(props.name) const [isRunning, setIsRunning] = useState(false) const [timeRemaining, setTimeRemaining] = useState(props.startTime * 10) const toggle = () =\u0026gt; { if (isRunning) { clearInterval(timer) setIsRunning(false) } else { timer = setInterval(() =\u0026gt; tick, 100) setIsRunning(true) } } useEffect(() =\u0026gt; { // return a function that will run before unmounting  return () =\u0026gt; clearInterval(intervalRef.current) }, []) // cDM (run once) to register the cleanup code  return ( // JSX goes here  ) } Lab: useState and useEffect Hooks The instructions for this lab are at useEffect Lab - Product Browser.\nConclusion  The useEffect hook is used for managing side-effects in React components. It can be used to replace three lifecycle methods: componentDidMount, componentDidUpdate, and componentWillUnmount. The useEffect hook takes as its 2nd argument a watch list of variables that when modified trigger the effect to execute.  "
},
{
	"uri": "/react/pillars/hooks/useeffect/",
	"title": "The useEffect Hook",
	"tags": [],
	"description": "",
	"content": "Concepts and Skills  Understand how useEffect replaces componentDidMount, componentDidUpdate, and componentWillUnmount. Apply the useEffect hook to manage side effects in a React component.  Introduction If you’re familiar with React class lifecycle methods, you can think of useEffect Hook as componentDidMount (cDM), componentDidUpdate (cDU), and componentWillUnmount (cWU) combined. This is because useEffect gets called after the first render (cDM) and may also get called after every update (cDU). Additionally the provided function (the 1st argument) may itself return a function that will be called when the component is unmounted (cWU). So this is where you can put any cleanup code.\n Think of effects as an escape hatch from React’s purely functional world into the imperative world.\n Controlling when useEffect is executed By default, effects run after every render! The good news is that we don\u0026rsquo;t need to worry about stale data, but the bad news is that we probably don\u0026rsquo;t want all of our effects to run with every render. For example, if an effect is to make an HTTP request to the server, we probably don\u0026rsquo;t want to make that HTTP request on every render.\nThis is what the 2nd argument to the useEffect function is all about. The 2nd argument specifies a watch list of variables that trigger when the effect should run.\nHere is the structure for using useEffect:\nHere is an example:\nuseEffect(() =\u0026gt; { axios.get(apiUrl).then(res =\u0026gt; { setProducts(res.data) }).catch(error =\u0026gt; { toastr.error(error) }) }, []) // 2nd argument is an empty array (cDM)!!! In the above example the empty array for the 2nd argument to useEffect indicates that the effect should execute once after the component is mounted (similar to the componentDidMount lifecycle method).\nRules for the 2nd argument to useEffect Here are the rules for the 2nd argument:\n If the Array is empty, the effect only executes once (cDM). If the Array is not provided, the effect executes with every change to props or state (cDM + cDU). If the Array contains some variables, the effect executes whenever any of those variables are reassigned (cDM, cDU with dirty checks). For more information, see Optimizing Performance By Skipping Effects.   Pay careful attention to the 2nd argument\nBe careful to use the 2nd argument (the dependency list) correctly. Incorrect usage can result in subtle bugs or performance problems.\nNote that you may never find a reason to omit the 2nd argument (so far I haven\u0026rsquo;t).\n Comparing useEffect with React lifecycle methods The question is not \u0026ldquo;when does this effect run\u0026rdquo; the question is \u0026ldquo;with which state does this effect synchronize with\u0026rdquo;:\nuseEffect(fn) // all state useEffect(fn, []) // no state useEffect(fn, [these, states]) // specific states  Quote from this article\n Below compares the use of React lifecycle methods in a JS class to the equivalent in useEffect hooks:\ncDM Example with Lifecycle Method\nclass ProductBrowser extends React.Component { constructor(props) { super(props) this.state = { products: [] } } componentDidMount() { axios.get(this.apiUrl).then(res =\u0026gt; { this.setState({products: res.data}) }).catch(error =\u0026gt; { toastr.error(error) }) } render() { // JSX goes here  } } Example with useEffect hook\nconst ProductBrowser = props =\u0026gt; { const [products, setProducts] = useState([]) // useEffect replaces cDM  useEffect(() =\u0026gt; { axios.get(apiUrl).then(res =\u0026gt; { setProducts(res.data) }).catch(error =\u0026gt; { toastr.error(error) }) }, []) // note the empty braces for cDM  return ( // JSX goes here  ) } cDU Example with Lifecycle Method\nclass AmortizationChart extends React.Component { this.chart = null componentDidMount() { this.chart = Highcharts.chart(\u0026#39;chart\u0026#39;, getConfig(this.props.amortization) ) } componentDidUpdate() { if (this.chart) { this.chart.update(getConfig(this.props.amortization)) } } render() { return ( // JSX goes here  ) } } Example with useEffect hook\nconst AmortizationChart = props =\u0026gt; { const chartRef = useRef(null) useEffect(() =\u0026gt; { if (!chartRef.current) { chartRef.current = Highcharts.chart(\u0026#39;chart\u0026#39;, getConfig(amortization)) } else { chartRef.current.update(getConfig(amortization)) } }, [amortization, getConfig, id]) // cDM + cDU with deps  return ( // JSX goes here  ) } cWU Example with Lifecycle Method\nclass KitchenTimer extends React.Component { constructor(props) { super(props) this.state = { name: props.name, isRunning: false, timeRemaining: props.startTime * 10 } } toggle = () =\u0026gt; { if (isRunning) { clearInterval(this.timer) this.setState({ isRunning: false }) } else { this.timer = setInterval(() =\u0026gt; this.tick, 100) this.setState({ isRunning: true }) } } componentWillUnmount() { if (this.timer) { clearInterval(this.timer) } } render() { // JSX goes here  } } Example with useEffect hook\nconst KitchenTimer = props =\u0026gt; { const [name, setName] = useState(props.name) const [isRunning, setIsRunning] = useState(false) const [timeRemaining, setTimeRemaining] = useState(props.startTime * 10) const toggle = () =\u0026gt; { if (isRunning) { clearInterval(timer) setIsRunning(false) } else { timer = setInterval(() =\u0026gt; tick, 100) setIsRunning(true) } } useEffect(() =\u0026gt; { // return a function that will run before unmounting  return () =\u0026gt; clearInterval(intervalRef.current) }, []) // cDM (run once) to register the cleanup code  return ( // JSX goes here  ) } Lab: useState and useEffect Hooks The instructions for this lab are at useEffect Lab - Product Browser.\nConclusion  The useEffect hook is used for managing side-effects in React components. It can be used to replace three lifecycle methods: componentDidMount, componentDidUpdate, and componentWillUnmount. The useEffect hook takes as its 2nd argument a watch list of variables that when modified trigger the effect to execute.  "
},
{
	"uri": "/golang/testing/types/",
	"title": "Types of Testing",
	"tags": [],
	"description": "",
	"content": "Goals Gain an understanding of the different types of testing.\nLearning Objectives  Ways to execute tests Explore scopes of testing Investigate classifications of testing  Executing Tests  Manual - A user runs tests via the UI, in the same fashion as a true customer would. Automated - Test scripts are executed that call into the code and compare results to expected outputs.  Scopes of Testing The scope of the test tells us the limits of what is being tested.\n Unit - Focuses on an individual functionality, usually at a function or method level. Component - Testing a single class, package, component, or library. Integration - Combined components that collaborate to perform a task, or set of tasks. End-to-end (E2E) - A test that will check all functionality from begining to end on an application.  Testing Aspects Functional There are two functional aspects to testing:\nPositive\nDoes the application as expected?\nNegative\nDoes the application handle errors, or provide errors when expected.\nNon-Functional Smoke\nDid the build work?\nPerformance/Load/Benchmarking\nHow does the software handle under a heavy load? Can it handle lots of users/traffic? Can it handle large data sets?\nUsability\nHow intuitive is the software?Could someone understand how to use it without instructions?\nAccessibility\nCan users with disabilities use our software?Such as, but not limited to color-blind, or blind using screen readers.\nSecurity\nPoking holes in areas that tend to be vulnerable.\nCompatibility\nHow well does the software work in different browsers, OS, network environments?\nRecovery\nDoes the software recover gracefully from software and hardware failures?\nUser Acceptance Testing\nCan users with disabilities use our software? Such as, the visually impaired.\nConclusion There are many forms and degrees of testing with their own purposes. A plan for testing should be curated and agreed to in the product team as each piece of software will have different testing needs. You\u0026rsquo;ll need to ask, what are the vulnerabilities and requirements of this software.\n"
},
{
	"uri": "/python/testing/types/",
	"title": "Types of Testing",
	"tags": [],
	"description": "",
	"content": "Goals Gain an understanding of the different types of testing.\nLearning Objectives  Ways to execute tests Explore scopes of testing Investigate classifications of testing  Executing Tests  Manual - A user runs tests via the UI, in the same fashion as a true customer would. Automated - Test scripts are executed that call into the code and compare results to expected outputs.  Scopes of Testing The scope of the test tells us the limits of what is being tested.\n Unit - Focuses on an individual functionality, usually at a function or method level. Component - Testing a single class, package, component, or library. Integration - Combined components that collaborate to perform a task, or set of tasks. End-to-end (E2E) - A test that will check all functionality from begining to end on an application.  Testing Aspects Functional There are two functional aspects to testing:\nPositive\nDoes the application as expected?\nNegative\nDoes the application handle errors, or provide errors when expected.\nNon-Functional Smoke\nDid the build work?\nPerformance/Load/Benchmarking\nHow does the software handle under a heavy load? Can it handle lots of users/traffic? Can it handle large data sets?\nUsability\nHow intuitive is the software?Could someone understand how to use it without instructions?\nAccessibility\nCan users with disabilities use our software?Such as, but not limited to color-blind, or blind using screen readers.\nSecurity\nPoking holes in areas that tend to be vulnerable.\nCompatibility\nHow well does the software work in different browsers, OS, network environments?\nRecovery\nDoes the software recover gracefully from software and hardware failures?\nUser Acceptance Testing\nCan users with disabilities use our software? Such as, the visually impaired.\nConclusion There are many forms and degrees of testing with their own purposes. A plan for testing should be curated and agreed to in the product team as each piece of software will have different testing needs. You\u0026rsquo;ll need to ask, what are the vulnerabilities and requirements of this software.\n"
},
{
	"uri": "/software-eng-essentials/testing/types/",
	"title": "Types of Testing",
	"tags": [],
	"description": "",
	"content": "Goals Gain an understanding of the different types of testing.\nLearning Objectives  Ways to execute tests Explore scopes of testing Investigate classifications of testing  Executing Tests  Manual - A user runs tests via the UI, in the same fashion as a true customer would. Automated - Test scripts are executed that call into the code and compare results to expected outputs.  Scopes of Testing The scope of the test tells us the limits of what is being tested.\n Unit - Focuses on an individual functionality, usually at a function or method level. Component - Testing a single class, package, component, or library. Integration - Combined components that collaborate to perform a task, or set of tasks. End-to-end (E2E) - A test that will check all functionality from begining to end on an application.  Testing Aspects Functional There are two functional aspects to testing:\nPositive\nDoes the application as expected?\nNegative\nDoes the application handle errors, or provide errors when expected.\nNon-Functional Smoke\nDid the build work?\nPerformance/Load/Benchmarking\nHow does the software handle under a heavy load? Can it handle lots of users/traffic? Can it handle large data sets?\nUsability\nHow intuitive is the software?Could someone understand how to use it without instructions?\nAccessibility\nCan users with disabilities use our software?Such as, but not limited to color-blind, or blind using screen readers.\nSecurity\nPoking holes in areas that tend to be vulnerable.\nCompatibility\nHow well does the software work in different browsers, OS, network environments?\nRecovery\nDoes the software recover gracefully from software and hardware failures?\nUser Acceptance Testing\nCan users with disabilities use our software? Such as, the visually impaired.\nConclusion There are many forms and degrees of testing with their own purposes. A plan for testing should be curated and agreed to in the product team as each piece of software will have different testing needs. You\u0026rsquo;ll need to ask, what are the vulnerabilities and requirements of this software.\n"
},
{
	"uri": "/software-eng-essentials/text-editors/vs-code/",
	"title": "VS Code",
	"tags": [],
	"description": "",
	"content": "The main purpose of this lesson is to get comfortable with the VS Code editor, including how to configure it, install plugins, and discover more efficient ways of editing files.\nVS Code  Developed by Microsoft Free and open source Multi-platform (OS X, Windows, Linux) Popular (widely used for web development) Extensible (we can add functionality via VS Code packages)  Installing VS Code Downloading  Visit this link and the download will start immediately Double click on the VSCodeXXX.zip file and follow the instructions Move it into the Applications directory  Opening VS Code    Way of Opening Steps     Dock or Launchpad Click the VS Code icon in the Dock or Launchpad.   Spotlight Search Press CMD+ SPACE BARto open Spotlight.Type VS (the rest of the app name should appear)Click Return button and the app will open.   From the terminal In the terminal, navigate to the root of the current projectTo open VS Code, type code .If this doesn\u0026rsquo;t work, press CMD+ SHIFT+ Pin VS Code and type: Install 'code' command in PATH. Then, try typing code . in the terminal    Anatomy of VS Code Let\u0026rsquo;s go over the basics!\nSource: VS Code \u0026lsquo;Get Stared\u0026rsquo; documentation\nBells and Whistles How to change or add themes and plugins/extensions\nThemes: To change the background and text coloration\n In VS Code, open the Color Theme picker with Code \u0026gt; Preferences \u0026gt; Color Theme. Use the cursor keys to preview the colors of the theme. Select the theme you want and press Enter. (OR Install Additional Color Themes\u0026hellip;.) Preview the options and click the install button Quit VS Code and reopen Repeat step one or click CMD+ K+ CMD+ Tand the newly installed theme should be listed  Beautify Plugin: Formats code according to best practices\n Click the Extensions icon in the Activity Bar (far left side of the text editor) Search the Marketplace for a plugin called \u0026lsquo;Prettier\u0026rsquo; Click the install button Chose the keybinding that does not conflict with other shortcuts or bindings. (Suggestion: OPT+ Bshould not conflict with other bindings )  User and Workspace Settings How to modify user settings\nWith VS Code you can alter the default settings and customize its behavior.\nTo modify the user settings visit the menu bar and select: Code \u0026gt; Preferences \u0026gt; Settings. The user settings window will open.\nThe following table shows settings that add useful functionality to VS Code.\n   Settings Why it\u0026rsquo;s Useful     \u0026quot;files.autoSave\u0026quot;: \u0026quot;onFocusChange\u0026quot; Auto saves when cursor moves to a different window   \u0026quot;editor.tabSize\u0026quot;: 2 Sets tab size to 2 spaces (standard)   \u0026quot;workbench.editor.enablePreview\u0026quot;: false Allows newly opened files to have their own editor pane and not replace an existing one    Don\u0026rsquo;t Touch That Mouse! The following shortcuts will allow you to avoid using the mouse or trackpad as much as possible, increasing productivity. It seems cumbersome at first, but if you integrate these short cuts into your development practice, you will be more productive (and you\u0026rsquo;ll look super cool!).\nBasic Editing    Key Description     CMD+ X Cut a line (may be pasted)   CMD+ Pfilename return Open a file named filename   OPT+ SHIFT+ ↑/ ↓ Clone line above/below current   OPT+ ↑/ ↓ Move selected code (or current line) up/down (single or multiple lines)    Selection    Key Description     CMD+ D Select elements on a page one at a time   CMD+ l Select entire line   CMD+ l+ l Select multiple lines below origin    Search \u0026amp; Replace    Key Description     OPT+ CMD+ F Find and replace multiple elements on page    Navigation    Key Description     CMD+ ← / → Move to beginning/end of a line   OPT+ ← / → Move forward/back a word   CONTROL+ Genter line number Navigate to a specific line number    Editor Management    Key Description     CMD+ B Show / Hide sidebar   CMD+ J Show / Hide terminal   CMD+ \u0026lt;/kbd\u0026gt; Split screen into multiple editor groups (left/right)   CMD+ W Close single editor group   CMD+ K→ CMD+ ← / → Move between open editor groups   CMD+ K→ CMD+ T, select theme Change the theme (background and text colors)    Custom Keyboard Shortcuts How to modify keyboard shortcuts\nThe following will add new keybindings to allow for navigating through the editors by simply using the CMD+ (editor number)\nNavigate to: Code \u0026gt; Preferences \u0026gt; Keyboard Shortcuts\nAdd the key and command pairs to the keybindings.json file. Upon saving, you will be able to easily navigate through the editors in the same editor group.\n{\u0026#34;key\u0026#34;:\u0026#34;cmd+1\u0026#34;, \u0026#34;command\u0026#34;:\u0026#34;workbench.action.openEditorAtIndex1\u0026#34;}, {\u0026#34;key\u0026#34;:\u0026#34;cmd+2\u0026#34;, \u0026#34;command\u0026#34;:\u0026#34;workbench.action.openEditorAtIndex2\u0026#34;}, {\u0026#34;key\u0026#34;:\u0026#34;cmd+3\u0026#34;, \u0026#34;command\u0026#34;:\u0026#34;workbench.action.openEditorAtIndex3\u0026#34;} Project mode Real-world software projects often involve many files organized into folders. It is handy to be able to see all the files in our project when working in our text editor. VS Code makes this easy as it supports a project mode. To use this we simply pass a directory instead of a file:\ncode recipes or\u0026hellip;\ncd recipes code . Lab: Test Drive Your Text Editor Listed below are exercises for you to work through to help you learn how to use your text editor to become an efficient software engineer.\n Eggs and Ham Fruit Math Superheroes  References  VS Code docs Tips and Tricks VS Code Cheat sheet  "
},
{
	"uri": "/web-essentials/webmastery-foundations/",
	"title": "Webmastery Foundations",
	"tags": [],
	"description": "",
	"content": "Welcome to the Basics of the HTML \u0026amp; CSS "
},
{
	"uri": "/application-security/api-security/01_service_to_service_oauth2/20_whatisoauth2/",
	"title": "What is OAuth2?",
	"tags": [],
	"description": "",
	"content": "Why OAuth2  Now the de facto industry standard. It has been adopted by some of the largest names in tech: Google, Facebook, Github, Microsoft, etc RFC based solution Can handle Human to Service and Service to Service.  OAuth 2 Terms When you start looking at diagrams and documentation from various sources about OAuth2, you will quickly be bombarded with terms that are assumed you know. The following section will take some time to define the most common of these terms.\nWe are going to define a few terms that apply to both Human to Service and Service to Service but then spend rest of the day on Service to Service\nRoles in OAuth2  Resource Owner (Human, Optional :D ) Client (Browser, iPhone, FirstPhone, Server etc) Resource Server (Service on PCF or GCP) Authorization Server (PingFed, AzureAD, etc)  Resource Owner  A human Can prove who they are via credentials or other means  Client  A piece of technology that is asking for access to a resource Browsers can be clients Backend Servers can be clients to other servers CLIs can be clients Public and Private Clients (can you keep a secret?)  Can you keep a secret? Private Clients  Service to Service Can hold a secret long term  Public Clients  Unable to hold a secret Browsers Native Mobile (Android, iOS, etc) CLI  Resource Server  The resource server is what provides access to the protected \u0026ldquo;stuff\u0026rdquo; Examples would be: Pricing, Inventory, etc any service that has information you want.  Authorization Server (AS) / Identity Provider (IdP)  The Authorization Server\u0026rsquo;s job is to handle OAuth2 requests. It is always paired with an Identity Provided (IdP) whose job is to handle user authentication The IdP is usually invisible to the user. The Authorization Server is the trust broker between the two services.  Grant Types The two main grants are:\n Client Credentials Grant (Servers) Authorization Code Grant (Humans)  Grants are sometimes referred to as flows\nClient Credentials Grant  Used for to allow a server acting as a client to a resource server for permissions No human interaction Most simple of the two flows  Authorization Code Grant  Used for user client (typically a browser) to server Authorization Think about when/if you choose \u0026ldquo;Log in with Google\u0026rdquo; as an option for a website Used with OIDC  Further Reading What is OAuth and why does it matter? - OAuth in Five Minutes\nOfficial OAuth2 Site\n"
},
{
	"uri": "/golang/testing/creating-tests/",
	"title": "Creating and Writing Tests",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Intro to testing Test File Set Up Test Function Skipping Tests Sub Tests  Testing Intro Testing is an extremely important part of software engineering, ensuring quality and improve reliability.\n Testing Scenario\nYou were asked to create a function Add that should take in two numbers and returns the sum. So you created the following:\npackage calculate func Add(a int, b int) int { return a - b } Running Add(3, 2) would give you 1, not the expected 5! While this code would run without any errors, this does not work as intended. A test would help catch this logical error.\n Go makes testing very easy with its built in testing framework.\nTest File Set Up Go test files should have names ending in _test.go (e.g. calculate_test.go ), usually placing the name of the component you are testing in front of _test.go. Files ending in _test.go will only be built when go test command is called. They’re excluded from regular package builds triggered by the go run command.\ncalculate/ ├── calculate.go \u0026lt;- File to be tested └── calculate_test.go \u0026lt;- Test file 0 directories, 2 files The file can be added to any package, most commonly it is in the same package as the component to be tested (same folder, same package). A benefit of this is that it allows access to unexported functions and types, enabling white-box testing.\nTest Function Test function names should start with Test, followed by a capital letter. Any functions that do not start with Test, will not be treated as test cases. They will not be run when go test command is issued, even if inside of a test file.\nEvery test function should have a single parameter of type testing.T from the testing package. T is passed to Test functions to manage test state and support formatted test logs. Logs are accumulated during execution and dumped to standard output when done.\nSome testing.T methods to signal failure are:\n Log: similar to Println, and records the text in the error log. Logf: similar to Printf, and records the text in the error log. A final newline is added if not provided. Fail: marks the function as having failed but continues execution. Error: equivalent to Log followed by Fail. Errorf: equivalent to Logf followed by Fail.  The log of tests will only be printed only if the test fails or the -v flag is set when the go test command is used.\n Testing Scenario Continued\nAfter having an extensive review, you found your mistake and decided that you will use tests to ensure the quality of your code and avoid future embarrassment. So you create calculate_test.go:\npackage calculate import \u0026#34;testing\u0026#34; func TestAdd(t *testing.T) { result := Add(3, 2) //1 \tif result != 5 { //2 \tt.Errorf(\u0026#34;Expected 5, got %v\u0026#34;, result) //2 \t} } 1. The result of Add(3, 2) was stored it in the variable result. 2. If result does not match the output expected, t.Errorf is called to give a helpful response.\nNow when go test command is used with your original code, you get the following output:\n=== RUN TestAdd --- FAIL: TestAdd (0.00s) calculate_test.go:8: Expected 5, got 1 FAIL When go test -v is run, you receive the output of the error log, giving more details about the test failure:\n=== RUN TestAdd --- FAIL: TestAdd (0.00s) calculate_test.go:8: Expected 5, got 1 FAIL exit status 1 FAIL github.homedepot.com/example/calculate 0.007s You altered the Add function to return a + b (Correcting your error) and reran go test -v. Giving the following output:\n=== RUN TestAdd --- PASS: TestAdd (0.00s) PASS ok github.homedepot.com/example/calculate 0.006s  Testing Different Packages However, tests can also be placed in a separate test package appended with _test, enabling black-box testing. This ensures you are only using the exported components. For example, to test a sum of squares function in a calculate package, then declare the new test file in a new package named calculate_test (same folder, different package). When go test is run, the test files in calculate_test package will be compiled separately from the calculate package. After compilation, they are linked to the main test binary.\ncalculator_test.go can be altered to test a file from a different package:\npackage calculate_test //1  import ( \u0026#34;testing\u0026#34; \u0026#34;github.homedepot.com/example/calculate\u0026#34; //2 \t) func TestAdd(t *testing.T) { result := calculate.Add(3, 2) //3 \tif result != 5 { t.Errorf(\u0026#34;Expected 5, got %v\u0026#34;, result) } } 1. Changing the package the test belongs to2. Now the test must import the package it wants to import3. Now the module must be placed in front of the function\nLarger example found here: Blackbox testing example\n Skipping Tests There might be cases where it is helpful to skip a specific test, allowing for quicker and selective testing. This could be done by commenting out functions, but it can also be done by calling t.SkipNow() at the top of the test function.\nTo specify the message given when skipping a test, use the Skip(args ...interface{}) method. The Skip method calls both the Log and SkipNow methods.\nfunc TestAdd(t *testing.T) { t.SkipNow() result := Add(3, 2) if result != 5 { t.Errorf(\u0026#34;Expected 5, got %v\u0026#34;, result) } } Result of go test -v:\n=== RUN TestAdd --- SKIP: TestAdd (0.00s) PASS ok github.homedepot.com/example/calculate 0.006s Having a test be skipped all of the time would create a very pointless test. The testing.Short() method returns true if a test is run or not with the -short flag.\nThe following test will not run if go test -v -short command is used:\nfunc TestAdd(t *testing.T) { if testing.Short() { t.SkipNow() } result := Add(3, 2) if result != 5 { t.Errorf(\u0026#34;Expected 5, got %v\u0026#34;, result) } } If you were to run go test -v (Notice NO -short flag):\n=== RUN TestAdd --- PASS: TestAdd (0.00s) PASS ok github.homedepot.com/example/calculate 0.007s If you were to run go test -v -short:\n=== RUN TestAdd --- SKIP: TestAdd (0.00s) PASS ok github.homedepot.com/example/calculate 0.006s Sub Tests When testing, many scenarios are examined, not just one set of inputs.\nA popular pattern in Golang is table-driven testing, where a single test is run with an array of different input parameters:\nfunc TestAdd(t *testing.T) { addTests := []struct { a int b int expected int }{ { a: 0, b: 0, expected: 0}, { a: 0, b: -5, expected: -5}, { a: 150, b: 55, expected: 205}, { a: 10, b: 37, expected: 47}, } for _, test := range addTests { result := Add(test.a, test.b) if result != test.expected { t.Errorf(\u0026#34;%v + %v != %v\u0026#34;, test.a, test.b, result) } } } === RUN TestAdd --- PASS: TestAdd (0.00s) PASS ok github.homedepot.com/example/calculate 0.006s Although many scenarios are being tested, notice that there is only one output for all of them. If one of the test cases fails, the whole test function fails, and it can be difficult to tell which one failed without a useful error message.\nThe testing package t.Run method allows tests to be split out into explicit sub-tests. Run takes two parameters: a name for a subtest and a Test Function to run in a separate goroutine. This blocks until this function returns.\nSo if the above code is rewritten to:\nfunc TestAdd(t *testing.T) { addTests := []struct { a int b int expected int }{ { a: 0, b: 0, expected: 0}, { a: 0, b: -5, expected: -5}, { a: 150, b: 55, expected: 205}, { a: 10, b: 37, expected: 47}, } for _, test := range addTests { name := fmt.Sprintf(\u0026#34;%v+%v\u0026#34;, test.a, test.b) t.Run(name, func(t *testing.T){ result := Add(test.a, test.b) if result != test.expected { t.Errorf(\u0026#34;%v + %v != %v\u0026#34;, test.a, test.b, result) } }) } } The new result of run test -v:\n=== RUN TestAdd === RUN TestAdd/0+0 === RUN TestAdd/0+-5 === RUN TestAdd/150+55 === RUN TestAdd/10+37 --- PASS: TestAdd (0.00s) --- PASS: TestAdd/0+0 (0.00s) --- PASS: TestAdd/0+-5 (0.00s) --- PASS: TestAdd/150+55 (0.00s) --- PASS: TestAdd/10+37 (0.00s) PASS ok github.homedepot.com/example/calculate 0.007s Now there is a separate success message for each sub-test!\nLab Setup\n If you have not already, Fork https://github.homedepot.com/om-labs/go-testing to your homedepot profile Clone down your newly forked repo cd into the go-testing/creating-tests directory Follow the instructions found in the README  Additional Resources  Proper Package naming Structuring tests in go Go Testing Package Doc  "
},
{
	"uri": "/react/pillars/advanced-react/react-router-advanced-solutions/",
	"title": "React Router Advanced Solutions",
	"tags": [],
	"description": "",
	"content": "Advanced patterns with React Router v4 and the Marta API.\n Topics 1. Lab 01 - Application Setup 1.1. Answer   2. Lab 02 - Initial Route and Navigation 2.1. Answers   3. Lab 04 - Bus Lines 3.1. Answer   4. Lab 05 - Display Bus Line Info 4.1. Answers   5. Lab 06 - Adherence 5.1. Answer     1. Lab 01 - Application Setup   check out branch 01-start\n  install and configure\n  eslint\n  prettier\n     run yarn\n  Setup components to match diagram found below\n  For now, create stateless/presentational components that will return a \u0026lt;div\u0026gt; with the component\u0026#8217;s name.\nie: \u0026lt;div\u0026gt; NavBar \u0026lt;/div\u0026gt;.\n  Update App.js and index.js to import files from the correct places\n      src ├── components │ ├── App.js │ ├── busses │ │ ├── AllBusses.js │ │ ├── Bus.js │ │ ├── BusContainer.js │ │ ├── Lines.js │ │ └── OneBus.js │ └── utils │ └── NavBar.js ├── index.js ├── registerServiceWorker.js └── styles ├── App.css └── index.css   1.1. Answer eslint-prettier-setup $ yarn add eslint -D $ yarn eslint --init $ yarn add eslint prettier eslint-plugin-react eslint-plugin-prettier eslint-config-prettier $ touch .prettierrc   eslintrc.json { \"extends\": [\"airbnb\", \"prettier/react\"], \"plugins\": [\"prettier\"], \"env\": { \"browser\": true, \"es6\": true }, \"parser\": \"babel-eslint\", \"parserOptions\": { \"ecmaVersion\": 2017, \"ecmaFeatures\": { \"experimentalObjectRestSpread\": true, \"jsx\": true }, \"sourceType\": \"module\" }, \"rules\": { \"react/jsx-filename-extension\": [1, { \"extensions\": [\".js\"] }], \"prettier/prettier\": \"error\", \"comma-dangle\": [\"error\", \"never\"], \"jsx-a11y/anchor-is-valid\": [\"error\", \"never\"] } }   prettierrc { \"useTabs\": false, \"printWidth\": 80, \"tabWidth\": 2, \"singleQuote\": true, \"trailingComma\": \"none\", \"jsxBracketSameLine\": false, \"parser\": \"babylon\", \"semi\": true, \"rcVerbose\": true }   component-setup $ mkdir src/components $ mkdir src/styles $ mv ./src/App.js ./src/components $ mv ./src/*.css ./src/styles $ mkdir src/components/busses $ touch src/components/busses/AllBusses.js $ touch src/components/busses/Bus.js $ touch src/components/busses/BusContainer.js $ touch src/components/busses/OneBus.js $ touch src/components/busses/Lines.js $ mkdir src/components/utils $ touch src/components/utils/NavBar.js   src/components/App.js import React from 'react'; import './styles/App.css'; const App = () =\u0026gt; ( \u0026lt;div className=\"App\"\u0026gt; \u0026lt;h3\u0026gt; Hello World \u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; ); export default App;   src/components/busses/AllBusses.js import React from 'react'; const AllBusses = () =\u0026gt; \u0026lt;div\u0026gt;All Busses\u0026lt;/div\u0026gt;; export default AllBusses;   src/components/busses/AllBusses.js import React from 'react'; const AllBusses = () =\u0026gt; \u0026lt;div\u0026gt;All Busses\u0026lt;/div\u0026gt;; export default AllBusses;   src/components/busses/Bus.js import React from 'react'; const Bus = () =\u0026gt; \u0026lt;div\u0026gt;Bus Component\u0026lt;/div\u0026gt;; export default Bus;   src/components/busses/BusContainer.js import React from 'react'; const BusContainer = () =\u0026gt; \u0026lt;div\u0026gt;Bus Container\u0026lt;/div\u0026gt;; export default BusContainer;   src/components/busses/Lines.js import React from 'react'; const Lines = () =\u0026gt; \u0026lt;div\u0026gt;Lines\u0026lt;/div\u0026gt;; export default Lines;   src/components/busses/OneBus.js import React from 'react'; const OneBus = () =\u0026gt; \u0026lt;div\u0026gt;OneBus Component\u0026lt;/div\u0026gt;; export default OneBus;   src/components/utils/NavBar.js import React from 'react'; const NavBar = () =\u0026gt; \u0026lt;div\u0026gt;NavBar\u0026lt;/div\u0026gt;; export default NavBar;   src/index.js import React from 'react'; import ReactDOM from 'react-dom'; import 'semantic-ui-css/semantic.min.css'; import './styles/index.css'; import App from './components/App'; import registerServiceWorker from './registerServiceWorker'; ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById('root')); registerServiceWorker();      2. Lab 02 - Initial Route and Navigation   Checkout branch 02-initial-routes\n  Create a new component in utils named NoMatch\n  The component should tell the user the page/resource/however-you-want-to-word-it is unavailable\n  You should also provide a Link back to the hompage ie: \"The page you\u0026#8217;ve requested is unavailable, click here to go home\"\n     Set your router up to render the NoMatch component when the users types in an unknown route\n  Provide a \u0026lt;Route\u0026gt; for /busses that handles navigation to the BusContainer component\n  Create a \u0026lt;Route\u0026gt; for /rails that renders a simple \u0026lt;h1\u0026gt; that says Coming Soon!\n  Setup your NavBar to provide routes to:\n  Home\n  Available Busses\n  Lines - the route will be /busses/lines, however it currently won\u0026#8217;t work. We\u0026#8217;ll set it up shortly\n  Rails\n     Check to insure that Home, Available Busses, and Rails load the proper components\n   note: We will style the NavBar later, but feel free to add some spacing between your link components with something like \u0026lt;span\u0026gt; | \u0026lt;/span\u0026gt; to space out the nav links.\n 2.1. Answers $ touch ./src/components/utils/NoMatch.js   src/components/utils/NoMatch.js import React from 'react'; import { Link } from 'react-router-dom'; const NoMatch = () =\u0026gt; ( \u0026lt;div\u0026gt; \u0026lt;h3\u0026gt; {' '} The page you{\"'\"}re looking for does not exist. Click{' '} \u0026lt;Link to=\"/\"\u0026gt; here \u0026lt;/Link\u0026gt; to go home \u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; ); export default NoMatch;      3. Lab 04 - Bus Lines We have all of the Bus Line data in the response. Take a look at the example response\n example-response { \"ADHERENCE\": \"-13\", \"BLOCKID\": \"448\", \"BLOCK_ABBR\": \"71-5\", \"DIRECTION\": \"Eastbound\", \"LATITUDE\": \"33.7385109\", \"LONGITUDE\": \"-84.4243359\", \"MSGTIME\": \"1/7/2018 4:48:00 PM\", \"ROUTE\": \"71\", \"STOPID\": \"900247\", \"TIMEPOINT\": \"Cascade Ave \u0026amp; Beecher St\", \"TRIPID\": \"5818933\", \"VEHICLE\": \"1456\" }   The item that we want to work with is \"ROUTE\", we are going to change the name (in our app) to Line as to avoid confusion.\n   checkout branch 04-bus-container-setup\n  inside the last then function\n  iterate over the busses and produce a new array of bus lines/routes\nnote: the lines array only needs to consist of string values\n  merge the new data into the lines array in your component state\n      3.1. Answer src/components/busses/BusContainer.js componentDidMount = () =\u0026gt; { /*eslint-disable */ const targetUrl = 'http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetAllBus'; fetch(proxyUrl + targetUrl) .then(response =\u0026gt; response.json()) .then(busses =\u0026gt; { const lines = [...new Set(busses.map(bus =\u0026gt; bus.ROUTE))]; this.setState({ busses, lines }); }); /* eslint-enable */ };      4. Lab 05 - Display Bus Line Info When a user clicks on the Specific Bus Line either from the Bus Card we just implemented, or the Bus Line component, they should be taken to a view containing only busses for the Bus Line.\n Thankfully, we\u0026#8217;ve already implemented the majority of the logic. We can actually use the AllBusses component with a smaller array of items. It\u0026#8217;s your turn to implement!\n   check out branch 05-display-bus-info\n  In BusContainer\n  Add a \u0026lt;Route\u0026gt; that renders AllBusses\n  Pass in the correct path\n  Pass in all necessary props\n     In AllBusses.js\n  Display only the busses that belong to the Bus Line the user has selected\n      4.1. Answers src/components/busses/BusContainer.js \u0026lt;Route path=\"/busses/lines/:id\" render={props =\u0026gt; \u0026lt;AllBusses {...props} busses={busses} /\u0026gt;} /\u0026gt;   src/components/busses/AllBusses.js // ... const AllBusses = ({ match, ...props }) =\u0026gt; { return match.params.id ? ( \u0026lt;div className=\"allBusses\"\u0026gt; \u0026lt;h3\u0026gt;Busses on line {match.params.id}\u0026lt;/h3\u0026gt; \u0026lt;Divider /\u0026gt; \u0026lt;Card.Group itemsPerRow={4} doubling stackable\u0026gt; {busses( match.path.replace('/lines/:id', ''), props.busses.filter(bus =\u0026gt; bus.ROUTE === match.params.id), )} \u0026lt;/Card.Group\u0026gt; \u0026lt;/div\u0026gt; ) : ( \u0026lt;div className=\"allBusses\"\u0026gt; \u0026lt;h3\u0026gt; All Busses\u0026lt;/h3\u0026gt; \u0026lt;Divider /\u0026gt; \u0026lt;Card.Group itemsPerRow={4} doubling stackable\u0026gt; {busses(match.path, props.busses)} \u0026lt;/Card.Group\u0026gt; \u0026lt;/div\u0026gt; ); };      5. Lab 06 - Adherence   checkout branch 06-bus-info\n  write a function named adherence that\n  evaluates the ADHERENCE property on the bus object\nhint: you\u0026#8217;ll need to convert the string to a number\n  Returns the string on time if the ADHERENCE is 0\n  Returns a string indicating the bus is early if ADHERENCE is greater than 0\nie: '4 minutes ahead of schedule'\n  Returns a string indicating the bus is late if ADHERENCE is less than 0\nie: 3 minutes behind schedule\n     Render the result of the function inside of your SEGMENT component\nie: Bus 1117 is headed Southwest\u0026#8230;\u0026#8203; and is 5 minutes ahead of schedule\n   5.1. Answer src/components/busses/OneBus.js import React from 'react'; import { Redirect } from 'react-router-dom'; import { Segment } from 'semantic-ui-react'; const adherence = bus =\u0026gt; { const time = Number(bus.ADHERENCE); if (time === 0) { return `on time`; } else if (time \u0026gt; 0) { return `${time} minutes ahead of schedule`; } else if (time \u0026lt; 0) { return `${time.toString().replace('-', '')} minutes behind schedule`; } }; const OneBus = ({ match, busses }) =\u0026gt; { const bus = busses.find(b =\u0026gt; match.params.busId === b.VEHICLE); return ( \u0026lt;div className=\"oneBus\"\u0026gt; {bus ? ( \u0026lt;Segment size=\"massive\"\u0026gt; Bus {bus.VEHICLE} is headed {bus.DIRECTION} toward {bus.TIMEPOINT} and running {adherence(bus)} \u0026lt;/Segment\u0026gt; ) : ( \u0026lt;Redirect to=\"/busses\" /\u0026gt; )} \u0026lt;/div\u0026gt; ); }; export default OneBus;      "
},
{
	"uri": "/python/testing/additional-material/pytest-pycharm/",
	"title": "Setting up Pytest with PyCharm",
	"tags": [],
	"description": "",
	"content": "Adding pytest to pycharm project To add pytest to your Pycharm Project goto:\n PyCharm \u0026gt; Preferences \u0026gt; Tools \u0026gt; Python Integrated Tools \u0026gt; Testing. Change Default test runner to pytest.   Make sure pytest package is installed for your project. You may have to restart your project for changes to take affect\n Running tests You can run your test file the same way you run all other programs with PyCharm\nRunning individual tests Once you add pytest you should notice a green play button show up on the left side of every function or class definition that contains an assert statement or a a function with an assert statement.\n"
},
{
	"uri": "/software-eng-essentials/looker/building-reports-dive/",
	"title": "Building Reports: Deep Dive",
	"tags": [],
	"description": "",
	"content": "This lesson will cover a deeper dive of the creation of ad-hoc reports using the Explore interface.\nObjectives  How to use Pivot Tables How to use custom filters  Pivot Table A Pivot Table is used to summarize, sort, reorganize, group, count, total or average data stored in a table. It allows us to transform columns into rows and rows into columns. It allows grouping by any dimension, and using calculations on them.\nMultiple dimensions are often easier to look at when one of the dimensions are pivoted horizontally. Each value in the dimension will become a column in the Look. This makes the information easier to consume visually, and reduces the need to scroll down to find data.\nPivot rotates a table-valued expression by turning the unique values from one column in the expression into multiple columns in the output. And PIVOT runs aggregations where they\u0026rsquo;re required on any remaining column values that are wanted in the final output.\nExample: THD Pivot Table Get into Edit mode in the CF APP LOGS dashboard created in the previous examples:\n Click on the three dots in the top right corner of any of the tiles Click Duplicate tile Click to edit this new tile Update the name of the tile to Proxy Donut. In the Visualization section, change the display to Donut multiples. This will then provide a message that a pivot table is required to use this display. In the Filters section, remove the filter for Ot Proxy Profile by clicking on the X next to it. Using the All Fields menu on the left, make sure you have the dimensions: Com Cf App Logs Ot Proxy Profile, and Com Cf App Logs Distinct Count (Could already be selected) In the Data section, click the gear icon on the Com Cf App Logs Ot Proxy Profile column. (Shown Below) Select Pivot.    This changes something that was a row to a column. This does not look that significant in this particular example since it is just one set of columns that is being created.\nClick Run. This will generate a new donut graph in the visualization section.\n  To add the percentages of each of the donut slices, go to the setting section in the visualization and turn on Value Labels\nSave this new tile to the dashboard.\nExample: More Detailed THD Pivot Table To make this graph more specific, chose to break up count of the logs to every 15 minutes. To do this:\n Click on the three dots in the top right corner of the Proxy Donut tile Click Duplicate tile Click to edit this new tile Update the name of the tile to Proxy over time. Use the All Fields menu on the left to apply the dimension Com Cf App Logs Timestamp Minute15. Click Run. This will generate a new messy visual in the visualization section that will be updated in the next steps. Choose a Line graph. Click Run which should now show you something like:    Save this tile to the dashboard.\n In the dashboard, click to edit the existing Timestamp Time filter and click in the Tiles To Update tab.\nNotice that the two new tiles automatically had the filter applied to them. This is because these tiles started off as duplicates from already set up tiles. If these tiles had been started with an Explore then added to the dashboard, these filters would need to be manually added.\n Save the dashboard.\nCustom Filters Custom filters are filters with custom conditions that might not be available with the other, simpler filter types. These conditions can be simple or complex. Custom filters take in the fields, constants, functions, and operators that express the filtering desired.\nWhen adding a custom filter, Looker displays an editor to build an expression that evaluates as true or false. When the query is ran, Looker will only return rows for which that condition is true.\nTo add a custom filter, expand the Filters section and click the Custom Filter checkbox in the upper right. This will open up the Custom Filter editor at the bottom of the Filters section:\n  To create a Looker expression for the filter, start typing a dimension or function. Looker will display a list of functions, operators, and field names that you might want to use in the expression. Click on a term in the drop-down to add it to the expression. When finished, the expression must evaluate to true or false.\nClick Run to run the query with the custom filter applied.\n The Creating Looker expressions documentation page explains how to create Looker expressions and how the editor helps.\nLooker expressions can use as many fields, functions, and operators as the business logic requires. Just keep in mind that the more complex the condition, the more work the database must do to evaluate it, which may lengthen query times.\n Example: THD Custom Filter To access the dashboard created in the previous example, go to the Browse menu at the top, then to your personal folder, then to the Looker Workshop folder, then click on CF APP LOGS.\n To access the dashboard created in the previous example, go to the Browse menu at the top, then to your personal folder, then to the Looker Workshop folder, then click on CF APP LOGS. Start editing the dashboard by clicking on the three dots in the top right of the screen, then select Edit dashboard. Click on the three dots in the top right corner of the BOPIS tile, then click Duplicate tile. This will create a second tile titled BOPIS (copy). Click edit on BOPIS (copy) to edit this tile. Change the title of the tile to Custom Message Filter.  In the filter section, note that the Com Cf App Logs Message filter has multiple conditions in the input box.\n  These are queried using an or statement, meaning this query is saying: \u0026ldquo;Find the Messages that contain either Published CreateOrder-KafkaTopic:- Orderid OR Time taken for addTopicName.\u0026rdquo; What if you wanted to only get the messages that contains BOTH of those filters? This is where a custom filter comes into play.\nTo set up the custom filter that would check if an app name has the letter e AND has the letter z in it:\n Remove all filters with the exception of Com Cf App Logs Timestamp Time. Check the Custom Filter box. In the custom filter editor add: contains(${com_cf_app_logs.cf_app_name}, \u0026quot;e\u0026quot;) AND contains(${com_cf_app_logs.cf_app_name}, \u0026quot;z\u0026quot;) Click Run Click Save  This will now show the tile with the number of log messages that match that query. (There is a good chance no results will be returned)\nSummary In this lesson there was a deeper dive in editing dashboards.\n"
},
{
	"uri": "/python/testing/intro-to-pytest/",
	"title": "Creating and Writing Tests",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Intro to testing in Python with pytest Test File Set Up Test Function Skipping Tests Sub Tests  Testing Intro Testing is an extremely important part of software engineering, ensuring quality and improve reliability.\nTesting Scenario\nYou were asked to create a function add that should take in two numbers and return the sum. You create the following:\ndef add(x, y): return x - y Running add(3, 2) would give you 1, not the expected 5! While this code would run without any errors, this does not work as intended. A test would help catch this logical error.\nIt is very easy to test with the PyTest framework.\nPyTest The pytest framework makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries.\nInstallation When using pytest, it is possible to use the PyTest CLI to run the tests. In order to install this, run the following command in your command line:\npip3 install -U pytest Check that you installed the correct version:\n$ pytest --version This is pytest version x.y.z, imported from ... Test File Set Up By default, pytest will run all files of the form test_*.py or *_test.py (e.g. calculate_test.py ) in the current directory and its subdirectories.\nFor us to get started, create the following file structure:\ncalculate/ ├── calculate.py \u0026lt;- File to be tested └── calculate_test.py \u0026lt;- Test file 0 directories, 2 files Test Function From a test file, pytest looks for:\n test functions or methods that start with test* outside of class test functions or methods that start with test* inside classes that start with Test (without an __init__ method)  Testing Scenario Continued\nAfter having an extensive review, you found your mistake and decided that you will use tests to ensure the quality of your code and avoid future embarrassment.\nSo you create calculate_test.py:\nfrom calculate import add def test_add(): op1, op2 = 3, 2 result = 5 assert add(op1, op2) == result # 1  assert checks that your function returns a certain value. (We will go in more depth on this topic in a future lesson)  To execute the above test, type pytest. Below is an example output:\n# some more output calculate_test.py F [100%] # some more output ========== short test summary info ========== FAILED calculate_test.py::test_add - assert 1 == 5 ========== 1 failed in 0.04s ========== This test returns a failure report because add(3, 2) does not return 5.\n= It is possible to customize the output of if a test fails. Below is an example of test_add updated to have a custom message:\ndef test_add(): op1, op2 = 3, 2 result = 5 assert add(op1, op2) == result, f\u0026#34;add({op1}, {op2}) does not give the expected output of {result}\u0026#34; It is possible to get a more detailed output from tests with pytest's -v flag.\nYou altered the add function to return a + b (Correcting your error) and reran pytest -v.\nGiving the following output:\n======== test session starts ======== # some more output calculate_test.py::test_add PASSED [100%] ======== 1 passed in 0.02s ======== Skipping Tests There might be cases where it is helpful to skip a specific test, allowing for quicker and selective testing. This could be done by commenting out functions, but it can also be done by using pytests methods of skipping.\nskip decorator One way to skip a test is to use the skip decorator at the above a function.\nAn example of this is:\n@pytest.mark.skip(reason=\u0026#34;no way of currently testing this\u0026#34;) def test_add(): # function code continued The reason argument is optional to give additional output of why that test is currently skipped.\nTo see the full output of why a test is skipped, use pytest's -rs flags together.\nIt is possible to skip conditionally with the skipif decorator.\nimport sys @pytest.mark.skipif(sys.version_info \u0026lt; (3,3), reason=\u0026#34;version too old to handle this test\u0026#34;) def test_add(): # function code continued If the condition evaluates to True during testing, the test function will be skipped.\nskip method Another way to skip a test is to use the pytest.skip method anywhere within a test function.\ndef test_add(): pytest.skip(\u0026#34;Not testable currently\u0026#34;) Multiple Test Inputs When testing, many scenarios are examined, not just one set of inputs.\npytest allows the use of parameterized test, which gives the ability to run a test with multiple test conditions. Parameterized test will check what happens when different inputs, valid and invalid, are used.\nparametrize has two required arguments to help run the multiple inputs:\n argnames: is a comma-separated string denoting one or more argument names, or a list/tuple of argument strings argvalues: holds a list of values with their expect results to test.  So now we can update test_add to take in multiple different inputs:\ninput_scenarios = [(2,3,5),(100,-250,-50), (-20, -5, -25)] #1 @pytest.mark.parametrize(\u0026#34;op1,op2,expect\u0026#34;, input_scenarios) #2 def test_add(op1, op2, expect): assert add(op1, op2) == expect #3  input_scenarios holds all of the different inputs and their expected output Giving names to all of the test arguments and giving values for them. Test the specified values  An example output when running pytest -v:\n======= test session starts ======= # more output calculate_test.py::test_add[2-3-5] PASSED [ 33%] calculate_test.py::test_add[100--250--150] PASSED [ 66%] calculate_test.py::test_add[-50--25--75] PASSED [100%] ======= 3 passed in 0.02s ======= Test Class It is possible to group multiple tests in one class while using pytest.\nAn example of this could be if you wanted to have a test for both an add and a subtract method:\nclass TestCalculator: def test_add(self): op1, op2 = 3, 2 result = 5 assert add(op1, op2) == result, f\u0026#34;add({op1}, {op2}) does not give the expected output of {result}\u0026#34; def test_subtract(self): op1, op2 = 3, 2 result = 1 assert subtract(op1, op2) == result, f\u0026#34;subtract({op1}, {op2}) does not give the expected output of {result}\u0026#34; pytest discovers all tests following its conventions for Python test discovery, so it finds both test_ prefixed functions.\nTesting with Fixtures Fixtures are functions that run before each test for which it is called. They are often used to feed data to a test, such as database and API connections. Instead of writing the same code for multiple tests, we can create a fixture function to attach to the test. The fixture will execute and return data to the test before running the test.\nFixtures are created using the decorator @pytest.fixture above a function. For a test function to use a fixture, it calls the fixture as a parameter.\nWe start by adding a fixture to the beginning of the TestCalculator class and declare self as a parameter.\nclass TestCalculator: @pytest.fixture def nums(self): return 2, 3 Next, the fixture nums is called as a parameter to the functions that will use its return values. Since we are returning more than one value, the actual return values are sent as a tuple. To access each tuple, we much call its index value.\ndef test_add(self, nums): result = 5 assert add(nums[0], nums[1]) == result, f\u0026#34;add({nums[0]}, {nums[1]}) does not give the expected output of {result}\u0026#34; def test_subtract(self, nums): result = 1 assert subtract(nums[0], nums[1]) == result, f\u0026#34;subtract({nums[0]}, {nums[1]}) does not give the expected output of {result}\u0026#34; While this is a simple test, you can imagine how useful this would be for, say, database testing where you are needing to return an instance of a database connection for each test.\n# Sets up the connection to the database for the test as a fixture to run before each test @pytest.fixture def db_connect(): su.db_set_up() host = \u0026#34;localhost:27017\u0026#34; return MongoConnect(\u0026#34;test_trucks\u0026#34;,host) #Deletes the database after all tests have completed @pytest.fixture def db_tear_down(): client = pymongo.MongoClient(\u0026#34;mongodb://localhost:27017/\u0026#34;) return client.drop_database(\u0026#39;test_trucks\u0026#39;) Fixtures are very useful in PyTest. For more examples of their usage, check out the PyTest Documentation.\nSummary Testing applications has become a standard skill set required for any competent developer today. PyTest stands out among them due to its ease of use and its ability to handle increasingly complex testing needs.\n"
},
{
	"uri": "/custom-workshops/frontend-at-thd/harmony-in-practice/",
	"title": "Harmony in Practice",
	"tags": [],
	"description": "",
	"content": "Concepts and Skills  Use Harmony CLI to create a new component Use Harmony UI to document a new component  Introduction So far, we have seen how to discover components using the Harmony UI. Now, we will walk through creating new components using the Harmony command-line interface (CLI).\nIn the Getting Started module, you should have installed the Harmony CLI. To verify that Harmony is installed, open a new terminal (or command prompt for Windows) and type harmony --version. If Harmony is installed, you will see a version number printed to the console (e.g. 0.0.73).\nCreating a new component harmony make In a terminal window (or command prompt for Windows), run the following command: harmony make\nYou will be presented with a menu, as shown in the picture below.\nDefinitions of each option can be found below.\n Component:: Reusable, encapsulated code that meets an existing UX approved standard. These would be components that would live in separate repos, apart from the consuming apps/experiences. Utility:: A reusable piece of code that does not perform any UI rendering (i.e. not a component) Experience:: A page that serves as a container for UI components. Provides a common header and footer. Style:: A reusable style for UI components in the form of a CSS (or CSS variant, e.g. SCSS) Guideline:: The documented communication of design from our UX partners.  Select \u0026ldquo;Component\u0026rdquo; from the menu to create a new component. You will be presented with a list of UI frameworks in which to create the new component, as shown in the picture below.\nNOTE: At the time of writing, the only available framework is React. However, other frameworks such as Angular may be added in the future.\n"
},
{
	"uri": "/python/relational-db/postgres-python/",
	"title": "PostgreSQL and Python",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Installing the Psycopg PostgreSQL database adapter Using Psycopg to connect to/disconnect from a database Executing DDL to create a database schema Executing SQL statements to interact with database resources  Set Up We are going to show how to connect and work with relational databases and Python using PostgreSQL.\nYour instructor will be giving you the necessary credentials to connect to a PostgreSQL database. Store these credentials as environment variables with the following keys:\n PG_USER PG_PASSWORD PG_HOST  Create a new directory called pg-python. Download and add the following files to this new directory:\n connection.py requirements.txt  Making your file structure look like:\npg-python |── requirements.txt └── connection.py Within that new directory, create a virtual environment and install all needed dependencies with the following:\npython3 -m venv venv source venv/bin/activate pip3 install -r requirements.txt Database Connection In connection.py, there is a PostgresConnect class. This class is used to handle connecting, interacting, and disconnecting with a Postgres database. The methods currently in the class are:\n __init __: this will create the connection to the database __del__: this will handle when the program ends and disconnect from the database  Once a database connection is established, it is possible to interact with and manipulate the database.\nIn order to do this, we need to create methods in the PostgresConnect class:\n ddl: For Data Definition Language (DDL) statements like creating and dropping tables insert: For the inserting Data Manipulation Language (DML) statements update: For the updating DML statements delete: For the deleting DML statements read: reading in the data  DDL We need to create a cursor in order to interact with the database. Cursors created from the same connection are not isolated, i.e., any changes done to the database by a cursor are immediately visible by the other cursors.\nddl will have one parameter called sql to hold the SQL commands.\nIn your connection.py file, add the following method in the PostgresConnect class:\ndef ddl(self, sql): success = None #1 if self.db is not None and isinstance(sql,str) and sql is not \u0026#34;\u0026#34;: cursor = self.db.cursor() #2 try: cursor.execute(sql) #3 except (pg.OperationalError, Exception) as e: print(e) success = \u0026#34;Error: {e}\u0026#34; #4 self.db.rollback() else: self.db.commit() success = True #5 finally: cursor.close() #6 return success #7 To test out this new method, add the following to your main function:\nprint(\u0026#34;dropping table holidays\u0026#34;) db_connect.ddl(\u0026#34;DROP TABLE IF EXISTS holidays;\u0026#34;) print(\u0026#34;creating table holidays\u0026#34;) sql = \u0026#34;\u0026#34;\u0026#34;CREATE TABLE holidays ( HOLIDAY_NAME CHAR(40) NOT NULL, DATE CHAR(40), PRIMARY KEY (HOLIDAY_NAME));\u0026#34;\u0026#34;\u0026#34; db_connect.ddl(sql) Insert To place records into your database table, execute SQL insert statements to create a single record into holidays table with execute method.\nTo place multiple records into a table at the same time, you use the executemany method.\ninsert will have three parameters:\n sql to hold the SQL commands values to hold all of the values for the row(s) to insert into the specified table. If you are inserting one row, values will be a tuple. If you are inserting multiple rows, values will be a list of tuples. multi will be an optional parameter that will specify if one or many rows are being inserted. By default, it is set to false  Insert the following in the PostgresConnect class:\ndef insert(self, sql, values, multi=False): success = None if self.db is not None and isinstance(sql,str) and sql is not \u0026#34;\u0026#34;: cursor = self.db.cursor() try: if multi: cursor.executemany(sql, values) #1  else: cursor.execute(sql, values) #2 except (pg.OperationalError, Exception) as e: print(e) success = \u0026#34;Error: {e}\u0026#34; self.db.rollback() else: print(f\u0026#34;Insertion of {cursor.rowcount} lines successful\u0026#34;) #3 self.db.commit() success = True finally: cursor.close() return success To test out this new method, add the following to your main function:\nprint(\u0026#34;inserting a single row to holidays\u0026#34;) db_connect.insert(\u0026#34;INSERT INTO holidays(HOLIDAY_NAME, DATE) VALUES (%s, %s)\u0026#34;, (\u0026#34;New Years\u0026#34;, \u0026#39;01/01\u0026#39;)) To insert multiple records at one time, set the boolean parameter called multi (that has a default value of False) to True.\nTo test this out, add the following to your main function:\nprint(\u0026#34;inserting rows to holidays\u0026#34;) data = [(\u0026#39;Christmas\u0026#39;, \u0026#39;12/25\u0026#39;), (\u0026#39;Thanksgiving\u0026#39;, \u0026#39;11/22\u0026#39;), (\u0026#39;Valentines Day\u0026#39;, \u0026#39;02/14\u0026#39;), (\u0026#39;Llama Day\u0026#39;, \u0026#39;12/9\u0026#39;)] db_connect.insert(\u0026#34;INSERT INTO holidays(HOLIDAY_NAME, DATE) VALUES (%s, %s)\u0026#34;, data, multi=True) Read The reading operation on any database means to fetch some useful information from the database. Once our database connection is established, you are ready to make a query into this database. You can use either fetchone() method to fetch single record or fetchall() method to fetch multiple values from a database table.\n fetchone()- It fetches the next row of a query result set. A result is an object that is returned when a cursor object is used to query a table. fetchall()- It fetches all the rows in a result set. If some rows have already been extracted from the result set, then it retrieves the remaining rows from the result set. rowcount- This is a read-only attribute and returns the number of rows that were affected by an execute() method.  Queries all of the records from EMPLOYEE table that are a Sales Rep\ndef read(self, sql): success = None if self.db is not None and isinstance(sql,str) and sql is not \u0026#34;\u0026#34;: cursor = self.db.cursor() try: cursor.execute(sql) success = cursor.fetchall() except (pg.OperationalError, Exception) as e: print(e) success = \u0026#34;Error: {e}\u0026#34; else: print(f\u0026#34;Read {cursor.rowcount} lines successfully\u0026#34;) finally: cursor.close() return success To test out this new method, add the following to your main function:\nprint(\u0026#39;reading rows from holidays\u0026#39;) results = db_connect.read(\u0026#34;SELECT * FROM HOLIDAYS WHERE DATE LIKE \u0026#39;%12%\u0026#39;\u0026#34;) for row in results: [holiday_name, date] = row print(f\u0026#34;{holiday_name}: {date}\u0026#34;) ## Now print fetched result Update The update operation on any database means to update one or more records, which are already available in the database.\ndef update(self, sql): success = None if self.db is not None and isinstance(sql,str) and sql is not \u0026#34;\u0026#34;: cursor = self.db.cursor() try: cursor.execute(sql) except (pg.OperationalError, Exception) as e: print(e) success = \u0026#34;Error: {e}\u0026#34; self.db.rollback() else: print(f\u0026#34;Updated {cursor.rowcount} lines successfully\u0026#34;) self.db.commit() success = True finally: cursor.close() return success To test out this new method, add the following to your main function to update all holidays with 02 to Galentines Day:\nprint(\u0026#39;updating rows in holidays\u0026#39;) db_connect.update(f\u0026#34;UPDATE HOLIDAYS SET HOLIDAY_NAME=\u0026#39;Galentines Day\u0026#39; WHERE DATE LIKE \u0026#39;%02%\u0026#39;\u0026#34;) Delete The delete operation is required when you want to delete some records from your database.\ndef delete(self, sql): success = None if self.db is not None and isinstance(sql,str) and sql is not \u0026#34;\u0026#34;: cursor = self.db.cursor() try: cursor.execute(sql) except (pg.OperationalError, Exception) as e: print(e) success = \u0026#34;Error: {e}\u0026#34; self.db.rollback() else: print(f\u0026#34;Deleted {cursor.rowcount} lines successfully\u0026#34;) self.db.commit() success = True finally: cursor.close() return success To test out this new method, add the following to your main function to delete all holidays that have a date with a 9 in it:\nprint(\u0026#39;deleting rows in holidays\u0026#39;) db_connect.delete(f\u0026#34;DELETE FROM HOLIDAYS WHERE DATE LIKE \u0026#39;%9%\u0026#39;\u0026#34;) Summary Database adapters like Psycogpg provide many useful functions that allow a straight-forward connection to a relational database and easy schema and resource creation. The code base requires a minimal amount of imports and allows the use of pure Python code with recognizable SQL statements.\nLab Clone down the repo for the PostgreSQL Python lab with the following instructions:\ngit clone https://github.homedepot.com/om-labs/python-databases.git cd python-databases/pg-python Follow the instructions in the README\n"
},
{
	"uri": "/python/relational-db/postgres-testing/",
	"title": "Testing Postgres",
	"tags": [],
	"description": "",
	"content": "Learning Objective  Getting familiar the Python Unittest Library Writing test using Unittest methods  Unittest Testing Library We will use the Python testing library, Unittest, to test our database interactions. Unittest provides a very straight forward way to test the methods on the PostgresConnect class.\nFor a more in-depth explanation of Unittest, please refer to the Unittest documentation and Orange Academys Unittest Curriculum.\nTest Set-up In the pg-python directory, add a new file called test.py.\nMaking your file structure look like:\npg-python |── connection.py └── test.py The unittest module supports several tools for constructing and running tests. Begin by importing the PostgresConnect class from connection.py and the Unittest module.\nfrom connection import PostgresConnect import unittest The first test to write will test the ddl method on our class.\nclass PostgresConnectTest(unittest.TestCase): #1 def setUp(self): self.test_connect = PostgresConnect(\u0026#39;test_truck\u0026#39;) #2  def test_ddl(self): #3  test_true = \u0026#34;\u0026#34;\u0026#34; drop table if exists test_warehouse; create table test_warehouse( warehouse_id SERIAL PRIMARY KEY, location VARCHAR(30), phone NUMERIC(10) );\u0026#34;\u0026#34;\u0026#34; #4  Writing Assertions Now it\u0026rsquo;s time to add assertions to our test. Assertions assert a particular condition or expected result. A list of assertions can be found in Orange Academys Unittest Curriculum and in the Unittest documentation.\n# Given the test_true variable, test if the value will allow the transaction to complete successfully  self.assertTrue(self.test_connect.ddl(test_true)) #1 # Write a test that checks the expected outcome if a value of None or empty string is sent self.assertIsNone(self.test_connect.ddl(None)) #2 # Write a test that verify\u0026#39;s an exception is called if the sql is `drop table someTable` self.assertRaises(Exception, self.test_connect.ddl(\u0026#34;drop table someTable;\u0026#34;)) #3 Running the test Running the tests is fairly simple. unittest.main() provides a command-line interface to the test script.\nif __name__ == \u0026#39;__main__\u0026#39;: unittest.main() When ran from the command line, the above script produces an output that looks like this:\nConnected to Postgres database table \u0026#34;sometable\u0026#34; does not exist Connection closed . ---------------------------------------------------------------------- Ran 1 test in 0.053s OK Messages from the method are seen, as well as any Exception encountered during the test.\nSummary Unittest provides a very easy way to check the validity of the methods, including methods to create interaction with the database. It allow for the creation of to simple test cases and an easy to interpret command line read-out.\nLab In the python-databases/pg-python/ directory, complete the tests in the db_testing.py file. Run the test by typing python db_testing.py at the command line.\n"
},
{
	"uri": "/python/relational-db/orm-intro/",
	"title": "ORM Intro",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Understand the SQLAlchemy Object Relationship Mapper Define the file hierarchy of the course Set up a successful database connection  SQLAlchemy ORM An object relational mapper(ORM) maps a relational database system to objects. The ORM is independent of which relational database system is used. From within Python, you can talk to objects and the ORM will map it to the database. We will specifically learn to use the SqlAlchemy ORM.\nWe communicate with the database using the ORM with Python objects and classes. What an ORM does is shown in the illustration below:\nSet Up For these lessons, your instructor will be giving you the necessary credentials to connect to the database. Store these credentials as environment variables with the following keys:\n ORM_USER (with the value of the username given to you from your instructor) ORM_PASSWORD (with the value of the password given to you from your instructor) ORM_HOST (with the value of the host given to you from your instructor)  WARNING: If you have not already, install the psycopg library with this command: pip3 install psycopg2-binary\nConnect Create a directory called orm-python. In the subdirectory, create a file called set_up.py and add this starter code.. Your file structure should look like the following:\norm-python └── set_up.py When you run set_up.py, you should get back Successfully connected!\nStarter Code Methods Explained\n create_engine: creates a SQLAlchemy engine that connects a Pool and Dialect together to provide a source of database connectivity and behavior.  Summary SQLAlchemy ORM provides the ability of associating user-defined Python classes with database tables, and instances of those classes with rows in their corresponding tables.\n"
},
{
	"uri": "/react/pillars/advanced-state-mgmt/",
	"title": "Advanced State Management",
	"tags": [],
	"description": "",
	"content": "Welcome to Advanced State Management in React! For more details see the syllabus.\n"
},
{
	"uri": "/software-eng-essentials/text-editors/atom/",
	"title": "Atom",
	"tags": [],
	"description": "",
	"content": "Learning Objectives The main purpose of this lesson is to get students comfortable with the Atom editor, including how to configure it, install plugins, and discover faster, more efficient ways of editing files.\nAtom  Developed by GitHub Free and open source Multi-platform (OS X, Windows, Linux) Popular (widely used for web development) Extensible (we can add functionality via Atom packages)   Atom is a desktop application built with HTML, JavaScript, CSS, and Node.js integration. It runs on Electron, a framework for building cross platform apps using web technologies.\n Launching Atom To open atom, simply click the icon in the Dash or Launchpad or just type atom in a terminal.\nTo open Atom with a specific file, we can use the command line again, but this time passing in a file name: atom veggie_soup.txt\nProject mode Real-world software projects often involve many files organized into folders. It is handy to be able to see all the files in our project when working in our text editor. Atom makes this easy as it supports a project mode. To use this we simply pass a directory instead of a file:\natom recipes or\u0026hellip;\ncd recipes atom .  The sidebar now has a folders section that shows all the files and folders in the project. Clicking on a folder expands the view to show its contents.\n Atom Editor Window Components When you first launch Atom you should see something like this:\nLet\u0026rsquo;s go over the basics!:\n Menu Sidebar Open files via tabs  can rearrange tabs can change layout of tabs - Alt-Command-\u0026lt;Number\u0026gt;   Edit pane Ruler Footer  Line #, Column # White Space Mode File Type    Find (Search)  You can search a single file or all of the open files You can search case sensitive or case insensitive You can search using regular expressions (we will talk about those later)  Settings and themes cmd + , allows you to access the Atom\u0026rsquo;s settings.\nYou can customize the following settings in Atom:\n Core settings - window and pane behavior, auto-updating, etc. Editor settings - font size, indenting, tabs vs. spaces, line height, etc. Keybindings - keyboard shortcuts Packages - view, configure, and uninstall Atom packages Themes - customize the look of Atom Install - you can install Atom packages that teach Atom new tricks!  Lab: Test Drive Your Text Editor Listed below are four exercises for you to work through. They will help you learn how to use your text editor to become an efficient software engineer. Follow the instructions in each lesson.\n Eggs and Ham Fruit Math Superheroes  References  Atom\u0026rsquo;s Official website Atom Flight Manual Atom Basics  "
},
{
	"uri": "/golang/foundations/building/",
	"title": "Building",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Building and running a Go file Cross Compiling Installing the built artifact  Building The build subcommand compiles the packages named by the import paths, along with their dependencies, but it does not install the results.\n Install is covered below Does output an executable binary Same file/package rules as run apply  Try it: Build Messenger App Using the same code and file from above, execute the following command from that same directory:\ngo build\nList the contents of your directory.\n You should have a file with the same name as your directory, OR the name of the file that your main function was defined in if you supplied the a file to go build  Naming Your Binary: The -o flag By default the executable binary is named after your directory.\nUse -o with the build command to name your binary\nTry it Run the following:\ngo build main.go -o hello-world\nYou should now have an executable named hello-world\nCross Compiling You can compile for specific platforms from any platform that supports go.\nFor example:\n Mac to Windows Linux to Mac (Darwin) Windows to Linux  GOOS and GOARCH\nThese two environment variables control the target platform your application will be compiled for.\nTry it: Mac Users\nExecute the following on your Mac to cross-compile for Windows:\nGOOS=windows GOARCH=amd64 go build main.go Windows users\nExecute the following on your Windows machine to cross-compile for Mac:\nGOOS=darwin GOARCH=amd64 go build main.go Then attempt to execute your binary (it will fail).\nMac AND Windows users:\nExecute the following to cross-compile for Linux:\nGOOS=linux GOARCH=amd64 go build main.go Installing Your Program or Module The command, go install works similar to go build except that it produces the binary into a path that is specified by the GOBIN environment variable.\nDefault GOBIN Paths: If GOBIN environment variable is not set, it defaults to\n $HOME/go/bin on Unix/Linux %USERPROFILE%/go/bin on Windows  Note: If you\u0026rsquo;ve changed your GOPATH environment variable, your GOBIN will be located in the bin of that path\nSummary In this lesson we learned:\n how to build a Golang program into a executable binary how to cross-compile for other operating systems and/or CPU platforms how to install our built program into our GOBIN directory  "
},
{
	"uri": "/golang/concurrency/channels/",
	"title": "Channels",
	"tags": [],
	"description": "",
	"content": "Channels provide a way for goroutines to communicate. Channels are created by using the the make keyword, and are defined with the type chan and the data type of the data the channel will carry.\n// unbuffered channel c1 := make(chan \u0026lt;datatype\u0026gt;) //buffered c2 := make(chan \u0026lt;datatype\u0026gt;, \u0026lt;capacity\u0026gt;) // more on capacity later Channels can be passed as function argument . make() will create a pointer for the channel. When the channel is passed in, it will not be a copy. You will need to keep this in mind when designing an application that passes channels around.\nThe direction of arrow for a channel specifies the direction of flow of data\n  chan :bidirectional channel (Both read and write)\n  chan \u0026lt;- :only writing to channel\n  \u0026lt;- chan :only reading from channel (input channel)\n  Unbuffered Channels Syntax: \u0026lt;name\u0026gt; := make(chan \u0026lt;type\u0026gt;)\nExample: c := make(chan string)\nUnbuffered channels have no capacity and therefore require goroutines to make any exchange.\nWhen a goroutine attempts to send a resource to an unbuffered channel and there is no goroutine waiting to receive the resource, the channel will lock the sending goroutine and make it wait.\nExample:\npackage main import \u0026#34;fmt\u0026#34; func main() { c := make(chan string) //unbuffered channel has no capacity and will cause a deadlock of the \u0026#34;main\u0026#34; goroutine \tc \u0026lt;- \u0026#34;Hello\u0026#34; //this will block the \u0026#34;main\u0026#34; routine. \tfmt.Println(\u0026lt;-c) } The output results in this error:\nfatal error: all goroutines are asleep - deadlock! To prevent a deadlock, we can add a goroutine that will add the string on the channel in the background.\npackage main import \u0026#34;fmt\u0026#34; func main() { c := make(chan string) go func() { // the goroutine runs in the background and prevents the \u0026#34;main\u0026#34; go routine from blocking.  c \u0026lt;- \u0026#34;Hello\u0026#34; }() fmt.Println(\u0026lt;-c) } Values can only be added to an unbuffered channel in a goroutine.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; ) func main() { var c chan string = make(chan string) // 1 \tgo pinger(c) // 2 \tgo printer(c) // 3 \tvar input string fmt.Scanln(\u0026amp;input) // 4 } func pinger(c chan string) { for i := 0; ; i++ { time.Sleep(time.Second * 10) // 5 \tc \u0026lt;- \u0026#34;ping\u0026#34; // 6 \t} } func printer(c chan string) { for { log.Println(\u0026#34;Waiting for a message\u0026#34;) msg := \u0026lt;-c // 7 \tlog.Println(\u0026#34;Message received!\u0026#34;) log.Println(msg) } } Share by Communicating Go encourages shared values to be passed around on channels, making values actively never shared by separate threads of execution.\nOnly one goroutine has access to the value at any given time avoiding data races.\nDo not communicate by sharing memory; instead, share memory by communicating. - A Pikism.\nA race condition is an undesirable effect when you have concurrent processes on a system that has resources which must be accessed in a specific order.\nRace conditions only occur sometimes, race conditions can be difficult to troubleshoot.\nExample: sending out a request for data, waiting 5 seconds, and then attempting to use that data. If the process to retrieve the data takes longer than 5 seconds, an error will occur.\nLab Unbuffered Channels  If you haven\u0026rsquo;t already, Clone down the exercise repo found at https://github.homedepot.com/om-labs/go-concurrency Complete the instructions in unbuffered/README.md  Buffered Channels Channels can be buffered. Buffered channels:\n Have the ablility to hold more than one value (defined by it\u0026rsquo;s capacity). Allow data to queue on a channel, in a FIFO pattern (First-In, First-Out)  The number of items that can be placed onto the channel is defined by a second argument in the make() function.\nmake(chan string, 4)\nThis creates a channel with a buffer size of 4. In other words, it could hold 4 strings before it would block anything from being put on it.\n Sending to a buffered channel blocks only when the buffer is full. Receiving from the channel blocks when the buffer is empty.  Normally a channel will block both sides until they are both ready to \u0026ldquo;send/receive\u0026rdquo;.\nExample 1. The channel is blocking anything else from being put on\nExample 2. Unbuffered channel, so it is blocking anything being written to\nc := make(chan string, 2) // 1 \tc \u0026lt;- \u0026#34;weeee\u0026#34;\t// 2 \tc \u0026lt;- \u0026#34;ride again...\u0026#34; // 3 \tfmt.Println(\u0026lt;-c)\t// 4 \tfmt.Println(\u0026lt;-c)\t// 5 Buffered Channel Example  Pay attention to the arrows in the function signature where a channel is accepted. It has directional significance.\n  Follow the instructions in the readme for the go foundations labs cd \u0026lt;your workspace\u0026gt;/go-concurrency/channelExample/buffered Code is in main.go, producer.go ,and consumer.go. Open the files or execute by running go run *.go  Lab Buffered Channels  If you haven\u0026rsquo;t already, Clone down the exercise repo found at https://github.homedepot.com/om-labs/go-concurrency Complete the instructions in buffered/README.md  Closing Channels Closing a channel indicates that no more values will be sent on it. This can be useful to communicate completion to the channel’s receivers.\nA sender can close a channel by calling the close method on it, for example :\nclose(ch) // where \u0026#39;ch\u0026#39; is a channel. A receiver can test whether a channel has been closed by assigning a second parameter to the receive expression:\nv, ok := \u0026lt;-ch ok is false if there are no more values to receive and the channel is closed.\npackage main import \u0026#34;fmt\u0026#34; func getjobs(jobs chan\u0026lt;- int){ // 1 \t// Let\u0026#39;s create 3 jobs. \tjobs \u0026lt;- 55 jobs \u0026lt;- 65 jobs \u0026lt;- 75 close(jobs) // 2 } func work(jobs \u0026lt;-chan int, done chan\u0026lt;- bool){ // 3 \t// Forever loop, return when the channel is closed. \tfor { job, open := \u0026lt;-jobs // 4 \tif open { fmt.Printf(\u0026#34;Doing the work on %v \\n\u0026#34;, job) } else { // Else the channel was closed. \tfmt.Println(\u0026#34;Work is finished. No more jobs to do.\u0026#34;) done \u0026lt;- true return } } } func main(){ jobs := make(chan int, 5) done := make(chan bool) go getjobs(jobs) go work(jobs, done) \u0026lt;-done }  getjobs accepts a channel of integers, that it will only be written to. getjobs closes the channel after writing 3 integers to the channel. work accepts a channel of integers that it will only read from called jobs, and a channel of booleans, that it will write to. Inside a forever loop, the next job is attempted to be read from the jobs channel. If the channel is not closed, it will perform work on the job. Otherwise it will end the execution of the work function.  In more complex patterns this can be used to end worker goroutines.\nRanging over a channel When using range on a channel, it is very important to close the channel. In the example below, If the channel is left open, the range never finishes and the function does not complete.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { ch := make(chan int, 3) ch \u0026lt;- 2 ch \u0026lt;- 2 ch \u0026lt;- 2 close(ch) go sum(ch) time.Sleep(time.Second * 1) } func sum(ch chan int) { sum := 0 for val := range ch { sum += val } fmt.Printf(\u0026#34;Sum: %d\\n\u0026#34;, sum) Channel Summary Table A summary table which shows the result of each operation on the different types of channel.\nSource: Golang By Example - Channel In Go (Golang)\n   Command Unbuffered Channel**(Not Closed and not nil)** Buffered Channel**(Not Closed and not nil)** Closed Channel Nil Channel     Send Block if there is is no corresponding receiver otherwise success Block if the channel is full otherwise success Panic Block forever   Receive Block if there is no corresponding sender otherwise success Block if the channel is empty otherwise success Receives the default value of data type from the channel if channel is empty else receives the actual value Block forever   Close Success Success Panic Panic   Length 0 Number of elements queued in the buffer of the channel -0 if unbuffered channel-Number of elements queued in the buffer if buffered channel 0   Capacity 0 Size of the buffer of the channel -0 if unbuffered channel-Size of the buffer if buffered channel 0    Lab - Closing Channels  If you haven\u0026rsquo;t already, Clone down the exercise repo found at https://github.homedepot.com/om-labs/go-concurrency Complete the instructions in closingch/README.md  Summary Channels in go provide a way of communicating among concurrent processes in Golang. They can be buffered or non-buffered. They should be closed when the work is completed.\n"
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/getting-started/",
	"title": "CLI - Getting Started",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  How to start a terminal session Understanding the role of the Terminal and the Shell Executing basic commands Using man pages Chaining and Piping commands  Starting a Terminal Session Recall that the Terminal is a window where we can interact with the computer using a Command Line Interface.\nYou can use Spotlight to start a terminal session on a Mac:\n Press CMD + Spacebar to open a Spotlight Search bar (or click the Magnifying Glass icon in the upper right-hand corner of your sreen) Type \u0026ldquo;terminal\u0026rdquo; in the search bar and hit the return key  You should see a Terminal window appear on your screen.\n  Identifying the prompt The terminal window should display a shell prompt. This is where you will type commands for the shell to execute.\n NOTE: Often the prompt ends in a $ character, but the prompt can be customized in many ways.\n The Basics of the Shell The shell is a REPL that waits for user input and then:\n Reads the input Evaluates the input Prints the output Loops back to waiting for input again.    In essence the shell is your personal genie waiting for you to make a request and then rapidly processing the request and waiting for your next request. And there is no 3 wish limit!\nEverything is a command  Everything we enter into the command line is a command. When we hit enter, the command is executed. Most commands have output, which is displayed on the screen for us to see. Some commands exist to have a side-effect which means that they alter our computer in some way. Some commands may provide both an output and a side effect.   NOTE: Often times a command whose main job is a side effect may not provide any output if it succeeds. If there is an error it will print an error message.\n Command Syntax (Flags and Arguments) Commands generally consist of three parts, the command, followed by flags (aka options), and finally arguments.\n$ command [-options] [arguments]  The command comes first. It is like the verb, which says generally, \u0026ldquo;this is what I want to do\u0026rdquo;. options or flags - these are optional and are used to customize the command in different ways. There may be zero or more options. Options usually start with one or two dashes. Usually one dash is for a short one letter abbreviations, while two dashes is used for the long name for the option. The arguments specify the data or resources you want to do the action against. Examples include file names, directory names, URLs, processes, etc.  Our First Command  We want to follow a programming convention and print \u0026ldquo;hello world\u0026rdquo; to the screen for our first command. Our tool to accomplish this task is the echo command, which takes a string of characters as an argument and prints them to the screen. Type \u0026ldquo;echo hello world\u0026rdquo; at the shell prompt, and then press return to enter the command.  $ echo hello world hello world $ echo does not require the string argument to be wrapped in quotation marks, but it certainly accepts these strings just the same.\nPrinting arguments with single or double quotes:\n$ echo \u0026#39;hello, thd\u0026#39; hello, thd $ echo \u0026#34;hello, thd\u0026#34; hello, thd $ Getting Unstuck Leaving off a closing quotation mark will result in the following:\n$ echo \u0026#39;hello, Orange Academy \u0026gt; Now we are stuck!\nLet\u0026rsquo;s fix the problem by simply adding the matching quote and hitting return.\n$ echo \u0026#39;hello, Orange Academy \u0026gt; \u0026#39; hello, Orange Academy Getting Into Trouble  There are lots of things than can get you into trouble when using the command line. A command may be entered which starts an infinite loop, or simply leaves the terminal hanging or unresponsive.  Examples that get you stuck (usually because you did not provide the command with enough arguments):\n$ cat $ tail $ echo \u0026#34;hello $grep foobar $yes please Getting Out Of Trouble  Getting out of trouble is usually easy! Usually the solution is to type CTRL + C When CTRL + C fails, hitting esc may do the trick As a last resort, you can close your Terminal window or tab and start a new one  Getting Help There are generally 3 ways to get help with a command.\n Some commands will display help when you add --help or -h to the end of the command; for example: brew --help Consult the man (manual) page; for example: man ls Search Google and/or Stack Overflow  The manual Pages  A powerful tool called man can be used learn more about available commands. To use man, type man followed by the command you want to learn more about. Your system’s details for the man page of echo might look like the following:  $ man echo ECHO(1) BSD General Commands Manual ECHO(1) NAME echo -- write arguments to the standard output SYNOPSIS echo [-n] [string ...] DESCRIPTION The echo utility writes any specified operands, separated by single blank (` \u0026#39;) characters and followed by a newline (`\\n\u0026#39;) character, to the standard output. The following option is available: -n Do not print the trailing newline character. This may also be achieved by appending `\\c\u0026#39; to the end of the string, as is done by iBCS2 compatible systems. Note that this option as well as the effect of `\\c\u0026#39; are implementation-defined in IEEE Std 1003.1-2001 (``POSIX.1\u0026#39;\u0026#39;) as amended by Cor. 1-2002. Applications aiming for maximum portability are strongly encouraged to use printf(1) to suppress the newline character. ...  NOTE: To exit out of the man page, type the q (for quit) character.\n Exercises  Write a command that prints out the string \u0026ldquo;hello, home depot\u0026rdquo;. Do it two different ways, both with and without using quotation marks. Type the command echo \u0026lsquo;hello (with a missing single quote), and then get out of trouble!  Some More Commands Let\u0026rsquo;s try another command, the history command, which simply outputs a list of commands that we have executed in our shell:\n$ history 1 echo hello world 2 echo \u0026#39;hello, thd\u0026#39; 3 echo \u0026#34;hello, thd\u0026#34; 4 echo \u0026#39;hello, Orange Academy\\n\u0026#39; Another command is whoami, which is helpful when you have multiple accounts and want to know your login id:\n$ whoami mah3093 If you want to know the date and time (according to your computer), simply enter the date command:\ndate Fri Oct 9 11:09:54 EDT 2020 To see a calendar containing the current month, use the cal command:\n$ cal October 2020 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 For fun try executing the command cal 2020.\nExercise To find out what day of the week you were born, try cal month year where month and year are the month and year you were born. For example: cal june 1987.\nConditional Execution  Sometimes you may want to execute a command only if a previous command is successful Or conversely only run a command if the previous command failed You can accomplish these conditional executions with the \u0026amp;\u0026amp; (AND) and the || (OR) operators  rm foo.txt \u0026amp;\u0026amp; echo \u0026#34;file removed\u0026#34; # only do the echo if the `rm` is successful rm foo.txt || echo \u0026#34;file not removed\u0026#34; # only do the echo if the `rm` failed To run a second command after a first command unconditionally, you can use a ; between the 2 commands:\nrm foo.txt; echo \u0026#34;done\u0026#34; # always echo the `done` message Cleaning up Two essential commands are:\n clearing the terminal screen exiting the terminal  $ clear The keyboard shortcut for clear is ^l (CTRL + l)\n$ exit The keyboard shortcut for exit is ^d (CTRL + d)\nExercises  Clear the contents of the current tab. Open a new tab, execute echo goodbye, and then exit. By running man sleep, figure out how to make the terminal \u0026ldquo;sleep\u0026rdquo; for 5 seconds, and execute the command to do so. Execute the command to sleep for 5000 seconds, realize that’s well over an hour, and then use the instructions from \u0026ldquo;Getting out of trouble\u0026rdquo; to cancel the command.  "
},
{
	"uri": "/javascript/performance/client-side-rendering/",
	"title": "Client-side Rendering",
	"tags": [],
	"description": "",
	"content": "Modern web development: client-side rendering What is client-side rendering? Client-side rendering is a way to present rich data in an application, but relies on the client (rather than the server) to build the content of the webpage. This lesson is intended to talk about the pros and cons of client-side rendering in the context of today’s web ecosystem.\nLearning objectives  Understand why it was necessary to invent client-side rendering (what problems does client-side rendering solve?) Understand how client-side rendering provides a higher level of interactivity, at the cost of a slower First Contentful Paint (FCP) and slower First Meaningful Paint (FMP) Quantify the performance difference between client-side rendering and server- side rendering  How did we get here? In the pre-2010\u0026rsquo;s world of the internet, server-side rendering was the default way to serve HTML pages to a user. This worked very well for displaying images and text, like in a blog or e-magazine, but provided little in the way of interactivity. However, sometimes not much interactivity is needed to accomplish a goal.\nFor example, consider amazon.com. It\u0026rsquo;s a catalog of items that you can browse. Sure, the page refreshes every time you navigate between items, but the page loads so fast and the level of interactivity required to build an ecommerce site is low enough that server-side rendering is all that is needed.\nHowever, consider a website like facebook.com, or even Instagram. You can scroll through an endless amount of posts without the web page ever reloading. Websites that render content dynamically, like Facebook and Instagram, are called Single Page Applications (SPAs) and are made possible through the magic of client-side rendering.\nWe will dive deeper into Single Page Applications in the next section.\nThe rise of the Single Page Application (SPA) From Wikipedia: a single-page application (SPA) is a web application or web site that interacts with the user by dynamically rewriting the current page rather than loading entire new pages from a server.\nAfter the advent of mobile phones and the introduction of mobile phone applications, users began to expect more from websites. Users became accustomed to an \u0026ldquo;app-like\u0026rdquo; experience on their phones, why not on the web as well? Thanks to Moore\u0026rsquo;s Law and vast improvements in the JavaScript language, it was now possible to perform complex calculations within a browser; the kind of calculations that could enable complex component-centric logic that had previously proved impractical in the previous web-development paradigm.\nThe good news: Websites can now be apps!\nThe bad news: The complex logic required to make a website an app results in slow initial load times, i.e. slower First Contentful Paints and slower First Meaningful Paints.\nJust how slow are we talking? Using the skills that we just acquired in the Gathering Metrics lesson, let\u0026rsquo;s measure the FCP and FMP of several web applications that use client-side rendering.\n"
},
{
	"uri": "/react/performance/client-side-rendering/",
	"title": "Client-side Rendering",
	"tags": [],
	"description": "",
	"content": "Modern web development: client-side rendering What is client-side rendering? Client-side rendering is a way to present rich data in an application, but relies on the client (rather than the server) to build the content of the webpage. This lesson is intended to talk about the pros and cons of client-side rendering in the context of today’s web ecosystem.\nLearning objectives  Understand why it was necessary to invent client-side rendering (what problems does client-side rendering solve?) Understand how client-side rendering provides a higher level of interactivity, at the cost of a slower First Contentful Paint (FCP) and slower First Meaningful Paint (FMP) Quantify the performance difference between client-side rendering and server- side rendering  How did we get here? In the pre-2010\u0026rsquo;s world of the internet, server-side rendering was the default way to serve HTML pages to a user. This worked very well for displaying images and text, like in a blog or e-magazine, but provided little in the way of interactivity. However, sometimes not much interactivity is needed to accomplish a goal.\nFor example, consider amazon.com. It\u0026rsquo;s a catalog of items that you can browse. Sure, the page refreshes every time you navigate between items, but the page loads so fast and the level of interactivity required to build an ecommerce site is low enough that server-side rendering is all that is needed.\nHowever, consider a website like facebook.com, or even Instagram. You can scroll through an endless amount of posts without the web page ever reloading. Websites that render content dynamically, like Facebook and Instagram, are called Single Page Applications (SPAs) and are made possible through the magic of client-side rendering.\nWe will dive deeper into Single Page Applications in the next section.\nThe rise of the Single Page Application (SPA) From Wikipedia: a single-page application (SPA) is a web application or web site that interacts with the user by dynamically rewriting the current page rather than loading entire new pages from a server.\nAfter the advent of mobile phones and the introduction of mobile phone applications, users began to expect more from websites. Users became accustomed to an \u0026ldquo;app-like\u0026rdquo; experience on their phones, why not on the web as well? Thanks to Moore\u0026rsquo;s Law and vast improvements in the JavaScript language, it was now possible to perform complex calculations within a browser; the kind of calculations that could enable complex component-centric logic that had previously proved impractical in the previous web-development paradigm.\nThe good news: Websites can now be apps!\nThe bad news: The complex logic required to make a website an app results in slow initial load times, i.e. slower First Contentful Paints and slower First Meaningful Paints.\nJust how slow are we talking? Using the skills that we just acquired in the Gathering Metrics lesson, let\u0026rsquo;s measure the FCP and FMP of several web applications that use client-side rendering.\n"
},
{
	"uri": "/golang/testing/coverage/",
	"title": "Code Coverage",
	"tags": [],
	"description": "",
	"content": "Goals Understand the meaning of code coverage and why its important.\nLearning Objectives  What is code coverage? The Test Pyramid  What is Code Coverage? Code coverage is a term used to describe the percentage of your code that has been included in tests. There are different breakdowns of code coverage:\n  Function: % of functions in the code that have been tested.\n  Line: % of lines ( with code ) that have been tested\n  Path/Branch: % of statements that have been covered. This means if you have an if-then-else statements, both possibilities are accounted for in tests.\n  The below is an example of a code coverage report.  Warning: A common pitfall on development teams is that they will demand a specific code coverage. This can actually cause poorly written tests that are more to meet the goal than to test.\nDon\u0026rsquo;t write tests just to meet test coverage goals, write tests to test code.\n The Testing Pyramid The \u0026ldquo;Testing Pyramid\u0026rdquo; is an idea that demonstrates how to group software tests into sections of tests covering different scopes and comparatively what percentage of testing should be in that group.\nMike Cohn came up with this concept in his book Succeeding with Agile. The original test pyramid has three layers.\nThey are :\n UI Tests (The least) Service tests (The middle) Unit tests (The most)  This could be modernized to include more of the types we have now. From the bottom to the top, it may look more like:\n E2E (The least percentage of tests) Integrated Component Unit (The largest percentage of tests)  Therefore, unit tests should be the most numerous and take the least amount of time, while E2E tests should be the least in number, and take the most amount of time to run.\nThe pyramid itself is one train of thought and a general idea. A team should investigate the solution to testing that best fits the needs of the application and the team.\nConclusion There are three ways to measure the amount of tests that have been written:\n Function Line Branch  The Testing Pyramid method says the majority of tests should be on the unit scope.\nIt isn\u0026rsquo;t the number of tests, but the level of reliability the tests can provide.\n"
},
{
	"uri": "/python/testing/coverage/",
	"title": "Code Coverage",
	"tags": [],
	"description": "",
	"content": "Goals Understand the meaning of code coverage and why its important.\nLearning Objectives  What is code coverage? The Test Pyramid  What is Code Coverage? Code coverage is a term used to describe the percentage of your code that has been included in tests. There are different breakdowns of code coverage:\n  Function: % of functions in the code that have been tested.\n  Line: % of lines ( with code ) that have been tested\n  Path/Branch: % of statements that have been covered. This means if you have an if-then-else statements, both possibilities are accounted for in tests.\n  The below is an example of a code coverage report.  Warning: A common pitfall on development teams is that they will demand a specific code coverage. This can actually cause poorly written tests that are more to meet the goal than to test.\nDon\u0026rsquo;t write tests just to meet test coverage goals, write tests to test code.\n The Testing Pyramid The \u0026ldquo;Testing Pyramid\u0026rdquo; is an idea that demonstrates how to group software tests into sections of tests covering different scopes and comparatively what percentage of testing should be in that group.\nMike Cohn came up with this concept in his book Succeeding with Agile. The original test pyramid has three layers.\nThey are :\n UI Tests (The least) Service tests (The middle) Unit tests (The most)  This could be modernized to include more of the types we have now. From the bottom to the top, it may look more like:\n E2E (The least percentage of tests) Integrated Component Unit (The largest percentage of tests)  Therefore, unit tests should be the most numerous and take the least amount of time, while E2E tests should be the least in number, and take the most amount of time to run.\nThe pyramid itself is one train of thought and a general idea. A team should investigate the solution to testing that best fits the needs of the application and the team.\nConclusion There are three ways to measure the amount of tests that have been written:\n Function Line Branch  The Testing Pyramid method says the majority of tests should be on the unit scope.\nIt isn\u0026rsquo;t the number of tests, but the level of reliability the tests can provide.\n"
},
{
	"uri": "/software-eng-essentials/testing/coverage/",
	"title": "Code Coverage",
	"tags": [],
	"description": "",
	"content": "Goals Understand the meaning of code coverage and why its important.\nLearning Objectives  What is code coverage? The Test Pyramid  What is Code Coverage? Code coverage is a term used to describe the percentage of your code that has been included in tests. There are different breakdowns of code coverage:\n  Function: % of functions in the code that have been tested.\n  Line: % of lines ( with code ) that have been tested\n  Path/Branch: % of statements that have been covered. This means if you have an if-then-else statements, both possibilities are accounted for in tests.\n  The below is an example of a code coverage report.  Warning: A common pitfall on development teams is that they will demand a specific code coverage. This can actually cause poorly written tests that are more to meet the goal than to test.\nDon\u0026rsquo;t write tests just to meet test coverage goals, write tests to test code.\n The Testing Pyramid The \u0026ldquo;Testing Pyramid\u0026rdquo; is an idea that demonstrates how to group software tests into sections of tests covering different scopes and comparatively what percentage of testing should be in that group.\nMike Cohn came up with this concept in his book Succeeding with Agile. The original test pyramid has three layers.\nThey are :\n UI Tests (The least) Service tests (The middle) Unit tests (The most)  This could be modernized to include more of the types we have now. From the bottom to the top, it may look more like:\n E2E (The least percentage of tests) Integrated Component Unit (The largest percentage of tests)  Therefore, unit tests should be the most numerous and take the least amount of time, while E2E tests should be the least in number, and take the most amount of time to run.\nThe pyramid itself is one train of thought and a general idea. A team should investigate the solution to testing that best fits the needs of the application and the team.\nConclusion There are three ways to measure the amount of tests that have been written:\n Function Line Branch  The Testing Pyramid method says the majority of tests should be on the unit scope.\nIt isn\u0026rsquo;t the number of tests, but the level of reliability the tests can provide.\n"
},
{
	"uri": "/react/foundations/labs/lab-component-props/",
	"title": "Component Props",
	"tags": [],
	"description": "",
	"content": "Part 1: Create a React Application to display a list of Products Using create-react-app create a new application:\n Create a Stateless (presentational) component named Product The Product component should take 3 props  name price quantity   The Product component should render a div with the following inside it:  a paragraph showing the product name and price, with a call to action (i.e. Click here to purchase the hammer at $19.99). Don\u0026rsquo;t worry about making the click do anything, we will add that feature in a later lab. when the quantity is under 5 display an \u0026lt;h3\u0026gt; element notifying the user there only a handful of items left in stock i.e.: Only 2 left in stock! Act Fast!   Render 3 different products inside of the parent \u0026lt;App\u0026gt; component.  Here is some CSS to make it a bit prettier:\nbody { background-color: rgb(240, 240, 240); } button { background: #ff9030; font-size: 0.9rem; } .product { border: 1px solid orange; max-width: 600px; margin: 20px auto; } Here is a sample screenshot:\nExtra Credit\n Instead of passing 3 props for name, price, and quantity, pass just one prop, the product object that contains the name, price and quantity. Use an array of products in App.js and use Array.map to convert the products array into an array of JSX expressions.   Part 2 - Add To Cart Add the following to your App from Part 1:\n Write a function in your App component named addToCart. This function should console.log the name of an item and indicates that it has been added to the cart: i.e.: \u0026ldquo;we\u0026rsquo;ve added a Hammer to the cart!\u0026rdquo;. Pass that function down to your child \u0026lt;Product\u0026gt; components as a prop. When the user click \u0026rsquo;s on a specific item, it should invoke the addToCart function.   TIP: You can add a button inside the \u0026lt;p\u0026gt;, as in:\n \u0026lt;p\u0026gt;Click \u0026lt;button onClick={() =\u0026gt; addToCart(product)}\u0026gt;here\u0026lt;/button\u0026gt;to purchase the ...\u0026lt;/p\u0026gt;  Verify that it is working via the Chrome Dev Tools JavaScript console:\n Part 3 - Using React Dev Tools  Inspect your application using React Dev Tools. See if you can modify the data being displayed via React Dev Tools.  Part 4 - Add Prop Types Add React propTypes to your Product component to verify that the correct props are being passed in.\n"
},
{
	"uri": "/cloud/containers/developing-with-docker/int-testing/data-sources/",
	"title": "Containerizing Persistent Data Sources",
	"tags": [],
	"description": "",
	"content": "Concepts  List some purposes for containerizing data sources Explain how containerizing a data source helps with testing Write a Dockerfile to containerize a data source Use environment variables to configure a containerized data source Seed a database as part of a docker build Clean up data source volumes  Why Containerize a Data Source? Containerizing a Data Source is great for development and testing. The advantages include:\n There’s less clutter on your development machine You can work on multiple projects side by side, which may depend on different database versions You can create a development environment on any OS in a reliable fashion Everything is \u0026ldquo;documented\u0026rdquo; and reproducible through automation  What about Production? Remember that orchestration tools such as Docker and Kubernetes were created with the assumption that containers need to be stateless, which means that they should not save any internal data that needs to be persisted. Therefore, running a containerized data source in production is not recommended.\nIf you are running in a cloud environment, then it\u0026rsquo;s recommended to use the cloud provider\u0026rsquo;s offerings for data sources.\nA Quick Demo Okay, so let’s run a PostgreSQL database in a Docker container!\n$ docker run -d --name my-db -e POSTGRES_PASSWORD=secret -p 5555:5432 postgres What it does:\n pulls the postgres Docker image from Docker Hub sets the POSTGRES_PASSWORD environment variable value to secret names the Docker container to be my-db maps the container’s internal 5432 port to the external 5555 port runs the container in the background (-d)  Testing It Out To test our database, we can connect to it from our host:\n$ psql -U postgres -h localhost -p 5555 Password for user postgres: # enter the secret password here psql (12.3) Type \u0026#34;help\u0026#34; for help. postgres=# CREATE TABLE public.movies (id int PRIMARY KEY, title varchar(30), genre varchar(30)); CREATE TABLE postgres=# \\d List of relations Schema | Name | Type | Owner --------+--------+-------+---------- public | movies | table | postgres (1 row) postgres=# \\q Notice that we created our first table.\nWe can also connect to the database from inside the container:\n$ docker exec -it my-db bash # connect to the container root@c4dda026031e:/# psql -U postgres psql (12.3 (Debian 12.3-1.pgdg100+1)) Type \u0026#34;help\u0026#34; for help. postgres=# CREATE TABLE public.actors (id int PRIMARY KEY, firstName varchar(30), lastName varchar(30)); CREATE TABLE postgres=# \\d List of relations Schema | Name | Type | Owner --------+--------+-------+---------- public | actors | table | postgres public | movies | table | postgres (2 rows) postgres=# \\q root@c4dda026031e:/# exit exit Here we have created a second table and we can see that both tables now exist - the one created from the host connection and the other created from inside the container.\nShutdown and Delete the Container Now let\u0026rsquo;s stop and delete the container:\n$ docker stop my-db my-db $ docker rm my-db my-db Custom Database Images Question: How can we automate the creation of a Docker container running PostgreSQL with a database schema and seed data?\nAnswer: Create our own custom PostgreSQL Docker image using a Dockerfile and a SQL script\nThe Dockerfile Here is a Dockerfile for creating a custom Docker database image\nFROMpostgresENV POSTGRES_PASSWORD secretENV POSTGRES_DB movies-dbCOPY init.sql /docker-entrypoint-initdb.d/Here is what is happening in this Dockerfile:\n pull the postgres image set two environment variables: POSTGRES_PASSWORD and POSTGRES_DB (a list of all available variables in this image can be found in Docker Hub) copy an init.sql file to the /docker-entrypoint-initdb.d/ folder located in the postgres Docker image. By default all scripts located in this folder will automatically run during container startup.  Securing the Password NOTE: putting the POSTGRES_PASSWORD in the Dockerfile is not secure as the value will be part of the Docker image and is viewable to anyone who has the image.\nIf you want to secure the password, you will have to dynamically set an environment variable in the container. The official PostgreSQL Docker image has support for this, see: Official PostgreSQL Image | DockerHub.\nThe init.sql Script Next we need to create the init.sql file with the following contents:\nCREATE TABLE public.movies ( id int PRIMARY KEY, title varchar(30), genre varchar(30) ); Building the Custom Image To build the image:\n$ docker build -t my-custom-db . $ docker images # you should see `my-custom-db` in the list Starting the Container Great! Now let’s run it as a container:\n$ docker run -d --name my-custom-db-container -p 5555:5432 my-custom-db $ docker ps # you should see the container running Inserting Some Data Let\u0026rsquo;s insert some data and see if it persists after stopping and restarting the container.\n$ psql -U postgres -h localhost -p 5555 -d movies-db Password for user postgres: # enter your secret password psql (12.3) Type \u0026#34;help\u0026#34; for help. movies-db=# INSERT INTO public.movies (id, title, genre) VALUES (1, \u0026#39;Star Wars\u0026#39;, \u0026#39;SciFi\u0026#39;), (2, \u0026#39;Groundhog Day\u0026#39;, \u0026#39;Comedy\u0026#39;), (3, \u0026#39;Die Hard\u0026#39;, \u0026#39;Action\u0026#39;); INSERT 0 3 movies-db=# \\q Stop and Restart the Container $ docker container stop my-custom-db-container my-custom-db-container $ docker container start my-custom-db-container my-custom-db-container Now let\u0026rsquo;s see if our data is still there:\n$ psql -U postgres -h localhost -p 5555 -d movies-db Password for user postgres: psql (12.3) Type \u0026#34;help\u0026#34; for help. movies-db=# select * from movies; id | title | genre ----+---------------+-------- 1 | Star Wars | SciFi 2 | Groundhog Day | Comedy 3 | Die Hard | Action (3 rows) movies-db=# \\q The data is still there.\nBut\u0026hellip; what would happen if we used the docker run command instead of docker container start to re-run the container?\nWith docker run we create a new container from the image so all changes made in the previous container are not saved in the new one.\nTo persist the data we would need to use a Docker volume, for example:\n$ docker run -d --name my-custom-db-container -p 5555:5432 \\  -v postgres-volume:/var/lib/postgresql/data my-custom-db Summary In this lesson we learned that:\n Containerizing your data sources is great for development but not a good idea for production. You can create a custom database image that is prepopulated with your schema and seed data. You can use volumes to add persistence to your containerized data sources, but there are limitations, such as when a container may be restarted on a different node.  Resources  Database in a Docker container — how to start and what’s it about Official PostgreSQL Image | DockerHub  "
},
{
	"uri": "/application-security/api-security/01_service_to_service_oauth2/30_cryptography/",
	"title": "Cryptography 101",
	"tags": [],
	"description": "",
	"content": "Hey Gary is this license from you?\nThis is meant as a quick explanation for those unfamiliar with the basics of Cryptography.\nAsymmetric vs Symmetric Watch as a group: Symmetric vs Asymmetric encryption - Simply explained\nWith any Cryptography, you have to have a secret. There are two general styles:\n Symmetric - two parties both know the super secret word. Asymmetric - You have a key pair, a public key and a private key. The keys are mathematically connected only to each other.  Encrypting vs Signing Watch as a group: Digital Signatures Explained\n Encrypting is taking the value and hiding the contents. Signing is like a fancy notary, it is a way to validate the content. It just flips the order of the keys are used.  Encryption is Public Key first, then Private Key. Signing is Private Key first, then Public Key    Validate the Sender  I write a message and sign it with my private key and post the message, the signature, and the public key on my website. Everybody else in the world can take my public key and the signature and can use that to validate the message is actually from me.  Public Key vs Certificate A Public and Private Keys are just really large numbers. A certificate (or cert) is just an envelope that holds the public key along with tons of useful meta data. So be aware, if you are talking about the Public Key or the Cert. They are the same\u0026hellip; but different\u0026hellip;\nExamples of real Public Keys The following keys/certs are publish in the JWKS format.\n https://identity-qa.homedepot.com/pf/JWKS https://login.windows.net/common/discovery/keys  "
},
{
	"uri": "/software-eng-essentials/db-sql/schemas/",
	"title": "DB Schemas",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Describe the following:  Database Schema CRUD Table Row Column Primary Key    Skills  Create a database Create tables Read and explain an ERD diagram Create an ERD diagram  Database Schemas The set of database tables, sequences, indexes, and other objects that define the structure of a database.\nTables Relational Database tables consist of a set of rows and columns.\ncolumn: defines the datatype and constraints for a single piece of data (such as name, age, city, state, etc.) in a row.\nColumns:\n have a data type, such as string, integer, boolean, number can have constraints, such as minimum length, maximum value, non-null, etc.  row: a single data record\n each row has a special column called the Primary Key (PK) that uniquely identifies that row  the PK should have no business meaning (a best practice) PK values are usually generated by the database   a column can be defined to be a Foreign Key (FK) indicating that it is a reference to another row (usually in another table)  thus a FK contains the PK value of the target row this is what makes a database relational!    Example Schema From this sample schema for superhero supplies diagram:\nWe can infer the following tables schemas from this diagram:\ncustomers table:\n   Column Name Column Data Type     id integer serial PRIMARY KEY   first_name varchar(50)   last_name varchar(50)   email varchar(50)    orders table:\n   Column Name Column Data Type     id integer serial PRIMARY KEY   order_number integer   date_ordered date   prime boolean   customer_id integer references customers(id)    items_ordered table:\n   Column Name Column Data Type     id integer serial PRIMARY KEY   order_id integer references orders(id)   name varchar(50)   description varchar(200)   quantity integer    ERD Diagrams Entity-Relationship Diagrams (ERD) are a way to illustrate a relational database schema.\n Each table is represented by a rectangle The relationships between tables are represented by lines with a symbol to designate the many side(s) of the relationship. This symbol could be a crows foot, a diamond, or an asterisk.  ERD Symbols Entity:\nEntities are objects or concepts that represent important data. Entities are typically nouns such as product, customer, location, or promotion.\nAttribute:\nERD attributes are:\n characteristics of the entity that help users to better understand the database. included to include details of the various entities that are highlighted in a conceptual ER diagram. Primary Keys are in bold and underlined Foreign Keys are implied with the relationship lines, meaning there is no need to add a foreign key attribute to an entity  Relationship:\n|\nWithin entity-relationship diagrams, relationships are used to document the interaction between two entities.\nRelationships are usually verbs such as assign, associate, or track and provide useful information that could not be discerned with just the entity types.\nDifferent kinds of relationships are shown in different ways:\nOne-to-Many Relationships The most common kind of relationship is a one-to-many relationship. Here are some examples:\n A customer has many orders and each order belongs to one customer. Each order has many ordered_items and each ordered_item belongs to one order. An owner has many pets and each pet belongs to one owner.  Question For one-to-many relationships, should the FK be on the one side or the many side?\nAnswer: The FK should be on the many side pointing back to the one side.\n  The table schema would be set up like the following:\n  Individual order records would be related to the customers by the customer_id as the foreign key.\n  One-to-One Relationships Occasionally we may want a one-to-one relationship. Here are some examples:\n A customer has a shipping address and a shipping address belongs to a customer. An order has a delivery address.  One-to-one relationships can be represented by folding the two tables into one table but often having them split into two tables can provide easier readability, maintenance, and even improved performance when we only need to select one-side of the relationship.\nMany-To-Many Relationships Many-to-many relationships are required when each side of the relationship may relate to many rows on the other side. Here are some examples:\n A student has many classes and each class has many students. A doctor has many patients and each patient may have many doctors. A movie has many actors and each actor may have (starred in) many movies.  Question: For many-to-many relationships, where should all of those FKs go?\nAnswer: Relational databases do not directly support a many-to-many relationship.\nmapping or join tables are needed to hold all of the FKs needed by a many-to-many relationship.\nThe mapping table contains 2 FKs: one to each table in the many-to-many relationship.\nThis effectively combines two (physical) one-to-many relationships to form a (logical) many-to-many relationship.\nThis example ERD for a many-to-many relationship has orders that have many items and items that are in many orders.\nOrderItems are a mapping table that is created to will hold the primary keys of both tables as foreign keys. Combined with the unique ID (primary key) of each OrderItem, we are able to create distinct OrderItem records.\nThe schema for this relationship will look like the following:\nSummary  Relational databases organize data into tables with rows and columns. Rows have columns for the primary key, the data, and any needed foreign keys. Foreign keys can be used to define one-to-one, one-to-many, and many-to-many relationships. The structure of a database consisting of tables with columns, PKs, FKs, and indexes is collectively known as the database\u0026rsquo;s schema.  "
},
{
	"uri": "/javascript/express/express-intro/",
	"title": "Express: An Introduction",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Write a simple RESTful API with Express Identify the HTTP verbs and routes we\u0026rsquo;ll be using for an API Create an API with Express Interact with routes using cURL \u0026amp; httpie Monitor and automatically restart a Node app with nodemon  Web Servers, Web Applications, and Web Frameworks Web Server:\nA web server is a computer and/or a server application that listens for HTTP requests, processes them, and returns an HTTP response. The web server may delegate the processing of the HTTP request to a specific web application.\nWeb Application:\nA web application processes HTTP request messages and generates an appropriate response. The web application may be connected to databases or other servers for data persistence.\nWeb Framework:\nA web framework provides the infrastructure for building a typical web (HTTP) server application. Since most web server applications share common characteristics, the framework can assist us with implementing a solution with these characteristics.\nCommon Web Server Responsibilities:  rendering HTML pages connecting to a port listening for HTTP requests routing a request to a function that can process the request generating and returning an HTTP response error handling and reporting managing lots of connections security  What is Express.js? Express.js is a simple, yet powerful web framework for Node.js. We can use Express to build web server applications.\nTo get started with express, we\u0026rsquo;ll need to perform the following steps.\nmkdir express-practice # 1 cd express-practice # 2 npm init -y # 3 npm install express --save # 4 touch app.js # 5 This process should seem familiar, as we have used the same process to create many other applications.\n Create a directory for our project cd into the new directory Initialize the application (adding a package.json file) Install our dependencies (express in this case) Create a file to store our JS code.  If we take a moment to review the package.json file, we\u0026rsquo;ll see that express has been added as a dependency.\n\u0026#34;dependencies\u0026#34;: { \u0026#34;express\u0026#34;: \u0026#34;^4.17.1\u0026#34;, } Setting up a webserver with express only requires a few lines of code.\napp.js:\nimport express from \u0026#39;express\u0026#39; const app = express(); const port = process.env.PORT || 3000; // a simple route app.get(\u0026#39;/\u0026#39;, function(req, res) { res.status(200).json({message: \u0026#39;Hi!\u0026#39;}); }); app.listen(port); console.log(\u0026#39;Server started on \u0026#39; + port); We can start the app by running node app.js in the terminal.\nThen, we can open another terminal window and send a cURL request to http://localhost:3000/\ncurl http://localhost:3000 # or http localhost:3000  TIP: Alternatively, you can use httpie to issue a GET request to localhost:3000\n nodemon The problem:\n We can modify our Node or Express app however we would like. Unfortunately, we’ll need to restart the server after each change. This is due to the fact that our server needs the information on startup.  The solution:\n To avoid manually restarting our server over-and-over again, we can use the super handy nodemon package. Nodemon watches files for changes and automatically restarts our server.  Installation To install nodemon, we’ll stop the server and install the package as a local dependency.\n$ npm i --save-dev nodemon Basic Usage Use the nodemon command and pass your app as an argument.\n$ nodemon \u0026lt;my-app\u0026gt; Nodemon usage is as easy as this. There are more options available which you can find with the help flag -h.\n$ nodemon -h Adding a Start Script Next, we’ll add a start script for nodemon to our package.json file. Since we will only use nodemon when developing our application, we will follow a convention of naming the command dev.\npackage.json\n\u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34; : \u0026#34;node app.js\u0026#34;, \u0026#34;dev\u0026#34; : \u0026#34;NODE_ENV=development DEBUG=express-practice:* nodemon --inspect app.js\u0026#34; }, //... Now we have a start script that can be run with the command:\n$ npm run dev This will tell nodemon to run the app.js file. Each time we make a change, nodemon will handle restarting our server, allowing the changes to load.\nRouting in Express Now this is pretty awesome (isn\u0026rsquo;t it?) but it doesn\u0026rsquo;t really do anything. Plus, what if we want to start creating additional endpoints?\nThis is where routing comes in. Express gives us the ability to easily create useful endpoints for our applications.\nExpress offers several useful methods for building RESTful routes, for example:\n get put post patch delete  GET example Let\u0026rsquo;s look at the route we\u0026rsquo;ve declared in app.js again:\napp.js:\nimport express from \u0026#39;express\u0026#39; //1 const app = express(); //2 const port = process.env.PORT || 3000; //3  // a simple route app.get(\u0026#39;/\u0026#39;, function(req, res) { //4  res.status(200).json({message: \u0026#39;Hi!\u0026#39;}); //5 }); app.listen(port); //6 console.log(\u0026#39;Server started on \u0026#39; + port);  TIP: Routes in Express are created using methods named after HTTP verbs. In the example above, we created a route to respond to GET requests at the root of the app. You will have a corresponding method on the app object for all the HTTP verbs. In this example, we sent back a simple message as JSON.\n Adding a Second Route Let\u0026rsquo;s add another route to our Express app. This route will return a joke.\napp.get(\u0026#39;/joke\u0026#39;, function(req, res) { res.status(200).json({joke: \u0026#34;Three sql statements walked into a NoSQL bar. A little while later they walked out because they couldn\u0026#39;t find a table.\u0026#34;}); }); We can access this new joke route/endpoint by using cURL or httpie.\ncurl http://localhost:3000/joke # or http localhost:3000/joke POST example A simple post route might look like:\napp.post(\u0026#39;/users\u0026#39;, function (req, res) { res.status(200).json({message: \u0026#39;POST request is successful\u0026#39;}) }) This route would now handle all post requests sent to a users endpoint.\nYou can test it out with:\ncurl --request POST http://localhost:3000/users Parsing req.body To read any data a user sends in the body of the HTTP request while doing a POST, you need add the following to app.js:\napp.use(express.json()); app.use(express.urlencoded({ extended: false })); IMPORTANT: We need to add these lines before our routes as it is adding middleware to the Express request processing pipeline. The order of these lines defines the order that the pipeline steps are processed with each request.\nNow it is possible to create a route that prints out any data that was sent in the body:\napp.post(\u0026#39;/users\u0026#39;, function(req, res) { res.status(200).json({message: req.body}); }); Now if you were to place in the terminal:\ncurl --location --request POST \u0026#39;127.0.0.1:3000/users\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --data-raw \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;Sue\u0026#34;, \u0026#34;occupation\u0026#34;: \u0026#34;Software Engineer\u0026#34; }\u0026#39; You would get the following output:\n{ \u0026#34;name\u0026#34;: \u0026#34;Sue\u0026#34;, \u0026#34;occupation\u0026#34;: \u0026#34;Software Engineer\u0026#34; } Additional Resources The official express docs show different examples of request methods and different patterns and options for writing the routes.\n Routing in Express  LAB Class Directory Guided Lab\n"
},
{
	"uri": "/software-eng-essentials/git-pillars/filter/",
	"title": "Git Filter Branch",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Remove History Remove Dead Branches  Mistakes were made Say something private (like personal email or password) was accidentally committed. Even if this is deleted manually there will be a history of it in the log.\nThis information can be considered compromised since anyone who has cloned or forked the repo after it was pushed and before you cleaned the history has the data.\nThere is a very powerful command that can actually delete not just files but also the commits that a file contains so that no one could go back in history to find those files.\nIt is also very dangerous because\u0026hellip; it deletes all the commits of that file all the way back through history.\nfilter-branch This command creates a branch that filters the tree of all given filename in all commits in history.\ngit filter-branch --tree-filter 'rm -f filename.blah' -- --all\nThis can be very destructive as it will create new objects of every commit that contain the file to be removed.\nOnce again, try to avoid these issues by using best practice of running git status before adding and committing and looking over all files that will be added.\nBut why can\u0026rsquo;t we just delete the file?\nLet\u0026rsquo;s Explore Say a file called password.txt that has our password is accidentally committed, like so:\n$ git log --oneline 5baf350 (HEAD -\u0026gt; master) adds password on accident 5aeb81c adds some code 35a215e adds even more code $ cat password.txt p@$$w0rd1234 What if we just delete the file and add and commit the deletion?\n$ rm password.txt $ git add -A $ git commit -m \u0026#34;Removes password file\u0026#34; (master 2c36f6b) Removes password file 1 file changed, 1 deletion(-) delete mode 100644 password.txt $ git log --oneline 5baf350 (HEAD -\u0026gt; master) Removes password file 5baf350 adds password on accidental 5aeb81c adds some code 35a215e adds even more code Does this mean we can go ahead an push up to our remote now?\nWrong!\nA git reset --hard HEAD^ will move the head back to the previous commit. It is possible to checkout old commit SHA1 objects to inspect the contents or even create a new branch.\nFor example:\n$ git checkout 5baf350 Now our repo is ready for filter-branch:\n$ git filter-branch --tree-filter \u0026#39;rm -f password.txt\u0026#39; -- --all Rewrite 12312311ab1232b465784564 (4/4) (0 seconds passed, remaining 0 predicted) Ref \u0026#39;refs/heads/master\u0026#39; was rewritten git tells us which commits were rewritten and in the example above we see the original commits in the log and then the new commits below with a log after the filter-branch.\nCan you tell what is different between the two \u0026lsquo;adds password\u0026rsquo; commits?\nFilter-branch practice\n"
},
{
	"uri": "/software-eng-essentials/git-pillars/filter-lab/",
	"title": "Git Filter Branch Lab",
	"tags": [],
	"description": "",
	"content": "Scenario You are working on a team that is writing tests. A team member accidentally pushed private information onto GitHub.\nThe branch is not yet client facing branch but your teammate needs help clearing the history so that no one will be able to see the private information.\nSteps to help your teammate  Clone down the following repo. https://github.com/one-thd/om_labs_git-filter.git.  You may need to run git branch -v and then git fetch origin \u0026lt;branchname\u0026gt; to have access to remote branches   Inspect the commit trees to find where the secret (42) was inserted Run the command that will filter out the bad file from all Branches Devise a test that will prove that the bad file is gone from all commits Screen cap your proof and post in slack  Hints git Hint\ngit log --oneline to see all the commits with messages in a compact view\nTerminal Hint\ncat filename to view contents of file in terminal\nFilter Hint\ngit filter-branch --tree-filter 'rm -f filename.blah' — --all\nProof Hint\ngit checkout commitSHA1 to checkout the snapshot from that shaw to inspect contents\nScreencap Hint\nshift command 4 to allow your mouse to click and drag an area\n"
},
{
	"uri": "/software-eng-essentials/git-foundations/",
	"title": "Git Foundations",
	"tags": [],
	"description": "",
	"content": "Welcome to Git Foundations! Additional Resources  Git Cheat Sheet GitHub Glossary Git In-Depth on Rebasing A Primer on Git Using Branches Merge development to master Visualize Merge History with Git Log Graph VS Code - Git History Diff Atom - Git Diff  "
},
{
	"uri": "/software-eng-essentials/git-pillars/interactive-rebase/",
	"title": "Git Interactive Rebase",
	"tags": [],
	"description": "",
	"content": "Let\u0026rsquo;s clean up our messy history tree! We can actually combine and even get rid of commits of our choosing.\n Go to our rebase content if you need a rebase refresher?\n Interactive rebase Rebase can help clean a branch timeline than repeatedly merging into your main code (Production, master, whatever) in.\nInteractive rebase can actually re-order commits, edit commits, squash commits together, or completely delete commits.\nSay the log of a repo looks similar to:\n$ git log --oneline 5baf350 (HEAD -\u0026gt; master) Removes password file 5baf320 adds password on accident 5aeb81c adds some code 35a215e adds even more code To get rid of the top two commits, run git rebase -i HEAD~3 to rebase back 3 commits.\ngit rebase -i HEAD~3 Running this will open an editor, like vi or VS Code.\nIn the editor, it will have something like:\npick 5aeb81c adds some code pick 5baf320 adds password on accident pick 5baf350 Removes password file # Rebase 5baf350..5baf350 onto 5baf350 (9 commands) # # Commands: # p, pick = use commit # r, reword = use commit, but edit the commit message # e, edit = use commit, but stop for amending # s, squash = use commit, but meld into previous commit # f, fixup = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message # x, exec = run command (the rest of the line) using shell # d, drop = remove commit Notice that two commits that are commented out. Git lists all of the available actions of interactive rebase in the provided comments.\nTo remove the unwanted commits from our history, update the word pick to drop next to the unwanted commits:\npick 5aeb81c adds some code drop 5baf320 adds password on accident drop 5baf350 Removes password file Then save and close your editor and the rebase will continue.\nOnce back in the terminal run git log --oneline again.\nThe terminal will now look something similar to:\n$ git log --oneline 5baf350 (HEAD -\u0026gt; master) Removes password file 5baf350 adds password on accident 5aeb81c adds some code 35a215e adds even more code $ git rebase -i HEAD~3 $ git log --oneline 5baf350 (HEAD -\u0026gt; master) Removes password file 5aeb81c adds some code 35a215e adds even more code Notice the unwanted commits are now gone.\n"
},
{
	"uri": "/software-eng-essentials/git-foundations/history/",
	"title": "History",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Why use a system of version control History of version control How it makes life better How it could make life worse     To get the idea of why we use version control, go to why version control? activity    Version Control In the beginning computers were reprogrammed by literally rewiring them. In those days there could only be one version of a program on a machine at a time.\nOnce programming languages were introduced, issues started to come up when teams would work on code together. The need grew for a better way to collaborate.\nA version control system (VCS) makes collaborating easier by:\n allowing engineers to creating a copy of the current code and make incremental changes in a safe environment. Once the code is ready, it can be integrated into the primary code base. keeping track of who has been working on a specific feature or bug fix which allows the entire team to easily communicate and understand the changes that are being proposed.  Types of Version Control  Centralized- Master copy on a server: Client-Server concept where Master Repository is only on a central server. Distributed- User can clone the repository master to their local machine. Several copies of Master Repository in existence.     Group Activity to compare: Centralized and Distributed Version Control    Examples of Version Control  Centralized (client-server model)  CVS Subversion VSS, TFS, Vault ClearCase AccuRev   Distributed  Git Mercurial Bazzar Perforce BitKeeper    Time to finally git it! Git is the current industry standard for version control. It was originally developed in 2005 by the creator of the Linux operating system, Linus Torvalds.\n Link to n interview with Linus Torvalds\n Git design goals  Speed Simple design Strong support for thousands of parallel branches Fully distributed  full local repository offline commits full size repository   Able to handle large projects like Linux kernel effectively Ensures integrity Open source  The Home Depot uses Git because of these advantages.\n"
},
{
	"uri": "/cloud/containers/docker-fundamentals/how-docker-works/",
	"title": "How Docker Works",
	"tags": [],
	"description": "",
	"content": "Objectives  Understand the difference between Images vs Containers Using Basic Docker Commands  Images vs Containers In Docker, there are images and there are containers. The two are closely related, but distinct. Grasping this dichotomy will help with understanding Docker immensely.\n  In summary:\n Images are templates for creating application containers Containers are instances of images and can be running or stopped  Images Images are:\n an inert, immutable, file that\u0026rsquo;s essentially a snapshot of a container created with the build command produce a container when started with run stored locally or in a Docker registry like Dockerhub or even in our THD Artifactory server.  All local images can be listed by running docker images or docker image ls:\n~ ○ → docker images REPOSITORY TAG IMAGE ID CREATED SIZE python 3.6 1f88553e8143 3 weeks ago 850MB python latest 1f88553e8143 3 weeks ago 933MB jupyter/base-notebook latest c207e7de43e4 7 weeks ago 591MB ubuntu 13.10 5e019ab7bf6d 2 months ago 180 MB concourse/concourse latest 494a89149d14 20 months ago 531MB Some things to note  IMAGE ID is the first 12 characters of the true identifier for an image. You can create many tags of a given image, but their IDs will all be the same (as above). VIRTUAL SIZE is virtual because it\u0026rsquo;s adding up the sizes of all the distinct underlying layers. This means that the sum of all the values in that column is probably much larger than the disk space used by all of those images. The value in the REPOSITORY column comes from the -t flag of the docker build command, or from docker tagging an existing image. You\u0026rsquo;re free to tag images using a nomenclature that makes sense to you, but know that docker will use the tag as the registry location in a docker push or docker pull. The TAG column is just the [:TAG] part of the full tag. The latest tag is not magical, it\u0026rsquo;s simply the default tag when you don\u0026rsquo;t specify a tag. You can have untagged images only identifiable by their IMAGE IDs. These will get the \u0026lt;none\u0026gt; TAG and REPOSITORY. It\u0026rsquo;s easy to forget about them.  Containers Containers are lightweight and portable running instances of an image. Containers \u0026ldquo;contain\u0026rdquo; a running application. Multiple containers can be made from the same image. Most Docker images include the supporting files and processes for a full operating system although some images may include a very minimal OS to reduce the container\u0026rsquo;s runtime footprint and speed up the starting and stopping of the container.\nThe Docker docs definition of a container can be found here\nAll local running containers can be listed by running docker ps or docker container ls:\n~ ○ → docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 354ab39cd6cf python:latest \u0026#34;/bin/bash\u0026#34; 16 minutes ago Up 9 minutes condescending_wilson 030b6ba054bc jupyter/base-notebook:latest \u0026#34;tini -g -- /bin/bash\u0026#34; 6 days ago Up 27 minutes 8888/tcp jupyter_terminal c6a35f05b38d jupyter/base-notebook:latest \u0026#34;tini -g -- start-no…\u0026#34; 6 days ago Up 27 minutes 0.0.0.0:8888-\u0026gt;8888/tcp jupyter_web Some things to note:  IMAGE ID, CONTAINER ID is the true identifier for the container. It has the same form, but it identifies a different kind of object. docker ps only outputs running containers. You can view all containers (running or stopped) with docker ps -a. The COMMAND is the command you want Docker to run when the container is started. Unless specified at the docker run|exec stage, the COMMAND is usually provided when an image is pulled from a repository. NAMES can be used to identify a started container via the --name flag.  To use a programming metaphor, if an image is like a class, then a container is an instance of a class — a runtime object.\nDocker CLI Commands Docker CLI management commands:\n have the format docker mgmt_category subcommand.  For example: docker container stop will stop a container.   that refer to a specific container or image require either the name or the id of that container or image.  For example: docker run --name my_app python:latest builds and runs a container using the python:latest image.    Common Docker Commands    Docker Command Description     docker attach Attaches your local input/output/error stream to a running container   docker build Build an image from a Dockerfile   docker create Creates a new image, if the image isn\u0026rsquo;t already stored locally this will retrieve the image from Docker Hub, if it exist   docker exec Runs a command in a container that is active or running   docker history Displays the history of an image   docker info Shows system-wide information   docker inspect Finds system-level information about docker containers and images   docker login Logins to local registry or Docker Hub   docker ps Lists running containers   docker restart Stops and starts a container   docker rm Remove containers   docker rmi Remove images   docker run Create and runs an isolated container with specified image   docker search Searches the Docker Hub for images   docker start Starts already stopped containers   docker stop Stops running containers   docker version Provides docker version information    Flags When containers are created, flags or [OPTIONS] are use to set or enable certain attributes within a container. Flags always come after the docker command.\nA flag may have two dashes in front for the full name of the flag or a single dash for the short name. For example, -p is short for the --port flag.\nCommon Docker Flags    Flag Description     --detach, -d Run container in background and print container ID   --mount Attach a filesystem mount to the container   --name Names the container   --network or --net Connect the container to a network   --read-only Mount the container’s root filesystem as read only   --rm Automatically remove container when it exits    The --help command option Applying --help to the end of any command will show all options available for that command in the terminal.\nExamples:\ndocker --help docker run --help docker start --help Lab: Hello World Let\u0026rsquo;s get our fingers busy and start up a container. Open your terminal and do the following steps:\n Run the following command: docker run hello-world List out all your containers Delete the new container Redo this process, except this time give the container a name and delete it by name  Lab: More Fun with Docker  Try the commands below to start containers. Use 2 terminal windows so that you can list the running container in the second terminal session.  # run a docker container that prints a hello message and then exits. docker run hello-world # run an ubuntu container running a bash shell and attach to it docker run -it ubuntu bash # once in the container, try the following to install vim # apt-get update \u0026amp;\u0026amp; apt-get install vim # run a container with an nginx HTTP server docker run --name simple-nginx -p 8080:80 -d nginx # test it by pointing your browser to http://localhost:8080 Lab: 3 Ways to be Interactive Below are 3 ways to start a container and attach to it with an interactive shell. Try each way and study the commands to understand what each command is doing.\ndocker create --name whatup ubuntu sleep 1d docker start whatup docker exec -it whatup bash # exit out of bash shell here docker stop whatup docker rm whatup docker run -d --name whatup ubuntu sleep 1d docker exec -it whatup bash # exit out of bash shell here docker stop whatup docker rm whatup docker run --rm -it --name whatup ubuntu bash # exit out of bash shell here docker rm whatup Summary In this lesson we introduced the core concepts of Docker, images and containers, and learned how to download images, create containers from images, and start and stop containers. We also learned how to remove stopped containers and how to remove images. But this is just the beginning of what Docker can do. Continue with the curriculum to learn more about Docker.\nResources  The Docker documentation has an excellent quick start guide at Docker Overview.  "
},
{
	"uri": "/software-eng-essentials/command-line-bash/inspecting-files/",
	"title": "Inspecting Files",
	"tags": [],
	"description": "",
	"content": "Objectives  Downloading a file Heads or Tails Less is more Grepping  Downloading A File To start we\u0026rsquo;ll download a file from the Internet using the powerful curl utility (sometimes written as \u0026ldquo;cURL\u0026rdquo;), which allows us to interact with a URL at the command line. Although it\u0026rsquo;s not part of the core Unix command set, the curl command is widely available on Unix systems. To make sure it\u0026rsquo;s available on your system, we can use the which command, which looks to see if the given program is available at the command line. The way to use it is to type which followed by the name of the program—in this case, curl:\n$ which curl /usr/bin/curl I\u0026rsquo;ve shown the output on my system (/usr/bin/curl, usually read as \u0026ldquo;user bin curl\u0026rdquo;), but the result on your system may differ. In particular, if the result is just a blank line, you will have to install curl.\nOnce curl is installed, we can download a file called pg16328.txt (a copy of the epic Beowulf) containing a large body of text using the command below.\nUsing curl to download a longer file.\n$ curl -OL http://www.gutenberg.org/cache/epub/16328/pg16328.txt $ mv pg16328.txt beowulf_complete.txt $ ls -rtl Be sure to copy the command exactly; note that the option -OL contains a capital letter \u0026ldquo;O\u0026rdquo; (O) and not a zero (0). (Figuring out what these options do is left as an exercise.) Also, on some systems you might have to run the command twice to get it to work; by inspecting the results of ls -rtl, you should be able to tell if the initial call to curl created the file pg16328.txt as expected. (If you do have to repeat the curl command, you could press ↑ twice to retrieve it.)\n We used the mv command to rename the file after downloading it.\n The result of running the above command is beowulf_complete.txt, a file containing every line of Beowulf plus frontmatter. This file contains 7,004 lines, far too many to fit on one screen. Learning how to inspect its contents is the goal of the rest of this section. (Among other things, we\u0026rsquo;ll learn how to determine that it has 7,004 lines without counting them all by hand.)\nRepeating previous commands\nRepeating previous commands is a frequent task when using the command line. So far in this course, we\u0026rsquo;ve used the up-arrow key to retrieve (and possibly edit) previous commands, but this isn\u0026rsquo;t the only possibility. An even quicker way to find and immediately run a previous command involves using the exclamation point !, which in the context of software development is usually pronounced \u0026ldquo;bang\u0026rdquo;. To run the previous command exactly as written, we can use \u0026ldquo;bang bang\u0026rdquo;:\n$ echo \u0026#34;foo\u0026#34; foo $ !! echo \u0026#34;foo\u0026#34; foo A closely related usage is \u0026ldquo;bang\u0026rdquo; followed by some number of characters, which runs the last command that started with those characters. For example, to run the last curl command, we could type this:\n$ !curl This would save us the trouble of typing out the options, the URL, etc. Depending on our history of commands, the even terser !cu or !c would work as well. This technique is especially useful when the desired command last happened many commands ago, which can make hitting up arrow cumbersome.\nA second and incredibly powerful technique is ⌃R, which lets you search interactively through your previous commands, and then optionally edit the result before executing. For example, we could try this to bring up the last curl command:\n$ \u0026lt;⌃R\u0026gt; (reverse-i-search)`\u0026#39;: curl On most systems, hitting return would then put the last curl command after our prompt and allow us to edit it (if desired) before hitting return to execute it. When your workflow happens to involve repeatedly running a variety of similar commands, sometimes it can seem like \u0026ldquo;all commands start with ⌃R.\u0026rdquo;\nExercises\n Use the command curl -I https://www.homedepot.com/ to fetch the HTTP header for the Home Depot website. What is the HTTP status code for the address? How does this differ from the status code for homedepot.com (without the https)? Using ls, confirm that beowulf_complete.txt exists on your system. How big is it in bytes?  Hint: Recall from the Manipulating Files lesson that the \u0026ldquo;long form\u0026rdquo; of ls displays a byte count.   The byte count in the previous exercise is high enough that it\u0026rsquo;s more naturally thought of in kilobytes (often treated as 1000 bytes, but actually equal to 2^10 = 1024 bytes). By adding -h (\u0026ldquo;human-readable\u0026rdquo;) option to ls, list the long form of the Beowulf file with a human-readable byte count. Suppose you wanted to list the files and directories using human-readable byte counts, all, by reverse time-sorted long-form. What command would you use?  Heads or Tails Two complementary commands for inspecting files are head and tail, which respectively allow us to view the beginning (head) and end (tail) of the file. The head command shows the first 10 lines of the file.\n$ head beowulf_complete.txt The Project Gutenberg EBook of Beowulf This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.net Title: Beowulf An Anglo-Saxon Epic Poem, Translated From The Heyne-Socin Similarly, tail shows the last 10 lines of the file.\n$ tail beowulf_complete.txt Most people start at our Web site which has the main PG search facility: http://www.gutenberg.net This Web site includes information about Project Gutenberg-tm, including how to make donations to the Project Gutenberg Literary Archive Foundation, how to help produce our new eBooks, and how to subscribe to our email newsletter to hear about new eBooks. These two commands are useful when (as is often the case) you know for sure you only need to inspect the beginning or end of a file.\nWordcount and Pipes It is not important to know how many lines head and tail show by default. Since there are only 10 lines in the output, we could have counted them by hand, but in fact we would able to figure it out using the wc command (short for \u0026ldquo;wordcount\u0026rdquo;).\nThe most common use of wc is on full files. For example, we can run beowulf_complete.txt through wc:\n$ wc beowulf_complete.txt 7004 42706 301063 beowulf_complete.txt Here the three numbers indicate how many lines, words, and bytes there are in the file, so there are 2620 lines (thereby fulfilling the promise made at the end of Downloading a file), 17670 words, and 95635 bytes.\nYou are now in a position to be able to guess one method for determining how many lines are in head beowulf.txt. In particular, we can combine head with the redirect operator Redirecting and appending to make a file with the relevant contents, and then run wc on it, as shown in below.\nRedirecting head and running wc on the result\n$ head beowulf_complete.txt \u0026gt; beowulf_head.txt $ wc beowulf_head.txt 10 60 385 beowulf_head.txt We see from the above example that there are 10 lines in head wc (along with 46 words and 294 bytes). The same method, of course, would work for tail.\nOn the other hand, you might get the feeling that it\u0026rsquo;s a little unclean to make an intermediate file just to run wc on it, and indeed there\u0026rsquo;s a way to avoid it using a technique called pipes. The example below shows how to do it.\nPiping the result of head through wc.\n$ head beowulf_complete.txt | wc 10 60 385 The command from the above example runs head beowulf.txt and then pipes the result through wc using the pipe symbol | (Shift-backslash on most QWERTY keyboards). The reason this works is that the wc command, in addition to taking a filename as an argument, can (like many Unix programs) take input from \u0026ldquo;standard in\u0026rdquo; (compare to \u0026ldquo;standard out\u0026rdquo; mentioned in Standard streams), which in this case is the output of head beowulf.txt. The wc program takes this input and counts it the same way it counts a file, yielding the same line, word, and byte counts.\nExercises\n Pipe the results of tail beowulf_complete.txt through wc, and confirm that the tail command outputs 10 lines by default. By running man head, learn how to look at the first n lines of the file. By experimenting with different values of n, find a head command to print out just enough lines to display the first lines of frontmatter for Beowulf ending with the line \u0026ldquo;with this eBook or online at www.gutenberg.net.\u0026rdquo; Pipe the results of the previous exercise through tail (with the appropriate options) to print out only the 3 lines that give us permission to use the ebook.  Hint: The lines beginning with \u0026ldquo;This eBook is for the use of anyone\u0026rdquo;. Hint-deuce: The command will look something like head -n \u0026lt;x\u0026gt; beowulf_complete.txt | tail -n \u0026lt;y\u0026gt;, where \u0026lt;x\u0026gt; and \u0026lt;y\u0026gt; represent the numerical arguments to the -n option.   To simulate the creation of a log file, run ping homedepot.com \u0026gt; homedepot.log in one terminal tab. (The ping command \u0026ldquo;pings\u0026rdquo; a server to see if it\u0026rsquo;s working.) In a second tab, type the command to tail the log file. (At this point, both tabs will be stuck, so once you\u0026rsquo;ve gotten the idea of tail -f you should use the technique from the the lesson on Getting out of trouble.)   One of the most useful applications of tail is running tail -f to view a file that\u0026rsquo;s actively changing. This is common when monitoring files used to log the activity of, e.g., web servers, a practice known as \u0026ldquo;tailing the log file\u0026rdquo;.\n less Is More Unix provides two utilities for the common task of wanting to look at more than just the head or tail of a file. The older of these programs is called more, but there\u0026rsquo;s a more powerful variant called less. The less program is interactive, but here\u0026rsquo;s approximately what it looks like:\nRunning less on beowulf_complete.txt\n$ less beowulf_complete.txt \u0026lt;U+FEFF\u0026gt;The Project Gutenberg EBook of Beowulf This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.net Title: Beowulf An Anglo-Saxon Epic Poem, Translated From The Heyne-Socin Text by Lesslie Hall Author: Release Date: July 19, 2005 [EBook #16328] Language: English *** START OF THIS PROJECT GUTENBERG EBOOK BEOWULF *** Produced by David Starner, Dainis Millers and the Online Distributed Proofreading Team at http://www.pgdp.net beowulf_complete.txt The last line is the file name\nThe point of less is that it lets you navigate through the file in several useful ways, such as moving one line up or down with the arrow keys, pressing space bar to move a page down, pressing ⌃f to move forward a page (i.e., the same as spacebar) or ⌃b to move back a page. To quit less, type q (for \u0026ldquo;quit\u0026rdquo;).\nPerhaps the most powerful aspect of less is the forward slash key /, which lets you search through the file from beginning to end. For example, suppose we wanted to search through beowulf.txt for \u0026ldquo;carle\u0026rdquo; one of the most frequently used images in Beowulf. The way to do this in less is to type /carle.\nThe result of pressing return after typing /carle is to highlight the first occurrence of \u0026ldquo;carle\u0026rdquo; in the file. You can then press n to navigate to the next match, or n to navigate to the previous match.\nThe last two essential less commands are ⇧g (shift + g) to move to the end of the file and g to move back to the beginning. The table below summarizes what are in my view the most important key combinations, but if you\u0026rsquo;re curious you can find a longer list of commands at the Wikipedia page on less.\nI encourage you to get in the habit of using less as your go-to utility for looking at the contents of a file. The skills you develop have other applications as well; for example, the man pages (see the Basics lesson) use the same interface as less, so by learning about less you\u0026rsquo;ll get better at navigating the man pages as well.\nThe most important less commands.\n   Command Description Example     ↑ \u0026amp; ↓ Move up or down one line    space Moving forward one page    ^f Moving forward one page    ^b Move back one page    ⇧g Move to end of file    g Move to the beginning of file    /\u0026lt;string\u0026gt; Search file for string /carle   n Move to next search result    N Move to previous search result    q Quit less     Exercises\n Run less on beowulf_complete.txt. Go down three pages and then back up three pages. Go to the end of the file, then to the beginning, then quit. Search for the string \u0026ldquo;All\u0026rdquo; (case-sensitive). Go forward a few occurrences, then back a few occurrences. Then go to the beginning of the file and count the occurrences by searching forward until you hit the end. Compare your count to the result of running grep All beowulf_complete.txt | wc. (We\u0026rsquo;ll learn about grep in the next section.) Using less and / (\u0026ldquo;slash\u0026rdquo;), find the line of Beowulf that begins with the line \u0026ldquo;Weary from travel\u0026rdquo;. Are there any other occurrences of this string in Beowulf?  Hint: Press n to find the next occurrence (if any).   Because man uses less, we are now in a position to search man pages interactively. By searching for the string \u0026ldquo;sort\u0026rdquo; in the man page for ls, discover the option to sort files by size. What is the command to display the long form of files sorted so the largest files appear at the bottom?  Hint: Use ls -rtl as a model.    Grepping One of the most powerful tools for inspecting file contents is grep, which probably stands for something, but it\u0026rsquo;s not important what. (We\u0026rsquo;ll actually mention it in a moment.) Indeed, grep is frequently used as a verb, as in \u0026ldquo;You should totally grep that file.\u0026rdquo;\n Grep stands for Global regular expression print.\n The most common use of grep is just to search for a substring in a file. For example, we saw in the last section how to use less to search for the string \u0026ldquo;carle\u0026rdquo; in Beowulf. Using grep, we can find the references directly, as shown below.\nFinding the occurrences of \u0026ldquo;carle\u0026rdquo; in Beowulf.\n$ grep carle beowulf.txt With the command above, it appears that we are in a position to count the number of lines containing references to the word \u0026ldquo;carle\u0026rdquo; by piping to wc, as shown below.\nPiping the results of grep to wc.\n$ grep carle beowulf.txt | wc This tells us that 10 lines contain \u0026ldquo;carle\u0026rdquo; (and potentially any substring like \u0026ldquo;carles\u0026rdquo;). But you may recall from that Beowulf\u0026rsquo;s first page contains \u0026ldquo;Carle\u0026rdquo; with a capital \u0026ldquo;C\u0026rdquo;.\nReferring to the example of running $ grep Carle beowulf.txt, we see that this line has in fact been missed. This is because grep is case-sensitive by default, and \u0026ldquo;carle\u0026rdquo; doesn\u0026rsquo;t match \u0026ldquo;Carle\u0026rdquo;.\nAs you might suspect, grep has an option to perform case-insensitive matching as well.\nOne way to figure it out is to search through the man page for grep:\n Type man grep Type /case and then return Read off the result  (As noted briefly in the less is More lesson, the man pages use the same interface as the less command, so we can search through them using /.)\nApplying the result of the above procedure yields the code example below.\nComparing the results of below with that of the above, we see that we now have 12 matching lines instead of only 10, so there must be a total of 12 − 10 = 2 lines containing \u0026ldquo;Carle\u0026rdquo; (but not \u0026ldquo;carle\u0026rdquo;) in the Beowulf.\nDoing a case-insensitive grep.\n$ grep -i carle beowulf.txt | wc The grep utility gets its name from a pattern-matching system called regular expressions (also called regexes for short): grep stands for \u0026ldquo;globally search a regular expression and print.\u0026rdquo; A full treatment of regular expressions is well beyond the scope of this course, but before moving on we\u0026rsquo;ll sample just a small taste.\nAs one simple example, let\u0026rsquo;s match every line in beowulf.txt that has a word beginning with the letters \u0026ldquo;ca\u0026rdquo;, followed by any number of (lower-case) letters, and ending in \u0026ldquo;s\u0026rdquo;. The way to represent \u0026ldquo;any letter\u0026rdquo; with a regular expression is [a-z], and following a pattern with an asterisk * matches \u0026ldquo;zero or more\u0026rdquo; of that thing. Thus, ca[a-z]*r matches \u0026ldquo;ca\u0026rdquo; and \u0026ldquo;r\u0026rdquo; with one or more letters in between.\nWe can add spaces to the beginning and end to ensure that the match consists of contiguous words, like this:\n$ grep \u0026#39; ca[a-z]*r \u0026#39; beowulf.txt We can see that the regular expression matches additional strings.\nIn general, one of the best tool for learning how to use regexes is an online regex builder, such as regex101, which lets you build up regexes interactively. Unfortunately, grep often doesn't support the precise format used by regex builders (including hard-to-guess requirements for \u0026ldquo;escaping out\u0026rdquo; special characters), and precision in regular expressions is everything.\nAs a result, despite its name-origins, the truth is I rarely use the regular expression capabilities of grep. By the time the situation calls for regexes, I'm far likelier to reach for a text editor or a full-strength programming language.\nNevertheless, the aspects of grep discussed in this section are useful, covering a huge number of common cases (including the important application of grepping processes). We'll see one final grep variant in the next lesson Directories.\nGrepping Processes Grepping Processes\nOne of the many uses of grep is filtering the Unix process list for running programs that match a particular string. (On Unix-like systems such as Linux and macOS, user and system tasks each take place within a well-defined container called a process.) This is especially useful when there\u0026rsquo;s a rogue process on your system that needs to be killed. (A good way to find such processes is by running the top command, which shows the processes consuming the most resources.)\nFor example, you may need to eliminate a program called spring from the process list. To do this, first the processes need to be found, and the way to see all the processes on your system is to use the ps command with the aux options:\n$ ps aux ps is short for \u0026ldquo;process status\u0026rdquo;. And for confusing and obscure reasons, options to ps aren\u0026rsquo;t written with a dash (so it\u0026rsquo;s ps aux instead of ps -aux).\nTo filter the processes by program name, you pipe the results of ps through the grep:\n$ ps aux | grep spring ubuntu 12241 0.3 0.5 589960 178416 ? Ssl Sep20 1:46 spring app | my_app | started 7 hours ago The result shown gives some details about the process, but the most important thing is the first number, which is the process id, or pid. To eliminate an unwanted process, we use the kill command to issue the Unix terminate code (which happens to be 15) to the pid:\n$ kill -15 12241 This is a technique that can be recommended for killing individual processes, such as a rogue web server (with the pid found via ps aux | grep server), but sometimes it\u0026rsquo;s convenient to kill all the processes matching a particular process name, such as when you want to kill all the spring processes gunking up your system. In this case, you can kill all the processes with name spring using the pkill command as follows:\n$ pkill -15 -f spring  When something isn\u0026rsquo;t behaving as expected, or a process appears to be frozen, it\u0026rsquo;s a good idea to do this sequence:\n Run top or ps aux to see what\u0026rsquo;s going on. Pipe ps aux through grep to select the suspected processes. Run kill -15 \u0026lt;pid\u0026gt; or pkill -15 -f \u0026lt;name\u0026gt; to clear things up.   Exercises\n By searching man grep for \u0026ldquo;line number\u0026rdquo;, construct a command to find the line numbers in beowulf_complete.txt where the string \u0026ldquo;carle\u0026rdquo; appears. You should find that the last occurrences of \u0026ldquo;carle\u0026rdquo; is (via \u0026ldquo;carles\u0026rdquo;) on line 3883. Figure out how to go directly to this line when running less beowulf_complete.txt.  Hint: Recall from link:./inspecting-files#less_is_more[Less is more] that 1G goes to the top of the file, i.e., line 1. Similarly, 16G goes to line 16. Etc.   By piping the output of grep to head, print out the first (and only the first) line in beowulf_complete.txt containing \u0026ldquo;carle\u0026rdquo;.  Hint: Use the result of the second exercise in the second section of this lesson (Heads or Tails).   We saw two additional lines that case-insensitively matched \u0026ldquo;carle\u0026rdquo;. Execute a command confirming that both of the lines contain the string \u0026ldquo;Carle\u0026rdquo; (and not, e.g., \u0026ldquo;cArle\u0026rdquo;).  Hint: Use a case-sensitive grep for \u0026ldquo;Carle\u0026rdquo;.   You should find in the previous exercise that there are three lines matching \u0026ldquo;Carle\u0026rdquo; instead of the two you might have expected. This is because there is one line that contains both \u0026ldquo;Carle\u0026rdquo; and \u0026ldquo;carle\u0026rdquo;, and thus shows up in both grep carle and grep -i carle. Write a command confirming that the number of lines matching \u0026ldquo;Carle\u0026rdquo; but not matching \u0026ldquo;carle\u0026rdquo; is equal to the expected 2.  Hint: Pipe the result of grep to grep -v, and then pipe that result to wc. (What does -v do? Read the man page for grep.)    Summary Here are some important commands from this lesson summarized below.\nImportant commands from Inspecting Files lesson.\n|Command |Description |Example |:\u0026ndash;:|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;|:_\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- |curl |Interact with URLs |$ curl -O example.com |which |Locate a program on the path |$ which curl |head \u0026lt;file\u0026gt; |Display first part of file\t|$ head foo |tail \u0026lt;file\u0026gt; |Display last part of file\t|$ tail bar |wc \u0026lt;file\u0026gt; |Count lines, words, bytes\t|$ wc foo |cmd1 \\| cmd2 |Pipe cmd1 to cmd2 |$ head foo \\| wc |ping \u0026lt;url\u0026gt; |Ping a server URL\t|$ ping google.com |less \u0026lt;file\u0026gt; |View file contents interactively\t|$ less foo |grep \u0026lt;string\u0026gt; \u0026lt;file\u0026gt; |Find string in file\t|$ grep foo bar.txt |grep -i \u0026lt;string\u0026gt; \u0026lt;file\u0026gt; |Find case-insensitively\t|$ grep -i foo bar.txt |ps |Show processes\t|$ ps aux |top |Show processes (sorted)\t|$ top |kill -\u0026lt;level\u0026gt; \u0026lt;pid\u0026gt; |Kill a process\t|$ kill -15 24601 |pkill -\u0026lt;level\u0026gt; -f \u0026lt;name\u0026gt; |Kill matching processes\t|$ pkill -15 -f spring\nExercises\n The history command prints the history of commands in a particular terminal shell (subject to some limit, which is typically large). Pipe history to less to examine your command history.  What was your 13th command?   By piping the output of history to wc, count how many commands you\u0026rsquo;ve executed so far. One use of history is to grep your commands to find useful ones you\u0026rsquo;ve used before, with each command preceded by the corresponding number in the command history. By piping the output of history to grep, determine the number for the last occurrence of curl. We learned about !! (\u0026ldquo;bang bang\u0026rdquo;) to execute the previous command. Similarly, !n executes command number n, so that, e.g., !18 executes the 18th command in the command history. Use the result from the previous exercise to re-run the last occurrence of curl. What do the O and L options in the link:./inspecting-files#downloading_a_file[Downloading a file] lesson mean?  Hint: Pipe the output of curl -h to less and search first for the string -O and then for the string -L.     The O and -O used in the last exercise both use the capital \u0026ldquo;O\u0026rdquo;.\n "
},
{
	"uri": "/python/web-framework/django_db_api/",
	"title": "Interacting with the API",
	"tags": [],
	"description": "",
	"content": "Now, let’s hop into the interactive Python shell and play around with the free API Django gives you. To invoke the Python shell, use this command:\n$ python manage.py shell We’re using this instead of simply typing “python”, because manage.py sets the DJANGO\\_SETTINGS\\_MODULE environment variable, which gives Django the Python import path to your store_finder/settingm.py file.\nOnce you’re in the shell, explore the database API:\n If you did not migrate your models you will not be able to use them in Django API\n \u0026gt;\u0026gt;\u0026gt; from locations.models import Store, Market # Import the model classes we just wrote. # No markets are in the system yet. \u0026gt;\u0026gt;\u0026gt; Market.objects.all() \u0026lt;QuerySet []\u0026gt; # Create a new Market. \u0026gt;\u0026gt;\u0026gt; market1 = Market(name=\u0026#34;ATN\u0026#34;, number=1, num_stores=30) # Save the object into the database. You have to call save() explicitly. \u0026gt;\u0026gt;\u0026gt; market1.save() # Now it has an ID. \u0026gt;\u0026gt;\u0026gt; market1.id 1 # Access model field values via Python attributem. \u0026gt;\u0026gt;\u0026gt; market1.name \u0026#34;ATN\u0026#34; \u0026gt;\u0026gt;\u0026gt; market1.num_stores 30 # Change values by changing the attributes, then calling save(). \u0026gt;\u0026gt;\u0026gt; market1.name = \u0026#34;Austin\u0026#34; \u0026gt;\u0026gt;\u0026gt; market1.save() # objects.all() displays all the markets in the database. \u0026gt;\u0026gt;\u0026gt; Market.objects.all() \u0026lt; QuerySet [\u0026lt;Market: Market object (1)\u0026gt;]\u0026gt; \u0026gt;\u0026gt;\u0026gt; exit() \u0026lt;Market: Market object (1)\u0026gt; isn’t a helpful representation of this object. Fix this by editing the Market model (in the locations/models.py file) and adding a **_ _str_ _()** method to both Market and Store:\n\u0026#34;\u0026#34;\u0026#34; title: locations/models.py \u0026#34;\u0026#34;\u0026#34; from django.db import models class Market(models.Model): # ... def __str__(self): return self.name class Store(models.Model): # ... def __str__(self): return self.name It’s important to add _ _str_ _() methods to your models, not only for your own convenience when dealing with the interactive prompt, but also because objects’ representations are used throughout Django’s automatically-generated admin.\nNote these are normal Python methods.Let’s add a custom method, just for demonstration:\nMethods within models \u0026#34;\u0026#34;\u0026#34; title: locations/models.py \u0026#34;\u0026#34;\u0026#34; import datetime from django.db import models from django.utils import timezone class Market(models.Model): # ... def has_stores(self): return self.num_stores \u0026gt; 0 #returns True if Market has stores Save these changes and start a new Python interactive shell by running python manage.py shell again:\n\u0026gt;\u0026gt;\u0026gt; from locations.models import Market, Store # Make sure our __str__() addition worked. \u0026gt;\u0026gt;\u0026gt; Market.objects.all() \u0026lt; QuerySet [\u0026lt;Market: ATN\u0026gt;]\u0026gt; # Django provides a rich database lookup API that\u0026#39;s entirely driven by # keyword argumentm. \u0026gt;\u0026gt;\u0026gt; Market.objects.filter(id=1) \u0026lt; QuerySet [\u0026lt;Market: ATN\u0026gt;]\u0026gt; \u0026gt;\u0026gt;\u0026gt; Market.objects.filter(name__startswith=\u0026#39;A\u0026#39;) \u0026lt; QuerySet [\u0026lt;Market: ATN\u0026gt;]\u0026gt; # Give the Market a couple of Store. The create call constructs a new # Store object, does the INSERT statement, adds the store to the set # of available stores and returns the new Store object. Django creates # a set to hold the \u0026#34;other side\u0026#34; of a ForeignKey relation # (e.g. a market\u0026#39;s store) which can be accessed via the API. \u0026gt;\u0026gt;\u0026gt; market1 = Market.objects.get(pk=1) \u0026gt;\u0026gt;\u0026gt; market1 \u0026lt;Market: ATN\u0026gt; \u0026gt;\u0026gt;\u0026gt; market1.has_stores() True \u0026gt;\u0026gt;\u0026gt; # Display any stores from the related object set -- none so far. \u0026gt;\u0026gt;\u0026gt; market1.store_set.all() \u0026lt; QuerySet []\u0026gt; # Create two stores. \u0026gt;\u0026gt;\u0026gt; import datetime \u0026gt;\u0026gt;\u0026gt;market1.store_set.create(name=\u0026#34;Austin\u0026#34;, number=\u0026#34;1\u0026#34;,phone=\u0026#34;111-999-5555\u0026#34;, date_opened =datetime.datetime.now(), address=\u0026#34;101 Cherry Lane Austin TX 33221\u0026#34;) \u0026lt; Store: Austin\u0026gt; \u0026gt;\u0026gt;\u0026gt; market1.store_set.create(name=\u0026#34;Round Rock\u0026#34;, number=\u0026#34;2\u0026#34;,phone=\u0026#34;111-222-5555\u0026#34;, date_opened =datetime.datetime.now(), address=\u0026#34;117 South Lane Austin TX 33221\u0026#34;) \u0026gt;\u0026gt;\u0026gt; # Store objects have API access to their related Market objects. \u0026gt;\u0026gt;\u0026gt; market1.market \u0026lt; Market: ATN\u0026gt; \u0026gt;\u0026gt;\u0026gt; market1.store_set.all() \u0026lt; QuerySet [\u0026lt;Store: Austin\u0026gt;, \u0026lt;Store: Round Rock\u0026gt;]\u0026gt; \u0026gt;\u0026gt;\u0026gt; market1.store_set.count() 2 \u0026gt;\u0026gt;\u0026gt; current_year = datetime.datetime.today().year \u0026gt;\u0026gt;\u0026gt; Store.objects.filter(date_opened__year=current_year) \u0026lt; QuerySet [\u0026lt;Store: Austin\u0026gt;, \u0026lt;Store: Round Rock\u0026gt;]\u0026gt; # Let\u0026#39;s delete all of the stores that begin with \u0026#39;R\u0026#39;. Use delete() for that. \u0026gt;\u0026gt;\u0026gt; store = market1.store_set.filter(name__startswith=\u0026#39;R\u0026#39;) \u0026gt;\u0026gt;\u0026gt; store.delete() \u0026gt;\u0026gt;\u0026gt; exit()  Using these same commands are how we will create \u0026amp; store markets in our code\n For more information on model relations, see Accessing related objects. For more on how to use double underscores to perform field lookups via the API, see Field lookups. For full details on the database API, see our Database API reference.\n Exercise: Test Your Models Write a test class to verify model object and their methods.\n test model creation test model methods  Starter code:\n\u0026#34;\u0026#34;\u0026#34; title: locations/tests.py \u0026#34;\u0026#34;\u0026#34; from django.test import TestCase from django.urls import reverse from .models import Market, Store class MarketModelTest(TestCase): def test_market_model(self): Market.objects.create(number=15, name=\u0026#34;Test_Market1\u0026#34;) Market.objects.create(number=23, name=\u0026#34;Test_Market2\u0026#34;), num_stores=32) Exercise: Populate DB with THD_Data Using the THD_api app you created in the first Django Exercise create an API that will populate our Django database with only the Markets and Stores.\nBonus Enable the API to also check for updates to markets.\n"
},
{
	"uri": "/custom-workshops/frontend-at-thd/intro-to-experiences/",
	"title": "Introduction to Experiences",
	"tags": [],
	"description": "",
	"content": "Nucleus Why was Nucleus created? Standardization As the Online organization moved into the Squad Model, it was soon discovered that the existing applications (CPR, PIP, BASS, etc) were built very differently. They have very different project structures, different naming conventions, different test suites, different build processes, different pipelines, and on and on. These differences make it difficult for squads to move from one application to another as it takes them time to acclimate themselves due to the lack of standardization.\nSpeed Have you ever found a simple bug in the code or a strange styling issue right after you deployed? Why can\u0026rsquo;t we just simply fix it immediately? Because our current build and deployment processes can be slow, it can sometimes take hours just to fix a simple thing. In order to change something simple, on say the Appliance Experience within PIP, the entire PIP application has to be rebuilt, retested, and redeployed! Also, remember when we said that our current monolithic application model requires each application to have its own instances in Google Cloud? Well every change requires our SREs to create brand new instances, validate that they\u0026rsquo;ve come online, and then turn off the old ones. All of this is very time consuming.\nBottlenecks Have you ever had a pull request for a small change get blocked because of other changes going in to a completely different part of the application? This is because of the monolithic nature of the existing apps. A change in one place can hold up another change because the entire application gets built and deployed as a whole.\n"
},
{
	"uri": "/react/foundations/jsx/",
	"title": "JSX Expressions",
	"tags": [],
	"description": "",
	"content": "What is JSX and how to organize your JSX expressions.\nConcepts  JSX expressions combine the HTML and JavaScript languages. JSX expressions are transformed into JavaScript expressions by the Babel plugin. JSX expressions can be treated the same way any JavaScript expression. For instance JSX expressions can be:  assigned to a variable returned from a function or method used in ternary expressions    Skills  Assign JSX expressions to a variable. Return JSX expressions from functions or methods. Organize and refactor JSX expressions for better code organization and readability.  What Is JSX?   JSX:\n isn\u0026rsquo;t really HTML is a domain-specific language that is a hybrid of HTML and JavaScript. is a superset of HTML can embed JavaScript expressions inside of JSX using curly braces has some specific rules:  HTML attributes that have the same names as a reserved JavaScript keyword cannot be used. For example, the HTML attributes class and for are changed in JSX to className and htmlFor. All tags, even self-closing tags, have to be closed in JSX. For example, \u0026lt;input type=\u0026quot;text\u0026quot;\u0026gt; needs to be coded with a closing tag: \u0026lt;input type=\u0026quot;text\u0026quot; /\u0026gt;.    Example:\nfunction App() { const greeting = \u0026#39;Hello World\u0026#39; return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;{greeting}\u0026lt;/h3\u0026gt; {/* Use curly braces to denote a JavaScript expression to be evaluated. */} \u0026lt;/div\u0026gt; ); }  NOTE: Everything being returned by the above function is JSX.\n JSX is Transpiled into JavaScript Here is an example of a simple React component\n\u0026lt;MyComponent\u0026gt; \u0026lt;p\u0026gt;Your Text Here\u0026lt;/p\u0026gt; \u0026lt;/MyComponent\u0026gt; For this piece of code to work in the browser, it must be transpiled into plain JavaScript:\nReact.createElement( MyComponent, null, React.createElement(\u0026#34;p\u0026#34;, null, \u0026#34;Your Text Here\u0026#34;) ); NOTE: You can try this for yourself at babeljs.io.\nAs you can see, it\u0026rsquo;s a little easier to write JSX than plain JavaScript. Essentially what JSX comes down to is just making it easier to express the following:\nReact.createElement(component, props, ...children) Some JSX Examples Here are some examples of JSX expressions:\nExample 1 - A simple header This one is both valid HTML and valid JSX:\n\u0026lt;h1\u0026gt;Welcome to My Website\u0026lt;/h1\u0026gt; Example 2 - A paragraph with some dynamic data JSX uses curly braces, { and }, to inject dynamic JavaScript expressions into the HTML expressions.\nFor example:\n\u0026lt;p\u0026gt;Hello {firstName} {lastName}\u0026lt;/p\u0026gt;  The curly braces around firstName and lastName indicate that a JavaScript expression should be evaluated. The result of the evaluation is a JavaScript value that can be displayed, such as \u0026ldquo;Hello John Smith\u0026rdquo;.   NOTE: The JavaScript expression inside the curly braces must evaluate to a JavaScript primitive value: i.e. a string, number, boolean, null, undefined, or a symbol.\n Example 3 - A paragraph with some dynamic data coming from a function  We can put any JavaScript expression inside the curly braces as long as it evaluates into a JavaScript primitive value. Here is an example of calling a function from inside the curly braces:  \u0026lt;p\u0026gt;Hello {getFullName()}\u0026lt;/p\u0026gt; Example 4 - An array of JSX Expressions  Often we want to loop through a set of values, converting each value from a JavaScript value into a JSX expression. Often you will use Array.map to do the looping and conversion:  \u0026lt;ul\u0026gt; {hobbies.map((hobby, index) =\u0026gt; \u0026lt;li key={index}\u0026gt;{hobby}\u0026lt;/li\u0026gt;)} \u0026lt;/ul\u0026gt;  In this example we have mapped over an Array of JavaScript strings and converted them into an Array of JSX expressions. Thus if we start with an array of 3 strings, we will map them into an Array of 3 \u0026lt;li\u0026gt; elements. What React renders to the DOM will be something like this:  \u0026lt;ul\u0026gt; \u0026lt;li key=0\u0026gt;Cycling\u0026lt;/li\u0026gt; \u0026lt;li key=1\u0026gt;Chess\u0026lt;/li\u0026gt; \u0026lt;li key=2\u0026gt;Photography\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt;  NOTE: The key value is used by React to efficiently manage updates to an Array of JSX expressions. If we modify or remove an entry, React can tell which entry was affected by its key value. The key should be unique and ideally should not depend on the index in an Array. If you\u0026rsquo;re using a database, often you will want to use the ID value for the key.\n Example 5 - A Ternary Expression Sometimes it\u0026rsquo;s helpful to use a JavaScript ternary operator to choose between two values to be displayed:\n\u0026lt;p\u0026gt;Hello {person ? person.name : \u0026#39;World\u0026#39;}\u0026lt;/p\u0026gt; Where Can I Use JSX?  Essentially a JSX expression is what your component must return. Thus JSX describes how your React component is displayed in the browser. While you can put all of your JSX expressions in the return expression, it\u0026rsquo;s often desirable to organize your JSX expressions for better readability and maintainability.  Example with Long JSX Expression Here is an example of a lengthy JSX Expression being returned from the Component. This JSX could be refactored for better organization.\nfunction Friends(props) { return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Here are some of my friends\u0026lt;/h1\u0026gt; \u0026lt;div\u0026gt; { props.friends.map(friend =\u0026gt; ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Hello {friend.firstName} {friend.lastName}\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;Your hobbies are:\u0026lt;/h2\u0026gt; \u0026lt;ul\u0026gt; { friend.hobbies ? friend.hobbies.map((hobby, index) =\u0026gt; ( \u0026lt;li key={index}\u0026gt;{hobby}\u0026lt;/li\u0026gt; )) : \u0026lt;p\u0026gt;No hobbies to display\u0026#39;\u0026lt;/p\u0026gt; } \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; )) } \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } Which would render to something like this:\nExample with Improved JSX Expression Here is the same example but refactored for better code organization:\nfunction Friends(props) { // Create a variable to hold a JSX expression  // (actually in this case it\u0026#39;s an array of JSX expressions)  const friendsList = props.friends.map(friend =\u0026gt; ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Hello {friend.firstName} {friend.lastName}\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;Your hobbies are:\u0026lt;/h2\u0026gt; \u0026lt;ul\u0026gt; { friend.hobbies ? friend.hobbies.map((hobby, index) =\u0026gt; \u0026lt;li key={index}\u0026gt;{hobby}\u0026lt;/li\u0026gt;) : \u0026lt;p\u0026gt;No hobbies to display\u0026lt;/p\u0026gt; } \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; )); // Now our return expression is much shorter.  return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Here are some of my friends\u0026lt;/h1\u0026gt; \u0026lt;div\u0026gt; {friendsList} {/* reference the variable containing the JSX expression */} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); }  In the improved code we have used a variable, friendsList, to hold an array of JSX expressions generated from mapping over the friends array. But now there is a lot going on in the calculation of friendsList.   NOTE: We can organize this even better; see below.\n Example with Improved JS via helper functions We can take this a step further by creating some functions to handle both the mapping of the friends array and the mapping of the hobbies for each friend:\nimport React from \u0026#39;react\u0026#39; function Friends(props) { function mapHobbiesToJSX(hobbies) { return hobbies ? hobbies.map((hobby, index) =\u0026gt; \u0026lt;li key={index}\u0026gt;{hobby}\u0026lt;/li\u0026gt;) : \u0026lt;p\u0026gt;No hobbies to display\u0026#39;\u0026lt;/p\u0026gt; } function mapFriendsToJSX(friends) { return friends.map(friend =\u0026gt; ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Hello {friend.firstName} {friend.lastName}\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;Your hobbies are:\u0026lt;/h2\u0026gt; \u0026lt;ul\u0026gt; {/* call a method that returns a JSX expression */} {mapHobbiesToJSX(friend.hobbies)} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; )); } return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Here are some of my friends\u0026lt;/h1\u0026gt; \u0026lt;div\u0026gt; {/* call a method that returns a JSX expression */} {mapFriendsToJSX(props.friends)} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ) } export default Friends  Here we have added two methods, mapHobbiesToJSX and mapFriendsToJSX. Each method does a specific tasks as indicated by the name of the method. Also, notice how short our final return expression has become! The original return implementation was 22 lines of code and now it\u0026rsquo;s down to 7 lines of code (with the help of some friend methods). The result is that the code that is much easier to read and maintain.  Lab: Refactor the Shopping Cart App Click here for the instructions to this lab.\nSummary  JSX expressions are just a special kind of JavaScript expression. As such you can use them just as you would any JavaScript expression.  Specifically you can:\n assign a JSX expression to a variable create an array of JSX expressions return a JSX expression from a function or method  Using these techniques you will be able to improve the readability and maintainability of your React code.\nFor Further Reading  Learn React - What is JSX  "
},
{
	"uri": "/python/bots/bot_labs/",
	"title": "Labs",
	"tags": [],
	"description": "",
	"content": "Create a class called Bot() that:\n Gets the ID of all \u0026ldquo;bot users\u0026rdquo; Writes a message to slack channel whenever the bot is mentioned List all usernames along with any message sent by a specific user in the channel. Has a greeting function that returns a greeting anytime a user greets the bot Using the nflgameRetriever.py give your bot the functionality to return some requested nfl data from the module  "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/labs/lab-listing-files/",
	"title": "Listing Files Lab",
	"tags": [],
	"description": "",
	"content": "Navigating inside the command-line-kitchen-organizer directory and do the following commands:\n List the absolute path of the current directory. List all of the files in kitchen/fridge directory simply. List all of the files in kitchen/fridge directory and show file types. List all of the files in kitchen/fridge directory as a long listing. List all of the files in kitchen/fridge directory as a long listing and include hidden files.  "
},
{
	"uri": "/react/pillars/testing/common/mocking/",
	"title": "Mocking",
	"tags": [],
	"description": "",
	"content": "react Mocking\n Topics 1. In this lesson you will learn: 2. What are mocks? 3. Mock functions 3.1. The .mock property   4. Mocking an External API 4.1. The Scenario   5. Why we need mocks 6. How to mock modules \u0026amp; functions 6.1. Add a manual mock 6.2. Create mocked module inside of the test file   7. Summary 8. Resources   1. In this lesson you will learn:   What are mocks\n  Why we need mocks\n  How to implement mocks\n     2. What are mocks? Mocks are functions or objects that mimic the behavior of real objects in controlled ways. Mocks are important to testing because we need to:\n   control the behavior of component under test by controlling the behavior of the mock (such as defining specific data sets useful for the tests)\n  improve the speed of running tests (as external dependencies such as APIs and databases tend to be much slower than a mock implementation)\n  improve the reliability of running tests (as external dependencies may not always be available)\n   In jest there are two ways to mock functions:\n  create a mock function to use in test code\n  create a manual mock to override a module dependency\n   We will first look at creating a mock function.\n   3. Mock functions Let\u0026#8217;s imagine we are testing a function that calculates a total for a bill including calculating the sales tax.\n calc.js module.exports = function calcTotal(items, salesTaxCalc) { const total = items.reduce((total, item) =\u0026gt; total + item + salesTaxCalc(item), 0); return Math.round(total * 100) / 100; }   To test this code we can provide our own implementation of salesTaxCalc. Furthermore, if we can use a jest mock function to inspect the mock\u0026#8217;s state and ensure the callback was invoked as expected.\n calc.test.js const calcTotal = require('./calc'); test('calculates a total with sales tax', () =\u0026gt; { const mockSalesTaxCalc = jest.fn(v =\u0026gt; v * 0.1); // the total bill is the sum of the item prices and their tax const expectedTotal = Math.round((2.50 + 0.25 + 3.75 + 0.375) * 100) / 100; expect(calcTotal([2.50, 3.75], mockSalesTaxCalc)).toBe(expectedTotal); // The mock function is called twice expect(mockSalesTaxCalc.mock.calls.length).toBe(2); // The first argument of the first call to the function was 0 expect(mockSalesTaxCalc.mock.calls[0][0]).toBe(2.5); // The first argument of the second call to the function was 1 expect(mockSalesTaxCalc.mock.calls[1][0]).toBe(3.75); // The return value of the first call to the function was 0.25 (the tax on 2.50) expect(mockSalesTaxCalc.mock.results[0].value).toBe(0.25); // The return value of the first call to the function was 0.25 (the tax on 3.75) expect(mockSalesTaxCalc.mock.results[1].value).toBe(0.375); });   3.1. The .mock property All jest mock functions have this special .mock property that contains data about how the function was called and what values the function returned. The .mock property also tracks the value of this for each call, so it is possible to inspect this as well!\n    4. Mocking an External API 4.1. The Scenario   Let\u0026#8217;s imagine you are shopping for a new ceiling fan on homedepot.com. You input “ceiling fans” into the search bar then click the button. Soon a wide assortment of images and descriptions return to the browser.\n Note the following:\n   The website user is not concerned with how the data is fetched. They only care that the ceiling fans are viewable in the browser.\n  Likewise, the front-end developer who is writing the unit tests is only concerned that the data is correctly displayed on the screen.\n   Therefore, as UI test writers we are concerned with how the user interacts with the app and what the user sees. We are not concerned with the implementation details, i.e. how the data gets passed to the front end. Since our unit tests are built to mimic how the user interacts with our app and what the user expects to see, the unit tests do not need to involve all the dependencies required in a real-world (production) environment. These dependencies can often be substituted with fake (mock) implementations that make testing easier and more efficient.\n    5. Why we need mocks In testing we often want to run our unit tests efficiently and without external dependencies such as an HTTP server or a database. If running our tests required having these dependencies available, our tests would run more slowly and it would be much more difficult to control how the tests execute (such as populating the database with the proper test data).\n We want to avoid hitting an external HTTP server API because:\n   Stable test data. We need to return the same data every time we run the test suite.\n  Control over test data We need to provide different data sets for different tests to control how the component under test responds to these data sets.\n  Time. Real network calls take a lot of time and unit tests need to be run in minutes or seconds.\n  Failure rates. Network calls tend to fail, which means tests may periodically fail.\n  Rate limits. If every time you run the test suite, an API call is made, you may hit the allocated maximum of API calls.\n  Cost. Some APIs cost money. If the API is hit every time the tests run, it will cost the company money.\n   We avoid hitting the real API and instead create a mocked version of the API that pretends to be the real API (often returning a Promise).\n In this shopping scenario, the client is making an HTTP request to the server using a package like fetch or axios. This is a great opportunity to mock the fetch or axios calls and remove the need to have an HTTP server available. Specifically we want to create a mock implementation of our axios library that mimics the asynchronous behavior of the axios API (i.e. returning a resolved Promise).\n jest provides a few different ways to mock a module. Let\u0026#8217;s review two methods, using axios as an example.\n   6. How to mock modules \u0026amp; functions 6.1. Add a manual mock To create a mock for a library that is imported from node_modules, you can simply create the folder __mocks__ on the same directory level as node_modules (usually in your project\u0026#8217;s root folder), then create a file in there with the same name as the package you want to mock, and that mock will automatically be applied. For more details, see Manual Mocks in Jest.\n To mock the axios library, we can create a __mocks__ directory and add a file named for the module you wish to mock.\n src/__mocks__/axios.js export default { get: jest.fn(() =\u0026gt; Promise.resolve({ data: [] })) };   Here we are mocking the axios get method so that get is now defined as a jest function that returns a resolved Promise containing an empty array. Consider this the default value when calling axios.get in a test.\n But what if we want axios.get to return different data? We can easily override this default value of axios.get inside of the test. We will take a look at how to do that in the next section.\n  6.2. Create mocked module inside of the test file The simplest way to mock a module is to do so right inside of the test suite.\n component.test.js jest.mock('axios', () =\u0026gt; { (1) return { get: jest (2) .fn(() =\u0026gt; Promise.resolve({ data: [] })) (3) .mockImplementationOnce(() =\u0026gt; Promise.resolve({ (4) data: [ {id: \"55\", person: \"Ms. Frizzle\", giftName: \"THD gift card\"} ] })) } })     1 jest.mock('axios)' Tells the test to use a mocked axios   2 override axios.get method with one of the following values   3 axios.get is being overriden by the jest.fn implementation which returns a default value. This is the same value set in the manually mocked setup option.   4 axios.get \u0026#8658; is being overriden by the jest.mockImplementationOnce the implementation of the mock for the first call. After all of the mockImplementationOnce implementations have executed, the axios.get will assume the default value.       7. Summary Mocks allow us to substitute fake implementations for the dependencies of a component under test. By mocking out these dependencies we can more efficiently execute our tests and ensure that we are in full control of the data and behavior needed for testing specific behaviors of the component under test.\n   8. Resources   Jest Expect API documentation\n  Mocking Axios in Jest + Testing Async Functions\n  Understanding Jest Mocks\n  Tutorial: Mocking API Calls and Ssimulating components interactions\n     "
},
{
	"uri": "/javascript/nodejs/advanced/express-and-bookshelf/bookshelf-movies/",
	"title": "Movies App with Bookshelf",
	"tags": [],
	"description": "",
	"content": "Bookshelf Movies This project builds off the knex-movies-express app. The aim is to use knex for migrations and bookshelf\u0026rsquo;s ORM capabilities for interacting with the database.\nSetting up Migrations We can start by setting up the migrations.\nMovies The movies migration will remain unchanged from our previous knex example.\nDirectors In this application we are going to add a directors table and setup a one to many relationship with our Movies model.\nthe migration will look like this:\nexports.up = knex =\u0026gt; knex.schema.hasTable(\u0026#39;directors\u0026#39;).then(exists =\u0026gt; { if (!exists) { return knex.schema .createTable(\u0026#39;directors\u0026#39;, table =\u0026gt; { table.increments(\u0026#39;id\u0026#39;).primary(); table.string(\u0026#39;first_name\u0026#39;); table.string(\u0026#39;last_name\u0026#39;); table.timestamps(true, true); }) .then(() =\u0026gt; knex.schema.table(\u0026#39;movies\u0026#39;, table =\u0026gt; { table .integer(\u0026#39;director_id\u0026#39;) .unsigned() .index(); table.foreign(\u0026#39;director_id\u0026#39;).references(\u0026#39;directors.id\u0026#39;); }) ); } }); exports.down = knex =\u0026gt; knex.schema .table(\u0026#39;movies\u0026#39;, table =\u0026gt; { table.dropColumn(\u0026#39;director_id\u0026#39;); }) .then(() =\u0026gt; knex.schema.dropTableIfExists(\u0026#39;directors\u0026#39;));  Create the directors table Then, add a director_id column to the movies table Also, specify the relationship - the director_id column is references the id column on the directors table.  If we need to rollback this migration, first we will need to drop the director_id column on the movies table.\nActors Now we can setup the actors table.\n$ yarn knex migrate: make actors\nThis migration is a little more verbose, but the idea is similar to directors. With the exception that we are going to create a many_to_many relationship with movies\nThis will require creating an additional table named actors_movies that will store actor_id and movie_id\nexports.up = knex =\u0026gt; knex.schema.hasTable(\u0026#39;actors\u0026#39;).then(exists =\u0026gt; { // 1  if (!exists) { return knex.schema .createTable(\u0026#39;actors\u0026#39;, table =\u0026gt; { table.increments(\u0026#39;id\u0026#39;).primary(); table.string(\u0026#39;first_name\u0026#39;); table.string(\u0026#39;last_name\u0026#39;); table.timestamps(true, true); }) .then(() =\u0026gt; { knex.schema.hasTable(\u0026#39;actors_movies\u0026#39;).then(exists =\u0026gt; { if (!exists) { return knex.schema.createTable(\u0026#39;actors_movies\u0026#39;, table =\u0026gt; { // 2  table .integer(\u0026#39;actor_id\u0026#39;) // 3  .unsigned() // 4  .references(\u0026#39;actors.id\u0026#39;) // 5  .onDelete(\u0026#39;CASCADE\u0026#39;); // 6  table .integer(\u0026#39;movie_id\u0026#39;) // 7  .unsigned() .references(\u0026#39;movies.id\u0026#39;) .onDelete(\u0026#39;CASCADE\u0026#39;); }); } }); }); } }); exports.down = function(knex) { return knex.schema.dropTable(\u0026#39;actors_movies\u0026#39;).dropTable(\u0026#39;actors\u0026#39;); // 8 };  create the actors table create the actors_movies table create the actor_id column unsigned will ensure that all numbers will be positive. For more check out this stackoverflow answer https://stackoverflow.com/a/3895705 point to the actors table Setup of cascade deletion, meaning that if we attempt to delete this column it will also delete any related data. For more on cascade check out this stack-exchange answer https://dba.stackexchange.com/a/44962 repeat for movie_id on rollback, drop actors_movies then drop actors  This set of nested promises and callbacks is becoming difficult to read, let\u0026rsquo;s refactor the code to use async/await\nexports.up = async knex =\u0026gt; { const actorsExists = await knex.schema.hasTable(\u0026#39;actors\u0026#39;); const actorsMoviesExists = await knex.schema.hasTable(\u0026#39;actors_movies\u0026#39;); if (!actorsExists) { await knex.schema.createTable(\u0026#39;actors\u0026#39;, table =\u0026gt; { table.increments(\u0026#39;id\u0026#39;).primary(); table.string(\u0026#39;first_name\u0026#39;); table.string(\u0026#39;last_name\u0026#39;); table.timestamps(true, true); }); } if (!actorsMoviesExists) { await knex.schema.createTable(\u0026#39;actors_movies\u0026#39;, table =\u0026gt; { table .integer(\u0026#39;actor_id\u0026#39;) .unsigned() .references(\u0026#39;actors.id\u0026#39;) .onDelete(\u0026#39;CASCADE\u0026#39;); table .integer(\u0026#39;movie_id\u0026#39;) .unsigned() .references(\u0026#39;movies.id\u0026#39;) .onDelete(\u0026#39;CASCADE\u0026#39;); }); } }; exports.down = knex =\u0026gt; knex.schema.dropTable(\u0026#39;actors_movies\u0026#39;).dropTable(\u0026#39;actors\u0026#39;); Above we are are first storing the promise value of the hasTable query in variables. Then using those values to determine if either table should be created.\nawait will execute each line in a synchronous fashion.\nMigrate You should be able to run your migrations at this point and succesfully create your tables.\n$ yarn knex migrate:latest --env development\nModels Now that we have a schema, we will need to create models for each. The models will tell our application about the relationship handle the more complicated SQL logic for us.\nLet\u0026rsquo;s start by setting up the more complicated many-to-many relationship between movies and actors\nmkdir models touch models/movie.js Instantiation Now we can create our first model.\nconst bookshelf = require(\u0026#39;./bookshelf\u0026#39;); // 1  const Movie = bookshelf.Model.extend({ // 2  tableName: \u0026#39;movies\u0026#39;, // 3  hasTimestamps: true, // 4 }); module.exports = bookshelf.model(\u0026#39;Movie\u0026#39;, Movie); // 5  import the bookshelf object from our bookshelf.js config file create a Movie model by using Bookshelf\u0026rsquo;s Model object. note: we\u0026rsquo;re also going to extend the model and add additional capabilities define the table name specify that we want to use timestamps link:Register (and export) the Movie model. Specifiying the name (first argument) and the model (second argument)  Define Relationships Because our movie model is really just a JavaScript object, we can setup relationships by adding a function (as a property of the object).\nconst Movie = bookshelf.Model.extend({ tableName: \u0026#39;movies\u0026#39;, hasTimestamps: true, actors: function() { return this.belongsToMany(\u0026#39;Actor\u0026#39;); } }); Above we have created an actors function that returns the relationship to the Actor model. belongsToMany is a function provided by bookshelf that, in this case, tells our Movie model about it\u0026rsquo;s relationship to actors.\nThis gives us the capability of looking up all actors that belong to a specific movie.\n In other words, we are telling our application about the relationships it should be aware of.\n In order to complete this relationship, we\u0026rsquo;ll need to tell our Actor model about Movies.\ntouch models/actor.js const Bookshelf = require(\u0026#39;./bookshelf\u0026#39;); const Actor = Bookshelf.Model.extend({ tableName: \u0026#39;actors\u0026#39;, hasTimestamps: true, movies: function() { return this.belongsToMany(\u0026#39;Movie\u0026#39;); } }); module.exports = Bookshelf.model(\u0026#39;Actor\u0026#39;, Actor); Alright! Now we have a relationship. This would be a good time to validate things are working as expected.\n$ NODE_ENV=test yarn mocha./test/models/movieTest.js\n$ NODE_ENV=test yarn mocha./test/models/actorTest.js\nLab 01 - Models Finish setting up the models\n checkout branch 02-models Bring all tests out of pending status by changing xit() to it() on all files in the test directory Run the test suite $ yarn test Write the passing code for the following models:  Movie Director     you can create a test database by running the the db commands found in the package.json file._\n Seeds Bookshelf also allows us to use create seed files.\nWe\u0026rsquo;ll start by creating a bookshelf directory under seeds and adding a seed file.\nmkdir seeds/bookshelf touch seeds/bookshelf/movies.js In seeds/bookshelf/movies.js we\u0026rsquo;ll add the following setup code.\nconst bookshelf = require(\u0026#39;./bookshelf\u0026#39;); // 1  const Director = require(\u0026#39;./models/director\u0026#39;); // 2 const Movie = require(\u0026#39;./models/movie\u0026#39;); // 2 const Actor = require(\u0026#39;./models/actor\u0026#39;); // 2 const data = require(\u0026#39;./data\u0026#39;); // 3  const { directors, movies, actors } = data; // 4  const fullName = person =\u0026gt; `${person.first_name}${person.last_name}`; // 5  const deleteAll = model =\u0026gt; model.where(\u0026#39;id\u0026#39;, \u0026#39;!=\u0026#39;, 0).destroy(); // 6  import the bookshelf configuration bring in all models require setup data (movies, actors, directors) use destructuring assignment to establish variables we can reference in our code. create a fullName function that will take in an actor or director and print their first and last name create a deleteAll function that will destroy everything in the database before seeding  Next we\u0026rsquo;ll create a seed function\n// ...  const seed = async () =\u0026gt; { await deleteAll(Actor); // 1  await deleteAll(Movie); // 2  await deleteAll(Director); // 3  // disconnect from database  // process.exit(0);  bookshelf.knex.destroy() // 4  .then(() =\u0026gt; console.log(\u0026#39;db connections destroyed\u0026#39;)); }; try { seed(); // 5 } catch (err) { // 6  console.error(\u0026#39;ERROR:\u0026#39;, err); process.exit(1); }  Delete all Actor data Delete all Movie data Delete all Director data Destroy the database connection call the seed function handle any errors  Add Directors We can start by seeding the directors.\nconst seed = async () =\u0026gt; { // ...  const [SS, GL, WP] = await Promise.all([ // 1  new Director(directors.spielberg).save(), // 2  new Director(directors.lucas).save(), // 2  new Director(directors.petersen).save() // 2  ]); console.log(\u0026#39;Directors Added!\u0026#39;); // ...  bookshelf.knex.destroy() .then(() =\u0026gt; console.log(\u0026#39;db connections destroyed\u0026#39;)); };  Use destructuring assignment to store the resolved values of Promise.all Create a new Director and save to the database  Add Movies Next we\u0026rsquo;ll add the movies. The syntax will look slightly different.\nconst seed = async () =\u0026gt; { // ...  const [RAIDERS, ET, SL, IJ, SW, AF1] = await Promise.all([ SS.movies().create(new Movie(movies.Raiders)), SS.movies().create(new Movie(movies.ET)), SS.movies().create(new Movie(movies.Schindlers)), SS.movies().create(new Movie(movies.IndianaJones)), GL.movies().create(new Movie(movies.StarWars)), WP.movies().create(new Movie(movies.AirForceOne)) ]); console.log(\u0026#39;Movies Added!\u0026#39;); // ...  bookshelf.knex.destroy() .then(() =\u0026gt; console.log(\u0026#39;db connections destroyed\u0026#39;)); }; Instaed of using the new syntax, we are going to create the movie in relation to the director.\nLAB 02 - Seed Actors Finish writing the seed file and seed the database.\n Checkout branch 03-seeds In seeds/bookshelf/movies.js you\u0026rsquo;ll find the following code +  const [HF, KA, DB, LN, BK, MH, CF, GC] = await Promise.all([ // CREATE actors ]); console.log(\u0026#39;Actors Added!\u0026#39;); await Promise.all([ // attach movies ]);  Write the logic for creating actors Using the Bookshelf documentation on attach connect actors to movies Seed the database  Setting up controllers and routes This is a good opportunity to add controller actions for each of our route handlers.\nA major reason for creating controllers is to provide a separation of concerns and make our routes much easier to understand.\nActors controller To start we\u0026rsquo;ll create an actors controller, import the model and create an index action.\n$ mkdir controllers $ touch controllers/actors.js Inside the controller action we\u0026rsquo;ll add our logic for handling the request.\nconst Actor = require(\u0026#39;./models/actor\u0026#39;); // 1  exports.index = (req, res) =\u0026gt; { // 2  Actor.fetchAll() // 3  .then(actors =\u0026gt; { res.status(200).json(actors); // 4  }) .catch(err =\u0026gt; { // 5  console.log(err); res.status(500).json(err); }); };  import the Actor model create a function named index that handles the request and response. call fetchAll on the Actor model provide the resolved promise value as a response handle the error (if any)  Index Now, in the actors route file we just need to call the index action.\nconst express = require(\u0026#39;express\u0026#39;); const actorsController = require(\u0026#39;./controllers/actors\u0026#39;); // 1  const router = express.Router(); router.get(\u0026#39;/\u0026#39;, actorsController.index); // 2  module.exports = router;  import the actors controller set actionController.index as the route handler\u0026rsquo;s callback function  Show For theshow action, we can follow a similar process.\ncontrollers/actors.js\nexports.show = (req, res) =\u0026gt; { Actor.where({ id: req.params.id }) .fetch({ withRelated: [\u0026#39;movies\u0026#39;] }) .then(actor =\u0026gt; { if (!actor) { res.status(404).json({ message: \u0026#39;Actor not found\u0026#39; }); } res.status(200).json(actor); }) .catch(err =\u0026gt; { console.log(err); res.status(500).json(err); }); }; Now in the route file we\u0026rsquo;ll add the show route handler\nrouter.get(\u0026#39;/:id\u0026#39;, actorsController.show); Create The create action will introduce another bookshelf method.\nexports.create = (req, res) =\u0026gt; { Actor.forge(req.body) .save() .then(actor =\u0026gt; { res.status(200).json(actor); }) .catch(err =\u0026gt; { console.log(err); res.status(500).json(err); }); }; According to the Bookshelf documentation, forge is a helper function that allows us to instantiate a new Model without using the new keyword.\nAt this point, you can easily guess the the syntax for the route handler\nrouter.post(\u0026#39;/\u0026#39;, actorsController.create); Lab 03 - Actors controllers and routes  checkout branch 04-actors-controller-and-routes and finsh writing out the standard crud functionality write controller actions and route handlers for  update delete   don\u0026rsquo;t forget to add proper error handling  Actors and Movies Actions Let\u0026rsquo;s add a couple of more complex actions for adding and removing movies associated with an actor\nAdd a movie to specified actor in the controller we\u0026rsquo;ll create an action named addActor\nexports.addMovie = (req, res) =\u0026gt; { Promise.all([ Actor.where({ id: req.params.id }).fetch(), // 1  Movie.where({ id: req.params.movieId }).fetch() // 2  ]) .then(([actor, movie]) =\u0026gt; { if (!actor) { // 3  const error = { message: \u0026#39;Actor not found\u0026#39; }; res.status(404).json(error); return Promise.reject(error); } else if (!movie) { // 4  const error = { message: \u0026#39;Movie not found\u0026#39; }; res.status(404).json(error); return Promise.reject(error); } return actor.movies().attach(movie); // 5  }) .then(() =\u0026gt; Actor.where({ id: req.params.id }).fetch({ withRelated: [\u0026#39;movies\u0026#39;] }) // 6  ) .then(actor =\u0026gt; res.status(200).send(actor)) .catch(err =\u0026gt; { console.log(err); res.status(500).json(err); }); };  fetch an actor based on the request params fetch a movie based on the request params return an error if the actor is not found return an error if the movie is not found attach the movie and actor fetch the actor returning all related movies  The route handler will be\nrouter.post(\u0026#39;/:id/movies/:movieId\u0026#39;, actorsController.addMovie); Delete a movie from the specified actor The delete action will look similar to the addMovie. With the only major difference being that we\u0026rsquo;ll use the detach method to remove the connection.\nexports.deleteMovie = (req, res) =\u0026gt; { Promise.all([ Actor.where({ id: req.params.id }).fetch(), Movie.where({ id: req.params.movieId }).fetch() ]) .then(([actor, movie]) =\u0026gt; { if (!actor) { const error = { message: \u0026#39;Actor not found\u0026#39; }; res.status(404).json(error); return Promise.reject(error); } else if (!movie) { const error = { message: \u0026#39;Movie not found\u0026#39; }; res.status(404).json(error); return Promise.reject(error); } return actor.movies().detach(movie); }) .then(() =\u0026gt; Actor.where({ id: req.params.id }).fetch({ withRelated: [\u0026#39;movies\u0026#39;] }) ) .then(actor =\u0026gt; { res.status(200).send(actor); }) .catch(err =\u0026gt; { console.log(err); res.status(500).json(err); }); }; The route handler will look like:\nrouter.delete(\u0026#39;/:id/movies/:movieId\u0026#39;, actorsController.deleteMovie); Lab 04 - Refactor Upon further inspection, we could probably stand to refactor this code. The difference is in 1 line of code.\n Checkout branch 05-actors-with-movies Write a function that can be called from the addMovie and deleteMovie Test it out!  Movies and Directors Now that we\u0026rsquo;ve setup the actors controller and routes, we can work on movies and directors.\nLab 05 - Add functionality for Movies and Directors  Checkout branch 06-movies-and-directors Starting with movies, add CRUD functionality Move on to adding CRUD functionality to directors  extra credit\n Add additional logic for attaching and detaching actors to movies.  "
},
{
	"uri": "/application-security/api-security/02_human_to_service_oidc/30_openid-connect-auth-code/",
	"title": "OpenID Connect + Auth Code Grant",
	"tags": [],
	"description": "",
	"content": "Auth Code Grant Remember the Client Credentials grant for service to service? Auth Code Grant is the much larger cousin for Authorization of Humans and their clients to resource servers.\nApps that use the Auth Code Grant do not collect the user\u0026rsquo;s password from them, instead it redirects the browser to the Authorization Server / Identity Provider and lets that system handle the user authentication.\nGIVE ME MY TOKENS!!! In the Client Credentials Grant, we just made a simple API call and received an access_token (aka jwt token). But in the Auth Code Grant there are few key differences.\n The browser (not the SPA) asks for the tokens Tokens are given to the BFF not the Browser or SPA You get two tokens instead of one: Access Token \u0026amp; Refresh Token.  The access token you already know. It is the same (give or take) from the Client Credentials Grant, but remember the Access Token is only good for 60 minutes? In Auth Code it is good for 30 minutes, and after 30 minutes, the BFF needs to make an API call to the Authorization Service to present the refresh token and request a \u0026ldquo;refreshed\u0026rdquo; access token.\nThe Refresh Token is very powerful, and should not be given to the SPA (more on that later)\nWhat is OpenID Connect (OIDC)? OpenID Connect 1.0 is a simple identity layer on top of the OAuth 2.0 protocol (Mostly Auth Code Grant)\nHow to Use OIDC Super simple!! When starting the Auth Code Flow add a scope named openid on a request to our auth server will \u0026ldquo;enable\u0026rdquo; OIDC.\nWhat do I get in return?  Do everything the Authorization Code Grant does, plus\u0026hellip;. Provide an additional token called an id_token in JWT format that gives additional info about the user (first name, last name, etc) Provides an /userinfo or proxied /identity/me endpoint to obtain additional information about a user (serves similar purpose as the id_token)  THIS IS COMPLICATED!!! UGH!! Don\u0026rsquo;t Break the Contract In an effort to be very explicit about the interaction of the SPA and the BFF, we have tried to document our decisions here:\nhttps://app-secure-community-docs.apps-np.homedepot.com/appendix/bff-contract/\nIt is a work in progress, so we are tweaking it as items come up. But this should explain some of the decisions we made along this journey.\nMiddleware Is Your Friend If you don\u0026rsquo;t remember anything else from the class, remember this\u0026hellip;. DON\u0026rsquo;T CODE THIS ON YOUR OWN! Seriously! DO NOT DO IT! It took us almost a year of testing and learning to get all the edges worked out.\nWe have worked tirelessly to create a super easy Paved Road solution for everybody, with NodeJS as the supported solution. Below is a link to the Middleware ane our Example app:\nhttps://app-secure-community-docs.apps-np.homedepot.com/identity/human-to-service/#code\nplease please please, don\u0026rsquo;t go cowboy on this. Lets work together.\n"
},
{
	"uri": "/python/relational-db/orm-models/",
	"title": "ORM Models",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Learning how to set up classes to build out the corresponding database tables Understand how to connect and interact with the database. Knowing how to set up a class for working with an existing database schema  Create SQLAlchemy is a very large library, so it is best to not import the library in it\u0026rsquo;s entirety. We will import the specific functions that apply to our examples.\nWithin your orm-python directory add this starter code. making your file structure look like:\norm-python |── models.py └── set_up.py Starter Code Methods Explained\n declarative_base: constructs a base class for declarative class definitions. This creates the parent class for all classes that represent a table. SQLAlchemy will create a table from any table that inherits Base. Base.metadata.create_all(engine): creates all of the tables from the classes inheriting Base.  Employee System ERD Explanation of the Department class:\nclass Department(Base): __tablename__ = \u0026#39;departments\u0026#39; # 1 dep_no_seq = Sequence(\u0026#39;dep_no_seq\u0026#39;, start=10, increment=10) # 2 dept_no = Column(Integer, dep_no_seq, primary_key=True) # 3 dept_name = Column(String(32), nullable=False) # 3 loc = Column(String(32), nullable=False) # 3 def __init__(self, dept_name, loc): # 4 self.dept_name = dept_name # 4 self.loc = loc # 4 def __repr__(self): # 5 return f\u0026#34;Department: {self.dept_name:15} Location: {self.loc}\u0026#34; # 5 Explanation of the Employee class:\nclass Employee(Base): # ... Code above manager = Column(Integer, ForeignKey(\u0026#34;employees.emp_no\u0026#34;, name=\u0026#39;emp_ref_man_fk\u0026#39;, ondelete=\u0026#39;SET NULL\u0026#39;, onupdate=\u0026#39;CASCADE\u0026#39;)) # 1 manager_rel = relationship(\u0026#34;Employee\u0026#34;, backref=backref(\u0026#39;emp_man\u0026#39;, remote_side=[emp_no], uselist=False)) # 2 # ... Code below  This creates a new Foreign Key in the Employee class. employees.emp_no represents the table name and column of what the FK is pointing to. emp_ref_man_fk is the name given to the FK. ondelete and onupdate explain what to do with the child row if you were to delete a row that the child row has a foreign key pointed to it  Explanation of new concepts in the JobHistory class:\nclass JobHistory(Base): # ... Code above __table_args__ = (CheckConstraint(salary \u0026gt;= 0, name=\u0026#34;emp_sal_ck\u0026#34;), {}) # 1 # ... Code below  CheckConstraint allows for checks on any value constraints on a column. In this case it is making sure that an employees salary is always positive  Execute seeds.py to build the schema in our database.\nCheck the schema was properly created using either Data Grip or the PSQL command-line tool.\nCreate Lab Clone down the repo for the PostgreSQL Python lab with the following instructions:\ngit clone https://github.homedepot.com/om-labs/python-databases.git cd python-databases/orm-python  Follow the instructions in the README for the Create lab: here\n Seeding The database is still empty. We can insert data into the database using Python objects. Because we use the SqlAlchemy ORM we do not have to write a single SQL query. We now simply create Python objects that we feed to the ORM.\nThe following would add a row to the departments table:\nSession = sessionmaker(bind=engine) # 1 session = Session() # 2 try: ny_dept = Department(\u0026#34;Accounting\u0026#34;, \u0026#34;New York\u0026#34;) # 3 session.add(ny_dept) # 4 except Exception as e: print(\u0026#34;Unable to add to departments\u0026#34;, e) session.rollback() # 5 else: print(ny_dept) # 6 session.commit() # 7 finally: session.close() # 8 Place seeds.py in the orm-python directory, making the file structure look like:\norm-python |── // ... possibly other files |── set_up.py |── models.py └── seeds.py Execute seeds.py to build the schema in our database.\nCheck the data was properly inserted using either Data Grip or the PSQL command-line tool.\nSeeding Lab  To go to the Seeding lab: click here\n Working with Existing Databases Most of the time, you will be working with a Database that is already created. You connect to an exiting database the same way we have previously, but building out the classes are done a little differently.\nSetting up classes for an existing database called trucking_company that is stored locally that has a table called shipment would look like:\nengine = create_engine(\u0026#39;trucking_company\u0026#39;) Base = declarative_base(engine) class Shipment(Base): \u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34; __tablename__ = \u0026#39;shipment\u0026#39; __table_args__ = {\u0026#39;autoload\u0026#39;: True} #1 def main(): metadata = Base.metadata Session = sessionmaker(bind=engine) session = Session()  autoload is a boolean that, when set to True, autoloads the columns and populates the metadata from the corresponding database schema.  You can now work with Shipment as if you created the table yourself. If you want to create the start of all of these classes there are SQL to SqlAlchemy converters out there such as sqlacodegen. Documentation here\nSummary Using declarative_base allows the construction of a base class that is use to define Python classes. The classes created include directives to describe the actual database table they are mapped to:\n Classes are mapped to tables Class attributes represent the table fields Instances of the class (objects) represent a row of data in the table  "
},
{
	"uri": "/java/foundations/package/",
	"title": "Packages",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Package structures Package naming conventions Import statements  Skills  Organize your Java apps into packages  What is a Package A package is a group of related classes and interfaces. You could just think about them as a folder structure recognized by the Java compiler. Other than the practical application of making classes easier to find, there is technical significance to package structure as well. Classes in the same package have special visibility to the attributes of one another. It also helps to avoid naming conflicts. You can\u0026rsquo;t imagine that your Car class is the only car class ever made, but it could be the only com.homedepot.om.wrg.Car class.\nNaming Convention Every class will have a package declared at the top:\npackage com.homedepot.om.wrg; //1  public class Truck implements Car { ...  package structure  You\u0026rsquo;ll notice com conventions:\n All lower case Company packages start with the reverse of their domain  homedepot.com =\u0026gt; com.homedepot   Any structure established by a company convention, usually related to field/project  All of this together creates a class\u0026rsquo; official (or fully qualified) name: com.homedepot.om.wrg.Car.\nImporting Packages When you use external classes in your class, the Java compiler has to know where to find them. There are a couple ways to make this happen. If the current class is within the same package as the external class, then the compiler will find it, no problem. However, if it is in a different package, you must explicitly tell the compiler where to find it through an import statement. Most classes contain at least one external class, so examples are easy to find.\npackage com.homedepot.di.xd.tlr.batch.manager; //1  import java.math.BigDecimal; //2 import java.util.ArrayList; import java.util.Collections; import java.util.Date; import java.util.List; import java.util.Map; import org.apache.log4j.Logger; //3  import com.homedepot.di.xd.tlr.batch.util.BatchUtils; //4 import com.homedepot.di.xd.tlr.batch.dao.LoadPlannerPrePlanDAO; import com.homedepot.di.xd.tlr.batch.dto.*; //5  public class RoundingManager { ...  package declaration import block for java classes import for external sources import clock for internal classes packages support wildcard notation, this will bring in every class in the dto package  Standard Packages You may be wondering, \u0026ldquo;If I have to import all external classes\u0026hellip;why do I never see an import for String? Its an external class, and I\u0026rsquo;m most definitely not in the same package\u0026hellip;\u0026rdquo;\nFirst of all, that was a very astute observation, so bravo. Second, this is because there are some packages that are always baked in when using Java. Most notably, the mother of all Java classes: java.lang which houses String, Object, Math, and so, so much more. The Java API Spec lists all packages that are included by default.\nProject Structure Example At this point, your project should look like this:\n. ├── build.gradle ├── gradle │ └── wrapper │ ├── gradle-wrapper.jar │ └── gradle-wrapper.properties ├── gradlew ├── gradlew.bat ├── settings.gradle └── src ├── main │ ├── java │ │ └── com │ │ └── homedepot │ │ └── om │ │ └── student │ │ └── SayHello.java │ └── resources └── test ├── java └── resources 13 directories, 7 files  gradle: this our dependency manager and it brings some stuff in to help do its job  build.gradle defines the project dependecies and structure for build gradle/ contains scripts and definitions for gradle gradlew a project-local gradle script entry point (this makes it so you don\u0026rsquo;t need a global gradle install)   src/ is the directory where most of your development will take place  main/java contains all main classes test/java contains all test classes     ℹ️ Even though your main and test classes are in separate directories, every class should be in the same package as its test class.\ne.g. Both classes SayHello and SayHelloTest are in the package com.homedepot.om.student.\nThis is because directories are how we organize our content and packages are how it will be organized once compiled into a jar. So while we keep it separate in our file structure, it will be grouped together inside its final compilation.\n Summary Well structured Java applications utilize packages to organize their classes in an intuitive and secure way.\n"
},
{
	"uri": "/cloud/platforms/pcf-foundations/pcf-backing-service/",
	"title": "PCF Backing Service",
	"tags": [],
	"description": "",
	"content": "Using a PCF Provided Backing Service Run the command cf marketplace. You should see a list of available services on the platform like this:\nWe want to create a MySQL instance that we can connect to so let\u0026rsquo;s run\ncf create-service p-mysql 100mb first-cups\nNow, run cf services to see if the service instance we created is available.\nThat\u0026rsquo;s really great! But it doesn\u0026rsquo;t mean anything to any of our applications until we bind the service to the application. This means letting an application know that this service instance exists and also supplying it with the correct credentials through what are called environment variables.\nRun cf env APP where APP is your application\u0026rsquo;s name.\nYou should see something like this:\nThese are the objects that represent the environment in which our application runs on PCF. We want the credentials for our database service to be available to the application, as well. The way we do that is by running the cf bind-service command.\nSo let\u0026rsquo;s run:\ncf bind-service first-deploy first-cups\n As suggested, let\u0026rsquo;s restage our application so our new bindings take effect.\ncf restage first-deploy\nNow, when we run cf env we should a lot more information - namely, our database service variables should be there!\nWe now have access to these environment variables in our application instance that runs on PCF! That\u0026rsquo;s way cooler than it seems, by the way.\nThis also gives us one more thing. It\u0026rsquo;s really easy to connect to a local database because the credentials, by default, are the same for the user account on the computer. So, it\u0026rsquo;s trivial to be able to check run queries on our database. But the credentials for our real, deployed application database service should not be exposed in our application code. We will reference only the environment variables.\nThere is a handy package that we can download that will help us with accessing environment variables on PCF.\nnpm install --save cfenv\nWhen we use it we, want to be able to programmatically represent the set of variables that show up when we run cf env APP\n Do not share your database service credentials with anyone and especially do not use them in your source code. Environment variables are your friend!\n So, if the application we just pushed \u0026amp; bound to the service we just created had a knexfile that needed database credentials, it would look like this:\n// Update with your config settings.  // cfenv gives us easy access to Cloud Foundry environment variables const cfenv = require(\u0026#39;cfenv\u0026#39;); # 1. const secrets = require(\u0026#39;./secrets\u0026#39;); # 2. const appEnv = cfenv.getAppEnv(secrets); # 3. const credentials = appEnv.getServiceCreds(\u0026#39;first-cups\u0026#39;); # 4. module.exports = { development: { client: \u0026#39;postgresql\u0026#39;, connection: { host: \u0026#39;127.0.0.1\u0026#39;, database: \u0026#39;om-directory\u0026#39;, charset: \u0026#39;utf8\u0026#39; } }, production: { client: \u0026#39;mysql\u0026#39;, # 5. connection: credentials ? credentials.uri : null, pool: { min: 2, max: 10 }, migrations: { tableName: \u0026#39;knex_migrations\u0026#39; } } };  Importing the cfenv package This is a file are including so the cfenv tool can work when we run in development mode. This variable will include the environment variables for our application, when running the application locally, cfenv is able to detect that we are local and will use the object you pass into it for \u0026ldquo;production\u0026rdquo; which is why we use the dummy secrets file. There is a method on the cfenv package that returns service credentials. We will connect to our database using a long connection string that includes the host, database, username, and password to connect to our database. On PCF, currently MySQL is supported. This is not a problem for us though because Knex is compatible with MySQL without having to make any changes to the application code.  Now, we should probably download a SQL client that will let us run queries on an external database.\nRun brew cask install sequel-pro\nPlease see an instructor for how to connect using Sequel Pro.\n"
},
{
	"uri": "/golang/databases/postgres-golang/",
	"title": "PostgreSQL and Golang",
	"tags": [],
	"description": "",
	"content": "Database Interaction Now that we have a model we can start to build logic around it. We know that we need a way of fetching and saving the model. Add a tools.go file in db/psql/:\ntool_rental ├── db │ └── psql │ ├── set_up.go │ └── tools.go ├── go.mod ├── main.go └── tools ├── data_store.go ├── model.go └── service.go 3 directories, 7 files We\u0026rsquo;ll define the following functions: Create, FindById, FindAll, Update, and Delete.\nWe need to create a type toolDataStore that satisfies the ToolDataStore interface to hold the specific DB connection and a constructor for the new type:\npackage psql import ( \u0026#34;database/sql\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.homedepot.com/yourldap/tool_rental/tools\u0026#34; //replace with yourldap with your ldap  _ \u0026#34;github.com/lib/pq\u0026#34; //gives access to the PSQL driver ) type toolDataStore struct {\t//1 \tdb *sql.DB } func NewPostgresToolDataStore(db *sql.DB) toolDataStore {\t//2 \treturn \u0026amp;toolDataStore{ db, } }  Creates a struct to hold a PSQL db connection and have all CRUD functions. This is private so that the user is forced to use the constructor to create an instance of this type. A constructor for creating a new toolDataStore instance  Implementation NewPostgresToolDataStore can now be used as an argument for NewToolService in main.go.\nReplace the line toolDataStore = //Data store constructor implemented here towards the bottom of the main with:\ntoolDataStore = psql.NewPostgresToolDataStore(db) We are going to use the ToolService that we created previously to interact with this.\nCREATE Now we can write a Create method that takes in a Tool instance and places the new tool into the database for the toolDataStore struct:\nfunc (t toolDataStore) Create(tool *tools.Tool) (err error) { sqlStatement := `INSERT INTO tools(name, description, price, quantity, created, updated) VALUES ($1, $2, $3, $4, $5, $6) RETURNING id` //1 \trow := t.db.QueryRow(sqlStatement, tool.Name, tool.Description, tool.Price, tool.Quantity, time.Now(), time.Now())\t//2 \terr = row.Scan(\u0026amp;tool.ID)\tif err == nil { fmt.Println(\u0026#34;New record ID is:\u0026#34;, tool.ID) //3 \t} return } An example usage of the above method at the bottom of main in main.go would look like:\nnewTool := tools.Tool{ Name: \u0026#34;Hammer\u0026#34;, Description: \u0026#34;Sturdy Hammer\u0026#34;, Price: 100, Quantity: 10, } err = toolService.CreateTool(\u0026amp;newTool) if err != nil { fmt.Println(err) }  This code will not compile until all methods of the ToolDataStore interface are implemented.\n Read Reading Single Record Now we can write a FindByID method that takes in a Tool ID and returns the associated tool, if it exists, for the toolDataStore struct.\nTo execute a query that is expected to return a single row, use DB's QueryRow() method. This method expects at least one row returned, otherwise a ErrNoRows error is thrown. If there multiple rows that match the query, just the first result will be returned.\nfunc (t toolDataStore) FindByID(id string) (tool *tools.Tool, err error) { tool = \u0026amp;tools.Tool{} sqlStatement := `SELECT * FROM tools WHERE id=$1` row := t.db.QueryRow(sqlStatement, id)\t//1 \terr = row.Scan(\u0026amp;tool.ID, \u0026amp;tool.Name, \u0026amp;tool.Description, \u0026amp;tool.Price, \u0026amp;tool.Quantity, \u0026amp;tool.Created, \u0026amp;tool.Updated)\t//2 \tswitch err { case sql.ErrNoRows:\t//3 \treturn tool, fmt.Errorf(\u0026#34;no rows were returned\u0026#34;) case nil: return default: return } }  Executes the SQL query and returns a single row Stores all of the columns from the result and stores them in the corresponding tool \u0026rsquo;s attribute Checks to see that at least one row was returned  An example usage of FindByID in the bottom of the main function of main.go:\nfoundTool, err := toolService.FindToolByID(\u0026#34;791658ed-04ff-41a6-bb05-1c5ca319f0d0\u0026#34;) if err != nil { fmt.Println(err) } fmt.Println(foundTool)  This code will not compile until all methods of the ToolDataStore interface are implemented.\n Reading Multiple Records Now we can write a FindAll method that returns the number of rows for the toolDataStore struct To do this, use the Query() method. Unlike Query(), QueryRow() defers error handling until you call Scan().\nfunc (t toolDataStore) FindAll() (allTools []*tools.Tool, err error) { sqlStatement := `SELECT * FROM tools` rows, err := t.db.Query(sqlStatement)\t//1 \tdefer rows.Close()\t//2 \tfor rows.Next() {\t//3 \tcurrentTool := \u0026amp;tools.Tool{} err = rows.Scan(\u0026amp;currentTool.ID, \u0026amp;currentTool.Name, \u0026amp;currentTool.Description, \u0026amp;currentTool.Price, \u0026amp;currentTool.Quantity, \u0026amp;currentTool.Created, \u0026amp;currentTool.Updated) if err == nil { allTools = append(allTools, currentTool) //append only if there was not an error \t} } err = rows.Err() //4 \treturn } An example usage of FindAll in the bottom of the main function of main.go:\nallTools, err := toolService.FindAllTools() if err != nil { fmt.Println(err) } for _, tool := range allTools { fmt.Println(tool) }  This code will not compile until all methods of the ToolDataStore interface are implemented.\n Update Now we can write a Update method that takes in a Tool instance and updates the tool with the corresponding ID in the database for the toolDataStore struct.\nfunc (t toolDataStore) Update(tool *tools.Tool) (err error) { _, err = t.FindByID(tool.ID) //Checks to see if ID is provided/valid \tif err != nil { return } sqlStatement := `UPDATE tools SET name = $2, description = $3, price = $4, quantity = $5, updated = $6 WHERE id = $1;` result, err := t.db.Exec(sqlStatement, tool.ID, tool.Name, tool.Description, tool.Price, tool.Quantity, time.Now()) fmt.Printf(\u0026#34;%v row affected\\n\u0026#34;, result) return err } An example usage of Update in the bottom of the main function of main.go:\nupdateTool := tools.Tool{ ID: \u0026#34;97a69754-9cf6-4fb9-9c63-b9de09818c5e\u0026#34;, Name: gofakeit.Word(), Description: gofakeit.Sentence(5), Price: gofakeit.Price(1, 1000), Quantity: gofakeit.Number(0, 100), } err = toolService.Update(\u0026amp;updateTool) //...error handling  This code will not compile until all methods of the ToolDataStore interface are implemented.\n Delete Now we can write a Delete method that takes in a Tool id and deletes the tool with the corresponding ID in the database for the toolDataStore struct.\nfunc (t toolDataStore) Delete(id string) (err error) { _, err = t.FindByID(id) if err != nil { return fmt.Errorf(\u0026#34;delete: id not found\u0026#34;) } sqlStatement := `DELETE FROM tools WHERE id = $1;` result, err := t.db.Exec(sqlStatement, id) numRows, _ := result.RowsAffected() fmt.Printf(\u0026#34;%v rows deleted\u0026#34;, numRows) return err } An example usage of the above method in the bottom of the main function of main.go:\nerr = toolService.DeleteTool(\u0026#34;791658ed-04ff-41a6-bb05-1c5ca319f0d0\u0026#34;) if err != nil { fmt.Println(err) } Now you should be able to compile and see all of the above examples work.\nConclusion Now we are able to complete CRUD actions on a Postgres database.\n"
},
{
	"uri": "/software-eng-essentials/postman-foundations/lab/",
	"title": "Postman Essential Labs",
	"tags": [],
	"description": "",
	"content": "Learning Objective  Use Postman to test the endpoints of the Store Data API  Loading the Store Data API Clone the following repository from Github: https://github.com/one-thd/om_labs_JavaScript-store-data-api.git\nThe root URI of our call will be http://localhost:3000/.\n  Click here to follow the set-up instructions found in the ReadMe.md.\n  In Postman, test the endpoints of the Store Data API\n Send a GET request to see: All stores A single store by ID All Stores in a specific state Send a PUT request and change the attributes of a single record Send a POST request to add a new record to the table Send a DELETE request to delete a record from the table.    Set up a Collection to perform all the function at once.\n  "
},
{
	"uri": "/python/foundation/print-function/",
	"title": "Print Functions",
	"tags": [],
	"description": "",
	"content": "print() Function Since the first thing everyone needs to know how to do in any programming language is write a \u0026ldquo;Hello world\u0026rdquo; program, we\u0026rsquo;ll start with the print() function to do just that.\nCreate a new Python file in your project called print_practice. Type the following on the first line of this file:\nprint(\u0026#34;Hello world!\u0026#34;) Run this program.\nLet\u0026rsquo;s discuss what we\u0026rsquo;re putting within the parenthesis of the print function. It is a data-type called a string. The important thing to note right now about strings, is that they require \u0026quot; quotation marks around them so that the function knows we\u0026rsquo;re handing it a string.\nprint() Set Up It\u0026rsquo;s displaying whatever you put within the parenthesis in your console once the program is run.\nIn previous versions of Python the print function was actually a \u0026ldquo;print statement\u0026rdquo; and was written like so:\nprint \u0026#34;Hello world!\u0026#34; In Python3, it is now a print function and the syntax has changed to be written with parenthesis at all times, as you would to call any function:\nprint() Keep these important words in mind: Data-Type, String and Function. We\u0026rsquo;ll be talking much more about all of these as we dig deeper into our \u0026ldquo;Hello world!\u0026rdquo; program.\nNew Line and Tabbed Characters We can format our output of print() functions by including a few characters within our string.\nTo create a new line in the output, type \\n such as:\nprint(\u0026#34;Hello,\\nwelcome to Orange Academy!\u0026#34;) If we want to tab over to create more space between items within our string, we can use \\t like so:\nprint(\u0026#34;Testing, testing\\t1\\t2\\t3...\u0026#34;) We can combine the two to make cool, interesting and useless patterns in our output.\nCopy and paste the following into the Python Console:\nprint(\u0026#34;Testing, testing\\n\\t1\\n\\t\\t2\\n\\t\\t\\t3...\u0026#34;) Printing out on one line You may use the end=\u0026quot; \u0026quot; keyword in Python3 to be able to print out content on one line while using several different print() function statements.\nFor example, if you just print out:\nprint(\u0026#34;Hello,\u0026#34;) print(\u0026#34;my name is\u0026#34;) print(\u0026#34;George\u0026#34;) The above will print out on three separate lines. In order to get it to print on one line as a sentence, do the following with the end=\u0026quot; \u0026quot; keyword:\nprint(\u0026#34;Hello,\u0026#34;, end=\u0026#34; \u0026#34;) print(\u0026#34;my name is\u0026#34;, end=\u0026#34; \u0026#34;) print(\u0026#34;George\u0026#34;) Go to Comments Lesson\n"
},
{
	"uri": "/react/pillars/testing/react-testing-library/",
	"title": "React Testing Library",
	"tags": [],
	"description": "",
	"content": "Lessons "
},
{
	"uri": "/react/pillars/perf-opt-strategies/use-memo/",
	"title": "React.useMemo",
	"tags": [],
	"description": "",
	"content": "Use React.useMemo to avoid unnecessarily recomputing expensive operations.\nBackground  Memoization is an optimization technique used primarily to speed up computer programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again. Memoization is only valid for pure functions.  What are Pure Functions? Recall that a pure function\u0026rsquo;s output only depends on its inputs. For example:\n// add is a pure function function add(x, y) { return x + y; } let tipRate = 0.2 // getTipAmount is not a pure function function getTipAmount(billAmount) { return billAmount * tipRate; }  For the add function, when we pass in the values of 3 and 5 we will always get back 8. But for the getTipAmount function, the output depends on an external (global) variable named tipRate. This variable could change over time making getTipAmount return different outputs for the same input.  A function is not be pure if it does any of the following:\n Makes network requests Accesses a database or the file system Modifies application state  How React Does Memoization In general, memoization can remember any number of past inputs and outputs:\n Remember all past inputs and outputs - essentially an unbounded cache Remember the past N inputs and outputs - a bounded cache Remember only the previous input and output - called the memo-one pattern.  React\u0026rsquo;s useMemo (and useCallback) use the memo-one pattern and thus only remember the previous input and output. This ensures that memoization does not consume too much memory.\nAlso note that React\u0026rsquo;s implementation of useMemo does not guarantee that the memoized value will always be available:\n You may rely on useMemo as a performance optimization, not as a semantic guarantee. In the future, React may choose to “forget” some previously memoized values and recalculate them on next render, e.g. to free memory for offscreen components. Write your code so that it still works without useMemo — and then add it to optimize performance. - React docs\n If you need an implementation that guarantees memoization is always preserved, see: use-memo-one.\nUsing React.useMemo  React.useMemo is a hook added in React version 16.8. You can use React.useMemo to remember any JavaScript value (primitive, object, or array). useMemo takes 2 arguments:  a function that can be called to run an expensive calculation, and an array of dependencies that, when changed, will trigger the expensive calculation to be recomputed.   Note that changes to the dependencies are detected via a shallow comparison (referential equality).  const memoizedValue = React.useMemo(() =\u0026gt; computeExpensiveValue(a, b), [a, b]); Summary  Memoization is a way to remember or cache the inputs and output of an expensive operation. React.useMemo uses the memo-one pattern to remember only the last set of inputs and output. React.useMemo takes 2 arguments, a function to call and an array of dependencies.  Lab - Approximately 10 minutes  Use the React Performance Optimization Playground App for this lab. You will find a \u0026ldquo;React.useMemo\u0026rdquo; example and within that there are tabs for \u0026ldquo;Before\u0026rdquo; and \u0026ldquo;After\u0026rdquo;. The code for these tabs is found in the project source code under the folder src/pages/UseMemoEx. Currently the code in the Before folder and the After folder are identical. Make the necessary changes in the After folder to add useMemo to the PICalculator and DogYears components. Test that when you interact with the parent component, the child components render quickly as the slow computations no longer need to be recalculated with each render.  "
},
{
	"uri": "/python/automation/report-creation/",
	"title": "Report Creation",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Create reports from Panda data frames in various formats Add images to the reports  Report Creation There are several database interactions in chart form that you might want to place together in one single report. This report might need to be in several different formats, such as html, markdown or xlsx.\nDataframe to Excel Pandas offers support of converting from a DataFrame to an Excel sheet with the help of openpyxl.\nIn order to work with excel and interact with a Pandas data frame, you need to make sure that you have installed everything you need. Install all needed libraries for this lesson using this file and running:\npython3 -m venv venv # only if you have not created a virtual environment yet source venv/bin/activate pip3 install -r requirements.txt This function creates an excel document with the data to data frame\nimport pandas as pd def create_excel(df, img_name, file_name): writer = pd.ExcelWriter(file_name) # 1 df.to_excel(writer, index=False) # 2 worksheet = writer.sheets[\u0026#39;Sheet1\u0026#39;] # 3 worksheet.insert_image(\u0026#39;E2\u0026#39;, img_name) # 4 writer.close() Implementation of the create_excel function looks like:\ncreate_excel(df, img_name, \u0026#39;emp_added_yearly.xlsx\u0026#39;) The contents of emp_added_yearly.xlsx Lab\nIf you have not already, clone down the repo for the Python Automation lab with the following instructions:\ngit clone https://github.homedepot.com/om-labs/python-automation.git cd python-automation/report-creation  Follow the instructions in the README\n Dataframe to HTML Using the prior example of finding the total number of employees per job title, we can place all of the information from a DataFrame into an HTML file.\nPandas creates an HTML table from DataFrame data with the method to_html().\nFor example:\ndef create_html(df, file_name, img_name=None): html_output = df.to_html(file_name) # 1 if img_name is not None: with open(file_name, \u0026#39;a\u0026#39;) as html_file: # 2 import base64 # 3 data_uri = base64.b64encode(open(img_name, \u0026#39;rb\u0026#39;).read()).decode(\u0026#39;utf-8\u0026#39;).replace(\u0026#39;\\n\u0026#39;, \u0026#39;\u0026#39;) # 4 html_file.write(f\u0026#39;\u0026lt;img src=\u0026#34;data:image/png;base64,{data_uri}\u0026#34;\u0026gt;\u0026#39;) # 5 Adds the table with data from the Number of Employees added per year dataframe to an html file called num_emp.html\ncreate_html(df, \u0026#34;num_emp.html\u0026#34;) This will generate num_emp.htmlUsing the optional image_name argument to add a chart:\ncreate_html(df, \u0026#34;num_emp.html\u0026#34;, img_name) This will generate num_emp.htmlLab\nIf you have not already, clone down the repo for the Python Automation lab with the following instructions:\ngit clone https://github.homedepot.com/om-labs/python-automation.git cd python-automation/report-creation  Follow the instructions in the README\n Dataframe to Markdown Using the prior example of finding the total number of employees per job title, we can place all of the information from a DataFrame into a Markdown file.\nTo take in a DataFrame and return a string with a Markdown table, use Panda\u0026rsquo;s to_markdown method.\ndef create_markdown(df, file_name): md = df.to_markdown() with open(file_name, \u0026#39;w\u0026#39;) as file: file.write(md) Implementation of the create_markdown method looks like:\ncreate_markdown(df, \u0026#34;num_emp.md\u0026#34;) Contents of num_emp.md:\n| | count | job | |:---|:--------|:----------| | 0 | 1 | PRESIDENT | | 1 | 3 | MANAGER | | 2 | 1 | ANALYST | | 3 | 4 | CLERK | | 4 | 4 | SALESMAN | Lab\nIf you have not already, clone down the repo for the Python Automation lab with the following instructions:\ngit clone https://github.homedepot.com/om-labs/python-automation.git cd python-automation/report-creation  Follow the instructions in the README\n Summary The Python library Pandas allows you to easily read in data from various types of formats and allows you to write that same information to other formats easily. Adding images to these reports is done with ease as well.\n"
},
{
	"uri": "/react/pillars/advanced-react/reusable-components/",
	"title": "Reusable Components",
	"tags": [],
	"description": "",
	"content": "Designing React Components for Reuse and Composition.\n Topics 1. Learning Objectives 1.1. Concepts \u0026amp; Skills   2. Problem Statement 3. Reuse via Presentational Components 4. Reuse via Inheritance 4.1. Problems with Inheritance   5. Reuse via HOCs 5.1. Disadvantages of HOCs 5.2. For Further Exploration   6. Reuse via Render props 6.1. Advantages of Render Props 6.2. For Further Exploration   7. Reuse via Recompose 7.1. Advantages and Disadvantages of recompose   8. Summary 8.1. Discussion   9. Resources 9.1. HOCs 9.2. Render Props 9.3. Recompose   10. LAB - Movies App   1. Learning Objectives 1.1. Concepts \u0026amp; Skills   Describe various strategies for code reuse between similar React components\n  Extract common JSX code into a Presentational Component\n  Use the render props pattern for reuse of structure \u0026amp; behavior between React components\n      2. Problem Statement Often we have several React components that share a similar structure or behavior but differ in some significant ways. This is the common DRY (don\u0026#8217;t repeat yourself) principle applied to React components.\n     Don\u0026#8217;t Repeat Yourself (DRY) is a principle of software development aimed at reducing repetition of software patterns, replacing them with abstractions for better organization, maintenance, and code reuse.     Let\u0026#8217;s look at an example:\n  Figure 1. SimpleCounter vs. FancyCounter  How do we DRY up this code and share the common parts between the SimpleCounter and the FancyCounter?\n     You can find the source code for this problem at GitHub repo.       3. Reuse via Presentational Components Often reusing code between components is as simple as creating a presentational component that contains the common behavior and rendering. In the above example we can observe that the 3 buttons for increment, decrement and reset are identical between the counters.\n     Recipe  Identify common JSX code in render methods\n  Move common JSX code into a Presentational Component\n       Let\u0026#8217;s create a new Presentational Component called CounterButtons that contains these 3 buttons.\n CounterButtons.js import React from 'react'; export default ({ count, increment, decrement, reset }) =\u0026gt; [ \u0026lt;button key={1} onClick={decrement} disabled={count===0}\u0026gt;Decrement\u0026lt;/button\u0026gt;, \u0026lt;button key={2} onClick={increment}\u0026gt;Increment\u0026lt;/button\u0026gt;, \u0026lt;button key={3} onClick={reset}\u0026gt;Reset\u0026lt;/button\u0026gt; ];   Now the render method for our SimpleCounter looks like this:\n render method from SimpleCounter.js render() { return ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Simple Counter\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;The count is {this.state.count}\u0026lt;/p\u0026gt; \u0026lt;CounterButtons count={this.state.count} increment={this.increment} decrement={this.decrement} reset={this.reset} /\u0026gt; \u0026lt;/div\u0026gt; ); }     4. Reuse via Inheritance Now that we have the common buttons shared between our counters, we still see that there is still a good bit of duplicated code. Perhaps the most obvious solution would be to refactor the code using Class Inheritance.\n Let\u0026#8217;s try that now.\n     Recipe  Identify React components with common structure\n  Move common structure to a new base / parent class\n  Modify React components to extend the base class\n       Counter.js import React from 'react'; class Counter extends React.Component { constructor(props) { super(props); this.state = { count: 0 }; this.increment = this.increment.bind(this); this.decrement = this.decrement.bind(this); this.reset = this.reset.bind(this); } increment() { this.setState({ count: this.state.count + 1 }); } decrement() { const newValue = Math.max(0, this.state.count - 1); this.setState({ count: newValue }); } reset() { this.setState({ count: 0 }); } } export default Counter;       The Counter class has everything from our SimpleCounter and FancyCounter except for the render methods.     Now our SimpleCounter looks like this:\n SimpleCounter.js import React from 'react'; import CounterButtons from './CounterButtons'; import Counter from './Counter'; class SimpleCounter extends Counter { (1) render() { return ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Simple Counter\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;The count is {this.state.count}\u0026lt;/p\u0026gt; \u0026lt;CounterButtons count={this.state.count} increment={this.increment} decrement={this.decrement} reset={this.reset} /\u0026gt; \u0026lt;/div\u0026gt; ); } } export default SimpleCounter;     1 Here we extend the super class.        You can find the solution using inheritance at [inheritance solution](https://github.com/one-thd/om_labs_react-reuse-counters/tree/solution-inheritance).     4.1. Problems with Inheritance    Using inheritance to share common Component structure and behavior has a few problems:\n   How to share / inherit from multiple Components?\n  ES6 classes (and JS prototypes) do not directly support multiple inheritance (though there are tricks that will get it done).\n     Even in languages with direct support for multiple inheritance, challenges often arise that make reuse difficult.\n  Inheritance for reuse causes the well-known fragile base class problem.\n  Inheritance is good for sharing common structure and overriding behavior, but not so good at sharing common behavior and overriding structure.\n          So What About Inheritance? At Facebook, we use React in thousands of components, and we haven’t found any use cases where we would recommend creating component inheritance hierarchies.\n Props and composition give you all the flexibility you need to customize a component’s look and behavior in an explicit and safe way. Remember that components may accept arbitrary props, including primitive values, React elements, or functions.\n        5. Reuse via HOCs Higher-Order Components, or HOCs, are another strategy for DRYing up common code between components.\n What is an HOC?\n      A higher-order component (HOC) is an advanced technique in React for reusing component logic. HOCs are not part of the React API, per se. They are a pattern that emerges from React’s compositional nature.  \u0026#8212; React Docs       HOCs reuse code using a technique similar to decorators (i.e. the GoF / OOP decorator pattern). You start with the component that defines the bulk of the markup to be rendered and then wrap it inside more components that contain the behavior you’d like to share.\n But really, what is an HOC?\n     Definition: Higher-Order Component A higher-order component (or HOC) is a function that takes a component and returns a new component.\n const EnhancedComponent = higherOrderComponent(WrappedComponent);\n       Let\u0026#8217;s refactor our counters example using an HOC.\n     Recipe  Identify React components with common structure\n  Write an HOC function that wraps the common structure and takes a wrapped Component as an argument. The HOC will render the wrapped component and pass any state or props to the wrapped component.\n  Call the HOC function with the wrapped component as an argument.\n       withCounter.js import React from 'react'; const withCounter = Component =\u0026gt; class extends React.Component { (1) constructor(props) { super(props); this.state = { count: 0 }; this.increment = this.increment.bind(this); this.decrement = this.decrement.bind(this); this.reset = this.reset.bind(this); } increment() { this.setState({ count: this.state.count + 1 }); } decrement() { const newValue = Math.max(0, this.state.count - 1); this.setState({ count: newValue }); } reset() { this.setState({ count: 0 }); } render() { return ( \u0026lt;Component (2) {...this.props} count={this.state.count} increment={this.increment} decrement={this.decrement} reset={this.reset} /\u0026gt; ); } }; export default withCounter;     1 withCounter is a function that takes a Component as an argument and returns a Component.   2 The HOC renders the wrapped Component, passing any needed props.    Now let\u0026#8217;s see what the SimpleCounter looks like after using the HOC:\n SimpleCounter.js import React from 'react'; import PropTypes from 'prop-types'; import CounterButtons from './CounterButtons'; import withCounter from './withCounter'; const SimpleCounter = ({ count, increment, decrement, reset }) =\u0026gt; ( (1) \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Simple Counter\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;The count is {count}\u0026lt;/p\u0026gt; \u0026lt;CounterButtons count={count} increment={increment} decrement={decrement} reset={reset} /\u0026gt; \u0026lt;/div\u0026gt; ); SimpleCounter.propTypes = { (2) count: PropTypes.number.isRequired, increment: PropTypes.func.isRequired, decrement: PropTypes.func.isRequired, reset: PropTypes.func.isRequired }; export default withCounter(SimpleCounter);     1 SimpleCounter is now an arrow function that takes the props it needs from the HOC.   2 We have added the PropTypes to make eslint happy!        You can find the full HOC solution at [HOC solution](https://github.com/one-thd/om_labs_react-reuse-counters/tree/solution-hoc).     5.1. Disadvantages of HOCs   Complexity and indirection - it is often tempting to nest HOCs but things get complicated rather quickly. For example, it can be difficult to determine which HOC is providing which props.\n  Naming collisions - two HOCs that try to use the same prop name will collide and overwrite one another and React won’t warn us about the prop name collision. 😳\n    5.2. For Further Exploration Implement an HOC using React Router\u0026#8217;s withRouter() and some other component.\n    6. Reuse via Render props Render props is a pattern that has recently taken off in the React community. The idea is this: instead of decorating a component (via an HOC) to share behavior, just render a regular component with a function prop (a callback) that can be used to dynamically decide what to render. Any state can be passed to the render prop as function arguments.\n     A render prop is a function prop that a component uses to know what to render.     Let\u0026#8217;s try render props with our counters example.\n     Recipe  Create a generic Component with the common code. One of the props for this Component will be a render callback.\n  Have the specific components render the generic component passing in a render prop.\n       Counter.js import React from 'react'; import PropTypes from 'prop-types'; import CounterButtons from './CounterButtons'; class Counter extends React.Component { constructor(props) { super(props); this.state = { count: 0 }; this.increment = this.increment.bind(this); this.decrement = this.decrement.bind(this); this.reset = this.reset.bind(this); } increment() { this.setState({ count: this.state.count + 1 }); } decrement() { const newValue = Math.max(0, this.state.count - 1); this.setState({ count: newValue }); } reset() { this.setState({ count: 0 }); } render() { return ( \u0026lt;div\u0026gt; {this.props.render(this.state.count)} (1) \u0026lt;CounterButtons count={this.state.count} increment={this.increment} decrement={this.decrement} reset={this.reset} /\u0026gt; \u0026lt;/div\u0026gt; ); } } Counter.propTypes = { render: PropTypes.func.isRequired }; export default Counter;     1 The magic happens here. We call the render prop and pass in any state/props as needed.    Now let\u0026#8217;s see what the SimpleCounter looks like:\n SimpleCounter.js import React from 'react'; import Counter from './Counter'; const render = count =\u0026gt; ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Simple Counter\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;The count is {count}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ); const SimpleCounter = () =\u0026gt; ( \u0026lt;Counter render={render} /\u0026gt; (1) ); export default SimpleCounter;     1 SimpleCounter renders Counter passing it a render prop.        You can find the render props solution at [Render Props Solution](https://github.com/one-thd/om_labs_react-reuse-counters/tree/solution-render-props).     6.1. Advantages of Render Props The advantages of render props over inheritance and HOCs are:\n   Composition - we can use as many render props as we want, as siblings or as nestings, without any additional complexity.\n  Simplicity - we don’t have to wonder where our state or props are coming from. We can see them in the render prop’s argument list.\n  Naming collisions - there is no automatic merging of property names, so there is no chance for a naming collision.\n    6.2. For Further Exploration Explore React Router\u0026#8217;s render prop.\n    7. Reuse via Recompose Recompose is another option that has been gaining favor lately. Recompose is a library for react that really does HOCs but it hides a lot of the HOC complexity from you.\n  \"Recompose is a React utility belt for function components and higher-order components. Think of it like lodash for React.\"\u0026#8201;\u0026#8212;\u0026#8201;recompose GitHub page\n   First, let\u0026#8217;s look at a very simple example:\n JavaScript import React from 'react'; import { withState } from 'recompose'; const withCounting = withState('counter', 'setCounter', 0); (1) const Counter = withCounting( ({ counter, setCounter }) =\u0026gt; (2) \u0026lt;div\u0026gt; Count: {counter} \u0026lt;button onClick={() =\u0026gt; setCounter(n =\u0026gt; n + 1)}\u0026gt;Increment\u0026lt;/button\u0026gt; \u0026lt;button onClick={() =\u0026gt; setCounter(n =\u0026gt; n - 1)}\u0026gt;Decrement\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; );     1 withState returns an HOC that wraps a state variable, sets it to an initial value, and provides a setCounter method that calls this.setState for us.   2 our Counter component is an arrow function passed into withCounter.        Remember that HOCs are functions that take a Component as an argument and returns a Component. Thus withCounter above is an HOC.     Let\u0026#8217;s see how to use recompose for our SimpleCounter and FancyCounter example:\n     Recipe  Become familiar with the recompose api\n  Choose the recompose functions that define the structure of your component\n  Compose your components in terms of the recompose api and your render method\n       withCounting.js import { compose, withState, withHandlers } from 'recompose'; export default compose( (1) withState('count', 'setCount', 0), (2) withHandlers({ (3) increment: ({ setCount }) =\u0026gt; () =\u0026gt; setCount(n =\u0026gt; n + 1), (4) decrement: ({ setCount }) =\u0026gt; () =\u0026gt; setCount(n =\u0026gt; n - 1), reset: ({ setCount }) =\u0026gt; () =\u0026gt; setCount(0) }) );     1 compose is used to combine multiple HOCs   2 withState creates an HOC for our count state   3 withHandlers is used to create an HOC that contains multiple methods   4 increment is a method that takes props and returns a method that we can call. The inner arrow function is an updater function that maps the previous state value to a new state value (see the recompose docs!).        Notice how compose chains HOCs together. In the above example, the setCount method is available to the withHandlers HOC as a prop! All state and props are passed from one HOC to the next via props.     Now our SimpleCounter looks like this:\n SimpleCounter.js import React from 'react'; import PropTypes from 'prop-types'; import CounterButtons from './CounterButtons'; import withCounting from './withCounting'; const SimpleCounter = ({ count, increment, decrement, reset }) =\u0026gt; ( (1) \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Simple Counter\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;The count is {count}\u0026lt;/p\u0026gt; \u0026lt;CounterButtons count={count} increment={increment} decrement={decrement} reset={reset} /\u0026gt; \u0026lt;/div\u0026gt; ); SimpleCounter.propTypes = { (2) count: PropTypes.number.isRequired, increment: PropTypes.func.isRequired, decrement: PropTypes.func.isRequired, reset: PropTypes.func.isRequired }; export default withCounting(SimpleCounter); (3)     1 SimpleCounter is an arrow function that deconstructs the props it needs.   2 We added the PropTypes to make eslint happy!   3 We export the recomposed SimpleCounter.    7.1. Advantages and Disadvantages of recompose recompose is powerful and fun to use. Many of the built-in HOC builders are exactly what you need when coding a React Component, and using recompose can greatly reduce how much code you have to write.\n But recompose is still HOCs and as such may suffer from prop name collisions and even performance issues in some cases (see Performance concerns).\n    8. Summary Code reuse is an important aspect of any software project. When writing React components, we have several options for how to reuse code between similar components. Some of the older techniques such as mixins and higher-order components have fallen out of favor and replaced with the simpler and more powerful techniques of render props and recompose.\n 8.1. Discussion Which of the reuse strategies seem best to you?\n    9. Resources 9.1. HOCs   React Docs: Higher-Order Components\n    9.2. Render Props   I\u0026#8217;m Breaking up with Higher-Order Components\n  Use a Render Prop!\n  Advanced React Component Patterns\n    9.3. Recompose   Recomposing Your React Components\n  Building HOCs with Recompose\n  Why The Hipsters Recompose Everything\n      10. LAB - Movies App Clone the following GitHub repo and refactor the code using any of the above techniques (but definitely try render-props and/or recompose).\n You will want to DRY up the code between the following 3 components (found in src/components):\n   ActorList.js\n  DirectorList.js\n  MovieList.js\n   git clone https://github.com/one-thd/om_labs_react-movies-app-reuse-problem.git\n     Using recompose If you use recompose, you will need to add it as a dependency with:\n yarn add recompose         "
},
{
	"uri": "/golang/api/routing-and-middleware/",
	"title": "Routing &amp; Middleware with Gorilla/Mux",
	"tags": [],
	"description": "",
	"content": "Objectives  Introduce gorilla/mux Discuss when to introduce a web framework Refactor our existing application  Skills  Work with major features of gorilla/mux Gracefully handle URL \u0026amp; query params Easily write middleware  Beyond the Standard Library As you may have noticed, we\u0026rsquo;re starting to run into limitations with the net/http package. In many ways, this is to be expected.\nWhile the Go standard library offers enough functionality to build and ship a production-grade application, it does not easily handle complex routing, and tends to become overly verbose.\nGorilla/Mux If you perform a google search for API/Web-App frameworks, you will find many options. You\u0026rsquo;ll also find lots of opinions on the topic.\nAs with many decisions in software development, it often comes down to choosing the right tool for the job. And we\u0026rsquo;ve reached a point in our application where it\u0026rsquo;s advisable to bring in a more comprehensive solution in the form of Gorilla Web Toolkit\u0026rsquo;s mux package.\nnote: Gorilla Web Toolkit offers a number of packages for building web-based applications. In this course, we\u0026rsquo;re focusing specifically on the mux package.\nAccording to the package overview, gorilla/mux implements the http.Handler  interface and is compatible with http.ServeMux.\nAdditionally the documentation states that, like the standard http.ServeMux, the gorilla mux router matches incoming requests against a list of registered routes. Calling the appropriate handler that matches a given URL.\nOther features of note include:\n Request matching based on URL, path, header query values, HTTP methods, and custom matchers. Ability to evaluate URL hosts, paths and query values variables with a regular expression. Subrouting Capabilities  Nested routes are only tested if the parent route matches. This is useful to define groups of routes that share common conditions like a host, a path prefix or other repeated attributes. As a bonus, this optimizes request matching.     Setup \u0026amp; Refactor Installing gorilla/mux is as simple as running the go get command.\n$ go get github.com/gorilla/mux Setup does not involve much more effort. We\u0026rsquo;ll start by importing the package, and refactoring our existing handlers.\nmain.go\npackage main import ( // ... \t\u0026#34;github.com/gorilla/mux\u0026#34; // 1 \t// ... ) func main() { r := mux.NewRouter() // 2  toolHandlers := tools.Handlers() r.HandleFunc(\u0026#34;/api/tools/\u0026#34;, toolHandlers.Items) // 3 \tr.HandleFunc(\u0026#34;/api/tools\u0026#34;, toolHandlers.Root) // ...  log.Fatal(http.ListenAndServe(\u0026#34;localhost:3000\u0026#34;, r)) // 4 }   Import the gorilla/mux package\n  Instantiate a new router (using gorilla/mux)\n  Use the (new) router\u0026rsquo;s HandleFunc implementation\n  Pass the router as ListenAndServe's second argument\n  Even with the above refactor, we are still able to keep the existing functionality. This is due to the fact that, as previously discussed, gorilla/mux implements the http.Handler interface.\nMatchers \u0026amp; Methods Gorilla/Mux uses the concept of matchers to call the appropriate handler functions in your application. Along with custom matchers, the following matchers are included out-of-the-box:\n Methods - handles http verbs (GET, POST, PATCH, etc.) PathPrefix - looks for a specific prefix: r.PathPrefix(\u0026quot;/foo/\u0026quot;) Schemes - evaluates URL schemes: r.Schemes(\u0026quot;https\u0026quot;) Headers - listens for specific header values: r.Headers('Accept', 'application/json') Queries - checks for query params: r.Queries(\u0026quot;someKey\u0026quot;, \u0026quot;someValue\u0026quot;)  Methods(\u0026quot;GET\u0026quot;) To kick off the bigger portion of our refactor, we\u0026rsquo;ll make use of the Methods matcher. However, let\u0026rsquo;s first modify the Root tools handler.\ntools/handlers.go\n// Index handles GET requests made to the /tools endpoint. // GET /api/tools. func (t *Tools) Index(w http.ResponseWriter, r *http.Request) { w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // Fetch tool data from DB \ttools, err := t.db.All() if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) } // Set status of 200 \tw.WriteHeader(http.StatusOK) // Write JSON to response stream. \tjson.NewEncoder(w).Encode(tools) } Now, in main.go we can clean up the existing handlers and use the Methods matcher. note: for clarity, all other handlers have been removed\nmain.go\n// ... func main() { r := mux.NewRouter() toolHandlers := tools.Handlers() r.HandleFunc(\u0026#34;/api/tools\u0026#34;, toolHandlers.Index).Methods(\u0026#34;GET\u0026#34;) fmt.Println(\u0026#34;API running on port :3000\u0026#34;) log.Fatal(http.ListenAndServe(\u0026#34;localhost:3000\u0026#34;, r)) } All that\u0026rsquo;s left is to test out our new function by making a call to http://localhost:3000/api/tools, which should have retained the existing functionality.\nMethods(\u0026quot;POST\u0026quot;) We can take the remainder of code from the Root tools handler and create a new function for handling POST requests.\ntools/handlers.go\n// Create handles POST requests to the tools endpoint. // POST /api/tools func (t *Tools) Create(w http.ResponseWriter, r *http.Request) { // Set a response header indicating content will be JSON. \tw.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) tool := \u0026amp;db.Tool{} if err := json.NewDecoder(r.Body).Decode(tool); err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) } if err := t.db.Create(tool); err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) } w.WriteHeader(http.StatusCreated) json.NewEncoder(w).Encode(tool) } We\u0026rsquo;ll also need to create a new route in our main function that listens for POST requests.\nmain.go\nfunc main() { // ...  r.HandleFunc(\u0026#34;/api/tools\u0026#34;, toolHandlers.Index).Methods(\u0026#34;GET\u0026#34;) r.HandleFunc(\u0026#34;/api/tools\u0026#34;, toolHandlers.Create).Methods(\u0026#34;POST\u0026#34;) // ... } Issuing a POST request to http://localhost:3000/api/tools should continue to work as expected.\nVars \u0026amp; URL Params Next, we\u0026rsquo;ll create a route for showing individual tools, which leads us into determining how to handle URL parameters. Thankfully, gorilla/mux makes this process significantly easier.\nThis time, we\u0026rsquo;ll start with adding the route to our main function.\nmain.go\nfunc main() { // ... \tr.HandleFunc(\u0026#34;/api/tools\u0026#34;, toolHandlers.Index).Methods(\u0026#34;GET\u0026#34;) r.HandleFunc(\u0026#34;/api/tools\u0026#34;, toolHandlers.Create).Methods(\u0026#34;POST\u0026#34;) r.HandleFunc(\u0026#34;/api/tools/{id}\u0026#34;, toolHandlers.Show).Methods(\u0026#34;GET\u0026#34;) // ... } As you can see above, gorilla/mux allows for dynamic URL params with the {} syntax. In this case, we\u0026rsquo;ll use id as our parameter.\nIn tools/handlers.go we\u0026rsquo;ll need to write a Show method that can work with our URL params. For starters, we\u0026rsquo;ll use the Vars method provided by gorilla/mux.\ntools/handlers.go\nfunc (t *Tools) Show(w http.ResponseWriter, r *http.Request) { vars := mux.Vars(r) fmt.Fprintf(w, \u0026#34;vars: %#v\u0026#34;, vars) } Sending a request to http://localhost:3000/api/tools/1 should result in the following output:\nvars: map[string]string{\u0026#34;id\u0026#34;:\u0026#34;1\u0026#34;} The Vars() method takes a Request as it\u0026rsquo;s argument, and returns the current route params, in the form of a Map. Giving us a simple and reliable way to access URL parameters.\nNow, we can build on this to by using our existing string conversion technique.\nfunc (t *Tools) Show(w http.ResponseWriter, r *http.Request) { vars := mux.Vars(r) id, _ := strconv.Atoi(vars[\u0026#34;id\u0026#34;]) fmt.Fprintf(w, \u0026#34;vars: %#v\\nid: %d\u0026#34;, vars, id) } Making a request to http://localhost:3000/api/tools/5 will result in:\nvars: map[string]string{\u0026#34;id\u0026#34;:\u0026#34;5\u0026#34;} id: 5 All that\u0026rsquo;s left is to implement the existing logic for finding and returning the specified object.\n Lab 01 - Show, Update, Delete Take the existing logic from the Items handler and finish writing methods for handling standard Show, Update, and Delete actions.\n  Checkout the 03-gmux-setup branch\n  Show - finish writing the method\n Return a tool (in JSON format) to the Client Ensure there is proper error handling    Update \u0026amp; Delete\n Add routes in main.go for updating/deleting items Write separate handlers in tools/handlers.go that performs the expected actions    Remove the existing Items handler function\n   Subrouters Often, when building an application, you end up with routes that have similar matchers. Gorilla/Mux offers the additional capability of implementing Subrouters that allow for grouping routes that share the same requirements.\nIn our main function, we can add sets of Subrouters for each set of resources. Let\u0026rsquo;s take a look.\nmain.go\nfunc main() { r := mux.NewRouter() toolHandlers := tools.Handlers() t := r.PathPrefix(\u0026#34;/api/tools\u0026#34;).Subrouter() t.HandleFunc(\u0026#34;\u0026#34;, toolHandlers.Index).Methods(\u0026#34;GET\u0026#34;) t.HandleFunc(\u0026#34;\u0026#34;, toolHandlers.Create).Methods(\u0026#34;POST\u0026#34;) t.HandleFunc(\u0026#34;/{id}\u0026#34;, toolHandlers.Show).Methods(\u0026#34;GET\u0026#34;) t.HandleFunc(\u0026#34;/{id}\u0026#34;, toolHandlers.Update).Methods(\u0026#34;PUT\u0026#34;, \u0026#34;PATCH\u0026#34;) t.HandleFunc(\u0026#34;/{id}\u0026#34;, toolHandlers.Delete).Methods(\u0026#34;DELETE\u0026#34;) // ... } Above, we register a Subrouter with the PathPrefix of /api/tools, and attach our Handler functions to the new instance of Subrouter.\nAs we continue to build the application and add additional resources, we can register new Subrouters.\nFor example:\nfunc main() { r := mux.NewRouter() // ... \tt := r.PathPrefix(\u0026#34;/api/tools\u0026#34;).Subrouter() t.HandleFunc(\u0026#34;\u0026#34;, toolHandlers.Index).Methods(\u0026#34;GET\u0026#34;) // ... \tf := r.PathPrefix(\u0026#34;/api/rentals\u0026#34;) f.HandleFunc(\u0026#34;\u0026#34;, rentalHandlers.MyAction).Methods(\u0026#34;GET\u0026#34;) // ... } The gorilla/mux docs go on to say this about Subrouters:\n Subrouters can be used to create domain or path \u0026ldquo;namespaces\u0026rdquo;: you define subrouters in a central place and then parts of the app can register its paths relatively to a given subrouter.\n This allows for interesting solutions that produce clean code that is easy to reason-about.\nMiddleware Gorilla/Mux also offers middleware that requires minimal setup. The docs state the following about middleware:\n Mux supports the addition of middlewares to a Router, which are executed in the order they are added if a match is found, including its subrouters. Middlewares are (typically) small pieces of code which take one request, do something with it, and pass it down to another middleware or the final handler.\n The signature for middleware is as follows:\ntype MiddlewareFunc func(http.Handler) http.Handler The MiddlewareFunc takes a Handler and returns a Handler\nTo demonstrate, we\u0026rsquo;ll create a simple middleware to always set our Content-Type headers to application/json\nmain.go\nfunc main() { // ... } func setContentTypeHeaders(next http.Handler) http.Handler { // 1 \treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { // 2 \tw.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // 3 \tnext.ServeHTTP(w, r) // 4 \t}) }  Take a single argument of the next Handler in the stack Return a Handler Function (as a closure) Set the Headers Pass the ResponseWriter and Request object along to the next function.  To activate the middleware, we can wrap our existing route Handler.\nlog.Fatal(http.ListenAndServe(\u0026#34;localhost:3000\u0026#34;, setContentTypeHeaders(r))) Now, on each request, the content headers will be set to send JSON to the client.\nAll together our main function should resemble the following:\nmain.go\n// ... func main() { r := mux.NewRouter() toolHandlers := tools.Handlers() t := r.PathPrefix(\u0026#34;/api/tools\u0026#34;).Subrouter() t.HandleFunc(\u0026#34;\u0026#34;, toolHandlers.Index).Methods(\u0026#34;GET\u0026#34;) t.HandleFunc(\u0026#34;\u0026#34;, toolHandlers.Create).Methods(\u0026#34;POST\u0026#34;) t.HandleFunc(\u0026#34;/{id}\u0026#34;, toolHandlers.Show).Methods(\u0026#34;GET\u0026#34;) t.HandleFunc(\u0026#34;/{id}\u0026#34;, toolHandlers.Update).Methods(\u0026#34;PUT\u0026#34;, \u0026#34;PATCH\u0026#34;) t.HandleFunc(\u0026#34;/{id}\u0026#34;, toolHandlers.Delete).Methods(\u0026#34;DELETE\u0026#34;) fmt.Println(\u0026#34;API running on port :3000\u0026#34;) log.Fatal(http.ListenAndServe(\u0026#34;localhost:3000\u0026#34;, setContentTypeHeaders(r))) } func setContentTypeHeaders(next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) next.ServeHTTP(w, r) }) } The final step is to remove the individual calls to w.Header().Set() in our handlers, and verify that our application is working as expected.\nLab 02 - Write a Logger Middleware Using the strategy above, write a logger middleware that outputs data about the Request object.\n Checkout the 04-subroutes-and-middleware branch Log the Request Method Log the Request URL Add this new middleware to the callstack  The output should resemble the following:\nRequest Method: PATCH Request URL: /api/tools/12  Queries We can use the built-in Queries method to handle query params. Queries takes arguments in the form of key/value pairs.\nr.Queries(\u0026#34;key\u0026#34;, \u0026#34;{value}\u0026#34;) Using this strategy, we can reinstate the sort query param.\nmain.go\n// .. func main() { // ... \tt.HandleFunc(\u0026#34;\u0026#34;, toolHandlers.Index).Methods(\u0026#34;GET\u0026#34;) t.HandleFunc(\u0026#34;\u0026#34;, toolHandlers.Index).Methods(\u0026#34;GET\u0026#34;).Queries(\u0026#34;sort\u0026#34;, \u0026#34;{sort}\u0026#34;) // ... } // .. And if the code is run now \u0026hellip;, OH NO There\u0026rsquo;s nothing in the map created by mux.Vars(r).\nOrder Matters Above, we\u0026rsquo;ve created an additional handler to listen specifically for query params.\nOrder here matters! Because they have the same initial pattern, the first will be matched. We would always match on the non-queries handler first.\nIf we swap them as in the following, we\u0026rsquo;ll get our expected result.\n// .. func main() { // ... \tt.HandleFunc(\u0026#34;\u0026#34;, toolHandlers.Index).Methods(\u0026#34;GET\u0026#34;).Queries(\u0026#34;sort\u0026#34;, \u0026#34;{sort}\u0026#34;) t.HandleFunc(\u0026#34;\u0026#34;, toolHandlers.Index).Methods(\u0026#34;GET\u0026#34;) // ... } // .. Now, we can make use of the Vars method in our Index handler to gain access to our key/value pairs\ntools/handers.go\nfunc (t *Tools) Index(w http.ResponseWriter, r *http.Request) { tools, err := t.db.All() // ...  vars := mux.Vars(r) if vars[\u0026#34;sort\u0026#34;] == \u0026#34;asc\u0026#34; { sort.SliceStable(tools, func(i, j int) bool { return tools[i].Price \u0026lt; tools[j].Price }) } if vars[\u0026#34;sort\u0026#34;] == \u0026#34;desc\u0026#34; { sort.SliceStable(tools, func(i, j int) bool { return tools[i].Price \u0026gt; tools[j].Price }) } // ... } Sending requests to the following endpoints should result in a different order for each request:\n http://localhost:3000/api/tools http://localhost:3000/api/tools?sort=asc http://localhost:3000/api/tools?sort=desc  Conclusion In this lesson, we\u0026rsquo;ve covered some of the major features of gorilla/mux, and found that it\u0026rsquo;s a solid library for building API\u0026rsquo;s in Go. It\u0026rsquo;s worth noting that in addition to the net/http package and gorilla/mux, there are a number of excellent libraries and frameworks for web development with Go. Check out the Additional Resources section below for a short list.\nAdditional Resources  net/http Gorilla/Mux Buffalo Gin httprouter  "
},
{
	"uri": "/cyber-security/static-dynamic-analysis/2-sast-overview-tools/",
	"title": "SAST Overview and Tools",
	"tags": [],
	"description": "",
	"content": "Overview Scanning your applications is vital to ensure security. In this chapter we will introduce the tools you will be performing to scan your code for vulnerabilities.\nPurpose\nScanning performs an automated, security-focused code review. It analyzes inputs, outputs and the data flow in between. This provides an insider perspective, meaning it can see the code from the inside out to give you insights on where there might be vulnerabilities. This acts as a conversation starter, giving you a perspective on the security of your code that you can discuss with your team.\nLimitations While scanning can identify vulnerabilities it cannot fix them. It also cannot tell you if a vulnerability has been or will be exploited.\nCadence Scanning on a regular basis is necessary to ensure that your application is secure. This is because changing a big part of code can introduce vulnerabilities, and even in legacy code new vulnerabilities can be discovered.\nWhen you should scan:\n Significant change in the code. Active development—at least once per sprint. Legacy code—at least once a year.  YOU are responsible for timely scanning.\nTools Viper: Viper is an in-house orchestration tool for requesting scans.\nFortify: Market leader in static analysis. This is our primary scanning technology, it works by compiling submitted code and then analyzing it.\nLanguages:\n          .NET/Core Apex ASP.NET   Bytecode C# COBOL   GoLang HTML Java   Javascript JSP Kotlin   MXML (Flex) PHP PL/SQL   Python Ruby Scala   VB.NET VBScript Visual Basic   XML      Checkmarx: This tool provides coverage for certain versions of C, C++ and Objective C that fortify does not. Instead of compiling the source code like Fortify it will analyze the raw source code.\nLanguages:\n C C++ Objective C  Whitesource: Open source analysis. This tool scans third party libraries for known vulnerabilities. Happens automatically with Fortify.\nWorkflow Now that we have been introduced to the tools, lets look at how they fit together into a basic workflow.\n  "
},
{
	"uri": "/software-eng-essentials/looker/scheduling/",
	"title": "Scheduling",
	"tags": [],
	"description": "",
	"content": "This lesson will cover the basics of scheduling reports in Looker.\nObjectives  How to send reports  Scheduling It is possible to schedule ahead of time when a Look or Dashboard is run and delivered to any integrated services that are available for a Looker instance.\n Development Mode must be turned off to enable these scheduling options.\n Depending on how Looker admins have set up permissions for data delivery, it is possible to deliver via:\n email a webhook Slack an SFTP server   To schedule in a dashboard, click on the settings gear in top right corner of the screen.\nTo find out what scheduling set up works for a particular situation, use this graphic from Google.\n Entire Dashboard The following steps show how to schedule a daily report of the entire dashboard.\nClick on Settings (the 3 dots in the top right corner) \u0026gt; Schedule Delivery.\n  This will pop up either an existing schedules window appears or a schedule and send window appears, depending on whether or not an already created existing schedules on the dashboard.\nNote that there are three tabs in this window:\n Settings: allows for the customization of recurrence, destination, format, filters, and more. Filters: shows any filters applied to the dashboard as well as their values. Here is possible to edit the values for any existing filters applied to the dashboard and the new values will be applied to the delivery. The dashboard itself will not be affected. Advanced Options: provides additional customization for a delivery. The options available depend on the selected destination and format of a delivery.  Example: THD Schedule Entire Dashboard Report Here we are going to practice scheduling a delivery from our dashboard.\nTo access the dashboard created in the previous example:\n Go to the Browse menu at the top Click on your personal folder, then to the Intro to Looker folder, then click on CF APP LOGS Make sure you are not in Edit mode in the CF APP LOGS dashboard created in the above examples. Click on Settings \u0026gt; Schedule Delivery. Fill in the Email addresses textbox in the Setting tab with your THD email. Click Test now. Within a couple of minutes you should receive an email with a PDF attached with the contents of the dashboard.  For this example, go ahead and click Cancel instead of Save so that you do not receive daily emails about this demo dashboard.\nSingle Tile Alert When hovering over a tile in a dashboard, a bell icon with a + on it appears at the top right of the tile. This is called an alert.\nOnce an alert for a tile is selected, a window pops up with alert configurations:\n specific conditions the alert should be sent on where and how to send it the frequency of which this alert should be sent  Example: THD Schedule Tile Alert Here we are going to practice setting up an alert on a tile in a dashboard.\n Get out of Edit mode in the CF APP LOGS dashboard created in the above examples. Hover over the Current Hour Discount Counts tile and click on the bell Alert button. Change the condition of the alert to Distinct Count is greater than 20000. Fill in the Email addresses textbox in the Setting tab with your THD email. Click Save Alert.  This will pop up a window that will show the newly created alert along with any previously created alerts for this tile.\nThis example was simply for demo purposes, make sure to delete the alert by clicking on the three dots next to the alert and click Delete:\n  Summary This lesson covered basic usage for Looker for scheduling notifications\n"
},
{
	"uri": "/software-eng-essentials/agile-lean/scrum_and_kanban/",
	"title": "Scrum &amp; Kanban",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Describe the Scrum Process and sprints Describe the Kanban Process and pull Compare Scrum and Kanban List and describe the Agile ceremonies commonly used in Agile Development Describe Scrum and Kanban Boards  What are Scrum and Kanban? Scrum and Kanban are two different strategies for implementing an agile development or project management system.\n Scrum is based on short, structured work sprints that provide working software for review. Kanban is based on a continuous flow of work that provides working software for review.  Scrum Scrum teams commit to shipping working software through set intervals called sprints.\n A sprint is a short, time-boxed period to complete a set amount of work. The goal is to create learning loops to quickly gather and integrate customer feedback. Scrum teams adopt specific roles, create special artifacts, and hold regular ceremonies to keep things moving forward. Scrum is best defined in The Scrum Guide.  Agile Ceremonies Backlog Grooming The product owner will have a prioritized product backlog.\nDuring grooming the following takes place:\n Each item is discussed with the development team. The group collectively estimates the effort involved (using a point system called story points). That body of work is known as stories, which then become the sprint backlog.  Daily Standup The daily standup is designed to quickly inform everyone of what\u0026rsquo;s going on across the team.\n It\u0026rsquo;s called a \u0026ldquo;standup\u0026rdquo; because traditionally the team is standing in a circle during this meeting.  standing indicates that the meeting should be short - perhaps 5 to 10 minutes   It\u0026rsquo;s not a detailed status meeting. Each team member answers the following questions:  What did I do yesterday? What will I be doing today? Am I blocked by anything?    Sprint Review The sprint review is an opportunity for the team and the stakeholders to review the work completed in the sprint and how that work integrates with the product as a whole.\nDuring the Sprint Review the team and the stakeholders can question anything about the product and discuss ideas for moving forward.\nRetrospective Agile is about getting rapid feedback to make the product and the development culture better.\nRetrospectives allow the team to have an internal (team only) meeting where praise and concerns can be discussed in a safe environment.\nRetrospectives enable continuous improvement by providing an opportunity for the team to:\n understand what worked well and what didn\u0026rsquo;t discuss opportunities for improvement identify creative solutions develop an action plan.  Continuous improvement is what sustains and drives development within an agile team, and retrospectives are a key part of that.\nKanban Kanban is a Lean Method that emphasizes continuous flow, value streams, and identifying and removing waste.\nWith Kanban issues enter the queue and then get “pulled” through a series of steps in the development process.\nKanban emphasizes:\n visualizing your work (via information radiators such as Kanban Boards and other visualization tools) limiting work in progress (WIP) to balance demands with available capacity maximizing efficiency (or flow) by continuously identifying and removing waste pulling in work only when needed (just-in-time or JIT) to maximize value to the customer      Understanding Pull A good way to understand pull is to consider various ways that restaurants prepare food:\n  Question: Can you think of ways that restaurants use push and pull?    pull - food is prepared just-in-time based on exactly what the customer has ordered push - food is prepared ahead of time (such as fast food or a buffet); thus assumptions are made for the type and quantity of food that will be desired    An Example From Dell Computers Many years ago, Dell Computers revolutionized the production and delivery of personal computers by:\n Building each computer to the specifications of the customer\u0026rsquo;s order Purchasing the parts for each computer just-in-time (when the order was submitted) Thus keeping almost zero inventory    Question: Why was this revolutionary?   Because:\n Computer parts, especially CPUs, memory, and graphics cards, were getting faster and cheaper every week (volatility). Dell found a competitive edge by always providing the best (fastest and cheapest) parts by eliminating their inventory.  Inventory was waste because the components became obsolete so quickly. Selling inventory at reduced prices was not financially feasible because the industry was very competitive and profit margins were too thin.   Therefore Dell was beating the competition by removing the waste of keeping inventory and purchasing components and building computers just-in-time - a pull system.\n  Scrum Boards vs. Kanban Boards Scrum and Kanban boards are similar as they both contain the following elements:\n Cards - represent a user story Columns - represent a specific activity and together compose a workflow. For example, \u0026ldquo;To do\u0026rdquo;, \u0026ldquo;In Progress\u0026rdquo; and \u0026ldquo;Complete\u0026rdquo;  The main difference is that Kanban boards have WIP (Work In Progress) Limits that limit the maximum number of cards that can be on each column at any given time, optimizing flow and reducing bottlenecks.\nScrum Boards on the other hand do not have WIP limits but instead have a set start and end date for the work to be completed.\n Summary  Scrum balances adapting to change with stability via a time-boxed \u0026ldquo;sprint\u0026rdquo; to ensure that work is prioritized and focused. Kanban focuses on maximizing the value stream and eliminating waste via visualization and limiting WIP.  Some of their high level differences are:\n   Aspect Scrum Kanban     Cadence Regular fixed length (Normally 2 weeks) Continuous flow   Release At end of sprint Continuous delivery   Roles Product Owner, Scrum master, dev team No required roles   Key Metrics Velocity Lead time, cycle time, WIP   Change Philosophy Teams should not make changes during sprint Change can happen at anytime    Also, Kanban has fewer ceremonies than Scrum:\nCeremonies Breakdown:\n   Name Scrum Kanban     Backlog Grooming Yes Yes   Sprint Planning Yes No   Daily Standup Yes Yes   Sprint Review Yes When Needed   Retrospective Yes Yes    Keep in mind that:\n both Scrum and Kanban are agile methodologies that can be adapted to fit a team\u0026rsquo;s specific needs they are tools in a team\u0026rsquo;s toolbox Scrum provides more structure while Kanban is more flexible some work may be better managed using Scrum with sprints and other work may be better managed as a continuous, prioritized flow using a Kanban approach  Ultimately we want to:\n Identify and prioritize the work needed Get continuous feedback from stakeholders Make changes as needed to minimize the risk of building the wrong thing  Additional Resources  Learn about Agile The Agile Manifesto Differences between Scrum and Kanban The Scrum Guide So Long Scrum, Hello Kanban  "
},
{
	"uri": "/web-essentials/webmastery-foundations/selectors-and-specificity/",
	"title": "Selectors and Specificity",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Explain the concept of CSS specificity Define \u0026ldquo;cascading\u0026rdquo; in the context of CSS specificity  Skills  Use CSS selectors to style an HTML page Use CSS specificity to apply CSS rules to specific HTML elements  Introduction Since HTML elements can have both a type (the tag) and several attributes (such as an id, a class, or a set of classes), we can use these types and attributes to select a specific DOM node or a set of specific DOM nodes.\nLet\u0026rsquo;s look at an example:\n\u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello world!\u0026lt;/h1\u0026gt; \u0026lt;!--1--\u0026gt; \u0026lt;p\u0026gt;This is some fake dummy content. It doesn\u0026#39;t matter what it is! Whatever you want!\u0026lt;/p\u0026gt; \u0026lt;!--2--\u0026gt; \u0026lt;p class=\u0026#34;red\u0026#34;\u0026gt;This paragraph has a class of \u0026#34;red\u0026#34;\u0026lt;/p\u0026gt; \u0026lt;!--2--\u0026gt; \u0026lt;p class=\u0026#34;red\u0026#34; id=\u0026#34;green\u0026#34;\u0026gt;This paragraph has an id of \u0026#34;green\u0026#34;\u0026lt;/p\u0026gt; \u0026lt;!--2--\u0026gt; \u0026lt;div class=\u0026#34;red\u0026#34;\u0026gt;This div has a class of \u0026#34;red\u0026#34;\u0026lt;/div\u0026gt; \u0026lt;!--3--\u0026gt; \u0026lt;/body\u0026gt;  an h1 element 3 p elements: 2 have the the CSS class of red and 1 has an id value of green a div with the CSS class of red  The following makes all elements with a class of \u0026ldquo;red\u0026rdquo; have a background of red:\n.red { background: red; } The following makes just the \u0026lt;p\u0026gt; elements with that class name to have a background of red:\np.red { background: red; } The following uses the id selector (#) to set the background color of the p element that have a class of \u0026ldquo;green\u0026rdquo;:\np.red { background: red; } #green { background: green; } The above example can be found at this codepen.\nCSS Specificity If the css selector is changed from p.red back to .red, the \u0026lt;p\u0026gt; element with the id of green is still green. This is because of CSS Specificity. While CSS rules cascade from top to bottom. The CSS that is applied depends on specificity as well.\nTake the following example:\n#green { background: green; } .red { background: blue; } .red { background: red; } In this example, the elements that have the class red will have a background of red even though blue was set first because it takes the last declared property.\nHowever, even though the #green selector was written first, it has a higher specificity and therefore overrides the following background properties.\nCommon Selectors The following list of selector types is in order by increasing specificity\nuniversal  Syntax: * Example HTML: \u0026lt;p\u0026gt;A short paragraph\u0026lt;/p\u0026gt; Example CSS:  * { color: black; } type  Syntax: p Example HTML: \u0026lt;p\u0026gt;A short paragraph\u0026lt;/p\u0026gt; Example CSS:  p { color: blue; } class  Syntax: . Example HTML: \u0026lt;h1 class=\u0026quot;weather\u0026quot;\u0026gt;Today's Weather\u0026lt;/h1\u0026gt; Example CSS:  .weather { color: red; } attribute  Syntax: [key=\u0026quot;value\u0026quot;] Example HTML: \u0026lt;button type=\u0026quot;radio\u0026quot;\u0026gt;Click Me!\u0026lt;/button\u0026gt; Example CSS:  [type=\u0026#34;radio\u0026#34;] { color: green; } Pseudo-classes  Syntax: :hover Example HTML: \u0026lt;div\u0026gt;Hover Over Me!\u0026lt;/div\u0026gt; Example CSS:  :hover { background-color: purple; } id  Syntax: # Example HTML: \u0026lt;h1 id=\u0026quot;weather\u0026quot;\u0026gt;Today's Weather\u0026lt;/h1\u0026gt; Example CSS:  #weather { color: red; } Inline style Example: \u0026lt;p style=\u0026quot;color: magenta\u0026quot;\u0026gt;Hello\u0026lt;/h1\u0026gt;\nThe Descendant Selector and the Adjacent Selector Multiple selectors can be combined in different ways. For example, given the following HTML code:\n\u0026lt;p class=\u0026#34;news\u0026#34;\u0026gt;News\u0026lt;/p\u0026gt; \u0026lt;article class=\u0026#34;weather\u0026#34;\u0026gt; \u0026lt;p\u0026gt;Today\u0026#39;s Weather\u0026lt;/p\u0026gt; \u0026lt;button\u0026gt;Radar Map\u0026lt;/button\u0026gt; \u0026lt;button\u0026gt;Weather Alerts\u0026lt;/button\u0026gt; \u0026lt;/article\u0026gt; And apply the following CSS:\np.news { // 1 color: blue; } article p { // 2 color: green; } button { // 3 color: white; background-color: blue; } button + button { // 4 margin-left: 20px; } We have selected the following:\n the 1st paragraph is selected using both the type selector and the class selector the 2nd paragraph is selected using the descendant selector both buttons are selected with the type selector the 2nd button is selected using the adjacent selector  The above example can be found at this codepen\nThe !important Exception When an !important rule is used on a style declaration, this declaration overrides any other declarations. Although technically !important has nothing to do with specificity, it interacts directly with it.\nExample of !important to overriding the color of H1\nh1 { color: blue !important; /* I **REALLY** want them to be BLUE!!! */ } When two conflicting declarations with the !important rule are applied to the same element, the declaration with a greater specificity will be applied.\n Sometimes it is necessary to use !important when you want to customize the CSS of a external stylesheet. But beware of using !important as it is considered a bad practice and should be avoided whenever possible. This is because it breaks the natural cascading in your stylesheets.\n Always look for a way to use specificity before even considering !important Only use !important on page-specific CSS that overrides foreign CSS (from external libraries, like Bootstrap or normalize.css).   Summary  CSS styles are applied to HTML elements via CSS selectors. Common CSS selectors are the tag, id, and class selectors. When 2 or more CSS styles with different selectors match a specific HTML element, the CSS style with the greater specificity wins.  the id selector has the largest specificity, followed by the class and the tag selectors. combining selectors increases their specificity. For example h2.red has a higher specificity than both h2 and .red. When desperate measures are needed, you can use the !important exception to force a CSS rule to be applied.       Go to Selectors and Specificity Labs    "
},
{
	"uri": "/javascript/performance/universal-rendering-lab/step-2/",
	"title": "Step 2: Render the App markup to a string",
	"tags": [],
	"description": "",
	"content": "  In the request handler that we just created, there is a portion of the string where we define the \u0026ldquo;root\u0026rdquo; element of our application: \u0026lt;div id=\u0026quot;root\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;. Locate this element within src/server/app.js\n  Use renderToString from the react-dom/server package to render the markup for our application on the server: https://reactjs.org/docs/react-dom-server.html#rendertostring. Pass our \u0026lt;App /\u0026gt; component to renderToString. Note that \u0026lt;App /\u0026gt; is JSX, and thus compiles to React.createElement(App, null). This means that we will need to import React: import React from 'react';\n  Using template literal notation, insert the output of renderToString between the opening and closing tags of the \u0026ldquo;root\u0026rdquo; element (\u0026lt;div id=\u0026quot;root\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;) that we located in \u0026ldquo;Step 1\u0026rdquo;.\n  Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and you should now see the app render again, rather than a blank screen.\n  But there is one problem. Remember how our application used to load all of the markets? Those seem to be missing now\u0026hellip;\nWhy aren\u0026rsquo;t the markets getting populated anymore? Have a close look at src/client/components/MarketList.jsx for the answer.\n"
},
{
	"uri": "/react/performance/universal-rendering-lab/step-2/",
	"title": "Step 2: Render the App markup to a string",
	"tags": [],
	"description": "",
	"content": "  In the request handler that we just created, there is a portion of the string where we define the \u0026ldquo;root\u0026rdquo; element of our application: \u0026lt;div id=\u0026quot;root\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;. Locate this element within src/server/app.js\n  Use renderToString from the ReactDOMServer package to render the markup for our application on the server: https://reactjs.org/docs/react-dom-server.html#rendertostring. Pass our \u0026lt;App /\u0026gt; component to renderToString. Note that \u0026lt;App /\u0026gt; is JSX, and thus compiles to React.createElement(App, null). This means that we will need to import React: import React from 'react';\n  Using template literal notation, insert the output of renderToString between the opening and closing tags of the \u0026ldquo;root\u0026rdquo; element (\u0026lt;div id=\u0026quot;root\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;) that we located in \u0026ldquo;Step 1\u0026rdquo;.\n  Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and you should now see the app render again, rather than a blank screen.\n  But there is one problem. Remember how our application used to load all of the markets? Those seem to be missing now\u0026hellip;\nWhy aren\u0026rsquo;t the markets getting populated anymore? Have a close look at src/client/components/MarketList.jsx for the answer.\n"
},
{
	"uri": "/javascript/foundations/labs/strings-lab/",
	"title": "Strings Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch strings.js Add the following code to strings.js:\n// Part 1: const x = 3; const y = 5; // TODO: refactor the following string to use a String Template const mathString = \u0026#34;The value of \u0026#34; + x + \u0026#34; + \u0026#34; + y + \u0026#34; = \u0026#34; + (x + y); console.log(mathString); // Part 2: const name = \u0026#34;Homer D. Poe\u0026#34;; const age = 40; // TODO: refactor the following string to use a String Template const greeting = \u0026#34;Hello, my name is \u0026#34; + name + \u0026#34;!\\nI am \u0026#34; + age + \u0026#34; years old.\u0026#34;; console.log(greeting); // prints // Hello, my name is Homer D. Poe! // I am 40 years old. Step 2: Complete the code and test Complete the TODOs in the above code.\nTest your solution with:\nnode strings.js The expected output is:\nThe value of 3 + 5 = 8 Hello, my name is Homer D. Poe! I am 40 years old. "
},
{
	"uri": "/javascript/nodejs/testing/",
	"title": "Testing",
	"tags": [],
	"description": "",
	"content": "Welcome to Testing in JavaScript! "
},
{
	"uri": "/python/nonrelational-db/testing/",
	"title": "Testing Database Interactions",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Testing database interactions using the Pytest Library  Testing Cassandra Interactions For testing with Cassandra, we are going to use the same SQL set up script as the Cassandra labs. Download script here We will be using this script to help set up the database environment before each test. We will use a local database to test Cassandra database interactions.\nSet Up To make sure the database environment is set up correctly for every test, we are going to use a pytest fixture decorator.\nContents of test_cassandra_connect.py\nimport pytest from cassandra.cluster import Cluster @pytest.fixture def db_connect(): import os os.system(\u0026#34;cqlsh -f seeds.cql\u0026#34;) cluster = Cluster() return cluster.connect(\u0026#39;test_thd_stores\u0026#39;) A pytest fixture will connect to the Cassandra server and delete the test_thd_stores database when all test are completed.\n@pytest.fixture def db_tear_down(): cluster = Cluster() cluster.connect(\u0026#39;test_thd_stores\u0026#39;) return client.execute(\u0026#39;DROP KEYSPACE IF EXISTS test_thd_stores;\u0026#39;) The fixture db_tear_down is called as an argument in the test_clean method.\ndef test_clean(db_tear_down): return db_tear_down Testing Methods Using pytest parameterized tests, we are going to test functions with multiple test conditions.\nFor testing create_collections(), parameterized test will check what happens when different inputs, valid and invalid, are used.\ntest_scenarios = [(\u0026#34;Texas\u0026#34;,11),(\u0026#34;Georgia\u0026#34;,1), (\u0026#34;Colorado\u0026#34;, 1)] #1 @pytest.mark.parametrize(\u0026#34;state,expect\u0026#34;, test_scenarios) #2 def test_create_collection(db_connect, state, expect): stmt = db_connect.prepare(\u0026#34;SELECT address FROM stores WHERE state=? allow filtering;\u0026#34;) rows = db_connect.execute(stmt, (state,)) count = 0 for row in rows: count += 1 assert count == expect #3  Holds the test inputs and outputs for the test Passing the test scenarios Checking if the number of rows returned match what is expected  Run the test using pytest test_cassandra_connect.py -v. Each test case in the parameterized test is ran and reported separately.\nTesting MongoDB Interactions For testing, tests will focus on the methods that were created in the MongoConnect, in particular those that interact with the database.\nA local database will be used with a small subset of data. In the lab repo, in the mongodb-python directory, the file mongo_test_set_up.py will create and seed the database prior to testing.\nThe file contains the method db_set_up() that will be called before each test, to ensure the test is using fresh data and is not dependent on the the previous test.\ndef db_set_up(): test_trucks = [{\u0026#34;truck_number\u0026#34;:907,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Nelly\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Minghetti\u0026#34;,\u0026#34;delivery_stops\u0026#34;:18,\u0026#34;region\u0026#34;:3}, {\u0026#34;truck_number\u0026#34;:421,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Avictor\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Dulwich\u0026#34;,\u0026#34;delivery_stops\u0026#34;:19,\u0026#34;region\u0026#34;:2}, {\u0026#34;truck_number\u0026#34;:208,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Nicolea\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Stanbury\u0026#34;,\u0026#34;delivery_stops\u0026#34;:15,\u0026#34;region\u0026#34;:1}, {\u0026#34;truck_number\u0026#34;:784,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Emelia\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Gronw\u0026#34;,\u0026#34;delivery_stops\u0026#34;:9,\u0026#34;region\u0026#34;:4}, {\u0026#34;truck_number\u0026#34;:249,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Tanitansy\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Blomefield\u0026#34;,\u0026#34;delivery_stops\u0026#34;:9,\u0026#34;region\u0026#34;:5}, {\u0026#34;truck_number\u0026#34;:631,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Tammy\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Embleton\u0026#34;,\u0026#34;delivery_stops\u0026#34;:12,\u0026#34;region\u0026#34;:3}, {\u0026#34;truck_number\u0026#34;:937,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Daphne\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Hadden\u0026#34;,\u0026#34;delivery_stops\u0026#34;:11,\u0026#34;region\u0026#34;:3}, {\u0026#34;truck_number\u0026#34;:707,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Tommy\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Bedward\u0026#34;,\u0026#34;delivery_stops\u0026#34;:18,\u0026#34;region\u0026#34;:2}, {\u0026#34;truck_number\u0026#34;:748,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Tessa\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Folke\u0026#34;,\u0026#34;delivery_stops\u0026#34;:17,\u0026#34;region\u0026#34;:3}, {\u0026#34;truck_number\u0026#34;:927,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Pavlov\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Starsmeare\u0026#34;,\u0026#34;delivery_stops\u0026#34;:3,\u0026#34;region\u0026#34;:3}, {\u0026#34;truck_number\u0026#34;:840,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Wanids\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Gowdie\u0026#34;,\u0026#34;delivery_stops\u0026#34;:4,\u0026#34;region\u0026#34;:3}, {\u0026#34;truck_number\u0026#34;:596,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Katti\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Haimes\u0026#34;,\u0026#34;delivery_stops\u0026#34;:20,\u0026#34;region\u0026#34;:1}, {\u0026#34;truck_number\u0026#34;:812,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Ester\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Brogiotti\u0026#34;,\u0026#34;delivery_stops\u0026#34;:6,\u0026#34;region\u0026#34;:1}, {\u0026#34;truck_number\u0026#34;:301,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Fanni\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;O\u0026#39;Dea\u0026#34;,\u0026#34;delivery_stops\u0026#34;:14,\u0026#34;region\u0026#34;:4}, {\u0026#34;truck_number\u0026#34;:295,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Lindy\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Enright\u0026#34;,\u0026#34;delivery_stops\u0026#34;:4,\u0026#34;region\u0026#34;:5}, {\u0026#34;truck_number\u0026#34;:720,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Khalil\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Claris\u0026#34;,\u0026#34;delivery_stops\u0026#34;:15,\u0026#34;region\u0026#34;:5}, {\u0026#34;truck_number\u0026#34;:872,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Terrance\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Ondracek\u0026#34;,\u0026#34;delivery_stops\u0026#34;:3,\u0026#34;region\u0026#34;:5}, {\u0026#34;truck_number\u0026#34;:507,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Mag\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Whiteman\u0026#34;,\u0026#34;delivery_stops\u0026#34;:14,\u0026#34;region\u0026#34;:3}, {\u0026#34;truck_number\u0026#34;:916,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Davy\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;McMenamin\u0026#34;,\u0026#34;delivery_stops\u0026#34;:13,\u0026#34;region\u0026#34;:1}, {\u0026#34;truck_number\u0026#34;:829,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Berty\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Filipic\u0026#34;,\u0026#34;delivery_stops\u0026#34;:18,\u0026#34;region\u0026#34;:2}, {\u0026#34;truck_number\u0026#34;:135,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Corly\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Badman\u0026#34;,\u0026#34;delivery_stops\u0026#34;:1,\u0026#34;region\u0026#34;:3}, {\u0026#34;truck_number\u0026#34;:890,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Stormi\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Shurrocks\u0026#34;,\u0026#34;delivery_stops\u0026#34;:6,\u0026#34;region\u0026#34;:4}, {\u0026#34;truck_number\u0026#34;:667,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Kathlin\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Wraith\u0026#34;,\u0026#34;delivery_stops\u0026#34;:11,\u0026#34;region\u0026#34;:5}, {\u0026#34;truck_number\u0026#34;:756,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Lib\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Clowney\u0026#34;,\u0026#34;delivery_stops\u0026#34;:11,\u0026#34;region\u0026#34;:5}, {\u0026#34;truck_number\u0026#34;:487,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Kyle\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Curthoys\u0026#34;,\u0026#34;delivery_stops\u0026#34;:7,\u0026#34;region\u0026#34;:1}, {\u0026#34;truck_number\u0026#34;:545,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Joletta\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;La Grange\u0026#34;,\u0026#34;delivery_stops\u0026#34;:12,\u0026#34;region\u0026#34;:4}, {\u0026#34;truck_number\u0026#34;:955,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Blake\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Strattan\u0026#34;,\u0026#34;delivery_stops\u0026#34;:1,\u0026#34;region\u0026#34;:4}] The code below takes care of all the actions needed to test out MongoConnect class, using only methods from pymongo.\n#Create the client client = pymongo.MongoClient(\u0026#34;mongodb://localhost:27017/\u0026#34;) #drop database if it exists to have clean data each time client.drop_database(\u0026#34;test_trucks\u0026#34;) #Create the database test_db = client[\u0026#34;test_trucks\u0026#34;] #Create the collection  collection = test_db[\u0026#34;trucks\u0026#34;] #Insert test data new_trucks = collection.insert_many(test_trucks) #print list of added trucks print(f\u0026#34;Set up successful! {len(new_trucks.inserted_ids)} were trucks added to the trucks collection in the test_trucks database\u0026#34;) In lab repo, open the file testing_mongo_connect.py.\n#...other imports from mongo_connect import MongoConnect #1 import mongo_test_set_up as su #2 import pytest #3  Imports the class MongoConnect that will have the methods to be tested. Imports the set up method that will be called before each test Imports the pytest library  Setting up pytest test fixtures allows for test set up that runs before every every test that calls the fixture. The db_connect() fixture will call the db_set_up() method from the set up file before every test that calls it in it\u0026rsquo;s arguments. It also connects to the database once the it has been seeded and created the database object that will be used in the tests.\n# Sets up the connection to the database for the test as a fixture to run before each test @pytest.fixture def db_connect(): su.db_set_up() host = \u0026#34;localhost:27017\u0026#34; return MongoConnect(\u0026#34;test_trucks\u0026#34;,host) Similarly The db_teardown fixture will connect to the mongo server and delete the test_trucks database when all test are completed.\n#Deletes the database after all tests have completed @pytest.fixture def db_tear_down(): client = pymongo.MongoClient(\u0026#34;mongodb://localhost:27017/\u0026#34;) return client.drop_database(\u0026#39;test_trucks\u0026#39;) The fixture db_tear_down is called as an argument in the test_clean method.\n####### TEST CLEAN UP ####### def test_clean(db_tear_down): return db_tear_down pytest allows the use of parameterized test, which gives the ability to run a test with multiple test conditions. For testing create_collections(), parameterized test will check what happens when different inputs, valid and invalid, are used.\n# Use parametrized test to test the following test scenarios of creating collections with the following # names and the expected outcomes: \u0026#34;trucks\u0026#34;, \u0026#34;\u0026#34;, and 100. collection_scenarios = [(\u0026#34;trucks\u0026#34;,True),(\u0026#34;\u0026#34;,False), (100, False)] #1 @pytest.mark.parametrize(\u0026#34;collection_name,expect\u0026#34;, collection_scenarios) #2 def test_create_collection(db_connect, collection_name, expect): assert db_connect.create_collection(collection_name) == expect #3  collection_scenarios holds the value used for collection and the expected output. @pytest.mark.parametrize format how the values of will be read into the method The assertion calls the create_collection() substituting the values for the variables collection_name and expect  Run the test using pytest test_mongo_connect.py -v. Each test case in the parameterized test is ran and reported separately.\n========================================================= test session starts ========================================================== collected 4 items test_mongo_connect.py::test_create_collection[trucks-True] PASSED [ 25%]Connection to database closed test_mongo_connect.py::test_create_collection[-False] PASSED [ 50%]Connection to database closed test_mongo_connect.py::test_create_collection[100-False] PASSED [ 75%]Connection to database closed test_mongo_connect.py::test_clean PASSED [100%] ==================================================== 4 passed, 4 warnings in 0.46s ===================================================== The insert() method returns either a boolean if it fails or an object if it\u0026rsquo;s successful. Instead of looking for a specific value, we will use isinstance() to check the return type.\nThis test may also be parameterized, however that may affect readability given the size of the test inputs for each test case.\n# Test the following test scenarios of inserting documents with the following inputs: # a single truck into collection \u0026#39;trucks\u0026#39; - {\u0026#34;truck_number\u0026#34;:497,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Tania\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Glasscoe\u0026#34;,\u0026#34;delivery_stops\u0026#34;:14,\u0026#34;region\u0026#34;:3}  def test_insert_one_valid(db_connect): collection = \u0026#34;trucks\u0026#34; new_truck = {\u0026#34;truck_number\u0026#34;:497,\u0026#34;driver_first_name\u0026#34;:\u0026#34;Tania\u0026#34;,\u0026#34;driver_last_name\u0026#34;:\u0026#34;Glasscoe\u0026#34;,\u0026#34;delivery_stops\u0026#34;:14,\u0026#34;region\u0026#34;:3} # The insert_one() and insert_many() functions return an object type which is set as the value of the return from the MongoConnect insert() method assert isinstance(db_connect.insert(collection, new_truck), object) Summary When testing database interations, it\u0026rsquo;s important to set up a test environment that is as close to the production environment as possible. Pytest provide an easy and flexible way to check the validity of the methods, allowing for fixtures and parameterized test, and an easy to interpreet command line read out.\nLab Clone down the repo for the Mongo Python lab with the following instructions:\ngit clone https://github.homedepot.com/om-labs/python-nonrelational-databases.git cd python-nonrelational-databases/mongodb-python Follow the instructions in the README.\n"
},
{
	"uri": "/javascript/nodejs/testing/testing-express/",
	"title": "Testing Express",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Creating Mocks with Jest Testing an express route and middleware using nock and supertest  Creating Mocks With Jest Mocking is a powerful testing pattern use in just about all languages. It is often used to mimic dependencies of a function under test, so that the test can focus on the logic in the unit being tested.\nLet\u0026rsquo;s say, for example, we want to test a middleware function that can be provided to an express route. An express middleware has the following method signature:\nfn(req,res,next)\n req short for request, is an object containing information about the incoming http request. res is an object that has the supporting functions to respond to a client (res.send()) for example. next is a callback function that is intended to be called if it is not sending back to the client.  So we have a module with the following function that can be provided as middleware:\nconst checkid = (req,res,next) =\u0026gt;{ if (req.query.id){ next() } res.status(413).send(\u0026#39;{\u0026#34;message\u0026#34;:\u0026#34;id is missing\u0026#34;\u0026#39;) } module.exports = {checkid} We have some behavior here that we want to test.\n If the id is a valid param ( http://mydomain/?id=\u0026quot;bob\u0026quot;), call next() If it is not present, we want to an error code back to the client.  We don\u0026rsquo;t care how, or if req, res, or next work. We just need to be sure they are called under the correct conditions. So how do we do this without actually using an express route?\nWe create mocks that represent that will mimic the actual functions and objects passed to our function.\nManually Mocking While we may not care in our test how req,res and next actually work, we should have an understanding of when to call them and how to use them.\nMock Req\nconst req = { query: { id: \u0026#34;bob\u0026#34; } } The real request object has a lot more in it. For our implementation, we really only care about the query.id property, so we can simply create a JavaScript object literal to represent the real request.\nMock next\nlet nextCalled = false const nextFn = () =\u0026gt; () =\u0026gt; { nextCalled = true } next is a little more complex. However, in our code we just want to know that it was called at the appropriate time.\nSetting nextCalled to true will give us a way to test that it was called at some point in the code.\nMock Res\nconst getRes = (rc) =\u0026gt; { return { called: false, // 1  code: 0, // 1  responseMessage: \u0026#34;\u0026#34;, // 1  status: function(c){ // 2  this.code = c this.called = true return this // 3  }, send: function(message){ // 4  this.responseMessage = message } } } Now things are getting pretty complex. However, this is still way more simple than the actual object.\n Rather than relying on a global variable, we will use a property of the object here to keep a record of our results. We know that we need a status function, so we define one here on the object. It will set the code property to whatever the calling code provides. We know that it is common to call res.status().send(), so to maintain that, we will return this. Returning this will allow us to chain the object. In other words we are able to chain a send call off of status because status returns the same object that has send in it.  We now have 3 mocks that will give us the behavior we expect when called, without calling the real thing.\nLets see what this looks like with tests.\nconst { checkid } = require(\u0026#34;./middleware\u0026#34;) // Manually creating mocks let nextCalled = false const nextFn = () =\u0026gt; () =\u0026gt; { nextCalled = true } const getRes = (rc) =\u0026gt; { return { called: false, code: 0, responseMessage: \u0026#34;\u0026#34;, status: function(c){ this.code = c this.called = true return this }, send: function(message){ this.responseMessage = message } } } describe(\u0026#34;#checkid\u0026#34;, () =\u0026gt; { describe(\u0026#34;Given the checkid middleware\u0026#34;, () =\u0026gt; { describe(\u0026#34;When the query param \u0026#39;id\u0026#39; is present\u0026#34;, () =\u0026gt; { it(\u0026#34;Should call next\u0026#34;, () =\u0026gt; { // Set up the default  nextCalled = false const next = nextFn() // req can be a simple JSON object as the mock  const req = { query: { id: \u0026#34;bob\u0026#34; } } /* Get a mock our response object and give it a return code to so we can be sure the default 0 was not overridden. */ mockRes = getRes(123) //Make the actual call to our function with our mocks  checkid(req, mockRes, next) // Ensure next was called  expect(nextCalled).toBe(true) // Ensure no response was sent  expect(mockRes.responseMessage).toEqual(\u0026#34;\u0026#34;) // Ensure no status code  expect(mockRes.coding).toBe(0) }) }) describe(\u0026#34;When the query param \u0026#39;id\u0026#39; is NOT present\u0026#34;, () =\u0026gt; { it(\u0026#34;It should respond with a 413\u0026#34;, () =\u0026gt; { // Set up/reset the default so we don\u0026#39;t get a false positive.  nextCalled = false // Get an instance of our mock next function  const next = nextFn() // req can be a simple JSON object as the mock  const req = { query: {} } const mockRes = getRes() checkid(req, mockRes, next) expect(mockRes.coding).toBe(413) expect(mockRes.responseMessage).toEqual(\u0026#39;{\u0026#34;message\u0026#34;:\u0026#34;id is missing\u0026#34;}\u0026#39;) expect(nextCalled).toBe(false) }) }) }) })  You do not need to create your mocks in the same file as your test. In fact, many teams may create their own modules for their own mocks to avoid rework.\n Lab 1: Creating req, res and next mocks.  Create a file that exports a middleware function. Create your own mocks for res and next Write a tests that asserts they were called.  Using Jest to Create Mocks Jest has built-in mocking library to help with creating mocks. There are some limitations, however. For example, we cannot easily auto-generate the same sort of mock object we built for response. We will convert our next function to demonstrate how this can lend to the readability of our code.\nWe can replace\nlet nextCalled = false const nextFn = () =\u0026gt; () =\u0026gt; { nextCalled = true } with\nconst mockNext = jest.fn() We can now use fn as a function\nconst mockNext = jest.fn() checkid(req, mockRes, mockNext) expect(mockNext.mock.calls.length).toBe(1); In short, jest gives us the ability to quickly create mock functions that will allow us to easily validate without having to write extra validation variables to determine if the function was called.\nMocking tools can be powerful, but sometimes hard to grasp. Here are ust a few more quick things you can do with Jest function mocking that you may find useful and easy to use right away:\nMore examples of mocking with Jest\n//Create your own implementation behavior. const mathMock = mock.fn(x=\u0026gt;2+x) console.log(mathMock(5)) // This can even be used for your asserts const fnAndExpect = mock.fn(()=\u0026gt;expect(true).toBe(true)) fnAndExpect() // Have prepared return values const mockDataFetch = mock.fn(()=\u0026gt;\u0026#39;{\u0026#34;data\u0026#34;:0101}\u0026#39;) console.log(mockDataFetch()) // Chain prepared return values const mockChinReturn = jest.fn() .mockImplementationOnce(() =\u0026gt; 1) .mockImplementationOnce(() =\u0026gt; 2) .mockImplementationOnce(() =\u0026gt; 3) console.log(mockChinReturn()) console.log(mockChinReturn()) console.log(mockChinReturn()) It is worth at least skimming over the other functions that Jest offers in its mocking library. You can find them here\nAnother powerful mocking library that can be used with any testing framework is SinonJs, commonly referred to as just Sinon. In addition to mocking it has powerful server testing utilities built in so that you can easily manage starting/stopping servers if needed.\nTesting Express Just like any other code, we want to be able to test the behavior of our endpoints.\nLets say we have the following code:\nconst express = require(\u0026#39;express\u0026#39;) const app = express() app.get(\u0026#39;/endpoint\u0026#39;, (req, res) =\u0026gt; { res.status(200).send(\u0026#39;It worked!\u0026#39;) }) module.exports = app We need a way to unit test that the response function was called appropriately when the /endpoint path was called.\nStill using Jest, we can use a very popular library called supertest.\nSupertest Supertest is library that extends another popular library called superagent which will allow us to mock client call to ensure our responses are working as expected.\nInstalling Supertest As with jest, we want to install the supertest module as a dev dependency. Therefore, be sure to use the -D flag when installing the module from npm.\nnpm install -D supertest\nOnce installed, your devDependencies section should contain at least the following, at whatever the current versions are:\n\u0026#34;devDependencies\u0026#34;: { \u0026#34;jest\u0026#34;: \u0026#34;^23.6.0\u0026#34;, \u0026#34;supertest\u0026#34;: \u0026#34;^3.3.0\u0026#34; } Your first test using supertest The supertest library allows us to write tests in a format that is similar to other client libraries that make calls to endpoints, such as request-promise or axios.\nconst request = require(\u0026#39;supertest\u0026#39;); // 1 const routes = require(\u0026#39;./app\u0026#39;) // 2  describe(\u0026#39;Get /endpoint\u0026#39;, () =\u0026gt; { // 3  it(\u0026#39;It should response the GET method\u0026#39;, () =\u0026gt; { return request(routes).get(\u0026#39;/endpoint\u0026#39;).then((response) =\u0026gt; { expect(response.statusCode).toBe(200); }); // 4  }); });  Import supertest. Although not required, it is common practice to call the import request Import your routes. For unit tests, it is important not to import your code that invokes the listen(fn()) function from express Describing your route under test, as well as the HTTP method is not required, but results in a more readable output. Supertest returns a promise after mocking the appropriate call specified after the request function. In this case, we make a GET call to the /endpoint  Built in Assertions In addition to making the request, supertest also provide some common assertions you\u0026rsquo;d make with http calls.\nFor example, we could covert the above test to use built the built in expect function:\nreturn request(routes) .get(\u0026#39;/endpoint\u0026#39;) .expect(200);  When using the built in expect assertion, the assertion message is slightly different.\nRather than seeing:\nExpected: 200 Received: 404\nYou will see:\nexpected 200 \u0026ldquo;OK\u0026rdquo;, got 404 \u0026ldquo;Not Found\u0026rdquo;\n You can still use then to do further assertions. supertest will resolve a response object that will contain a lot of the things you\u0026rsquo;d expect when making a client call in node.\nFor example, if we wanted to assert the response text of a call:\nreturn request(routes).get(\u0026#39;/endpoint\u0026#39;) .expect(200) .then((response) =\u0026gt; { expect(response.text).toBe(\u0026#34;Hello\u0026#34;); }); In this case we first expect a 200, then expect the text to be equal to Hello\n When chaining built-in expects, the promise will return at the first failure.\n Setting Request Headers It is common for clients to set specific headers, such as telling the server it would like an 'application/json' response.\nreturn request(routes).get(\u0026#39;/endpoint\u0026#39;) .set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;) .expect(\u0026#39;Content-Type\u0026#39;, /json/) .expect(200) .then((response) =\u0026gt; { expect(response.body).toEqual({message: \u0026#34;hi\u0026#34;}); }); Other HTTP Methods You can test all http methods with supertest.\nPOST Example return request(routes).post(\u0026#39;/endpoint\u0026#39;) .set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;) .send({requestMessage: \u0026#34;give me a response\u0026#34;}) // 1  .expect(\u0026#39;Content-Type\u0026#39;, /json/) .expect(200) .then((response) =\u0026gt; { expect(response.body).toEqual({message: \u0026#34;hi\u0026#34;}); });  Sends the data provided as the POST data  Posting Forms You can also easily post application/x-www-form-urlencoded forms, using the type function in your request chain.\nreturn request(routes).post(\u0026#39;/endpoint\u0026#39;) .set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;) .type(\u0026#39;form\u0026#39;) .send({username: \u0026#34;supercool1212\u0026#34;}) .send({password: \u0026#34;4321drowssap\u0026#34; }) .expect(\u0026#39;Content-Type\u0026#39;, /json/) .expect(200) .then((response) =\u0026gt; { expect(response.body).toEqual({message: \u0026#34;hi\u0026#34;}); }); Designing Testable Routes Since we want to focus on only the code within a given unit for unit testing, we want to ensure that is ALL we are testing.\nFor express routes, we don\u0026rsquo;t necessarily want to test the entire middleware chain for a unit test. We also don\u0026rsquo;t want to make any real calls to external resources. However, we do still expect the routes to give a specific response when called.\nInjecting Middleware A common piece of middleware used in express routes is some sort of authorization middleware. For example, lets say we are securing the following endpoint:\napp.get(\u0026#39;/secure/endpoint\u0026#39;, isAuthorized, (req,res) =\u0026gt;{ res.status(200).send(\u0026#34;All OK!\u0026#34;) } ) Lets assume that isAuthorized is a middleware function that communicates with some sort of authorization service. However, when we test the /secure/endpoint route, we don\u0026rsquo;t care specifically what this is doing. So how can we make this code testable with this isAuthorized external dependency?\nThere are a few methods that can be used to inject your dependencies.\nFactory Function A factory function is a way to implement the factory pattern. The factory pattern is simply a way to generate instances of something in a specific configuration with a single function.\nWe will refactor the route above to implement a factory function to allow for dependency injection.\nconst express = require(\u0026#39;express\u0026#39;) const secureEndPoint = (authMiddleware)=\u0026gt;{ const router = express.Router(); router.get(\u0026#39;/secure/endpoint\u0026#39;, authMiddleware, (req,res) =\u0026gt;{ res.status(200).send(\u0026#34;All OK!\u0026#34;) } ) return router } module.exports = {secureEndPoint} Our factory function is called secureEndPoint the instance of the \u0026ldquo;thing\u0026rdquo; we are returning is a configured express router.\nNow to test this, we can create our own mock and pass it to the factory function as part of the test setup.\nconst request = require(\u0026#39;supertest\u0026#39;); const {secureEndPoint} = require(\u0026#39;./app\u0026#39;) const express = require(\u0026#34;express\u0026#34;) let app // Initialize \u0026#34;app\u0026#34; before each test beforeEach(()=\u0026gt;{ app = express() }) // Mock auth object. const mockAuth = (req,res,next) =\u0026gt;{ next() } describe(\u0026#39;GET /secure/endpoint\u0026#39;, () =\u0026gt; { it(\u0026#39;It should respond with a 200\u0026#39;, () =\u0026gt; { // Use app.use to add the route  app.use(secureEndPoint(mockAuth)) // Test as normal  return request(app) .get(\u0026#39;/secure/endpoint\u0026#39;) .expect(200) }); }); Not only have we tested, but we also have documentation on how the route is intended to be configured and used.\n You can set up multiple routes at a time this way. For example, say you have a group of endpoints that you want to secure in this manner. You could add as many routes that need the same decency as you want in the same function.\n Testing Routes that call external services. You will run into situations where dependency injection won\u0026rsquo;t make anything more testable. In fact, it can make things harder to test and read if you attempt to.\nIO tends to be one of the major areas. In a lot of cases, this is where you can draw the line and commit to covering the code in an integration test.\nHowever, there are some tools and methods you can use to test routes that use calls to services.\nNock Lets say our secure endpoint makes a call to dapper:\nconst secureEndPoint = (authMiddleware) =\u0026gt; { const router = express.Router(); router.get(\u0026#39;/secure/endpoint\u0026#39;, authMiddleware, (req, res) =\u0026gt; { request(\u0026#39;http://dapper.apps-np.homedepot.com/users/exw5373\u0026#39;) .then(json =\u0026gt; res.json(json)) }) return router } There is no real way we can inject the request here. If the network is down or the site is down, then our unit tests fail. That is not an acceptable failure reason for a unit test.\nNock allows us to intercept calls and reply with mock responses. It works by overriding the http.request\nUsing nock in our test, we are able to intercept it an form our own reply:\n/* 1. Provide the domain we need 2. Specify a get the expected path 3. reply with the status code and message */ nock(\u0026#39;http://dapper.apps-np.homedepot.com\u0026#39;) .get(\u0026#39;/users/exw5373\u0026#39;) .reply(200,{message: \u0026#34;you got nocked!\u0026#34;}) it(\u0026#39;It should respond with a 200\u0026#39;, () =\u0026gt; { app.use(secureEndPoint(mockAuth)) return request(app).get(\u0026#39;/secure/endpoint\u0026#39;). expect(200) .then(res =\u0026gt; { console.log(res.body) }) });  If you set up a nock, it must be used or the test fails.\n More on Nock\nLab 2  Create a route for /user/:name Write a test that will test that the route returns a json in the following format:  { \u0026#34;name\u0026#34;: \u0026#34;name given\u0026#34; \u0026#34;address\u0026#34;: \u0026#34;Some address\u0026#34; } Lab 3  Create another route using path /v2/user/:name The route should accept a middleware that would intended to be used to look up the the user info in database. You can assume that the database route would store the result of the query in the req.userdata. This should be written so that you can test it using a mock of the middleware. The response should be the same as above, but with an additional property: version: 2  "
},
{
	"uri": "/react/pillars/testing/react-testing-library/rtl-generic-components/",
	"title": "Testing Generic Components",
	"tags": [],
	"description": "",
	"content": "Introduction  Generic Components are components that are intended to be reused throughout your application. They can easily be tested as they will not have dependencies on other components in your project (thus making them generic and reusable).  In this lesson we will look at testing the NumericInput generic component.\nTesting the NumericInput Component First create the test file:\ntouch client/src/components/numeric-input/NumericInput.test.js Now open the file in your text editor and add the following:\nNumericInput.test.js:\nimport React from \u0026#39;react\u0026#39; import \u0026#39;@testing-library/jest-dom\u0026#39; import { screen } from \u0026#39;@testing-library/dom\u0026#39; import { render } from \u0026#39;@testing-library/react\u0026#39; import userEvent from \u0026#39;@testing-library/user-event\u0026#39; import NumericInput from \u0026#39;./NumericInput\u0026#39; function getNumericInput(value, min, max, onChange) { // create and return the Component under test  return ( \u0026lt;NumericInput data-testid=\u0026#34;item-quantity\u0026#34; value={value} min={min} max={max} onChange={onChange} /\u0026gt; ) } describe(\u0026#39;NumericInput\u0026#39;, () =\u0026gt; { it(\u0026#39;renders without crashing\u0026#39;, () =\u0026gt; { const { container } = render(getNumericInput(3, 0, 10, null)) expect(container).toBeTruthy() }) it(\u0026#39;renders the value\u0026#39;, () =\u0026gt; { render(getNumericInput(3, 0, 10, null)) screen.getByText(\u0026#39;3\u0026#39;) }) it(\u0026#39;increments the value when the increment button is clicked\u0026#39;, () =\u0026gt; { const onChange = jest.fn(v =\u0026gt; v) // create a mock function for the onChange callback  render(getNumericInput(3, 0, 10, onChange)) const button = screen.getByTestId(\u0026#39;numeric-increment\u0026#39;) // get and click on the increment button  userEvent.click(button) expect(onChange.mock.calls.length).toBe(1) // expect that the callback was called  expect(onChange).toHaveBeenCalledWith(4) // with the proper value  }) it(\u0026#39;disables the increment button when the value is the maximum\u0026#39;, () =\u0026gt; { render(getNumericInput(10, 0, 10, null)) // when the value has reached the max,  expect(screen.getByTestId(\u0026#39;numeric-increment\u0026#39;)).toBeDisabled() // the increment button should be disabled  }) it(\u0026#39;decrements the value when the decrement button is clicked\u0026#39;, () =\u0026gt; { // TODO: implement this test  }) it(\u0026#39;disables the decrement button when the value is the minimum\u0026#39;, () =\u0026gt; { // TODO: implement this test  }) }) Activity - Complete the Test Complete the last 2 tests in the code above.\nSummary Testing generic components is no different than testing any other components. We simply need to test each responsibility the component has, such as rendering expected DOM nodes and responding to user input.\n"
},
{
	"uri": "/golang/testing/",
	"title": "Testing with Go",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/javascript/pillars/resiliency-patterns/circuit-breaker/",
	"title": "The Circuit Breaker Pattern",
	"tags": [],
	"description": "",
	"content": "The Circuit Breaker resiliency pattern.\n Topics 1. Learning Objectives 2. What is the Circuit Breaker Pattern? 2.1. Why Use a Circuit Breaker 2.2. States of a Circuit Breaker   3. Circuit Breaker Parameters 3.1. Visualization of Circuit Breaker   4. Introducing the opossum Library 5. Lab 6. Summary 7. Additional Resources   1. Learning Objectives   Paint a picture of the circuit breaker pattern\n  Describe the situation where circuit breaker pattern is best used\n  Use the opossum library to implement a circuit breaker\n     2. What is the Circuit Breaker Pattern? Think about the electrical device, the circuit breaker. When it receives a surge in power, it opens, causing a gap in connectivity and protects the circuitry and devices downstream.\n   The circuit breaker pattern uses this concept, but instead of an influx of power, it protects against an influx of requests.\n   2.1. Why Use a Circuit Breaker The Circuit Breaker pattern offers the following advantages:\n   Avoids continuously accessing a failed service, giving time for the service to recover\n  Fails fast by returning an error quickly instead of waiting on a failed service to generate an error\n      2.2. States of a Circuit Breaker Circuit breakers aren\u0026#8217;t just open or closed. They can also be half open and work to throttle the amount of requests.\n    Thus there are 3 states to a Circuit Breaker as illustrated by the state transition diagram below.\n      3. Circuit Breaker Parameters The Circuit Breaker pattern provides the following parameters to configure the behavior of the Circuit Breaker.\n   timeout : If the service takes this long to respond, trigger a failure.\n  error threshold percentage : If faults reach this percentage in a certain window, open the circuit breaker.\n  error rolling window : How long to consider successes and faults when calculating the error percentage.\n  reset timeout: After being closed for this long, allow a retry of the service (using the half open state).\n   3.1. Visualization of Circuit Breaker Let\u0026#8217;s consider the following visual example:\n     In a 5 second window, 50% of calls fail. This triggers the CB to open.\n  After 5 seconds, the CB goes half open.\n  While in half open, a 500 response is received, causing the CB to go open.\n  After 5 seconds, the CB goes half open.\n  It receives a 200 response causing the CB to fully close.\n      4. Introducing the opossum Library  Opossum is a Node.js circuit breaker that executes asynchronous functions and monitors their execution status. When things start failing, opossum plays dead and fails fast. If you want, you can provide a fallback function to be executed when in the failure state.  \u0026#8212; From the Opossum documentation   The basic usage is to set your options, and pass them and a function that could fail, creating an instance of a circuit breaker.\n const CircuitBreaker = require('opossum'); function asyncFunctionThatCouldFail (x, y) { return new Promise((resolve, reject) =\u0026gt; { // Do something, maybe on the network or a disk }); } const options = { timeout: 3000, // If our function takes longer than 3 seconds, trigger a failure errorThresholdPercentage: 50, // When 50% of requests fail, trip the circuit resetTimeout: 30000 // After 30 seconds, try again. }; const breaker = new CircuitBreaker(asyncFunctionThatCouldFail, options); breaker.fire(params) .then(console.log) .catch(console.error);   The opossum library also provided events that are triggered when the circuit breaker changes states. You can use these events to execute custom code.\n breaker.on(\"open\", function(){ /* code to execute... */ }); breaker.on(\"close\", function(){ /* code to execute... */ }); breaker.on(\"halfOpen\", function(){ /* code to execute.. */});     5. Lab For instructions see the Circuit Breaker lab at Resiliency Cart Service.\n   6. Summary The circuit breaker pattern works well when a resource may fail for a longer period of time (i.e. persistent failures).\n The Circuit Breaker pattern performs by:\n   tracking the percentage of failures in a predetermined window of time\n  transitioning from the closed state to the open state when the percentage of failures reaches a certain threshold\n  transitioning from the open state to the half open state after a specified reset time\n  transitioning from the half open state to either the closed state or the open state depending on the success or failure of the next request\n   Using the circuit breaker pattern on a resource that may fail can help that service return to service faster. It helps not to kick the proverbial \"dead horse.\"\n   7. Additional Resources   https://martinfowler.com/bliki/CircuitBreaker.html\n  https://docs.microsoft.com/en-us/azure/architecture/patterns/circuit-breaker\n  https://learning.oreilly.com/videos/microservices-patterns-video/9781617294549VE\n     "
},
{
	"uri": "/react/pillars/hooks/usecontext/",
	"title": "The useContext Hook",
	"tags": [],
	"description": "",
	"content": "Concepts and Skills  Understand how the useContext hook eliminates the need for nested component wrappers when consuming a Context value. Apply the useContext hook to simplify React components that consume Context values.  Problem Statement React\u0026rsquo;s Context API provides a great way to manage shared state across components without the need for \u0026ldquo;prop drilling\u0026rdquo; or using a 3rd party state management library like Redux. (Note: we have an entire lesson on the Context API at The Context API).\nBut the Context API does introduce a kind of component wrapper hell when you want to consume multiple contexts. For example:\nconst MyComponent = () =\u0026gt; { return ( \u0026lt;ThemeContext.Consumer\u0026gt; {({ theme }) =\u0026gt; ( \u0026lt;ShoppingCart.Consumer\u0026gt; {({ cart }) =\u0026gt; ( // JSX code to render the cart  )} \u0026lt;/ShoppingCart.Consumer\u0026gt; )} \u0026lt;/ThemeContext.Consumer\u0026gt; ) } Using useContext to Simplify the Consuming Component The useContext hook greatly simplifies the above code to:\nconst MyComponent = () =\u0026gt; { const { theme } = useContext(ThemeContext) const { quote } = useContext(QuoteContext) return ( // JSX code to render the cart  ) } Explanation The useContext hook accepts a context object (the value returned from React.createContext) and returns the current context value for the context. The current context value is determined by the value prop of the nearest \u0026lt;MyContext.Provider\u0026gt; above the calling component in the tree.\nWhen the nearest \u0026lt;MyContext.Provider\u0026gt; above the component updates, this hook will trigger a rerender with the latest context value passed to that MyContext provider.\nLab - Replace Prop Drilling with the Context API and the useContext hook Instructions for the lab can be found here.\nConclusion The useContext hook can be used to simplify React components that consume one or more Context values.\n"
},
{
	"uri": "/javascript/foundations/variables/",
	"title": "Variables",
	"tags": [],
	"description": "",
	"content": "How to create variables in JavaScript.\nLearning Objectives Concepts  Describe the purpose of JavaScript variables List the data types used by JavaScript Compare static vs. dynamic typing Explain the JavaScript operator precedence rules  Skills  Use the var, let, and const keywords to declare a variable Properly name JavaScript variables using camelCase Define JavaScript expressions using parentheses to control operator precedence  Naming Variables  All JavaScript variables have a name, also called an identifier. Identifiers:  can be short names, like x and y, or more descriptive names, like age, sum, totalVolume can contain letters, digits, underscores, and dollar signs should begin with a letter are case sensitive: y and Y are different variables should be camelCase (a common best practice)    Declaring Variables  JavaScript variables are declared using the var, let, and const keywords JavaScript variables have a name and a value  const camelCase = \u0026#39;Camel case capitalizes each word (except the first one).\u0026#39;; const snake_case = \u0026#39;Snake case is *not* recommended for JavaScript (but is recommended for Ruby).\u0026#39;;  Values are of a type such as String, Number, or Boolean  Here are some examples of JavaScript variables:\nconst greeting = \u0026#39;Hello, OM!\u0026#39;; // a String const year = 2015; // a Number const pi = 3.14159; // a Number const completed = false; // a Boolean (can be true or false) const fruit = [\u0026#39;Apple\u0026#39;, \u0026#39;Orange\u0026#39;, \u0026#39;Banana\u0026#39;] // an Array const person = { // an Object  firstName: \u0026#39;Homer D.\u0026#39;, lastName: \u0026#39;Poe\u0026#39; }; const fullName = person.firstName + \u0026#39; \u0026#39; + person.lastName; var, let and const  You can declare variables with the var, let, and const keywords.  var is the original way to declare a variable let and const were added in ES-2015   Each of these keywords has a different effect on the variable:  var has function scope and declares a mutable variable let has block scope and declares a mutable variable const has block scope and declares an immutable variable    NOTE: We haven\u0026rsquo;t discussed scope, functions, or blocks yet. We will revisit these topics in future lessons.\nSome examples:\nvar x = 3; let y = 12; const greeting = \u0026#39;Hello\u0026#39;; Dynamic Typing  JavaScript uses dynamic typing as opposed to static typing. Static typing binds a data type to a variable Dynamic typing binds a data type to a value  Example of Static Typing (Java)\nint x = 3; // x has been declared as an integer data type String message = \u0026#34;Java uses static typing\u0026#34;; x = false; // compiler error: incompatible types Example of Dynamic Typing (JavaScript)\nlet x = 3; // x has been assigned a value of 3, which is a Number let message = \u0026#34;JavaScript uses dynamic typing\u0026#34;; x = false; // no error, x is now assigned a boolean value of false Static Typing vs. Dynamic Typing There is no consensus on whether static typing or dynamic typing is better. There are advantages and disadvantages to each.\n The advantages of static typing include:  additional compile-time checks that may catch bugs at compile-time provides a kind of self documentation because the explicit types declare how the variables are to be treated   The advantages of dynamic typing include:  the reduced mental (and typing) effort required to declare the type of each variable the reduced verbosity of the written code less work to make changes to the types when new features mandate that the types of certain variables need to be changed    Some statically typed languages are C, C++, Java, and Scala.\nSome dynamically typed languages are JavaScript, Ruby, and Python.\nAll Variables Should Be Declared Bad 😔:\nx = 3 // this line is missing the `var` or \u0026#39;let\u0026#39; keyword and the semicolon. The above code will work but is not considered good style and can lead to subtle bugs in your code.\nGood 😀:\nlet x = 3; Here we have used the let keyword to formally declare the variable x and we have also added the semicolon at the end of the assignment statement!\nSummary  JavaScript is a dynamically typed programming language. JavaScript variables are used to hold values (data). JavaScript variables should be named using camelCase. JavaScript variables are declared using the var, let, and const keywords.  "
},
{
	"uri": "/javascript/pillars/restful-api-express-node/deploy-pcf/",
	"title": "Deploying to PCF",
	"tags": [],
	"description": "",
	"content": "This lesson will walk you through deploying an application to Pivotal Cloud Foundry\n Topics 1. Learning Objectives 1.1. Concepts 1.2. Skills     1. Learning Objectives 1.1. Concepts   12 Factor methodology for writing modern webapps\n  Using a Platform-as-a-Service (PaaS)\n  Managing an application on Pivotal Cloud Foundry (PCF)\n    1.2. Skills   How to use the cf-cli to interact with a Cloud Foundry space\n  Leveraging cf services to connect to a database\n  How to create environment variables\n   Click here to go to the PCF lesson.\n    "
},
{
	"uri": "/software-eng-essentials/git-pillars/interactive-rebase-lab/",
	"title": "Git Interactive Rebase Lab",
	"tags": [],
	"description": "",
	"content": "No hints this time\n Open the dir you worked on in the filter-branch lesson/lab Checkout a branch with the empty commits Get rid of those commits!  "
},
{
	"uri": "/python/relational-db/orm-relationships/",
	"title": "ORM Relationships",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Understanding the SQLAlchemy Relationship API Mapping database table relationships to Python classes and objects  SQLAlchemy Relationship API SQLAlchemy supports different types of relationships:\n One To Many Many To One One To One Many To Many Self-referential  For a more indepth look at SQLAlchemy\u0026rsquo;s Relationship API, check out the documentation at the SQLAlchemy website.\nOne to Many The first type, One To Many, is used to mark that an instance of a class A can be associated with many instances of another class B.\nA may be linked to many elements of B, but a member of B is linked to only one element of A.\nFor instance, think of A as authors, and B as books. An author can have many books, but a book can only have one author.\nIn this example, a one to many relationship places a foreign key on the child table, book, referencing the parent, author.\nrelationship() is then specified on the parent, as referencing a collection of items represented by the child:\nclass Book(Base): __tablename__ = \u0026#34;books\u0026#34; #matches the name of the actual database table id = Column(Integer,Sequence(\u0026#39;book_seq\u0026#39;),primary_key=True) name = Column(String(50)) author_id = Column(Integer,ForeignKey(\u0026#39;authors.id\u0026#39;)) author = relationship(\u0026#34;Author\u0026#34;, backref=\u0026#34;books\u0026#34;) # 1 class Author(Base): __tablename__ = \u0026#34;author\u0026#34; #matches the name of the actual database table id = Column(Integer,Sequence(\u0026#39;book_seq\u0026#39;),primary_key=True) name = Column(String(50)) Once the relationship has been created, you can use it like:\no_book = session.query(Book).filter_by(name=\u0026#34;Harry Potter and the methods of rationality\u0026#34;).first() o_author = o_book.author # o_author is now an Author instance. o_author.id == o_book.author_id #it works the other way as well o_author = session.query(Author).filter_by(name=\u0026#34;Orsan Scott Card\u0026#34;) for o_book in o_author.books: print o_book.name #adding a new book o_new_book = Book() o_book.name = \u0026#34;Ender\u0026#39;s Game\u0026#34; o_book.author = o_author #adding a new book in a different way... o_new_book = Book() o_book.name = \u0026#34;Ender\u0026#39;s Shadow\u0026#34; o_author.books.append(o_book) One to One class Parent(Base): __tablename__ = \u0026#39;parent\u0026#39; id = Column(Integer,Sequence(\u0026#39;p_seq\u0026#39;),primary_key=True) child_id = Column(Integer, ForeignKey(\u0026#39;child.id\u0026#39;)) child = relationship(\u0026#34;Child\u0026#34;, backref=backref(\u0026#34;parent\u0026#34;, uselist=False)) # 1 class Child(Base): __tablename__ = \u0026#39;child\u0026#39; id = Column(Integer,Sequence(\u0026#39;c_seq\u0026#39;),primary_key=True) We can make use of this like so:\no_child = session.query(Child).get(1) o_parent = o_child.parent o_parent2 = Parent() o_parent.child = Child() Many to Many A many to many relationship requires an extra table to create mappings between lines. There are two ways of doing this.\n The first approach is to use models:  class Category(Base): __tablename__ = \u0026#39;categories\u0026#39; id = Column(Integer,Sequence(\u0026#39;cat_seq\u0026#39;),primary_key=True) name = Column(String(20)) class Product(Base): __tablename__ = \u0026#39;products\u0026#39; id = Column(Integer,Sequence(\u0026#39;prod_seq\u0026#39;),primary_key=True) name = Column(String(20)) class Map(Base): __tablename__ = \u0026#39;map\u0026#39; id = Column(Integer,Sequence(\u0026#39;map_seq\u0026#39;),primary_key=True) cat_id = Column(Integer,ForeignKey(\u0026#39;categories.id\u0026#39;)) prod_id = Column(Integer,ForeignKey(\u0026#39;products.id\u0026#39;))  The second approach is better if your map table is only a map table and requires no complex interactions:  map_table = Table(\u0026#39;maps\u0026#39;, Base.metadata, Column(\u0026#39;cat_id\u0026#39;, Integer, ForeignKey(\u0026#39;categories.id\u0026#39;)), Column(\u0026#39;prod_id\u0026#39;, Integer, ForeignKey(\u0026#39;products.id\u0026#39;)) ) class Category(Base): __tablename__ = \u0026#39;categories\u0026#39; id = Column(Integer,Sequence(\u0026#39;cat_seq\u0026#39;),primary_key=True) name = Column(String(20)) products = relationship(\u0026#34;Product\u0026#34;, secondary=map_table, #1 backref=\u0026#34;categories\u0026#34;) class Product(Base): __tablename__ = \u0026#39;products\u0026#39; id = Column(Integer,Sequence(\u0026#39;prod_seq\u0026#39;),primary_key=True) name = Column(String(20)) You can make use of the relationship like this:\n#construct a category and add some products to it o_cat = Category() o_cat.name = \u0026#34;Books\u0026#34; o_product = Product() o_product.name = \u0026#34;Ender\u0026#39;s Game - Orsan Scott Card\u0026#34; o_cat.products.append(o_product) o_product = Product() o_product.name = \u0026#34;Harry Potter and the methods of Rationality\u0026#34; o_product.categories.append(o_cat) # interact with products from an existing category for o_product in o_cat.products: print o_product.name #interact with categories of an existing product o_product = session.query(Product).filter_by(name=\u0026#34;\u0026#34;) for o_cat in o_product.categories: print o_cat.name Self-referential Relationships Sometimes you have a table with a foreign key pointing at the same table. For example, say we have a bunch of nodes in a directed tree. A node can have many child nodes but at most one parent\nclass Employee(Base): __tablename__ = \u0026#34;employees\u0026#34; emp_no = Column(Integer, autoincrement=True, primary_key=True) emp_name = Column(String(32), nullable=False) manager = Column(Integer, ForeignKey(\u0026#34;employees.emp_no\u0026#34;, name=\u0026#39;emp_ref_man_fk\u0026#39;, ondelete=\u0026#39;SET NULL\u0026#39;, onupdate=\u0026#39;CASCADE\u0026#39;)) manager_rel = relationship(\u0026#34;Employee\u0026#34;, backref=backref(\u0026#39;emp_man\u0026#39;, remote_side=[emp_no], uselist=False)) #1 You can make use of this relationship like any many to one relationship:\n# Find all employees that are managers and list those who report to them reporters = session.query(Employee).filter(Employee.manager_rel!=None) for i in reporters: print(i.emp_name, i.manager_rel) Output:\nKING [Employee: JONES ] JONES [Employee: BLAKE , Employee: CLARK , Employee: SCOTT ] BLAKE [Employee: MILLER , Employee: ADAMS , Employee: JAMES , Employee: SMITH ] CLARK [Employee: WARD , Employee: ALLEN , Employee: TURNER , Employee: MARTIN ] Summary SQLAlchemy Relationship API allows the use of Python classes and objects to be mapped to database table relationships. This corresponds to a parent-child or associative table relationship. Relationships include One To Many, One To One, Many To One, Many To Many, and Self-referential.\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/selectors-and-specificity-labs/",
	"title": "Selectors and Specificity Labs",
	"tags": [],
	"description": "",
	"content": " Percipio lesson on selectors   CSS: Selectors  Play CSS Diner to learn more about CSS Selectors. See if you can finish all 32 levels.  Additional Resources  30 CSS Selectors You Must Memorize Specifics on CSS Specificity CSS Specificity Calculator CSS Specificity  "
},
{
	"uri": "/golang/testing/go-test/",
	"title": "Using the go test command",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Identifying Existing Tests Execute a Test Running tests Recursively Running a Specific Test Short Flags Tags (Unit, Int) Args Flag Setting a Timeout Saving Test Results Generating coverage reports  Go Test The go test command is intended to be used in concert with the testing package which provides support for automating testing of Go packages.\nThe go test command will execute Test Functions:\nfunc TestCalculate(t *testing.T){ if Calculate.Add(2,2) != 4 { t.Error(\u0026#34;Error Robinson\u0026#34;) } } Identifying Existing Tests When being new to a group, it might be important to find all existing tests to know what you\u0026rsquo;re working with. Tests can provide documentation as to an app\u0026rsquo;s purpose and function.\nWe can use the go test list option to identify all existing tests.\nUnfortunately, this only works on one directory at a time.\n$ go test -list . TestCalculate ok github.homedepot.com/om-labs/go-testing/calculate 0.004s In this case the only testing file in the current directory is TestCalculate\nExecute a Test If your file structure looked like the below,\n└── foo └── foo.go └── foo_test.go You could simply run\n$ go test PASS ok github.homedepot.com/om-labs/go-testing 0.025s This would execute all tests at this level, even integrated tests if they lived at this directory level.\nVerbose Mode To see the status of each test and print lines, you can pass the -v option which stands for verbose.\ngo test -v === RUN TestCalculate --- PASS: TestCalculate (0.00s) === RUN TestTableCalculate --- PASS: TestTableCalculate (0.00s) === RUN TestReversesString --- PASS: TestReversesString (0.00s) PASS ok github.homedepot.com/om-labs/go-testing 0.005s Run Tests Recursively Given we have a package calculate with packages add, subtract, multiply and divide inside of it, we could test all subdirectories using\ngo test ./... Given the directory structure of Calculate:\n├── calculate.go ├── calculate_test.go ├── add │ ├── add.go │ └── add_test.go ├── divide │ ├── divide.go │ └── divide_test.go ├── multiply │ ├── multiply.go │ └── multiply_test.go └── subtract ├── subtract.go └── subtract_test.go We can run all tests in the Calculate package as follows.\n$ go test ./... -v === RUN TestCalculate Adds: 3 Subtracts: -197 Multiplies: 600 Divides: 200 Tested Central Calculate Function. --- PASS: TestCalculate (0.00s) PASS ok github.homedepot.com/om-labs/go-testing/calculate 0.006s === RUN TestAdd --- PASS: TestAdd (0.00s) PASS ok github.homedepot.com/om-labs/go-testing/calculate/add (cached) === RUN TestDivide --- PASS: TestDivide (0.00s) PASS ok github.homedepot.com/om-labs/go-testing/calculate/divide (cached) === RUN TestMultiply --- PASS: TestMultiply (0.00s) PASS ok github.homedepot.com/om-labs/go-testing/calculate/multiply (cached) === RUN TestSubtract --- PASS: TestSubtract (0.00s) PASS ok github.homedepot.com/om-labs/go-testing/calculate/subtract (cached) Specify a File You could specify the testing file in which you would like to run.\nIf the testing package belongs to the same package as the files you\u0026rsquo;re testing, you may need to pass the source code as an argument to the go test command.\n└── calculate ├── calculate.go ├── calculate_int_test.go └── calculate_test.go Contents of calculate.go\npackage calculate Contents of calculate_test.go\npackage calculate In order to specifically run calculate_test.go, pass calculate.go as an argument, as in below.\n$ go test calculate_test.go calculate.go ok command-line-arguments 0.013s But! If your test belongs to a separate package, and imports the package that is being tested, then you can do the following:\nContents of calculate.go\npackage calculate Contents of calculate_int_test.go\npackage calculate_test import ( \u0026#34;testing\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;calculate\u0026#34; ) Then you could provide a simpler command\ngo test calculate_int_test.go ok command-line-arguments 0.005s Specify a Test A specific test can be ran by itself by passing the name of the test as an argument.\n$ go test -run TestCalculate PASS ok github.homedepot.com/om-labs/go-testing 0.013s Where TestCalculate is the name of the test function. This argument can also be a regular expression.\n$ go test -run .*Calc.* -v === RUN TestCalculate --- PASS: TestCalculate (0.00s) === RUN TestTableCalculate --- PASS: TestTableCalculate (0.00s) PASS ok github.homedepot.com/om-labs/go-testing 0.012s Skipping You can choose to skip certain tests by passing arguments.\nIf you have long running tests that you don\u0026rsquo;t wish to run all the time, especially during development that doesn\u0026rsquo;t affect that test.\nIn your test, use the skip method.\nfunc TestCalculate(t *testing.T) { if testing.Short() { t.Skip(\u0026#34;skipping test in short mode.\u0026#34;) } if Calculate(2) != 4 { t.Error(\u0026#34;Expected 2 + 2 = 4\u0026#34;) } } Then, you can run in short mode with the following command:\n$ go test -v -short === RUN TestCalculate --- SKIP: TestCalculate (0.00s) main_test.go:32: skipping test in short mode.  Tags We can divide our tests into groups, such as unit and integrated. We can also create custom groups such as concurrency tests, or API tests. We can add the following text to the top of the testing files and run them independently.\nContent of main_integration_test.go\n// *build integration package main_test ... Then run our integrations tests by calling the tag.\ngo test -tags=integration We can do the same thing for a custom group.\nContent of main_test.go\n// *build millivanilly package main_test ... We can then run our unit tests by calling the tag.\ngo test -tags=millivanilly Args Flag On occassion when running behavioral tests, not so much unit tests, there may be a need to accept command line arguments. This can be done by the following:\ngo test -v -args foobar Then in your go code, you can obtain the arguments through the following code:\nargs := os.Args[1:] //[-test.v=true foobar] The above skips index 0 as that is the path to the go file.\nSetting a Timeout In order to have a test Panic if not completed by X units of time, we can specify a max time for tests to run.\nThe following will timeout after 300ms.\ngo test -timeout 300ms A failed time could present a print out like the below:\n$ go test -timeout 30ns Adds: 3 Subtracts: -197 Multiplies: 600 Divides: 200 Tested Central Calculate Function. panic: test timed out after 30ns goroutine 17 [running]: testing.(*M).startAlarm.func1() /usr/local/opt/go/libexec/src/testing/testing.go:1296 +0xfd created by time.goFunc /usr/local/opt/go/libexec/src/time/sleep.go:172 +0x44 goroutine 1 [chan receive]: testing.(*T).Run(0xc0000a0100, 0x1137a56, 0xd, 0x113eee0, 0x10693f6) /usr/local/opt/go/libexec/src/testing/testing.go:879 +0x383 testing.runTests.func1(0xc0000a0000) /usr/local/opt/go/libexec/src/testing/testing.go:1119 +0x78 testing.tRunner(0xc0000a0000, 0xc000093e08) /usr/local/opt/go/libexec/src/testing/testing.go:827 +0xbf testing.runTests(0xc00000a0a0, 0x121b2a0, 0x1, 0x1, 0x100b19f) /usr/local/opt/go/libexec/src/testing/testing.go:1117 +0x2aa testing.(*M).Run(0xc00009c000, 0x0) /usr/local/opt/go/libexec/src/testing/testing.go:1034 +0x165 main.main() _testmain.go:44 +0x13d goroutine 6 [runnable]: fmt.(*pp).argNumber(0xc0000b0000, 0x0, 0x113656b, 0x5, 0x1, 0x1, 0xc00001e000, 0xc000076d18, 0x1062f7d) /usr/local/opt/go/libexec/src/fmt/print.go:926 +0x112 fmt.(*pp).doPrintf(0xc0000b0000, 0x113656b, 0x5, 0xc000076df8, 0x1, 0x1) /usr/local/opt/go/libexec/src/fmt/print.go:1014 +0x1df fmt.Sprintf(0x113656b, 0x5, 0xc000076df8, 0x1, 0x1, 0x23, 0x105f012) /usr/local/opt/go/libexec/src/fmt/print.go:203 +0x66 testing.fmtDuration(0xb5d3, 0xc055cac900, 0x1222c80) /usr/local/opt/go/libexec/src/testing/testing.go:475 +0xd2 testing.(*T).report(0xc0000a0100) /usr/local/opt/go/libexec/src/testing/testing.go:1053 +0x55 testing.tRunner.func1(0xc0000a0100) /usr/local/opt/go/libexec/src/testing/testing.go:814 +0x228 testing.tRunner(0xc0000a0100, 0x113eee0) /usr/local/opt/go/libexec/src/testing/testing.go:831 +0xc9 created by testing.(*T).Run /usr/local/opt/go/libexec/src/testing/testing.go:878 +0x35c exit status 2 FAIL github.homedepot.com/om-labs/go-testing/calculate 0.014s Saving Test Results Because go test will output to the STDOUT of the terminal, we can use terminal commands to save the contents of this output to a file.\nOne could run the following command. It will place the output of the test inside the current folder with the current date. (This works on a darwin based system.) This could be used in concert with grep, or awk to achieve pretty printed results.\n$ go test -race \u0026gt; $(date +\u0026#34;%m_%d_%Y\u0026#34;) Let\u0026rsquo;s say that your pipeline, whether it be Team City, Jenkins, GitHooks, or Concourse requires the json output of the test results.\nWe could run the below command to achieve this.\ngo test -json \u0026gt; test_results.json If the above command were run on the calculate package, we could get a file test_results.json with the following contents.\n{\u0026#34;Time\u0026#34;:\u0026#34;2019-03-21T09:34:42.972186-04:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;run\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;github.homedepot.com/om-labs/go-testing/calculate\u0026#34;,\u0026#34;Test\u0026#34;:\u0026#34;TestCalculate\u0026#34;} {\u0026#34;Time\u0026#34;:\u0026#34;2019-03-21T09:34:42.972485-04:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;output\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;github.homedepot.com/om-labs/go-testing/calculate\u0026#34;,\u0026#34;Test\u0026#34;:\u0026#34;TestCalculate\u0026#34;,\u0026#34;Output\u0026#34;:\u0026#34;=== RUN TestCalculate\\n\u0026#34;} {\u0026#34;Time\u0026#34;:\u0026#34;2019-03-21T09:34:42.972512-04:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;output\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;github.homedepot.com/om-labs/go-testing/calculate\u0026#34;,\u0026#34;Test\u0026#34;:\u0026#34;TestCalculate\u0026#34;,\u0026#34;Output\u0026#34;:\u0026#34;{1 2 3} {8 3 5} {6 6 36} {45 5 9}\\n\u0026#34;} {\u0026#34;Time\u0026#34;:\u0026#34;2019-03-21T09:34:42.972532-04:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;output\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;github.homedepot.com/om-labs/go-testing/calculate\u0026#34;,\u0026#34;Test\u0026#34;:\u0026#34;TestCalculate\u0026#34;,\u0026#34;Output\u0026#34;:\u0026#34;Adds: 3\\n\u0026#34;} {\u0026#34;Time\u0026#34;:\u0026#34;2019-03-21T09:34:42.97255-04:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;output\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;github.homedepot.com/om-labs/go-testing/calculate\u0026#34;,\u0026#34;Test\u0026#34;:\u0026#34;TestCalculate\u0026#34;,\u0026#34;Output\u0026#34;:\u0026#34;Subtracts: 5\\n\u0026#34;} {\u0026#34;Time\u0026#34;:\u0026#34;2019-03-21T09:34:42.972561-04:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;output\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;github.homedepot.com/om-labs/go-testing/calculate\u0026#34;,\u0026#34;Test\u0026#34;:\u0026#34;TestCalculate\u0026#34;,\u0026#34;Output\u0026#34;:\u0026#34;Multiplies: 36\\n\u0026#34;} {\u0026#34;Time\u0026#34;:\u0026#34;2019-03-21T09:34:42.972571-04:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;output\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;github.homedepot.com/om-labs/go-testing/calculate\u0026#34;,\u0026#34;Test\u0026#34;:\u0026#34;TestCalculate\u0026#34;,\u0026#34;Output\u0026#34;:\u0026#34;Divides: 9\\n\u0026#34;} {\u0026#34;Time\u0026#34;:\u0026#34;2019-03-21T09:34:42.972583-04:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;output\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;github.homedepot.com/om-labs/go-testing/calculate\u0026#34;,\u0026#34;Test\u0026#34;:\u0026#34;TestCalculate\u0026#34;,\u0026#34;Output\u0026#34;:\u0026#34;Tested Central Calculate Function.\\n\u0026#34;} {\u0026#34;Time\u0026#34;:\u0026#34;2019-03-21T09:34:42.9726-04:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;output\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;github.homedepot.com/om-labs/go-testing/calculate\u0026#34;,\u0026#34;Test\u0026#34;:\u0026#34;TestCalculate\u0026#34;,\u0026#34;Output\u0026#34;:\u0026#34;--- PASS: TestCalculate (0.00s)\\n\u0026#34;} {\u0026#34;Time\u0026#34;:\u0026#34;2019-03-21T09:34:42.972612-04:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;pass\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;github.homedepot.com/om-labs/go-testing/calculate\u0026#34;,\u0026#34;Test\u0026#34;:\u0026#34;TestCalculate\u0026#34;,\u0026#34;Elapsed\u0026#34;:0} {\u0026#34;Time\u0026#34;:\u0026#34;2019-03-21T09:34:42.972632-04:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;output\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;github.homedepot.com/om-labs/go-testing/calculate\u0026#34;,\u0026#34;Output\u0026#34;:\u0026#34;PASS\\n\u0026#34;} {\u0026#34;Time\u0026#34;:\u0026#34;2019-03-21T09:34:42.973099-04:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;output\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;github.homedepot.com/om-labs/go-testing/calculate\u0026#34;,\u0026#34;Output\u0026#34;:\u0026#34;ok \\tgithub.homedepot.com/om-labs/go-testing/calculate\\t0.005s\\n\u0026#34;} {\u0026#34;Time\u0026#34;:\u0026#34;2019-03-21T09:34:42.973156-04:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;pass\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;github.homedepot.com/om-labs/go-testing/calculate\u0026#34;,\u0026#34;Elapsed\u0026#34;:0.005} Now we would have something for automated pipelines or hooks to read from.\nGenerating Coverage Reports Test coverage is a term in the software engineering realm that describes how much of a code base is exercised by its automated tests.\nTo get the test coverage for the package, we use the -cover flag with go test.\ngo test -cover Utilizing the cover flag with the previously mentioned calculate package, we get the following:\n$ go test -v -cover === RUN TestCalculate {1 2 3} {8 3 5} {6 6 36} {45 5 9} Adds: 3 Subtracts: 5 Multiplies: 36 Divides: 9 Tested Central Calculate Function. --- PASS: TestCalculate (0.00s) PASS coverage: 100.0% of statements ok github.homedepot.com/om-labs/go-testing/calculate 0.005s In the above example we\u0026rsquo;ve executed the \u0026ldquo;cover\u0026rdquo; tool which is a separate program, included in the golang distribution.\nWhen cover is asked to verify the coverage on code, it rewrites the source code to set a counter on each executable block of code and will count how many times it was executed during the automated tests. This can provide a heat map displaying this in html format.\n$ go tool cover -html=coverage.out These html files could then be hosted.\nExample:\n$ touch coverage.out $ go test -coverprofile=coverage.out {1 2 3} {8 3 5} {6 6 36} {45 5 9} Adds: 3 Subtracts: 5 Multiplies: 36 Divides: 9 Tested Central Calculate Function. PASS coverage: 100.0% of statements ok github.homedepot.com/om-labs/go-testing/calculate 0.005s $ go tool cover -html=coverage.out After running the above command, a browser automatically opens to the following:\nAnd.. Voila!\nLab Setup\n If you have not already, Fork https://github.homedepot.com/om-labs/go-testing to your homedepot profile Clone down your newly forked repo cd into the go-testing/go-test-command directory Follow the instructions found in the README  "
},
{
	"uri": "/python/relational-db/orm-querying/",
	"title": "ORM Querying",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Understanding how to query the database tables using SQLAlchemy\u0026rsquo;s Query API Learn the different functions that can be used to customize our queries Understand the different types of joins for tables with relationships Using functions to manipulate data  The Query API The Query API provides us with the Query Object.\nQuery objects are initially created using the query() method of Session - session.query(\u0026lt;MAPPED_CLASS\u0026gt;). Query is the souce of all SELECT statements generated by the ORM.\nRead Without writing a single SQL query, we are able to query a database.\nWithin the orm-python directory, create a new file called queries.py, making your file structure:\norm-python |── models.py |── queries.py └── set_up.py Place the following code block in queries.py:\nfrom models import Employee, Department, JobHistory from set_up import orm_connect from sqlalchemy.orm import sessionmaker def main(): engine = orm_connect(\u0026#39;emp_system\u0026#39;, False) session = None try: Session = sessionmaker(bind=engine) session = Session() for employee in session.query(Employee): # 1 print(employee) except Exception as e: print(e) finally: session.close() if __name__ == \u0026#34;__main__\u0026#34;: main() Output:\nEmployee: KING Employee: JONES Employee: BLAKE ... rest of employes Query functions    Function Description     count Returns the total number of rows of a query   filter Filters the query by applying a criteria   distinct Applies a distinct statement to a query   first Returns the first row in a query   exists Adds an exists operator to a subquery   get Gets the row with the primary key passed as argument   limit Limits the number of rows returned by a query   order_by Sets an order in the rows returned by a query   group_by Groups the result-set by one or more columns   join Creates a SQL join in a query   update Updating the databases current rows   delete Removes from the database the rows matched by a query    count\ncount() counts the numbers of rows that a query returns.\nIf you wanted to find the number of Employees are in the Employee table, you would do the following:\nprint(session.query(Employee).count()) Example Output:\n21 filter\nAllows searching a table for a specific keyword you would use filter(), like the following:\nfor employee in session.query(Employee).filter(Employee.emp_name == \u0026#34;MILLER\u0026#34;): print(employee) The output would be:\nEmployee: MILLER Employee: MILLER distinct\nApplies a distinct statement, only distinct (different) values, to a query. Inside a table, a column often contains many duplicate values; and sometimes you only want to list the different (distinct) values.\nShowing each distinct job value:\nfor job in session.query(JobHistory.job).distinct(): print(job) Output:\n(\u0026#39;PRESIDENT\u0026#39;,) (\u0026#39;MANAGER\u0026#39;,) (\u0026#39;ANALYST\u0026#39;,) (\u0026#39;CLERK\u0026#39;,) (\u0026#39;SALESMAN\u0026#39;,) first\nReturn the first result of this Query or None if the result doesn’t contain any row.\nShowing the first result that matches the filter\nprint(session.query(JobHistory).filter(JobHistory.salary \u0026gt; 2000).first()) Output:\nEmployee Number: 1 Started Job as PRESIDENT on: 1981-11-17 Salary: $5000.00 Showing that there is not a result at all that matches the filter\nprint(session.query(JobHistory).filter(JobHistory.salary \u0026gt; 8000).first()) Output:\nNone exists\nApplies an exists statement, which is used to test for the existence of any record in a subquery.\nShowing if any one gets a salary over $2000/month\nprint(session.query(JobHistory).filter(JobHistory.salary \u0026gt; 8000).exists()) Output:\nEXISTS (SELECT 1 FROM job_history WHERE job_history.salary \u0026gt; :salary_1) Without the call to the first() method immediately after exists(), you get back the SQL query equivalent.\nTo get back the result of either True or False, first() needs to be added.\nq = session.query(JobHistory).filter(JobHistory.salary \u0026gt; 2000).exists() print(session.query(q).first()) Output:\n(True,) get\nReturns an instance based on the given primary key identifier, or None if not found.\nSearch for Employee with a primary key (emp_no) of 7\nprint(session.query(JobHistory).get(7)) Output:\nEmployee Number: 6 Started Job as ANALYST on: 2010-05-05 Salary: $3000.00 limit\nLimits the numbers of rows that can be returned.\nReturning the first five rows in JobHistory\nfor employee in session.query(JobHistory).limit(5): print(employee) Output:\nEmployee Number: 1 Started Job as PRESIDENT on: 1981-11-17 Salary: $5000.00 Employee Number: 2 Started Job as MANAGER on: 1981-04-02 Salary: $2975.00 Employee Number: 3 Started Job as MANAGER on: 1981-05-03 Salary: $2850.00 Employee Number: 4 Started Job as MANAGER on: 1981-06-09 Salary: $2450.00 Employee Number: 5 Started Job as ANALYST on: 1981-12-03 Salary: $3000.00 order_by\nOrders rows by a column\u0026rsquo;s value.\nOrders the rows in Job History by the date they started\nfor employee in session.query(JobHistory).order_by(JobHistory.start_date): print(employee) Output:\nEmployee Number: 6 Started Job as CLERK on: 1980-12-17 Ended: 1990-05-04 Salary: $800.00 Employee Number: 10 Started Job as CLERK on: 1980-12-17 Salary: $1000.00 Employee Number: 11 Started Job as SALESMAN on: 1981-02-02 Salary: $1250.00 Employee Number: 12 Started Job as SALESMAN on: 1981-02-20 Salary: $1600.00 ... rest of the employee group_by\nOften used with aggregate functions (COUNT, MAX, MIN, SUM, AVG) to group the result-set by one or more columns.\nTo replicate SQL\u0026rsquo;s count of a number of times each value occurs in a column, use func.count().\nCounts the number of employees have each individual job\nfor job in session.query(JobHistory.job, func.count(JobHistory.job)).group_by(JobHistory.job): print(job) Output:\n(\u0026#39;PRESIDENT\u0026#39;, 1) (\u0026#39;MANAGER\u0026#39;, 3) (\u0026#39;ANALYST\u0026#39;, 2) (\u0026#39;CLERK\u0026#39;, 8) (\u0026#39;SALESMAN\u0026#39;, 11) join\nCreates a SQL JOIN against this Query object’s criterion and apply generatively, returning the newly resulting Query.\n   Diagram SQL          Consider a mapping between Employees and JobHistory, that has a relationship JobHistory.emp_no representing a collection of JobHistory objects associated with each Employees. The most common usage of join() is to create a JOIN along this relationship, using the JobHistory.emp_no attribute as an indicator for how this should occur.\nShows the Employees with Job History\nfor row in session.query(Employee).join(JobHistory): print(row) Output:\nEmployee: KING Employee: JONES Employee: BLAKE Employee: CLARK Employee: SCOTT Employee: FORD // ... rest of employee The SQL equivalent is:\nSELECT employees.emp_no AS employees_emp_no, employees.emp_name AS employees_emp_name, employees.address AS employees_address, employees.phone AS employees_phone, employees.manager AS employees_manager FROM employees INNER JOIN job_history ON employees.emp_no = job_history.emp_num Place the specific columns that you want in the output in the query method\nfor row in session.query(Employee.emp_name, JobHistory.start_date, JobHistory.job).join(JobHistory): print(row) Output:\n(\u0026#39;KING\u0026#39;, datetime.date(1981, 11, 17), \u0026#39;PRESIDENT\u0026#39;) (\u0026#39;JONES\u0026#39;, datetime.date(1981, 4, 2), \u0026#39;MANAGER\u0026#39;) (\u0026#39;BLAKE\u0026#39;, datetime.date(1981, 5, 3), \u0026#39;MANAGER\u0026#39;) (\u0026#39;CLARK\u0026#39;, datetime.date(1981, 6, 9), \u0026#39;MANAGER\u0026#39;) (\u0026#39;SCOTT\u0026#39;, datetime.date(1981, 12, 3), \u0026#39;ANALYST\u0026#39;) (\u0026#39;FORD\u0026#39;, datetime.date(1980, 12, 17), \u0026#39;CLERK\u0026#39;) // ... continued To clear up the output, alter the code to:\nfor row in session.query(Employee.emp_name, JobHistory.start_date, JobHistory.job).join(JobHistory): print(f\u0026#34;{row.emp_name} started being a {row.job} on {row.start_date}\u0026#34;) Output:\nKING started being a PRESIDENT on 1981-11-17 JONES started being a MANAGER on 1981-04-02 BLAKE started being a MANAGER on 1981-05-03 CLARK started being a MANAGER on 1981-06-09 SCOTT started being a ANALYST on 1981-12-03 FORD started being a CLERK on 1980-12-17 FORD started being a ANALYST on 1990-05-05 // ... continued If we wanted to include the name for the department, we can add an additional join with Department.\nfor row in session.query(Employee.emp_name, Employee.manager, JobHistory.start_date, JobHistory.job, Department.dept_name).join(JobHistory, Department): print(f\u0026#34;{row.emp_name} started being a {row.job} in the {row.dept_name} department on {row.start_date}\u0026#34;) Output:\nKING started being a PRESIDENT in the Accounting department on 1981-11-17 CLARK started being a MANAGER in the Accounting department on 1981-06-09 MILLER started being a CLERK in the Accounting department on 1982-01-23 JAMES started being a CLERK in the Accounting department on 1981-12-03 // ... continued The results can be filtered to match specific criteria, I.E. just getting the information for an employees current position by selecting only employees that do not have an end date:\nfor row in session.query(Employee.emp_name, Employee.manager, JobHistory.start_date, JobHistory.job, Department.dept_name).join(JobHistory, Department).filter(JobHistory.end_date == None): print(f\u0026#34;{row.emp_name} started being a {row.job} in the {row.dept_name} department on {row.start_date}\u0026#34;) full outer join\nThe FULL OUTER JOIN keyword return all records whether there is a match or not in either left (table1) or right (table2) table records.\n   Diagram SQL          To show a list of all the employee information for each department. (Even if there is not an employee in that deparment)\nquery = session.query(Department, JobHistory).join(full=True) for i in query: print(i) Output:\n(Department: Accounting Location: New York, Employee Number: 1 Started Job as PRESIDENT on: 1981-11-17 Salary: $11250.00) (Department: Research Location: Dallas, Employee Number: 1 Started Job as PRESIDENT on: 1981-11-17 Salary: $11250.00) (Department: Sales Location: Chicago, Employee Number: 1 Started Job as PRESIDENT on: 1981-11-17 Salary: $11250.00) (Department: Operations Location: Boston, Employee Number: 1 Started Job as PRESIDENT on: 1981-11-17 Salary: $11250.00) // ... continued left join\nLEFT JOIN performs a join starting with the first (left-most) table and then any matching second (right-most) table records.\n   Diagram SQL          To show a list of all the employee information for each department. (Even if there is not an employee in that deparment)\nquery = session.query(Department, JobHistory).join(JobHistory, isouter=True) for i in query: print(i) Output:\n(Department: Accounting Location: New York, Employee Number: 1 Started Job as PRESIDENT on: 1981-11-17 Salary: $11250.00) (Department: Accounting Location: New York, Employee Number: 4 Started Job as MANAGER on: 1981-06-09 Salary: $5512.50) (Department: Accounting Location: New York, Employee Number: 7 Started Job as CLERK on: 1982-01-23 Salary: $2925.00) (Department: Accounting Location: New York, Employee Number: 9 Started Job as CLERK on: 1981-12-03 Ended: 1983-01-14 Salary: $950.00) // ... continued subquery\nA subquery is a SQL query within a query, providing data to the enclosing query. Subqueries can return individual values or a list of records. A Query object is suitable for generating statements which can be used as subqueries.\nSuppose we wanted the number of JobHistory rows each Employee has. We would do that by getting the count of jobs grouped by employee ids, and JOIN to the parent.\nstmt = session.query(JobHistory.emp_no, func.count(\u0026#39;*\u0026#39;).label(\u0026#39;job_count\u0026#39;)).group_by(JobHistory.emp_no).subquery() for u, count in session.query(Employee, stmt.c.job_count).outerjoin(stmt, Employee.emp_no == stmt.c.emp_no).order_by(Employee.emp_no): print(u, count) Output:\nEmployee: KING 1 Employee: JONES 1 Employee: BLAKE 1 Employee: CLARK 1 Employee: SCOTT 1 Employee: FORD 2 // ... continued If we wanted to know the number of Employees that started after the current President of the company in order by start_date:\nt = session.query(JobHistory.start_date).filter(JobHistory.job == \u0026#39;PRESIDENT\u0026#39;).subquery(\u0026#39;t\u0026#39;) query = session.query(Employee.emp_name, JobHistory.start_date).filter(and_( Employee.emp_no == JobHistory.emp_no, JobHistory.start_date \u0026gt; t.c.start_date )).order_by(JobHistory.start_date) Output:\nSCOTT 1981-12-03 JAMES 1981-12-03 MILLER 1982-01-23 JAMES 1983-01-15 ADAMS 1987-05-23 ADAMS 1988-04-13  Go on to Read Lab here\n Update Updating the databases current rows or adding new ones.\nTo use the values parameter, place the column names and values in a dictionary format.\nGive all current employees in department 1 a 50% raise\nsession.query(JobHistory).filter(and_(JobHistory.end_date == None, JobHistory.dept_no == 1)).update({JobHistory.salary: (JobHistory.salary * 1.5)}, synchronize_session=\u0026#39;fetch\u0026#39;) session.commit() The synchronize_session chooses the strategy for the removal or updating of matched objects from the session.\nValid values are:\n   Value Description     False Means to not synchronize the session. This option is the most efficient and is reliable once the session is expired, which typically occurs after a commit(), or explicitly using expire_all(). Before the expiration, updated objects may still remain in the session with stale values on their attributes, which can lead to confusing results.   'fetch' performs a select query before the update to find objects that are matched by the update query. The updated attributes are expired on matched objects.   'evaluate' Evaluate the Query’s criteria in Python straight on the objects in the session. If evaluation of the criteria isn’t implemented, an exception is raised. The expression evaluator currently doesn’t account for differing string collations between the database and Python. The \u0026lsquo;evaluate\u0026rsquo; strategy performs a scan of all matching objects within the Session; if the contents of the Session are expired, such as via a proceeding Session.commit() call, this will result in SELECT queries emitted for every matching object.     Go on to Update Lab here\n Delete Removes from the database the rows matched by a query.\nRemoving the Employees with the last name Ford\nsession.query(Employee).filter(Employee.emp_name == \u0026#34;FORD\u0026#34;).delete(synchronize_session=\u0026#39;fetch\u0026#39;) session.commit()    Value Description     False Means to not synchronize the session. This option is the most efficient and is reliable once the session is expired, which typically occurs after a commit(), or explicitly using expire_all(). Before the expiration, objects may still remain in the session which were in fact deleted which can lead to confusing results if they are accessed via get() or already loaded collections.   'fetch' performs a select query before the delete to find objects that are matched by the delete query and need to be removed from the session. Matched objects are removed from the session.   'evaluate' Evaluate the query’s criteria in Python straight on the objects in the session. If evaluation of the criteria isn’t implemented, an error is raised. The expression evaluator currently doesn’t account for differing string collations between the database and Python.     Go on to Delete Lab here\n Summary Using the SQLAlchemy ORM allows the codebase to interact with the database resources without the need to write any SQL statements. The Query API provides the query() function that can be used in conjuction with query functions and the update() and delete() methods to perform all CRUD data manipulations.\n"
},
{
	"uri": "/golang/testing/testify-assertion/",
	"title": "Testify Assertion",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Installing testify assert methods  Life without testify Go allows for testing with its built-in testing framework.\nTake this Add function in calculate:\npackage calculate func Add(a int, b int) int { return a + b } Testing Add in calculate_test with the built-in framework looks like:\npackage calculate import ( \u0026#34;testing\u0026#34; ) func TestAdd(t *testing.T) { result := Add(2, 3) if result != 5 { t.Errorf(\u0026#34;2 + 3 != %v\u0026#34;, result) } } To run this test, call go test -v, passing the -v flag to ensure we can see a more verbose output.\nIf Add is correctly implemented, output is:\n=== RUN TestAdd --- PASS: TestAdd (0.00s) PASS ok github.homedepot.com/example/calculate 0.006s While this way works, there are other frameworks out there!\nWith testify, there is no longer a need for an if statement to check if the result matches the expected. There are testify methods that do this check instead. testify allows for tests to be written in a more natural lanuage.\nInstalling testify Since testify is not built-in, it must be installed.\nWithout Gomods While the following instructions introduce installing testify via dep, it is possible to install via go get.\nIf dep hasn\u0026rsquo;t already been set up, run the dep init command within the directory to be tested. Giving the following file structure (vendor has be shortened with ... for simplicity sake):\n. ├── Gopkg.lock ├── Gopkg.toml ├── README.md ├── calculate.go ├── calculate_test.go └── vendor └── github.com ├── ... │ 11 directories, 26 files If using git, make sure to add the vendor directory and all of its contents to .gitignore.\n Now to add testify, run the following: dep ensure -add github.com/stretchr/testify.\nOutput:\nFetching sources... \u0026#34;github.com/stretchr/testify\u0026#34; is not imported by your project, and has been temporarily added to Gopkg.lock and vendor/. If you run \u0026#34;dep ensure\u0026#34; again before actually importing it, it will disappear from Gopkg.lock and vendor/. Just as the message says, the current project does not currently use anything from the testify testing framework. So it is import to add it to the project before running dep ensure (which makes sure you are only importing libraries that are being used).\n To use the testify/assert package, \u0026quot;github.com/stretchr/testify/assert\u0026quot; should be added at the top of a test file along with the testing package:\nimport ( \u0026#34;testing\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; ) With Gomods Add \u0026quot;github.com/stretchr/testify/assert\u0026quot; to the top of a test file along with the testing package:\nimport ( \u0026#34;testing\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; ) Then run go test ./.. and testify will be added to your go.mod file.\ntestify Packages testify contains the following packages:\n  assert: provides a comprehensive set of assertion functions that tie in to the Go testing system.\n  http: contains tools to make it easier to test http activity using the Go testing system.\n  mock: provides a system by which it is possible to mock your objects and verify calls are happening as expected.\n  suite: provides a basic structure for using structs as testing suites, and methods on those structs as tests. It includes setup/teardown functionality in the way of interfaces.\n  Only assert will be discussed on this page.\nassert Methods Some of the commonly used assertion methods are:\n Equal NotEqual Nil NotNil New  Look at the Assertion documentation to see additional methods.\nEqual   Returns true if expected equals actual, then the test is passed the output is the same as a Pass message from the built-in framework.\n  Returns false if expected does not equal actual, then the test fails and a detailed error message is written to the console.\n  Signature:\nEqual(*testing.T, expected interface{}, actual interface{}, msgAndArgs ...interface{}) bool\nMessage is optional due to properties of a variadic function\nExample:\npackage calculate import ( \u0026#34;testing\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; ) func TestAdd(t *testing.T) { assert.Equal(t, 5, Add(2, 3), \u0026#34;Add does not equal the desired result\u0026#34;) } Example output if the code is incorrectly implemented:\n--- FAIL: TestAdd (0.00s) calculate_test.go:14: Error Trace: calculate_test.go:14 Error: Not equal: expected: 5 actual : -5 Test: TestAdd Messages: Add does not give desired result FAIL exit status 1 FAIL github.homedepot.com/example/assert_testing 0.015s  Error Trace Shows the file and line number of the failing test Error Gives a description from the failing test. Shows the expected and actual values. Test Gives the name of the Test function that failed Messages If a message is given, then the message is displayed.  Equalf Equivalent to Equal, but has allows for the message to be formatted according to a format specifier.\nSignature:\nEqualf(expected interface{}, actual interface{}, msg string, args ...interface{}) bool\nExample:\npackage calculate import ( \u0026#34;testing\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; ) func TestAdd(t *testing.T) { a, b := 2, 3 result := Add(a, b) assert.Equalf(t, 5, result, \u0026#34;%d + %d != %d\u0026#34;, a, b, result) } Example output if the code is incorrectly implemented:\n--- FAIL: TestAdd (0.00s) calculate_test.go:14: Error Trace: calculate_test.go:14 Error: Not equal: expected: 5 actual : -5 Test: TestAdd Messages: 2 + 3 != 3 FAIL exit status 1 FAIL github.homedepot.com/example/assert_testing 0.015s NotEqual  Returns true if expected does not equal actual, then the test is passed the output is the same as a Pass message from the built-in framework. Returns false if expected equals actual, then the test fails and a detailed error message is written to the console.  Signature:\nNotEqual(*testing.T, expected interface{}, actual interface{}, msgAndArgs ...interface{}) bool\nMessage is optional\nExample:\npackage calculate import ( \u0026#34;testing\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; ) func TestAdd(t *testing.T) { assert.NotEqual(t, 5, Add(2, 3), \u0026#34;Add does not give desired result\u0026#34;) } Example output if the code is incorrectly implemented:\n--- FAIL: TestAdd (0.00s) calculate_test.go:14: Error Trace: calculate_test.go:27 Error: Should not be: 5 Test: TestAdd Messages: Add does not give desired result FAIL exit status 1 FAIL github.homedepot.com/example/assert_testing 0.015s NotEqualf Equivalent to NotEqual, but allows for the message to be formatted according to a format specifier.\nSignature:\nNotEqualf(expected interface{}, actual interface{}, msg string, args ...interface{}) bool\nExample:\npackage calculate import ( \u0026#34;testing\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; ) func TestAdd(t *testing.T) { a, b := 2, 3 result := Add(a, b) assert.NotEqualf(t, 5, result, \u0026#34;%d + %d == %d\u0026#34;, a, b, result) } Example output if the code is incorrectly implemented:\n--- FAIL: TestAdd (0.00s) calculate_test.go:14: Error Trace: calculate_test.go:34 Error: Should not be: 5 Test: TestAdd Messages: 2 + 3 == 5 FAIL exit status 1 FAIL github.homedepot.com/example/assert_testing 0.015s  Nil   Returns true if object is nil, then the test is passed the output is the same as a Pass message from the built-in framework.\n  Returns false if object is not nil, then the test fails and a detailed error message is written to the console.\n  Signature:\nfunc Nil(t TestingT, object interface{}, msgAndArgs ...interface{}) bool\nExample:\nfunc TestInvalid(t *testing.T) { var result map[string]string assert.Nil(t, result, \u0026#34;Result is not nil\u0026#34;) }  Message is optional  Example output if the object is not nil:\n--- FAIL: TestInvalid (0.00s) calculate_test.go:12: Error Trace:\tcalculate_test.go:12 Error: Expected nil, but got: map[string]string{} Test: TestInvalid Messages: Add does not give desired result FAIL  Nilf Equivalent to Equal, but allows for the message to be formatted according to a format specifier.\nSignature:\nfunc Nilf(t TestingT, object interface{}, msg string, args ...interface{}) bool\nExample:\nfunc TestInvalid(t *testing.T) { var result map[string]string assert.Nilf(t, result, \u0026#34;%T is not nil\u0026#34;, result) } Example output if the object is not nil:\n--- FAIL: TestInvalid (0.00s) calculate_test.go:12: Error Trace:\tcalculate_test.go:12 Error: Expected nil, but got: map[string]string{} Test: TestInvalid Messages: map[string]string is not nil FAIL NotNil  Returns true if object is not nil, then the test is passed the output is the same as a Pass message from the built-in framework. Returns false if object is nil, then the test fails and a detailed error message is written to the console.  Signature:\nfunc NotNil(t TestingT, object interface{}, msgAndArgs ...interface{}) bool\nExample:\nfunc TestInvalid(t *testing.T) { result := make(map[string]string) assert.Nil(t, result, \u0026#34;Result is nil\u0026#34;) }  Message is optional  Example output if the object is nil:\n--- FAIL: TestInvalid (0.00s) calculate_test.go:34: Error Trace: calculate_test.go:34 Error: Expected value not to be nil. Test: TestInvalid Messages: Result is nil FAIL  NotNilf Equivalent to Equal, but allows for the message to be formatted according to a format specifier.\nSignature:\nfunc NotNilf(t TestingT, object interface{}, msg string, args ...interface{}) bool\nExample:\nfunc TestInvalid(t *testing.T) { var result map[string]string assert.NotNilf(t, result, \u0026#34;%T is nil\u0026#34;, result) } Example output if the object is nil:\n--- FAIL: TestInvalid (0.00s) calculate_test.go:12: Error Trace:\tcalculate_test.go:12 Error: Expected nil, but got: map[string]string{} Test: TestInvalid Messages: map[string]string is nil FAIL  New The assert.New(*testing.T) method allows for the removal of t as our first parameter every time.\nfunc TestAdd(t *testing.T) { assert := assert.New(t) assert.Equal(5, Add(2, 3), \u0026#34;Add does not give desired result\u0026#34;) } This does not change the behavior of the tests, just allows for assertion methods to be called without the testing parameter.\nWhen multiple asserts are present, New can be used so testing.T does not have to be repetitively passed in to all asserts.\nExample:\nTesting a function PrimesUpToNumber that takes in a number and returns three values: if that number is even, if that number is a prime, and a slice containing all of the prime numbers up to that point.\nExample of that test without using the New:\nfunc TestPrimesUpToNumber(t *testing.T) { isEven, isPrime, primeNumbers := PrimesUpToNumber(10) assert.Equal(t, false, isEven) assert.Equal(t, false, isPrime) assert.Equal(t, []int{2,3,5,7}, primeNumbers) } This can be cleaned up with New:\nfunc TestPrimesUpToNumber(t *testing.T) { assert := assert.New(t) isEven, isPrime, primeNumbers := PrimesUpToNumber(10) assert.Equal(false, isEven) assert.Equal(false, isPrime) assert.Equal([]int{2,3,5,7}, primeNumbers) } Subtests Example:\nfunc TestAdd(t *testing.T) { assert := assert.New(t) addTests := []struct { a int b int expected int }{ { a: 0, b: 0, expected: 0}, { a: 0, b: -5, expected: -5}, { a: 150, b: 55, expected: 205}, { a: 10, b: 37, expected: 47}, } for _, test := range addTests { assert.Equal(Add(test.a, test.b), test.expected) } } Although many scenarios are being tested, there is only one output for all of them. If one of the cases fail, the whole test function fails, and it can be difficult to tell which one failed without a useful error message.\nThe testing package t.Run method allows tests to be split out into explicit sub-tests. Run takes two parameters: a name for a subtest and a Test Function to run in a separate goroutine. This blocks until this function returns.\nSo if the above code is rewritten to:\nfunc TestAdd(t *testing.T) { assert := assert.New(t) addTests := []struct { a int b int expected int }{ { a: 0, b: 0, expected: 0}, { a: 0, b: -5, expected: -5}, { a: 150, b: 55, expected: 205}, { a: 10, b: 37, expected: 47}, } for _, test := range addTests { name := fmt.Sprintf(\u0026#34;%v+%v\u0026#34;, test.a, test.b) t.Run(name, func(t *testing.T) { result := Add(test.a, test.b) assert.Equalf(result, test.expected, \u0026#34;%v + %v != %v\u0026#34;, test.a, test.b, result) }) } } Lab Setup\n If you have not already, Fork https://github.homedepot.com/om-labs/go-testing to your homedepot profile Clone down your newly forked repo cd into the go-testing/testify-assert directory Follow the instructions found in the README  Conclusion The testify framework allows for an alternative to Go\u0026rsquo;s built-in testing framework. testify/assert package provides a comprehensive set of assertion functions that tie in to the Go testing system.\nThere is quite a strong opinion in the Gopher community that the built-in testing package should be preferred all the time in spite of its simplicity and limitations. However to get jUnit style tests or make your tests a little less verbose, testify could be a better choice.\n"
},
{
	"uri": "/cloud/",
	"title": "Cloud Offerings",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Cloud Offerings "
},
{
	"uri": "/python/relational-db/orm-testing/",
	"title": "Testing with Python and ORM",
	"tags": [],
	"description": "",
	"content": "Learning Objective  Getting familiar the Python Unittest Library Writing test using Unittest methods and assertions  Unittest Testing Library We will use the Python testing library, Unittest, to test our database interactions. Unittest provides a very straight forward way to test the methods on the PostgresConnect class.\n For a more in-depth explanation of Unittest, please refer to the Unittest documentation and Orange Academys Unittest Curriculum.\n Test Set-up In the orm-python directory, add a new file called orm-testing.py.\nMaking your file structure look like:\norm-python |── models.py |── orm_testing.py |── queries.py └── set_up.py The unittest module supports several tools for constructing and running tests. You will test the methods created in the ORM labs, in the queries.py file.\nComplete the set-up in the ORM Lab testing.\n### Imports needed to set up the test database from set_up import orm_connect from models import Shipment, Trip, Warehouse, Store, Truck from sqlalchemy.orm import sessionmaker from sqlalchemy.ext.declarative import declarative_base from sqlalchemy import cast, String ### Brings in the queries file to access the methods  ### for testing and the Unittest Library  import queries as q import unittest The first step is setting up our test class.\nclass TestOrmMethods(unittest.TestCase): #1 # This method helps to set up our test with variables that will be instantiated before each test.  def setUp(self): #2  self.engine = orm_connect(\u0026#39;test_truck_orm\u0026#39;, False) self.Base = declarative_base self.Session = sessionmaker(bind=self.engine) self.session = self.Session() # tearDown runs after each test. def tearDown(self): #3 self.session.close() if __name__ == \u0026#39;__main__\u0026#39;: unittest.main() Writing Assertions Now it\u0026rsquo;s time to write our test and add assertions to our test. Assertions assert a particular condition or expected result. A list of assertions can be found in Orange Academys Unittest Curriculum and in the Unittest documentation.\nEach test will contain assertions that will verify the various outcomes of our methods.\ndef test_insert_statement(self): #1 # Given valid argument, test the method insert 1 row of data without raising an error (success = True) self.assertTrue(q.insert_statement(self.engine,Trip(\u0026#39;1974-07-15\u0026#39;,2,8))) #2  #Given valid arguments, test the method inserts multiples rows of data without raising an error (sucess = True) new_stores = [Store(\u0026#39;Dream Aviation\u0026#39;, \u0026#39;4065 Abia Martin Drive, Brentwood, NY 11717\u0026#39;), Store(\u0026#39;Fairy Lighting\u0026#39;, \u0026#39;609 Horizon Circle, Kent, WA 98032\u0026#39;), Store(\u0026#39;Oracle Trampolines\u0026#39;, \u0026#39;3602 Rosewood Lane, New York, NY 10004\u0026#39;)] self.assertTrue(q.insert_statement(self.engine,new_stores,True)) #2 #Given an empty query, test the method sends a return of None self.assertIsNone(q.insert_statement(self.engine,\u0026#34;\u0026#34;,True)) #3 #Given an invalid query, test the method raises an error self.assertRaises(Exception,q.insert_statement(self.engine,\u0026#34;bad_query\u0026#34;)) #4 Running the test Running the tests is fairly simple. unittest.main() provides a command-line interface to the test script.\nif __name__ == \u0026#39;__main__\u0026#39;: unittest.main() The above script produces an output that looks like this:\nSuccessfully connected Trip #None at 1974-07-15 started at 2 with truck #8 Successfully added [Dream Aviation located at 4065 Abia Martin Drive, Brentwood, NY 11717, Fairy Lighting located at 609 Horizon Circle, Kent, WA 98032, Oracle Trampolines located at 3602 Rosewood Lane, New York, NY 10004] Successfully added bad_query Class \u0026#39;builtins.str\u0026#39; is not mapped . ---------------------------------------------------------------------- Ran 1 test in 0.191s OK Messages from the method are seen, as well as any Exception encountered.\nSummary Unittest provides a very easy way to check the validity of the methods created for interacting with the database. It allow for the creation of simple test cases and an easy to interpret command line read-out.\nLab In the python-databases/om-python/ directory, complete the tests in the orm_testing.py file. Run the test by typing python orm_testing.py at the command line.\n"
},
{
	"uri": "/software-eng-essentials/db-sql/sql/",
	"title": "Intro to SQL",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  DDL and DML statements SQL Scripts  Skills  Create some data in the database Read some data from the database Update some data in the database Delete some data from the database  Intro to SQL Structured Query Language(SQL) lets you access and manipulate databases.\nSQL is an ANSI (American National Standards Institute) standard, but\n although SQL is an ANSI (American National Standards Institute) standard, there are different versions of the SQL language. most RDBMS systems are SQL-92 compliant there is little variation in DML syntax there is more variation in supported datatypes and DDL statements.  What Can You Do with SQL Manage Schemas via Data Definition Language (DDL) statements:\n CREATE DATABASE - creates a new database ALTER DATABASE - modifies a database CREATE TABLE - creates a new table ALTER TABLE - modifies a table DROP TABLE - deletes a table CREATE INDEX - creates an index (search key) DROP INDEX - deletes an index set permissions on tables, procedures, and views  Manage Data via Data Manipulation Language (DML) statements:\n SELECT - extracts data from a database INSERT INTO - inserts new data into a database UPDATE - updates data in a database DELETE - deletes data from a database  DDL Statements With DDL we can create and remove databases and tables.\n Creating a PostgreSQL database called vet_clinic Connect to vet_clinic with psql:  createdb vet_clinic psql vet_clinic -U user_name The vet_clinic=\u0026gt; prompt will appear.\nCREATE a new table You can copy and paste the following into the terminal and press enter:\n/* here is a multiline comment. */ -- A DDL statement to CREATE a TABLE -- SQL comments start with 2 dashes CREATE TABLE pets ( -- table name is usually plural  id serial PRIMARY KEY, -- define the Primary Key  name varchar(50) NOT NULL, -- columns have a name, datatype, and sometimes constraints  owner varchar(50) NOT NULL, -- column names are snake_case  age integer -- this column has no constraints ); -- SQL statements end with a semicolon Use psql commands to see what just got created:\nvet_clinic=# \\d # list all objects vet_clinic=# \\dt # list all tables vet_clinic=# \\d pets # describe the pets table DROP (delete) a table: DROP TABLE IF EXISTS pets; DML Statements and CRUD DML allows for adding, removing, reading, and altering data within the tables.\nInserting Data - INSERT You can copy and paste the following into the terminal and press enter:\n-- INSERT data into a table: INSERT INTO pets -- INSERT INTO are SQL keywords (name, owner, age) -- here we list the columns we want to insert data into VALUES -- and now for the data (\u0026#39;Miko\u0026#39;, \u0026#39;Mike\u0026#39;, 4), (\u0026#39;Meisha\u0026#39;, \u0026#39;Mike\u0026#39;, 3), (\u0026#39;Max\u0026#39;, \u0026#39;Shane\u0026#39;, 6), (\u0026#39;Snoopy\u0026#39;, \u0026#39;Charlie\u0026#39;, 7), (\u0026#39;Felix\u0026#39;, \u0026#39;John\u0026#39;, 9); Output: INSERT 0 5\n We do not have to provide a value for the id, it will be generated for us by the RDBMS and will be guaranteed to be unique for each row.\nSQL commands are case-insensitive but using UPPERCASE for SQL commands and lowercase for table and column names is a nice convention!\n Reading Data - SELECT Reading data from a database is often referred to as querying the database, and the execution of the SELECT statement is often called a query.\nSELECT * FROM pets; -- \u0026#39;*\u0026#39; means return all columns SELECT id, name, age FROM pets; -- we can specify which columns to return Notice the id values that were generated for us.\nRemoving Duplicates - SELECT DISTINCT If multiple rows will return the same values for the selected columns, we can remove duplicates with the DISTINCT keyword:\nExample:\nSELECT owner FROM pets; -- contains duplicates SELECT DISTINCT owner FROM pets; -- no duplicates Filtering Results - WHERE Clause The SELECT statement has a WHERE clause for filtering out the results.\nSyntax:\nSELECT * FROM \u0026lt;table_name\u0026gt; WHERE \u0026lt;column_name\u0026gt; operator \u0026lt;value\u0026gt; [AND | OR] \u0026lt;column_name\u0026gt; operator \u0026lt;value\u0026gt; Example:\n-- SELECT all pets with an owner of Mike SELECT * FROM pets WHERE owner = \u0026#39;Mike\u0026#39;; Note the following\n the comparison in the WHERE clause is a single = Strings are in single quotes  GREATER_THAN operator example:\n-- SELECT all pets with an owner of Mike SELECT * FROM pets WHERE age \u0026gt; 4; PATTERN matching on a String:\nSELECT * FROM pets WHERE name LIKE \u0026#39;M%\u0026#39;; You can combine multiple clauses together using the AND and OR operators.\nSELECT * FROM pets WHERE age \u0026gt; 3 AND owner LIKE \u0026#39;M%\u0026#39;; Comparison Operators    Operator Notes     = Equal   \u0026lt;\u0026gt; Not equal.   != Some versions of SQL also support != for the not equal operator.   \u0026gt; Greater than   \u0026lt; Less than   \u0026gt;= Greater than or equal   \u0026lt;= Less than or equal   BETWEEN Between an inclusive range - i.e. BETWEEN x AND y   LIKE Search for a pattern - %BAMA%   IN To specify multiple possible values for a column - IN (1, 2, 3)     WHERE clauses are also used in UPDATE and DELETE statements.\n Sorting - ORDER BY SQL provides the ORDER BY clause for sorting data.\nORDER BY:\n Sorts the result-set by one or more columns Sorts the records in ascending order by default To sort in a descending order, use the DESC keyword  Syntax:\nSELECT column_name, column_name FROM table_name ORDER BY column_name, column_name ASC|DESC; Example:\nSELECT * FROM pets ORDER BY owner, age DESC; The above example orders first by the owner column. If there are multiple rows under the same owner, then sort those rows by age.\nGroup By The GROUP BY statement groups rows that have the same values into summary rows.\nSELECT column_name, column_name FROM table_name GROUP BY column_name, column_name ...; The GROUP BY statement is often used with aggregate functions to group the result-set by one or more columns. Before we show an example of using GROUP BY, we need to understand aggregate functions.\nAggregate Functions SQL provides aggregate functions for summarizing the data in a table:\n   Function Description     AVG() Returns the average value   COUNT() Returns the number of rows   MAX() Returns the largest value   MIN() Returns the smallest value   SUM() Returns the sum    Examples SELECT AVG(age) FROM pets; SELECT ROUND(AVG(age), 2) FROM pets; -- here we have combined 2 functions SELECT COUNT(*) FROM pets; SELECT COUNT(DISTINCT(owner)) FROM pets; -- how many owners are there? Notice the similarity to working with a Spreadsheet!!!\nSQL is a declarative language much like what you use in a Spreadsheet. Thus you specify what you want, not how to calculate it.\nSELECT * FROM pets ORDER BY age LIMIT 1; -- Works in PostgreSQL and MySQL, but syntax varies. GROUP BY (continued) Using aggregate functions, we are able to query things like \u0026ldquo;What is the average age of pets for each owner?\u0026quot;:\nSELECT owner, AVG(age) FROM pets GROUP BY owner; HAVING The HAVING clause was added to SQL because the WHERE keyword could not be used with aggregate functions.\nSo if we wanted to ask specifics like: \u0026ldquo;What is the average age of pets for each owner, but only the ones that have an average age over 4?\u0026rdquo;\nSELECT owner, AVG(age) FROM pets GROUP BY owner HAVING AVG(age) \u0026gt; 4; Updating Data - UPDATE Syntax:\nUPDATE table_name SET column1 = value1, column2 = value2, ... WHERE some_column = some_value; Examples:\nUPDATE pets SET age = 2 WHERE id = 2; UPDATE pets SET owner = \u0026#39;Michael\u0026#39; WHERE id IN (1, 2); TIP: When Updating or Deleting data, it is important to refer to the data being modified via its PK (i.e. ID column)!\nDeleting Data - DELETE Syntax:\nDELETE FROM table_name WHERE some_column = some_value; Example:\nDELETE FROM pets WHERE id = 2; BE CAREFUL:\nYou can easily delete all of the data from a table by leaving off the WHERE clause:\nDELETE FROM table_name; -- deletes ALL of the rows!!! PSQL Transactions You can start a new transaction in psql using the BEGIN command:\nSELECT * FROM pets; BEGIN; UPDATE pets SET age=4; -- Our attempt to update the age of a pet SELECT * FROM pets; -- OOPS, we forgot the WHERE clause and updated all of the pets. ROLLBACK; -- We just ROLLBACK to get back to before the mistake. SELECT * FROM pets; BEGIN; UPDATE pets SET age=4 WHERE id=1; -- Using a WHERE clause SELECT * FROM pets; -- Verify that it looks good! COMMIT;  What happens when you don\u0026rsquo;t use BEGIN/COMMIT/ROLLBACK in PSQL? By default, psql uses autocommit\n SQL Functions In addition to aggregate functions, there are more functions in SQL called Scalar Functions.\nScalar Functions SQL also provides scalar functions for transforming an expression:\n   Function Description     UPPER() Converts a field to upper case   LOWER() Converts a field to lower case   SUBSTRING() Extract characters from a text field   CHAR_LENGTH() Returns the length of a text field   ROUND() Rounds a numeric field to the number of decimals specified   CURRENT_TIME Returns the current system date and time   CURRENT_DATE Returns the current system date   TO_CHAR() Formats how a field or expression is to be displayed    SQL Scripts You can run SQL commands in SQL script files. Create a new file called print_pets.sql and place the following in it:\nFor example:\n-- print_pets.sql SELECT name, age, owner FROM pets ORDER BY age; You can run this script via psql:\npsql -d vet_clinic -f print_pets.sql Notice that you started with the BASH prompt and ended with the BASH prompt!\nThe psql command ran a SQL script for you!\nSummary  SQL stands for Structured Query Language. The SQL language is divided into DDL (data-definition language) and DML (data manipulation language). DDL statements are used to create and update the DB schema (structure). DML statements are used to read, insert, update, and delete data rows in tables. The 4 DML statements are SELECT, INSERT, UPDATE, and DELETE. The SELECT, UPDATE, and DELETE statements accept a WHERE clause that specifies which rows should be read, updated, or deleted.  LAB: Shopping Receipts  Run git clone https://github.com/one-thd/om_labs_databases-and-sql.git cd into the om_labs_databases-and-sql directory Go to the shopping-with-single-table folder and follow the directions found in the README.  Additional Resources  PluralSight: Introduction to SQL W3Schools: Introduction to SQL Relationships Explained  "
},
{
	"uri": "/javascript/express/middleware/",
	"title": "Understanding Middleware",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Understand how Express is a middleware engine Describe the function signature of a middleware function Explain how the order of middleware registration affects the order of execution Write a simple middleware function  Introduction Middleware is the bread and butter of the Express framework. All of the following are achieved via middleware:\n injecting any cross-cutting logic into the request processing pipeline, for example:  logging requests authorizing a user session parsing the request body and converting it into JSON parsing any browser cookies   defining routes and routers defining a 404 error handler defining a generic error handler  What is Middleware?   The following is taken from the Express Docs:\n Middleware functions are functions that have access to the request object (req), the response object (res), and the next function in the application’s request-response cycle. The next function is a function in the Express router which, when invoked, executes the middleware succeeding the current middleware.  Middleware functions can perform the following tasks:\n Execute any code. Make changes to the request and the response objects. End the request-response cycle. Call the next middleware in the stack (pipeline).   IMPORTANT: If the current middleware function does not end the request-response cycle, it must call next() to pass control to the next middleware function. Otherwise, the request will be left hanging!\n Types of Middleware An Express application can use the following types of middleware:\n Application-level middleware - via app.use() or app.get() or app.post(), etc. Router-level middleware - via router.use() or router.get() or app.post(), etc. Error-handling middleware - via app.use(function(err, req, res, next) { ... })  Express provides some built-in middleware functions and there are also many third-party / open source middleware functions available for installation via npm install.\nApplication-level Middleware Bind application-level middleware to an instance of the app object by using the app.use() and app.METHOD() functions, where METHOD is the HTTP method of the request that the middleware function handles (such as GET, PUT, or POST) in lowercase.\nYou can omit the mount path (the URL) to have the middleware invoked for all requests, or provide a mount path to have the middleware invoked only for requests matching that path.\nExample:\nimport express from \u0026#39;express\u0026#39; const app = express() const port = process.env.PORT || \u0026#39;3000\u0026#39; // DEFINE SOME MIDDLEWARE  // applies to all paths app.use((req, res, next) =\u0026gt; { console.log(\u0026#39;Time:\u0026#39;, new Date().toLocaleString()) next() // don\u0026#39;t forget to call next() }) // applies only to requests with the path \u0026#39;/users/:id\u0026#39; app.use(\u0026#39;/greeting/:name\u0026#39;, (req, res, next) =\u0026gt; { console.log(`Request: ${req.method}${req.originalUrl}`) next() // don\u0026#39;t forget to call next() }) // DEFINE SOME ROUTES  app.get(\u0026#39;/greeting/:name\u0026#39;, (req, res, next) =\u0026gt; { res.json({ message: \u0026#39;Hello \u0026#39; + req.params.name }) }) app.get(\u0026#39;/goodbye\u0026#39;, (req, res, next) =\u0026gt; { res.json({ message: \u0026#39;Farewell\u0026#39;, }) }) app.listen(port) console.log(\u0026#39;Server started on \u0026#39; + port) Multiple functions can be \u0026ldquo;chained\u0026rdquo; together to form a middleware sub-stack:\napp.use(\u0026#39;/user/:id\u0026#39;, (req, res, next) =\u0026gt; { console.log(\u0026#39;Request URL:\u0026#39;, req.originalUrl) next() }, (req, res, next) =\u0026gt; { console.log(\u0026#39;Request Type:\u0026#39;, req.method) next() }) Router-level middleware  Router-level middleware works in the same way as application-level middleware, except it is bound to an instance of express.Router(). Routers are often used to partition your routes by feature area  Example:\nimport express from \u0026#39;express\u0026#39; const router = express.Router() // a middleware function with no mount path. This code is executed for every request to the router router.use((req, res, next) =\u0026gt; { console.log(\u0026#39;Time:\u0026#39;, new Date().toLocaleString()) next() }) // a normal route for returning some data as json router.get(\u0026#39;/\u0026#39;, (req, res, next) =\u0026gt; { res.status(200).json({ message: \u0026#39;You found me!\u0026#39; }) }) export default router Route-specific Middleware A middleware function can also be added to a specific route, for example:\nimport express from \u0026#39;express\u0026#39; const router = express.Router() function validateSession(session) { return true // NOT TOO SECURE } // define a middleware function to verify that the user has a valid session function isUserAuthenticated(req, res, next) { const session = req.cookies[\u0026#39;my-session-cookie\u0026#39;] if (!validateSession(session)) { const error = new Error(\u0026#39;FORBIDDEN\u0026#39;) error.statusCode = 403 next(error) // use next to report an error  } else { req.session = session next() // use next to continue processing the request  } } // define a route that uses the above middleware router.put(\u0026#39;/update\u0026#39;, isUserAuthenticated, (req, res, next) =\u0026gt; { res.status(200).json({ message: \u0026#39;You reached the update route!\u0026#39; }) }) export default router Error-handling Middleware Define error-handling middleware functions in the same way as other middleware functions, except with four arguments instead of three, specifically with the signature (err, req, res, next)).\nIMPORTANT:\n Error-handling middleware always takes four arguments. You must provide four arguments to identify it as an error-handling middleware function. Even if you don’t need to use the next object, you must specify it to maintain the signature. Otherwise, the next object will be interpreted as regular middleware and will fail to handle errors.  Example:\napp.use(function (err, req, res, next) { console.error(err.stack) res.status(500).json({ message: \u0026#39;Something broke!\u0026#39; }) }) Built-in middleware Starting with version 4.x, Express no longer depends on Connect. The middleware functions that were previously included with Express are now in separate modules; see here for the list of provided middleware functions.\nExpress has the following built-in middleware functions:\n express.static serves static assets such as HTML files, images, and so on. express.json parses incoming requests with JSON payloads. NOTE: Available with Express 4.16.0+ express.urlencoded parses incoming requests with URL-encoded payloads. NOTE: Available with Express 4.16.0+  Third-party middleware  You can use third-party middleware to add functionality to Express apps. Simply Install the Node.js module for the required functionality, then load it in your app at the application level or at the router level.  The following example illustrates installing and loading the cookie-parsing middleware function cookie-parser.\n$ npm install cookie-parser import express from \u0026#39;express\u0026#39; const app = express() import cookieParser from \u0026#39;cookie-parser\u0026#39; // load the cookie-parsing middleware app.use(cookieParser()) For a partial list of third-party middleware functions that are commonly used with Express, see: Third-party middleware.\nA Common Middleware Configuration For RESTful APIs, a commonly used configuration of middleware would be:\nimport express from \u0026#39;express\u0026#39; import cookieParser from \u0026#39;cookie-parser\u0026#39; import morgan from \u0026#39;morgan\u0026#39; const port = process.env.PORT || \u0026#39;3000\u0026#39; const app = express() // ***** MIDDLEWARE *****  // request logging app.use(morgan(\u0026#39;dev\u0026#39;, { skip: () =\u0026gt; process.env.NODE_ENV === \u0026#39;test\u0026#39; })) // configure body parser to parse url encoded JSON payloads app.use(express.json()) app.use(express.urlencoded({ extended: false })) // Parse Cookie header and populate req.cookies with an object keyed by the cookie names. app.use(cookieParser()) // Routes go here app.get(\u0026#39;/\u0026#39;, (req, res, next) =\u0026gt; { res.json({ message: \u0026#39;The server is alive!\u0026#39;, }) }) // 404 Error handler goes here  // Generic Error handling goes here  // Connect to Port app.listen(port) console.log(\u0026#39;Server started on \u0026#39; + port) Summary  Express is largely a middleware execution engine. Middleware can be defined to handle cross-cutting concerns such as user session validation, logging, and error handling. Express routers can have their own middleware. Express provides some built-in middleware. There are also many third-party, open-source middleware functions.  Resources  Using Middleware | Express Docs Writing Middleware | Express Docs  "
},
{
	"uri": "/custom-workshops/",
	"title": "Custom workshops",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s custom workshop offerings! "
},
{
	"uri": "/cyber-security/",
	"title": "Cyber Security",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Cybersecurity offerings! "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/labs/lab-a-new-terminal/",
	"title": "A New Terminal",
	"tags": [],
	"description": "",
	"content": "A long time ago in a unix environment far, far away, young Jedi padawans who knew only of desktop software were seduced by the dark side of the Force to enter\u0026hellip; The Terminal.\nGoing to the Dark Side\nPlace your hands on your keyboard, and let the Force flow through your finger tips. No touching your mousepad!\n Open the Terminal app (use Spotlight) Make sure you are in your ~/Downloads directory. Create a directory called orange-method inside of the Downloads directory. Navigate into the newly created directory. Create a directory called a-new-terminal and cd into it. Create a new file called skywalker.txt. Rename skywalker.txt to vader.txt. Create a new directory called Deathstar. Move vader.txt into the Deathstar. List the contents of Deathstar to confirm that Vader is onboard. Create a new directory called Alderaan. Enter the Alderaan directory. Create three new files: voice1, voice2, voice3. List the voices (filenames) of Alderaan in the terminal. Use the echo command to put the following content into each voice file:  terror Terror TERROR Return to ~/Downloads/orange-method/a-new-terminal and blow up Alderaan with a single command. Move Vader back out of the Deathstar. Blow up the Deathstar. Eliminate Vadar.  "
},
{
	"uri": "/javascript/foundations/labs/arrays-lab/",
	"title": "Arrays Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch arrays.js Add the following code to arrays.js:\nconst shoppingList = [\u0026#39;pizza\u0026#39;, \u0026#39;chips\u0026#39;, \u0026#39;salsa\u0026#39;, \u0026#39;coffee\u0026#39;]; const cart = []; // TODO: add \u0026#39;apples\u0026#39; to the end of the shoppingList  // TODO: add \u0026#39;bread\u0026#39; to the front of the shoppingList  // TODO: use indexOf to replace \u0026#39;coffee\u0026#39; with \u0026#39;tea\u0026#39;  // TODO: use splice to replace `chips` and `salsa` with `rice` and `beans`  // TODO: put the first and the last items from your shoppingList into your cart  // now let\u0026#39;s see what we got console.log(\u0026#39;shoppingList:\u0026#39;, shoppingList); console.log(\u0026#39;cart:\u0026#39;, cart); Step 2: Complete the code and test Complete the TODOs in the above code.\nTest your solution with:\nnode arrays.js The expected output is:\nshoppingList: [ \u0026#39;pizza\u0026#39;, \u0026#39;rice\u0026#39;, \u0026#39;beans\u0026#39;, \u0026#39;tea\u0026#39; ] cart: [ \u0026#39;bread\u0026#39;, \u0026#39;apples\u0026#39; ] "
},
{
	"uri": "/python/automation/charts/database-interaction/db-dataframe/",
	"title": "Chart Creation",
	"tags": [],
	"description": "",
	"content": "Tables to DataFrames To have the ability to working with Pandas, we first need to convert all database tables to DataFrames.\nTransitioning from a database table to a DataFrame, you need to read in each row as a dictionary. The keys are the names of the columns, and the values are the contents of the cells of the table. The dictionaries are then placed individually at the end of a list.\nThis could be done with creating two separate data structures and using for loops to fill them or you could dramatically shorten the number of lines of code with the help of comprehensions.\nAn explanation of comprehensions can be found here\nSo you don\u0026rsquo;t have to repeat the action of writing these comprehensions, you can create a function.\nSet Up Create a new directory called chart_creation.\nCreate a new file called create_charts.py. Also add an additional directory called charts, creating the following file structure:\nchart_creation ├── charts/ └── create_charts.py In create_charts.py, add the following import statements:\nimport matplotlib.pyplot as plt import pandas as pd import numpy as np import datetime def data_frame(query, col_headers): \u0026#34;\u0026#34;\u0026#34; Takes a sqlalchemy query and a list of column headers, returns a dataframe. \u0026#34;\u0026#34;\u0026#34; def make_row(x): # 1 return dict([(c, getattr(x, c)) for c in col_headers]) # 2 return pd.DataFrame([make_row(x) for x in query])  The make_row() function is created inside the data_frame() function. This means that the scope of make_row() is enclosed. This means, once you are outside of the data_frame() function, you no longer have access to make_row() function. getattr is a function that returns the value of the named attribute of an object. This is similar to the object.name syntax.  With this new function data_frame(), we are able to give any query (or table) and a list of the column headers from the query (or table) and return a DataFrame.\nTo show usage of data_frame(), the following queries the JobHistory table to look at the number of employees at each current position and converts the results of the query to a DataFrame.\nAdd the following to create_charts.py:\nfrom models import * def num_employees(engine): df = None try: Session = sessionmaker(bind=engine) session = Session() query = session.query(JobHistory.job, func.count(JobHistory.job).label(\u0026#34;count\u0026#34;)).filter(JobHistory.end_date == None).group_by(JobHistory.job) except Exception as e: print(e) else: df = data_frame(query, [\u0026#39;job\u0026#39;, \u0026#39;count\u0026#39;]) finally: session.close() return df def main(): engine = orm_connect(\u0026#39;emp_system\u0026#39;, False) df = num_employees(engine) print(df) if __name__ == \u0026#34;__main__\u0026#34;: main() Output:\ncount job 0 1 PRESIDENT 1 3 MANAGER 2 2 ANALYST 3 4 CLERK 4 4 SALESMAN To see this information plotted out, you will need to incorporate matplotlib.\nTypes of Graphs Plotting methods allow for a handful of plot styles other than the default line plot. These methods can be provided as a method to plot(), and include:\n .bar() for bar plots .line() for line graph .hist() for histogram .box() for boxplot .area() for area plots .scatter() for scatter plots .pie() for pie plots  Bar Graph With pandas, you can choose what the the x-axis and the y-axis represent with the x and y arguments, and choose if you want to show the chart right away or save it. Additional arguments for savefig described here\nJust like the following function shown above.\ndef bar_graph(df, filename=None): df.plot.bar(x=\u0026#39;job\u0026#39;, y=\u0026#39;count\u0026#39;) if filename is not None: plt.savefig(filename) else: plt.show() Add the following to the bottom of the main:\ndf = num_employees(engine) bar_graph(df, filename=f\u0026#39;charts/bar_graph{datetime.datetime.now().date()}.png\u0026#39;)  datetime.datetime.now() gets the current date and time. You can grab the individual details of a DateTime object by calling the individual attributes, such as: .month or .day and it will return the corresponding numerical values.\n This will give an output like the following: image:/python/chart_creation/pandas_plot.png[480, 360]\nIf you want to add a title, remove the legend and rotate the x-axis labels by 45 degrees:\ndef bar_graph(df, filename=None): df.plot.bar(x=\u0026#39;job\u0026#39;, y=\u0026#39;count\u0026#39;, rot=45, legend=False, title=\u0026#39;Number of Employees per Job\u0026#39;) if filename is not None: plt.savefig(filename) else: plt.show() This will give an output like the following: image:/python/chart_creation/pandas_plot2.png[480, 360]\nAll of the arguments that you can change and their descriptions can be found here.\nLine plot Line graphs are the default plot style of Pandas. Here\u0026rsquo;s a code example of how to make a simple line plot:\ndef added_per_year(engine): df, img_name = None, None try: Session = sessionmaker(bind=engine) session = Session() q = session.query(extract(\u0026#39;year\u0026#39;, JobHistory.start_date).label(\u0026#39;year\u0026#39;), func.count(JobHistory.emp_no).label(\u0026#39;num_employees\u0026#39;)). \\ group_by(extract(\u0026#39;year\u0026#39;, JobHistory.start_date)) except Exception as e: print(e) else: df = data_frame(q, [\u0026#39;year\u0026#39;, \u0026#39;num_employees\u0026#39;]) df = df.sort_values(\u0026#39;year\u0026#39;) return df def line_graph(df, filename=None): df.plot.line(x=\u0026#39;year\u0026#39;, y=\u0026#39;num_employees\u0026#39;, label=\u0026#39;year\u0026#39;, legend=False, title=\u0026#34;Number of Employees added Each year\u0026#34;) # Get the names of all the distinct jobs and set the x axis labels if filename is not None: plt.savefig(filename) else: plt.show()  extract('year', JobHistory.start_date) gets just the year portion of a Date column\n Add the following to main():\ndf = added_per_year(engine) line_graph(df, f\u0026#39;charts/line_graph{datetime.datetime.now().date()}.png\u0026#39;) This will give an output like the following: Pie Chart def added_per_month(engine): df = None try: Session = sessionmaker(bind=engine) session = Session() query = session.query(extract(\u0026#39;month\u0026#39;, JobHistory.start_date).label(\u0026#39;month\u0026#39;), func.count(JobHistory.emp_no).label(\u0026#39;num_employees\u0026#39;)).group_by(extract(\u0026#39;month\u0026#39;, JobHistory.start_date)) except Exception as e: print(e) else: df = data_frame(query, [\u0026#39;month\u0026#39;, \u0026#39;num_employees\u0026#39;]) return df def pie_chart(df, filename=None): colors = [\u0026#34;#d2eaff\u0026#34;, \u0026#34;#dfffe4\u0026#34;, \u0026#34;#e9dafd\u0026#34;, \u0026#34;#fcffc8\u0026#34;, \u0026#34;#d8bcb5\u0026#34;, \u0026#34;#fca2cf\u0026#34;, \u0026#34;#d8f4f6\u0026#34;, \u0026#34;#ade1eb\u0026#34;, \u0026#34;#fccdd3\u0026#34;, \u0026#34;#fff2d8\u0026#34;, \u0026#34;#a69ce7\u0026#34;, \u0026#34;#e9c6ff\u0026#34;] df.plot.pie(x=\u0026#39;month\u0026#39;, y=\u0026#39;num_employees\u0026#39;, labels=df[\u0026#39;month\u0026#39;], shadow=False, colors=colors, autopct=\u0026#39;%1.1f%%\u0026#39;) if filename is not None: plt.savefig(filename) else: plt.show() Add the following to the bottom of your main():\ndf = added_per_month(engine) pie_chart(df, f\u0026#39;charts/pie_chart{datetime.datetime.now().date()}.png\u0026#39;) This will give an output like the following: image:/python/chart_creation/pie_graph.png[480, 480]\nCheck out this website for more pie chart inspiration: Matplotlib, Pandas\nChart Creation Labs\n"
},
{
	"uri": "/python/foundation/comments/",
	"title": "Comments",
	"tags": [],
	"description": "",
	"content": "An introduction to IDLE, math functions and variables\nMaking comments in our code with Python There are two types of commenting in python: single-line and multi-line\nSingle-line Comments In order to make comments that describe our programs but are not run as code, we can use the # symbol before any line we\u0026rsquo;d like the program to ignore.\nFor example, let\u0026rsquo;s put some comments in our \u0026ldquo;Hello world\u0026rdquo; program like so:\n## This is my first python program print(\u0026#34;Hello world!\u0026#34;) ## This is the end of my new Python program. In order for all Python programmers\u0026rsquo; comments to be uniform and readable, you may get certain errors regarding the formatting of comments.\nComments should be formatted with one space after the # symbol, and the first letter of the comment should be capitalized. Just like the example above.\nIf you want to make multiple single line comments, you can highlight the section of code that you would like to comment and press command + /.\nMulti-line Comments If you\u0026rsquo;d like to write more than one line in comments, use the ''' character to surround the text as follows:\n\u0026#39;\u0026#39;\u0026#39; This is an example of a multi-line comment in python. If you have a lot to say about how the program runs you can put a block of comments like so! \u0026#39;\u0026#39;\u0026#39; If you wish, you can also use double-quotes for your multi-line comments:\n\u0026#34;\u0026#34;\u0026#34; This is an example of a multi-line comment in python. If you have a lot to say about how the program runs you can put a block of comments like so! \u0026#34;\u0026#34;\u0026#34; The triple double-quotes are meant for docstrings. Python documentation strings (or docstrings) provide a convenient way of adding documentation with Python modules, functions, classes, and methods. docstring describes what the code does, not how.\nFrom now on, place the following at the top of your files:\n\u0026#34;\u0026#34;\u0026#34; title: file_name author: your_name date: current_date \u0026#34;\u0026#34;\u0026#34;  If using PyCharm, it is possible to create a template that will create a header whenever a new Python file is added.\nPyCharm \u0026gt; Preferences \u0026gt; Editor \u0026gt; File and Code Templates \u0026gt; Python Script.\nimage:header_template.png[]\nType the following in the text box.\n\u0026#34;\u0026#34;\u0026#34; title: ${NAME} author: ${USER} date: ${DATE} ${TIME} \u0026#34;\u0026#34;\u0026#34;  When creating functions, docstrings allow for a developer to describe the details of the function. The format of the docstring is autogenerated by many IDEs. An example of the pep 257 style guide for docstrings is:\ndef greeting(name, year): \u0026#34;\u0026#34;\u0026#34; Greet the user with a friendly hello and inform them of the year :param name: a string that stores the users name :param year: an integer that stores the current year :return: the concatenated string \u0026#34;\u0026#34;\u0026#34; return \u0026#34;Hello from the other side,\u0026#34; + name + \u0026#34;! It is \u0026#34; + str(year) If we wanted to see the docstring from the greeting example from above, we would do:\nhelp(greeting) Output:\ngreeting(name, year) Greet the user with a friendly hello and inform them of the year :param name: a string that stores the users name :param year: an integer that stores the current year :return: the concatenated string IMPORTANT: Please complete the first two exercises titled Multiple Print Statements and ASCII Art: Print function exercises\n"
},
{
	"uri": "/react/foundations/labs/lab-component-state/",
	"title": "Component State",
	"tags": [],
	"description": "",
	"content": "Traffic Light Part 1 - Function Components with the useState hook Follow the Basic Instructions below using all function components\nPart 2 - Class Components with the setState method Follow the Basic Instructions below using JavaScript class components for the stateful components.\n Basic Instructions Use create-react-app to write a simple Traffic Light App:\nYou should have 3 components:\n App  a stateless component that renders 3 TrafficLightController components and passes a distinct name prop to each one.   TrafficLightController  a stateful component with a name prop and a color state variable a callback function, next(), that advances to the next color: green -\u0026gt; yellow \u0026ndash;\u0026gt; red   TrafficLight  a stateless component that renders the traffic light displays the message \u0026ldquo;The color at {name} is {color}\u0026rdquo; displays a button to go to the next state (via the callback provided as a prop.)    Here is a screenshot:\nYou should verify that each button, when clicked, updates only its own TrafficLight.\n NOTE: Adding the CSS styling for colors is optional.\n "
},
{
	"uri": "/cloud/containers/developing-with-docker/containerizing-your-application/containerizing-your-application/",
	"title": "Containerizing Your Application",
	"tags": [],
	"description": "",
	"content": "Concepts  Altering code to be stateless Source code should not depend on local variables Dockerizing a runtime Copying source code into a container Container port mapping Adding a web framework dependency Leverage build cache Set working directory Set user with permissions  Code should be stateless This relates to the following Factors:\n Factor IV – Backing Services Factor VI – Processes Factor VII – Concurrency  Containers are ephemeral. They can spin up quickly and stop or die suddenly, and it\u0026rsquo;s no big deal because new containers can spin up. It would be a big deal if there was some state lost in a container crash.\nYour app should be executed in a container as one or more stateless processes. There is nothing to be shared between stateless processes, and that is ok since any data will persist in a backing service. This frees up your application to scale via the process model. With a stateless design, you should normally be able to run multiple copies of it to provide additional capacity. This principle is a default assumption in Docker Compose, Docker Swarm and Kubernetes.\nCode should not depend on local vars This relates to the following Factor:\n Factor 3 – Config  Store config in the environment: Storing configuration locally in source code as a constant variable is not cool. It is a violation of the separation between code and config. Configuration will be stored in the container as environment variables.\nDockerizing a Runtime  Hello World, from NodeJS via Docker!\n Use NodeJS to run a simple program in a container.\nNOTE: You don\u0026rsquo;t need NodeJS installed on your machine for this workshop.\nThis program will log a string to the console.\nDockerfile\nFROMalpineCMD [\u0026#34;node\u0026#34;, \u0026#34;-e\u0026#34;, \u0026#34;console.log(\u0026#39;Hello World!\u0026#39;)\u0026#34;]Build an image named hello with a tag node.\n$ docker build -t hello:node . Run a container.\n$ docker run hello:node docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused \u0026#34;exec: \\\u0026#34;node\\\u0026#34;: executable file not found in $PATH\u0026#34;: unknown. Problem – Missing dependency. The NodeJS runtime is missing from our container. An instruction could be added to the Dockerfile that installs NodeJS, but a simple solution is to use an official NodeJS image.\nSolution: Use a base image with NodeJS dependency installed.\nDockerfile\nFROMnode:alpineCMD [\u0026#34;node\u0026#34;, \u0026#34;-e\u0026#34;, \u0026#34;console.log(\u0026#39;Hello World!\u0026#39;)\u0026#34;]Rebuild the image hello:node and run the container.\nWeb server This example will build a simple web server.\nindex.js\nconst http = require(\u0026#34;http\u0026#34;); http .createServer((req, res) =\u0026gt; { console.log(\u0026#34;Request received\\n\u0026#34;); res.end(\u0026#34;Hello World!\u0026#34;); }) .listen(3000); console.log(\u0026#34;Server started...\\n\\n\u0026#34;); Dockerfile\nFROMnode:alpineCMD [\u0026#34;node\u0026#34;, \u0026#34;index.js\u0026#34;]$ docker build -t hello:node-web . $ docker run hello:node-web internal/modules/cjs/loader.js:1023 throw err; ^ Error: Cannot find module \u0026#39;/index.js\u0026#39; at Function.Module._resolveFilename (internal/modules/cjs/loader.js:1020:15) at Function.Module._load (internal/modules/cjs/loader.js:890:27) at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:71:12) at internal/main/run_main_module.js:17:47 { code: \u0026#39;MODULE_NOT_FOUND\u0026#39;, requireStack: [] } Problem – Missing source code. Solution: Copy the source code into the container to be run.\nDockerfile\nFROMnode:alpineCOPY ./ ./CMD [\u0026#34;node\u0026#34;, \u0026#34;index.js\u0026#34;]Rebuild the hello:node-web image and run the container to start the server. Test by visiting link:http://localhost:3000[localhost:3000] in the browser or by opening another terminal window and using curl:\n$ curl http://localhost:3000 Problem – There will be a failure to connect to the server. Solution: Container port mapping.\nIf the container is running it may not respond to a kbd:[control+C] or SIGINT signal. Find the running container with docker ps and stop it.\n$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES daeb7af21ea6 hello:node-web \u0026#34;docker-entrypoint.s…\u0026#34; 7 minutes ago Up 7 minutes condescending_bohr $ docker stop condescending_bohr # pass the container name or ID as an argument to `stop` Node may take ~10 seconds to terminate.\nMap the container port to the host port at runtime.\n$ docker run --rm -it -p 3000:3000 hello:node-web Test the connection again, and you should receive a response.\nStop the container with kbd:[control+C]. This is achievable since the -it flag was given at runtime and the container can receive input from the command line.\nAdd a web framework dependency package.json\n{ \u0026#34;dependencies\u0026#34;: { \u0026#34;express\u0026#34;: \u0026#34;*\u0026#34; }, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node index.js\u0026#34; } } index.js\nconst express = require(\u0026#34;express\u0026#34;); const app = express(); const PORT = process.env.PORT || 3000; app .get(\u0026#34;/\u0026#34;, (req, res) =\u0026gt; { console.log(\u0026#34;Request received\\n\u0026#34;); res.end(\u0026#34;Hello World!\u0026#34;); }) .listen(PORT, () =\u0026gt; { console.log(`Listening on port ${PORT}.`); }); $ docker build -t hello:express . Run the container for the new image.\n$ docker run --rm -it -p 3000:3000 hello:express internal/modules/cjs/loader.js:1023 throw err; ^ Error: Cannot find module \u0026#39;express\u0026#39; # ... Problem – Missing framework dependency. Solution: Run command to install missing dependencies into the container.\nDockerfile\nFROMnode:alpineCOPY ./ ./RUN npm installCMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;]Rebuild and run the image.\nProblem – Unnecessary rebuilds Change the \u0026ldquo;Hello World!\u0026rdquo; response to \u0026ldquo;Hello Home Depot!\u0026rdquo;\nNote that the changed files copy over super fast, but then every step after that cannot take advantage of caching including dependency installation which can take the longest time.\nSolution: Minimize cache busting and rebuilds.\nDockerfile\nFROMnode:alpineCOPY ./package* ./RUN npm installCOPY ./ ./CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;]Rebuild the image. Change the response to \u0026ldquo;Gimme an \u0026lsquo;H\u0026rsquo;!\u0026rdquo; and rebuild the image again. This time the image build time was faster because the dependency installation layer was cached.\nProblem – root level is working directory No working directory specified. Working at the container\u0026rsquo;s root level.\n$ docker inspect hello:express | grep WorkingDir \u0026#34;WorkingDir\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;WorkingDir\u0026#34;: \u0026#34;\u0026#34;, No working directory is specified, so the root directory is defaulted to.\n$ docker run hello:express pwd / Run $ docker run hello:express ls to see all the files in the container. This typically includes files like lib which is problematic because your image may overwrite the lib file or any others if it copies over any files with the same name. A best practice is to specify a working directory with the WORKDIR instruction.\nDockerfile\nFROMnode:alpineWORKDIR/home/node/appCOPY ./package* ./RUN npm installCOPY ./ ./CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;]Rebuild the image and run the container to verify the new working directory:\n$ docker run hello:express pwd /home/node/app Problem – Operating as root A system administration best practice is to prevent login access directly as a root user. If you run a program as root and a security flaw is exploited, the attacker has access to all data and can directly control the system.\nInspect the image to see the user specified.\n$ docker inspect hello:express | grep User \u0026#34;User\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;User\u0026#34;: \u0026#34;\u0026#34;, No user is specified. What user does the container default to?\n$ docker run hello:express whoami root Solution: Create and/or specify a user.\nDockerfile\nFROMnode:alpineUSERnodeWORKDIR/home/node/appCOPY ./package* ./RUN npm installCOPY ./ ./CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;]Try to rebuild the image you\u0026rsquo;ll see a warning like npm WARN checkPermissions Missing write access to /home/node/app and also an error message like\u0026hellip;\nProblem – permission denied npm ERR! code EACCES npm ERR! syscall access npm ERR! path /home/node/app npm ERR! errno -13 npm ERR! Error: EACCES: permission denied, access \u0026#39;/home/node/app\u0026#39; npm ERR! [Error: EACCES: permission denied, access \u0026#39;/home/node/app\u0026#39;] { npm ERR! errno: -13, npm ERR! code: \u0026#39;EACCES\u0026#39;, npm ERR! syscall: \u0026#39;access\u0026#39;, npm ERR! path: \u0026#39;/home/node/app\u0026#39; npm ERR! } npm ERR! npm ERR! The operation was rejected by your operating system. npm ERR! It is likely you do not have the permissions to access this file as the current user Solution: Give appropriate permissions to the user.\nDockerfile\nFROMnode:12-stretchRUN mkdir /home/node/app \u0026amp;\u0026amp; chown node:node /home/node/appWORKDIR/home/node/appUSERnodeCOPY --chown=node:node ./package* ./RUN npm installCOPY --chown=node:node ./ ./CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;]Rebuild the image and run the container\n$ docker run hello:express whoami node Voilà! The user is now not root. Give it up for Now Not Root!\nSummary A containerized app relates to a 12 Factor app. A containerized app is executed as one or more stateless processes. Since the app is stateless, persisted data will be in stored in databases that are treated as resources. Configuration is stored in the container as environment variables.\nEquipped with that knowledge, we built a Docker image for a web app. The image installed dependencies and copied source code into the image, and we ran a container instance of that image and published the containerized app to a port. We minimized cache busting and unnecessary rebuilds by installing certain dependencies in a particular order. We learned a couple of best practices for security: we created a working directory that was scoped away from the root level, and we set a user without root permissions.\n"
},
{
	"uri": "/custom-workshops/frontend-at-thd/react-crash-course/context-api/",
	"title": "Context API",
	"tags": [],
	"description": "",
	"content": "Learn about React\u0026rsquo;s Context API for sharing state across components.\nObjectives  Review state in a React app Learn about the Context API Explore the use cases of Context Learn the 3 steps to using the Context API  Skills  Use the context API to share state in a React app Create a Context Object Use a Provider component to provide a value Use the useContext hook to consume a value  React App State Let\u0026rsquo;s review some concepts around React app state management.\nThe Data Flows Down  A component may choose to pass its state down as props to its child components. The child components can then communicate back to the parent via callback functions. A child can also share its props with its own child components. The parent maintains control of changes to the state. Thus there is a single source of truth for any data that changes in a React application. But what if we need to share state from a parent to a descendent component that is several levels down (a grandchild or great grandchild or great great grandchild component)?  The Prop Drilling Problem    When passing props from parent to child to grandchild, often the intermediary components don\u0026rsquo;t really need to do anything with the props data. They just need to receive it in order to pass it down the line. This creates unnecessary couplings of components to props. If the props need to be refactored in some way, we will need to edit all of the intermediary components as well as the parent and the descendent that consumes the props. This is called \u0026ldquo;prop drilling\u0026rdquo; and it leads to components having props they don’t actually use, but they need to pass down the tree to components that do use them.   Prop drilling refers to the process you have to go through to get data to (deeper) parts of the React Component tree. - Kent C. Dodds\n Example of Prop Drilling:\n In the following example we pass the name prop from App \u0026ndash;\u0026gt; Navbar \u0026ndash;\u0026gt; Greeting so that it can be displayed. The Navbar component is just an intermediary that must know about and pass the name prop without needing it for any other reason.  What is the Context API?  The React Context API was added in React version 16.3. The Context API provides a way to share data through the component tree without having to pass props down manually at every level. If a component needs the data, it can subscribe to that data via a Context object and it will be re-rendered whenever that data changes.  The following diagram illustrates the difference between prop drilling and Context:\nHow to Use Context Using the new React Context API depends on three main steps:\n Create a Context object with an initial state. Typically the Context object is created and exported from its own source file, such as MyContext.js. Put the Context\u0026rsquo;s Provider component at the top of the component tree where it will be used and set its value. Consume the data provided by the Provider in any component that is a descendant of the Provider component. You can consume the data in one of two ways:   via the Context\u0026rsquo;s Consumer component (old way, needed for Class components) via the useContext hook (new easier way, nice for Function components)  Let\u0026rsquo;s look at each of these steps in more detail.\nStep 1: Create a Context Object to hold the initial state  Use React.createContext to create a Context object. The object returned will contain a Provider object and a Consumer object.  import React from \u0026#39;react\u0026#39; const MyContext = React.createContext(defaultValue) export default MyContext  As indicated above, we generally want to place the custom context object in a separate source file so that it can be imported into other components (one component using the Provider and one or more components using the Consumer or a useContext hook). React.createContext creates a Context object. When React renders a component that subscribes to this Context object it will read the current context value from the closest matching Provider above it in the tree.  About the Default Value  The defaultValue argument is only used when a component does not have a matching Provider above it in the tree. This is intended to be helpful for testing components in isolation without wrapping them, but in practice it is not very useful.   TIP: It is best not to rely on the defaultValue argument. You want your tests to match the end user experience as much as possible. Thus in practice you should just use null as the default value. See How to use React Context effectively | Kent C. Dodds.\n Step 2: Add the Provider component Add the Provider component at the top of the component subtree where the data will be needed and define its value prop.\nimport MyContext from \u0026#39;./MyContext\u0026#39; function MyContainer(props) { return ( \u0026lt;MyContext.Provider value={/* some value */}\u0026gt; {/* child components go here */ } \u0026lt;/MyContext.Provider\u0026gt; ) } export default MyContainer  NOTE: The Provider value can be any JavaScript expression, such as a Number, boolean, String, Object, or an Array!\n Every Context object comes with a Provider component that:\n allows consuming components to subscribe to context changes accepts a value prop to be shared with consuming components that are descendants of this Provider can be nested to override values higher in the component tree.  All components that subscribe to the context value that are descendants of a Provider will re-render whenever the Provider’s value prop changes.\nStep 3: Consume the value  Any components that are below the Provider in the component tree can consume the value from the Context There are 2 ways to consume the value:  For Class or Function Components: add the Consumer component from the Context object (this is the old way) For Function Components: use the useContext hook (this is the new way - it\u0026rsquo;s easier but only works for function components)    TIP: Consuming context with function components via the useContext hook is easier and less tedious than doing so with class components and the Context.Consumer component.\nExample with a Function Component (via the useContext hook):\nimport React, { useContext } from \u0026#39;react\u0026#39; import MyContext from \u0026#39;./MyContext\u0026#39; function MyContainer() { const value = useContext(MyContext) // get value from context  return ( \u0026lt;p\u0026gt;The value is {value}\u0026lt;/p\u0026gt; {/* use value in JSX */} ) } export default MyContainer Example with a Class Component (via the Consumer Component):\nimport React, { Component } from \u0026#39;react\u0026#39; import MyContext from \u0026#39;./MyContext\u0026#39; class MyComponent extends Component { render() { return ( \u0026lt;MyContext.Consumer\u0026gt; {value =\u0026gt; ( {/* get value from MyContext */} \u0026lt;p\u0026gt;The value is {value}\u0026lt;/p\u0026gt; {/* use value in JSX */} )} \u0026lt;/MyContext.Consumer\u0026gt; ) } } export default MyComponent The Context Consumer Component The Context Consumer Component:\n is just a React component that subscribes to context changes expects a function as its children prop receives its value as an argument passed to the function the value will be equal to the value prop of the closest Provider above it in the tree  Summarized Steps to Context:\n Create a Context object Put the Context\u0026rsquo;s Provider component at the top of the tree and set its value. Put the useContext or the Context\u0026rsquo;s Consumer component below the Provider to get a Context value.  Avoid Unnecessary Re-renders  Because context uses reference identity to determine when to re-render, there are some caveats that could trigger unintentional renders in consumers when a provider’s parent re-renders. For example, the code below will re-render all consumers every time the Provider re-renders because a new object is always created for the value:  function App() { return ( \u0026lt;Provider value={{ name: \u0026#39;Susan\u0026#39; }}\u0026gt; {/* the value is an object literal that gets recreated with each render */} \u0026lt;Toolbar /\u0026gt; \u0026lt;/Provider\u0026gt; ); } } To get around this, lift the value into the parent’s state:\nfunction App() { const [value, setValue] = React.useState({ name: \u0026#39;Susan\u0026#39; }) // or we could use:  const value = React.useRef() return ( \u0026lt;Provider value={value}\u0026gt; {/* now the value is no longer recreated with each render */} \u0026lt;Toolbar /\u0026gt; \u0026lt;/Provider\u0026gt; ); } } Some Applications of The Context API Themes  The ability to set the theme is a big win for UX. For example, a blogging platform may provide dark mode and light mode giving the user options to read in the low light environments. To implement themes, every component must have colors and images changed to accommodate the selected theme. Without Context it would be cumbersome and verbose to pass a theme prop to every component that might need it.  Multilingual application  Implementing multiple languages in an app would require replacing the text in every component with the translated text. But this can be easily implemented using Context. We can set the current language in a React Context and all the components in a large component tree can display text in the selected language.  Authorization  Setting the user role and info \u0026ndash; many apps require the display of dynamic content and messages based on the type of user that has logged in. We can easily add user info in a Context object.  When not to use Context  There is one drawback to using Context - it makes component reuse more difficult as it creates a dependency between the component and the Context. If you only want to avoid passing some props through many levels, component composition may be a simpler solution than context. See: Before You Use Context for more information. For a more advanced state management you may want to consider other options. You can even combine the Context API with React\u0026rsquo;s state management hooks such as the useState and useReducer to create custom hooks for sharing state.  Summary  The Context API makes it easier to share global data with many components. The Context API has been considered one of the key features of the React framework and a prominent improvement in the recent releases of the framework.  Additional Resources  React docs on Context 16-minute Wes Bos video on Context How to use React Context effectively Introduction to React Context API  "
},
{
	"uri": "/golang/concurrency/coordination/",
	"title": "Coordinating Channels",
	"tags": [],
	"description": "",
	"content": "We\u0026rsquo;ve seen how channels can be used for communication between concurrent processes, now lets discuss how to coordinate several concurrent processes.\nIn this section we\u0026rsquo;ll cover the following:\n Select : Watching several channels in one place, like a terminal at an airport. Wait Group : Waiting for several processes to complete before proceeding to something else. Mutex : Control reading and writing to a resource from concurrent processes. Context : Provides the ability to cancel or place a time limit on concurrent processes.  Select The select statement is a special keyword for dealing with multiple channels. It works exactly like a switch statement, but specifically with multiple channels.\n blocks until on of its cases can run executes the first case ready if multiple cases are ready, chooses one at random to run if a default is provided, will choose that if no cases are ready  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { // Create two channels and send messages on them concurrently \tc1 := make(chan string) c2 := make(chan string) go func() {c1 \u0026lt;- \u0026#34;hello\u0026#34;}() go func() {c2 \u0026lt;- \u0026#34;world\u0026#34;}() // Select will block until a message is received. If no message is received after 3 seconds, we send \u0026#34;timeout\u0026#34; and exit the `select` \tselect { case msg1 := \u0026lt;-c1: fmt.Println(\u0026#34;Message 1\u0026#34;, msg1) case msg2 := \u0026lt;-c2: fmt.Println(\u0026#34;Message 2\u0026#34;, msg2) case \u0026lt;-time.After(3*time.Second): fmt.Println(\u0026#34;timeout\u0026#34;) }  2 channels called c1 and c2. Either could have data placed on them at any time. We want to run similar code for either channel. We can use a select statement for this purpose.  If one or more of the communications can proceed, a single one that can proceed is chosen via a uniform pseudo-random selection. Otherwise, if there is a default case, that case is chosen.\nselect { case msg1 := \u0026lt;-c1: fmt.Println(\u0026#34;Message 1\u0026#34;, msg1) case msg2 := \u0026lt;-c2: fmt.Println(\u0026#34;Message 2\u0026#34;, msg2) default: fmt.Println(\u0026#34;No one is ready\u0026#34;)\t} If there is no default case, the select statement blocks until at least one of the communications can proceed. Unless the selected case is the default case, the respective communication operation is executed.\nLab Select  If you haven\u0026rsquo;t already, clone down the exercise repo found at https://github.homedepot.com/om-labs/go-concurrency Complete the instructions in select/README.md  Wait Group Wait Groups can be used to gracefully pause a process until all the required asynchronous processes have finished processing.\nThey can more specifically be used to hold the main process from exiting prematurely.\nWaitGroup is a constant on the sync package.\n  An instance of a WaitGroup can be created by setting a variable equal to the WaitGroup datatype, var wg sync.WaitGroup, for example.\n  Use the Add method to add a job to the WaitGroup. Pass the number of jobs you want to add to the Add method, i.e. wg.Add(2) will add two jobs.\n  Once each job finishes you would notify the group via wg.Done().\n  A wg.Wait() will wait for ALL processes to be completed before carrying on.\n  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var wg sync.WaitGroup nums := []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10} for _, val := range nums { fmt.Println(\u0026#34;in for loop\u0026#34;, val) wg.Add(1) // Tell the group there\u0026#39;s a job to wait for. \tgo func(num int) { defer wg.Done() // Tell the group that this job is finished. \tfmt.Println(num) }(val) } fmt.Println(\u0026#34;before the wait\u0026#34;) wg.Wait() // Wait for ALL processes to be complete. \tfmt.Println(\u0026#34;I\u0026#39;m done waiting!\u0026#34;) } There\u0026rsquo;s several concurrent processes that we want to run. We don\u0026rsquo;t want to exit the main function until they\u0026rsquo;re all done, so we\u0026rsquo;ll wait for each one to finish. Each job gets to tell the group when it is done working.\nIf you\u0026rsquo;re familiar with Node, a WaitGroup is similar to a Promise.All().\nLab Wait Group  If you haven\u0026rsquo;t already, clone down the exercise repo found at https://github.homedepot.com/om-labs/go-concurrency Complete the instructions in waitgroup/README.md  Mutex A Mutex is a mutual exclusion lock that allows multiple threads to use the same resource but not simultaneously, using synchonization.\nOn uniprocessor systems, a thread running into a locked mutex must sleep and hence trigger a context switch.\nOn multi-processor systems, the thread may instead poll the mutex in a spinlock. Both of these may sap performance and force processors in symmetric multiprocessing (SMP) systems to contend for the memory bus, especially if the granularity of the locking is fine.\nA Mutex is a Stuct type Go. There are two types of mutexes:\n Mutex : standard RWMutex : A Reader/Writer mutal exclusion lock. Allows any number of readers or one writer to hold the lock.  For the standard Mutex there are the method Lock and Unlock.\ntype Mutex struct{} func (m *Mutex) Lock() //Lock locks m. If the lock is already in use, the calling goroutine blocks until the mutex is available.  func (m *Mutex) Unlock() For the Reader/Writer Mutex, we have a few more methods.\ntype RWMutex struct{} func (rw *RWMutex) Lock() //Lock locks rw for writing. If the lock is already locked for reading or writing, Lock blocks until the lock is available.  func (rw *RWMutex) Unlock() //Unlock unlocks rw for writing. It is a run-time error if rw is not locked for writing on entry to Unlock.  func (rw *RWMutex) RLock() //RLock locks rw for reading.It should not be used for recursive read locking; a blocked Lock call excludes new readers from acquiring the lock.  func (rw *RWMutex) RUnlock() //RUnlock undoes a single RLock call; it does not affect other simultaneous readers. It is a run-time error if rw is not locked for reading on entry to RUnlock. If a goroutine holds a RWMutex for reading and another goroutine might call Lock, no goroutine should expect to be able to acquire a read lock until the initial read lock is released. This prohibits recursive read locking. This ensures that the lock eventually becomes available; a blocked Lock call excludes new readers from acquiring the lock.\nAn example from gobyexample.com:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) // Container holds a map of counters; since we want to // update it concurrently from multiple goroutines, we // add a `Mutex` to synchronize access. The mutex is // _embedded_ in this `struct`; this is idiomatic in Go. // Note that mutexes must not be copied, so if this // `struct` is passed around, it should be done by // pointer. type Container struct { sync.Mutex counters map[string]int } func (c *Container) inc(name string) { // Lock the mutex before accessing `counters`; unlock \t// it at the end of the function using a [defer](defer) \t// statement. Since the mutex is embedded into \t// `Container`, we can call the mutex\u0026#39;s methods like \t// `Lock` directly on `c`. \tc.Lock() defer c.Unlock() c.counters[name]++ } func main() { c := Container{ counters: map[string]int{\u0026#34;a\u0026#34;: 0, \u0026#34;b\u0026#34;: 0}, } var wg sync.WaitGroup // This function increments a named counter \t// in a loop. \tdoIncrement := func(name string, n int) { for i := 0; i \u0026lt; n; i++ { c.inc(name) } wg.Done() } // Run several goroutines concurrently; note \t// that they all access the same `Container`, \t// and two of them access the same counter. \twg.Add(3) go doIncrement(\u0026#34;a\u0026#34;, 10000) go doIncrement(\u0026#34;a\u0026#34;, 10000) go doIncrement(\u0026#34;b\u0026#34;, 10000) // Wait a for the goroutines to finish \twg.Wait() fmt.Println(c.counters) } Example using a mutex in a struct:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) type Numbers struct{ m sync.Mutex num int } func (n *Numbers) addNum( wg *sync.WaitGroup) { //pass the waitgroup as a pointer \tn.m.Lock() //since the mutex is part of the struct, it needs to be refered to through the struct \tn.num++ // increments the number \tn.m.Unlock() // unlocks the mutex \twg.Done() return } func main(){ var wg sync.WaitGroup //creates a new waitgroup variable \tan := Numbers{num: 2} // sets the initial value of num \tfmt.Println(\u0026#34;Starting goroutines...\u0026#34;) for i := 1; i \u0026lt; 1000; i++ { //kicks off 1000 go routines \twg.Add(1) go an.addNum(\u0026amp;wg) } wg.Wait() fmt.Println(\u0026#34;Done\u0026#34;) fmt.Println(an.num) // prints the final value  } Example of using the standard Mutex from Docker.\nvar lock = sync.Mutex{} func RegisterSubnet(network *net.IPNet, subnet *net.IPNet){ lock.Lock() defer lock.Unlock() key := network.String() if _, ok := allocatedIPs[key]; ok { return ErrNetworkAlreadyRegistered; } // ... }  The above mutex will ensure that no two containers use the same IP Address because they can\u0026rsquo;t register at the same time. The reason why this is important, is because you don\u0026rsquo;t want any process to register to the same subnet. Each docker container needs its own IP address.  When the first goroutine invokes RegisterSubnet, the mutex is locked. All subsequent goroutines must wait. After the first goroutine is complete registering its subnet, the mutex is unlocked. Now that the mutex is unlocked, the second goroutine may register its subnet.\nLab Mutexes  If you haven\u0026rsquo;t already, clone down the exercise repo found at https://github.homedepot.com/om-labs/go-concurrency Complete the instructions in mutex/README.md  Context Let\u0026rsquo;s face it, sometimes programs fail. We need to account for this, and make sure our applications fail gracefully. But how do we communicate a failure down several goroutines?\ncontext package to the rescue!\nThe term context refers to common scoped data within our application that we want to pass around. For example:\n Request IDs for function calls and goroutines that are part of an HTTP request call Errors when fetching data databases Cancellation signals that may occur when performing async operations using goroutines  Using the Context datatype is the idiomatic way to pass:\n cancellation signals to terminate the operation miscellaneous data required at function call invoked by the operation  Often combined with goroutines,context helps simplify data processing, cancellation, and other operations, and prevents the system from doing unnecessary work.\nContext is delivered layer by layer with Goroutines, so when an error occurs in the upper layer, and termination is required, the Goroutine in the lower layer can get the notice and process, avoiding additional overhead.\nThe Context interface has four functions:.\ntype Context interface { // Done returns a channel that is closed when this Context is canceled  // or times out.  Done() \u0026lt;-chan struct{} // Err indicates why this context was canceled, after the Done channel  // is closed.  Err() error // Deadline returns the time when this Context will be canceled, if any.  Deadline() (deadline time.Time, ok bool) // Value returns the value associated with key or nil if none.  Value(key interface{}) interface{} } Let\u0026rsquo;s consider the example of someone starting a purchase on the THD site.\n They add items to their cart, start the checkout process just as they are about to pay - they change their mind and close their browser Ideally, we don\u0026rsquo;t want that process hanging on forever, so we may use a deadline or have their browser closing send a cancellation signal that stops the process and frees up resources.  Implementation of Context Go provides two useful implementations of context, backgroundand todo.\n context.Background() returns an empty context, usually in the main or main thread, to create the parent context. context.TODO() also creates an empty context and is used in the main or main thread but has a wider application. You can use it when you are unsure of what context to use, or when you plan to receive a context.  After creating the parent context via context.Background(), we can derive more sub-contexts from it by the four With* functions provided by the context package.\n WithCancel WithTimeout WithDeadline WithValue  We will focus on the first two, WithCancel and WithTimeout.\nThis comes straight from the Go documentation\nCanceling concurrent processes WithCancel The WithCancel () function does the following:\n returns a copy of parent with a new Done channel that serves as a cancellation event. The returned context\u0026rsquo;s Done channel is closed when the returned cancel function is called or when the parent context\u0026rsquo;s Done channel is closed, whichever happens first.  Canceling this context releases the resources associated with it, so code should call cancel as soon as the operations running in this Context are complete.\nExample:\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { // gen generates integers in a separate goroutine and \t// sends them to the returned channel. \t// The callers of gen need to cancel the context once \t// they are done consuming generated integers not to leak \t// the internal goroutine started by gen. \tgen := func(ctx context.Context) \u0026lt;-chan int { dst := make(chan int) num := 1 go func() { for { select { case \u0026lt;-ctx.Done(): //The returned context\u0026#39;s Done channel is closed when the returned cancel function is called or when the parent context\u0026#39;s Done channel is closed, whichever happens first. \treturn // returning not to leak the goroutine \tcase dst \u0026lt;- num: num++ } } }() return dst //returns the current count or the Done signal \t} ctx, cancel := context.WithCancel(context.Background()) defer cancel() // cancel when we are finished consuming integers  for n := range gen(ctx) { fmt.Println(n) if n == 10 { break } } } Timing out concurrent process WithTimeout Any application that needs to maintain an SLA (service level agreement) for the maximum duration of a request, should use time based cancellation. We can create a time limit for concurrent processes to take place.\nWe start with an empty, non-nil context, but this time run the WithTimeout() method, adding a time to send the cancellation.\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) const shortDuration = 1 * time.Millisecond //determine the duration to wait before cancelling  func main() { // Pass a context with a timeout to tell a blocking function that it \t// should abandon its work after the timeout elapses. \tmycontext := context.Background() // creates an empty context \tctx, cancel := context.WithTimeout(mycontext, shortDuration) defer cancel() select { case \u0026lt;-time.After(1 * time.Second): //this is called if the Done signal is not sent within 1 second \tfmt.Println(\u0026#34;overslept\u0026#34;) case \u0026lt;-ctx.Done(): fmt.Println(ctx.Err()) // prints \u0026#34;context deadline exceeded\u0026#34; \t} } Let\u0026rsquo;s pretend that we\u0026rsquo;re the Paint experience team. Our application allows our paint vendors to create new color pallets. The following function will transfer those colors to our database, and we\u0026rsquo;ll use goroutines to speed it up. We need to account for a cancellation signal if the vendor feels they have made a mistake.\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { var wg sync.WaitGroup ctx, cancel := context.WithCancel(context.Background()) colors := map[string][]int{ \u0026#34;darkred\u0026#34;: []int{139, 0, 0}, \u0026#34;maroon\u0026#34;: []int{128, 0, 0}, \u0026#34;tomato\u0026#34;: []int{255, 99, 71}, } resultsChan := make(chan string, len(colors)) wg.Add(1) // for the parent call to saveColors. \tgo saveColors(ctx, \u0026amp;wg, colors, resultsChan) time.Sleep(time.Millisecond * 1500) cancel() // Sending the cancel signal \twg.Wait() fmt.Println(\u0026#34;before exiting.\u0026#34;) } func saveColors(ctx context.Context, wg *sync.WaitGroup, colors map[string][]int, resultsChan chan string) { defer wg.Done() // No matter how we exit, say that we\u0026#39;re finished via wg.Done  for key, val := range colors { //fmt.Println(\u0026#34;in for loop\u0026#34;, key) \tgo saveColor(key, val, resultsChan) } count := 0 for { select { case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;Cancel happened.\u0026#34;) // Cancel has been called. \treturn case succeeded := \u0026lt;-resultsChan: fmt.Println(succeeded) count++ if count == len(colors) { fmt.Println(\u0026#34;closing...\u0026#34;) close(resultsChan) return } } } } func saveColor(name string, rgb []int, resultsChan chan string) { time.Sleep(time.Second * 3) // Saved to the db... \tresultsChan \u0026lt;- fmt.Sprintf(\u0026#34;Saved %v to db.\u0026#34;, name) return } We use a WaitGroup to wait until all the concurrent processing has finished before we exit our main function.\nWe send the colors to get recorded concurrently, but listening for a cancel signal while that\u0026rsquo;s in progress.\nCaveats to context cancellations While context cancellation in Go is a versatile tool, there are a few things that you should keep in mind before proceeding. The most important of which, is a context can only be cancelled once.\n  If there are multiple errors that you would want to propagate in the same operation, then using context cancellation may not the best option.\n  The most idiomatic way to use cancellation is when you actually want to cancel something, and not just notify downstream processes that an error has occurred.\n  Lab Context  If you haven\u0026rsquo;t already, clone down the exercise repo found at https://github.homedepot.com/om-labs/go-concurrency Complete the instructions in context/README.md  Summary Selects give us the ability to listen to multiple channels at once. Wait groups provide a way to wait for a concurrent process to finish. Mutexes make can ensure that only one goroutine can change a resource at a time. Mutexes are especially helpful when working with databases.\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/colors-and-fonts/",
	"title": "CSS Colors and Fonts",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Explain how CSS works with color. Explain CSS font families and fonts.  Skills  Use CSS to set an HTML element\u0026rsquo;s text, background, and border colors. Use CSS to set an HTML element\u0026rsquo;s font style, size, and weight.  Colors With CSS we can define colors for text, backgrounds, and borders. CSS provides support for 24-bit color, providing over 16 million colors.\nA color can be specified via one of the 140 predefined colors.\n List of the 140 predefined CSS Colors A color can also be entering by its 24-bit color value.  Color valued can be entered as:\n   Notation Examples     Color Name Red, CornflowerBlue, PeachPuff   RGB values rgb(255,0,0), rgb(100,149,237), rgba(128, 128, 255, 0.5)   Hexadecimal values #FF0000, #6495ED, #FFDAB9   HSL values (CSS3) hsl(0, 100%, 50%), hsl(219, 79%, 66%), hsl(28, 100%, 86%)     Not all colors have a name. There are only 140 named colors but 2^24^ (16,777,216) possible colors.\n Opacity Colors can be defined in the Red-green-blue-alpha model (RGBa) using the rgba() functional notation. RGBa extends the RGB color model to include the alpha channel, allowing specification of the opacity of a color. a means opacity where 0=transparent and 1=opaque.\nHere are some examples:\nrgba(255,0,0,0.1) /* 10% opaque red */ rgba(255,0,0,0.4) /* 40% opaque red */ rgba(255,0,0,0.7) /* 70% opaque red */ rgba(255,0,0, 1) /* full opaque red */ Here is an example of setting various colors to an HTML section:\nsection { background-color: #0000FF; color: rgb(255, 255, 9); border: 5px solid red; } Fonts CSS provides font properties to define the font family, boldness, size, and the style of a text.\nCSS Font Families In CSS, there are two types of font family names:\n generic family - a group of font families with a similar look (like \u0026ldquo;Serif\u0026rdquo; or \u0026ldquo;Monospace\u0026rdquo;) font family - a specific font family (like \u0026ldquo;Times New Roman\u0026rdquo; or \u0026ldquo;Arial\u0026rdquo;)  The font-family Property The font family of a text is set with the font-family property.\nThe font-family property should hold several font names as a \u0026ldquo;fallback\u0026rdquo; system. If the browser does not support the first font (usually most specific font), it tries the next font, and so on all the way to a more generic family.\nIf the name of a font family is more than one word, it must be in quotation marks, like: \u0026quot;Times New Roman\u0026quot;.\nMore than one font family is specified in a comma-separated list:\np { font-family: \u0026#34;Times New Roman\u0026#34;, Times, serif; } The font-style Property The font-style property is mostly used to specify italic text.\nThis property has three values:\n normal - The text is shown normally italic - The text is shown in italics oblique - The text is \u0026ldquo;leaning\u0026rdquo; (oblique is very similar to italic, but less supported)  The font-size Property The font-size property sets the size of the text.\n Do not use font size adjustments to make paragraphs look like headings, or headings look like paragraphs! Always use the proper HTML tags, like \u0026lt;h1\u0026gt; - \u0026lt;h6\u0026gt; for headings and \u0026lt;p\u0026gt; for paragraphs.\n The font-size value can be an absolute, or relative size.\nAbsolute size  Sets the text to a specified size Does not allow a user to change the text size in all browsers (bad for accessibility reasons) Absolute size is useful when the physical size of the output is known  Relative size  Sets the size relative to surrounding elements Allows a user to change the text size in browsers  If you do not specify a font size, the default size for normal text, like paragraphs, is 16px (16px=1em).\nBest Practice: Setting Font Size with em To allow users to resize the text (in the browser menu),em is used instead of pixels by developers (and recommended by W3C).\n1em is equal to the current font size. The default text size in browsers is 16px. So, the default size of 1em is 16px. The size can be calculated from pixels to em using this formula: pixels/16=em\nh1 { font-size: 2.5em; /* 40px/16=2.5em */ } h2 { font-size: 1.875em; /* 30px/16=1.875em */ } p { font-size: 0.875em; /* 14px/16=0.875em */ } The font-weight Property The font-weight property specifies the weight of a font. The possible values are normal, bold, bolder, lighter, and the numeric values 100, 200, 300, up to 900.\np.normal { font-weight: normal; } p.thick { font-weight: bold; } The font-variant Property The font-variant property specifies whether or not a text should be displayed in a small-caps font.\nIn a small-caps font, all lowercase letters are converted to uppercase letters. However, the converted uppercase letters appears in a smaller font size than the original uppercase letters in the text.\np.normal { font-variant: normal; } p.small { font-variant: small-caps; } Summary  CSS colors can be applied to text, backgrounds, and borders. CSS provides support for 24-bit color, providing over 16 million colors. A color can be specified via one of the 140 predefined colors or via a numeric value. CSS defines a set of font-families and fonts. CSS fonts have the following properties: font-family, font-style, font-size, font-weight, and font-variant.  "
},
{
	"uri": "/python/web-framework/django_views/",
	"title": "Customizing Views",
	"tags": [],
	"description": "",
	"content": "Overview A view is a “type” of Web page in your Django application that generally serves a specific function and has a specific template. For example, in a blog application, you might have the following views:\n Blog homepage – displays the latest few entries. Entry “stores” page – permalink page for a single entry. Year-based archive page – displays all months with entries in the given year. Month-based archive page – displays all days with entries in the given month. Day-based archive page – displays all entries in the given day. Comment action – handles posting comments to a given entry.  In our store finder application, we’ll start with the following 2 views:\nMarket “index” page – displays the list of markets. Market “stores” page – displays a list of stores in specified market.\nIn Django, web pages and other content are delivered by views. Each view is represented by a simple Python function (or method, in the case of class-based views). Django will choose a view by examining the URL that’s requested (to be precise, the part of the URL after the domain name).\n Writing more views Now let’s add our new view to locations/views.py and edit our `index view. Our new view is slightly different, because it takes an argument:\nfrom django.shortcuts import render from django.http import HttpResponse def index(request): response = \u0026#34;Hello, world. You\u0026#39;re at the locations index. This will show a list of markets as cards\u0026#34; return HttpResponse(response) def stores(request, mkt_num): response= \u0026#34;Hello, world. You\u0026#39;re at the markets index. This will show a list of stores in the chosen market: %s\u0026#34; return HttpResponse(response % mkt_num) Wire the new view into the locations.urls module by adding the following path() call:\n#locations/urls ... urlpatterns = [ path(\u0026#39;\u0026#39;, views.index, name=\u0026#39;index\u0026#39;), path(\u0026#39;\u0026lt;int:mkt_num\u0026gt;/\u0026#39;, views.stores, name=\u0026#39;stores\u0026#39;), ] Take a look in your browser, at “/locations/34/”. It’ll run the stores() method and display whatever ID you provide in the URL.\nWhen somebody requests a page from your website – say, “/locations/34/”, Django will load the locations.urls Python module because it’s pointed to by the ROOT_**URLconf** setting. It finds the variable named urlpatterns and traverses the patterns in order. After finding the match at 'locations/', it strips off the matching text (\u0026quot;locations/\u0026quot;) and sends the remaining text – \u0026quot;34/\u0026quot; – to the ‘locations’ URLconf for further processing. There it matches '\u0026lt;int:mkt_num\u0026gt;/', resulting in a call to the stores() view like so:\nstores(request=\u0026lt;HttpRequest object\u0026gt;, mkt_num=34) Write views that actually do something Each view is responsible for doing one of two things: returning an HttpResponse object containing the content for the requested page, or raising an exception such as `Http404. The rest is up to you.\nYour view can read records from a database, or not. It can use a template system such as Django’s – or a third-party Python template system – or not. It can generate a PDF file, output XML, create a ZIP file on the fly, anything you want, using whatever Python libraries you want.\nAll Django wants is that HttpResponse. Or an exception.\nBecause it’s convenient, let’s use Django’s own database API. Here’s one stab at a new index() view, which displays the latest 5 location markets in the system, separated by commas, according to market number:\n#locations/views.py ... from .models import Market, Store def index(request): market_list = Market.objects.order_by(\u0026#39;number\u0026#39;)[:5] output = \u0026#39;, \u0026#39;.join([m.name for m in market_list]) return HttpResponse(output) There’s a problem with our view: the page’s design is hard-coded in the view. If you want to change the way the page looks, you’ll have to edit this Python code. So let’s use Django’s template system to separate the design from Python by creating a template that the view can use.\n Creating templates First, create a directory called templates/ in your locations directory. Django will look for templates in there.\nYour project’s TEMPLATES setting describes how Django will load and render templates. The default settings file configures a DjangoTemplates backend whose APP_DIRS option is set to True. By convention DjangoTemplates looks for a “templates” subdirectory in each of the INSTALLED_APPS.\nWithin the templates/ directory you have just created, create another directory called locations, and within that create a file called index.html. In other words, your template should be at locations/templates/locations/index.html. Because of how the app_directories template loader works as described above, you can refer to this template within Django simply as **locations/index.html**. te\n ####Template namespacing Now we might be able to get away with putting our templates directly in locations/templates (rather than creating another locations subdirectory), but it would actually be a bad idea. Django will choose the first template it finds whose name matches, and if you had a template with the same name in a different application, Django would be unable to distinguish between them. We need to be able to point Django at the right one, and the easiest way to ensure this is by namespacing them. That is, by putting those templates inside another directory named for the application itself.\n Put the following code in the body of that template:\n\u0026lt;h1\u0026gt;THD Markets\u0026lt;/h1\u0026gt; {% if market_list %} \u0026lt;ul\u0026gt; {% for market in market_list %} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;/locations/{{ market.number }}/\u0026#34;\u0026gt;{{ market.name }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; {% else %} \u0026lt;p\u0026gt;No markets are available.\u0026lt;/p\u0026gt; {% endif %} Now let’s update our index view in locations/views.py to use the template:\nfrom django.template import loader def index(request): market_list = Market.objects.order_by(\u0026#39;number\u0026#39;)[:5] template = loader.get_template(\u0026#39;locations/index.html\u0026#39;) context = { \u0026#39;market_list\u0026#39;: market_list, } return HttpResponse(template.render(context, request)) That code loads the template called **locations/index.html** and passes it a context. The context is a dictionary mapping template variable names to Python objects.\nLoad the page by pointing your browser at /locations/, and you should see a bulleted-list containing the “ATL” market. The link points to the market\u0026rsquo;s stores page\n Raising a 404 error Now, let’s tackle the market store view – the page that displays the stores for a given market. Here’s the view inside of **locations/index.html**:\nfrom django.shortcuts import get_object_or_404, render #... from .models import Market #... def stores(request, mkt_num): response= \u0026#34;Hello, world. You\u0026#39;re at the markets index. This will show a list of stores in the chosen market: %s\u0026#34; market = get_object_or_404(Market, number=mkt_num) return render(request, \u0026#39;locations/stores.html\u0026#39;, {\u0026#39;market\u0026#39;: market}) The get_object_or_404() function takes a Django model as its first argument and an arbitrary number of keyword arguments, which it passes to the get() function of the model’s manager. It raises Http404 if the object doesn’t exist.\nThere’s also a get_list_or_404() function, which works just as get_object_or_404() – except using filter() instead of get(). It raises Http404 if the list is empty.\n Using the template system #locations/stores.html \u0026lt;h1\u0026gt;{{ market.name }}\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt; {% for store in market.store_set.all %} \u0026lt;li\u0026gt;{{ store.name }}\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; The template system uses dot-lookup syntax to access variable attributes. In the example of {{ market.name }}, first Django does a dictionary lookup on the object market. Failing that, it tries an attribute lookup – which works, in this case. If attribute lookup had failed, it would’ve tried a list-index lookup.\nMethod-calling happens in the {% for %} loop: market.store_set.all is interpreted as the Python code market.store_set.all(), which returns an iterable of Store objects and is suitable for use in the {% for %} tag.\nSee the template guide for more about templates.\n Removing hardcoded URLs in templates Remember, when we wrote the link to a market in the **locations/index.html** template, the link was partially hardcoded like this:\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;/locations/{{ market.number }}/\u0026#34;\u0026gt;{{ market.name }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; The problem with this hardcoded, tightly-coupled approach is that it becomes challenging to change URLs on projects with a lot of templates. However, since you defined the name argument in the path() functions in the locations.urls module, you can remove a reliance on specific URL paths defined in your url configurations by using the {% url %} template tag:\n**`**`locations/index.html`**`** The way this works is by looking up the URL definition as specified in the locations.urls module. You can see exactly where the URL name of ‘stores’ is defined below:\n# the \u0026#39;name\u0026#39; value as called by the {% url %} template tag path(\u0026#39;\u0026lt;int:mkt_num\u0026gt;/\u0026#39;, views.stores, name=\u0026#39;stores\u0026#39;), Specific URLs If you want to change the URL of the locations stores view to something else, perhaps to something like locations/specifics/12/ instead of doing it in the template (or templates) you would change it in locations/urls.py:\n# added the word \u0026#39;specifics\u0026#39; path(\u0026#39;specifics/\u0026lt;int:market_id\u0026gt;/\u0026#39;, views.stores, name=\u0026#39;stores\u0026#39;),  Namespacing URL names The tutorial project has just one app, locations. In real Django projects, there might be five, ten, twenty apps or more. How does Django differentiate the URL names between them? For example, the locations app has a stores view, and so might an app on the same project that is for a blog. How does one make it so that Django knows which app view to create for a url when using the {% url %} template tag?\nThe answer is to add namespaces to your URLconf. In the locations/urls.py file, go ahead and add an app_name to set the application namespace:\n#locations/urls.py from django.urls import path from . import views app_name = \u0026#39;locations\u0026#39; urlpatterns = [ path(\u0026#39;\u0026#39;, views.index, name=\u0026#39;index\u0026#39;), path(\u0026#39;\u0026lt;int:mkt_num\u0026gt;/\u0026#39;, views.stores, name=\u0026#39;stores\u0026#39;), ] Now change your locations/index.html template from:\n#locations/templates/locations/index.html \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;/locations/{{ market.number }}/\u0026#34;\u0026gt;{{ market.name }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; to point at the namespaced stores view:\n#locations/templates/locations/index.html \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{% url \u0026#39;locations:stores\u0026#39; market.number %}\u0026#34;\u0026gt;{{ market.name }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; "
},
{
	"uri": "/javascript/foundations/data-types/",
	"title": "Data Types",
	"tags": [],
	"description": "",
	"content": "Understanding the data types of the JavaScript language.\nData Types JavaScript supports primitive and composite (reference) data types.\nPrimitive Types Primitive types are the most basic data types for storing data.\n   Type Description Examples     String A sequence of characters \u0026ldquo;Hello\u0026rdquo;, \u0026lsquo;123\u0026rsquo;   Number An integer or floating point number 23, 3.14, -17   Boolean A true or false value true, false    Composite (Reference) Composite or reference data types can store multiple values, each of which can be a primitive data type or another composite data type.\n   Type Description Examples     Array An indexed list of values [1, 2, 3], [\u0026lsquo;apple\u0026rsquo;, \u0026lsquo;orange\u0026rsquo;, \u0026lsquo;banana\u0026rsquo;]   Object A collection of properties each having a name and a value. { name: \u0026lsquo;Susan\u0026rsquo;, age: 23 }    Special Types and Values JavaScript supports the following special types and values:\n   Value Description Example Explanation     undefined A variable that has not been assigned a value let y; the value of y is undefined   null The intentional absence of a value (a value has not yet been determined) let x = null; the value of x is null   NaN Not a Number: the result in a mathematical error let z = 3 / \u0026lsquo;hello\u0026rsquo;; the value of z is NaN   Infinity A numeric value that is too large to represent, for example 3 / 0. let w = 3 / 0; the value of w is Infinity    The typeof Operator JavaScript provides the typeof operator for determining the data type of a variable.\nlet x = 3; console.log(typeof x); // prints \u0026#39;number\u0026#39;  x = \u0026#39;hello\u0026#39;; console.log(typeof x); // prints \u0026#39;string\u0026#39; Type Casting and Type Coercion  Sometimes we need a variable of one type to be converted into a different type (usually inside of an expression). The conversion can either be explicit (casting) or implicit (coercion).  Casting—the code explicitly converts a variable into a different type. Coercion—the JavaScript runtime converts the variable into a different type to satisfy the evaluation of an expression.    Below are some examples.\nconst n = Number(\u0026#39;123\u0026#39;); // cast a string to a number const s = String(456); // cast a number to a string const b = Boolean(\u0026#39;\u0026#39;); // cast a string to a boolean (follows the rules of truthy/falsey)  console.log(n, s, b); const n2 = +\u0026#39;123\u0026#39;; // coercion to Number to satisfy the unary `+` operator const s2 = \u0026#39;\u0026#39; + 456; // coercion to String to satisfy the binary `+` operator const b2 = !!\u0026#39;\u0026#39;; // coercion to Boolean to satisfy the logical NOT operator  console.log(n2, s2, b2); Summary  The primitive data types are String, Number, and Boolean. The composite data types are Array and Object. The typeof operator can determine the type of a value assigned to a variable. The special values are undefined, null, NaN, and Infinity. Values can be converted from one data type to another explicitly (via casting) or implicitly (via coercion).  "
},
{
	"uri": "/software-eng-essentials/db-sql/",
	"title": "Databases and SQL",
	"tags": [],
	"description": "",
	"content": "Welcome to Databases \u0026amp; SQL "
},
{
	"uri": "/software-eng-essentials/command-line-bash/directories/",
	"title": "Directories",
	"tags": [],
	"description": "",
	"content": ":lesson-title: Command Line and Bash Scripting :tags: command line commandline cli bash shell scripting scripts :description: Learning to use the power of the command line and bash shell scripting include::vars.adoc[]\n{description}\nObjectives  Directory structure Making directories Navigating directories Renaming, copying, and deleting directories    Having examined many of Unix utilities for dealing with files, the time has come to learn about directories, sometimes known by the synonym folders. As we’ll see, many of the ideas developed in the context of files also apply to directories, but there are many differences as well.\nDirectory Structure The structure of Unix-style directories is typically indicated using a list of directory names separated by forward slashes, which we can combine with the ls command (link:./manipulating-files[Manipulating Files]) like this:\n[source] $ ls /Users/KXB0QJK/ruby\nor like this:\n[source] $ ls /usr/local/bin\nAs seen in the figure below, these representations correspond to directories in a hierarchical filesystem, with (say) KXB0QJK a subdirectory of Users and ruby a subdirectory of KXB0QJK.\n.The correspondence between folders \u0026amp; directories. // To do: Add figure of GUI folder structure The most important directory for a particular user is the home directory, which on my macOS system is /Users/KXB0QJK, corresponding to my username (KXB0QJK). The home directory can be specified as an absolute path, as in /Users/KXB0QJK, or using the shorthand for the home directory is the tilde character ~ (which is typed using kbd:[⇧] + kbd:[`] (Shift-backtick). As a result, the two paths shown in the above figure are identical:\n[source] /Users/KXB0QJK/ruby/projects\nis the same as\n[source] ~/ruby/projects\n// To Do: fix the above line /Users/KXB0QJK/ruby/projects\n[TIP] Amusingly, the reason the tilde character is used for the home directory is simply because the “Home” key was the same as the key for producing “~” on some early keyboards. In addition to user directories, every Unix system has system directories for the programs essential for the computer’s normal operation. Modifying system files or directories requires special powers granted only to the superuser, known as root. (This use of “root” is unrelated to the “root directory” mentioned above.) The superuser is so powerful that it’s considered bad form to log in as root; instead, tasks executed as root should typically use the sudo command (see below).\nOrdinary Users Endowed with Super Powers sudo gives ordinary users the power to execute commands as the superuser. For example, let’s try touching a file in the system directory /opt as follows:\nimage:makeSandwich.png[caption=\u0026quot;Sudo Comic\u0026rdquo;, title=\u0026quot;Sudo Comic\u0026rdquo;, alt=\u0026quot;AWK Comic\u0026rdquo;, width=\u0026quot;600\u0026rdquo;] +\n$ touch /opt/foo touch: /opt/foo: Permission denied\nBecause normal users don’t have permission to modify /opt, the command fails, but it succeeds with sudo:\n$ sudo touch /opt/foo Password:\nAs shown, after entering sudo we are prompted to enter our user password; if entered correctly, and if the user has been configured to have sudo privileges (which is the default on most desktop Unix systems), then the command will succeed. This pattern of being denied at first, only to succeed using sudo, is a common theme in computing.\nTo check that the file really was created, we can ls it:\n$ ls -l /opt/foo -rw-r\u0026ndash;r\u0026ndash; 1 root wheel 0 Jul 23 19:13 /opt/foo\nNote that (1) a normal user can ls a file in a system directory (without sudo) and (2) the name root appears in the listing, indicating that the superuser owns the file. // To do: explain \u0026ldquo;root\u0026rdquo; and \u0026ldquo;wheel\u0026rdquo; ??? or nah?\nTo remove the file we just created, we again need superuser status:\n$ rm -f /opt/foo rm: /opt/foo: Permission denied $ sudo !! $ !ls ls: /opt/foo: No such file or directory\nHere the first rm fails, so we’ve run sudo !!, which runs sudo and then the previous command, and we’ve followed that up with !ls, which runs the previous ls command (recall from link:./inspecting-files[Inspecting Files]).\nBy the way, the su in sudo originally stood for “super-user”, but over time its use expanded, and now is usually thought of as “substitute user”. sudo is therefore a contraction of “substitute user do”, with the substitute user being the superuser by default.\n[big black]Exercises\n. In /Users/grendel/sonnets, what is the home directory? What is the username? Which directory is deepest in the hierarchy?\n. For a user with username grendel, how do /Users/grendel/beowulf and ~/beowulf differ (if at all)?\nMaking Directories So far in this course, we’ve created (and removed) a large number of text files. The time has finally come to make a directory to contain them. Although most modern operating systems include a graphical interface for this task, the Unix way to do it is with mkdir (short for “make directory”):\n[source] $ mkdir text_files\nHaving made the directory, we can move the text files there using a wildcard:\n[source] $ mv *.txt text_files/\nWe can confirm the move worked by listing the directory:\n[source] $ ls text_files/\nbeowulf_1.txt beowulf_1_reversed.txt beowulf.txt\n(Depending on how closely you’ve followed this workshop, your results may vary.)\nBy default, running ls on a directory shows its contents, but we can show just the directory using the -d option:\n[source] $ ls -d text_files/\ntext_files/ This usage is especially common with the -l option link:./manipulating-files#listing[Listing]:\n[source] $ ls -ld text_files/ drwxr-xr-x 7 KXB0QJK staff 238 Jul 24 18:07 text_files\nFinally, we can change directories using cd:\n[source] $ cd text_files/\nNote that cd typically supports tab completion, so we can actually type cd tex⇥.\nAfter running cd, we can confirm that we’re in the correct directory using the “print working directory” command, pwd, together with another call to ls:\n[source] $ pwd /Users/KXB0QJK/text_files $ ls beowulf_1.txt beowulf_1_reversed.txt beowulf.txt\nThese last steps of typing pwd to double-check the directory, and especially running ls to inspect the directory contents, are a matter of habit for many a grizzled command-line veteran. (Your result for pwd will, of course, be different, unless you happen to be using the username “KXB0QJK” on macOS.)\n[big black]Exercises\n. What is the option for making intermediate directories as required, so that you can create, e.g., ~/foo and ~/foo/bar with a single command? Hint: Refer to the man page for mkdir.\n. Use the option from the previous exercise to make the directory foo and, within it, the directory bar (i.e., ~/foo/bar) with a single command.\n. By piping the output of ls to grep, list everything in the home directory that contains the letter “o”.\nNavigating Directories We saw in the last section how to use cd to change to a directory with a given name. This is one of the most common ways of navigating, but there are a couple of special forms worth knowing. The first is changing to the directory one level up in the hierarchy using cd ..:\n[source] $ pwd /Users/KXB0QJK/text_files $ cd .. $ pwd /Users/KXB0QJK\nIn this case, because /Users/KXB0QJK is my home directory, we could have accomplished the same thing using cd by itself:\n[source] $ cd text_files/ $ pwd /Users/KXB0QJK/text_files $ cd $ pwd /Users/KXB0QJK\nThe reason this works is that cd by itself changes to the user’s home directory, wherever that is. This means that\n[source] $ cd\nand\n[source] $ cd ~\nare equivalent.\nWhen changing directories, it’s frequently useful to be able to specify the home directory somehow. For example, suppose we make a second directory and cd into it:\n[source] $ pwd /Users/KXB0QJK $ mkdir second_directory $ cd second_directory/\nNow if we want to change to the text_files directory, we can cd to text_files via the home directory ~:\n[source] $ pwd /Users/KXB0QJK/second_directory $ cd ~/text_files $ pwd /Users/KXB0QJK/text_files\nClosely related to .. for “one directory up” is . which means “the current directory”. The most common use of . is when moving or copying files to the current directory:\n[source] $ pwd /Users/KXB0QJK/text_files $ cd ~/second_directory $ ls $ cp ~/text_files/sonnets.txt . $ ls sonnets.txt\nNote in that the first call to ls returns nothing, because second_directory is initially empty.\nAnother common use of . is in conjunction with the find command, which like grep is incredibly powerful, but in my own use it looks like this 99% of the time:\n[source] $ cd $ find . -name \u0026lsquo;*.txt\u0026rsquo; ./text_files/sonnet_1.txt ./text_files/sonnet_1_reversed.txt ./text_files/sonnets.txt\nIn words, what this does is find files whose names match the pattern *.txt, starting in the current directory . and then in its subdirectories. The find utility is incredibly useful for finding a misplaced file at the command line.\nPerhaps my favorite use of . is in “open dot”, which will work only on macOS:\n[source] $ cd ~/ruby/projects $ open .\nThe remarkable open command opens its argument using whatever the default program is for the given file or directory. (A similar command, xdg-open, works on some Linux systems.) For example, open foo.pdf would open the PDF file with the default viewer (which is Preview on most Macs). In the case of a directory such as ., that default program is the Finder, so open . produces a result like that shown above. // To do: add a figure above to show GUI directory structure\nA final navigational command, and one of my personal favorites, is cd -, which cds to the previous directory, wherever it was:\n[source] $ pwd /Users/KXB0QJK/second_directory $ cd ~/text_files $ pwd /Users/KXB0QJK/text_files $ cd - /Users/KXB0QJK/second_directory\nI find that cd - is especially useful when combining commands, as described below.\nCombining commands It’s often convenient to combine commands at the command line, such as when installing software using the Unix programs configure and make, which often appear in the following sequence:\n==== [source] $ ./configure ; make ; make install This line runs the configure program from the current directory ., and then runs both make and make install. (You are not expected to understand what these programs do, and indeed they won’t work on your system unless you happen to be in the directory of a program designed to be installed this way.) Because they are separated by the semicolon character ; delimiter operator, three commands are run in sequence.\nAn even better way to combine commands is with the double-ampersand \u0026amp;\u0026amp; control operator:\n==== [source] $ ./configure \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install The difference is that commands separated by \u0026amp;\u0026amp; run only if the previous command succeeded. In contrast, with ; all the commands will be run no matter what, which will cause an error in the likely case that subsequent commands depend on the results of the ones that precede them.\nI especially like to use \u0026amp;\u0026amp; in combination with cd -, which lets me do things like this:\n==== [source] $ build_article \u0026amp;\u0026amp; cd ~/tau \u0026amp;\u0026amp; deploy \u0026amp;\u0026amp; cd - Again, you are not expected to understand these commands, but the general idea is that we can (say) build an article in one directory, cd to a different directory, deploy something (perhaps a website) to production, and then cd back (cd -) to the original directory, where we can continue our work. Then, if need be, we can just use up arrow (or one of the techniques for repeating previous commands) to retrieve the whole thing and do it all again.\n[big black]Exercises\n. How do the effects of cd and cd ~ differ (or do they)?\n. Change to text_files, then change to second_directory using the “one directory up” double dot operator ...\n. From wherever you are, create an empty file called nil in text_files using whatever method you wish.\n. Remove nil from the previous exercise using a different path from the one you used before. (In other words, if you used the path ~/text_files before, use something like ./text_files or /Users/\u0026lt;username\u0026gt;/text_files.)\nRenaming, Copying, and Deleting Directories The commands for renaming, copying, and deleting directories are similar to those for files (link:./manipulating-files#renaming_copying_deleting[Manipulating Files]), but there are some subtle differences worth noting. The command with the least difference is mv, which works just as it does for files:\n[source, bash] $ mkdir foo $ mv foo/ bar/ $ cd foo/ -bash: cd: foo: No such file or directory $ cd bar/\nHere the error message indicates that the mv worked: there is no file or directory called foo. (The word bash refers to the shell being run, in this case the “Bourne Again SHell”.) The only minor subtlety is that the trailing slashes (which are typically added automatically by tab completion (link:./manipulating-files#renaming_copying_deleting[Tab completion])) are optional:\n// To do: add a better link/tag to Tab completion\n[source, bash] $ cd $ mv bar foo $ cd foo/\nThis issue with trailing slashes never makes a difference with mv, but with cp it can be a source of much confusion. In particular, when copying directories, the behavior you usually want is to copy the directory contents including the directory, which on many systems requires leaving off the trailing slash. When copying files, you also need to include the -r option (for “recursive”). For example, to copy the contents of the text_files directory to a new directory called foobar, we use the command shown below.\n.Copy a directory. [source, bash] $ cd $ mkdir foobar $ cd foobar/ $ cp -r ./text_files . $ ls text_files\nNote that we’ve used .. to make a relative path, going up one directory and then into text_files. Also note the lack of a trailing slash in cp -r ./text_files .; if we included it, we’d get this instead.\n.Copy with a trailing slash. [source, bash] $ cp -r ./text_files/ . $ ls sonnet_1.txt sonnet_1_reversed.txt sonnets.txt text_files\nIn other words, the above example copies the individual files, but not the directory itself. As a result, I recommend always omitting the trailing slash, as in the first example; if you want to copy only the files, be explicit using the star operator, as in:\n[source, bash] $ cp ./text_files/* .\nUnlike renaming (moving) and copying directories, which use the same mv and cp commands used for files, in the case of removing directories there’s a dedicated command called rmdir. In my experience, though, it rarely works, as seen here:\n[source, bash] $ cd $ rmdir second_directory rmdir: second_directory/: Directory not empty\nThe error message here is what happens 99% of the time when I try to remove directories, because rmdir requires the directory to be empty. You can of course empty it by hand (using rm repeatedly), but this is frequently inconvenient, and I almost always use the more powerful (but much more dangerous) “remove recursive force” command rm -rf, which removes a directory, its files, and any subdirectories without confirmation.\n.Use rm -rf to remove a directory. [source, bash] $ rm -rf second_directory/ $ ls second_directory ls: second_directory: No such file or directory\nAs the error message from ls in the above example indicates (“No such file or directory”), our use of rm -rf succeeded in removing the directory.\nThe powerful command rm -rf is too convenient to ignore, but remember: “With great power comes great responsibility”\nGrep redux Now that we know a little about directories, we are in a position to add a useful grep variation to our toolkit from link:./inspecting-files#grepping[Grepping]. As with cpand rm, grep takes a “recursive” option, -r, which in this case greps through a directory’s files and the files in its subdirectories. This is incredibly useful when you’re looking for a string in a file somewhere in a hierarchy of directories, but you’re not sure where the file is. Here’s the setup, which puts the word “hierarchically” in a file called long_word.txt:\n$ cd text_files/ $ mkdir foo $ cd foo/ $ echo hierarchically \u0026gt; long_word.txt $ cd The final cd puts us back in the home directory. Suppose we now want to find the file containing “hierarchically”. The way not to do it is this:\n$ grep hierarchically text_files # This doesn\u0026#39;t work. grep: text_files: Is a directory Here grep’s error message indicates that the command didn’t work, but adding -r does the trick:\n$ grep -r hierarchically text_files text_files/foo/long_word.txt:hierarchically Because case rarely matters, I recommend making a habit of adding the -i option when grepping recursively, as follows:\n$ grep -ri hierarchically text_files text_files/foo/long_word.txt:hierarchically Armed with grep -ri, we are now equipped to find strings of our choice in arbitrarily deep hierarchies of directories.\n[big black]Exercises\n. Make a directory foo with a subdirectory bar, then rename the subdirectory to baz. . Copy all the files in text_files, with directory, into foo. . Copy all the files in text_files, without directory, into baz. . Remove foo and everything in it using a single command.\nSummary .Important commands from Directories lesson. [%header,cols=3*] |=== |Command |Description |Example\n|mkdir |Make directory with name |$ mkdir foo\n|pwd |Print working directory |$ pwd\n|cd |Change to |$ cd foo/\n|cd ~/\u0026lt;dir\u0026gt; |cd relative to home |$ cd ~/foo/\n|cd |Change to home directory |$ cd\n|cd - |Change to previous directory |$ cd \u0026amp;\u0026amp; pwd \u0026amp;\u0026amp; cd -\n|. |The current directory |$ cp ~/foo.txt .\n|.. |One directory up |$ cd ..\n|find |Find files \u0026amp; directories |$ find . -name foo*.*\n|cp -r \u0026lt;old\u0026gt; |Copy recursively |$ cp -r ~/foo .\n|rmdir \u0026lt;dir\u0026gt; |Remove (empty) dir |$ rmdir foo/\n|rm -rf \u0026lt;dir\u0026gt; |Remove dir \u0026amp; contents |$ rm -rf foo/\n|grep -ri \u0026lt;string\u0026gt; \u0026lt;dir\u0026gt; |Grep recursively (case-insensitive) |$ grep -ri foo bar/ |===\n[big black]Exercises\n. Starting in your home directory, execute a single command-line command to make a directory foo, change into it, create a file bar with content “baz”, print out bar \u0026rsquo;s contents, and then cd back to the directory you came from. + Hint: Combine the commands as described in link:./directories#combining_commands[Combining commands].\n. What happens when you run the previous command again? How many of the commands executed? Why?\n. Explain why the command rm -rf / is unbelievably dangerous, and why you should never type it into a terminal window, not even as a joke.\n. How can the previous command be made even more dangerous? + Hint: Refer link:./directories#ordinary_users_endowed_with_super_powers[Ordinary Users Endowed with Super Powers]. (This command is so dangerous you shouldn’t even think it, much less type it.)\n"
},
{
	"uri": "/cloud/containers/developing-with-docker/int-testing/networks/",
	"title": "Docker Networks",
	"tags": [],
	"description": "",
	"content": "Concepts  Describe how Docker networks allow containers to communicate Explain the default network Explain named networks and how they differ from the default network  Introduction Docker networks:\n allow containers and services to communicate with one another do not require any dependencies on Docker  Network Drivers Docker’s networking subsystem is pluggable, using drivers. Several drivers are available and provide core networking functionality.\nNOTE: You don\u0026rsquo;t need to remember all of these drivers, but we list them here to give you an idea of the drivers that are available.\n bridge: The default and most common network driver. Useful for intercommunication between standalone containers. host: Useful for standalone containers, removes the network isolation between the container and the Docker host, and uses the host’s networking directly. overlay: Overlay networks connect multiple Docker daemons together and enable swarm services to communicate with each other. macvlan: Macvlan networks allow you to assign a MAC address to a container, making it appear as a physical device on your network. none: For this container, disable all networking. Usually used in conjunction with a custom network driver. Network plugins: You can install and use third-party network plugins with Docker. These plugins are available from Docker Hub or from third-party vendors.  In this course we will be using the bridge driver.\nNetworking Commands To get started let\u0026rsquo;s look at some basic Docker networking commands:\ndocker network ls # prints a list of the current networks docker network inspect \u0026lt;network\u0026gt; # displays details about a network docker network create --driver bridge hello-net # create a bridge network docker network rm \u0026lt;network\u0026gt; # delete a network docker network prune # removes all unused networks docker network connect \u0026lt;network\u0026gt; \u0026lt;container\u0026gt; # connects a container to a network (after the container has been started) The Default Network If a container does not specify the network it should connect to, then it will be connected to the default bridge network (a network with the name bridge and using the bridge driver).\nWe will see this in the following demo.\nDefault Network Demo The following demo will start 2 containers and inspect the network that they connect to.\nHere are the commands:\n# list the current networks and notice the network with name `bridge` docker network ls # start 2 containers using the alpine image docker run -dit --name alpine1 alpine ash docker run -dit --name alpine2 alpine ash # check that both containers have started docker container ls # or docker ps # inspect the bridge network to see what containers are connected to it docker network inspect bridge You should see that the containers alpine1 and alpine2 are listed in the details of the bridge network. Make a note of the IP addresses of these containers as we will use them next.\nNow attach to alpine1 and try some ping commands\n$ docker attach alpine1 \u0026gt; ping -c 2 google.com \u0026gt; ping -c 2 \u0026lt;ip-address-of-alpine2-container\u0026gt; \u0026gt; ping -c 2 alpine2 # this will fail but we will fix it later NOTE: The last ping command will fail but we will fix it when we learn about named networks.\nDetach from alpine1 without stopping it by using the detach sequence, CTRL + p CTRL + q (hold down CTRL and type p followed by q).\nYou can then stop and remove the containers with:\ndocker stop alpine1 alpine2 docker container rm alpine1 alpine2 Named Networks Now we want to learn about named (user-defined) networks because:\n Using the default network is not recommended in production. Named networks allow you to control which containers connect to each network. With named networks containers can communicate with other containers by container name. This is called automatic service discovery.  Demo of Named Networks In this demo we will create two alpine containers that are attached to a user-defined, named network.\n# create a named network # bridge is the default driver but we include it to show how the --driver option works. docker network create --driver bridge alpine-net # show a list of networks docker network ls # create the containers docker run -dit --name alpine1 --network alpine-net alpine ash docker run -dit --name alpine2 --network alpine-net alpine ash # inspect the named network docker network inspect alpine-net Now attach to alpine1 and try the ping command to ping alpine2:\n$ docker attach alpine1 \u0026gt; ping -c 2 alpine2 # this works now because we used a named network Detach from alpine1 without stopping it by using the detach sequence, CTRL + p CTRL + q (hold down CTRL and type p followed by q).\nYou can then stop and remove the containers with:\ndocker stop alpine1 alpine2 docker container rm alpine1 alpine2 Finally you can delete the alpine-net network with:\ndocker network rm alpine-net Summary In this lesson we learned that:\n Docker networks allow containers to communicate Docker networks do not require any dependencies on Docker There is a default, bridge network Using named networks allows:  control over which containers connect to each network automatic service discovery    Resources  Networking Overview | Docker Docs Networking with Standalone Containers | Docker Docs  "
},
{
	"uri": "/cloud/containers/docker-fundamentals/docker-registries/",
	"title": "Docker Registries",
	"tags": [],
	"description": "",
	"content": "Objectives  How to use Docker Hub? How to use THD\u0026rsquo;s Artifactory  What Are Registries?  Recall that Docker registries are web services that provide a directory of available Docker images. Docker Hub is a public, remote registry that anyone can use. Docker is configured to look for images on Docker Hub by default. If required, one can host their own Docker registry and can use it for publishing and pulling images. THD provides a private Docker registry that uses Artifactory.  Docker Hub Docker Hub is the world\u0026rsquo;s easiest way to create, manage, and deliver your teams\u0026rsquo; container applications. - Docker Hub\nDocker Hub makes managing, creating and delivering containers very straightforward and less of a hassle. A Docker repository is a place to publish and access Docker images. Just like GitHub is a place to publish and access git repositories.\nIt provides the following major features:\n Repositories: Push and pull container images. Teams \u0026amp; Organizations: Manage access to private repositories of container images. Official Images: Pull and use high-quality container images provided by Docker. Publisher Images: Pull and use high- quality container images provided by external vendors. Certified images also include support and guarantee compatibility with Docker Enterprise. Builds: Automatically build container images from GitHub and Bitbucket and push them to Docker Hub. Webhooks: Trigger actions after a successful push to a repository to integrate Docker Hub with other services.  Activity: Docker Hub Quickstart Docker Hub Quickstart\nDocker Tags Docker tags convey useful information about a specific image version. They often look like image_name:the_tag. They are aliases to the ID of the image which often look like this: f0388oi11c19. It\u0026rsquo;s just a way of referring to the image.\nA good analogy is how Git tags refer to a particular commit in the history.\nNavigating THD\u0026rsquo;s Artifactory Before you pull or push images, you will want to understand the Artifactory registry layout that we have set up.\nUnderstanding the Artifactory Layout First navigate to the artifactory page. If you\u0026rsquo;ve not been here, this is a GUI view of our docker repository.\n  NOTE: You will need to login on the artifactory page before you can view most of the artifacts in the repository.\n  You may have navigated to other repositories that look similar, such as npm at npm.artifactory.homedepot.com. Aside from a few options and menu items that change, you can access the same information from here.\nFor docker there are a couple of areas you will want to be aware of.\n1. Package View\nPackage view will allow you to search for images, similar to how you would on Dockerhub. You can navigate to this search from the left menu:\nThis will present you with a search bar in the middle of the page that you can search the registry for images. For example, this search returned all images for containing flow in the name:\n2. Manually Searching for Images\nYou can manually search through repositories and images using the Artifact Repository Browser\nMake sure you expand the docker root tree. From here you will see the repository names. This is a good way to see examples of how others have stored their repositories.\n3. Image properties\nWhen you view a image tag, or repository, you may see the repository path listed something like:\ndocker/flow/base/1.221.0/\n NOTE: It is a common mistake to think this is the name you\u0026rsquo;ll use when pulling or pushing to docker. You will not need the docker/ prefix, and the tag should be separated with a colon : rather than slash. Using the above example, this would convert to flow/base:1.221.0\n See the next section on how to fully tag, name and push your image.\nAuthenticating with Artifactory via Tokens Before we can push/pull images to/from Artifactory, we must authenticate with Artifactory using a token.\nThe steps to authenticating are:\n Obtain a Token Log into Docker Artifactory using the Docker cli:  docker login docker.artifactory.homedepot.com -u $USERNAME -p $DOCKER_TOKEN\nObtaining a Token Tokens are specific to the registry instance you are accessing. This means there are different tokens for each of the following:\n maven.artifactory.homedepot.com npm.artifactory.homedepot.com docker.artifactory.homedepot.com \u0026hellip;  Therefore, you will need to request a token specific to the instance with which you are authenticating.\nBefore getting a token, read over the instructions on the DevTools Token Generator page. This covers usage as well as important details such as how long different types of tokens are good for.\nOnce you\u0026rsquo;re read over you can get your token by following these steps:\n Navigate to the token generator page  Select docker from the dropdown  Click the Copy Token button  Once on the clipboard you are ready to paste it into a credentials store, environment variable, or your preferred secure method of storing personal tokens.\nLogging into Artifactory Docker  NOTE: You only need to login if you intend to push an image up. Pulling images does not require authentication.\n Once you have a token, you can log into docker artifactory using the cli:\ndocker login [OPTIONS] [SERVER] The server and options can go in either position after the login command.\ndocker login -u exw5373 docker.artifactory.homedepot.com Note that the -p is optional. If omitted you will be prompted to enter you password.\nThe THD Artifactory Server URL is located at docker.artifactory.homedepot.com\n NOTE: Logging in sets your docker registry to the server given. By default it is set to Dockerhub. From here, all pulls and pushes will now go though our registry. until you log out. with docker logout\n Logging into Artifactory Docker via a Shell Function There is a very easy way to create a token and use the token to authenticate via a bash or zsh function. You can add this function to your .bashrc or .zshrc file and call it whenever you need to login to docker.artifactory.homedepot.com.\nThe shell function will:\n prompt you for your LDAP credentials use curl to get a token from https://token-generator.artifactory.homedepot.com/api/docker/generateToken call docker login with your LDAP credentials and the generated token  Here is the shell function that works with both BASH and ZSH:\nfunction docker-artifactory() { echo -n Artifactory User: read ARTIFACTORY_USER echo -n Artifactory Password: read -s ARTIFACTORY_PASSWORD echo echo $(curl -s -X POST -d username=\u0026#34;$ARTIFACTORY_USER\u0026#34; -d password=\u0026#34;$ARTIFACTORY_PASSWORD\u0026#34; \u0026#34;https://token-generator.artifactory.homedepot.com/api/docker/generateToken\u0026#34; | jq -r .access_token) | docker login --username $ARTIFACTORY_USER --password-stdin https://docker.artifactory.homedepot.com } Lab: Get Your Token and Login   Get your token from the token request page\n  Log into docker\n  If using Orange Academy provided iMacs, allow the CLI to prompt you for your password( token )\nPulling Images Pulling images from Artifactory works just like pulling images from Dockerhub. You need to be logged in to pull images from Artifactory. To pull an image you will specify the full path and tag:\ndocker pull docker.artifactory.homedepot.com/Orange Academy/docker/hello-nginx To run this image (aka create and run a container):\ndocker run -p 8080:80 --name hello docker.artifactory.homedepot.com/Orange Academy/docker/hello-nginx Lab: Pulling Images Try searching Artifactory for an image and pulling it down.\nSummary  How to download images, create containers from images, and start and stop containers in DockerHub. Pulling and pushing images to our THD Artifactory is essentially the same as doing so with Docker Hub. Pulling images does not require authentication but you must be on bandsaw to access our THD Artifactory to pull images.  Resources  The Docker documentation has an excellent quick start guide at Docker Overview.  "
},
{
	"uri": "/javascript/express/error-handling/",
	"title": "Error Handling",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Understand how Express uses middleware functions to handle errors Dispatch an error from a route Write a generic error handler for an Express application Write a 404 error handler for an Express application  Introduction There are 2 aspects to proper error handling:\n How to detect and dispatch an error How to handle the error and communicate it back to the client  It is important to separate these concerns so that your business logic is only concerned with detecting and dispatching errors. The business logic should not be concerned with how these errors are sent back to the client. This separation helps to keep our code DRY and easy to understand, maintain, and modify over time.\n TIP: The separation of detecting and dispatching errors from the task of handling and reporting errors is a common best practice in software engineering.\n Express.js makes it easy to handle errors in your routes. Using middleware, you can create a centralized error handler for all of your routes.\nExpress Without a Custom Error Handler Next is a simple Express app.js file with no error handling. You can find this code at Express Error Handling Starter Code.\napp.js:\nimport express from \u0026#39;express\u0026#39; const app = express(); const port = process.env.PORT || 3000; app.use(express.json()); app.use(express.urlencoded({ extended: false })); app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.status(200).json({ message: \u0026#39;The app is up and running.\u0026#39; }); }); app.get(\u0026#39;/bad\u0026#39;, (req, res, next) =\u0026gt; { const error = new Error(\u0026#39;Something bad happened!\u0026#39;); error.statusCode = 500; next(error); // dispatch an error using the `next` callback }); app.listen(port, () =\u0026gt; console.log(\u0026#39;Now listening on port\u0026#39;, port)); Dispatching Errors To dispatch an error:\n Create the error object and pass the message property as the as a parameter. This becomes the error.message used later. Attach a status code appropriate to the problem that occurred. Call next(error) to dispatch the error to the Express middleware. If next receives an argument, Express will assume there was an error, skip all other routes, and send whatever was passed to any error-handling middleware you have defined.  Error Handling of Async Operations  When using Promises, you can either use .then() and .catch() or async and await. For .catch(), simply dispatch an error from the .catch() function handler. For await, wrap your code in a try/catch and dispatch the error from the catch block:  Example:\nimport express from \u0026#39;express\u0026#39; const app = express() const port = process.env.PORT || 3000 app.use(express.json()) app.use(express.urlencoded({ extended: false })) app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.status(200).json({ message: \u0026#39;The app is up and running.\u0026#39; }) }) app.get(\u0026#39;/bad\u0026#39;, (req, res, next) =\u0026gt; { const error = new Error(\u0026#39;Something bad happened!\u0026#39;) error.statusCode = 500 next(error) // dispatch an error using the `next` callback }) function getMessage() { return new Promise((resolve, reject) =\u0026gt; { setTimeout(() =\u0026gt; resolve(\u0026#39;Have a nice day!\u0026#39;), 1000) }) } // with promise chaining app.get(\u0026#39;/message1\u0026#39;, (req, res, next) =\u0026gt; { const id = Number(req.params.id) getMessage() .then(message =\u0026gt; { res.status(201).json(message) }) .catch(err =\u0026gt; { next(err) }) }) // with async/await app.get(\u0026#39;/message2\u0026#39;, async (req, res, next) =\u0026gt; { try { const message = await getMessage() res.status(201).json(message) } catch (err) { next(err) } }) app.listen(port, () =\u0026gt; console.log(\u0026#39;Now listening on port\u0026#39;, port)) Detecting and Reporting Business Logic Errors If you need to report business logic errors, such as invalid input data or requested data not found, you can report these errors by calling next(error) from your business logic.\nFor example:\nrouter.post(\u0026#39;/:id\u0026#39;, async (req, res, next) =\u0026gt; { try { const id = Number(req.params.id); const found = await dataService.getById(id); if (!found) { const error = new Error(`Record with id ${id}not found.`); error.statusCode = 404; return next(error); } const saved = await dataService.update(id, req.body); res.status(201).json(saved); } catch (err) { next(err); } }) Let\u0026rsquo;s run our app and test it out with httpie or cURL.\nFirst test the good route:\nIf you test the route localhost:3000 you should see a successful response with a JSON payload:\n$ http localhost:3000 HTTP/1.1 200 OK X-Powered-By: Express Content-Type: application/json; charset=utf-8 Content-Length: 40 ETag: W/\u0026#34;28-EW3XbR7mbRB7zzc9t9IGgDgihgI\u0026#34; Date: Fri, 20 Sep 2019 17:48:54 GMT Connection: keep-alive {\u0026#34;message\u0026#34;:\u0026#34;The app is up and running.\u0026#34;} Now test the bad route.\nFor the bad route, we do get a 500 Internal Server Error but what\u0026rsquo;s strange is that we got an HTML response 🤨.\n Express defaults to returning the error as an HTML response. But we want a RESTful server that always returns JSON (even for errors).\n Let\u0026rsquo;s fix this by adding an error handler that will report all errors as JSON.\nAdding a Centralized Error Handler Create a centralized error handler by adding the following code after the routes in app.js:\napp.js:\n// error handler middleware app.use(function(err, req, res, next) { console.error(err.message); // Use the provided `err.statusCode` as the HTTP status code,  // otherwise use 500 for the HTTP status code.  res.status(err.statusCode || 500).json({ message: err.message }); }); app.use(function(err, req, res, next)\n NOTE: Express.js interprets any route callback with four parameters as error-handling middleware. The first parameter is err. You should put error-handling middleware at the end of your routes and middleware in your application. This let\u0026rsquo;s you catch any thrown errors.\n Now when we test the localhost:3000/bad route, we get:\n$ http localhost:3000/bad HTTP/1.1 500 Internal Server Error X-Powered-By: Express Content-Type: application/json; charset=utf-8 Content-Length: 37 ETag: W/\u0026#34;25-b0m8wdBDUbI1QEsSEfuFQddSg7Q\u0026#34; Date: Fri, 20 Sep 2019 17:56:17 GMT Connection: keep-alive {\u0026#34;message\u0026#34;:\u0026#34;Something bad happened!\u0026#34;} Much better! Our error is reported back as JSON.\nHandling 404 Errors Now let\u0026rsquo;s try hitting a route that does not exist, such as localhost:3000/whatever:\nhttp localhost:3000/whatever HTTP/1.1 404 Not Found X-Powered-By: Express Content-Security-Policy: default-src \u0026#39;none\u0026#39; X-Content-Type-Options: nosniff Content-Type: text/html; charset=utf-8 Content-Length: 147 Date: Fri, 20 Sep 2019 17:57:59 GMT Connection: keep-alive \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Error\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;pre\u0026gt;Cannot GET /whatever\u0026lt;/pre\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Wait, we get HTML again. Why?\n Well, we didn\u0026rsquo;t hit any of our routes so we have no control over how the error is dispatched.\nLet\u0026rsquo;s fix this by adding middleware to handle any routes that don\u0026rsquo;t match our specified routes.\nAdd the following code after your routes and before the general error handler.\napp.js:\n// catch 404 and forward to error handler app.use(function(req, res, next) { const err = new Error(`${req.originalUrl}not found`); err.statusCode = 404; next(err); }); Now test it out:\n$ http localhost:3000/whatever HTTP/1.1 404 Not Found X-Powered-By: Express Content-Type: application/json; charset=utf-8 Content-Length: 33 ETag: W/\u0026#34;21-iG6MafeRHuTxkasNpEe/E4QmCSw\u0026#34; Date: Fri, 20 Sep 2019 18:03:43 GMT Connection: keep-alive {\u0026#34;message\u0026#34;:\u0026#34;/whatever not found\u0026#34;} Great! Now we can handle errors we detect and dispatch 404 errors, and the centralized error handler always sends the error message as a JSON response.\nConclusion Express makes it easy to dispatch and report errors. We use the next callback to dispatch an error. Then we use middleware functions to handle both 404 and dispatched errors.\n"
},
{
	"uri": "/javascript/express/",
	"title": "Express",
	"tags": [],
	"description": "",
	"content": "Welcome to Express! "
},
{
	"uri": "/golang/api/external-apis/",
	"title": "External APIs",
	"tags": [],
	"description": "",
	"content": "Objectives  Discuss how to pull in data from an external API Display data from 3rd party along-side existing data Collect and send information to external API Formatting the data once retrieved  API Interaction To interact with APIs in Go, this lesson will use the net/http package provides HTTP client and server implementations.\nGet, Head, Post, and PostForm make HTTP (or HTTPS) requests without the need to create an HTTP client. (These will be discussed in greater detail later in this lesson)\nFirst glance at HTTP methods\nresp, err := http.Get(\u0026#34;http://example.com/\u0026#34;) ... resp, err := http.Post(\u0026#34;http://example.com/upload\u0026#34;, \u0026#34;application/json\u0026#34;, \u0026amp;buf) ... resp, err := http.PostForm(\u0026#34;http://example.com/form\u0026#34;, url.Values{\u0026#34;key\u0026#34;: {\u0026#34;Value\u0026#34;}, \u0026#34;id\u0026#34;: {\u0026#34;123\u0026#34;}}) An HTTP client needs to be created to do a PUT, PATCH, and DELETE. Making an HTTP (or HTTPS) request with creating a Client takes three parts:\nclient := \u0026amp;http.Client{}\t//1 req, err := http.NewRequest(http.MethodPut, url, data)\t//2 response, err := client.Do(req)\t//3  Create an HTTP client Create a new request given an HTTP action(PUT in the above example), URL, and optional body. Send an HTTP request and returns an HTTP response, following policy (such as redirects, cookies, auth) as configured on the client.  GET We\u0026rsquo;ll begin by making a simple call to an open API, MARTA RealTime Bus API. The endpoint URL is http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetAllBus. This API requires no sign-ups or keys for access. When a call is made to the API, a JSON dataset is returned that lists the real-time location information of all MARTA Buses.\nThe net/http package\u0026rsquo;s GET method takes in a URL and issues a GET to the URL. GET returns:\n a non-nil response body of type http.Response. In this lesson, both response.Body and response.Status will be used a *url.Error occurs if there were too many redirects or if there was an HTTP protocol error. This is a nil response if there is a non-2xx response.  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { url := \u0026#34;http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetAllBus\u0026#34; response, err := http.Get(url) if err != nil { fmt.Printf(\u0026#34;http request failed: %s\u0026#34;, err) } defer response.Body.Close()\t//response.Body should close after reading from it is complete  fmt.Println(\u0026#34;Status:\u0026#34;, response.Status) fmt.Println(\u0026#34;Response:\u0026#34;, response.Body) } The value of response.Body, as of now, would be something like:\nStatus: 200 OK Response: \u0026amp;{0xc0000ce480 {0 0} false \u0026lt;nil\u0026gt; 0x1223560 0x12234f0} That does not show any Marta data! In order to read the data, the data needs to be decoded.\nDecode response There are a couple of ways to decode the body of a response. In this section, the json package\u0026rsquo;s NewDecoder and Decode methods will be used to decode.\n NewDecoder takes in anything that implements the io.Reader interface and returns a json.Decoder instance. Decode takes in any instance that implements interface{} and stores the values from the Decoder into the instance.  The above example updated to use the json package methods\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;encoding/json\u0026#34; ) func main() { url := \u0026#34;http://developer.itsmarta.com/BRDRestService/RestBusRealTimeService/GetAllBus\u0026#34; response, err := http.Get(url) if err != nil { fmt.Printf(\u0026#34;http request failed: %s\u0026#34;, err) } defer response.Body.Close() var marta []map[string]interface{} //Decodes API response \tif err := json.NewDecoder(response.Body).Decode(\u0026amp;marta); err != nil { fmt.Print(err) } fmt.Println(marta) } Example output:\n[map[ADHERENCE:-19 BLOCKID:182 BLOCK_ABBR:181-3 DIRECTION:Westbound LATITUDE:33.5623755 LONGITUDE:-84.5873 MSGTIME:8/16/2019 1:46:16 PM ROUTE:181 STOPID:213373 TIMEPOINT:Shannon Pkwy \u0026amp; Lancaster Lane TRIPID:6849176 VEHICLE:1818] map[ADHERENCE:0 BLOCKID:112 BLOCK_ABBR:14-1 DIRECTION:Eastbound LATITUDE:33.7890973 LONGITUDE:-84.4412427 MSGTIME:8/16/2019 1:47:33 PM ROUTE:37 STOPID:901789 TIMEPOINT:Arts Center Station TRIPID:0 VEHICLE:1459] ... continued Lab: Decoded API Response Lab Setup\n Run git clone https://github.homedepot.com/om-labs/go-apis.git cd into the go-apis repository Follow the instructions for Decode Response in the README in the external-apis folder  API Keys Getting API Key\nIt is not unusual for API's to require authentication to communicate with their endpoints. A common way to authenticate with an API is by use of an API Key. An API Key acts as both a unique identifier and a secret token for authentication, and will generally have a set of access rights on the API associated with it. We are going to use the OpenWeatherMap API found at: http://api.openweathermap.org.\nTo use this API, you first need to create an API key. An API key acts as both a unique identifier and a secret token for authentication, and will generally have a set of access rights on the API associated with it.\n To get an API key with OpenWeatherMap, you have to sign up here: https://home.openweathermap.org/users/sign_up\n API Call Set Up Now that you have the API key, you now have all of the data needed to make an API call.\nThe URL pattern to get the current weather information in imperial units from a location is:\nhttps://api.openweathermap.org/data/2.5/weather?q=\u0026lt;location\u0026gt;\u0026amp;units=imperial\u0026amp;appid=\u0026lt;api_key\u0026gt;\n \u0026lt;location\u0026gt; would be replaced with a location in one of the formats specified here: https://openweathermap.org/current#one \u0026lt;api_key\u0026gt; would be replaced with the API key generated with the above steps.  API call for getting the weather in Austin, Texas\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { //Set up \tlocation := \u0026#34;Austin,us\u0026#34; apiKey := \u0026#34;123456789\u0026#34; url := fmt.Sprintf(\u0026#34;https://api.openweathermap.org/data/2.5/weather?q=%s\u0026amp;units=imperial\u0026amp;appid=%s\u0026#34;, location, apiKey) //GET API call \tresponse, err := http.Get(url) if err != nil { fmt.Println(\u0026#34;GET error: \u0026#34;, err) return } defer response.Body.Close() //response.Body should close after reading from it is complete \tvar weather map[string]interface{} //Decodes API response \tif err := json.NewDecoder(response.Body).Decode(\u0026amp;weather); err != nil { fmt.Print(err) } fmt.Println(weather) }  It is not advised to store API keys in plain text in a program. We are doing this for simplicity\u0026rsquo;s sake. Keys can be stored:\n as an environment variable encrypted in your code with a secrets syncing service   The output should look something like:\nmap[base:stations clouds:map[all:1] cod:200 coord:map[lat:30.27 lon:-97.74] dt:1.56572434e+09 id:4.671654e+06 main:map[humidity:37 pressure:1014 temp:99.68 temp_max:102.99 temp_min:96.8] name:Austin sys:map[country:US id:5739 message:0.0128 sunrise:1.565697405e+09 sunset:1.565745308e+09 type:1] timezone:-18000 visibility:16093 weather:[map[description:clear sky icon:01d id:800 main:Clear]] wind:map[deg:100 speed:4.7]] Parse response What if you did not want all of the data that API GET response gives you? The JSON data can be parsed by using a struct.\nSince the weather API details are structured (meaning the structure of the data is known beforehand), a struct can easily be made to mirror the data that is being parsed. This newly created struct does not have to have all of the data that is returned from the API.\nA struct to hold just the coordinates, weather, main data, and wind data would look like:\ntype WeatherData struct { Coord map[string]float64 Main map[string]float64 Name string Weather []map[string]interface{} Wind map[string]float64 }  By convention, Go uses the same title cased attribute names as are present in the case insensitive JSON properties. So the Coord attribute in our WeatherData struct will map to the Coord, or coord or CoOrD JSON property.\n Now the decoding of the API data could be updated from\nvar weather map[string]interface{} to\nvar weather WeatherData Now the result of weather should look like:\n{map[lat:30.27 lon:-97.74] map[humidity:37 pressure:1013 temp:100.81 temp_max:104 temp_min:98.01] Austin [map[description:clear sky icon:01d id:800 main:Clear]] map[deg:180 speed:4.7]} Now each field of data can now be accessed a bit more specifically.\nAccessing the name of the city\nfmt.Println(weather.Name) Accessing the wind details\nfmt.Println(weather.Wind) Output:\nmap[deg:180 speed:4.7] Lab: Parse Response Lab Setup\n If you have not already:  run git clone https://github.homedepot.com/om-labs/go-apis.git cd into the go-apis repository   Follow the instructions for Parse Response in the README in the external-apis folder  Custom Attribute Names As mentioned before, Go uses convention to ascertain the attribute name it should map a property to. Many times though, you want a different attribute name than the one provided in your JSON data.\nThis can be done with struct field tags. Now, we can explicitly tell our code which JSON property to map to which attribute.\ntype WeatherData struct { Coord map[string]float64 `json:\u0026#34;coord\u0026#34;` Basics map[string]float64 `json:\u0026#34;main\u0026#34;` City string `json:\u0026#34;name\u0026#34;` Weather []map[string]interface{} `json:\u0026#34;weather\u0026#34;` Wind map[string]float64 `json:\u0026#34;wind\u0026#34;` } Notice the name of the struct fields changed. Go will still be able to map the fields to the json fields because of the struct field tag.\nThe data is still accessed with the field name, not the name of the JSON key.\nAccessing the name of the city\nfmt.Println(weather.City) Lab: Custom Attribute Names Lab Setup\n If you have not already:  run git clone https://github.homedepot.com/om-labs/go-apis.git cd into the go-apis repository   Follow the instructions for Custom Attribute Names in the README in the external-apis folder  Embedded Objects In the WeatherData struct, most fields are structs themselves. For example, the Coord field is a struct that contains the Lat and Lon of the location in question.\nWe need to mirror the structure of the object in question in the code. To add an embedded coord object, create a coord struct :\ntype Coord struct { Lat float64 `json:\u0026#34;lat\u0026#34;` Long float64 `json:\u0026#34;lon\u0026#34;` } Now the WeatherData struct will include a Coord field:\ntype WeatherData struct { Coord Coord `json:\u0026#34;coord\u0026#34;` Basics map[string]float64 `json:\u0026#34;main\u0026#34;` City string `json:\u0026#34;name\u0026#34;` Weather []map[string]interface{} `json:\u0026#34;weather\u0026#34;` Wind map[string]float64 `json:\u0026#34;wind\u0026#34;` } It is not necessary to include all of the details of all fields. This can be done by simply not adding a mapping to the json field in question.\nAfter adding a struct for all fields that are maps, the weather example looks like:\n//Coord hold the latitude and longitude of the location type Coord struct { Lat float64 `json:\u0026#34;lat\u0026#34;` Long float64 `json:\u0026#34;lon\u0026#34;` } //Basics hold the temp, humidity, pressure, temp_max, and temp_min type Basics struct { Humidity int `json:\u0026#34;humidity\u0026#34;` Pressure int `json:\u0026#34;pressure\u0026#34;` Temp float64 `json:\u0026#34;temp\u0026#34;` TempMax float64 `json:\u0026#34;temp_max\u0026#34;` TempMin float64 `json:\u0026#34;temp_min\u0026#34;` } //Weather holds the description of the weather type Weather struct { Description string `json:\u0026#34;description\u0026#34;` } //Wind holds the wind speed type Wind struct { Speed float64 `json:\u0026#34;speed\u0026#34;` } //WeatherData holds the structure for holding data from the weather API type WeatherData struct { Coord Coord `json:\u0026#34;coord\u0026#34;` Basics Basics `json:\u0026#34;main\u0026#34;` City string `json:\u0026#34;name\u0026#34;` Weather []Weather `json:\u0026#34;weather\u0026#34;` Wind Wind `json:\u0026#34;wind\u0026#34;` } The output of weather would now look similar to:\n{{30.27 -97.74} {37 1013 100.81 98.01 104} Austin [{clear sky}] {4.7}} Lab: Embedded Objects Lab Setup\nIf you have not already:\n run git clone https://github.homedepot.com/om-labs/go-apis.git cd into the go-apis repository Follow the instructions for Embedded Objects in the README in the external-apis folder  POST data We are going to use a non-prod API that can be found at: https://thd-stores-api.apps-np.homedepot.com/stores to demonstrate the other HTTP verbs.\nThe following routes are supported with this example API:\n   REST API Route     GET /stores   GET /stores/:id   POST /stores   PUT /stores/:id   PATCH /stores/:id   DELETE /stores/:id    New data setup The following struct will be used to work with this API:\n//Store holds the details a specific store type Store struct { ID int `json:\u0026#34;id\u0026#34;` StoreNumber int `json:\u0026#34;store_number\u0026#34;` StreetAddress string `json:\u0026#34;street_address\u0026#34;` City string `json:\u0026#34;city\u0026#34;` State string `json:\u0026#34;state\u0026#34;` NumEmployees int `json:\u0026#34;number_of_employees\u0026#34;` MonthlySales string `json:\u0026#34;monthly_sales\u0026#34;` } To add a new Store, you can create a new instance of the Store struct. json.Marshal is then used to get the []byte representation of the new Store.\nnewStore := Store{ StoreNumber: 1234, StreetAddress: \u0026#34;123 Main St\u0026#34;, City: \u0026#34;Austin\u0026#34;, State: \u0026#34;Texas\u0026#34;, } bytesRepresentation, err := json.Marshal(newStore) if err != nil { fmt.Errorf(\u0026#34;Struct conversion error: %v\u0026#34;, err) } API Interaction A POST request using the http.Post function creates an actual POST API call. http.POST takes in the API url, the new content type (which is JSON) and then we create and pass a new bytes.Buffer object from the bytes representation.\nWhy is there a need to create a buffer here? The http.Post function expects an implementation of io.Reader. So http.Post could even read this part from disk or network or any custom readers. In this case, a bytes buffer will suffice since it implements the io.Reader interface. After the request is made, there is a check for errors. If successful, the result is decoded and printed.\nresponse, err := http.Post(\u0026#34;https://thd-stores-api.apps-np.homedepot.com/stores\u0026#34;, \u0026#34;application/json\u0026#34;, bytes.NewBuffer(bytesRepresentation)) defer response.Body.Close() if err != nil { fmt.Errorf(\u0026#34;POST error: %v\u0026#34;, err) } var result Store //Decodes API response if err := json.NewDecoder(response.Body).Decode(\u0026amp;result); err != nil { fmt.Print(err) } fmt.Println(result) Lab: POST Data Lab Setup\nIf you have not already:\n run git clone https://github.homedepot.com/om-labs/go-apis.git cd into the go-apis repository Follow the instructions for POST Instructions in the README in the external-apis folder  DELETE Data Go\u0026rsquo;s net/http package does have PUT, PATCH, and DELETE simplified like GET, POST, and HEAD. Explained at the beginning of the lesson, a client must be made, an HTTP request made, then the request should be sent.\nstoreIdToDelete := 1000 url := fmt.Sprintf(\u0026#34;https://thd-stores-api.apps-np.homedepot.com/stores/%v\u0026#34;, storeIdToDelete) client := \u0026amp;http.Client{}\t//1 req, err := http.NewRequest(http.MethodDelete, url, nil)\t//2 if err != nil { fmt.Errorf(\u0026#34;New Request error: %v\u0026#34;, err) } resp, err := client.Do(req)\t//3 if err != nil { fmt.Errorf(\u0026#34;Do error: %v\u0026#34;, err) } if resp.Status == \u0026#34;200 OK\u0026#34; {\t//4 \tfmt.Println(\u0026#34;Successfully deleted store number:\u0026#34;, storeIdToDelete) } fmt.Errorf(\u0026#34;DELETE error: %v\u0026#34;, resp.Status)  Create an HTTP client. Create a new request the DELETE HTTP action, URL, and no body. Send an HTTP request and returns an HTTP response. Check to see if the DELETE occurred successfully.  Lab: DELETE Data Lab Setup\n If you have not already:  run git clone https://github.homedepot.com/om-labs/go-apis.git cd into the go-apis repository   Follow the instructions for DELETE Instructions in the README in the external-apis folder  PUT Data When doing a PUT API call, the Content-Type needs to be set before the HTTP request is sent.\nOnce a request (req) has been created, the request header needs to be customized to contain the content type of incoming data, which in this case is application/json; charset=utf-8\u0026quot;. This is done with the following line:\nreq.Header.Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json; charset=utf-8\u0026#34;) Updating store 999\nnewStore := api.Store{ ID: 999, StoreNumber: 1234, StreetAddress: \u0026#34;123 Main St\u0026#34;, City: \u0026#34;Austin\u0026#34;, State: \u0026#34;Texas\u0026#34;, } bytesRepresentation, err := json.Marshal(newStore) if err != nil { fmt.Errorf(\u0026#34;Struct conversion error: %v\u0026#34;, err) } url := fmt.Sprintf(\u0026#34;https://thd-stores-api.apps-np.homedepot.com/stores/%v\u0026#34;, id) client := \u0026amp;http.Client{} req, err := http.NewRequest(http.MethodPut, url, bytes.NewBuffer(bytesRepresentation)) if err != nil { fmt.Errorf(\u0026#34;New Request error: %v\u0026#34;, err) } req.Header.Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json; charset=utf-8\u0026#34;) response, err := client.Do(req) if err != nil { fmt.Errorf(\u0026#34;Do error: %v\u0026#34;, err) } var result interface{} json.NewDecoder(response.Body).Decode(\u0026amp;result) fmt.Println(\u0026#34;Successful PUT\u0026#34;) Lab: PUT Data Lab Setup\n If you have not already:  run git clone https://github.homedepot.com/om-labs/go-apis.git cd into the go-apis repository   Follow the instructions for PUT Instructions in the README in the external-apis folder  Authentication Sometimes APIs require a user to get an API token every time they interact with the API. One process is to have a user use a client ID and a client secret to hit an API\u0026rsquo;s token endpoint URL to obtain a temporary token. That token is then used to interact with the API. For example, to use the any of the THD APIs a client secret and a client ID must be used to request a token.\nSo far, all GET s made have used the simplified http.Get method, which used the default http client client := \u0026amp;http.Client{}. This was fine due to the fact there were not any headers or credentials being passed. Now there is a need to provide credentials to the client, so the simplified http.Get method won\u0026rsquo;t do. Now we will do a set up similar to DELETE and PUT.\nWhile there are a number of ways/packages to create an http client with credentials, in this lesson the package used is golang.org/x/oauth2. This package implements the OAuth2.0 \u0026ldquo;client credentials\u0026rdquo; token flow, also known as the \u0026ldquo;two-legged OAuth 2.0\u0026rdquo;.\nSetting up client credential configuration data\nimport ( \u0026#34;golang.org/x/oauth2\u0026#34; \u0026#34;golang.org/x/oauth2/clientcredentials\u0026#34; ) //...  authClientID := \u0026#34;---insert client id here---\u0026#34;\t//1 authClientSecret := \u0026#34;---insert client secret here---\u0026#34;\t//2 tokenURL := \u0026#34;---insert the token endpoint url here---\u0026#34;\t//3  //Set up the clientcredentials Configuration data conf := \u0026amp;clientcredentials.Config{\t//4 \tClientID: authClientID, ClientSecret: authClientSecret, TokenURL: tokenURL, }  Update to use the client ID given in the workshop (or that you retrieved following the below steps). Update to use the client secret given in the workshop (or that you retrieved following the below steps). Update tokenURL to https://master-data-security.apps-np.homedepot.com/security/oauth/token, THD\u0026rsquo;s endpoint URL that provides a temporary token. A pointer is used so that the conf variable will be a pointer to a clientcredentials.Config value, a value that is encouraged to be shared and reused. clientcredentials.Config is a pointer so passing conf around to other functions is less intense. Only the pointer value will be copied, not the pointed clientcredentials.Config struct, so the struct itself (the clientcredentials.Config value) will be reused. Should you not use a pointer, if you would pass it to other functions, the struct itself would be copied and not reused. So even though the \u0026amp;`` address operator is not needed in this simple example, it's good to keep the habit of using it, should the example grow or should you write code where this does matter (e.g. you pass around the created Config`).  Client credentials will be provided for this workshop, but you can learn how to get your own on the link:https://master-data-security.apps-np.homedepot.com/security/api-guide.html[THD Security API Guide^].\nTo create an http client with the new configuration:\nclient := conf.Client(oauth2.NoContext) The provided context optionally controls which HTTP client is returned. oauth2.NoContext is the default context if not using your own context.Context.\nNow you have an http client that has the correct authorization to interact with the designated API. With this client you can create and send a new request just like we did with DELETE and POST.\nIf we wanted to get the details of department 94 for THD using the URL \u0026quot;https://master-data-sku.apps-np.homedepot.com/sku/departments/94\u0026quot;, the rest of our code would look like:\nurl := \u0026#34;https://master-data-sku.apps-np.homedepot.com/sku/departments/94\u0026#34; //GET API call req, err := http.NewRequest(http.MethodGet, url, nil) if err != nil { fmt.Errorf(\u0026#34;New Request error: %v\u0026#34;, err) } var result interface{} //Decodes API response response, err := client.Do(req) if err != nil { fmt.Errorf(\u0026#34;Do error: %v\u0026#34;, err) } json.NewDecoder(response.Body).Decode(\u0026amp;result) fmt.Println(result) An example output of the above code:\nmap[_links:map[self:map[href:https://master-data-sku.apps-np.homedepot.com/sku/departments/94]] abbreviatedDepartmentName:SKU departmentName:LUMBER departmentNumber:94 effectiveBeginDate:1990-01-01 lastUpdateTimestamp:1.384488495537e+12 merchandiseDepartmentDetails:map[allocateAdditionalSupplyDays:\u0026lt;nil\u0026gt; carPurchaseOrderSourceIndicator:RDC domesticPurchaseOrderProductGroupCode:\u0026lt;nil\u0026gt; effectiveBeginDate:2013-10-29 importPurchaseOrderProductGroupCode:\u0026lt;nil\u0026gt; lastUpdateTimestamp:1.384488491564e+12 maxWaitOrderDays:\u0026lt;nil\u0026gt; merchandiseDepartmentNumber:94 palletRoundAdditionalSupplyDays:\u0026lt;nil\u0026gt; skuReviewMinimumDays:\u0026lt;nil\u0026gt;] shortDepartmentName:NBR] Conclusion In order to interact with an existing API, you need to:\n create an HTTP client create a new request given an HTTP action(PUT in the above example), URL, and optional body. send an HTTP request and returns an HTTP response, following policy (such as redirects, cookies, auth) as configured on the client.  Once the API data is accessed you can format what data is retrieved with a custom struct.\n"
},
{
	"uri": "/custom-workshops/frontend-at-thd/",
	"title": "Frontend Development at THD",
	"tags": [],
	"description": "",
	"content": "Pre-flight checklist  Do you have node.js installed?  If not, download and install Node.js from here: https://nodejs.org/en/download/ Close and reopen any terminal (macOS) or command prompt windows (windows) so that the npm command is available   Do you have your npm registry set to https://npm.artifactory.homedepot.com/artifactory/api/npm/npm/ ?  If not, open a new terminal (macOS) or command prompt window (windows) and execute the following command: npm config set registry https://npm.artifactory.homedepot.com/artifactory/api/npm/npm/   Do you have access to the thd-olt-component-react Github repository? To verify access, ensure that your name appears in the \u0026ldquo;people\u0026rdquo; list  If not, request access to the repository by posting in the #nucleus channel in Slack.    Install Harmony Mac OS  Open up a new terminal (command+space, then type \u0026ldquo;terminal\u0026rdquo; and press return) Install Harmony by copy-pasting the below command into the terminal and press return  npm i -g @harmony/harmony-cli Tell Harmony where to store and retrieve components by copy-pasting the below command into the terminal and press return  harmony setup harmony.homedepot.com Windows  Open up a new command prompt window Install Harmony by copy-pasting the below command into command prompt and press return  npm i -g @harmony/harmony-cli Tell Harmony where to store and retrieve components by copy-pasting the below command into command prompt and press return  harmony setup harmony.homedepot.com "
},
{
	"uri": "/software-eng-essentials/git-pillars/stash/",
	"title": "Git Stash",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Holding changes out of the index Putting changes back into the index Selectively stash changes out of the index  Git Stash git stash puts aside a set of commits while you commit another set.\nThis is helpful when there are changes that need to be set aside for a while, so you can stage some urgent updates. It is also helpful if there are unrelated updates that you would like to include on separate commits.\nThe stash option allows you to proceed with an add and commit of urgent changes while holding incomplete changes out of the index.\nIn the following snippet you can see that git has one file staged, tracking two other deleted files, and there is a new file that is not yet tracked.\n$ git status On branch master Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: file3.txt Changes not staged for commit: (use \u0026#34;git add/rm \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) deleted: file1.txt deleted: file2.txt Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) file4.txt Running git stash will show that git will un-stage (remove from index) the third-file, hold out the file deletions and only the text file will show in a status check.\nOn branch master Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) file4.txt nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track)  Use git stash --include-untracked for unstaged files or git stash --all for your ignored files.\n Practice stashing\nGit it back Once something is stashed, it\u0026rsquo;s is important to be able to get it back. Git provides two different methods to bring the stash back to the index.\n   Command Action     git stash apply places stash object back into the index without removing it from the stash   git stash pop places stash object back into the index and drops it from stash    Running git stash show shows that the changes are ready to be committed again but are also still in the stash:\nfile1.txt | 1 - file2.txt | 1 - file3.txt | 1 + 3 files changed, 1 insertion(+), 2 deletions(-) Running git stash apply gives an output similar to:\nRemoving file2.txt Removing file1.txt On branch master Changes not staged for commit: (use \u0026#34;git add/rm \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) deleted: file1.txt deleted: file2.txt modified: file3.txt Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) file4.txt no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) This leaves everything in the stash to be cleaned out manually at a later time.\nRunning git stash drop will take off the most recent stash commit and give an output similar to:\nDropped refs/stash@{0} (039dfaae1ec703201662fb3e48fc4bed809d47d5) This can get tedious, so git stash clear can be used to clean out all of the stash objects.\n If wanted stash objects are accidentally cleared, git reflog will give a list of commits where the head was or a git fsck --full to see any dangling objects.\n Practice Un-stashing\nGit Patch git stash --patch provides a workaround to stash a single file at a time by allowing going through changes one at a time.\nSay your repo has the current status:\nOn branch master Changes not staged for commit: (use \u0026#34;git add/rm \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) deleted: file1.txt deleted: file2.txt modified: file3.txt Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) file4.txt Running git stash --patch will show each change with a prompt asking if you want to \u0026ldquo;stash this hunk\u0026rdquo;. With each prompt you can type \u0026lsquo;y\u0026rsquo; or \u0026lsquo;n\u0026rsquo; or one of several other commands.\nEach hunk prompt looks like:\ndiff --git a/file1.txt b/file1.txt index e965047..0000000 --- a/file1.txt +++ /dev/null deleted file mode 100644 @@ -1 +0,0 @@ -Hello (1/1) Stash deletion [y,n,q,a,d,?]? git stash show or git stash list will show what is currently in the stash.\nCan you explain the difference between the two outputs?\ngit stash show\nfile1.txt | 1 - file3.txt | 1 + 2 files changed, 1 insertion(+), 1 deletion(-) git stash list\nstash@{0}: WIP on master: a9b0b9b Adds third file Practice Patching\nStash arguments Stash has some arguments that can help us be more specific with pop, apply, and drop also.\ngit stash list shows that git indexes the stash commits:\nstash@{0}: WIP on master: a9b0b9b Adds third file This means indexing can be used to drop a specific commit!\nRunning git stash drop stash@{0} will remove the specified stash commit:\nDropped stash@{0} (bcadb1d179b57a1250e49a6f4b687df46af1547e) The stash@{} works with git stash apply and git stash pop\nProve the stash\n"
},
{
	"uri": "/onboarding/cyber-security/general/module-4-going-forward/",
	"title": "Going Forward",
	"tags": [],
	"description": "",
	"content": "Topics  Recap of contact information for Cybersecurity Links to Cybersecurity policies Secure Code Warrior Product and Solution Review Board (PSRB) Architecture Security Assessment (ASA) | Legacy  Recap of contact information for Cybersecurity For questions or concerns, please contact the Cybersecurity Governance team:\n  Email: cybersecurity_policies_\u0026amp;_standards@homedepot.com\n  Slack: #cybersecurity-policies_standards\n  Approved Software:\n For questions about approved software, contact your department’s Technology partner or email: technology_partner@homedepot.com    Suspicious Email:\n If you receive a suspicious email, immediately report it to Cybersecurity via PhishAlarm by clicking the “Report Phish” icon on your Outlook home ribbon or email cybersecurity@homedepot.com.    Links to Cybersecurity policies The Cybersecurity Policies/Standards and a brief description are listed below. You must be logged in to myApron to be able to access all links.\n   Domain      Application Security Secure application development and acquisition   Data Protection Secure sensitive data usage   Cybersecurity Governance, Risk \u0026amp; Compliance Managing risk and ensuring compliance   Security Monitoring Monitoring and logging activities on all THD assets   Cybersecurity Resilience \u0026amp; Recovery Ensuring availability for critical infrastructure   Security Operations Removing vulnerabilities and exploits from the environment   Access Management Ensure all access is authorized   Third Party Risk Management Oversight and monitoring for 3rd party applications   Physical Security Protect assets from unauthorized physical access   Personnel Security Expectations for a secure workforce   Network Security Expectations for securing THD\u0026rsquo;s networks   Security Incident Response Ensuring proper response to security incidents    Secure Code Warrior Secure Code Warrior is a SAAS platform similar to hacker rank with the goal of educating Cybersecurity through gamification exercises though an online platform. In 2020 Secure Code Warrior and THD have entered a partnership to both fit our compliance needs while moving forward with tournaments \u0026amp; online exercises to educate our developers on how to optimize security in their applications.\n  FAQ\n  How to request access:\n Navigate to ARP (Access Request Portal) Select the request access icon for either yourself or another associate Search “Secure code warrior” You will be given a few options but please select the relevant role from the screenshot below (likely to be gg_scw_role_developer):     Training Videos:   Getting Started videos:\n How to login to SCW [youtube.com] How to play a challenge [youtube.com] Introduction to SCW API [youtube.com] How to create an SCW tournament [youtube.com] How to create an assessment [youtube.com]    Training KnowledgeBase articles:\n Training Module Overview[help.securecodewarrior.com] Engagement Cheat Sheet: Training Edition[help.securecodewarrior.com] Reporting in Secure Code Warrior [help.securecodewarrior.com]    Assessments KnowledgeBase articles:\n Assessments Module Overview [help.securecodewarrior.com]    Courses KnowledgeBase articles:\n Courses Public Labs Opt-In [help.securecodewarrior.com] Courses Overview [help.securecodewarrior.com] Creating a Course [help.securecodewarrior.com](Company Admin/Team Manager) Best Practice \u0026amp; Strategy Advice [help.securecodewarrior.com]    Product and Solution Review Board (PSRB)\n Details on the PSRB Slack channel #it_governance More Information    Architecture Security Assessment (ASA) | Legacy\n Details on the ASA    MyApron - Cybersecurity Home\n  Cybersecurity Service catalog\n   "
},
{
	"uri": "/application-security/api-security/02_human_to_service_oidc/40_lab/",
	"title": "Hands On Lab",
	"tags": [],
	"description": "",
	"content": "Identifying and Authorizing Users  This section covers the OIDC+Auth Code grant While not limited to browsers specifically it is the most common interaction with the flow developers and users have, but can be used with Native Mobile apps and even CLIs. One of the main issues here is the browser is terrible at keeping secrets, so the way this works is by constantly refreshing the token every 30 minutes. Which causes complexity, but increases security.  OIDC + Auth Code Flow Step by Step Although this looks like many, many steps, it is actually a pretty elegant pattern, and once you get the flow in your head, it is very secure. Also the library we have provided handled 98% of this so you just provide your yaml config and off you go.\nLogin What would happen if you just did Auth Code with no OIDC? Very little. Just remove the id_token from Steps 10 and 11. But leave it because the id_token plays an important role.\nFor the sake of vocabulary, the lines in the diagram will be called \u0026ldquo;path\u0026rdquo; as not to be confused with our workshop \u0026ldquo;steps\u0026rdquo;.\nHands On This can be very dry and technical, so instead of talking through these paths, instead we are going to walk you through the paths with a reference application.\nStep 1: Open the Webapp The following steps are directed at Chrome. If you are using a different browser, then you need to determine the proper steps in that browser.\n  Open empty tab (Incognito is best)\n  Open Inspect Tab\n Any of the following should show the Inspect Tab:  Right Click and choose Inspect F12 Alt + i      Open the Network Tab\n  In the filter tab, add the following string -css -js -font -data -png -ico -gif -html\n  Click the Preserve Logs checkbox\n  Make sure \u0026ldquo;All\u0026rdquo; is selected\n  Now in that tab open https://om-api-security-ui.apps-np.homedepot.com\n  Step 2: Login   The frontend talks to its BFF ( Backend for frontend ) by calling the /identity/login endpoint on the BFF.\n  This covers Path 1, 2, 3, 4, 5 on the diagram. You should see the 302 redirect come back.\n  You should now see the Login page on the browser.\n  IMPORTANT Your single page app code is completely removed from the picture. This is your browser talking directly to your Authorization Server (AS)\n Also note, that if you already have an active PF Cookie (more on that below) you still skip 5 and 6, and instead go from 4 to 7. (The magic of SSO)  Step 3: Login Redirect Explained Path 1, 2, 3, 4, and 5: The BFF redirects the browser to the Authentication Server with a few Query Params:\nAuth Code Query Params\n   Param Value     client_id A unique ID that identifies the BFF client   redirect_uri Often referred to as a callback url, this provides the Auth server a uri to redirect to once auth is completed   response_type code indicates you want the authorization code   scope The scopes being requested, which should only be openid   state A unique ID generated by the BFF that is used to help prevent CSRF Attacks    Here is an example: GET https://identity-qa.homedepot.com/as/authorization.oauth2?client_id=spiffe%3A%2F%2Fhomedepot.dev%2Fidentity-reference-webapp\u0026amp;redirect_uri=https%3A%2F%2Fidentity-reference-webapp-react-golang.apps-np.homedepot.com%2Fidentity%2Fcallback\u0026amp;response_type=code\u0026amp;scope=openid\u0026amp;state=c83b6076-1884-470b-95e4-7bb3a6bfc321\nWhy Query Parameters? Because the 302 redirect must be a URL, so only a GET works, and a GET only support query parameters. Only a POST support body params. Because of this, no secrets are posted during this process. (For those of you familiar with PKCE, we will save that for an advanced course)\nStep 4: Login The Authorization Server / Identity Provider will demand validation, this mostly occurs in the form of username and password, but in the future it could also be location, biometrics, badge, etc.\nAll associates have Production credentials by default, but those of us in IT, maybe have requested to have a QA Account setup. This is usually our same username, but with a different password that we use against Non-Production services. If you have your own QA Credentials, then please feel free to use them. Otherwise use any of the accounts below:\nIf you are not sure if you have a QA account, or need to reset the password, please use the new Password Reset Tool:\nhttps://mythdpassword.homedepot.com/\nOtherwise, feel free to use the values below, but they get locked out\u0026hellip; a lot!\nQA Users and their passwords to use with Lab\nPut in the user credentials and click login. This will trigger Path 5, 6, 7, 8, 9, 10, and 11 :D\nNOTE: If you are using the Inspect tab and see your own password in the clear, don\u0026rsquo;t panic. This is as expected. You, as the owner of your laptop, have full access to what goes in and out of Chrome, so therefore it is understandable that you can see that password in the clear. Nobody else can see these values because once they leave the browser they are in encrypted via HTTPS\nStep 5: Dig Deeper - Callback After Path 6 (username and password) were successfully POST-ed to AS/Idp, then it will response three things:\n a PF cookie - this is what allows SSO to other applications (see Step 11) A 302 redirect back to the /identity/callback URL given in Step 3 Authorization Code as a param to the /identity/callback url The State variable as a param to the /identity/callback url     Param Value     code a short lived authorization code that will be used by the BFF to complete the transaction   state included so that the BFF can verify that this is a valid request    Example\nhttps://om-api-security-ui.apps-np.homedepot.com/identity/callback?code=gzHNcbgRdYXUiLnX-uidxH12kiFL3jL268GtwEk0fnMUrl46AAAABQ\u0026amp;state=076fbd8c-1b3e-4fbc-8d29-073a0971a1b2 This completes Path 7 and 8\nStep 6: Dig Deeper - Auth Code Exchange The next few steps are hidden from the browser/client/spa/user. This exchange looks very much like the client credentials exchange.\nPath 9 and 10, the BFF makes a call to the auth server /token endpoint with the following data:\n   Field value     grant_type authorization_code   code the one time use authorization code from code param on the /identity/callback url   client_id A unique ID that identifies the BFF client   client_secret A password that is maintained by the BFF   roles Home Depot specific - Comma separated list of groups you want the Authorization Server to check the user for, and if a member add to the access_token    The token endpoint will do validation:\n Ensure the auth code is valid Ensure the client and secret are valid If a comma separated list of roles are provided, then the Authorization will check the user for all the groups listed. If the user is in a group, it will be added to the access_token. If success, it will return a token set containing: Access Token, ID Token, Refresh Token  curl --location --request POST \u0026#39;https://identity-qa.homedepot.com/as/token.oauth2\u0026#39; \\ --header \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; \\ --data-urlencode \u0026#39;grant_type=authorization_code\u0026#39; \\ --data-urlencode \u0026#39;client_id=spiffe://homedepot.com/om-api-security-ui\u0026#39; \\ --data-urlencode \u0026#39;client_secret=1234-573602938-hfaiuwenibfn\u0026#39; \\ --data-urlencode \u0026#39;code=abcd3fGh1jK1mN0\u0026#39; \\ --data-urlencode \u0026#39;roles=apie_admin,HR MIP Associate\u0026#39; Step 7: Dig Deeper - Tokens Set After Path 10, you now have 3 tokens on the server.\n{ \u0026#34;access_token\u0026#34;: \u0026#34;ey.....\u0026#34;, (type jwt) \u0026#34;id_token\u0026#34;: \u0026#34;ey.....\u0026#34;, (type jwt) \u0026#34;refresh_token\u0026#34;: \u0026#34;32 random chars\u0026#34; (type opaque) } We will take the access_token and refresh_token and put that in the session storage. By default, the THD Identity Node middleware uses a special encrypted cookie base session storage engine so that you don\u0026rsquo;t need to use a redis cluster. If you want to replace that with a different session management database then you are welcome to.\n Access Token  Placed into the session. Good for 30 minutes   ID Token  Payload is read and data put into the cache for this users token is discarded   Refresh Token  Very powerful, held on server side good for 8+ hours    DISCLAIMER NEVER EVER give the refresh token to the browser. It is too sensitive.\nStep 8: Refresh Token Path 11: This is a VERY powerful token. Also the browser can\u0026rsquo;t hold a secret. So you really don\u0026rsquo;t have any good options here, you must keep this token on the backend in session storage.\nIn Step 10 below, we explain how the refresh token is used.\nStep 9: Access Token Path 11: The Access Token is placed in session storage. Then we use standard cookie based session management that has been well tested over many years.\nStep 10: Control passed back to the SPA Using Path 12 and 13, the control is passed back to the SPA but now the user is fully logged in and both the BFF code and the UI code have full access to the Users Information.\nWe are not going to dive into the react code. You are welcome to do that on your own, but the cliff notes is the react code calls the /identity/me endpoint and if the user is properly logged in then the me endpoint will return a 200 and all the users info. React may do whatever they want with that information.\nThe /identity/me endpoint will NOT returns the tokens, but instead will return all the relevant information from the access_token, id_token, and /userinfo endpoint, all merged together in one simple json object.\nStep 11: Refreshing the Access Token The human\u0026rsquo;s Access Token is only good for 30 minutes. When it is expired (or close to expiring), we must use the refresh token to generate a new access token. It is just a simple POST call shown below. You must pass the groups again.\nWhen a call is made to the BFF, the token will be checked, if it needs to be refreshed it will happen automatically to the browser, (no action needed) and it will be placed back in the session.\ncurl --location --request POST \u0026#39;https://identity-qa.homedepot.com/as/token.oauth2\u0026#39; \\ --header \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; \\ --data-urlencode \u0026#39;grant_type=refresh_token\u0026#39; \\ --data-urlencode \u0026#39;client_id=spiffe://homedepot.com/identity-reference-app\u0026#39; \\ --data-urlencode \u0026#39;client_secret=1234-573602938-hfaiuwenibfn\u0026#39; \\ --data-urlencode \u0026#39;refresh_token=VHpLPGNrjOY4pFHhsOCHdoXmEw8naGmSuOTzxduh38\u0026#39; \\ --data-urlencode \u0026#39;roles=apie_admin,HR MIP Associate\u0026#39; Step 12: SSO and the PF Cookie The PF cookie is a critical part of this architecture. It represents the users and this device to PingFed. It is not directly used by your app, but instead is used for Single sign On (SSO). If you already had a valid PF cookie in your browser, you would have skipped the prompt for the user to enter their username and password (Path 5 and 6) and instead you would have been automatically logged in.\nIf you are know about another app attached to PingFed QA then open that link and validate that you sign in without being prompted to enter your username and password.\nAlthough the PF cookie is shared by all applications, the tokens are specific for THAT user and THAT app.\nStep 13: Runtime - CatFacts Now the app is up and running and the user is logged in. The access_token is safely in the session, and the SPA has fetched the /identity/me data. What now?\nWell, any time the SPA makes a call to the BFF, then the cookie based session serves as its validation that it is allowed to make that call. The BFF will validate the token on EVERY call unless you mark that route as public in the config. If the token in the session is expired, the middleware will refresh it automatically for you.\nRemember the CatFacts from yesterday? Well this app uses that exact app to display CatFacts to you. Click the \u0026ldquo;Demo\u0026rdquo; button and look on the right, you should see some fun CatFacts.\nBecause the BFF is a proxy as well, it will proxy the call to the resource server (CatFacts) and inject the access_token into the Authorization header as \u0026ldquo;Authorization: Bearer {access_token}\u0026rdquo;\nBuilding your own Webapp Security Middleware So we have talked about how to interact with the BFF side, but lets take a quick look at how to configure the BFF.\nHere is the direct link to the config setup for the thd-identity-node middleware\nversion: 1 # OIDC is enabled and configured which makes this a BFF instead of just a resource server.  oidc: enabled: true disable-login-redirect: false issuer-name: pingfed-qa base-url-path: \u0026#34;/identity\u0026#34; redirect-url: https://om-api-security-ui.apps-np.homedepot.com/identity/callback client-id: spiffe://homedepot.dev/om-api-security-ui client-secret: Set using the THD_ID_OIDC_CLIENT_SECRET environment variable secure-cookie: hash-key: Set using the THD_ID_OIDC_SECURE_COOKIE_HASH_KEY environment variable encryption-key: Set using the THD_ID_OIDC_SECURE_COOKIE_ENCRYPTION_KEY environment variable roles-to-check: - gg_cat_facts_admin # create the named session checks. the names (aka \u0026#39;auth-required\u0026#39;, \u0026#39;admin-required\u0026#39; can be whatever you want them to be.) security-checks: auth-required: issuer-name: pingfed-qa audience: spiffe://homedepot.dev/om-api-security-ui admin-required: issuer-name: pingfed-qa audience: spiffe://homedepot.dev/om-api-security-ui role: gg_cat_facts_admin # apply those checks to the paths you want. This gives you a TON of flexibility paths: p-022: path: /static/* disable-login-redirect: true check-names: - allow-all # For proxied APIs you will want to create an entry # to disable the automatic login redirect. p-044: path: /catfacts/* disable-login-redirect: true check-names: - auth-required p-999: path: /* check-names: - auth-required If you are ready to try your hand at building your own, we have our example app and middleware located at the link below:\nhttps://app-secure-community-docs.apps-np.homedepot.com/identity/human-to-service/#code\nProxy The proxy setup is completely up to you. We have provided one as an example that uses the http-proxy-middleware module which is very powerful. You can see how we used it in the example code here: https://github.homedepot.com/app-secure-community/thd-identity-example-react#config-the-proxy\n[ { \u0026#34;route\u0026#34;: \u0026#34;/catfacts/v1\u0026#34;, \u0026#34;forwardAuth\u0026#34;: true, \u0026#34;options\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;https://om-api-security-workshop.apps-np.homedepot.com\u0026#34;, \u0026#34;changeOrigin\u0026#34;: true } } ] "
},
{
	"uri": "/software-eng-essentials/git-foundations/history-labs/",
	"title": "History Labs",
	"tags": [],
	"description": "",
	"content": "Why Version control? Imagine you are part of a team that is tasked to build a bridge. The team is divided into two groups; North Group and South Group.\n  Each team has a set of plans and works independently on the respective side of the ravine. North Group changed their version of the plans to divert 6 feet East. Similarly, South Group decided to divert 3 feet west and 6 feet lower in elevation. Each team assumes the other can see the physical changes made and will compensate on their side. The result is the bridge above.\nTurn to the person next to you and discuss some possible solutions to the issues that caused this catastrophic failure.\nBe prepared to share with the room your solution for:\n Communicating Issues Sharing changes Managing Conflicts Checking for Alignment of Plans At least one potential drawback to your solution  Centralized or Distributed  You will be placed into groups of three You will be assigned either Centralized or Distributed Version Control In groups take 12 minutes to research with the intent of creating the following deliverables Graphic that represents your Version Control system List of Benefits of your system List of Detriments of your system A short 2-3 minute presentation of your graphic and findings  External Resources  Wikipedia version control Wikipedia Git  "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/input-output-streams/",
	"title": "Input, Output, and Streams",
	"tags": [],
	"description": "",
	"content": "Input/Output In computer programming, input/output (or I/O) is the communication between computers and the outside world.\n Input is the data that is fed into a command Output is the data that is generated by the command and (usually) displayed in the terminal  Input Input to a shell script can come from several different places:\n Command arguments that are provided to the command Environment variables, inherited from whatever process started the script Files in the file system Anything else a File Descriptor can point to (pipes, terminals, sockets, etc.). This will be discussed later.  Output Output refers to any information that a command produces. Output from a shell script can also go to lots of different places:\n Files Anything else a File Descriptor can point to Other commands via a | (pipe) operator Environment variables  Standard streams  Modern operating systems provide 3 channels (or streams) for communicating input and output data. These channels are referred to as the standard streams There are 3 standard streams: standard input (stdin), standard output (stdout) and standard error (stderr).     Standard Stream Description     stdin Standard input is data going into a program. Often the keyboard provides this data, but it can come from files or other commands.   stdout Standard output is where a program writes its output data. This is usually associated with the terminal screen but can be written to files or to other commands.   stderr Standard error is where a program sends error messages or diagnostics.    Demonstration of how stdin and stdout work For bash:\n$ read -p \u0026#34;What is your name? \u0026#34; name; echo \u0026#34;Howdy, $name.\u0026#34; For zsh:\n$ read \u0026#34;?What is your name? \u0026#34; name; echo \u0026#34;Howdy, $name.\u0026#34;  The read command reads information from stdin and stores it in the variable name. Then echo sends a message containing the name to stdout   By default, stdin and stdout are connected to your terminal, but stdin and stdout can point to other resources. More on this later.\n Demonstration of stderr $ rm top-secret rm: `top-secret\u0026#39;: No such file or directory  Unless you have a file called top-secret in your current directory, the rm command will fail and show an error message explaining what went wrong. Error messages like these are by convention displayed on stderr. stderr is also connected to your terminal\u0026rsquo;s output device, just like stdout. However, the distinction between stdout and stderr makes it easy to keep errors separated from the application\u0026rsquo;s normal messages. For example, a script might wish to log stderr messages in a special place for long-term storage.  Piping Commands Together  Often we may want to send the output of one command (what it writes to stdout) to another command (what is reads from stdin). This is accomplished via the | (pipe) operator.  Example:\n$ echo -n \u0026#34;Hello, My name is Homer D. Poe\u0026#34; | wc -c 30  The above example takes the output of the echo command and sends it as input to the wc (word count) command. Thus the stdout of echo is piped into the stdin of the wc command.  The -n argument tells echo to not print the trailing newline character. The -c argument tells wc to count characters (instead of lines or words).   Thus we discover that there are 30 characters in the message that we echoed.  Here are a few more examples:\n# send the output (stdout) of the echo command to a file. # the `\u0026gt;` operator redirects stdout to the specified file. $ echo \u0026#34;Welcome to Orange Academy\u0026#34; \u0026gt; greeting.txt # count the lines, words, and characters in a file $ wc greeting.txt 1 4 25 greeting.txt # another way to count the lines, words, and characters in a file $ cat greeting.txt | wc 1 4 25 Summary  Shell commands read input from stdin and write their output to stdout and stderr. The standard streams can be connected to your Terminal (reading from the keyboard and writing to the Terminal window). The standard streams can also be connected to files and other resources. The | (pipe) operator can connect the stdout of one command to the stdin of another, creating a pipeline for processing data.  "
},
{
	"uri": "/react/foundations/intro-to-components/",
	"title": "Intro to Components",
	"tags": [],
	"description": "",
	"content": "An introduction to creating React Components.\nConcepts  Define Components Compare stateful / container with stateless / presentation components Explain Component Composition  Skills  Use ES6 syntax for creating stateless components  Components  Components are the heart and soul of React. Components let you split the UI into independent, reusable pieces. Conceptually, components are like JavaScript functions. They accept arbitrary inputs (called \u0026ldquo;props\u0026rdquo;) and return JSX expressions describing what should appear on the screen.  A React Component:\nStateless and Stateful Components There are 2 kinds of React Components: stateless and stateful:\n Stateless components get all of their data from props, which is a simple JavaScript object passed to the component. Stateful components can have props but they also manage their own internal data, called state:  state is data that is managed by the component and can change over time We will discuss state in more depth in the next lesson    How to Create a React Component  You can create a React component using a JavaScript class or a JavaScript function. In the past, classes were used for stateful components and functions were used for stateless components. Now with the addition of React hooks, we can create all components using JavaScript functions 😎. We will be learning more about React Hooks throughout this course.  Returning JSX The only requirement of a React component is that it either:\n is a function that returns a JSX expression, or is a class that has a render method that returns a JSX expression.  Example using a JavaScript function:\nfunction HelloWorld(props) { // a function Component  return ( // returns a JSX expression  \u0026lt;h1\u0026gt;Hello {props.name}\u0026lt;/h1\u0026gt; ); }; Example using a JavaScript class:\nclass HelloWorld extends React.Component { constructor(props) { super(props); } render() { // a class Component has a render method  return ( // that returns a JSX expression  \u0026lt;h1\u0026gt;Hello {props.name}\u0026lt;/h1\u0026gt; ); } }  Favor Function Components over Class Components We recommend using JavaScript functions for all React components:\n Functions are more concise than JavaScript classes resulting in less surface area for bugs to hide. With React Hooks, both stateless and stateful components can be written as functions, making it easier to refactor when adding or removing state. Functions avoid the this context and the need for explicitly binding callback methods. Functions are easy to compose and reuse (for example when writing custom React hooks).  Some Rules for Returning JSX   The JSX expression that is returned should consist of a single DOM element (such as a div, an input control, a button, etc.).\n  If you need to render multiple DOM elements you must wrap them in a container, such as a div, section, nav, etc.\n  Since React 16, a new \u0026lt;React.Fragment\u0026gt; tag was added to act as a container but without adding any unnecessary nestings in the final DOM rendering. You can also use the empty tag, \u0026lt;\u0026gt; and \u0026lt;/\u0026gt; to act as a container.\n  Example - Returning Multiple DOM elements\n  function Buttons(props) { return \u0026lt;\u0026gt; \u0026lt;button onClick={props.save}\u0026gt;Save\u0026lt;/button\u0026gt; \u0026lt;button onClick={props.cancel}\u0026gt;Cancel\u0026lt;/button\u0026gt; \u0026lt;/\u0026gt; ); }; Component Composition Components are meant to be compose-able. Meaning that we can import components and render them when/where they are needed.\nTake a simple navbar for example.\ntouch src/Navbar.js touch src/navbar.css Create a very simple nav element with 3 links.\nsrc/Navbar.js:\nimport React from \u0026#39;react\u0026#39;; import \u0026#39;./navbar.css\u0026#39;; // Import our css file  function Navbar(props) { return ( \u0026lt;nav className=\u0026#39;navbar\u0026#39;\u0026gt; {/* return a `nav` element */} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#about\u0026#34;\u0026gt;About\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#contact\u0026#34;\u0026gt;Contact\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/nav\u0026gt; ); } export default Navbar; Next, add some very basic styling to the navbar.\nsrc/navbar.css:\n.navbar { text-align: left; } .navbar li { list-style: none; display: inline-block; margin: 5px; } Now we just need to import our Navbar component and call for it to render in our App component.\nsrc/App.js:\nimport React from \u0026#39;react\u0026#39;; import Navbar from \u0026#39;./Navbar\u0026#39;; // Import the Navbar component import \u0026#39;./App.css\u0026#39;; function App(props) { return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; \u0026lt;Navbar/\u0026gt; // Render the `Navbar` component  \u0026lt;h3\u0026gt;Hello World\u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; ); } export default App; After refreshing the browser, you should see the Navbar rendered.\nComposable Components Means:\n Components can be small pieces of functionality Components can be reusable Maintaining a large codebase is significantly easier  Summary  React is a Component based UI framework. All of the visual rendering is being managed by components. React components return JSX expressions that declare how the component should be rendered to the DOM. Components can be created via a JavaScript function or a JavaScript class. We recommend Function Components over class components as they are easier to write, maintain, compose, and reuse.  Additional Resources  Why React Hooks?  "
},
{
	"uri": "/react/pillars/redux/intro-to-redux/",
	"title": "Intro to Redux",
	"tags": [],
	"description": "",
	"content": "Exploring Redux with vanilla JS\n Topics 1. Learning Objectives 1.1. Concepts 1.2. Skills   2. What is Redux? 2.1. Why? 2.2. 3 Principles   3. Vanilla Counter 3.1. Reducers, Actions \u0026amp; Store, oh my! 3.1.1. Store 3.1.2. createStore() 3.1.3. Reducers (intro) 3.1.4. Actions (intro) dispatch (intro)   3.1.5. subscribe()   3.2. Updating State 3.2.1. Increment 3.2.2. Decrement 3.2.3. Increment if odd     4. LAB 01 - Finish the counter 5. Working with Objects and Initial State 6. LAB 02 - Update your code 7. Action Creators 8. LAB 03 - Use Action Creators   1. Learning Objectives 1.1. Concepts   Discuss the core concepts of Redux\n  Learn about\n  actions\n  reducers\n  store\n     Highlight the 3 core principles of Redux\n    1.2. Skills   Build a standalone JavaScript app using Redux\n  Explain how Redux works\n  Understand Redux core principles\n      2. What is Redux? At it\u0026#8217;s core, Redux is a state management library.\n   While it\u0026#8217;s not exclusively built for use with React, it does pair very well with React\u0026#8217;s one-way data flow.\n 2.1. Why? Before we actually dig into the Redux API, it\u0026#8217;s worth actually understanding what problem Redux aims to solve.\n As many of you know, managing state in React can be very difficult. For example, take a simple concept application built for viewing a menu and placing orders at a restaurant.\n The basic architecture might look something like this\u0026#8230;\u0026#8203;\n   We would also need to account for orders and users\n   note: we are not taking into account the individual architectures of order or user\n You should be able to imagine a flow here. However, upon further examination you might notice that the food categories are going to need further composition. Most menus are broken up into categories beyond just entrees and apps. so maybe, you decide to rearrange the categories to account for Appetizers, Entrees, Sides and Desserts.\n   At this point, our data model is already starting to get a layer of complexity, and we haven\u0026#8217;t even started to account for things like dietary restrictions (Gluten-Free, Vegetarian, etc.) or sub categories of food (Seafood, Chicken, Beef, etc.)\n It\u0026#8217;s also worth noting that we have not thought about how to handle orders. What happens when\u0026#8230;\u0026#8203;\n   a user decides to order 2 of the same item\n  something is out of stock\n  changes their mind after ordering and wants something different\n   Needless to say, if we continued the experiment, we would have many additional components that are passing props (some of which are of no concern to them) down to children and even grandchildren components.\n As you may have guessed, all of this is going to make our Application state difficult to manage.\n What we often fail to admit is that\u0026#8230;\u0026#8203;\n     State Management is hard     Enter Redux\n     Redux aims to make state management simple and predictable      2.2. 3 Principles Redux is a relatively small library built on 3 key principles.\n   There is always one Single Source of Truth\n  State is read-only\n  Changes are made with pure functions\n   We\u0026#8217;ll explore each of these principles in depth shortly.\n    3. Vanilla Counter We are going to start with a very basic counter in Vanilla JS. For now, we\u0026#8217;ll be using the following html. Yes\u0026#8230;\u0026#8203; we\u0026#8217;ll be using raw DOM manipulation\u0026#8230;\u0026#8203;\n index.html \u0026lt;div\u0026gt; \u0026lt;p\u0026gt; Clicked: \u0026lt;span id=\"value\"\u0026gt;\u0026lt;/span\u0026gt; times \u0026lt;button id=\"increment\"\u0026gt;+1\u0026lt;/button\u0026gt; \u0026lt;button id=\"decrement\"\u0026gt;-1\u0026lt;/button\u0026gt; \u0026lt;button id=\"incrementIfOdd\"\u0026gt;Increment if odd\u0026lt;/button\u0026gt; \u0026lt;button id=\"square\"\u0026gt;Square Count\u0026lt;/button\u0026gt; \u0026lt;button id=\"clear\"\u0026gt;Clear Count\u0026lt;/button\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt;   This will give us a basic counter with the ability to change the count by incrementing, decrementing, clearing, etc.\n Now we\u0026#8217;ll need to write the corresponding Redux code to address accomplish the tasks\n First, we\u0026#8217;ll need to install Redux. While this is typically accomplished through yarn/npm, we\u0026#8217;ll be using a CDN for this exercise.\n index \u0026lt;head\u0026gt; \u0026lt;script src=\"https://unpkg.com/redux@latest/dist/redux.min.js\"\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt;   Now we can start writing the code!\n Our first step will be to locate the value \u0026lt;span\u0026gt;.\n example const valueEl = document.getElementById('value')   Ultimately, we\u0026#8217;re going to inject our value into the \u0026lt;span\u0026gt;. Displaying the information if going to be a bit tricky at first, but hang in there!\n 3.1. Reducers, Actions \u0026amp; Store, oh my! 3.1.1. Store In Redux, the store is a single object that holds the entire state of your application.\n As mentioned above, this concept of a store introduces us to the first principle of Redux. The store serves as our Single Source of Truth\n For the example in this lesson, we\u0026#8217;ll need to first create a reducer function that returns a value, we\u0026#8217;ll then tell Redux to create a store based that function\u0026#8217;s value.\n create-store-example const counter = () =\u0026gt; 42 (1) const store = Redux.createStore(counter) (2)     1 create a counter function that returns a value   2 Use the createStore function from Redux passing counter as it\u0026#8217;s first argument     3.1.2. createStore() createStore is a function provided by Redux that (as the name implies) creates our store.\n Looking at the createStore documentation, you\u0026#8217;ll see that the createStore takes up to 3 arguments and returns an object. For now, we\u0026#8217;ll only be focusing on the first argument reducer\n  3.1.3. Reducers (intro) At it\u0026#8217;s most basic level\u0026#8230;\u0026#8203; a reducing function accepts an accumulation and a value, and then returns a new accumulation.\n     Reducing Functions are used to reduce a collection of values down to a single value.     Think about a standard reduce function used to add a collection of numbers. Let\u0026#8217;s say we have a soccer team and we want to accumulate all of the goals scored by the midfielders. We might have some objects with player names, numbers and total points.\n array-of-objects const unitedMidFielders = [ { name: \"Miguel Almiron\", number: 10, goals: 12}, { name: \"Andrew Carleton\", number: 30, goals: 6}, { name: \"Chris Goslin\", number: 20, goals: 5}, { name: \"Julian Gressel\", number: 24, goals: 9} ]   Now, if we want to add up all the total goals, we can use the reduce function\n reduce-score const totalGoals = unitedMidFielders.reduce((total, current) =\u0026gt; { return total += current.goals }, 0) console.log(totalGoals) // 32   The same could be done with returning an object\n reduce-score-and-players const totalGoalsAndPlayers = unitedMidFielders.reduce((accumulator, current) =\u0026gt; { return { ...accumulator, totalGoals: accumulator.totalGoals + current.goals } }, { totalGoals: 0, totalPlayers: unitedMidFielders.length}) console.log(totalGoalsAndPlayers) // {totalGoals: 32, totalPlayers: 4}       The concept of a reduce function in Redux is virtually the same as above. It takes in the Current State and a specified Action. Then performs the necessary operations to produce a single value.     redux-reducer function myReducer(state, action) { // For now, don't handle any actions // and just return the state given to us. return state }   As noted earlier, one of the core principles of Redux is that Changes are made with pure functions. It is important to keep in mind that your reducers must be pure functions.\n Meaning\u0026#8230;\u0026#8203; given the same input, the same output will always be produced. This helps to avoid unintended mutations to your application state.\n We will revisit reducer functions in more detail shortly, but first, we need to create some actions.\n  3.1.4. Actions (intro) According to the Redux Documentation\u0026#8230;\u0026#8203;\n  An action is a plain object that represents an intention to change the state. Actions are the only way to get data into the store\u0026#8230;\u0026#8203;\n  \u0026#8212; Redux Glossary   Read that again, an action is just a plain object. This object describes what changes should be made to the store. However, the action does not make the described changes. Instead the action is dispatched and runs through your reducers.\n This process reinforces the one of the governing principles of Redux\u0026#8230;\u0026#8203; that state is read-only. Actions themselves should not attempt to make changes, instead, an action should describe what type of change is being requested and provide any additional information.\n An action in our counter app may look like:\n action-example const increment = { total: totalFromStore, (1) type: 'INCREMENT' (2) }     1 The total found in our store (application state)   2 the type of action we want our reducer to take        An Action must contain a type property     dispatch (intro) Redux provides a dispatching function that accepts an action, and sends that action to your application\u0026#8217;s reducers.\n     This is the only way to trigger a state change     The function signature is pretty straightforward\n dispatch-signature store.dispatch(myAction)   The action passed to your reducer could be a predefined object, or created at invocation.\n action-with-object-literal store.dispatch({ foo: 'bar', type: 'ADD_BAR' })   You may have noticed that we\u0026#8217;ve been calling store.dispatch though pretty self-explanatory, it is worth noting that our store contains the dispatch method. In vanilla Redux, once an action is dispatched, the reducer functions are immediately invoked.\n Before wiring all of this up, we\u0026#8217;ll need to look at one at one more method from the Redux API\u0026#8230;\u0026#8203;\n   3.1.5. subscribe() We are going to want add an event listener that listens for anytime an action is dispatched and updates the UI accordingly.\n Out of the box, Redux offers the subscribe method. subscribe() takes one argument\u0026#8230;\u0026#8203; a listener function. This function is a callback that will be invoked anytime an action is dispatched.\n In our context, subscribe will be replaced by a special React Binding which uses subscribe under the hood. So we won\u0026#8217;t often work with it directly. However, subscribe is still worth understanding as it may be useful when working with Observables and libraries like RxJS.\n In order to use subscribe, we\u0026#8217;re going to want to first create some kind of function that will make a call to our store. This is typically accomplished by calling getState()\n For simplicity sake, we will call this function render\n getState const render = () =\u0026gt; { valueEl.innerHTML = store.getState().toString() }       Here, we are going to set the innerHTML value of our html span element (the counter value) to some value that we get from the store.     We are calling store.getState() which returns the current state tree of our application. Then (for this specific case) we are going to convert that value into a string.\n Next, we\u0026#8217;ll need to invoke render and finally, tell our subscribe method to use render as it\u0026#8217;s listener function.\n If that sounds complicated, don\u0026#8217;t worry, you\u0026#8217;re not alone. Looking at the code should clear things up.\n subscribe-to-changes const render = () =\u0026gt; { valueEl.innerHTML = store.getState() } render() (1) store.subscribe(render) (2)     1 render the application and state on load   2 listen for any changes to state, and invoke the render function    Our current code should look something like this:\n example const valueEl = document.getElementById('value') const store = Redux.createStore(counter) const render = () =\u0026gt; { valueEl.innerHTML = store.getState() } render() store.subscribe(render)   Take a few minutes to discuss this code with a partner.\n   3.2. Updating State As previously discussed, in order to follow the patterns introduced by Redux, we\u0026#8217;ll need to create actions that can be dispatched when each button is clicked.\n 3.2.1. Increment We\u0026#8217;ll start with increment.\n warning, this code isn\u0026#8217;t the prettiest\n increment // ... store.subscribe(render) document.getElementById('increment') (1) .addEventListener('click', () =\u0026gt; { (2) store.dispatch({ (3) type: 'INCREMENT' (4) }) })     1 Find the correct element on the DOM   2 Add an click event listener   3 call the dispatch function   4 describe the type of action you would like to take (supplying this as the payload of dispatch)    Alright! we are now ready to dispatch an action. As stated earlier, dispatch will call your reducer function. For us this is the counter function we wrote earlier.\n Logically, the next step is to setup our reducer to make the requested change to state and return a new object.\n increment-reducer const counter = (state=0, action) =\u0026gt; { (1) switch (action.type) { (2) case 'INCREMENT': (3) return state + 1 (4) default: (5) return state (6) } }     1 provide the state and action arguments - action is the payload provided from our argument to dispatch. We are also using a default param of 0 for our state   2 setup a switch statement to evaluate the type of action   3 If an action of INCREMENT, is provided execute the changes   4 update the value of state by 1   5 If no action is provided (or matched), execute the default case   6 return the default parameter provided in the function signature    There is a lot to unpack here, however, before moving forward, we can check to see if the increment button works.\n At this point, it should! Let\u0026#8217;s step through what happens.\n  On load, we make a call to render\n  which locates the store and gets the initial state\n  the counter reducer function will provide\n a default argument of 0 for the state\n  no type of action\n     the default case will execute, causing the reducer function to return a 0\n  0 is provided as the innerHTML of our value element and rendered to the DOM\n  We subscribe to changes in the store, passing render as our callback function\n  When a user clicks on the +1 button\u0026#8230;\u0026#8203;\n An action is dispatched to the store\n  INCREMENT is provided as the type of action we want to take\n  the reducer function runs and finds the case of INCREMENT to be true and executes the action.\n  returning 0 + 1\n     the subscription then calls the render callback function\n  gets the current state and replaces the innerHTML of our value element.\n       This pattern is what gives us predictability when interacting with state.\n A couple of other notes\n   INCREMENT is capitalized, while this is not necessary, it is considered a best practice, often, you\u0026#8217;ll use constants as types of actions\n  if/else statements can be used in place of switch/case. However, switch/case is more commonly used.\n  Typically, we\u0026#8217;ll be working with objects/arrays (instead of primitives), so most often you\u0026#8217;ll need to clone/copy the object before making changes to the state.\n    3.2.2. Decrement The pattern is almost exactly the same for decrement. Can you guess what we\u0026#8217;ll do?\n decrement const counter = (state=0, action) =\u0026gt; { switch (action.type) { case 'INCREMENT': return state + 1 case 'DECREMENT': return state - 1 default: return state } } // ... document.getElementById('decrement') .addEventListener('click', () =\u0026gt; { store.dispatch({ type: 'DECREMENT' }) })    3.2.3. Increment if odd For the increment if odd option, we\u0026#8217;ll add a little bit of logic to only call dispatch if the the counter value is odd.\n increment-if-odd document.getElementById('incrementIfOdd') .addEventListener('click', () =\u0026gt; { if (store.getState() % 2 !== 0) { store.dispatch({ type: 'INCREMENT' }) } })   In this scenario, we don\u0026#8217;t need to make any adjustments to our reducer. If our condition evaluates to true, the INCREMENT action will be dispatched.\n     4. LAB 01 - Finish the counter Using the code below\u0026#8230;\u0026#8203;\n   Write the logic for the remaining buttons\n  Square Count should return a square value\n  Clear Count should return a count of 0\n      \n   5. Working with Objects and Initial State Because we\u0026#8217;ll primarily be working with objects, it would be worth updating our counter to return an object, instead of a primitive.\n We can start by creating an object literal.\n initial-state-object const initialCounterState = { count: 0 }   Next we\u0026#8217;ll want update the reducer\n reducer-with-objects const counter = (state=initialCounterState, action) =\u0026gt; { (1) switch (action.type) { case 'INCREMENT': return {...state, count: state.count + 1} (2) case 'DECREMENT': return {...state, count: state.count - 1} default: return state } }     1 provide initialCounterState as the default state object   2 clone the existing state merge in the changes (an alternative syntax is Object.assign()) returning a new object    The reason we want to clone the state is that we must remember that state is read-only. By cloning the object, we are able to make the appropriate changes and let our reducer return a brand new object. This is a standard practice in functional programming, and used extensively throughout React.\n We also need to let our render method know to retrieve the count property (as opposed to the entire object)\n render-with-object const render = () =\u0026gt; { valueEl.innerHTML = store.getState().count }   Last but not least, we\u0026#8217;ll need to provide an action describing the property we want to change.\n action-with-object-property document.getElementById('increment') .addEventListener('click', () =\u0026gt; { store.dispatch({ count: parseInt(valueEl.innerHTML, 10), (1) type: 'INCREMENT' }) })     1 specify a count action and provide the current value found in the valueEl element\u0026#8217;s innerHTML. note: we\u0026#8217;ll need to use parseInt because the innerHTML value is a string    Now that we\u0026#8217;ve made the necessary changes, our increment button should work again.\n   6. LAB 02 - Update your code Using the above changes, update your existing action payloads.\n   7. Action Creators Last but not least, let\u0026#8217;s talk about Action Creators. According to the Redux documentation\u0026#8230;\u0026#8203;\n  Action creators are\u0026#8230;\u0026#8203; functions that create actions.\n  \u0026#8212; Redux Documentation   This means that Action Creators are simply functions that return objects. (Objects which happen to be actions.)\n We can use action creators in our existing code. Let\u0026#8217;s update the increment function.\n increment-action-creator const increment = (total) =\u0026gt; { return { type: 'INCREMENT', total: parseInt(total, 10) } } document.getElementById('increment') .addEventListener('click', () =\u0026gt; { store.dispatch(increment(valueEl.innerHTML)) })   Testing out our increment button, you\u0026#8217;ll note that we get the same (intended) result.\n Action creators are useful because they make our actions more portable. You can import an action into any file that needs it, and reuse as often as you like.\n   8. LAB 03 - Use Action Creators Refactor your existing code to use Action Creators in all of your calls to dispatch.\n   "
},
{
	"uri": "/javascript/nodejs/testing/intro-to-tdd/",
	"title": "Intro to TDD",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  What is TDD Why use TDD Approaches to TDD  What is TDD Test Driven Development (TDD) is an approach to programming where test code drives the implementation and detailed design of the production code.\nBob Martin (aka Uncle Bob), one of the leading experts and evangelists of TDD throughout the years put together the \u0026ldquo;Three Laws of TDD\u0026rdquo;.\nHere is what he came up with:\n Laws of TDD\n  You are not allowed to write any production code unless it is to make a failing unit test pass. You are not allowed to write any more of a unit test than is sufficient to fail; and compilation failures are failures. You are not allowed to write any more production code than is sufficient to pass the one failing unit test.  Before we go on to explain more what this means, lets ensure the definition of production code is clear.\nWhat is Production Code\nWhat is production code? Simply put, production code is any code that is intended to be deployed. It does not mean it will get deployed, but it has potential.\nMany people misunderstand TDD and think that no pre-work is done. You just jump straight into writing tests. Even for boiler plate code, at a minimum, some sort of discussion on the high level design and purpose of a feature need to be discussed.\nIn addition to design discussions, proof of concept code is not forbidden. It should expected to be short lived. The goal is to understand what you are working with so you can write good tests from the start.\nWhat the rules are saying is that you should NOT copy and paste this code and then try to write the tests for it.\nLaws or Guidelines\nFor many, hearing that you must do things this way is an immediate turn-off when adopting an idea. In reality, you can think of them highly recommended guidelines. If you practice TDD, you should not deviate from the \u0026ldquo;laws\u0026rdquo; easily.\nThere will be times when following the \u0026ldquo;laws\u0026rdquo; word for word are counter productive. If you feel you\u0026rsquo;ve come upon one of these times, you should really question why.\nWhy Practice TDD There are a lot of trends and fads that come a long with software engineering these days. It is always good to understand why something is popular to help make a decision on if you should adopt it or not, or if it is going to fade away in a year.\nTDD has grown in popularity along with agile development practices. In fact, they go very well together. Despite both becoming very popular, especially in previously water-fall heavy enterprises, they are not new. You can find their software development roots as far back as 1996 when extreme programming was coined/created by Kent Beck.\nCons of TDD\nFirst lets cover some of the downsides to TDD:\n   It adds to upfront development time Testing is hard The whole team needs to buy into the practice to make it work. Tests need to be maintained TDD is not a silver bullet Cannot apply TDD to legacy code  Pros of TDD\nOn the other hand, here are many of the pros:\n   Cleaner code Naturally high test coverage Decrease in bug potential because \u0026ldquo;stupid\u0026rdquo; mistakes are caught almost immediately Encourages modular code Encourages small steps saving time on the need for debugging Clarifies requirements if tests are implemented to the requirements. Regression tests are part of the natural development process Higher degree of confidence when making changes to code. Drives design  In some cases TDD often results in less tests than if you were to go back and write tests for code you already wrote. This is because you may of written functions/features that you really did not need in the first place.\nWhy Not Practice TDD? Outside of the pros, it may be easier say why you should practice TDD by addressing some of the common reasons given why people do not practice TDD.\nWe Don\u0026rsquo;t Have Time to Practice TDD TDD goes hand in hand with agile development. Despite this, a common excuse for not practicing TDD is that developers don\u0026rsquo;t have time to write the test before a feature needs to be delivered. This is partly to do with the upfront cost of TDD.\nWhat is easily missed is:\n Time saved fixing bugs Time saved attempting to understand code Time saved not rewriting the code because you ended up spending too much time on the previous point  However a great deal of the blame of not having time is poor estimation which has nothing to do with TDD. If you are cutting out testing before deploying, what else is getting skipped to make a date?\nI\u0026rsquo;m More Productive Implementing Code First This is awesome if you are a solo developer and it works for you. In reality most of us are on teams. If experience says anything, not everyone is going to be at the same level. The pool of perfect developers is very small as well, so chances are, writing tests for you code is a good thing.\nBy practicing TDD you are giving someone else confidence that they can change the code you wrote and to break anything else. As stated before, tests also act as documentation. They not only describe the behavior of a function, but they should be giving examples of how to use it and what to expect in negative situations.\nHow to Approach TDD Although the \u0026ldquo;laws\u0026rdquo; only mention unit tests, you are not limited to only implementing unit tests in TDD. At some point you will find that the only real way to test something is to write the integration test for it.\nA popular approach to start out by writing your acceptance/integration tests first, then implement the unit tests until the the integration tests pass:\nFigure 1. Test Cycle\nWhile behavior required Write an integration test for a specific behavior While integration test failing Write a unit test to fulfil partial behavior While unit test failing Write code to make unit test pass Commit While refactoring can be done Refactor While unit test failing Write code to make unit test pass Commit Push Source\nIf you notice, we include refactoring in this loop. This is an important concept that a lot of developers have a hard time with. Notice it comes after you\u0026rsquo;ve written and made the test pass, and you\u0026rsquo;ve done a commit.\nDo not worry when you first write code for a test that it is not perfect, or that it may be repeating something you\u0026rsquo;ve already done. Make it pass then refactor.\n Refactoring should not be left out. If you forget to do it, be sure you refactor before you push your code. Refactoring often helps prevent technical debt and drives clean code.\n "
},
{
	"uri": "/custom-workshops/frontend-at-thd/js-crash-course/",
	"title": "JS Crash Course",
	"tags": [],
	"description": "",
	"content": "Object Destructuring One of the many features that ES2015 (aka ES6) brought us is the Destructuring Assignment for Objects. The destructuring assignment syntax is a JavaScript expression making it possible to extract properties from objects into distinct variables.\nLet\u0026rsquo;s take a look.\nconst instructor = { name: \u0026#34;Shane\u0026#34;, email: \u0026#34;shane_barringer@homedepot.com\u0026#34; }; /* Map the `name` variable to `instructor.name` and the `email` to `instructor.email` */ const { name: name, email: email } = instructor; console.log(name); // \u0026#34;Shane\u0026#34; Compare the above example of destructuring to the old way.\nconst instructor = { name: \u0026#34;Shane\u0026#34;, email: \u0026#34;shane_barringer@homedepot.com\u0026#34; }; /* Map the `name` variable to `instructor.name` and the `email` to `instructor.email` */ let name = instructor.name let email = instructor.email console.log(name); // \u0026#34;Shane\u0026#34; Destructuring in the real world. When using a Node.js module or a library like React.js, you will find it less verbose to use destructuring assignment in your components.\nLet\u0026rsquo;s take a look at a practical example.\n// ...  this.state = { name: \u0026#34;foo\u0026#34;, email: \u0026#34;foo@bar.io\u0026#34;, admin: true }; // ...  const { name, email, admin } = this.state; name; // #\u0026gt; \u0026#34;foo\u0026#34;;  email; // #\u0026gt; \u0026#34;foo@bar.io\u0026#34;;  // Do something with `name` and `email` // ... In the above example, destructuring allows us to assign a value to name and email so we don\u0026rsquo;t have to type this.state.name and this.state.email.\nBelow is another example of React.js code without destructuring.\n It is not necessary to understand what the React code is doing, only to demonstrate how destructuring can make code less verbose and more readable.\n without destructuring\nconst Store = (props) =\u0026gt; ( \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Number: {props.store.number}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Manager: {props.store.manager}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; Location: {props.store.location.city}, {props.store.location.state}, {props.store.location.country} \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ); And here is what that code looks like refactored to use destructuring.\nwith destructuring\nconst Store = ({ store }) =\u0026gt; ( \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Number: {store.number}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Manager: {store.manager}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; Location: {store.location.city}, {store.location.state}, {store.location.country} \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ); New Variable Names We can also assign new variable names.\ndestructuring and variable declaration/assignment\nconst instructor = { name: \u0026#34;Shane\u0026#34;, email: \u0026#34;shane_barringer@homedepot.com\u0026#34; }; /* Assign `instructor.name` to the `x` variable and `instructor.email` to the `y` variable. */ const { name: x, email: y } = instructor; console.log(x); // Shane Deeply Nested Values This also works with deeply nested values.\nconst instructor = { name: \u0026#34;Shane\u0026#34;, contactInfo: { ldap: \u0026#34;mxb5594\u0026#34;, email: \u0026#34;shane_barringer@homedepot.com\u0026#34; } }; const { name: name, contactInfo: { ldap, email } } = instructor; console.log(email); // shane_barringe@homedepot.com Shorthand Syntax Another feature that ES2015 brought us is the ability to write shorthand syntax with objects. Meaning that if the new key being assigned has the same name as the existing property, you can write the value once.\nshorthand syntax\nconst instructor = { name: \u0026#34;Shane\u0026#34;, contactInfo: { ldap: \u0026#34;mxb5594\u0026#34;, email: \u0026#34;shane_barringer@homedepot.com\u0026#34; } }; const { name, contactInfo: { email } } = instructor; The above example works exactly as expected. Additionally, this technique can be used in Object creation.\n"
},
{
	"uri": "/application-security/api-security/01_service_to_service_oauth2/40_jwt/",
	"title": "JSON Web Token (JWT)",
	"tags": [],
	"description": "",
	"content": "JWT JWT ( pronounced jot )\n Stands for JSON Web Token Is a spec defining the fields and value types the JSON should have It is the glue that make all this work.  Looks something like this (shortened for brevity):\neyJhbGciOiJ_____.eyJzY29wZSI6Im9wZW5p____.JhriEGFoOJTEJt-aIdoepeH-7_____\nJWT Structure  Header Payload (Base64 encoded JSON) Signature Base64 encoded Encryption)  The Header JWT Header contains meta info about the token. It is a base64 URL encoded JSON. It includes the format and signing algorithm used\n{ \u0026#34;alg\u0026#34;: \u0026#34;RS256\u0026#34;, \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34;, \u0026#34;kid\u0026#34;: \u0026#34;x82hfg19dglsl\u0026#34; } The Payload The JWT payload field holds information about claims that were granted to the user/service the token is for. It is also a base64 URL encoded JSON.\n{ \u0026#34;sub\u0026#34;: \u0026#34;spiffe://homedepot.dev/my-client\u0026#34;, \u0026#34;aud\u0026#34;: \u0026#34;spiffe://homedepot.dev/my-resource-server\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;iss\u0026#34;: \u0026#34;https://identity-qa.homedepot.com\u0026#34;, \u0026#34;jti\u0026#34;: \u0026#34;QihJ9FfNfvsyh4SkO3K69C3TWcpvARj2\u0026#34;, \u0026#34;nbf\u0026#34;: 1597795642, \u0026#34;token_type\u0026#34;: \u0026#34;access_token\u0026#34;, \u0026#34;iat\u0026#34;: 1597795757, \u0026#34;exp\u0026#34;: 1597796362 } The Signature Used to validate that the token has not been modified and from the expected Authorization Server. It is a base64 URL encoded signature of the SHA of the first two sections (more on that below).\nClient Requests a JWT This will be covered in the next section in great detail, but for a quick look, the client will make a request for a JWT by using something similar:\ncurl --location --request POST \u0026#39;https://identity.service.homedepot.dev/oauth2/v1/token\u0026#39; \\ --header \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; \\ --data-urlencode \u0026#39;grant_type=client_credentials\u0026#39; \\ --data-urlencode \u0026#39;client_id=MY-CLIENT_ID\u0026#39; \\ --data-urlencode \u0026#39;client_secret=MY-SECRET\u0026#39; \\ --data-urlencode \u0026#39;scope=BEER_STORE_NAME/.default\u0026#39; Resource Server Takes Over Inspecting the JWT You have multiple ways to inspect the JWT and validate it.\n Open a browser to https://jwt.io or https://jwt.ms and copy and paste the JWT into those websites to inspect the JWT.  REMEMBER Tokens provide access, jwt.io is probably be safe, but a better solution is\u0026hellip;\u0026hellip;\n [RECOMMENDED] - use the step-cli if you installed it during PreFlight  # jwt shortened for brevity echo \u0026#39;eyJhbGciOiJSUzI1.eyJzY29wZSI6Im9wZW5pZCIsIm.JhriEGFoOJTEJt-aIdoepeH-7Dg4dO4BG\u0026#39; |step crypto jwt inspect --insecure Real Example eyJhbGciOiJSUzI1NiIsImtpZCI6IkFpODVXYXVLQmlKV3lSNmVZLXdEUUQzN1RVTSIsInBpLmF0bSI6ImtwY2EifQ.eyJzY29wZSI6Im9wZW5pZCIsImNsaWVudF9pZCI6InNwaWZmZTovL2hvbWVkZXBvdC5kZXYvaWRlbnRpdHktcmVmZXJlbmNlLXdlYmFwcCIsImlzcyI6Imh0dHBzOi8vaWRlbnRpdHktcWEuaG9tZWRlcG90LmNvbSIsImp0aSI6IlFpaEo5RmZOZnZzeWg0U2tPM0s2OUMzVFdjcHZBUmoyIiwiYXVkIjoic3BpZmZlOi8vaG9tZWRlcG90LmRldi9pZGVudGl0eS1yZWZlcmVuY2Utd2ViYXBwIiwic3ViIjoiQ0xUMDQiLCJuYmYiOjE1OTc3OTU2NDIsInRva2VuX3R5cGUiOiJhY2Nlc3NfdG9rZW4iLCJpYXQiOjE1OTc3OTU3NTcsImV4cCI6MTU5Nzc5NjM2Mn0.JhriEGFoOJTEJt-aIdoepeH-7Dg4dO4BGKAhz7SnLBxBpqdO2_dPwbPfRjxSo6b2SCwGxpya802BPTW1uqbGcmutgY8_Osxx6_ySmFskATV-nTiHWfX-0MFVsASAHHAJjZxQmRoBsfkU1X4yCTjwIBE0dJePVwboSZWdcAT9VdUtjUp663HBUsclhHtbEV4_YLXNju6-v1IwqoS48001wDm6_6UHqIQTuYJqwx3LrPTncL0pADhfW9rc6LiWbdBKlvTrB3joVMni7FQCAuCLz3-1ZnUotLmr5FMdn5FOQ_2zsls-AOBq8Kipn3eN1YEtUu7H3EXujmDuZyRvkXb29g Claims A JWT is nothing more than two verifiable JSON documents. It is mostly key/value pairs. There are some standard key/value pairs. These keys are called claims. Here is the wikipedia entry:\nHeader Claims          alg - Algorithm What algorithm was used to create this token? Should always be RS256   kid - Key ID Which Public Key should be used to validate this token?    Payload Claims          iss - Issuer Who issued this token?   sub - Subject Who requested the token?   aud - Audience Where will this token be used?   scopes - Scopes Any additional authorization information needed?   jti - JWT ID Universally Unique Identifier of this token   exp - Expiration Unix Timestamp of when this token expires   iat - Issued At Unix Timestamp of when this token was issued   nbf - Not Before Unix Timestamp of start of the valid time window   token_type Home Depot special addition, indicates if token is Access Token or ID TOken    All claims as defined in the RFC\nBack to Beer If you think back to our Beer analogy at the beginning\n Subject == Buyer of the Beer Audience == Seller of the Beer Issuer = Which Gov\u0026rsquo;t Issued the ID  What about the who Cryptography-thingy? So the reason a JWT is cryptographically signed? Lets unpack this:\nThe way a JWT is created is using the super secret Private Key of the Issuer (PingFed, Azure, etc)\nheaderBase64 = base64(header.json) payloadBase64 = base64(payload.json) tempString = concat(headerBase64, \u0026#34;.\u0026#34;, payloadBase64) shaString = sha256(tempString) signatureString = RSAWithPrivateKey(shaString) jwt = concat(headerBase64, \u0026#34;.\u0026#34;, payloadBase64, \u0026#34;.\u0026#34;, signatureString) But this also means we can use their very public Public Key to validate the JWT.\nSo where is the Public Key? So thank goodness for standards. For Authorization Servers, their public key must be published.\nHere are the steps:\n Take the issuer claim, which in our example is https://identity-qa.homedepot.com Append the RFC required discovery path: /.well-known/openid-configuration   https://identity-qa.homedepot.com/.well-known/openid-configuration  Look in that document for a key called jwks_uri   https://identity-qa.homedepot.com/pf/JWKS  Open that url, it is an array of keys. Open the header of the JWT, and find the kid claim. Now open the JWKS Url, and look for that exact kid That is the public key that must be used.  Pretty cool, huh?\nHow to use the Public Key? Simple answer is use a library. We are working on common patterns for all major languages.\nDon\u0026rsquo;t go cowboy on this one, it will end badly for you. :D\n"
},
{
	"uri": "/react/pillars/testing/tdd/gift-list/",
	"title": "Lab: Gift List App Set Up",
	"tags": [],
	"description": "",
	"content": "Gift List App Set Up\n Topics 1. In this lesson you will learn: 2. The Demo 3. Gift List App Design 4. Lab: Gift List Set Up 4.1. Create a new React App 4.2. Install libraries 4.3. Write the first test 4.4. Set Up Enzyme 4.5. Where\u0026#8217;s my View?     1. In this lesson you will learn:   Determine how will you design your app\n  How to set up a React app for testing\n     2. The Demo Your UX team has designed an incredible new app! It is called \"Gift List\" and it helps users keeps track of gifts they plan to purchase. They even created a clickable prototype in order to gain user feedback. Go ahead and play with the app and explore its functionality. The implementation allows users to create, read, update and delete gifts. [Demo Gift List App](https://github.com/one-thd/om_labs_gift-giver-tdd.git)\n \n   3. Gift List App Design Like JavaScript, React does not confine you to a set of rules to abide by. You have choices with how you structure and build your app. Now that you have played with the demo, discuss with a neighbor how you plan to build this app. Sketching and labeling the components may be helpful.\n  Into how many components will you break up the app?\n  Where will state live?\n     4. Lab: Gift List Set Up 4.1. Create a new React App  Create a new React application.\n create-react-app gift-list\n  cd gift-list\n     Check your commit history git log. Note that react makes the first commit for you. You\u0026#8217;re welcome!\n    4.2. Install libraries  You\u0026#8217;re going to need to install a few dev packages. They are:\n enzyme\n  enzyme-adapter-react-16\n     These are all development dependencies and are only used during the development process. In the package.json we want them to appear as devDependencies.\n   After installation, your package.json should look like this: \"devDependencies\": { \"enzyme\": \"^3.8.0\", \"enzyme-adapter-react-16\": \"^1.7.1\" }       How do we add these packages so that they are added as devDependencies?     Table 1. What do these packages do?     jest\n JavaScript testing library that serves as the test runner and assertion library\n   enzyme\n JavaScript testing utility for React that makes it easier to assert, manipulate, and traverse your React Components' output.\n   enzyme-adapter-react-16\n Adapters serve as the configuration tool needed by enzyme to be able to interact with React components\n     Check your package.json. Are the newly added libraries in the write place under devDependencies?\n    4.3. Write the first test We are going to test drive this entire app. We will write failing tests and implement the code to make them pass the entire way. Buckle up!\n  Open the Explorer panel in your text editor.\n  Delete the /src directory. Yes, mean it.\n  Create two new directories at once /src/components.\n  Inside of the /components directory, create the first test file named App.test.js\n  In the integrated terminal, run yarn test. You should see your first test failure. Congratulations!\n      In the App.test.js add:\n   import React from 'react'; import { shallow } from 'enzyme'; import App from './App'; describe(\"App\", () =\u0026gt; { it(\"renders \u0026lt;App /\u0026gt;\", () =\u0026gt; { const wrapper = shallow(\u0026lt;App/\u0026gt;) expect(wrapper.exists()).toEqual(true) }) })    Let’s look at this test failure. What is is telling us to do?\n      Time to create the App.js\n    4.4. Set Up Enzyme  You should see an error message pertaining to an Enzyme Internal Error. Looks like Enzyme needs an adapter to tap into the React component. Here is the link to the enzyme docs for you to review what we are about to do next.\n Create a file inside of the /src directory named setupTests.js. The file MUST have this name in order that enzyme can find it.\n  Add this code to that file:\n      import { configure } from 'enzyme'; import Adapter from 'enzyme-adapter-react-16'; configure({ adapter: new Adapter() });    Hmmm\u0026#8230;\u0026#8203;.we still have an error and the message is not as simple to understand. Read the error and think, \"What could jest be complaining about?\" Since we have altered a configuration file, we need to stop Ctrl + C and restart yarn test or npm run test the test suite.\n      Essentially the test is telling you that it does not have any content to return inside of the App.js. Let\u0026#8217;s give it what it wants.\n   import React, { Component } from 'react'; class App extends Component { render() { return ( \u0026lt;div\u0026gt; \u0026lt;/div\u0026gt; ); } } export default App;    Whoo hoo! We\u0026#8217;ve got our first passing test!\n      Sometimes tests pass that should not. Just to be sure that this is a legitimately passing test, change true to false. Watch the test fail, then change the value back to true.\n  Time to commit to git!\n Create a repository on GitHub. Make sure that as you complete each feature, you commit your code to GitHub with a meaningful commit message. \"Future you\" will thank you.\n  git add .\n  git commit -m 'set up testing framework'\n  git push\n       4.5. Where\u0026#8217;s my View?  Let\u0026#8217;s see what our app currently looks like. In a terminal tab, run yarn start.\n  Looks like the app is missing a file called index.js. Inside of /src, create an index.js file. Add the following content:\n   import React from 'react'; import ReactDOM from 'react-dom'; import App from './components/App'; ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById('root')); export default App;       What\u0026#8217;s the purpose of the index.js file?      Save the file and run yarn start again. You should be routed to localhost:3000 to see absolutely NOTHING! Don\u0026#8217;t worry. That will change soon.\n      "
},
{
	"uri": "/software-eng-essentials/text-editors/text-editors-labs/",
	"title": "Lab: Test Drive Your Text Editor",
	"tags": [],
	"description": "",
	"content": "Instructions:\n Create a directory, text-editor-labs Complete these challenges with minimal use of the mouse or trackpad  Eggs and Ham  Create a file called eggs-and-ham.txt Copy the following text into your editor and save the file  i AM SAM. i AM sam. SAM i AM. THAT SAM-I-AM! THAT SAM-I-AM! i DO NOT LIKE THAT SAM-I-AM! DO WOULD YOU LIKE BLUE EGGS AND HAM? i DO NOT LIKE THEM, sam-I-AM. i DO NOT LIKE BLUE EGGS AND HAM. WOULD YOU LIKE THEM HERE OR THERE? i WOULD NOT LIKE THEM HERE OR THERE. i WOULD NOT LIKE THEM ANYWHERE. i DO NOT LIKE BLUE EGGS AND HAM. i DO NOT LIKE THEM, sam-I-AM. WOULD YOU LIKE THEM IN A HOUSE? WOULD YOU LIKE THEN WITH A MOUSE? i DO NOT LIKE THEM IN A HOUSE. i DO NOT LIKE THEM WITH A MOUSE. i DO NOT LIKE THEM HERE OR THERE. i DO NOT LIKE THEM ANYWHERE. i DO NOT LIKE BLUE EGGS AND HAM. i DO NOT LIKE THEM, sam-I-AM.  Change all occurrences of BLUE to green Convert i to I where appropriate and all sam to Sam Replace all EGGS AND HAM with Eggs, ham and cheese Duplicate WOULD YOU LIKE THEM IN A HOUSE? two times. Move the two newly created lines from above to the end of the file  Fruit  Create a file called fruit.txt Copy the following text into your editor and save the file  \u0026#39;apple\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;banana\u0026#39;, \u0026#39;mango\u0026#39;, \u0026#39;pineapple\u0026#39;  Split the following line into 5 lines with 1 item per line Do not remove any of the commas.  Math  Create a file called math.txt Copy the following text into your editor and save the file  one plus one equals two one plus two equals three one plus three equals four two plus three equals five four plus one equals five four minus two equals two four minus three equals one five minus three equals two six minus four equals two two times two equals four two times three equals six three times two equals six four divided by two equals two six divided by two equals three six divided by three equals two  Convert the string numbers to integers Convert the operator words to symbols For example, the first line above should be changed to: 1 + 1 = 2  Superheroes  Create a file called superheroes.txt Copy the following text into your editor and save the file  batman robin joker catwoman wonder woman superman spiderman hulk flash wolverine underdog  Bring catwoman AND wonder woman to the top of the list Send the joker to the bottom  "
},
{
	"uri": "/software-eng-essentials/looker/",
	"title": "Looker",
	"tags": [],
	"description": "",
	"content": "Looker is a cloud-based service that provides search, analytics, dashboards and alert generation functionality for logged data.\nLooker provides visibility of operational data (mostly logged data) to deliver insights with impact and create data experiences able to be tailored for your organization. Anyone who needs operational data to do their jobs can benefit from Looker capabilities.\nBefore you Start Home Depot\u0026rsquo;s Looker can be found at https://homedepot.looker.com/. In order to get access to it, submit an ARP request for gg_cloud_gcp-io1-datalake-views_user.\n It is possible to complete the Google and Pluralsight\u0026rsquo;s training without the above ARP request.\n If you have any questions about looker, direct them to the #monitoring-logs Slack channel!\nExternal Training This pre-work will be where the majority of your learning will occur. The upcoming workshop will simply be a walk-through of how to apply this knowledge in THD\u0026rsquo;s Looker with opportunities to ask questions.\nThe times listed next to each lesson are estimated by Google on how long they will take. It is possible it will take less time than what is listed.\nData Consumer (approximately 100 min)  Why use Looker? (10 min) Where to look for data? (10 min) Working with saved content (20 min) Creating Looks and dashboards (40 min)  This is where the first lab occurs: Creating Looks and Dashboards  Qwiklabs is EXTREMELY picky, so if you are not able to get the official check, that is ay-okay! Just make sure it looks like the solution images that are at the bottom of the screen!     Sharing data with others (20 min)  There is a corresponding lab: Sharing Looks   (Optional) Data visualization best practices (60 min)  LookML Developer (approximately 145 min estimated) Google Training will ask if you want to switch to Developer mode. Select Yes.\n Understanding dimensions and measures (60 min) Filter options for users (25 min) Working with Looker content (60 min)  There is a corresponding lab here: Working with Looker Content   (Optional) What LookML can do for you (7 min)  Additional Resources  Looker Documentation THD Looker Documentation THD Guide for Creating a Dashboard with PCF or Orange Logs  Lessons "
},
{
	"uri": "/software-eng-essentials/looker/lookml/",
	"title": "LookerML",
	"tags": [],
	"description": "",
	"content": "This lesson will cover how Looker works as well as how to build and maintain your own LookML data model.\nObjectives  Explain how Looker writes SQL Write basic LookML to describe fields in your database Utilize Git version control to save and collaborate Create new fields Create Explores  Training  Getting Started with LookML THD\u0026rsquo;s advanced training  "
},
{
	"uri": "/java/foundations/primitives/",
	"title": "Primitives",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Understanding primitive types List the primitive types  Skills  Declare variables using any of the primitive types  Variables Creating a variable has two main parts:\n Declaration: which declares the type and name of the variable. Assignment: which assigns a value to the variable  Declaration type variableName; Initialization variableName = value; Variables contain either primitive data or object references. We will discuss primitives in this section.\nPrimitives Variables that are primitive types holds an actual value. This means that when variable is manipulated, all the work is contained to this singular variable.\n   Type Example Description     byte byte b = 65; 8-bit signed two\u0026rsquo;s complement integer (-128 \u0026gt;= byte \u0026gt;= 127)   short short s = 65; 16-bit signed two\u0026rsquo;s complement integer (-32,768 \u0026gt;= byte \u0026gt;= 32,767)   int int i = 65; 32-bit signed two\u0026rsquo;s complement integer (-2^31^ \u0026gt;= byte \u0026gt;= 2^31^-1)   long long l = 65L; 64-bit signed two\u0026rsquo;s complement integer (-2^63^ \u0026gt;= byte \u0026gt;= 2^63^-1)   float float f = 65f; single-precision 32-bit IEEE 754 floating point   double double d = 65.0; double-precision 64-bit IEEE 754 floating point   char char c = 'A'; Singular character (stored using ASCII, e.g. \u0026lsquo;A\u0026rsquo; is 65)   boolean boolean b = true; represents one bit of information, only possible values: true, false    Primitive Examples\nStrings Strings are an interesting case, in that they are proper objects that extend Java\u0026rsquo;s base Object.\nWe will be going into great detail about Objects later.\nIn many ways, a String\u0026rsquo;s behave similarly to a primitive type.\nString name = new String(\u0026#34;Elizabeth\u0026#34;); // can be written as String name = \u0026#34;Elizabeth\u0026#34;; Strings get their name from being a string of characters all together forming words and sentences. Unlike other common languages, Java uses different quotations to determine type. A character type uses single quotes ('A') while a String uses double quotes (\u0026quot;A String\u0026quot;).\nStrings are special. They are not primitives, but yet they\u0026rsquo;re not normal objects.\nString s1 = \u0026#34;abc\u0026#34;; // is composed of the characters strung: \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;e\u0026#39;  INFO Notice you don\u0026rsquo;t need a constructor as with most objects\n Strings are always immutable - the underlying object cannot be changed.\nSo when we assign\u0026hellip;\ns1 = \u0026#34;xyz\u0026#34;; \u0026hellip;we are not changing the object that used to hold \u0026ldquo;abc\u0026rdquo;, rather a new string \u0026ldquo;xyz\u0026rdquo; was created and a reference to the new string is now held in s1.\nStrings actually get handled specially. They are found in the memory heap like other objects, but unlike other objects they are kept in a pool of other similar objects, aptly named the string pool. This is done for efficiency as no String will be created more than once; if you create 100 variables to hold the String \u0026ldquo;WR is the best\u0026rdquo;, Java will only ever create one String object.\nIf we create a third string with the same value\u0026hellip;\nString s3 = \u0026#34;xyz\u0026#34;; \u0026hellip;a new string object is not created, rather s3 holds the same reference as s1. This explains why they must be immutable otherwise updating one would have unintended consequences to the other.\nEscape Character Sometimes there may be special characters that you want your String to ignore (white spaces, quotes, etc). This is where escape characters come in. In Java the escape character is a backslash (\\). Whenever you have a backslash in your string, the character afterwards in interpreted in a special way.\n   Character Squence Interpretation     New Line \\n Breaks the String to the next line during out   Tab \\t Tabs horizatonally during out   Backslash \\\\ Inserts backslash   Single Quote \\' Inserts single quote   Double Quote \\\u0026quot; Inserts double quote instead of ending String   Null Character \\0 Inserts null character    What will this statement print?\nSystem.out.println(\u0026#34;This is a test and \\nonly \\\u0026#34;a test.\\\u0026#34;\u0026#34;);  INFO\nThe System.out object is automatically created in every Java program.\nIt has methods for displaying text strings and numbers in plain text format on the system display, which is sometimes referred to as the “console.”\n Strongly Typed You may have heard it said about Java that it is strongly typed, but what does this mean? It means that every variable used in java must be declared and part of that declaration must be the Type that the program expects the variable to be. All variables, therefore, hold onto the type that was used when it was created and it demands to be treated as such and cannot change. When the variable is used, the Java compiler will check that the given type is valid for the accessor trying to use it. In other words, if you write a method that expects a String, you cannot compile while trying to pass in an Integer.\nString name = \u0026#34;Homer\u0026#34;; name = 10; // Compile error Casting Type casting is used to convert an object or variable of one type into another temporary.\nint number = 65; char letter = (char) number; //Casting an int to a char  System.out.print(\u0026#34;The number is: \u0026#34;); System.out.println(number); System.out.print(\u0026#34;The letter is: \u0026#34;); System.out.println(letter); When casting, the data type of the variable is converted to the type in the parentheses temporarily.\nIf you try to convert something to an incompatible type you will get an error.\nSummary Java is strongly-typed, meaning it cares what variables you make and forces you to treat them the same way until they\u0026rsquo;re destroyed.\nResources  Look at source code! Java Documentation  "
},
{
	"uri": "/python/testing/pytest-command/",
	"title": "Pytest Command",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Identifying Existing Tests Execute a Test Running Specific Tests Skip Tests Setting a Timeout Saving Test Results Generating Coverage Reports  pytest The pytest CLI command is intended to be used with test functions and classes found within a test file.\nThe pytest command will execute Test Functions:\nfrom calculate import add def test_add(): op1, op2 = 3, 2 result = 5 assert add(op1, op2) == result Identifying Existing Tests When working with an unfamiliar code base, it is important to find all existing tests to know what you\u0026rsquo;re working with. Tests can provide documentation as to an app\u0026rsquo;s purpose and function.\nWe can use the pytest --collect-only option to identify all existing tests.\nThis will show all of the tests in the current directory and all subdirectories broken down by the following categories:\n Module Class (If applicable) Function  An example output of this is:\n$ pytest --collect-only ========== test session starts ========== platform darwin -- Python 3.7.7, pytest-5.4.2, py-1.8.1, pluggy-0.13.1 rootdir: /Users/ldap/python-testing collected 3 items \u0026lt;Module calculate/calculate_test.py\u0026gt; \u0026lt;Class TestCalculator\u0026gt; \u0026lt;Function test_add\u0026gt; \u0026lt;Function test_subtract\u0026gt; \u0026lt;Module databases/database_test.py\u0026gt; \u0026lt;Function test_connect\u0026gt; ========== no tests ran in 0.02s ========== Sometimes this is too much information. You can add the -q flag to turn on quiet mode, giving you a much shorter output:\ncalculate/calculate_test.py::TestCalculator::test_add calculate/calculate_test.py::TestCalculator::test_subtract databases/database_test.py::test_connect no tests ran in 0.01s Execute a Test If your file structure looks like:\ncalculate |── calculate.py └── calculate_test.py You can simply run from the calculate directory:\n$ pytest ========= test session starts ========= platform darwin -- Python 3.7.7, pytest-5.4.2, py-1.8.1, pluggy-0.13.1 rootdir: /Users/ldap/python-testing/calculate collected 2 items calculate_test.py .. [100%] ========= 2 passed in 0.02s ========= Verbose Mode To see the status of each test and print lines, you can pass the -v option which stands for verbose.\npytest -v ====== test session starts ====== platform darwin -- Python 3.7.7, pytest-5.4.2, py-1.8.1, pluggy-0.13.1 -- /usr/local/opt/python/bin/python3.7 cachedir: .pytest_cache rootdir: /Users/ldap/python-testing/calculate collected 2 items calculate_test.py::TestCalculator::test_add PASSED [ 50%] calculate_test.py::TestCalculator::test_subtract PASSED [100%] ====== 2 passed in 0.02s ====== To see any standard output, use the -s flag:\npytest -s Specify Tests Pytest allow you to specify the modules, files, classes or methods you would like to run.\n To run all test files, classes, and methods found in a module called calculator:  pytest calculator/  To run all test classes and methods found in a file called calculator_test.py:  pytest calculator_test.py  To run all test methods in a class called TestCalculate in a file called calculator_test.py:  pytest calculator_test.py::TestCalculate  To run a specific test method call test_add in a class called TestCalculate in a file called calculator_test.py:  pytest calculator_test.py::TestCalculate::test_add  To run all tests with a specified marker, use the -m flag. So to run all tests that use the @pytest.marker.parametrize decorator:  pytest -m parametrize Skipping You can choose to skip certain tests by passing the r and s flags.\nIf you have long running tests that you don\u0026rsquo;t wish to run all the time, especially during development that doesn\u0026rsquo;t affect that test.\nIn your test, use pytest's skip method.\nimport pytest def calculate_test() { # code here pytest.skip(\u0026#34;Invalid credentials\u0026#34;) } Then, you can see the reason a test is skipped with the -rs flag.\nThe -r flag gives the \u0026ldquo;short test summary info\u0026rdquo; at the end of the output. This flag should be paired with another flag to describe what should be summarized. In this case, we used the s flag to say we want the skipped tests summary.\n$ pytest -rs calculate_test.py s. [100%] ======== short test summary info ======== SKIPPED [1] /Users/ldap/python-testing/calculate/calculate_test.py:6: Invalid credentials ======== 1 passed, 1 skipped in 0.02s ======== Setting a Timeout In order to have a test timeout if not completed by X units of time, we can specify a max time for tests to run using a pytest plugin called pytest-timeout.\nOnce this is installed, you can set timeouts on all tests or specific tests.\nSetting a timeout all tests after 3 seconds looks like:\n$ pytest --timeout 3 All tests that were not able to complete before timing out will all be labeled as failed, similar to:\nE Failed: Timeout \u0026gt; 3s calculate_test.py:7: Failed ====== short test summary info ======s FAILED calculate_test.py::TestCalculator::test_add - Failed: Timeout \u0026gt; 3s It is possible to have specific tests timeout at a specific time with the @pytest.mark.timeout decorator.\nFor example, the following would make test_add timeout whether the --timeout flag was used or not at 6 seconds:\n@pytest.mark.timeout(6) def test_add(self): # code here Saving Test Results PyTest will output to the STDOUT of the terminal, allowing us to use terminal commands to save the contents of this output to a file.\nOne could run the following command:\n$ pytest \u0026gt; $(date +\u0026#34;%m_%d_%Y\u0026#34;) It will place the output of the test inside the current folder with the current date. (This works on a darwin based system.) This could be used with grep, or awk to achieve pretty printed results.\nLet\u0026rsquo;s say that your pipeline, whether it be Team City, Jenkins, GitHooks, or Concourse requires the json output of the test results. This can be done with another pytest plugin pytest-json-report..\nWe can run the below command to create a report called .report.json in json format.\n$ pytest --json-report .report.json will have all of the details about when the test was ran, what kind of system it was ran on, a summary of the test results, and a detailed output of each test.\nTo just get a summary, run the --json-report flag with the --json-report-summary flag:\n$ pytest --json-report-summary --json-report This will provide something for automated pipelines or hooks to read from.\nGenerating Coverage Reports Test coverage is a term in the software engineering realm that describes how much of a code base is exercised by its automated tests.\nTo get the test coverage for a package, we use another pytest plugin called pytest-cov..\nThe following gets a coverage report of all files in a calculate module (If you were in the calculate module)\n$ pytest --cov=calculate ---------- coverage: platform darwin, python 3.7.7-final-0 ----------- Name Stmts Miss Cover ---------------------------------- calculate.py 8 2 75% If you are outside of the calculate module, you can specify which module to look in with:\n$ pytest --cov=calculate calculate/ You can specify if you want the coverage report to come out as an html file or xml file with the --cov-report flag. So if you wanted the above coverage to be placed in an html file:\n$ pytest --cov=calculate --cov-report=html This will generate a folder called htmlcov inside of the current directory. If you open up the calculate_py.html file you will get something similar to:\nSummary PyTest is not only a library to add to a python project, but a corresponding CLI. This is a very powerful tool that allows you to interact with tests in many different ways. You are also able to record the output of tests in various ways using pytest plugins.\nLab Setup\n If you have not already, Fork https://github.homedepot.com/om-labs/python-testing to your Home Depot profile Clone down your newly forked repo cd into the python-testing/pytest-command directory Follow the instructions found in the README  "
},
{
	"uri": "/react/pillars/redux/react-and-redux/",
	"title": "React and Redux",
	"tags": [],
	"description": "",
	"content": "Using Redux in your React application\n Topics 1. Learning Objectives 1.1. Concepts 1.2. Skills   2. Introduction 3. Project Setup 3.1. TodoMVC Styling 3.2. react-redux 3.3. Application Structure   4. Actions 5. Reducers 5.1. Reducer Composition 5.1.1. The visibilityFilter Reducer 5.1.2. The todos Reducer   5.2. The Root Reducer   6. Presentational Components 6.1. Todo.js 6.2. TodoList.js 6.3. Link.js 6.3.1. Understanding props.children   6.4. TodoCount.js 6.5. Footer.js 6.6. App.js   7. Container Components 7.1. FilterLink 7.1.1. connect() 7.1.2. mapStateToProps 7.1.3. mapDispatchToProps 7.1.4. FilterLink Revisited - Putting It All Together   7.2. ItemCount.js 7.3. VisibleTodoList 7.3.1. The Object Shorthand Form of mapDispatchToProps   7.4. Test It Out 7.5. AddTodo.js   8. LAB: Add the Redux Code for AddTodo 9. Redux DevTools 10. Lab - Setup Redux Dev Tools and Delete A Todo 11. Summary 12. Lab - Recap 13. Additional Resources   1. Learning Objectives 1.1. Concepts   Discuss using Redux for state management in your React applications\n  Showcase the react-redux library\n  Explore the Redux documentation\n    1.2. Skills   Use Redux in your React applications\n  Create a Redux store\n  Write action types and action creators\n  Write reducer functions\n  Use mapStateToProps and mapDispatchToProps to connect a component to the Redux store.\n      2. Introduction Now that you have mastered Redux, it\u0026#8217;s time to talk about integrating Redux with React. For this lesson we will be using the Redux documentation and building the example todo app. We will also be using the CSS Styling from Todo MVC to make our Todo App look pretty.\n  Figure 1. Todos App    3. Project Setup We\u0026#8217;ll start by creating a new app and installing redux as well as the react binding for redux (called react-redux).\n $ create-react-app redux-todo $ cd redux-todo $ yarn add redux   3.1. TodoMVC Styling To make our TODO app look nice, we are going to use the CSS styles from Todo MVC. We will also be using the classnames library for conditionally setting className values on our components. You can install these dependencies via:\n $ yarn add todomvc-common $ yarn add todomvc-app-css $ yarn add classnames   We can import the CSS files in the src/index.js file:\n src/index.js import React from 'react'; import ReactDOM from 'react-dom'; import './index.css'; import 'todomvc-common/base.css'; // add this line import 'todomvc-app-css/index.css'; // add this line too import App from './App'; import * as serviceWorker from './serviceWorker';    3.2. react-redux In order to use Redux with React, we also need to install the react-redux package:\n $ yarn add react-redux   This package provides special Redux bindings for use with React by giving us a couple of simple utility methods/components. One such utility component is the \u0026lt;Provider\u0026gt; component. Typically, this component wraps our entire application (at the root) and provides access to the store.\n Let\u0026#8217;s go ahead and wrap our application in \u0026lt;Provider\u0026gt;. This time we will put the \u0026lt;Provider\u0026gt; wrapper in our app.js file (instead of the index.js file).\n app.js import React from 'react' import { Provider } from 'react-redux' (1) import store from './redux/store'; (2) import './App.css' function App() { return ( \u0026lt;Provider store={store}\u0026gt; (3) \u0026lt;section className=\"todoapp\"\u0026gt; \u0026lt;header className=\"header\"\u0026gt; \u0026lt;h1\u0026gt;todos\u0026lt;/h1\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/Provider\u0026gt; ) } export default App     1 Import the Provider component   2 Import the store from a local file we will be creating next   3 Nest your \u0026lt;Provider\u0026gt; component inside the \u0026lt;App\u0026gt; component.     3.3. Application Structure Before we dig into the specifics of React and Redux, we\u0026#8217;ll need to structure our application. While there is no official way to setup a React app, there are several conventions that we could follow. Later we will explore specific patterns for structuring your actions and reducers. However, for this app, we are going to keep things simple.\n First let\u0026#8217;s create folders for our components and for our Redux support code such as Actions, Reducers, and creating the Store:\n mkdir src/components mkdir src/redux touch src/redux/store.js touch src/redux/actions.js touch src/redux/actionTypes.js mkdir src/redux/reducers touch src/redux/reducers/index.js     Afterwards the file structure of src should be:\n   src ├── App.css ├── App.js ├── App.test.js ├── components ├── index.css ├── index.js ├── redux │ ├── actionTypes.js │ ├── actions.js │ ├── reducers │ │ └── index.js │ └── store.js └── serviceWorker.js   We need a store to make the app run. So open src/redux/store.js and insert the following code:\n src/redux/store.js import { createStore } from \"redux\"; import rootReducer from \"./reducers\"; export default createStore(rootReducer);   The store depends on the rootReducer, so let\u0026#8217;s create a super simple rootReducer for now. Open src/redux/reducers/index.js and insert the following code:\n src/redux/reducers/index.js export default (state = {}, action) =\u0026gt; state;       This reducer doesn\u0026#8217;t do anything interesting yet, but we will come back to it later.     At this point the app should run without any errors, but it doesn\u0026#8217;t do much yet. Let\u0026#8217;s start our server and verify that our code runs without errors:\n yarn start   Now open your browser to http://localhost:3000 and confirm that you see the \"todos\" heading at the top of the page. Also, open Chrome\u0026#8217;s Dev Tools and confirm that there are no errors in the JavaScript console.\n    4. Actions Now, let\u0026#8217;s go ahead and set up our actions. We can define our action\u0026#8217;s in src/actions/index.js.\n We\u0026#8217;ll start by defining our action types. Edit src/redux/actionTypes.js and insert the following code:\n src/redux/actionTypes.js export const TOGGLE_TODO = 'TOGGLE_TODO'; export const SET_FILTER = 'SET_FILTER';   Here were are setting constants that are equal to string values. While not necessary for an application of this size, it is still recommended to follow the above convention.\n     Defining your action type\u0026#8217;s as constants makes your code more robust and self-documenting.     Next we\u0026#8217;ll need to add any other constants that might be applicable. In this case, we need to add our Visibility Filters that will allow the user to toggle between viewing all todos, just the completed todos, or just the incomplete todos.\n Let\u0026#8217;s create a src/constants.js file to hold our Visibility Filters values:\n touch src/constants.js   Open that file in your editor and insert the following code:\n src/constants.js export const VISIBILITY_FILTERS = { ALL: 'all', COMPLETED: 'completed', INCOMPLETE: 'incomplete' };   Finally, we\u0026#8217;ll need to define and export our action creator functions:\n src/redux/actions.js import { TOGGLE_TODO, SET_FILTER } from \"./actionTypes\"; export const toggleTodo = id =\u0026gt; ({ type: TOGGLE_TODO, id }); export const setFilter = filter =\u0026gt; ({ type: SET_FILTER, filter });     5. Reducers As we previously learned, A reducer is a pure function that takes the previous state, as well as an action, and then returns the next state. Before we can get too deep into the Reducers themselves, it would be a good idea to think about what our state will look like. Remember the state is going to be a single object. Let\u0026#8217;s think about the structure of our state object and it\u0026#8217;s key/values.\n TODO State:\n   A todos property - array a list of todo objects\n  A visibilityFilter property - string representing the current filter the user has selected\n   Each todo object will have 3 properties:\n   id - a numeric (integer) id for the todo\n  title - string indicating the the title of the todo\n  completed - boolean value indicating whether the task is complete\n   Example State { visibilityFilter: 'all', todos: [ { id: 1, title: 'Consider using Redux', completed: true, }, { id: 2, title: 'Keep all state in a single tree', completed: false } ] }   Now, we need to teach our reducers how to process the actions they will be receiving. First let\u0026#8217;s define our initial state and define a single reducer to handle all of our actions.\n Replace the code in src/redux/reducers/index.js with the following code:\n src/redux/reducers/index.js import { SET_FILTER, TOGGLE_TODO } from \"./actionTypes\"; import { VISIBILITY_FILTERS } from \"./constants\"; const initialState = { filter: VISIBILITY_FILTERS.ALL, todos: [] } const rootReducer = (state = initialState, action) =\u0026gt; { switch (action.type) { case SET_FILTER: { return { ...state, filter: action.filter } } case TOGGLE_TODO: { const todos = state.todos.map(todo =\u0026gt; todo.id === action.id ? { ...todo, completed: !todo.completed } : todo) return { ...state, todos } } default: { return state; } } } export default rootReducer;   At this point we are focusing on just 2 actions, SET_FILTER and TOGGLE_TODO.\n     When the state is initially loaded (connected / subscribed) our reducer should return an initial state of:\n{visibilityFilter: 'all', todos: []}.     Once a SET_FILTER action is dispatched describing an update to the visibilityFilter, the reducer will:\n  see the action 's payload indicating the new filter value (ALL, COMPLETED, or INCOMPLETE)\n  return a new state object with an updated visibilityFilter value.\n   5.1. Reducer Composition Taking a look at our existing code you can see that the reducer can become quite long. Just consider trying to support a dozen or more actions! Perhaps it\u0026#8217;s time to consider a bit of refactoring, specifically splitting the reducer into multiple reducers. But how should we split our reducer?\n Let\u0026#8217;s consider that our store has 2 major properties.\n   visibilityFilter\n  todos\n   So it makes sense to split the reducer into multiple reducers where each reducer is only concerned about a particular slice of the state. This pattern is known as reducer composition, and it is used extensively in Redux applications.\n 5.1.1. The visibilityFilter Reducer To start, let\u0026#8217;s create a reducer function for the visibility filter slice of the state. Our current code for the visibility filter looks like this\u0026#8230;\u0026#8203;\n before const rootReducer = (state = initialState, action) =\u0026gt; { switch (action.type) { case SET_FILTER: { return { ...state, filter: action.filter } } // ... } }   We\u0026#8217;re going to extract this and make a couple of changes. Let\u0026#8217;s create the file src/redux/reducers/visibilityFilter.js and insert the following code:\n src/redux/reducers/visibilityFilter.js import { SET_FILTER } from \"./actionTypes\"; import { VISIBILITY_FILTERS } from \"./constants\"; const initialState = VISIBILITY_FILTERS.ALL; function visibilityFilter(state = initialState, action) { switch (action.type) { case SET_FILTER: { return action.filter; } default: { return state; } } }; export default visibilityFilter;    5.1.2. The todos Reducer Todos will follow a similar pattern. In this case, the slice of state that we want to work with is the todos array. This will require some small, but important changes to the code.\n src/redux/reducers/todos.js import { TOGGLE_TODO } from \"./actionTypes\"; const initialState = [] function reducerFilter(state = initialState, action) { switch (action.type) { case TOGGLE_TODO: { return state.map(todo =\u0026gt; todo.id === action.id ? { ...todo, completed: !todo.completed } : todo) } default: return state; } } export default todosReducer;       Reducer composition allows each function to handle one slice of state and hand the updated values to a Root Reducer. The Root Reducer then returns a single object.     We still need to setup our root reducer to invoke these functions and return a single state object. We will do that next.\n   5.2. The Root Reducer The root reducer will handle calling our smaller reducer functions and composing the values. Writing our root reducer is very simple.\n src/redux/reducers/index.js import { combineReducers } from \"redux\"; import visibilityFilter from \"./visibilityFilter\"; import todos from \"./todos\"; export default combineReducers({ todos, visibilityFilter });       The Redux library provides the handy combineReducers function to help us combine multiple reducers into a single root reducer. combineReducers takes your reducer functions as arguments and returns a reducer function that invokes every function passed to it. It then constructs a state object to reflect the new state.     This type of composition and structure allows us to write composable functions each with a single responsibility of managing their own slice of the state. In larger applications this makes your code much cleaner and easier to follow.\n    6. Presentational Components At this point, we can take one of two paths\u0026#8230;\u0026#8203;.\n   Work on the container components\n  Work on the presentational components\n   For this example, we\u0026#8217;re going to create our presentational components so that we\u0026#8217;ll have visual feedback along the way. We\u0026#8217;ll step through the code in each component as we build it.\n     In order to be more concise, PropTypes are not included in this project.     6.1. Todo.js We will start with a simple Todo presentational component that will show an individual todo item and grant the ability to _click it to toggle the completed status. Note that this Todo component is only responsible for displaying the todo given to it (it has no state, no logic, and no connection to the Redux store).\n src/components/Todo.js import React from 'react' import classNames from 'classnames' const Todo = ({ todo, toggleTodo }) =\u0026gt; ( (1) \u0026lt;li className={classNames({ completed: todo.completed, })}\u0026gt; \u0026lt;div className=\"view\"\u0026gt; \u0026lt;input className=\"toggle\" type=\"checkbox\" checked={todo.completed} (2) onChange={() =\u0026gt; toggleTodo(todo.id)} (3) /\u0026gt; \u0026lt;label\u0026gt; {todo.title} (4) \u0026lt;/label\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/li\u0026gt; ) export default Todo     1 use destructuring assignment for our props   2 set the checked property on the checkbox via the todo.completed status   3 attach the toggleTodo callback to the checkbox   4 display the todo title     6.2. TodoList.js Next we will write a TodoList presentational component to map over an array of todo objects and render them using the Todo component from above.\n src/components/TodoList.js import React from 'react' import Todo from './Todo' const TodoList = ({ todos, toggleTodo }) =\u0026gt; { (1) const todosList = todos.map(todo =\u0026gt; ( (2) \u0026lt;li key={todo.id}\u0026gt; \u0026lt;Todo todo={todo} toggleTodo={toggleTodo} /\u0026gt; (3) \u0026lt;/li\u0026gt; )) return ( \u0026lt;section className=\"main\"\u0026gt; \u0026lt;ul className=\"todo-list\"\u0026gt; {todosList} \u0026lt;/ul\u0026gt; \u0026lt;/section\u0026gt; ) } export default TodoList     1 Destructure the props   2 Iterate over the todos to map them to \u0026lt;li\u0026gt;`s that contain `\u0026lt;Todo\u0026gt; components. Use todo.id as the key.   3 Pass the todo object and toggleTodo function as props     6.3. Link.js The Link component will ultimately be used to change the visibility filter. We will start with just how a link should be displayed (again no logic or connection to the store).\n src/components/Link.js import React from 'react'; const Link = ({ active, children, onClick }) =\u0026gt; { if (active) { (1) return \u0026lt;span\u0026gt;{children}\u0026lt;/span\u0026gt;; (2) } return ( \u0026lt;a href=\"#/\" onClick={e =\u0026gt; { (3) e.preventDefault(); (4) onClick(); (5) }}\u0026gt; {children} (2) \u0026lt;/a\u0026gt; ); }; export default Link;     1 use the active prop to control whether we use a \u0026lt;span\u0026gt; or an \u0026lt;a\u0026gt; element   2 children relates to React\u0026#8217;s special props.children feature (more below)   3 add an onClick handler passing the event object   4 prevent the default behavior of the link (we don\u0026#8217;t want to load a new page into the browser)   5 trigger the onClick event    6.3.1. Understanding props.children Notice that the Link component renders props.children without knowing anything about what components are in children. React always provides props.children as a way for a component to render its children in a generic way.\n According to the React Docs\n  Some components don’t know their children ahead of time\u0026#8230;\u0026#8203; We recommend that such components use the special children prop to pass children elements directly into their output\n  \u0026#8212; React Documentation     This pen by Dan Abramov showcases a simple use-case\u0026#8230;\u0026#8203;\n See the Pen ozqNOV by Dan Abramov (@gaearon) on CodePen.\n\n In the above snippet, the FancyBorder component will render props.children.\n When WelcomeDialogue invokes FancyBorder there are 2 children elements (\u0026lt;h1\u0026gt; and \u0026lt;p\u0026gt;) nested between the \u0026lt;FancyBorder\u0026gt; closing and opening tags. These elements and their content are now considered children and available through props.children\n     Another way to think about it is: \u0026lt;FancyBorder\u0026gt; I am children \u0026lt;/FancyBorder\u0026gt;     For an excellent explanation of props.children check out A quick intro to React\u0026#8217;s props.children\n   6.4. TodoCount.js The TodoCount component will display how many todos have not been completed. Here is the code for src/components/TodoCount.js:\n src/components/TodoCount.js import React from 'react'; const TodoCount = ({todoCount}) =\u0026gt;( (1) \u0026lt;span className=\"todo-count\"\u0026gt;\u0026lt;strong\u0026gt;{todoCount}\u0026lt;/strong\u0026gt; item left\u0026lt;/span\u0026gt; ) export default TodoCount;     1 This component receives the todoCount as a prop.     6.5. Footer.js The footer will ultimately provide 3 Links below our todo list. These links allow the user to toggle between different views of the todos.\n src/components/Footer.js import React from 'react'; import FilterLink from './FilterLink'; (1) import ItemCount from './ItemCount'; (1) import { VISIBILITY_FILTERS } from './constants'; const Footer = () =\u0026gt; ( \u0026lt;div className=\"footer\"\u0026gt; \u0026lt;ItemCount\u0026gt;\u0026lt;/ItemCount\u0026gt; \u0026lt;ul className=\"filters\"\u0026gt; \u0026lt;li\u0026gt;\u0026lt;FilterLink filter={VISIBILITY_FILTERS.ALL}\u0026gt;All\u0026lt;/FilterLink\u0026gt;\u0026lt;/li\u0026gt; (2) \u0026lt;li\u0026gt;\u0026lt;FilterLink filter={VISIBILITY_FILTERS.INCOMPLETE}\u0026gt;Active\u0026lt;/FilterLink\u0026gt;\u0026lt;/li\u0026gt; (2) \u0026lt;li\u0026gt;\u0026lt;FilterLink filter={VISIBILITY_FILTERS.COMPLETED}\u0026gt;Completed\u0026lt;/FilterLink\u0026gt;\u0026lt;/li\u0026gt; (2) \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; ); export default Footer;     1 Import the FilterLink and ItemCount components. Note that we have not written these components yet.   2 Render FilterLink passing the appropriate filter prop.     6.6. App.js Finally, we\u0026#8217;ll setup App.js to show our container components (we\u0026#8217;ll build those next):\n src/components/App.js import React from 'react' import { Provider } from 'react-redux' import store from \"./redux/store\"; // import AddTodo from './components/AddTodo'; import VisibleTodoList from './components/VisibleTodoList'; import Footer from './components/Footer'; import './App.css' function App() { return ( \u0026lt;Provider store={store}\u0026gt; \u0026lt;section className=\"todoapp\"\u0026gt; \u0026lt;header className=\"header\"\u0026gt; \u0026lt;h1\u0026gt;todos\u0026lt;/h1\u0026gt; {/* \u0026lt;AddTodo /\u0026gt; */} \u0026lt;/header\u0026gt; \u0026lt;VisibleTodoList /\u0026gt; \u0026lt;Footer /\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/Provider\u0026gt; ) } export default App   Above we imported the container components and render them as children of a root div.\n     We commented out the AddTodo component for now. We will come back to that later.        7. Container Components Now, we can create the container components and hook them up the the store. Before we proceed, there are a few items in the Implementing Container Components section of the Redux docs that are worth note.\n     Technically, a container component is just a React component that uses store.subscribe() to read a part of the Redux state tree and supply props to the presentational component it renders.     No magic here, our container components are the ones that subscribe to the store, requesting the piece of state it is concerned about. That component then passes the data down to it\u0026#8217;s children/presentational components as props.\n To connect our container components to the Redux store, we will be using the connect() function provided by react-redux\n From the Redux documentation:\n  Technically you could write the container components by hand using store.subscribe(). We don\u0026#8217;t advise you to do this because React Redux makes many performance optimizations that are hard to do by hand. For this reason, rather than write container components, we will generate them using the connect() function provided by React Redux\u0026#8230;\u0026#8203;\n  \u0026#8212; Redux Documentation     The connect() function will take care of generating our component (HoC style) and return a component that is subscribed to the store. The authors of Redux have gone to great length to make the connect() components as performant as possible.\n Let\u0026#8217;s take a look at some code to get a better understanding.\n 7.1. FilterLink The FilterLink component will be responsible for connecting to the Redux store, getting the\n src/components/FilterLink.js import { connect } from 'react-redux' (1) import Link from './components/Link' (2) const FilterLink = connect()(Link) (3) export default FilterLink     1 Import the connect function from react-redux   2 Import the Link component   3 Invoke the connect function, telling it to generate a container component for Link    Now, our container component is connected (subscribing) to the store.\n     Currently FilterLink doesn\u0026#8217;t do anything interesting (it doesn\u0026#8217;t use the store or dispatch an action) but we are not done yet.     7.1.1. connect() Before moving on, we need to take a look at connect(). If the syntax here: const FilterLink = connect()(Link) looks foreign, or strange, just know that you\u0026#8217;re not alone. To understand what\u0026#8217;s happening, we first need to look at the return value of connect.\n According the to react-redux documentation, The connect() function returns\u0026#8230;\u0026#8203;\n  A higher-order React component class that passes state and action creators into your component derived from the supplied arguments.\n  \u0026#8212; react-redux docs     But what does that even mean?\n     connect returns a function that is a Higher Order Component factory. This factory is able to then create a Higher-Order Component (an HOC) that wraps your component so that it will receive the proper state and actions as props.     So when you call connect you get a Higher Order Component factory. Then you pass your component as an argument to that function to get the final HOC. If you\u0026#8217;re familiar with currying, this is very similar. The entire process will generate a component that is connected / subscribed to the store.\n In this case the HOC is named FilterLink. That\u0026#8217;s a lot to think about and it will start to make more sense once we look at connecting it with the store\u0026#8217;s state via mapStateToProps and mapDispatchToProps, which we will look at next.\n  7.1.2. mapStateToProps Now that we understand a bit more about how connect works, we need to understand how it passes state (and action creators) from the store to the HOC.\n Looking at the documentation, you\u0026#8217;ll notice that connect 's function signature can take up to 4 arguments. The first is mapStateToProps, which is a special function that transforms state (from the store) into props for our presentational component. Note that:\n   mapStateToProps is called anytime the store is updated\n  the return value must be a plain object\n  the return object will be merged into the component\u0026#8217;s props\n   More about mapStateToProps can be found in arguments section of the react-redux documentation on connect.\n  7.1.3. mapDispatchToProps So, now we know how to send data from the store to our components, but how do we send our action creators? Thankfully, the connect function takes a second special argument named mapDispatchToProps that will help us out. mapDispatchToProps is a function that receives the dispatch function (as an argument) and returns functions that can be passed as props. This way we don\u0026#8217;t have to pass dispatch and action creators down manually.\n  7.1.4. FilterLink Revisited - Putting It All Together Let\u0026#8217;s determine how we can use mapStateToProps in our first container component, FilterLink:\n src/components/FilterLink.js import { connect } from 'react-redux'; import Link from './Link'; (1) import { setFilter } from './redux/actions'; (2) const mapStateToProps = (state, ownProps) =\u0026gt; { (3) return { active: ownProps.filter === state.visibilityFilter (4) }; }; const mapDispatchToProps = (dispatch, ownProps) =\u0026gt; { (5) return { onClick: () =\u0026gt; { (6) dispatch(setFilter(ownProps.filter)); (7) } }; }; const FilterLink = connect(mapStateToProps, mapDispatchToProps)(Link); export default FilterLink;     1 Import the setFilter action creator   2 Import the Link component   3 receive state and props (see below for explanation) as arguments   4 compare the props.filter value to the state.visibilityFilter value to determine if this Link is active   5 receive dispatch and props as arguments   6 onClick dispatch the setFilter action creator that will describe an intention to change the current visibilityFilter        ownProps is the second argument that can be passed to mapStateToProps and mapDispatchToProps and represents the props being passed to the container component. By convention it is named ownProps.       7.2. ItemCount.js The ItemCount component will connect to the store to get the todos, calculate the number of uncompleted todos, and render the TodoCount component passing in the todoCount as a prop via mapStateToProps:\n src/components/ItemCount.js import { connect } from 'react-redux'; import TodoCount from './TodoCount'; const mapStateToProps = (state, actions) =\u0026gt; { return { todoCount: state.todos.reduce((count, todo) =\u0026gt; (1) todo.completed ? count : count + 1, 0 ) }; }; const ItemCount = connect(mapStateToProps)(TodoCount); (2) export default ItemCount;     1 Set the todoCount prop to the number of uncompleted todos.   2 Connect to the store and wrap the TodoCount component     7.3. VisibleTodoList The point of this component is to only render the todo items associated with the current filter chosen by the user. For example, when the user clicks on the completed link, all incomplete tasks should be filtered out.\n To do this, we can write a simple function that takes in the todos array and user selected filter and return an array with the proper contents.\n Create the file src/components/VisibleTodoList.js and insert the following code:\n src/components/VisibleTodoList.js import { VISIBILITY_FILTERS } from './constants' const getVisibleTodos = (todos, filter) =\u0026gt; { (1) switch (filter) { (2) case VISIBILITY_FILTERS.COMPLETED: return todos.filter(t =\u0026gt; t.completed); (3) case VISIBILITY_FILTERS.INCOMPLETE: return todos.filter(t =\u0026gt; !t.completed); (4) case VISIBILITY_FILTERS.ALL': default: return todos; (5) } };     1 pass in todos and filter as arguments   2 write a switch statement that evaluates the filter value   3 if completed, return an array with only complete tasks   4 if active, return an array with only incomplete (active) tasks   5 otherwise return all todos    Now we can use the store\u0026#8217;s state to determine which set of todos should be passed down as props to the TodoList presentational component.\n     The getVisibleTodos function is sort of like a reducer function. But in this case we don\u0026#8217;t need to connect this function to our reducers / store because we are simply doing the calculation locally in the VisibleTodoList component and don\u0026#8217;t need to manage the list of visible todos in the store (we will just render them instead).     To make all of this work, we need to define a mapStateToProps function to get all of the todos from the store and then pass them to the getVisibleTodos function to filter them based on the store\u0026#8217;s filter value. We also need to define a mapDispatchToProps funtion for passing any callbacks as props where the callback needs to dispatch an action to the store.\n Here is our updated VisibleTodoList code:\n src/components/VisibleTodoList.js import { connect } from 'react-redux'; import TodoList from './TodoList'; import { toggleTodo } from './redux/actions'; import { VISIBILITY_FILTERS } from './constants'; const getVisibleTodos = (todos, filter) =\u0026gt; { switch (filter) { case VISIBILITY_FILTERS.COMPLETED: return todos.filter(t =\u0026gt; t.completed); case VISIBILITY_FILTERS.INCOMPLETE: return todos.filter(t =\u0026gt; !t.completed); case VISIBILITY_FILTERS.ALL: default: return todos; } }; const mapStateToProps = state =\u0026gt; ({ todos: getVisibleTodos(state.todos, state.visibilityFilter) }) const mapDispatchToProps = dispatch =\u0026gt; { return { toggleTodo: id =\u0026gt; { dispatch(toggleTodo(id)); } } }; const VisibleTodoList = connect(mapStateToProps, mapDispatchToProps)(TodoList); export default VisibleTodoList   7.3.1. The Object Shorthand Form of mapDispatchToProps There is an alternative implementation of mapDispatchToProps that is available under certain conditions. For example, the above mapDispatchToProps function can be replaced with the following single line of code:\n const mapDispatchToProps = { toggleTodo }   which is simply an object that maps prop names to actionCreators. Here we are also taking advantage of the fact that our prop names and our action creators are spelled the same. The object form of mapDispatchToProps is more generically the following:\n const mapDispatchToProps = { propCallbackA: actionCreatorA, propCallbackB: actionCreatorB }       Be aware that this shortcut is only available when the callbacks take the exact same parameters as the action creators. For more information see Two Forms of mapDispatchToProps.       7.4. Test It Out To see this in action, we can add a couple of todo items to our initial state, create the store, and take a look.\n src/reducers/todos.js const initialTodoList = [ (1) { id: 1, title: 'master redux', completed: true }, { id: 2, title: 'teach others', completed: false } ]; const todos = (state = initialTodoList, action) =\u0026gt; { (2) // ... }     1 Create an array with a couple of todo items   2 Pass our new array as the default argument    Now we have a fully connected and usable container component! When the component initially mounts and gets data from the store, all todos will be shown because the visibilityFilter is set to all.\n  7.5. AddTodo.js Lastly we need to implement a simple form for adding Todos.\n     As you may have noticed, so far we haven\u0026#8217;t put any JSX to our container components. This is because we were using them strictly as containers to wrap presentational components. The AddTodo component is slightly different. This container will contain both presentation and logic.     src/components/AddTodo.js import React from 'react'; import { connect } from 'react-redux'; import { addTodo } from './redux/actions'; const AddTodoForm = ({ dispatch }) =\u0026gt; { (1) let input; (2) function onSubmit(e) { (3) e.preventDefault(); (4) if (!input.value.trim()) { return; } dispatch(addTodo(input.value)); (5) input.value = ''; (6) } return ( \u0026lt;div\u0026gt; \u0026lt;form onSubmit={onSubmit}\u0026gt; \u0026lt;input ref={node =\u0026gt; { input = node; }} (7) className=\"new-todo\" placeholder=\"What needs to be done?\" autoFocus /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; ); }; const AddTodo = connect()(AddTodoForm); (8) export default AddTodo;     1 create a functional component passing dispatch as an argument. This allows AddTodo to make use of the dispatch function being supplied from connect.   2 declare an empty input that can track the input value   3 declare an onSubmit function for handling the form submission.   4 stop the form from submitting if empty. if there is nothing to trim, the input field is blank   5 dispatch the addTodo action creator on submit   6 reset the form input   7 use a ref to track the user input   8 connect the AddTodoForm component to the store, naming the container AddTodo        Remember to uncomment the references to AddTodo in app.js.         The above code uses an uncontrolled input for the text input. To review uncontrolled vs. controlled input components, see the lesson on Form Controls.        8. LAB: Add the Redux Code for AddTodo We just created the AddTodo form but you will need to create the following Redux support code to make it work:\n   an ActionType for ADD_TODO\n  an action creator called addTodo that takes a title and returns an action. The action should contain a type of ADD_TODO and a payload object that contains an id, title, and completed (set to false).\n  a case in the todos reducer for reducing the ADD_TODO action to the new state containing the new todo in the todos array.\n       Remember to keep your reducers pure functions. You may need to add some logic to generate ID values for your new todos. Put that logic inside the action creators instead of inside the reducers.       9. Redux DevTools Redux offers an amazing set of developer tools to gain greater insight into the flow of your application.\n While there is a tiny bit of setup required, the benefits are well worth the time.\n There are 2 flavors\n   standalone Redux DevTools\n  Browser Extension for Chrome and Firefox\n   Each has pros and cons. For this lesson, we\u0026#8217;ll be setting up the chrome devtools extension.\n To get started, we\u0026#8217;ll head over to the Chrome Web Store and specifically look for the Redux DevTools Extension\n After installing, you will have an additional tab in your chrome developer tools (usually next to the React Dev Tools). note: you may need to open up a new tab to see the dev tools\n For this application, we\u0026#8217;ll be utilizing the basic setup instructions. The Usage section of the docs, has additional setup instructions for more complex applications (ie: using custom middleware). To configure, we just need to open src/redux/store.js and change the code to the following:\n src/redux/stores.js import { createStore } from \"redux\"; import rootReducer from \"./reducers\"; const store = createStore( rootReducer, window.__REDUX_DEVTOOLS_EXTENSION__ \u0026amp;\u0026amp; window.__REDUX_DEVTOOLS_EXTENSION__() ); export default store;   What we are doing is telling the store to look at the window (global) object. If the Redux DevTools Extension is found (truthy), activate it for use. Now we have full access to the Redux Dev Tools.\n     For a deep dive into the capabilities of Redux DevTools check out the documentation, and the links found in the Additional Resources section below.       10. Lab - Setup Redux Dev Tools and Delete A Todo  Setup redux dev tools\n  Walk through each piece of the app using the Redux Dev Tools to inspect and understand the flow of data\n  Add the ability to delete a task when clicking on a delete icon. Below are the details:\n   Actions:\n   Create a new DELETE_TODO constant\n  Add a deleteTodo action creator\nhint: you\u0026#8217;ll need to pass the index as part of the payload\n  export your new constant and action creator\n   Reducers:\n   import your DELETE_TODO constant\n  Add a case to your todos reducer to operate on when the DELETE_TODO action type is present\n   You\u0026#8217;ll need to figure out a way to remove the todo item in question\nhint: remember that you cannot mutate the original todos array, use some kind of array method to generate a new array without the current todo item\n Container - VisibleTodoList:\n   import your deleteTodo action creator\n  create an additional prop that will dispatch the deleteTodo action creator\n   Presentational Components:\n   pass the callback function as a prop all the way down to the Todo component\n  In the Todo component add a button for deleting the todo. To integrate with the TodoMVC CSS styling, you can use the following code:\n   \u0026lt;button className=\"destroy\" onClick={() =\u0026gt; deleteTodo(todo.id)} /\u0026gt;     11. Summary You now have a fundamental understanding of how to use Redux in your React applications. The next steps will be learning how to properly handle side effects, work with API\u0026#8217;s, databases, localStorage etc. To persist data and integrate with the React Lifecycle. Until then, complete the lab below and check out the additional resources section.\n   12. Lab - Recap   Read A cartoon intro to Redux\n  Read react-redux connect explained\n  Read Why you might not need Redux\n  Write 3 key takeaways from articles above and submit them to your instructor for a class discussion later today\n     13. Additional Resources  Improve your development workflow with Redux DevTools\n  Time Travel in React Redux Apps\n  A quick look at the React and Redux Dev Tools\n     "
},
{
	"uri": "/react/pillars/perf-opt-strategies/use-callback/",
	"title": "React.useCallback",
	"tags": [],
	"description": "",
	"content": "Declaring callback functions can cause unnecessary renders. Use React.useCallback to avoid the unnecessary re-renders.\nMotivation  Recall that in JavaScript (and other functional programming languages) a function is just a value. Functions can be dynamically created, passed as arguments to other functions, and returned from functions. React.useCallback is essentially React.useMemo but for remembering function values instead of data values.  Question: When would we need to memoize a function value?\nAnswer:\n The most common use-case is when defining a callback function that is passed as a prop to a child component. Since callbacks are props, whenever they are recreated, it triggers the child to be re-rendered (because it has a new prop as detected by referential equality).  In general you want to use React.useCallback when:\n A functional component wrapped inside React.memo() accepts a function object prop When the function object is a dependency to other hooks, e.g. useEffect(\u0026hellip;, [callback]) When the function has some internal state, e.g. when the function is debounced or throttled.  (The above was taken from Your Guide to React.useCallback()).\nSyntax const memoizedCallback = useCallback( () =\u0026gt; { doSomething(a, b); }, [a, b], ); Example   In the above example, we have used React.memo to memoize the Button component, but each time GreetingApp is rendered, the Button component is re-rendered. This is because the thankYou callback function, which is passed as a prop to Button, is recreated with each render of GreetingApp.\nWe can fix this by wrapping the thankYou callback function with React.useMemo.\nFor a live demo of the solution, see After useCallback | Stackblitz.\nSummary  React.useCallback provides for memoization of functions. Use React.useCallback to:  keep callback functions from changing and triggering a child component from re-rendering. keep functions from changing when they are a dependency of other hooks, such as useEffect. preserve the internal state of a function (i.e. a closure).    Lab - Approximately 10 minutes  Use the React Performance Optimization Playground App for this lab. You will find a \u0026ldquo;React.useCallback\u0026rdquo; example and within that there are tabs for \u0026ldquo;Before\u0026rdquo;, \u0026ldquo;Memoized\u0026rdquo;, and \u0026ldquo;Simplified\u0026rdquo;. The code for these tabs is found in the project source code under the folder src/pages/UseCallbackEx. Currently the code in the Before folder, the Memoized folder, and the Simplified folder are identical. Make the necessary changes in the Memoized folder to memoize the inc callback. Make the necessary changes in the Simplified folder to simplify the callback so that you are passing the setCount function as a callback instead of an inc function. Test that when you interact with the parent component, the child components no longer re-render.  "
},
{
	"uri": "/golang/databases/redis-setup/",
	"title": "Redis Set Up",
	"tags": [],
	"description": "",
	"content": " If you have Homebrew installed, install Redis the following way: brew install redis Launch Redis on computer starts ln -sfv /usr/local/opt/redis/*.plist ~/Library/LaunchAgents Start Redis server via \u0026ldquo;launchctl\u0026rdquo; redis-server /usr/local/etc/redis.conf Test if Redis server is running. redis-cli ping  If it replies \u0026ldquo;PONG\u0026rdquo;, then it\u0026rsquo;s good to go!\nOther Actions  Stop Redis on autostart on computer start. launchctl unload ~/Library/LaunchAgents/homebrew.mxcl.redis.plist Location of Redis configuration file. /usr/local/etc/redis.conf Uninstall Redis and its files. brew uninstall redis rm ~/Library/LaunchAgents/homebrew.mxcl.redis.plist Get Redis package information. brew info redis  "
},
{
	"uri": "/golang/api/",
	"title": "RESTful API&#39;s",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/cyber-security/static-dynamic-analysis/3-scanning-setup/",
	"title": "Scanning Set-up and Execution",
	"tags": [],
	"description": "",
	"content": "Viper Viper is an in-house orchestration and automation tool for onboarding your applications to Fortify. It will allow us to quickly and easily request a scan for our application and share results with a team.\nBefore we review setting up the scan lets take a look at the key terms.\nViper Self Service Portal:\nUnified self-service portal to onboard all applications for both Static and Dynamic analysis.\nURL: https://viper-ui.apps-np.homedepot.com/\n  Features:\n Request a Token: Request a bearer token to submit an application for scanning. Token Lookup: Lookup an existing token for an application. Add Applications to Fortify Access List: Add users to be able to view existing scans in Fortify.  You will also find several helpful links on home page.\nViper Token:\nUnique and persistent scan token, used for both Static and Dynamic scans. This token will allow you to upload your application to Fortify via Viper. There is one token per application. You can recover a token using the Viper self service portal.\nNote that while it is currently possible to request a token for any application, you should only ever request tokens for applications you are responsible for scanning.\nViper API:\nUpload the macro, request a scan. Use curl or an API tool such as Postman. Even better, integrate into the CI pipeline.\nHow To Scan Prepare your files Collect the latest files from your repo.\nAdd any open source dependencies.\nWindows:\nRight-click the file, “Send to \u0026gt; Compressed (zipped) folder.”\nDon’t use a third-party app (e.g., 7-Zip).\nMac/Nix:\nUse\ntar -cvf replaceWithYourFileName Don’t put “.zip” in the file name.\nRequest a scan Upload the File:\nFirst we will upload the file using a post command. You can replace cURL with any tool that speaks HTTP, including Postman. We will supply the Viper token and the file we compressed on a previous step. This step prepares the file for scanning.\ncurl -k -X POST \\** https://lnc3fd5.homedepot.com:9443/upload \\  -H \u0026#39;authorization: Bearer replaceWithYourToken\u0026#39; \\  -H \u0026#39;content-type: multipart/form-data;\u0026#39; \\  -F \u0026#39;file=@C:\\Users\\jml1330\\Desktop\\replaceWithYourFileName.zip\u0026#39; Receive a Single-Use File Indicant:\nNext we will receive the file indicant we can upload for scanning.\n\u0026#34;fileIndicant\u0026#34;: \u0026#34;0573c1e2-8b1f-4ba5-a22c-72eee_yourFileName.zip\u0026#34; Request the Scan:\nFinally, we will upload the file to the Viper API for scanning. We will supply the Viper token in the header and the file indicant in the payload with the attached parameters.\ncurl -X POST \\  https://viper-static-scan-service.apps-np.homedepot.com/api/scan \\  -H \u0026#39;authorization: Bearer replaceWithYourToken\u0026#39; \\  -H \u0026#39;content-type: application/json\u0026#39; \\  -d \u0026#39;{\u0026#34;projVer\u0026#34;: \u0026#34;dev\u0026#34;, \u0026#34;language\u0026#34;: “replaceWithYourCodeLanguage\u0026#34;, \u0026#34;payloadFile\u0026#34;: \u0026#34;0573c1e2-8b1f-4ba5-a22c-72eee_yourFileName.zip\u0026#34;}\u0026#39; Automation You can automate the process with the Viper API and even integrate the process into your CI/CD Pipeline. Doing this will save you time, ensure consistency of scans, and is your due diligence to keep Home Depot\u0026rsquo;s application ecosystem secure.\nYou can use your build server of choice:\n Jenkins TeamCity Bamboo etc.  The previously provided cURL commands can be modified to be used by any program that speaks HTTP. You can create jobs to scan on a certain cadence or on demand.\nThe 10% Rule The 10% rule indicates there is a big enough difference between scans to warrant a manual review by the AppSec team. This rule will trigger a manual review of your application by AppSec under the following conditions:\n  10% change in number of files.\n  10% change in number of lines of code.\n  Notes about the manual review by AppSec:\n  May approve or e-mail you for additional context.\n  Be on the lookout for such e-mails.\n  Please reply.\n  “Requires Approval” will appear in Fortify SSC.\n  24 business hour SLA (usually much shorter.)\n  The Viper Architecture This diagram is provided only to illustrate the complexity of the Viper system extends beyond what the end users interact with. If your scan fails, you can reach out to AppSec for troubleshooting.\n  Final notes:\n Every scan is performed, even if the results await approval. Repeated scan requests amount to a “friendly fire” DoS attack on Viper, so please avoid requesting more than one scan until you have verified a failure. You can provide access to Fortify scan results via the Viper self service portal. Make sure to only add yourself or users to applications you are responsible for scanning.  "
},
{
	"uri": "/python/automation/send-emails/",
	"title": "Sending Emails",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Create emails using Python Send emails using Python the Home Depot way  Emails A common thing that takes place in the industry is to automate the sending of emails. Python is capable of helping us do this.\nAt Home Depot, it is recommended we send email via O365 Graph API instead of SMTP. This lesson will show you how to do this with an already created shared mailbox.\n. Your instructor will be giving you the necessary credentials to an existing shared email . Store these credentials as environment variables with the following keys:\n MS_APP_ID App ID given to your shared mailbox to interact with the Azure email API MS_TENANT Directory (tenant) ID given to your shared mailbox to interact with the Azure email API MS_SECRET Secret key to interact with the Azure email API that is received from the THD Azure Team MS_SENDER_EMAIL Email of the Azure email  Set Up Install all needed libraries for this lesson using this file and running:\npython3 -m venv venv # only if you have not created a virtual environment yet source venv/bin/activate pip3 install -r requirements.txt Create a new python file called: send_email.py.\nWithin send_email.py add the following imports and variables:\nimport requests import os API_VERSION = \u0026#39;v1.0\u0026#39; APP_ID = os.environ[\u0026#39;MS_APP_ID\u0026#39;] TENANT = os.environ[\u0026#39;MS_TENANT\u0026#39;] SECRET = os.environ[\u0026#39;MS_SECRET\u0026#39;] SENDER_EMAIL = os.environ[\u0026#39;MS_SENDER_EMAIL\u0026#39;] Authentication Before being able to send an email via the O365 Graph API, you need to get a temporary token. Once the token has been generated, it is possible to log in using your credentials you created.\nGenerating a token To be able to generate a token, add the following to send_email.py:\ndef get_auth_token(): AUTH_URL = \u0026#34;https://login.microsoftonline.com/{tenant}/oauth2/v2.0/token\u0026#34; # 1 payload = {\u0026#34;client_id\u0026#34;: APP_ID, \u0026#34;scope\u0026#34;: \u0026#34;https://graph.microsoft.com/.default\u0026#34;, \u0026#34;client_secret\u0026#34;: SECRET, \u0026#34;grant_type\u0026#34;: \u0026#34;client_credentials\u0026#34;} # 2 headers = {\u0026#39;content-type\u0026#39;: \u0026#39;application/x-www-form-urlencoded\u0026#39;} # 3 response = requests.post(AUTH_URL.format(tenant=TENANT, client_id=APP_ID, secret=SECRET), data=payload, headers=headers) # 4 return response.json() # 5  Get the authentication URL to POST to to get the API key Create a dictionary to hold all of the credentials Create a dictionary to update the header of the POST request to the correct type Send the POST request with the specified credentials  Send Mail Once the token has been generated and the user has been authenticated, you can now send an email.\nThe following takes in the generated token and the body of the email. This is an example of what the body could look like.\ndef send_mail(token, body): headers = {\u0026#39;Authorization\u0026#39;: f\u0026#34;{token.get(\u0026#39;token_type\u0026#39;)} {token.get(\u0026#39;access_token\u0026#39;)}\u0026#34;, \u0026#34;Content-type\u0026#34;: \u0026#34;application/json\u0026#34;} # 1 GRAPH_URL = f\u0026#34;https://graph.microsoft.com/{API_VERSION}/users/{SENDER_EMAIL}/sendMail\u0026#34; # 2 response = requests.post(GRAPH_URL, headers=headers, json=body) # 3  Set up the correct headers to POST Sets up the URL to send the mail Send the POST request to send the email  Implementation An example of implementing these functions looks like:\nif __name__ == \u0026#34;__main__\u0026#34;: token_response = get_auth_token() print(token_response) with open(\u0026#39;email_body.json\u0026#39;) as f: body = json.load(f) send_mail(token_response, body) Summary Creating emails using Python can be done in several ways. But since this lesson is created with Home Depot, we are showing the preferred, safe way of creating and sending an email.\n"
},
{
	"uri": "/javascript/performance/server-side-rendering/",
	"title": "Server-side Rendering",
	"tags": [],
	"description": "",
	"content": "What is server-side rendering? Server-side rendering is one of the earliest techniques for serving web pages, and involves building a web document before it is sent to a client. This is presented in contrast to client-side rendering, which relies on the client to render the web document.\nIn this lesson, we will dive deeper into the pros and cons of server-side rendering in the context of contemporary web development practices.\nLearning objectives  Understand the performance benefits of server-side rendering for fast First Contentful Paint (FCP) and First Meaningful Paint (FMP) Understand how rendering on a laptop is less efficient than rendering on a high- performance server Understand the limited interactivity provided by server-side rendering  Why are we talking about it? With the advent of client-side rendering, many considered server-side rendering to be out of date.\n Can you think of apps written in Java that serve HTML from a service? What is the perception of these apps amongst your team? Are they considered \u0026ldquo;legacy\u0026rdquo; technology?  However, server-side rendering has been rediscovered and refurbished due to a key weakness of client-side rendering: slow FCP and FMP.\nA super-cooled server is probably faster than your laptop Think for a moment about the distribution of work with respect to server-side rendering and client-side rendering.\nWhere is our code running when we implement server-side rendering? On the server\nWhere is our code running when we implement client-side rendering? In the browser\nWhich environment is more likely to have more computing power? The server\nFollowing this logic, it makes sense that server-side rendering results in a faster FCP and FMP. A server typically has more computing power than our laptop, thus it can build a document faster.\nRendering client-side requires extra code Have you ever bought a piece of furniture that required you to assemble it at home, rather than coming pre-assembled? If so, it likely shipped with a small set of tools that could be used to assemble the furniture.\nClient-side rendering requires us to send a set of tools to the browser that the browser can then use to build a document. In today\u0026rsquo;s modern web development ecosystem, the size of these tools can be quite large. Between 2010 and 2016, the average size of a webpage increased from 702kb to 2332kb!\nAll of that extra code needs time to be sent across the network (think about how the extra weight of the tools might slow down the delivery of furniture), time to be parsed into something that your web browser can run (think about the time it takes for you to unpack and organize the tools before building your furniture), and then finally your browser is ready to build a web document.\nNow think about the speed at which a factory can build furniture. It might be able to produce ten pieces of furniture in the time that it takes for you to assemble one. However, factories have maintenance and operational costs. The same is true for the servers that we use for server-side rendering of webpages.\nFast, but limited interactivity Think about a time when you clicked a button or link in a webpage and then the whole page flashed white for a moment before the same page was displayed, but with slightly different contents (e.g. clicking on a product link within an ecommerce site).\nServer-side rendering is quick, but it comes with one large weakness: the browser needs to send a request to the server whenever it wants to change anything.\nImagine having to send your furniture back to the factory every time a screw became slightly loose, due to the fact that you don\u0026rsquo;t own a screwdriver. This is a limitation of server-side rendering, and it is the problem that client-side rendering was intended to solve.\nServer-side rendering in the wild Though client-side rendering has generated a lot of hype, not every website needs to be client-side rendered. In fact, many popular websites still leverage server-side rendering with great success.\nSome examples:\n www.thehomedepot.com www.nytimes.com www.wikipedia.org  Just how much faster is server-side rendering than client-side rendering? Using the skills we acquired in the Gathering Metrics lesson, measure FCP and FMP for the above mentioned websites. Compare the FCP and FMP times of the server-side rendered websites with the FCP and FMP times of the client-side rendered websites from the previous lesson.\n"
},
{
	"uri": "/react/performance/server-side-rendering/",
	"title": "Server-side Rendering",
	"tags": [],
	"description": "",
	"content": "What is server-side rendering? Server-side rendering is one of the earliest techniques for serving web pages, and involves building a web document before it is sent to a client. This is presented in contrast to client-side rendering, which relies on the client to render the web document.\nIn this lesson, we will dive deeper into the pros and cons of server-side rendering in the context of contemporary web development practices.\nLearning objectives  Understand the performance benefits of server-side rendering for fast First Contentful Paint (FCP) and First Meaningful Paint (FMP) Understand how rendering on a laptop is less efficient than rendering on a high- performance server Understand the limited interactivity provided by server-side rendering  Why are we talking about it? With the advent of client-side rendering, many considered server-side rendering to be out of date.\n Can you think of apps written in Java that serve HTML from a service? What is the perception of these apps amongst your team? Are they considered \u0026ldquo;legacy\u0026rdquo; technology?  However, server-side rendering has been rediscovered and refurbished due to a key weakness of client-side rendering: slow FCP and FMP.\nA super-cooled server is probably faster than your laptop Think for a moment about the distribution of work with respect to server-side rendering and client-side rendering.\nWhere is our code running when we implement server-side rendering? On the server\nWhere is our code running when we implement client-side rendering? In the browser\nWhich environment is more likely to have more computing power? The server\nFollowing this logic, it makes sense that server-side rendering results in a faster FCP and FMP. A server typically has more computing power than our laptop, thus it can build a document faster.\nRendering client-side requires extra code Have you ever bought a piece of furniture that required you to assemble it at home, rather than coming pre-assembled? If so, it likely shipped with a small set of tools that could be used to assemble the furniture.\nClient-side rendering requires us to send a set of tools to the browser that the browser can then use to build a document. In today\u0026rsquo;s modern web development ecosystem, the size of these tools can be quite large. Between 2010 and 2016, the average size of a webpage increased from 702kb to 2332kb!\nAll of that extra code needs time to be sent across the network (think about how the extra weight of the tools might slow down the delivery of furniture), time to be parsed into something that your web browser can run (think about the time it takes for you to unpack and organize the tools before building your furniture), and then finally your browser is ready to build a web document.\nNow think about the speed at which a factory can build furniture. It might be able to produce ten pieces of furniture in the time that it takes for you to assemble one. However, factories have maintenance and operational costs. The same is true for the servers that we use for server-side rendering of webpages.\nFast, but limited interactivity Think about a time when you clicked a button or link in a webpage and then the whole page flashed white for a moment before the same page was displayed, but with slightly different contents (e.g. clicking on a product link within an ecommerce site).\nServer-side rendering is quick, but it comes with one large weakness: the browser needs to send a request to the server whenever it wants to change anything.\nImagine having to send your furniture back to the factory every time a screw became slightly loose, due to the fact that you don\u0026rsquo;t own a screwdriver. This is a limitation of server-side rendering, and it is the problem that client-side rendering was intended to solve.\nServer-side rendering in the wild Though client-side rendering has generated a lot of hype, not every website needs to be client-side rendered. In fact, many popular websites still leverage server-side rendering with great success.\nSome examples:\n www.thehomedepot.com www.nytimes.com www.wikipedia.org  Just how much faster is server-side rendering than client-side rendering? Using the skills we acquired in the Gathering Metrics lesson, measure FCP and FMP for the above mentioned websites. Compare the FCP and FMP times of the server-side rendered websites with the FCP and FMP times of the client-side rendered websites from the previous lesson.\n"
},
{
	"uri": "/software-eng-essentials/db-sql/sql-joins/",
	"title": "SQL Joins",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Learn how rows are related to other rows via foreign keys Describe the different types of joins: inner, left-outer, right-outer, and full-outer.  Skills  Write SQL queries that use joins to select related data from multiple tables. Choose between inner and outer joins to get the desired result set.  Foreign Keys and SQL Joins A foreign key is a column in one table dedicated to storing the PK value of another row (usually in another table). Thus foreign keys create a relationship between 2 rows of data.\nSQL provides a join mechanism for select ing data from multiple related rows. SQL joins are usually performed using PKs and FKs.\nExample First create a new database:\ncreatedb vet_clinic2 Sign into vet_clinic2 and create 2 tables with a relationship between them with this vet clinic\u0026rsquo;s schema file\nThis will create the following schema:\nAdd some data with this vet clinic\u0026rsquo;s seeds file\nThere are two related tables of pets and owners. To see how the data looks together, try running:\nSELECT pets.name, owners.name FROM pets, owners; Notice this gives a list of every combination of pet with every owner (in math this is called a Cartesian Product). Why does it do this?\nSince there were not any instructions given on how to relate one table with the other the system doesn\u0026rsquo;t know that so it returns every possible solution. This can return both unexpected and invalid results.\nHow do describe the relationship between the two tables in our query?\nAnswer: By leveraging our FK column.\nJOINing the above 2 tables like this:\nSELECT pets.name, owners.name FROM pets INNER JOIN owners ON pets.owner_id = owners.id; This JOIN tells tbe DMS exactly how to combine to two sets of data. Every record in one is not relevant to every record of the other, rather their relevance must be determined by the join criteria (here, where owner_id from pets matches id of owner).\nThis is why well-defined joins are crucial to query creation. A missing or malformed JOIN can lead to faulty data and often way more results than expected.\nThis can cause app failure as well as terrible performance issues. So it is important to understand exactly how one table relates to another to join properly.\nMore Examples The following are more examples using the same vet-clinic2 database created above:\nSelect all columns from pets and owners sorted by owner name, pet name\nSELECT * FROM owners INNER JOIN pets ON owners.id = pets.owner_id ORDER BY owners.name, pets.name; Output:\nid | name | phone | id | name | owner_id | age ----+---------+----------------+----+--------+----------+----- 3 | Charlie | 123-4567 | 4 | Snoopy | 3 | 7 4 | John | 1-800-432-5000 | 5 | Felix | 4 | 9 2 | Marc | 867-5309 | 3 | Deisel | 2 | 4 1 | Mike | 678-957-9556 | 2 | Meisha | 1 | 1 1 | Mike | 678-957-9556 | 1 | Miko | 1 | 2 (5 rows) Select the number of pets by owner with the name of the owner next to the count\nSELECT owners.name, COUNT(*) FROM owners INNER JOIN pets ON owners.id = pets.owner_id GROUP BY owners.name; Output:\nname | count ---------+------- Mike | 2 Marc | 1 Charlie | 1 John | 1 (4 rows) Select the average age of pets by owners\nSELECT owners.name, AVG(pets.age) FROM pets INNER JOIN owners ON pets.owner_id = owners.id GROUP BY owners.id; Output:\nname | avg ---------+-------------------- John | 9.0000000000000000 Marc | 4.0000000000000000 Mike | 1.5000000000000000 Charlie | 7.0000000000000000 (4 rows) Select the pet names for all pets over 1 year old and belonging to either Mike or Marc\nSELECT pets.name FROM pets INNER JOIN owners ON pets.owner_id = owners.id WHERE owners.name = \u0026#39;Mike\u0026#39; or owners.name = \u0026#39;Marc\u0026#39; or pets.age \u0026gt; 1 GROUP BY owners; Output:\nname -------- Miko Meisha Deisel (3 rows) Table name aliases When working with multiple tables, sometimes it starts to get tedious to write out the full name of a table. This is where aliases come in handy.\nTo create an alias for a table, use the following syntax:\ntablename alias The following is updating the select the pet names for all pets over 1 year old and belonging to either Mike or Marc with using table aliases:\nSELECT p.name FROM pets p INNER JOIN owners o ON p.owner_id = o.id WHERE o.name = \u0026#39;Mike\u0026#39; or o.name = \u0026#39;Marc\u0026#39; or p.age \u0026gt; 1 GROUP BY o; Notice that you only need to write out the full table name with the FROM keyword.\nOuter Joins JOINing tables can be done with using Inner or Outer joins. So far, only inner joins covered: the intersection of all matching rows.\nIt is possible to come up with a lot more combinations of rows using outer joins. An outer join is the union of all matching rows. Outer Joins can be LEFT, RIGHT, or FULL.\nMuch of the SQL language is based on Math and Sets, shown here: Left Outer Join Left Outer Join is often shortened to Left Join.\nEach row in a table (for example: pets) may have zero or many corresponding rows in another table (for example: owners).\nIn the vet-clinic example, this would mean not all pets have a owner. To select all data from pets no matter what and all corresponding owner data (if applicable), a LEFT JOIN would help with this.\nTo specify which table to select all data from, place that table name on the left of the keywords LEFT JOIN. (In this case, pets)\nSELECT * FROM pets LEFT JOIN owners ON pets.owner_id = owners.id; Output:\nid | name | owner_id | age | id | name | phone ----+----------+----------+-----+----+---------+---------------- 1 | Miko | 1 | 2 | 1 | Mike | 678-957-9556 2 | Meisha | 1 | 1 | 1 | Mike | 678-957-9556 3 | Deisel | 2 | 4 | 2 | Marc | 867-5309 4 | Snoopy | 3 | 7 | 3 | Charlie | 123-4567 5 | Felix | 4 | 9 | 4 | John | 1-800-432-5000 6 | Snuggles | | 2 | | | (6 rows) Notice that Snuggles simply has blank values where the owner\u0026rsquo;s information would be.\nRight Outer Join Right Outer Joins are often called Right Joins.\nRight Joins are very similar to Left Joins, with the main difference being to specify which table to select all data from, place that table name on the right of the keywords RIGHT JOIN.\nUsing the vet-clinic example, to show all owner\u0026rsquo;s info with their corresponding pet data (if applicable) do the following:\nSELECT * FROM pets RIGHT JOIN owners ON pets.owner_id = owners.id; Output:\nid | name | owner_id | age | id | name | phone ----+--------+----------+-----+----+---------+---------------- 1 | Miko | 1 | 2 | 1 | Mike | 678-957-9556 2 | Meisha | 1 | 1 | 1 | Mike | 678-957-9556 3 | Deisel | 2 | 4 | 2 | Marc | 867-5309 4 | Snoopy | 3 | 7 | 3 | Charlie | 123-4567 5 | Felix | 4 | 9 | 4 | John | 1-800-432-5000 | | | | 5 | Susan | 777-666-5555 (6 rows) Notice that Susan simply has blank values where the pet\u0026rsquo;s information would be.\nFull Outer Join Full Outer Join is often shortened to Full Join.\nA FULL JOIN can be used to select all data from 2+ tables and its corresponding data in another table (even if there is not corresponding data).\nIn the vet-clinic example, this would mean not all pets have a owner and not all owners have a pet. To select all data from pets AND owners no matter what, a FULL JOIN would help with this:\nSELECT * FROM pets FULL JOIN owners ON pets.owner_id = owners.id; The order of naming the tables either to the left or the right of the FULL JOIN will not affect the data returned, just possibly the order of the columns.\nOutput:\nid | name | owner_id | age | id | name | phone ----+----------+----------+-----+----+---------+---------------- 1 | Miko | 1 | 2 | 1 | Mike | 678-957-9556 2 | Meisha | 1 | 1 | 1 | Mike | 678-957-9556 3 | Deisel | 2 | 4 | 2 | Marc | 867-5309 4 | Snoopy | 3 | 7 | 3 | Charlie | 123-4567 5 | Felix | 4 | 9 | 4 | John | 1-800-432-5000 6 | Snuggles | | 2 | | | | | | | 5 | Susan | 777-666-5555 (7 rows) Notice that both Snuggles (who doesn\u0026rsquo;t have an owner) and Susan (who doesn\u0026rsquo;t have a pet) are listed.\nMultiple table labs If you have not already:\n Run git clone https://github.com/one-thd/om_labs_databases-and-sql.git cd into the om_labs_databases-and-sql repository  Go to the following folders and follow the instructions with the corresponding README\u0026rsquo;s:\n shopping-with-two-tables lost-and-found  Summary  Relational databases manage relationships between rows of data in multiple tables. These relationships are managed with Primary and Foreign keys. A foreign key is a column dedicated to holding the value of a PK of the related row. Using PKs and FKs we can define one-to-one, one-to-many, and many-to-many relationships. Many-to-many relationships require a mapping table to store all of the FK values. SQL provides INNER JOINS and OUTER JOINS to SELECT data from related rows.  Additional Resources  Visual Representation of SQL Joins  "
},
{
	"uri": "/javascript/performance/universal-rendering-lab/step-3/",
	"title": "Step 3: Call the API from the server to fetch data for the app",
	"tags": [],
	"description": "",
	"content": "The markets aren\u0026rsquo;t getting populated because the function componentDidMount() in src/client/components/MarketList.jsx doesn\u0026rsquo;t ever get called when our app is rendered via renderToString. This makes sense. On the server, there isn\u0026rsquo;t a document to which the component can mount, so componentDidMount() never gets called.\nTherefore, we need to move the logic from componentDidMount() into the route handler where we build the index.html response.\nSpecifically, inside componentDidMount(), we make a call to an API that returns the list of markets for our application. We need to move this API call to into our route handler and pass the data directly to our App component.\n Create a fetchMarketsAndPageInfo function in src/server/app.js to retrieve the market data. Be sure to install axios: npm install axios .  // src/server/app.js import axios from \u0026#39;axios\u0026#39;; const fetchMarketsAndPageInfo = async () =\u0026gt; { const response = await axios.get(\u0026#39;http://om-performance-workshop-proxy.apps-np.homedepot.com/location/markets?page=0\u0026#39;); const { markets } = response.data._embedded; const pageInfo = response.data.page; return { markets, pageInfo }; };  Call fetchMarketsAndPageInfo inside of our route handler and store it in a variable called data. fetchMarketsAndPageInfo is an async function, so we\u0026rsquo;ll need to make our route handler async as well.  // src/server/app.js app.get(\u0026#39;/\u0026#39;, async (req, res) =\u0026gt; { const data = await fetchMarketsAndPageInfo(); res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;${ ReactDOMServer.renderToString(\u0026lt;App /\u0026gt;) }\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); });  Pass data to our App component.  // src/server/app.js app.get(\u0026#39;/\u0026#39;, async (req, res) =\u0026gt; { const data = await fetchMarketsAndPageInfo(); res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;${ ReactDOMServer.renderToString(\u0026lt;App data={ data }/\u0026gt;) }\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); });  Within App.js, pass markets and pageInfo from data to the MarketList component.  // src/client/App.js const App = props =\u0026gt; ( \u0026lt;main\u0026gt; \u0026lt;section className=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;header-logo\u0026#34;\u0026gt; \u0026lt;i className=\u0026#34;icon_homedepot\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;header-info\u0026#34;\u0026gt; \u0026lt;label className=\u0026#34;product-info\u0026#34;\u0026gt;Store Finder!\u0026lt;/label\u0026gt; \u0026lt;label className=\u0026#34;user-info\u0026#34;\u0026gt;Lost your store? Find it here!\u0026lt;/label\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;header-search\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;header-actions\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;section className=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;MarketList markets={ props.data.markets } pageInfo={ props.data.pageInfo } /\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/main\u0026gt; );   Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and you should now see the page render with data.\n  Try clicking on the \u0026ldquo;right\u0026rdquo; arrow to load the next page of data. Does anything happen? If no, why?\n  Let\u0026rsquo;s take a closer look at the markup generated by the server.\n  In the Chrome window where we have our app displayed, open the Chrome developer tools by pressing command and shift and i at the same time.\n  Navigate to the \u0026ldquo;Network\u0026rdquo; tab.\n  With the Network tab open, reload the page.\n  A list of network requests will be shown in the left-most panel. At the very top of this list, there will be a request named \u0026ldquo;localhost\u0026rdquo;. This is the initial request made for the root document of our web application. Click on this list item to view the request in more detail.\n  In the detailed view of our request, we should see a set of tabs. Click on the \u0026ldquo;Response\u0026rdquo; tab.\n  We should now see our server-generated markup. Look closely at the contents of the element \u0026lt;div id=\u0026quot;root\u0026quot;\u0026gt;. This is where we called renderToString(\u0026lt;App /\u0026gt;) on the server. What do you notice about the elements inside \u0026lt;div id=\u0026quot;root\u0026quot;\u0026gt;?\n  \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;main data-reactroot=\u0026#34;\u0026#34;\u0026gt;...\u0026lt;/main\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; React puts a specific property on the server-generated elements that will help us in the next lab.\n"
},
{
	"uri": "/react/performance/universal-rendering-lab/step-3/",
	"title": "Step 3: Call the API from the server to fetch data for the app",
	"tags": [],
	"description": "",
	"content": "The markets aren\u0026rsquo;t getting populated because the function componentDidMount() in src/client/components/MarketList.jsx doesn\u0026rsquo;t ever get called when our app is rendered via renderToString. This makes sense. On the server, there isn\u0026rsquo;t a document to which the component can mount, so componentDidMount() never gets called.\nTherefore, we need to move the logic from componentDidMount() into the route handler where we build the index.html response.\nSpecifically, inside componentDidMount(), we make a call to an API that returns the list of markets for our application. We need to move this API call to into our route handler and pass the data directly to our App component.\n Create a fetchMarketsAndPageInfo function in src/server/app.js to retrieve the market data.  // src/server/app.js import { fetchTHDMasterData } from \u0026#39;src/server/proxy/HTTPRequests\u0026#39;; import { THD_MASTER_DATA, createFetchMarketsURLWithParams } from \u0026#39;src/constants\u0026#39;; const FIRST_PAGE_INDEX = 0; const fetchMarketsAndPageInfo = async () =\u0026gt; { const response = await fetchTHDMasterData( createFetchMarketsURLWithParams(FIRST_PAGE_INDEX, THD_MASTER_DATA.PAGE_SIZE__MARKETS) ); const markets = response._embedded.markets; const pageInfo = response.page; return { markets, pageInfo }; };  Call fetchMarketsAndPageInfo inside of our route handler and store it in a variable called data. fetchMarketsAndPageInfo is an async function, so we\u0026rsquo;ll need to make our route handler async as well.  // src/server/app.js app.get(\u0026#39;/\u0026#39;, async (req, res) =\u0026gt; { const data = await fetchMarketsAndPageInfo(); res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;${ ReactDOMServer.renderToString(\u0026lt;App /\u0026gt;) }\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); });  Pass data to our App component.  // src/server/app.js app.get(\u0026#39;/\u0026#39;, async (req, res) =\u0026gt; { const data = await fetchMarketsAndPageInfo(); res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;${ ReactDOMServer.renderToString(\u0026lt;App data={ data }/\u0026gt;) }\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); });  Within App.js, pass markets and pageInfo from data to the MarketList component.  // src/client/App.js const App = props =\u0026gt; ( \u0026lt;main\u0026gt; \u0026lt;section className=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;header-logo\u0026#34;\u0026gt; \u0026lt;i className=\u0026#34;icon_homedepot\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;header-info\u0026#34;\u0026gt; \u0026lt;label className=\u0026#34;product-info\u0026#34;\u0026gt;Store Finder!\u0026lt;/label\u0026gt; \u0026lt;label className=\u0026#34;user-info\u0026#34;\u0026gt;Lost your store? Find it here!\u0026lt;/label\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;header-search\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;header-actions\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;section className=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;MarketList markets={ props.data.markets } pageInfo={ props.data.pageInfo } /\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/main\u0026gt; );   Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and you should now see the page render with data.\n  Let\u0026rsquo;s take a closer look at the markup generated by the server.\n  In the Chrome window where we have our app displayed, open the Chrome developer tools by pressing command and shift and i at the same time.\n  Navigate to the \u0026ldquo;Network\u0026rdquo; tab.\n  With the Network tab open, reload the page.\n  A list of network requests will be shown in the left-most panel. At the very top of this list, there will be a request named \u0026ldquo;localhost\u0026rdquo;. This is the initial request made for the root document of our web application. Click on this list item to view the request in more detail.\n  In the detailed view of our request, we should see a set of tabs. Click on the \u0026ldquo;Response\u0026rdquo; tab.\n  We should now see our server-generated markup. Look closely at the contents of the element \u0026lt;div id=\u0026quot;root\u0026quot;\u0026gt;. This is where we called renderToString(\u0026lt;App /\u0026gt;) on the server. What do you notice about the elements inside \u0026lt;div id=\u0026quot;root\u0026quot;\u0026gt;?\n  \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;main data-reactroot=\u0026#34;\u0026#34;\u0026gt;...\u0026lt;/main\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; React puts a specific property on the server-generated elements that will help us in the next lab.\n"
},
{
	"uri": "/golang/testing/tdd/",
	"title": "Test Driven Development",
	"tags": [],
	"description": "",
	"content": "Goals To learn what test driven development is and where to start\nLearning Objectives  What is TDD How to Start  What is TDD Test-Driven development is an incremental way to build a feature.\nWhen you look at a wireframe, it is made up of components with functions that support component behavior.\nWhat test-driven development does is provide a repetitive pattern for developers to follow. This pattern is commonly known as Red, Green, Refactor.\n Red: Write a test that describes how the app should behave with user interaction. Green: Write the code that makes a feature work. Refactor: Update the code to improve the implementation.  This process helps developers focus on building only ONE feature at a time. Write a failing test…​.Implement the code to make the test pass…​.Refactor the implementation…​.Repeat.\nAn integrated test is one that checks the behaviors of combined components that collaborate to perform a task, or set of tasks. Now let\u0026rsquo;s take a step back and look at a bigger picture. Imagine a set of features that make up package, class, or grouping. Before we implement any feature, we would:\n Write the first integrated test Perform the TDD cycle for each feature Make the integration test pass Refactor.  Its TDD cycles, within a larger TDD cycle.\nWhere to start? One of the most common questions new engineers ask when given a wireframe, acceptance criteria or a prototype is, \u0026ldquo;Where do I begin?\u0026rdquo; And the answer is, write a failing test for a feature. You do not need to concern yourself with building the entire application.\nSteps to Begin Test Driven Development:\n  If you are given a wireframe, study it. If you have a clickable prototype, play with it. Familiarize yourself with how the app should behave.\n  Review the acceptance criteria. If you do not have acceptance criteria, create your own list by recording the actual behavior as you interact with each feature of the app.\n  Once you know how each piece of the app should behave, you can write your first failing test for one feature.\n  Conclusion Test Driven Development forces the developer to focus on satifying one feature at a time.\n"
},
{
	"uri": "/software-eng-essentials/testing/tdd/",
	"title": "Test Driven Development",
	"tags": [],
	"description": "",
	"content": "Goals To learn what test driven development is and where to start\nLearning Objectives  What is TDD How to Start  What is TDD Test-Driven development is an incremental way to build a feature.\nWhen you look at a wireframe, it is made up of components with functions that support component behavior.\nWhat test-driven development does is provide a repetitive pattern for developers to follow. This pattern is commonly known as Red, Green, Refactor.\n Red: Write a test that describes how the app should behave with user interaction. Green: Write the code that makes a feature work. Refactor: Update the code to improve the implementation.  This process helps developers focus on building only ONE feature at a time. Write a failing test…​.Implement the code to make the test pass…​.Refactor the implementation…​.Repeat.\nAn integrated test is one that checks the behaviors of combined components that collaborate to perform a task, or set of tasks. Now let\u0026rsquo;s take a step back and look at a bigger picture. Imagine a set of features that make up package, class, or grouping. Before we implement any feature, we would:\n Write the first integrated test Perform the TDD cycle for each feature Make the integration test pass Refactor.  Its TDD cycles, within a larger TDD cycle.\nWhere to start? One of the most common questions new engineers ask when given a wireframe, acceptance criteria or a prototype is, \u0026ldquo;Where do I begin?\u0026rdquo; And the answer is, write a failing test for a feature. You do not need to concern yourself with building the entire application.\nSteps to Begin Test Driven Development:\n  If you are given a wireframe, study it. If you have a clickable prototype, play with it. Familiarize yourself with how the app should behave.\n  Review the acceptance criteria. If you do not have acceptance criteria, create your own list by recording the actual behavior as you interact with each feature of the app.\n  Once you know how each piece of the app should behave, you can write your first failing test for one feature.\n  Conclusion Test Driven Development forces the developer to focus on satifying one feature at a time.\n"
},
{
	"uri": "/react/pillars/testing/",
	"title": "Testing",
	"tags": [],
	"description": "",
	"content": "Welcome to Testing with React! "
},
{
	"uri": "/react/pillars/testing/react-testing-library/rtl-forms/",
	"title": "Testing Forms",
	"tags": [],
	"description": "",
	"content": "Introduction Forms in React generally have these characteristics:\n a \u0026lt;form\u0026gt; HTML element that contains one or more \u0026lt;input\u0026gt; elements a \u0026lt;submit\u0026gt; input or button that submits the form state variables that track the state of each input element inside the form a callback to invoke when submitting the form some form validation logic - an invalid form state may mean the submit button is disabled  Our ProductForm component has all of these characteristics, so let\u0026rsquo;s get to testing them.\nTesting the ProductForm Component First let\u0026rsquo;s create the test file:\ntouch client/src/components/product-form/ProductForm.test.js Now open the file in your text editor and add the following:\nProductForm.test.js:\nimport React from \u0026#39;react\u0026#39; import \u0026#39;@testing-library/jest-dom\u0026#39; import { screen } from \u0026#39;@testing-library/dom\u0026#39; import { render } from \u0026#39;@testing-library/react\u0026#39; import ProductForm from \u0026#39;./ProductForm\u0026#39; import userEvent from \u0026#39;@testing-library/user-event\u0026#39; import dataSet from \u0026#39;./mock-utils/dataSet1\u0026#39; function getProductForm(departments, addProduct) { // get the Component under test  return \u0026lt;ProductForm departments={departments} addProduct={addProduct} /\u0026gt; } function setSelectInputValue(label, val) { // helper function for setting value on select inputs  userEvent.selectOptions(screen.getByLabelText(label), String(val)) } function setTextInputValue(label, val) { // helper function for setting value on text inputs  userEvent.type(screen.getByLabelText(label), String(val)) } describe(\u0026#39;ProductForm\u0026#39;, () =\u0026gt; { it(\u0026#39;renders without crashing\u0026#39;, () =\u0026gt; { const { container } = render( getProductForm(dataSet.departments, () =\u0026gt; {}) ) expect(container).toBeTruthy() }) it(\u0026#39;has a disabled submit button when form is not valid\u0026#39;, () =\u0026gt; { // verify that the form validation is working  const addProduct = jest.fn() render(getProductForm(dataSet.departments, addProduct)) setTextInputValue(\u0026#39;Name\u0026#39;, \u0026#39;Large Hammer\u0026#39;) // The form should be invalid here because we have not set the  // department, brand, or price which are all required fields.  const submit = screen.getByTestId(\u0026#39;submit\u0026#39;) expect(submit).toBeDisabled() }) it(\u0026#39;can add a new product\u0026#39;, () =\u0026gt; { // verify that we can fill out the form and submit it  const addProduct = jest.fn() // mock the callback function  render(getProductForm(dataSet.departments, addProduct)) const newProduct = { // the test data for our form  departmentId: 1, name: \u0026#39;16 oz. Fiberglass Handle Hammer\u0026#39;, brand: \u0026#39;HDX\u0026#39;, description: \u0026#39;The 16 oz. Claw Hammer features Perm bond construction between its head and handle for strength.\u0026#39;, price: 697, rating: 4.8 } setSelectInputValue(\u0026#39;Department\u0026#39;, newProduct.departmentId) // fill out the form with our test data  setTextInputValue(\u0026#39;Name\u0026#39;, newProduct.name) setTextInputValue(\u0026#39;Brand\u0026#39;, newProduct.brand) setTextInputValue(\u0026#39;Description\u0026#39;, newProduct.description) setTextInputValue(\u0026#39;Price\u0026#39;, newProduct.price) setTextInputValue(\u0026#39;Rating\u0026#39;, newProduct.rating) const submit = screen.getByTestId(\u0026#39;submit\u0026#39;) userEvent.click(submit) // submit the form  expect(addProduct.mock.calls.length).toBe(1) // very that the callback was invoked  expect(addProduct).toHaveBeenCalledWith({ ...newProduct }) // with the proper data  }) }) Observations  The fact that the form is controlling the inputs and managing state internally is an implementation detail that our tests don\u0026rsquo;t care about. The tests simply interact with the form the way a user would and then we inspect the data passed to our callback function.  Testing onSubmit on Forms  The above examples do not use a form with an onSubmit property as they simply use a button with an onClick handler to submit the form. If you need to test a form with onSubmit, then here is how to do it.  import React from \u0026#39;react\u0026#39; import { screen } from \u0026#39;@testing-library/dom\u0026#39; import { render, fireEvent } from \u0026#39;@testing-library/react\u0026#39; const Form = ({ onSubmit }) =\u0026gt; { // create a Form compononent to test  return ( \u0026lt;form data-testid=\u0026#34;form\u0026#34; onSubmit={onSubmit}\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Submit\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; ) } it(\u0026#39;submits\u0026#39;, () =\u0026gt; { const onSubmit = jest.fn() // mock the onSubmit callback  render(\u0026lt;Form onSubmit={onSubmit} /\u0026gt;) fireEvent.submit(screen.getByTestId(\u0026#39;form\u0026#39;)) // get the form via its data-testid prop and submit it  expect(onSubmit).toHaveBeenCalled() // expect the callback to have been called }) NOTE: We need to call submit on the form itself as firing an onClick event on the form\u0026rsquo;s submit button or attempting to submit the submit button does not work.\nSummary  React testing library and its companion libraries make testing forms very simple. All we need to do is fill out the form (via userEvent methods), submit the form, and verify that the (mocked) callback was called with the correct data.  "
},
{
	"uri": "/react/pillars/testing/tdd/test-suite-structure/",
	"title": "Testing Suite Structure",
	"tags": [],
	"description": "",
	"content": "Testing Suite Structure\n Topics 1. In this lesson you will learn: 2. How do you structure a test suite? 2.1. Test suite template:   3. How to write a React test 3.1. Accessing the DOM elements 3.2. Selector for tests: Data-attributes 3.3. Happy path testing 3.4. Sad path testing   4. Resources 4.1. Jest 4.2. Enzyme 4.3. Testing \u0026amp; App Design     1. In this lesson you will learn:   How to structure of a test suite\n  How to write a test\n     2. How do you structure a test suite?   The Happy Path: (Positive tests). As we write tests (and build features) we are walking through how we believe a user should navigate through the app. We must account for the \"happy path\", when the inputs are all valid, the proper sequence is followed as the user interacts with the app (the way we have designed it).\n  The Sad Path: (Negative tests). We also need to account for the \"sad path\" when input is NOT valid or a user clicks buttons out of the order we expect them to. When we write \"sad path\" tests, we are practicing defensive programming. According to Wikipedia, defensive coding is a form of defensive design intended to ensure the continuing function of a piece of software under unforeseen circumstances.\n   2.1. Test suite template: describe('Component you are testing', () =\u0026gt; { describe('condition 1 ', () =\u0026gt; { it('what behavior requirement are we testing', () =\u0026gt; { { set up test } expect(thing).toBe(thisValue) }) }) describe('condition 2', () =\u0026gt; { it('what behavior requirement are we testing', () =\u0026gt; { { set up test } expect(thing).toBe(thatValue) }) }) })   A breakdown of each jest function being used here:\n   describe block sets up the context for WHY we’re writing the test\n  it block specifies the piece of functionality we’re testing. it is an alias for test\n  expect with toBe creates the assertion\n      3. How to write a React test 3.1. Accessing the DOM elements     wrapper.find(selector): is the syntax used to access components on the page. Components can be built-in like a div or span or custom like \u0026lt;App /\u0026gt;.\n  find: a shallow API method called on a shallow rendered component, referred to as wrapper.\n  selector: a pointer to a node on the page. The most common selectors are CSS (#id, .className) and data-attributes.\n    3.2. Selector for tests: Data-attributes     When writing tests, one approach is the use data-attributes as selectors.\n  data-attributes give us the ability to embed custom data attributes on all HTML elements.\n  The syntax is data-* meaning you can add anything you want in place of the asterisk. For example, data-whatever-you-want.\n    3.3. Happy path testing describe('GroceryList', () =\u0026gt; { let wrapper; (1) describe('when user input is valid', () =\u0026gt; { (2) wrapper = shallow(\u0026lt;GroceryList/\u0026gt;) (3) it('grocery item displays on page after clicking submit button', () =\u0026gt; { const groceryInput = wrapper.find('[data-grocery-item]') (4) const groceryEvent = { target: { value: \"eggs\" (5) } } groceryInput.simulate('change', groceryEvent) (6) const submitButton = wrapper.find('[data-submit]') (4) submitButton.simulate('click') (7) const list = wrapper.find('[data-list]') (4) expect(list).toContain('eggs') (8) }) }) })     1 wrapper: Declare variable for the wrapper.   2 Describe block for positive path tests   3 shallow(\u0026lt;GroceryList /\u0026gt;): Create an instance of the GroceryList component.   4 groceryInput, submitButton, list: various components that exist inside the GroceryList component.   5 groceryEvent: the event object. The value represents what the user typed into the input field.   6 Simulate typing 'eggs' in the groceryInput field.   7 Simulate clicking the submitButton.   8 Assertion that 'eggs' will be added to the list.     3.4. Sad path testing describe('GroceryList', () =\u0026gt; { . . { happy path tests} . describe('when user input is invalid', () =\u0026gt; { (1) describe('button is disabled', =\u0026gt; { it('when grocery input field is empty', () =\u0026gt; { const groceryInput = wrapper.find('[data-grocery-item]') (2) const groceryEvent = { target: { value: \"\" (3) } } groceryInput.simulate('change', groceryEvent) (4) const submitButton = wrapper.find('[data-submit]') (2) submitButton.simulate('click') (5) expect(submitButton.props().disabled).toBe(true) (6) }) }) }) })     1 Describe block for negative path tests   2 groceryInput, submitButton: various components that exist inside the GroceryList component.   3 groceryEvent: the event object. The value represents what the user typed into the input field.   4 Simulate not adding any text into the groceryInput field.   5 Simulate clicking the submitButton.   6 Assertion that the submit button will be disabled.       4. Resources 4.1. Jest   Jest Expect API documentation\n    4.2. Enzyme   Enzyme documentation\n  Enzyme Shallow API documentation\n  Simulate\n    4.3. Testing \u0026amp; App Design   Rethinking Unit Test Assertions\n  Happy, Sad, Evil, Weird: Putting Use Case Planning into Practice\n      "
},
{
	"uri": "/react/pillars/hooks/useref/",
	"title": "The useRef Hook",
	"tags": [],
	"description": "",
	"content": "Concepts and Skills  Learn how useRef can hold onto mutable objects within a React component Learn how useRef is sometimes necessary when using 3rd party libraries that are not written for React  Introduction The useRef hook returns a mutable object whose .current property is initialized to the passed argument (initialValue). The returned object will persist for the full lifetime of the component.\nconst ref = useRef(initialValue); Essentially, useRef is like a “box” that can hold a mutable value in its .current property.\nThe only difference between useRef and creating a {current: \u0026hellip;} object yourself is that useRef will give you the same ref object on every render.\nCommon Use Cases Case 1: Calling DOM APIs Here is an example of setting the focus on an input element\n  Here is another example where we read the value from an input element\n  Observations:\n Once we get a reference to the DOM node we can call any DOM API methods to control it But don\u0026rsquo;t abuse this. Try to implement behavior via React state and props whenever possible  Case 2: Using a Timer   Observations:\n We need the useRef hook to mange a JavaScript interval timer. This can be helpful for doing animations or generating other events at a regular interval. We must remember to destroy any timers when the component unmounts. In this example we use the useEffect hook to return a function that destroys the timer.  Case 3: Calling a 3rd Party Library The following example was taken from Kent C. Dodds Egghead lessons on React Hooks and Suspense\n  Observations:\nOften we may need to call a 3rd party library that does DOM interactions but was not written for React. This may include animation libraries, charting and graphing libraries, or even something as advanced as D3: Data Driven Documents. The useRef hook allows us to get a reference to an object for calling into the 3rd party library.\nConclusion The useRef hook allows us to store a mutable object reference in a React component. This allows us to do things like:\n directly access DOM API methods and events manage other JavaScript runtime features such as interval timers call into 3rd party DOM libraries that were not written for React store any mutable value in a React component (similar to how you’d use instance fields in classes)  Cautions:\n useRef doesn’t notify you when its content changes mutating the .current property doesn’t cause a re-render. If you want to run some code when React attaches or detaches a ref to a DOM node, you may want to use a callback ref instead, see: useCallback.  Finally, remember to use the useRef hook sparingly. There may be a better (more React) way to solve a problem than creating a mutable object reference.\n"
},
{
	"uri": "/golang/foundations/types/",
	"title": "Types",
	"tags": [],
	"description": "",
	"content": "Go Types Learning Objectives Concepts  What is a built-in type The number types The string type Boolean types  Skills  Basic number literal arithmetic and operators Understanding String Using boolean types and operators.  Types  Types are how we identify a data type in Go. Everything can be said to be a type. Go comes with many built in types.  Numbers In go there there are two major number types:\n Integers Floating point numbers.  Integers Integers are non-decimal based numbers that can be represented using one of the following types:\n The int types can represent any positive or negative non-decimal number. The uint types can only be positive non-decimal numbers.  Sized Types:\n  int8, int16, int32, and int64\n  uint8, uint16, uint32, and uint64\n  8,16, 32, and 64 by each type represents the maximum size of the type in bits.\n  int8 has a max size of 8 bits, and uint64 has a max size of 64 bits.\n  You will most commonly see int or uint\n  32 bit processor int will be the same as int32\n  64 bit processor int will be the same as int64\n  Same applies to unit\n  Float  Floating point numbers are decimal numbers. Floating point numbers are represented by either float32 or float64  Like int, the 32 and 64 represent the bit capacity of the floating point number.\nThere are also complex64 and complex128 types that fall under floating point that we will not cover here.\nUsing Number Literals A literal is a value written as is, and not assigned to any variables.\nOperators    Operator Description     + addition   - subtraction   * multiplication   / division   % remainder/Modulus    Example of using number literals and operators\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(200 - 1 + 3 - 4) fmt.Println(-10 + 4) fmt.Println(1.2 + 1.3) fmt.Println(1.2 + 1) } Try Me\nRune and Byte Runes and Bytes are types based on other Types defined by go used for specific use-cases\n rune is equivalent to int32 byte is equivalent to uint8  Both are typically used to map to unicode characters\nStrings  Strings used to represent text. Made up of a series of (or slice) of bytes  Creating String Literals A string literal can be created by:\n surrounding the characters with double quotes \u0026quot; or \u0026ldquo;back ticks\u0026rdquo; `  Double Quotes\n Example: \u0026quot;Get Going\u0026quot; Will translate escape characters. For example \\n is translated to a newline.  Back Ticks\n Example: `Get Going` Will not translate escape characters. Handy when creating literals that contain double quotes, such as when working with JSON strings.  Concatenating Strings   The + operator can be used to concat too strings\n  Example: \u0026quot;Go on \u0026quot; + \u0026quot; with your bad self.\u0026quot;\n  Efficiency of concating with + You may want to find more efficient methods to concat when:\n Dealing with large strings Dealing with a large, frequent number of concatenations  Some methods are outlined here\nWorking with String Literals package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Part one \u0026#34; + \u0026#34;joined with \u0026#34; + \u0026#34;Part 2\u0026#34;) fmt.Println(\u0026#34;I\u0026#39;m a string Literal!\\n\u0026#34;, `So am I!`) fmt.Printf(\u0026#34;Printing A JSON String: %s \\n\u0026#34;, `{\u0026#34;color\u0026#34;:\u0026#34;red\u0026#34;}`) fmt.Printf(\u0026#34;I\u0026#39;m #%d\u0026#34;, 1) } Try Me\nBoolean Boolean values represented by either true or false.\nThe bool type can define a variable that represents either of these states.\nOperators There are five operators used with boolean values in go.\n   Operator Description     \u0026amp;\u0026amp; And   || Or   ! Not   == Equals   != Not Equals    Example:\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;this\u0026#34; == \u0026#34;that\u0026#34;) //false  fmt.Println(1 == 1) // true  fmt.Println(\u0026#34;this\u0026#34; == \u0026#34;this\u0026#34;) // true  fmt.Println(\u0026#34;this\u0026#34; != \u0026#34;that\u0026#34;) // true  fmt.Println(\u0026#34;this\u0026#34; != \u0026#34;this\u0026#34;) // false  fmt.Println(\u0026#34;this\u0026#34; == \u0026#34;this\u0026#34; \u0026amp;\u0026amp; 1 == 1) // true \tfmt.Println(\u0026#34;this\u0026#34; == \u0026#34;this\u0026#34; \u0026amp;\u0026amp; 1 == 2) // false \tfmt.Println(\u0026#34;this\u0026#34; == \u0026#34;this\u0026#34; || 1 == 2) // true  } Try Me\n"
},
{
	"uri": "/software-eng-essentials/agile-lean/user-stories/",
	"title": "User Stories",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Describe User Stories and their benefits List some benefits of User Stories Write a User Story that follows the INVEST criteria Describe Epics and Themes  Some History User stories:\n originated with Extreme Programming (XP) are now used in many Agile methodologies are an escape from the large requirements documents that were common in Waterfall projects that did \u0026ldquo;large up front design\u0026rdquo;.  What is a User Story?   Definition: A User Story is a simple description of something that a user of your product wants to achieve.\n User stories:\n are usually written from the user\u0026rsquo;s perspective describe only one feature or aspect of the product are intended to facilitate discussion between your product team, dev team, designers, and stake holders   You can think of a user story as a \u0026ldquo;placeholder for a conversation.\u0026rdquo;\n The Structure of a User Story User stories follow a common structure, such as:\n As a certain type of user I want to achieve this goal for some particular reason.\n which can be further generalized as:\n As a \u0026lt;role\u0026gt; I want to \u0026lt;achieve some goal\u0026gt;, so that I \u0026lt;receive some benefit\u0026gt;\n Examples   As a customer I would like to search for a product by title or key word so that I can find interesting products to purchase .\n  As a customer I would like to add an item to my shopping cart so that I can purchase the item at a later time   As a customer I would like to view my shopping cart so that I can see what I will be purchasing at checkout   As a customer I would like to remove an item from my shopping cart so that I will not purchase it when checking out   As a customer I would like to modify the quantity of an item in my shopping cart so that I can specify how much I want to purchase when checking out .\n  As an administrator I want to modify the list of available products so that only the available products are displayed to the customers .\n  As a finance employee I want to view analytics about orders and revenue so that I can see how we are tracking against our goals .\n  Last Responsible Moment  User stories allow a team to defer the detailed design for a requirement until the last responsible moment. The last responsible moment - the point in time closest to implementation at which we can reasonably define the requirement without putting the project at risk. Thus we can ensure that we have the most effective and accurate specification at the time of implementation.  Writing User Stories with INVEST INVEST is an acronym for writing user stories that have the following characteristics:\n Independent - stories should be (mostly) independent from one another. Negotiable - a story is not a contract, but an invitation to a conversation. Valuable - each story has to be of value to the customer. Estimable - a story should be concrete enough that developers can reasonably estimate the amount of work involved. Small - a story should be small enough to be completed in a single sprint (or for Kanban in no more than 2 weeks). Testable - a story should have a clear acceptance criteria so that it is obvious when the story is done.  Acceptance Criteria   Acceptance Criteria can be added to a user story. Mike Cohn defines acceptance criteria as \u0026ldquo;notes about what the story must do in order for the product owner to accept it as complete.\u0026rdquo; They define the boundaries of a user story and are used to confirm when a story is completed and working as intended.  The appropriate amount of information to be included in the acceptance criteria varies by team, program and project.\n Some may include prerequisite criteria, for example: \u0026ldquo;The user has already logged in and has already edited his information once\u0026rdquo;. Some may write the acceptance criteria in typical agile format, i,e, Given-When-Then. Others may simply use bullet points taken from original requirements gathered from customers or stakeholders.   In order for a story to be considered done or complete, all acceptance criteria must be met.\n User Stories, Epics, and Themes If a User Story is too large or complex it may need to be labeled as an Epic from which several user stories are developed.\nFor example:\nAs a customer I would like to manage my shopping cart so that I can determine which products to purchase.\nThis is an Epic because there are many features involved in \u0026ldquo;managing a shopping cart\u0026rdquo;, such as:\n viewing adding items removing items modifying a quantity  Since each of these aspects of managing a shopping cart is somewhat independent, it makes sense to define a user story for each.\nThemes Several Epics may be organized into themes, which are simply logical groupings of Epics.\nSome examples of themes for an ecommerce site might be:\n Customer Shopping Inventory Management Financial Analysis  User Stories in Scrum and Kanban There are slight differences to how user stories fit into Scrum and Kanban:\n For Scrum teams, user stories are usually added to a sprint (from the backlog) during the Sprint Planning meeting, and then implemented over the course of that sprint.  Also for Scrum, user stories are assigned Story Points during Sprint Planning. Story points are simply a way of assigning weights to stories that estimates how much effort each story will require. The purpose of story points is to avoid committing to too much work in a single sprint.   For Kanban teams, user stories are pulled from the backlog when there is available bandwidth to not exceed the WIP limits, and then processed through the workflow.  User Stories, the Ice Box, and the Backlog    Two artifacts of Agile are the Backlog and the Ice Box:\n Ice Box - stories that have not been groomed - i.e. they need further discussion, revision, or prioritization. Backlog - stories that are ready to be pulled into a sprint (Scrum) or pulled and worked on (Kanban). The Backlog is usually prioritized with the higher priority stories at the top. In Progress - stories that are being developed Under Review - work is complete but needs review Done - all work is complete, tested, and reviewed  Summary User stories:\n focus on what the user wants to accomplish (what brings value to the user) define requirements at the \u0026ldquo;last responsible moment\u0026rdquo; (just-in-time or JIT) so that they are relevant and accurate follow the INVEST criteria - Independent, Negotiable, Valuable, Estimable, Small, and Testable  Resources  INVEST – definition INVEST for great user stories Engineering guide to writing correct User Stories Creating Effective User Stories – Pluralsight video  "
},
{
	"uri": "/cloud/platforms/pcf-foundations/user-defined-service/",
	"title": "Using a User Defined Service",
	"tags": [],
	"description": "",
	"content": "These instructions assume that an external database has been created for you. You should be provided with the following information about the database you are to use:\nDatabase connection information\n host: the ip address of the server running the database database: the name of the database user: the user name (credentials) password: the user password  Creating the PCF Service You will need to create a PCF service with the proper environment variables for connecting to the external database.\nFirst use your browser to login to the Pivotal Apps Manager, go to the Space you are using for your app, and click on the Services tab. You should see something like this:\n Now click on the Add a Service button (do not use the hypertext link, be sure to use the big blue button). Then select the last option, User Provided Service. You should see a form that you can fill out. You can name your service instance anything you want, but you will need to use this name in your knexfile.js configuration.\nAlso add the host, database, user, and password values to your service using the Credential Parameters section of the form. Note the + button for adding additional parameters. You should end up with something similar to the following:\n If you need to make any changes to your service parameters, you can update them through the Service Configuration tab:\n Add the Production Configuration to the knexfile.js Your knexfile.js should look something like this:\nknexfile.js\nconst cfenv = require(\u0026#39;cfenv\u0026#39;); const debug = require(\u0026#39;debug\u0026#39;)(\u0026#39;express-movies\u0026#39;); // edit as needed  const appEnv = cfenv.getAppEnv(); const credentials = appEnv.getServiceCreds(\u0026#39;express-movies-db\u0026#39;); // edit as needed  module.exports = { development: { client: \u0026#39;postgresql\u0026#39;, debug: false, connection: { host: \u0026#39;127.0.0.1\u0026#39;, database: \u0026#39;express-movies-dev\u0026#39;, // edit as needed  charset: \u0026#39;utf8\u0026#39; }, pool: { min: 2, max: 10, afterCreate: (conn, done) =\u0026gt; { debug(\u0026#39;We have a connection!\u0026#39;); done(null, conn); } } }, test: { client: \u0026#39;postgresql\u0026#39;, debug: false, connection: { host: \u0026#39;127.0.0.1\u0026#39;, database: \u0026#39;express-movies-test\u0026#39;, // edit as needed  charset: \u0026#39;utf8\u0026#39; } }, production: { client: \u0026#39;postgresql\u0026#39;, connection: { host: credentials ? credentials.host : null, database: credentials ? credentials.database : null, user: credentials ? credentials.user : null, password: credentials ? credentials.password : null }, pool: { min: 2, max: 10 } } }; "
},
{
	"uri": "/software-eng-essentials/git-pillars/stash-lab/",
	"title": "Git Stash Lab",
	"tags": [],
	"description": "",
	"content": "Stashing Lab  Create a directory and call it git-stash-lab Navigate into the git-stash-lab directory Initialize this as a git repo Create three text files: test1.txt, test2.txt, and test3.txt. Add some text into each (it doesn\u0026rsquo;t really matter what.) Now stage and commit only test1.txt and test2.txt. Add some new text into test1.txt and test2.txt  This will set us up for our first stash.\nRun git stash and check your stash status. This will show the two files that were previously staged are now gone and test3.txt should still show un-staged.\nNow run git stash show to see what is in your stash object.\nUnstashing lab  Go back to your terminal where you just worked. git show shows you only have one stashed object. Using either git stash apply or git stash pop, get your stashed object back into the index. Remember each of these will replace the most recent stash into the index but only one will also clear the stash. After you\u0026rsquo;ve replaced your index run git show and then check the status.  Patch Lab  Go back to the terminal where your stash work is and add text to each of your three files. Add your changes to the index. Run your stash with the patch Take note on how many changes patch toggled through. Decide on a method to show what is in the stash object and look at the contents.  Turn to a partner and discuss why several changes may have had just one stash.\nPaired Patching  Decide on a technique to empty your stash objects. Once the stash is empty edit each of your files again. Devise a way to add the changes so that you could have more than one object for your stashes on this attempt. Redo your git stash --patch. Run your favorite command to inspect the patch objects.  Prove the Stash With a partner devise a test to prove that stash@{} calls the specified commit.\n Write out your plan with details for:  Creation of directory and files Changing files Using git to stage files Using git to stash and track which changes are which Use stash@{} as an argument to call a commit Use an argument to check what is in the stash   Find another group to trade instructions with and work through each other\u0026rsquo;s proofs  "
},
{
	"uri": "/javascript/nodejs/testing/tdd-js-lab/",
	"title": "Intro to TDD Lab",
	"tags": [],
	"description": "",
	"content": "JavaScript TDD Lab This lab will require you to write both integration tests and unit tests. Use the feature below to fist start writhing the integration tests.\nSteps\n Clone and follow the Readme instructions from the lab repository Implement the following feature:  Feature:Roman to Decimal As a football fan I want to be able to easily convert Roman numerals to Decimal So that I know what Super Bowl I am watching Scenario:Converting a valid Roman Numeral to Decimal Given A call to \u0026#34;/converter/roman/decimal/:symbols\u0026#34; When the symbols are all valid Roman numerals Then it should respond with a 200And the value as a JSON Payload Example: | symbols|expected|| IV|{\u0026#34;romanNumeral\u0026#34;:IV, decimalValue:4}|| XIX|{\u0026#34;romanNumeral\u0026#34;:XIX, decimalValue:19}|| MMVI|{\u0026#34;romanNumeral\u0026#34;:MMVI, decimalValue:2006}|| MCMXLIV|{\u0026#34;romanNumeral\u0026#34;:MCMXLIV, decimalValue:1944}|| XLIV|{\u0026#34;romanNumeral\u0026#34;:XLIV, decimalValue:44}|| XC|{\u0026#34;romanNumeral\u0026#34;:XC, decimalValue:90}| Scenario:When the Roman Numeral is not valid Given A call to \u0026#34;/converter/roman/decimal/:symbols\u0026#34; When the symbols are not all valid Roman numerals Then it should respond with a 400And the value as a JSON Payload with an error message | symbols|expected|| VX|{\u0026#34;input\u0026#34;:VX, message:\u0026#34;Invalid Roman numeral\u0026#34;}|| LM|{\u0026#34;input\u0026#34;:LM, message:\u0026#34;Invalid Roman numeral\u0026#34;}|| XCX|{\u0026#34;input\u0026#34;:XCX, message:\u0026#34;Invalid Roman numeral\u0026#34;}|| XM|{\u0026#34;input\u0026#34;:XM, message:\u0026#34;Invalid Roman numeral\u0026#34;}| Scenario:Invalid Symbols Given A call to \u0026#34;/converter/roman/decimal/:symbols\u0026#34; When the symbols are not valid Roman Numeral symbols Then it should respond with a 400And the value as a JSON Payload with an error message | symbols|expected|| x|{\u0026#34;input\u0026#34;:x, message:\u0026#34;Invalid Symbol(s)\u0026#34;}|| c|{\u0026#34;input\u0026#34;:c, message:\u0026#34;Invalid Symbol(s)\u0026#34;}|| ff|{\u0026#34;input\u0026#34;:ff, message:\u0026#34;Invalid Symbol(s)\u0026#34;}|| XLIVZ|{\u0026#34;input\u0026#34;:XLIVZ, message:\u0026#34;Invalid Symbol(s)\u0026#34;}|    Symbol Number     I 1   V 5   X 10   L 50   C 100   D 500   M 1000     Numbers are formed by combining symbols together and adding the values. Generally, symbols are placed in order of value, starting with the largest values. When smaller values precede larger values, the smaller values are subtracted from the larger values, and the result is added to the total.\n Example Output\n   Roman Number Computation Value     MMVI 1000 + 1000 + 5 + 1 2006   MCMXLIV 1000 + (1000 - 100) + (50 - 10) + (5 - 1) 1944    "
},
{
	"uri": "/react/pillars/testing/tdd/gift-list-choice/",
	"title": "Lab: Gift App, Choose your own adventure",
	"tags": [],
	"description": "",
	"content": "Gift App, Choose your own adventure\n Topics 1. Choose your own adventure lab 1.1. Level A: I got this! 1.2. Level B: I need a few hints.     1. Choose your own adventure lab 1.1. Level A: I got this!   In this lab, you will use test-driven development practices to make the acceptance tests pass. There are no hints, no code to get you started. This is designed for developers who are very comfortable with React and have a solid understanding of test-driven development practices. The instructors are here merely to help you get unstuck. Start here\n    1.2. Level B: I need a few hints.   This lab has the same acceptance criteria as Level A but offers some test structure, code samples and hints as to how to implement the required features. This is designed for developers who are familiar with React but need guidance through the test-driven development process. Start here\n       After completion of each feature, commit your code to GitHub!        "
},
{
	"uri": "/golang/databases/redis-golang/",
	"title": "Redis and Golang",
	"tags": [],
	"description": "",
	"content": "Redis and Golang Say now that we have an implementation done, you present the CRUD actions to the team and someone questions your choice in database. Have you considered a NoSQL database like Redis? Oh dear! This is going to require some extra work!\nTo help with redis setup on your machine, refer to the redis set up lesson.\ngithub.com/go-redis/redis is one of the recommended redis drivers for the Golang programming language.\nFor our purposes, run the redis-server without protected mode with the following command: redis-server --protected-mode no.\nSet Up Create a redis directory inside of the db directory. Create a set_up.go file in the newly created db/redis directory:\n. ├── db │ ├── psql │ │ ├── set_up.go │ │ └── tools.go │ └── redis │ └── set_up.go ... 4 directories, 8 files We are going to create a function that takes in a name for a database and creates a configuration string to connect to the example database.\nsslmode=disable determines the security of the connection. disable is HTTP.\nExample: To connect to an example database with the following credentials:\n Database: using default redis database Host: localhost Password: no password set  Within db/redis/set_up.go, add:\npackage redis import \u0026#34;github.com/go-redis/redis\u0026#34; func NewRedisConnection(url string) (client *redis.Client, err error) { client = redis.NewClient(\u0026amp;redis.Options{ //1 \tAddr: url, Password: \u0026#34;\u0026#34;, // no password set \tDB: 0, // use default DB \t}) err = client.Ping().Err() //2  return }  Returns a client to the Redis Server specified by Options. Implements Redis\u0026rsquo; ping command, which should receive the response pong if it is successful.  Implementation NewRedisConnection can now be used in main.go. Make sure to import the newly created redis package at the bottom of the main with:\n\u0026#34;github.homedepot.com/yourldap/tool_rental/db/redis\u0026#34; //replace with yourldap with your ldap You can comment out the code to connect to a Postgres database:\n// --------- Credentials --------- // host := os.Getenv(\u0026#34;DB_HOST\u0026#34;) //1  // .... the rest of the connection here  // defer db.Close()  // toolDataStore = psql.NewPostgresToolDataStore(db) Place the following below the newly commented line:\nurl := \u0026#34;localhost:6379\u0026#34; db, err := redis.NewRedisConnection(url) defer db.Close() if err != nil { fmt.Println(err) } Database Interaction We can use the same Tools model we created for Postgres and create Redis logic around it.\nWe know that we need a way of fetching and saving the model. Update the file structure to:\n. ├── db │ ├── psql │ │ ├── set_up.go │ │ └── tools.go │ └── redis │ ├── set_up.go │ └── tools.go ├── ... 4 directories, 10 files So we\u0026rsquo;ll define the following functions Create, FindById, FindAll, Update, and Delete in the databases/redis/tools.go file.\nBefore we do, we need to create a type to hold the specific DB connection and a constructor for the new type:\npackage redis import ( \u0026#34;github.com/go-redis/redis\u0026#34; \u0026#34;github.homedepot.com/yourldap/tool_rental/tools\u0026#34; ) type toolDataStore struct {\t//1 \tconnection *redis.Client } //NewRedisToolDataStore is a constructor for creating a new ToolDataStore instance func NewRedisToolDataStore(connection *redis.Client) toolDataStore { //2 \treturn \u0026amp;toolDataStore{ connection, } }  Creates a struct that will hold a Redis database connection and have all CRUD functions attached to it. A constructor for creating a new toolDataStore instance  Implementation NewRedisToolDataStore can now be used in main.go directly above the line toolService := tools.NewToolService(toolDataStore) in the main with:\ntoolDataStore = redis.NewRedisToolDataStore(db)  This code will not compile until all methods of the ToolDataStore interface are implemented.\n CREATE The Create method that takes in a Tool instance and places the new tool into the database for the toolDataStore struct:\nfunc (r *toolDataStore) Create(tool *tools.Tool) error { encoded, err := json.Marshal(tool) //1  if err != nil { return err } err = r.connection.HSet(\u0026#34;tools\u0026#34;, tool.ID, encoded).Err() //2 \treturn err } This is where you can see a huge benefit to the ToolService layer. We do not have to change any of the examples that we had from working with Postgres.\n This code will not compile until all methods of the ToolDataStore interface are implemented.\n Read Reading Single Record Now we can write a FindByID method that takes in a Tool ID and returns the associated tool, if it exists, for the toolDataStore struct.\nfunc (t toolDataStore) FindByID(id string) (tool *tools.Tool, err error) { b, err := t.connection.HGet(\u0026#34;tools\u0026#34;, id).Bytes() //1  if len(b) \u0026lt;= 0 {\t//2 \treturn nil, fmt.Errorf(\u0026#34;no tool matched\u0026#34;) } if err != nil { return nil, err } tool = \u0026amp;tools.Tool{}\t//3  err = json.Unmarshal(b, tool) //4  if err != nil { return tool, fmt.Errorf(\u0026#34;unmarshal: %v\u0026#34;, err) } return tool, nil }  This code will not compile until all methods of the ToolDataStore interface are implemented.\n Reading Multiple Records Now we can write a FindAll method that returns all of the rows for the toolDataStore struct.\nfunc (t toolDataStore) FindAll() (allTools []*tools.Tool, err error) { ts := t.connection.HGetAll(\u0026#34;tools\u0026#34;).Val() //1 \tfor field, value := range ts { newTool := \u0026amp;tools.Tool{} err = json.Unmarshal([]byte(value), newTool) //2  if err != nil { return nil, err } newTool.ID = field allTools = append(allTools, newTool) } return }  HGetAll takes in a key and field and returns all of the matches with a StringStringMapCmd type. Val converts an array reply to an slice of individual replies. Unmarshal the JSON-encoded data and stores the result in newTool.   This code will not compile until all methods of the ToolDataStore interface are implemented.\n Update Now we can write a Update method that takes in a Tool instance and updates the tool with the corresponding ID in the database for the toolDataStore struct.\nfunc (t toolDataStore) Update(tool *tools.Tool) (err error) { _, err = t.FindByID(tool.ID)\t//1 \tif err != nil { return fmt.Errorf(\u0026#34;FindByID: %v\u0026#34;, err) } err = t.Create(tool)\t//2  return }  Checks to see if field/value pair exists in order to update. Uses the Create method we created above. This works since Redis just replaces a field if it already exists.   This code will not compile until all methods of the ToolDataStore interface are implemented.\n Delete Now we can write a Delete method that takes in a Tool id and deletes the tool with the corresponding ID in the database for the toolDataStore struct.\nfunc (t toolDataStore) Delete(id string) (err error) { _, err = t.FindByID(id)\t//1 \tif err != nil { return fmt.Errorf(\u0026#34;FindByID: %v\u0026#34;, err) } err = t.connection.HDel(\u0026#34;tools\u0026#34;, id).Err()\t//2  return }  Checks to see if field/value pair exists in order to delete. HDel takes in a table name and a field name and returns the match with a IntCmd type that states how many rows are deleted. Err returns if an error occurred while trying to Delete.  Conclusion Now we are able to complete CRUD actions on a redis database.\n"
},
{
	"uri": "/react/pillars/testing/tdd/gift-list-level-a/",
	"title": "Lab: Gift App, Choose your own adventure: Option A",
	"tags": [],
	"description": "",
	"content": "Gift App, Choose your own adventure\n 1. In this lesson you will learn:   How to turn acceptance criteria into tests\n     2. The Acceptance criteria According to Software Testing Class, acceptance criteria are \"conditions which a software application should satisfy to be accepted by a user or customer. It mentions the defined standards that a software product must meet.\" After the app is built users perform acceptance tests to see if the criteria has been met.\n Acceptance testing is when the customer check the app to ensure that it works the way it expected. If the feature works, the acceptance test passes. If not, it fails. There is no in-between or gray area during the acceptance test process. It feature either works or it does not.\n     After completion of each feature, commit your code to GitHub!     2.1. Initial app view    User should see the app title\n  User should see an input field for the person\u0026#8217;s name\n  User should see an input field for the gift\n  User should see a disabled button by default\n    2.2. Create gift    User should be able to enter a person\u0026#8217;s name and a gift into the input fields, click submit, then see the gift added to a list below the input fields\n  User should see active add gift button when valid input exists in both text input fields\n  After the gift is added to the list, the user should see empty input fields\n  User should not be able to create a gift list item if only the person\u0026#8217;s name is input\n  User should not be able to create a gift list item if only the gift is input\n    2.3. Delete gift  User should see a delete button next to each gift\n  User should be able to click a gift\u0026#8217;s delete button causing it to be removed from the page\n    2.4. Edit gift    User should be able to click the gift list item and the data repopulates the input fields and the 'Add gift' button text changes to 'Update'.\n  User should be able to modify the content of the input fields, click 'Update', then the updated gift item is displayed on the list, in the original list position.\n    2.5. Bonus Features   Add a search functionality to find a person or gift\n  Add a sortable table from the UX Style guide\n  Add styling from the UX Style guide\n   Back to Intro to React TDD\n    "
},
{
	"uri": "/react/pillars/testing/tdd/gift-list-level-b/",
	"title": "Lab: Gift App, Choose your own adventure: Option B",
	"tags": [],
	"description": "",
	"content": "Gift App, Choose your own adventure\n 1. In this lesson you will learn:   How to turn acceptance criteria into tests\n     2. The Acceptance criteria According to Software Testing Class, acceptance criteria are \"conditions which a software application should satisfy to be accepted by a user or customer. It mentions the defined standards that a software product must meet.\" After the app is built users perform acceptance tests to see if the criteria has been met.\n Acceptance testing is when the customer check the app to ensure that it works the way it expected. If the feature works, the acceptance test passes. If not, it fails. There is no in-between or gray area during the acceptance test process. It feature either works or it does not.\n     After completion of each feature, commit your code to GitHub!     2.1. Before you get started\u0026#8230;\u0026#8203;  Level B will only create one GiftLift component. When you are done, you may refactor it into as many components as you like. Then you will get to refactor your tests! Lucky you!\n  It is HIGHLY recommended that you type each test, one at a time. It will prevent curly bracket mayhem.\n  As you are adding tests to your suite, make sure you are adding them under the correct condition. When you are finished, your test suite structure should resemble the image below.\n      2.2. Initial app view    User should see the app title\n  User should see an input field for the person\u0026#8217;s name\n  User should see an input field for the gift\n  User should see a disabled button by default\n   import React from 'react'; import { shallow } from 'enzyme'; import GiftList from './GiftList'; describe('GiftList', () =\u0026gt; { let wrapper; let nameInput; let giftInput; let submitButton; //beforeEach is designed to set the value of the variable before each test runs beforeEach(() =\u0026gt; { wrapper = shallow(\u0026lt;GiftList /\u0026gt;) nameInput = wrapper.find('[data-person]'); giftInput = wrapper.find('[data-gift]'); submitButton = wrapper.find('[data-submit]'); }); describe('on page load', () =\u0026gt; { it('displays an app title', () =\u0026gt; { //create a variable for the app title //write assertions here: //the app title exists //the app title text is... }); xit('displays input field for person', () =\u0026gt; { expect(nameInput.exists()).toEqual(true) }); xit('displays input field for gift', () =\u0026gt; { //write assertion here: //the input field for gift exists }); xit('displays disabled submit button', () =\u0026gt; { const submitButton = wrapper.find('[data-submit]'); expect(submitButton.exists()).toEqual(true) expect(submitButton.props().disabled).toBe(true); }) }); })    2.3. Create gift    User should be able to enter a person\u0026#8217;s name and a gift into the input fields, click submit, then see the gift added to a list below the input fields\n  User should see active add gift button when valid input exists in both text input fields\n  After the gift is added to the list, the user should see empty input fields\n  User should not be able to create a gift list item if only the person\u0026#8217;s name is input\n  User should not be able to create a gift list item if only the gift is input\n   2.3.1. Create gift helper functions In an effort to keep our code as DRY as possible, let\u0026#8217;s create some helper functions to simulate adding data into the input fields and clicking the submit buttons. Place these functions directly above the beforeEach() function.\n //this function is used to add a person and a gift into the input fields const addItemToInputFields= (personName, giftName) =\u0026gt; { const nameEvent = { target: { value: personName } } const giftEvent = { target: { value: giftName } } nameInput.simulate('change', nameEvent); giftInput.simulate('change', giftEvent); } //this function is used to find the submit button and click it const clickSubmit= () =\u0026gt; { submitButton = wrapper.find('[data-submit]'); submitButton.simulate('click') } // beforeEach(() =\u0026gt; { // wrapper = shallow(\u0026lt;GiftList /\u0026gt;) // nameInput = wrapper.find('[data-person]'); // giftInput = wrapper.find('[data-gift]'); // submitButton = wrapper.find('[data-submit]'); // });    2.3.2. Create gift: Happy path condition describe('when user input is valid', () =\u0026gt; { xit('adds newly created gift record to page', () =\u0026gt; { addItemToInputFields(\"Becca\", \"Google Pixel 3\"); clickSubmit(); const giftResults = wrapper.find('[data-gift-list]'); expect(giftResults.children()).toHaveLength(1); expect(giftResults.text()).toContain(\"Becca | Google Pixel 3\"); }) xit('adds multiple new gifts page', () =\u0026gt; { addItemToInputFields(\"Becca\", \"Google Pixel 3\"); clickSubmit(); addItemToInputFields(\"Louis\", \"Garmin watch\"); clickSubmit(); const giftResults = wrapper.find('[data-gift-list]'); //write assertions here: //how many nodes should be in giftResults? //what text should be displayed in giftResults }) xit('lists gifts in order as they are added to the list', () =\u0026gt; { addItemToInputFields(\"Becca\", \"Google Pixel 3\"); clickSubmit(); addItemToInputFields(\"Louis\", \"Garmin watch\"); clickSubmit(); const giftResults = wrapper.find('[data-gift-list]'); const becca = giftResults.childAt(0); const louis = giftResults.childAt(1); //write assertions here: // using jest matcher `toContain`, what text will be rendered on the page expect(becca.text()).toContain(\"Becca | Google Pixel 3\"); expect(louis.text()).toContain(\"Louis | Garmin watch\"); }) xit('input fields are empty after clicking `add gift` button', () =\u0026gt; { addItemToInputFields(\"Becca\", \"Google Pixel 3\"); clickSubmit(); //write assertions here: //the name input field's value is \"\" //the gift input field's value is \"\" }); })    2.3.3. Create gift: Sad path condition describe('when user input is invalid', () =\u0026gt; { describe('button is disabled', () =\u0026gt; { xit('on page load', () =\u0026gt; { const submitButton = wrapper.find('[data-submit]'); submitButton.simulate('click') expect(submitButton.props().disabled).toBe(true); }); xit('when name input field is empty', () =\u0026gt; { addItemToInputFields(\"\", \"Bose headphones\"); clickSubmit(); //write assertions here: //submit button is disabled }) xit('when gift input field is empty', () =\u0026gt; { addItemToInputFields(\"Michelle\", \"\"); clickSubmit(); //write assertions here: //submit button is disabled }) }) })     2.4. Delete gift  User should see a delete button next to each gift\n  User should be able to click a gift\u0026#8217;s delete button causing it to be removed from the page\n   2.4.1. Delete gift: Happy path condition describe('can delete', () =\u0026gt; { xit('displays a delete button for each list item', () =\u0026gt; { addItemToInputFields(\"Cristiano\", \"soccer ball\"); clickSubmit(); addItemToInputFields(\"Kylie\", \"basketball\"); clickSubmit(); const giftResults = wrapper.find('[data-gift-list]'); const deleteButton = wrapper.find(`[data-delete-item=${1}]`); const deleteButton2 = wrapper.find(`[data-delete-item=${2}]`); expect(deleteButton.exists()).toBe(true); expect(deleteButton2.exists()).toBe(true); }); xit('deletes gift from list when delete button is clicked', () =\u0026gt; { addItemToInputFields(\"Cristiano\", \"soccer ball\"); clickSubmit(); let giftResults = wrapper.find('[data-gift-list]'); const deleteButton = wrapper.find(`[data-delete-item=${1}]`); deleteButton.simulate('click'); giftResults = wrapper.find('[data-gift-list]'); //write assertions here: //giftResults is empty }) })     2.5. Edit gift    User should be able to click the gift list item and the data repopulates the input fields and the 'Add gift' button text changes to 'Update'.\n  User should be able to modify the content of the input fields, click 'Update', then the updated gift item is displayed on the list, in the original list position.\n   2.5.1. Edit gift: Happy path condition describe('can edit', () =\u0026gt; { xit('populates input fields with person and giftname when list item is clicked', ()=\u0026gt; { addItemToInputFields(\"Cristiano\", \"soccer ball\"); clickSubmit(); const listElement = wrapper.find(`[data-list-item=${1}]`); listElement.simulate('click'); nameInput = wrapper.find('[data-person]'); giftInput = wrapper.find('[data-gift]'); expect(nameInput.props().value).toBe(\"Cristiano\"); expect(giftInput.props().value).toBe(\"soccer ball\"); }) xit('changes the button text to `Update` and is enabled', () =\u0026gt; { addItemToInputFields(\"Cristiano\", \"soccer ball\"); clickSubmit(); const listElement = wrapper.find(`[data-list-item=${1}]`); listElement.simulate('click'); submitButton = wrapper.find('[data-submit]'); //write assertions here: //submit button is not disabled //submit button says 'Update' //submit button has a class 'edit-mode' }) xit('displays the updated item in original list position', ()=\u0026gt; { addItemToInputFields(\"Cristiano\", \"soccer ball\"); clickSubmit(); const listElement = wrapper.find(`[data-list-item=${1}]`); listElement.simulate('click'); addItemToInputFields(\"Michelle\", \"Bose headphones\"); clickSubmit(); const giftResults = wrapper.find('[data-gift-list]'); const michelle = giftResults.childAt(0); //write assertions here: // text in giftResults should no longer say Cristiano | soccer ball // text in giftResults says Michelle | Bose headphones }) })     2.6. Bonus Features   Add a search functionality to find a person or gift\n  Add a sortable table from the UX Style guide\n  Add styling from the UX Style guide\n   Back to Intro to React TDD\n    "
},
{
	"uri": "/react/pillars/testing/tdd/gift-list-routing/",
	"title": "How to Test Routing",
	"tags": [],
	"description": "",
	"content": "How to Test Routing\n Topics 1. How to Test Routing 1.1. Bonus     1. How to Test Routing Now that the basics of enzyme + jest have been covered, it’s time to start talking about more real-world functionality.\n Most single page applications have multiple components and use a router to navigate between each component. For this lab, our GiftList.js component will be able to link to other components. Let\u0026#8217;s create our first tests that describe the router and routes that we want.\n  Add test to make sure the Routes are set up so that we can eventually navigate to alternative views\n   //describe(\"can edit\", () =\u0026gt; {}) describe(\"app routing\", () =\u0026gt; { let routes; it('routes to the CarGiver component', () =\u0026gt; { routes = wrapper.find(Route); expect(routes.at(0).props().path).toEqual(\"/car-giver\") //expect(routes.at(0).props().component).toEqual(CarGiver) }) });    Run the test suite. What does the failure say? How should we fix it?\n  We are referencing Route yet we have not installed react-router-dom. Go ahead and install that package now.\n  In the GiftLift test, import { Route } from \"react-router-dom\";\n  Next, Jest is complaining that it doesn\u0026#8217;t have any routes set up. Let\u0026#8217;s implement the code to make this test pass in the GiftList component.\n   GiftList.js import { BrowserRouter as Router, Route } from \"react-router-dom\"; \u0026lt;Router\u0026gt; \u0026lt;Route path='/car-giver' component={CarGiver} /\u0026gt; \u0026lt;/Router\u0026gt;    See if you can follow Jest\u0026#8217;s error messages to make this test pass.\n  Once you get the routes to the CarGiver component test to pass, uncomment out the last assertion.\n  Once that passes, write two more tests that expect to find two more routes with companion components\u0026#8201;\u0026#8212;\u0026#8201;\n path: /vacation-giver, component: VacationGiver\n  path /pay-off-mortgage-giver, component: PayOffMortgageGiver\n      1.1. Bonus  Once you\u0026#8217;ve tests these routes, test drive the addition of NavLinks to the GiftList. Add some simple content to the new components. Remember, you may need to import Switch from react-router-dom.\n      "
},
{
	"uri": "/software-eng-essentials/db-sql/advanced-sql-joins/",
	"title": "Advanced SQL Joins",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Learn how to join more than 2 tables together using inner, left-outer, right-outer, and full-outer joins Learn how to represent a many-to-many relationship  Skills  Write SQL queries that use joins to select related data from more than 2 tables. Create joining tables to represent many-to-many relationships.  2+ Tables So far, joins have only been shown with two tables. There are many cases there is a need to join more than just two tables.\nIn order to visualize/work with multiple tables, go ahead and create a new database:\ncreatedb home_depot Sign into home_depot and create 5 tables with a relationship between them with this home_depot\u0026rsquo;s schema file\nThis will create the following schema:\n  Add some data with this home depot\u0026rsquo;s seeds file\nNotice that there are multiple foreign keys in the various tables that refer to different tables.\nIn particular, notice shipment has two foreign keys:\n trip: to refer to the store table\u0026rsquo;s column, id store: to refer to the trip table\u0026rsquo;s column, id  To get the dates of all of the of trips that left from every store's name, the shipment table would have to get involved. This can be done with two JOINs.\nSELECT s.store_name, t.trip_date FROM trip t INNER JOIN shipment sh ON t.id = sh.trip INNER JOIN store s ON s.id = sh.store; Output:\nstore_name | trip_date ----------------------------+------------ Stormy Phone Animation | 2002-04-09 Grey Squirrel Restaurant | 2002-04-09 Grey Squirrel Restaurant | 2009-09-30 Foggy Pencil Print Design | 2013-03-08 Plain Bull Running Company | 2016-07-20 Thin Rabbit Films | 2009-09-30 Plain Bull Running Company | 2013-06-04 Grey Squirrel Restaurant | 2016-07-20 Stormy Phone Animation | 2002-04-09 Grey Squirrel Restaurant | 2002-04-09 Grey Squirrel Restaurant | 2009-09-30 Foggy Pencil Print Design | 2013-03-08 Plain Bull Running Company | 2016-07-20 Thin Rabbit Films | 2009-09-30 Plain Bull Running Company | 2013-06-04 Grey Squirrel Restaurant | 2016-07-20 (16 rows) Looking back at the SQL Statement, notice there was a need for multiple INNER JOINs. One to create a connection between trip and shipment, then a second to combine that connection to store.\nConnecting 3+ tables It is possible to combine as many tables as necessary, as long as there is a foreign key creating a relationship between them.\nFor example: to list the phone numbers and locations of warehouses that did trips for Grey Squirrel Restaurant and get the trip dates, the warehouse, trip, shipment and store tables would all need to be used:\nSELECT t.trip_date, w.location, w.phone, s.store_name FROM warehouse w INNER JOIN trip t ON w.id = t.warehouse INNER JOIN shipment sh ON t.id = sh.trip INNER JOIN store s ON s.id = sh.store WHERE s.store_name = \u0026#39;Grey Squirrel Restaurant\u0026#39;; Output:\ntrip_date | location | phone | store_name ------------+----------+------------+-------------------------- 2002-04-09 | Austin | 1259669845 | Grey Squirrel Restaurant 2009-09-30 | Richmond | 1278039067 | Grey Squirrel Restaurant 2016-07-20 | Austin | 1259669845 | Grey Squirrel Restaurant (3 rows) Multiple table lab If you have not already:\n Run git clone https://github.com/one-thd/om_labs_databases-and-sql.git cd into the om_labs_databases-and-sql repository  Go to the movies folder and follow the instructions in the corresponding README.\n"
},
{
	"uri": "/react/pillars/redux/async-redux/",
	"title": "Async Redux",
	"tags": [],
	"description": "",
	"content": "Adding Async Support to Redux with redux-thunk\n Topics 1. Learning Objectives 1.1. Concepts 1.2. Skills   2. Introduction 3. Setup a JSON Server 4. Add redux-thunk and redux-logger 4.1. What is Redux Middleware? 4.2. What is a thunk? 4.3. What is redux-thunk? 4.4. What is redux-logger   5. Connect the Middleware to our Redux Store 5.1. Create an actionType and actionCreator for fetching the todos 5.2. Add Reducer logic for FETCH_TODOS   6. Lab - Add Async Actions for \"Add Todo\", \"Toggle Todo\", and \"Delete Todo\". 7. Conclusion   1. Learning Objectives 1.1. Concepts   Understand the role of asynchronous action creators\n    1.2. Skills   Add redux-thunk to a React Redux application\n  Create asynchronous action creators that use thunks to support async operations\n      2. Introduction In this lesson we want to learn how to make Redux actions trigger async operations with Redux. Surprisingly Redux does not directly support async operations, but there are several ways to add this feature to Redux using other open source libraries.\n We are going to learn how to use the redux-thunk library to add async actions to Redux. We will continue to work on the Redux Todo App from the previous lesson, React and Redux.\n But first to test it out we will need a RESTful server that our React/Redux code can use. For that, we will use json-server.\n   3. Setup a JSON Server We will be using json-server to create a very simple RESTful test server for our React TODOs app. json-server provides a RESTful API that persists data to a simple json file. It\u0026#8217;s so simple that you don\u0026#8217;t need to right a single line of code to use it. You simply:\n   install json-server\n  create a db.json.orig file with your test data (this file will be copied to db.json each time we launch our server)\n  start the server\n   First let\u0026#8217;s install json-server as a devDependency into our React TODOs project:\n yarn add -D json-server   Then add a script to package.json to start the json server:\n \"server\": \"cp -f db.json.orig db.json \u0026amp;\u0026amp; yarn json-server -w -p 4000 db.json\"   Now let\u0026#8217;s create a db.json.orig file that contains some todos:\n touch db.json.orig   And insert the following into db.json.orig:\n db.json.orig { \"todos\": [ { \"id\": 1, \"title\": \"feed the cat\", \"completed\": true }, { \"id\": 2, \"title\": \"buy milk\", \"completed\": false } ] }   Finally start the json server from the terminal:\n yarn server   and test it out with your browser by navigating to http://localhost:4000/todos. You should see some TODOs in your browser.\n   4. Add redux-thunk and redux-logger Next we will add the redux-thunk and redux-logger middleware to our project:\n yarn add redux-thunk yarn add redux-logger   4.1. What is Redux Middleware? We can use middleware to extend Redux\u0026#8217;s capabilities, thus teaching Redux new tricks. This is similar to how middleware works in the Express web server.\n  4.2. What is a thunk? In computer programming, a thunk is a function used to inject an additional calculation into another function. Thunks are primarily used to delay a calculation until its result is needed, or to insert operations at the beginning or end of the other function.\n  4.3. What is redux-thunk? With a plain basic Redux store, you can only do simple synchronous updates by dispatching an action. redux-thunk extends the store\u0026#8217;s abilities, letting you write async logic that interacts with the store.\n  4.4. What is redux-logger redux-logger will log all of our dispatched actions to the JavaScript console. What\u0026#8217;s so nice is that it also logs the store\u0026#8217;s state before and after reducing each dispatched action.\n    5. Connect the Middleware to our Redux Store To get started with redux-thunk we need to connect it to our Redux store. Edit src/redux/store.js and insert the following code:\n src/redux/store.js import { createStore, compose, applyMiddleware } from 'redux'; import thunk from 'redux-thunk'; import rootReducer from './reducers'; import { fetchTodos } from './actions'; const configureStore = () =\u0026gt; { const middlewares = [thunk]; if (process.env.NODE_ENV === 'development') { const { logger } = require('redux-logger'); middlewares.push(logger); // note that the logger middleware should go last } // create and populate the Redux store const composeEnhancers = window.__REDUX_DEVTOOLS_EXTENSION_COMPOSE__ || compose const store = composeEnhancers(applyMiddleware(...middlewares))(createStore)(rootReducer); // Give some time for the axios mock to be configured by the integration test setTimeout(() =\u0026gt; { store.dispatch(fetchTodos()); }, 50); return store; } export default configureStore;   Now that we are exporting a function from store.js we will need to make a few changes in App.js:\n src/App.js import configureStore from \"./redux/store\"; ... \u0026lt;Provider store={configureStore()}\u0026gt;   5.1. Create an actionType and actionCreator for fetching the todos In the file src/redux/actionTypes:\n src/redux/actionTypes.js export const FETCH_TODOS = 'FETCH_TODOS';   In the file src/redux/actions.js add the following code:\n src/redux/actions.js import axios from 'axios'; import { FETCH_TODOS, ADD_TODO, TOGGLE_TODO, SET_FILTER } from \"./actionTypes\"; const API = axios.create({ baseURL: 'http://localhost:4000/todos' }); const fetchTodosSuccess = todos =\u0026gt; ({ (1) type: FETCH_TODOS, todos }); export const fetchTodos = () =\u0026gt; ( (2) async dispatch =\u0026gt; { try { const response = await API.get(); dispatch(fetchTodosSuccess(response.data)); (3) return response; } catch (error) { console.error(error); } } );     1 The familiar action creator that takes some data and returns an action object.   2 An async action creator that returns a function that takes dispatch and calls it after resolving an async operation.   3 Calling dispatch with the data from the server.    Notice that to support the FETCH_TODOS action, we need two action creators. The fetchTodosSuccess action creator is familiar in that it simply returns an action object with a type and a payload of our todos array.\n What is different is the fetchTodos action creator. This one is a thunk. Instead of returning an action object, it returns a function that takes dispatch as an argument to call later. First it needs to asynchronously communicate with the server to get the todos. Then it can dispatch those todos using the fetchTodosSuccess action creator.\n Also note that we only export the fetchTodos action creator since the fetchTodosSuccess action creator is only used by this file.\n We are using axios for sending HTTP requests to the server, so we need to install it as well:\n yarn add axios   Let\u0026#8217;s restart our React app with yarn start.\n  5.2. Add Reducer logic for FETCH_TODOS Edit src/redux/reducers/todos.js and add the following code:\n src/redux/reducers/todos.js import { FETCH_TODOS, ADD_TODO, DELETE_TODO, TOGGLE_TODO } from \"./actionTypes\"; const initialState = [ { id: 1, title: 'master redux', completed: true }, { id: 2, title: 'teach others', completed: false } ] function todosReducer(state = initialState, action) { switch (action.type) { case FETCH_TODOS: { return action.todos; } case ADD_TODO: { return [...state, action.todo]; // alternatively: return state.concat(action.todo) } case DELETE_TODO: { return state.filter(todo =\u0026gt; todo.id !== action.id) } case TOGGLE_TODO: { return state.map(todo =\u0026gt; todo.id === action.id ? { ...todo, completed: !todo.completed } : todo) } default: return state; } } export default todosReducer;   Our FETCH_TODOS reducer logic simply sets the todos to the data we received in the action.todos property.\n Test it out in your browser. Also open the Chrome DevTools JavaScript Console and check out the output from redux-logger.\n    6. Lab - Add Async Actions for \"Add Todo\", \"Toggle Todo\", and \"Delete Todo\". You will need to Add async thunking for the ADD_TODO, TOGGLE_TODO, and DELETE_TODO actions. You should use HTTP POST for adding a todo, HTTP PUT for toggling a todo, and HTTP DELETE for deleting a todo, for example:\n   HTTP POST: API.post('/', todo)\n  HTTP PUT: API.put(/${todo.id}, todo)\n  HTTP DELETE: API.delete(/${todo.id})\n       You can open db.json in your editor to watch to see if the todos data is being persisted correctly.       7. Conclusion While the redux and the react-redux libraries do not have direct support for asynchronous operations, we can add this support with other \"middleware\" libraries like redux-thunk. When using redux-thunk the main concept is adding async action creators which are similar to normal action creators except that they:\n   return a function that takes dispatch as a parameter\n  call dispatch after processing an asynchronous operation and invoking another action creator\n     "
},
{
	"uri": "/cloud/containers/docker-fundamentals/container-basics/",
	"title": "Container Basics",
	"tags": [],
	"description": "",
	"content": "Objectives  Understand the difference between Images vs Containers Using Basic Docker Commands What is Docker Hub Running Containers Viewing lists of containers and images Removing containers and images  Running Containers docker create [OPTIONS] IMAGE [COMMAND] [ARG...] The docker create command creates a fresh new container from a docker image.\nExample:\n~ ○ → docker create -t -i fedora bash 6d8af538ec541dd581ebc2a24153a28329acb5268abe5ef868c1f1a261221752 docker start [OPTIONS] CONTAINER [CONTAINER...] The docker start command will start any stopped container. Thus after running docker create to create a container, you can start the container with this command.\nExample:\n~ ○ → docker start -a -i 6d8af538ec5 docker run [OPTIONS] IMAGE [COMMAND] [ARG...] The docker run command is a combination of create and start as it creates a new container and starts it immediately. If the mentioned image is not found on your system, it will search Docker Hub.\nExample:\n~ ○ → docker run --name pytest -it python Python 3.8.1 (default, Jan 3 2020, 22:44:00) [GCC 8.3.0] on linux Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; print(\u0026#39;Hello, from Python running inside a container\u0026#39;) Hello, from Python running inside a container \u0026gt;\u0026gt;\u0026gt; exit() ~ ○ → docker run --name py -it python bash root@c76057d596a0:/# exit Removing Images \u0026amp; Containers docker rmi [OPTIONS] IMAGE [IMAGE...] Removes (and un-tags) one or more images. rmi:\n only removes the specified tag from an image with multiple tags. removes the tag and image from an image with a single tag. does not remove images from a registry. must use the -f option must to remove an image of a running container  ~ ○ → docker images REPOSITORY TAG IMAGE ID CREATED SIZE test1 latest fd484f19954f 23 seconds ago 7 B (virtual 4.964 MB) test latest fd484f19954f 23 seconds ago 7 B (virtual 4.964 MB) test2 latest fd484f19954f 23 seconds ago 7 B (virtual 4.964 MB) ~ ○ → docker rmi fd484f19954f Error: Conflict, cannot delete image fd484f19954f because it is tagged in multiple repositories, use -f to force 2013/12/11 05:47:16 Error: failed to remove one or more images ~ ○ → docker rmi test1:latest Untagged: test1:latest docker rm [OPTIONS] CONTAINER [CONTAINER...] This command will remove one or more containers.\n~ ○ → docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c76057d596a0 python \u0026#34;bash\u0026#34; 2 hours ago Exited (1) 9 seconds ago py 3e307b6a36f8 python \u0026#34;python3\u0026#34; 2 hours ago Exited (0) 2 hours ago pytest d86c1bf953ec python:latest \u0026#34;python3\u0026#34; 28 hours ago Exited (0) 28 hours ago festive_haibt ~ ○ → docker rm py py ~ ○ → docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3e307b6a36f8 python \u0026#34;python3\u0026#34; 2 hours ago Exited (0) 2 hours ago pytest d86c1bf953ec python:latest \u0026#34;python3\u0026#34; 28 hours ago Exited (0) 28 hours ago festive_haibt Lab: Image Retrieval and Maintenance This activity will help familiarize you with retrieving specific images from Dockerhub.\nInstructions:\n Create an account on Docker Hub (this will come in handy later in the course) Create and name a new Docker Container using an Official Docker Image Create and name a new Docker Container using an Official Image specifying the image version with a tag Start up your new Containers List out all your Containers Stop any running Containers Delete all Containers Delete all Images  Removing all Containers, Images, and other resources TIP: You can remove all stopped containers and images on your machine with a single command:\ndocker system prune -a Summary In this lesson we:\n Introduced the core concepts of Docker, images and containers Learned how to download images, create containers from images, and start and stop containers Learned how to remove stopped containers and how to remove images.  Resources  The Docker documentation has an excellent quick start guide at Docker Overview.  "
},
{
	"uri": "/python/testing/pytest-assertions/",
	"title": "Pytest Assertions",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Showing the different Assertions that can be used with Pytest Combining parametrized test with assertions  pytest Assertions As we\u0026rsquo;ve seen, Assertions in pytest check rather a test condition returns True or False. This uses Python\u0026rsquo;s standard assert, which verifies expectation and values in Python tests. We assert the expected return. If the actual return is not equal to the asserted return, the test is considered a fail, with an AssertionError.\nWhen writing assertions, we use a combination of comparison operators, logical operators, and membership operators.\nExample: using comparison operators\ndef num(): return 4 def test_num_4(): assert num() == 4 #1 def test_num_3(): assert num() \u0026gt;= 3 #2  Asserts the the return of num() is equal to 4 Asserts the return of num() is greater than or equal to 3  Example: using a logical operator\ndef num(): return 4 def test_num_4(): assert (num() == 4 and num() \u0026gt;= 3)\t#1  Asserts the return of num() is equal to 4 and greater than or equal to 3  Example: using membership operators\ndef tool_array(): return [\u0026#34;nails\u0026#34;, \u0026#34;screws\u0026#34;, \u0026#34;saws\u0026#34;, \u0026#34;hammers\u0026#34;] def test_tool_array_screws(): assert (\u0026#34;screws\u0026#34; in tool_array()) #1 def test_tool_array_rakes(): assert (\u0026#34;rakes\u0026#34; not in tool_array())\t#2  Asserts the string \u0026quot;screws\u0026quot; is in the return of tool_array() Asserts the string \u0026quot;rakes\u0026quot; is not in the return of tool_array()  Combining assert statements - yay or nay? What happens when more than one assert statement is added to a test:\ndef num(): return 4 def test_num_4(): assert (num() == 4) assert (num() == 3) assert (num() \u0026lt; 5) The output is the following:\n================================= FAILURES ================================== ______________________________test_num_4 ____________________________________ def test_num_4(): assert (num() == 4) \u0026gt; assert (num() == 3) E assert 4 == 3 E +4 E -3 practice_pytest.py:9: AssertionError ============================= short test summary info ======================= FAILED practice_pytest.py::test_num_4 - assert 4 == 3 ============================= 1 failed in 0.12s ============================= There are three assert statements, but there is only one test. If any assert results in False, the whole test fails. This presents two problems:\n The details needed for an accurate determination of the test result are unclear. Any assertions made after the failing assertion will not be reached.  While pytest allows for more than one assert statement to be in a test, in general this is not recommended. The standard is to have one assertion per test. There are times when it is necessary to test using several conditions. For this, using the parametrized decorator with a test is best.\nParametrized Testing vs Multiple asserts As seen earlier, parametrized testing using the decorator pytest.mark.parametrize() enable the parametrization of arguments to be used in a test function.\ntest_nums = [4, 3, 5] @pytest.mark.parametrize(\u0026#34;nums\u0026#34;, test_nums) def test_num_4(nums): assert (num() == nums or num() \u0026lt; nums) ========================== test session starts ========================== ... practice_pytest.py::test_num_4[4] PASSED [ 33%] practice_pytest.py::test_num_4[3] FAILED [ 66%] practice_pytest.py::test_num_4[5] PASSED [100%] =========================== FAILURES ==================================== ___________________________ test_num_4[3] _______________________________ nums = 3 @pytest.mark.parametrize(\u0026#34;nums\u0026#34;, test_nums) def test_num_4(nums): \u0026gt; assert (num() == nums or num() \u0026lt; nums) E assert (4 == 3 E +4 E -3 or 4 \u0026lt; 3) E + where 4 = num() practice_pytest.py:9: AssertionError ====================== short test summary info =========================== FAILED practice_pytest.py::test_num_4[3] - assert (4 == 3 ====================== 1 failed, 2 passed in 0.15s ======================= We can see each test condition is completed, even if there are previous failed test conditions.\nThe test_num_4 method is tested with two different conditions in the assert. This seems rather cumbersome, especially if you wanted to add more conditions, say 10 conditions.\nConsider the tool_array() method:\ndef tool_array(): return [\u0026#34;nails\u0026#34;, \u0026#34;screws\u0026#34;, \u0026#34;saws\u0026#34;, \u0026#34;hammers\u0026#34;] We can test the tool array for multiple tools.\ntool_search =[\u0026#34;nails\u0026#34;, \u0026#34;brooms\u0026#34;, \u0026#34;saws\u0026#34;, \u0026#34;hammers\u0026#34;, \u0026#34;clippers\u0026#34;,\u0026#34;screwdrivers\u0026#34;, \u0026#34;anvils\u0026#34;, \u0026#34;drills\u0026#34;] @pytest.mark.parametrize(\u0026#34;tool\u0026#34;,tool_search) def test_tool_array(tool): assert(tool in tool_array()) Instead of 8 separate tests for one function. Parametrizing the test function helps keep the test code D.R.Y., while achieving the goal of testing multiple conditions.\nAsserting Expected Exceptions To write assertions for raised exceptions, use pytest.raises. This can be used as a context manager or to get access to the actual exception being raised.\nExample: context manager\ndef test_import_error(): with pytest.raises(ImportError): import foo Output\n====================== test session starts ====================== collected 1 item practice_pytest.py::test_import_error PASSED [100%] ====================== 1 passed in 0.01s ======================== Because ModuleNotFound is a subclass of ImportError, we can assert the expected verbiage of the error. In this case we expect that the verbiage will be No module named 'foo'.\nExample: accessing the actual exception\ndef test_import_error2(): with pytest.raises(ImportError) as e: import foo assert \u0026#34;No module\u0026#34; in str(e.value) Output\n======================= test session starts ======================= collected 1 item practice_pytest.py::test_import_error2 PASSED\t[100%] ======================== 1 passed in 0.01s ======================== Any of the built-in Python exceptions can be used with pytest.raises().\nContext-sensitive Comparison pytest supports reporting context-sensitive information when evaluating comparisons. This can be seen when asserting a comparison with the following cases:\nExample: Comparing two sets will report specifically what is different in each set\n___________________________ test_compare_data[input10-input20] _____________________________ input1 = {\u0026#39;0\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;8\u0026#39;}, input2 = {\u0026#39;0\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;8\u0026#39;} @pytest.mark.parametrize(\u0026#34;input1, input2\u0026#34;, test_inputs) def test_compare_data(input1, input2): \u0026gt; assert input1 == input2 E AssertionError: assert {\u0026#39;0\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;8\u0026#39;} == {\u0026#39;0\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;8\u0026#39;} E Extra items in the left set: E \u0026#39;1\u0026#39; E Extra items in the right set: E \u0026#39;5\u0026#39; E Full diff: E - {\u0026#39;3\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;8\u0026#39;} E + {\u0026#39;8\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;0\u0026#39;} Example: when comparing two strings, context difference is shown\n___________________________ test_compare_data[fantastic-fancy] _______________________________ input1 = \u0026#39;fantastic\u0026#39;, input2 = \u0026#39;fancy\u0026#39; @pytest.mark.parametrize(\u0026#34;input1, input2\u0026#34;, test_inputs) def test_compare_data(input1, input2): \u0026gt; assert input1 == input2 E AssertionError: assert \u0026#39;fantastic\u0026#39; == \u0026#39;fancy\u0026#39; E - fancy E + fantastic Example: when comparing two long sentences, the first failing indices are indicated by ----\n________ test_compare_data[This is the first sentence-This is not the first sentence] _________ input1 = \u0026#39;This is the first sentence\u0026#39;, input2 = \u0026#39;This is not the first sentence\u0026#39; @pytest.mark.parametrize(\u0026#34;input1, input2\u0026#34;, test_inputs) def test_compare_data(input1, input2): \u0026gt; assert input1 == input2 E AssertionError: assert \u0026#39;This is the first sentence\u0026#39; == \u0026#39;This is not ...irst sentence\u0026#39; E - This is not the first sentence E ? ---- E + This is the first sentence Example: when comparing two dictionary object, different entries are indicated with ^^^^\n_________________________ test_compare_data[input13-input23] _____________________________________ input1 = {\u0026#39;name\u0026#39;: \u0026#39;Bob\u0026#39;}, input2 = {\u0026#39;name\u0026#39;: \u0026#39;Jimmy\u0026#39;} @pytest.mark.parametrize(\u0026#34;input1, input2\u0026#34;, test_inputs) def test_compare_data(input1, input2): \u0026gt; assert input1 == input2 E AssertionError: assert {\u0026#39;name\u0026#39;: \u0026#39;Bob\u0026#39;} == {\u0026#39;name\u0026#39;: \u0026#39;Jimmy\u0026#39;} E Differing items: E {\u0026#39;name\u0026#39;: \u0026#39;Bob\u0026#39;} != {\u0026#39;name\u0026#39;: \u0026#39;Jimmy\u0026#39;} E Full diff: E - {\u0026#39;name\u0026#39;: \u0026#39;Jimmy\u0026#39;} E ? ^^^^^ E + {\u0026#39;name\u0026#39;: \u0026#39;Bob\u0026#39;} E ? ^^^ Example: For long texts comparisons, beginning indices where characters match are skipped and the result is truncated to show where the differences are. Using the -v flag will show the full differences.\n___________________________________ test_eq_long_text _____________________________________________ def test_eq_long_text(): a = \u0026#34;1\u0026#34; * 100 + \u0026#34;a\u0026#34; + \u0026#34;2\u0026#34; * 100 b = \u0026#34;1\u0026#34; * 100 + \u0026#34;b\u0026#34; + \u0026#34;2\u0026#34; * 100 \u0026gt; assert a == b E AssertionError: assert \u0026#39;111111111111...2222222222222\u0026#39; == \u0026#39;111111111111...2222222222222\u0026#39; E Skipping 90 identical leading characters in diff, use -v to show E Skipping 91 identical trailing characters in diff, use -v to show E - 1111111111b222222222 E ? ^ E + 1111111111a222222222 E ? ^ Asserting Custom Messages The assert statement allows for the option of adding a more customized message. By adding a message after the assert, the message will print when a test fails.\ndef tool_array(): return [\u0026#34;nails\u0026#34;, \u0026#34;screws\u0026#34;, \u0026#34;saws\u0026#34;, \u0026#34;hammers\u0026#34;] tool_search =[\u0026#34;nails\u0026#34;, \u0026#34;brooms\u0026#34;, \u0026#34;saws\u0026#34;, \u0026#34;hammers\u0026#34;, \u0026#34;clippers\u0026#34;,\u0026#34;screwdrivers\u0026#34;, \u0026#34;anvils\u0026#34;, \u0026#34;drills\u0026#34;] @pytest.mark.parametrize(\u0026#34;tool\u0026#34;,tool_search) def test_array(tool): assert (tool in tool_array()), f\u0026#34;The tool {tool} was not found\u0026#34; #1  Output\n================================== test session starts ================================================= ... practice_pytest.py::test_array[nails] PASSED [ 12%] practice_pytest.py::test_array[brooms] FAILED [ 25%] practice_pytest.py::test_array[saws] PASSED [ 37%] practice_pytest.py::test_array[hammers] PASSED [ 50%] practice_pytest.py::test_array[clippers] FAILED [ 62%] practice_pytest.py::test_array[screwdrivers] FAILED [ 75%] practice_pytest.py::test_array[anvils] FAILED [ 87%] practice_pytest.py::test_array[drills] FAILED [100%] ... ... ... ===================================== short test summary info ============================================ FAILED practice_pytest.py::test_array[brooms] - AssertionError: The tool brooms was not found FAILED practice_pytest.py::test_array[clippers] - AssertionError: The tool clippers was not found FAILED practice_pytest.py::test_array[screwdrivers] - AssertionError: The tool screwdrivers was not found FAILED practice_pytest.py::test_array[anvils] - AssertionError: The tool anvils was not found FAILED practice_pytest.py::test_array[drills] - AssertionError: The tool drills was not found ================================== 5 failed, 3 passed in 0.17s =========================================== After each failure, you can see the custom fail message printed out.\nSummary PyTest Assertions allow for the simple or complex testing of methods. Built off the standard Python assert statement, Pytest assert helps developers construct straight-forward test that are easy to read, with the option of custom messaging. As a standard, each test will have only one (1) assert statement to allow for complete and accurate reporting of failures.\nLab Clone down the repo for the Testing Python lab with the following instructions:\ngit clone https://github.homedepot.com/om-labs/python-testing.git cd python-testing/pytest-assertions Follow the instructions in the README.\n"
},
{
	"uri": "/software-eng-essentials/agile-lean/",
	"title": "Agile Foundations",
	"tags": [],
	"description": "",
	"content": "Welcome to Agile Foundations! "
},
{
	"uri": "/golang/testing/bdd/",
	"title": "Behavior Driven Development",
	"tags": [],
	"description": "",
	"content": "Goals Gain an understanding of what Behavior Driven Development is and how it could be accomplished.\nLearning Objectives  What is BDD? The standard format of BDD Can you do BDD and TDD? Yes. BDD Libraries  Behavior Driven Development Behavior Driven Development (BDD) is a development approach that focuses on the behavior of the code rather than a specific implementation.\nBecause BDD tends to follow the Gherkin style, which is also used often in user stories, BDD tests can be written based off the user story.\nTests are often written with the following thought process:\nGiven a specific context When an action is taken Then this is the expected result Given 2and 2as input to Add When the function is invoked Then it should return 4A simplified format is often used in unit testing when describing the behavior of a function.\n#addTwoNumbers context: when 2 and 2 are passed as input it should return 4 BDD removes any consideration of the implementation details from unit tests.\nPoor unit tests cause issues when updating the function. If it is updated, even without changing the inputs and outputs, the tests must be updated.\nBDD addresses this problem by showing you how to test. You should not test implementation but instead behavior. Thus BDD is a form of black box testing.\nBDD and TDD Behavior Driven Development and Test Driven Development are not mutually exclusive. While BDD tells us how to test, TDD tells us when to write the test (first). See more in the TDD lesson.\nBDD Libraries You do not need any specific framework or library to use a BDD approach to testing, however, there are many out there for various languages:\nJavaScript:\n Jest Mocha/Chai Jasmine  Go:\n Ginkgo/Gomega  Java:\n Cucumber* Hamcrest   Cucumber actually has frameworks for many other languages including javascript.\n More on BDD\n"
},
{
	"uri": "/software-eng-essentials/testing/bdd/",
	"title": "Behavior Driven Development",
	"tags": [],
	"description": "",
	"content": "Goals Gain an understanding of what Behavior Driven Development is and how it could be accomplished.\nLearning Objectives  What is BDD? The standard format of BDD Can you do BDD and TDD? Yes. BDD Libraries  Behavior Driven Development Behavior Driven Development (BDD) is a development approach that focuses on the behavior of the code rather than a specific implementation.\nBecause BDD tends to follow the Gherkin style, which is also used often in user stories, BDD tests can be written based off the user story.\nTests are often written with the following thought process:\nGiven a specific context When an action is taken Then this is the expected result Given 2and 2as input to Add When the function is invoked Then it should return 4A simplified format is often used in unit testing when describing the behavior of a function.\n#addTwoNumbers context: when 2 and 2 are passed as input it should return 4 BDD removes any consideration of the implementation details from unit tests.\nPoor unit tests cause issues when updating the function. If it is updated, even without changing the inputs and outputs, the tests must be updated.\nBDD addresses this problem by showing you how to test. You should not test implementation but instead behavior. Thus BDD is a form of black box testing.\nBDD and TDD Behavior Driven Development and Test Driven Development are not mutually exclusive. While BDD tells us how to test, TDD tells us when to write the test (first). See more in the TDD lesson.\nBDD Libraries You do not need any specific framework or library to use a BDD approach to testing, however, there are many out there for various languages:\nJavaScript:\n Jest Mocha/Chai Jasmine  Go:\n Ginkgo/Gomega  Java:\n Cucumber* Hamcrest   Cucumber actually has frameworks for many other languages including javascript.\n More on BDD\n"
},
{
	"uri": "/golang/concurrency/benchmarking/",
	"title": "Benchmarking",
	"tags": [],
	"description": "",
	"content": "When we are using concurrency, we probably want to know just how much of an efficiency benefit we\u0026rsquo;re gaining from it. We may also need to use benchmarking in order to fine tune goroutines, or what size batches are the most performant.\n Note: Do not prematurely optimize!\n We prefix benchmark tests with the word Benchmark\nfunc BenchmarkCalculate(b *testing.B){ ... Ran with: go test -bench=.\nPermutations Example To show how benchmarking can help, we are going to create a non-concurrent and concurrent solution for summing up numbers 0 through max. (max with be a parameter of both functions)\nNon-concurrent Example The following is the permutation function that does not use concurrency:\nfunc PermExampleNoConc(max int) (sum int){ for _, value := range rand.Perm(max) { sum += value time.Sleep(20 * time.Millisecond) } return } Let\u0026rsquo;s create a benchmark test for it.\nfunc BenchmarkPermExampleNoConc(b *testing.B){ for i := 0; i \u0026lt; b.N; i++ { benchmarking.PermExampleNoConc(10) } } Notice we needed to run the test over and over for as many times as the testing package requires.\nWhy do you think this is?\nThe test will run again and again until the testing package can get a reliable reading, and provides that steady number.\nHere\u0026rsquo;s our result:\nBenchmarkPermExampleNoConc-8 5 212508093 ns/op  The -8 means we ran with 8 cores. 5 means that the test was run 5 times. 212508093 ns/op means that our steady run number is about: 212 milliseconds.  Concurrent Example We are slowly going to build up the concurrent example to help show/solve a \u0026ldquo;gotcha\u0026rdquo; with concurrency!\nDo you see the problem with the following?\nfor _, i := range rand.Perm(5) { go fmt.Println(i) fmt.Println(\u0026#34;.\u0026#34;) } In this case, there\u0026rsquo;s a good chance none of the i's will print before the function ends.\nTo help with this problem, we could put a WaitGroup around this.\nvar wg sync.WaitGroup for _, i := range rand.Perm(5) { wg.Add(1) go func(){ fmt.Println(i) wg.Done() }() fmt.Println(\u0026#34;.\u0026#34;) } wg.Wait() Will they print out in order now?\nNope!\nHere is one possible output:\n. . . . . 1 5 5 4 5 By the time the anonymous goroutine is running the value of i could have changed.\nSO\u0026hellip; How do we get the result we want and still get the time savings of concurrency?\nWe pass the value of i to the concurrent process!\nvar wg sync.WaitGroup for _, i := range rand.Perm(5) { wg.Add(1) go func(x int){ fmt.Println(i) wg.Done() }(i) fmt.Println(\u0026#34;.\u0026#34;) } wg.Wait() Now we\u0026#39;ll get the output we\u0026#39;re expecting. Not in order, but one for each integer in the slice. This is because we\u0026#39;ve created new variables with different scopes. ```bash . . . . . 2 5 4 1 3 We now have a function that completes the same action as our non-concurrent function.\nfunc PermExampleConc(max int) (sum int){ var wg sync.WaitGroup for _, value := range rand.Perm(max) { wg.Add(1) go func(val int){ sum += val time.Sleep(20 * time.Millisecond) wg.Done() }(value) } wg.Wait() return } Let\u0026rsquo;s run a couple different max values for each permutation example, and see how much a difference concurrency is providing us.\nfunc withoutConc(b *testing.B, max int){ for i := 0; i \u0026lt; b.N; i++ { benchmarking.PermExampleNoConc(max) } } func withConc(b *testing.B, max int){ for i := 0; i \u0026lt; b.N; i++ { benchmarking.PermExampleConc(max) } } func BenchmarkPermEx10(b *testing.B){ withoutConc(b, 10) } func BenchmarkPermEx100(b *testing.B){ withoutConc(b, 100) } func BenchmarkPermEx10C(b *testing.B){ withConc(b, 10) } func BenchmarkPermEx100C(b *testing.B){ withConc(b, 100) } Our output by running go test -bench=Perm\nBenchmarkPermEx10-8 5 212508093 ns/op BenchmarkPermEx100-8 1 2223450849 ns/op BenchmarkPermEx10C-8 100 22294648 ns/op BenchmarkPermEx100C-8 50 22428714 ns/op Results explained:\n    max = 10 max = 100     Without Concurrency 212 ms 223 ms   With Concurrency 22.2 ms 22.4 ms    These are exaggerated numbers because of time.Sleep in our code.\nCapping CPU Usage During Test It\u0026rsquo;s not uncommon to have packages that are being tested to contain goroutines, channels and other synchronization systems. By default, a go test will run with max CPU\u0026rsquo;s at 1, unless runtime.GOMAXPROCS has been set in the code or in the environment variables.\nYou could use\nGOMAXPROCS=3 go test in order to run tests with 3 cores.\nBut! There\u0026rsquo;s a better way. Let\u0026rsquo;s say you wanted to see the difference in running with different amounts of cores. In this case you could do:\ngo test -cpu=1,2,4 The above will run the test three times, first with one cpu, then with 2, and then with 4 cpu\u0026rsquo;s.\nLet\u0026rsquo;s say we have the following benchmark test on a Fibonacci function.\nfunc benchmarkFib(fibArg int, b *testing.B) { //run the Fib function b.N times. \tfor n := 0; n \u0026lt; b.N; n++ { Fib(fibArg) } } func BenchmarkFib1(b *testing.B) { benchmarkFib(1, b) } func BenchmarkFib2(b *testing.B) { benchmarkFib(2, b) } func BenchmarkFib3(b *testing.B) { benchmarkFib(3, b) } func BenchmarkFib10(b *testing.B) { benchmarkFib(10, b) } func BenchmarkFib20(b *testing.B) { benchmarkFib(20, b) } func BenchmarkFib40(b *testing.B) { benchmarkFib(40, b) } Using the previous example of benchmarking the Fib function, we could use the cpu and verbose flags to get the following:\n$ go test -bench=. -v -cpu=1,2,4 -race goos: darwin goarch: amd64 pkg: github.homedepot.com/om-labs/go-testing/benchmarking BenchmarkFibBase 500000 2474 ns/op BenchmarkFibBase-2 500000 2484 ns/op BenchmarkFibBase-4 500000 2480 ns/op BenchmarkFib1 50000000 24.1 ns/op BenchmarkFib1-2 100000000 24.1 ns/op BenchmarkFib1-4 50000000 25.5 ns/op BenchmarkFib2 30000000 52.2 ns/op BenchmarkFib2-2 30000000 52.0 ns/op BenchmarkFib2-4 30000000 54.5 ns/op BenchmarkFib3 20000000 81.1 ns/op BenchmarkFib3-2 20000000 79.7 ns/op BenchmarkFib3-4 20000000 79.1 ns/op BenchmarkFib10 500000 2572 ns/op BenchmarkFib10-2 500000 2536 ns/op BenchmarkFib10-4 500000 2492 ns/op BenchmarkFib20 5000 311494 ns/op BenchmarkFib20-2 5000 308299 ns/op BenchmarkFib20-4 5000 309446 ns/op BenchmarkFib40 1 4568477072 ns/op BenchmarkFib40-2 1 4642059146 ns/op BenchmarkFib40-4 1 4656502555 ns/op PASS ok github.homedepot.com/om-labs/go-testing/benchmarking 42.293s Lab Benchmarking  If you haven\u0026rsquo;t already, clone down the exercise repo found at https://github.homedepot.com/om-labs/go-concurrency Complete the instructions in benchmarking/README.md  Further Reading \u0026ldquo;Dave Chaney on Writing Benchmarks in Go\u0026rdquo;\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/box-model/",
	"title": "Box Model",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Describe the box model Describe the difference between block, inline, and inline-block elements  Skills  Adjust element spacing using padding and margin Create floating elements to position content removed from the standard document flow Explain the difference between and use cases of static, relative, fixed, \u0026amp; absolute positioning Create a page with multicolumn layout  Box Model Intro The CSS box model is essentially a box that wraps around every HTML element. It consists of: margins, borders, padding, and the actual content.\nThe image below illustrates the box model:\nDo the following to help visualize the box model:\n Create a new directory called hello-box-model Create an HTML page called index.html with an externally linked css stylesheet called app.css Inside the HTML page create a container div that contains 4 inner divs. Inside the CSS page, make the container a 500px gray square containing 100px squares within that are red, blue, green, and black.  index.html:\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34; href=\u0026#34;app.css\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;square1\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;square2\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;square3\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;square4\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; app.css:\n#container { height: 500px; width: 500px; background-color: gray; } #square1 { background-color: red; height: 100px; width: 100px; } #square2 { background-color: blue; height: 100px; width: 100px; } #square3 { background-color: green; height: 100px; width: 100px; } #square4 { background-color: black; height: 100px; width: 100px; } Now open Chrome\u0026rsquo;s dev tools and under the Elements tab hover over each of the divs.\nNotice a \u0026ldquo;box\u0026rdquo; is being highlighted in your browser!\nAdd the following into the css file:\n* { border: 1px solid red !important; } Notice the body, the container, and each of the divs are surrounded by a red border. Peak at the styles tab on the right and scroll all the way to the bottom to see boxes within boxes!\nThe page should look something like this:\nBox Model Example:\nThe Box Model and its components The image below illustrates the box model and what you should have seen in your dev tools:\nBut what do these different layers mean, and how are they relating to one another?\n Margin - clears an area around the border; the margin does not have a background color, it is completely transparent Border - a border that goes around the padding and content; the border is affected by the background color of the box Padding - clears an area around the content; the space between the content and the border; the padding is affected by the background color of the box Content - The content of the box, where text and images appear  Margin The margin is the space around the element. The larger the margin, the more space between elements and the elements around it. Adjusting the margin moves HTML elements closer to or farther from each other and moves elements relative to the \u0026ldquo;walls\u0026rdquo; of the HTML document.\nFor instance, if an HTML element with a specific width (such as \u0026lt;div\u0026gt; in the editor) has a margin set to auto - the document automatically puts equal left and right margins on the element, centering it on the page.\nTo specify a particular margin to a particular side, do something like:\ndiv { margin-top: /*some value*/ margin-right: /*some value*/ margin-bottom: /*some value*/ margin-left: /*some-value*/ } Experiment with altering each of these values in the dev tools for the div selector.\nTo set all of an element\u0026rsquo;s margins with 1 line of CSS, start from the top margin and go around clockwise (going from top to right to bottom to left).\nFor instance:\ndiv { margin: 1px 2px 3px 4px; /* top right bottom left */ } The shorthand to make the top and bottom margins the same and the left and right margins the same looks like the following:\ndiv { margin: 0 auto; /* top and bottom margins are `0`, left and right margins are `auto` */ } If the margin is the same for all 4 sides, use the following shorthand:\ndiv { margin: 10px; /* sets the margin for all 4 of the sides to 10px */ } Border The border is the edge of the element. It\u0026rsquo;s what we\u0026rsquo;ve been making visible every time we set the border property.\nTo add some thick borders to the \u0026lt;div\u0026gt;'s, remove the !important from the * selector and add:\ndiv { margin: 0 auto; border-width: 5px; border-style: solid; border-color: black; } The border properties have a shorthand notation as well. The above can be rewritten as:\ndiv { margin: 0 auto; border: 5px solid black; /* border-width border-style border-color */ } Setting a Border Radius CSS3 added a border-radius property that provides a way to have rounded corners on the borders!\nYou can try it out with border-radius: 5px;\nRead about all of the border properties here.\nPadding and Content The padding is the spacing between the content and the border that can be adjusted to move the border closer to or farther from the content.\nAdd some padding to the \u0026lt;div\u0026gt;'s from the dev tools. Notice, the space inside the \u0026ldquo;boxes\u0026rdquo; gets larger.\ndiv { margin: 0 auto; border: 5px solid black; padding: 2px; /* a single argument sets the padding around all of the edges */ } Padding becomes more apparent when \u0026ldquo;stuff\u0026rdquo; is inside the box.\nFor example, a \u0026lt;p\u0026gt; element, the \u0026ldquo;stuff\u0026rdquo; is the text of the paragraph - the content:\nindex.html\n\u0026lt;div id=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;p\u0026gt;Hi there!\u0026lt;/p\u0026gt; \u0026lt;div id=\u0026#34;square1\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;square2\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;square3\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;square4\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Open the browser, and now, give that p tag some padding in the dev tools:\np { padding: 20px; } Amazing! Add those styles to your CSS file.\nTaking Up Space using display Each HTML element gets its own \u0026ldquo;box\u0026rdquo; to live in. The outermost box of each element went all the way across the page. This is why, until now, your HTML elements have been sitting on top of one another: by default, they take up the full width of the page.\nThe default can change with positioning properties.\nOne of these properties is the display property that has the following values: block, inline, inline-block, and none.\n block elements span the whole width of the available space. inline elements use only the space as they need, without adding a new line after them. inline-block elements are inline element (on the same line as adjacent content), but it behaves as a block element. This makes the element a block box (with margin, padding and a border) but it will allow other elements to sit next to it on the same line. a display of none will effectively hide the element from view. The element is still there but is not rendered into the view (display).  Example of inline, block, and inline-block\nindex.html\n\u0026lt;div class=\u0026#34;inline\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;inline\u0026#34;\u0026gt;Apple\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;inline\u0026#34;\u0026gt;Orange\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;inline\u0026#34;\u0026gt;Banana\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;block\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;block\u0026#34;\u0026gt;Star Wars\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;block\u0026#34;\u0026gt;The Matrix\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;block\u0026#34;\u0026gt;Terminator\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;inline-block\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;inline-block\u0026#34;\u0026gt;Beyonce\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;inline-block\u0026#34;\u0026gt;Adele\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;inline-block\u0026#34;\u0026gt;David Bowie\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; app.css\n* { border: 1px solid black; margin: 5px; padding: 5px; } .inline { display: inline; border: 1px solid red; } .block { display: block; border: 1px solid green; } .inline-block { display: inline-block; border: 1px solid blue; } Output:\nExample of CSS Display Modes Diagram comparing block, inline, and inline-block:\nimage credit\nUse display: inline-block for right-justified alignment of labels in forms. For example:\nlabel { display: inline-block; width: 80px; text-align: right; margin: 10px; } will result in rendering:\nLabel Alignment with inline-block Default display values for HTML tags All of the HTML tags have a default setting for their display, but this setting can be modified via the proper CSS selectors and settings.\n   Default display Value HTML Tags     inline map, output, q, span, a, strong, em, input, abbr, acronym   block address, article, aside, blockquote, body, br, dd, details, div, dl, dt, fieldset, figcaption, footer, form, h1...h6, header, hr, html, iframe, legend, menu, nav, ol, p, pre, section, summary, ul   inline-block img   list-item (block) li   table (block) table   table-caption table-caption   table-cell td, th   table-column col   table-column-group colgroup   table-footer-group tfoot   table-header-group thead   table-row tr   table-row-group tbody   none datalist, head, link, param, script, style, title    Flexbox An HTML element with a display value of flex has its children arranged according to the rules of the flexbox (a new feature in CSS3). Flexbox is so powerful that we will have a separate lesson dedicated entirely to it.\nBreaking Outside the Box CSS Positioning defines how HTML elements are placed in the page flow. Compared to the display property discussed above, the position property acts as a more radical way of controlling an element\u0026rsquo;s placement on the page.\nThe position property can be used to specify whether an element flows with the page content (the default), is displayed independently of the content around it (absolute), or even remains fixed during scrolling (fixed).\nSchemes CSS positioning has 3 schemes (or strategies or modes).\n   Scheme Description     Normal flow Inline items are laid out one after the other across the available space until there is no more room, then starting a new line below. Block items stack vertically, like paragraphs and like the items in a bulleted list.   Floats Means an item is taken out of the normal flow and shifted to the left or right as far as possible in the space available. Other content then flows around the floated item.   Absolute positioning Means an item has no place in, and no effect on, the normal flow of other items, occupying its assigned position in its container independently of other items. If fixed the item doesn\u0026rsquo;t even scroll with the page.    Position Properties and Values For non-static positioned elements the properties top, bottom, left, and right can be used to specify offsets (relative) and positions (absolute and fixed).\n   Scheme Value Description     Normal Flow position: static Default value. Elements render in order, as they appear in the document flow   Normal Flow position: relative The element is positioned relative to its normal position, so \u0026ldquo;left:20px\u0026rdquo; adds 20 pixels to the element\u0026rsquo;s LEFT position   Absolute position: absolute The element is positioned relative to its first positioned (not static) ancestor element   Absolute position: fixed The element is positioned relative to the browser window   Misc. position: initial Sets this property to its default value.   Misc. position: inherit Inherits this property from its parent element.    Relative Positioning Declaring position: relative allows you to position the element top, bottom, left, or right relative to where it would normally occur. Let\u0026rsquo;s add some CSS and see what happens:\n#square1 { background-color: red; height: 100px; width: 100px; position: relative; top: 0; left: 40px; } Absolute Positioning Specifying position: absolute removes the element from the document and places it exactly where you tell it to be.\n#square1 { background-color: red; height: 100px; width: 100px; position: absolute; top: 0; right: 0; } A page element with relative positioning gives the control to absolutely position child elements inside of it.\nThe relative positioning on the parent is what matters here. This what would happen if we forgot that:\nThe absolutely positioned elements are positioning themselves in relation to the body element, instead of their direct parent. So if the browser window grows, that element in the bottom left is going to stick with the browser window, not hang back inside, like it was the case in the previous example.\nStatic Positioning HTML elements are positioned static by default. A \u0026ldquo;static positioned\u0026rdquo; element is always positioned according to the normal flow of the page and are not affected by the top, bottom, left, and right properties.\nAgain, the default positioning for all elements is static. This means that no positioning has been applied and the elements occurs where they normally would in the document.\nIf we revisit our squares from earlier in class:\n#container { background-color: gray; position: static; height: 500px; width: 500px; } You rarely explicitly declare position:static like this because it is the default.\nFixed Positioning An element with fixed position is positioned relative to the browser window. It will not move even if the window is scrolled, so a fixed positioned element will stay right where it is creating an effect a bit like the old school \u0026ldquo;frames\u0026rdquo; days.\nTry it out:\n#square2 { position: fixed; width: 100%; height: 100px; background-color: blue; top: 0; left: 0; } Example of display and position values\nHere is an example of the display and position values:\nYou can see this example in action here.\nFloat and clear  NOTE: float and clear are not usually needed in modern web design due to the newly added CSS Flexbox and CSS Grid.\n The float property may have one of three values. Absolutely positioned or fixed items cannot be floated. Other elements normally flow around floated items, unless they are prevented from doing so by their clear property.\n   Property Description     float: left The item floats to the left of the line that it would have appeared in; other items may flow around its right side.   float: right The item floats to the right of the line that it would have appeared in; other items may flow around its left side.   clear: \\[left \\| right \\| both] Forces the element to appear underneath (\u0026lsquo;clear\u0026rsquo;) floated elements to the left (clear: left), right (clear: right) or both sides (clear: both).    Notes regarding float and clear:\n Floated elements remain a part of the flow of the web page. This is distinctly different than page elements that use absolute positioning. All elements will float next to floated items until they are specifically cleared. absolutely positioned elements ignore the float property as they are removed from the normal document flow.   In its simplest use, the float and clear properties can be used to wrap text around images. Other uses of float are to display items side-by-side. Luckily, the flexbox layout makes float and clear obsolete!\n Units of Measure Relative Lengths Relative length units specify a length relative to another length property. Relative length units scale better between different rendering mediums.\n   Unit Description     em Relative to the font-size of the element (2em means 2 times the size of the current font)   ex Relative to the x-height of the current font (rarely used)   ch Relative to width of the \u0026ldquo;0\u0026rdquo; (zero)   rem Relative to font-size of the root element   vw Relative to 1% of the width of the viewport   vh Relative to 1% of the height of the viewport   vmin Relative to 1% of viewport\u0026rsquo;s smaller dimension   vmax Relative to 1% of viewport\u0026rsquo;s larger dimension   % A percentage of the element\u0026rsquo;s container size (width or height)     viewport is the browser window size. If the viewport is 50cm wide, 1vw = 0.5cm. The em and rem units are practical in creating a scalable layout!  Absolute Lengths The absolute length units are fixed and a length expressed in any of these will appear as exactly that size.\nAbsolute length units are not recommended for use on screen, because screen sizes vary so much. However, they can be used if the output medium is known, such as for print layout.\nRelative length units of measure\n   Unit Description     cm centimeters   mm millimeters   in inches (1in = 96px = 2.54cm)   px pixels (1px = 1/96th of 1in)   pt points (1pt = 1/72 of 1in)   pc picas (1pc = 12 pt)    Z Order The z-index property specifies the stack order of elements that overlap. An element with greater stack order is always in front of an element with a lower stack order.\n The z-index only works on non-static positioned elements (position:absolute, position:relative, or position:fixed).\n Here is an illustration of the stacking order:\nFor more information, see: What You Man Not Know About the Z-Index Property\nPro Tips The following are CSS best practices:\n All styles should go into external CSS files. Avoid using inline-styles. Only style using class and tag selectors. Avoid styling IDs. Avoid using !important. It\u0026rsquo;s a last resort.  Summary  Most of the HTML elements are rendered according to the rules of the box model. The box model defines a box around an HTML element: has a width and a height that can be calculated based on the elements contents or set to a specific value. The box model includes padding, a border, and margin surrounding the box. The display CSS property to set an HTML element to be treated as a block, inline, inline-block, or hidden (none) element. Position an HTML element outside of the normal flow of the page via the float display values or the absolute and fixed position values. CSS provides several relative and absolute units of measure. The most common are em, %, px, and pt. Set a z-order on elements to specify their stacking order.     Go to Box Model Labs    "
},
{
	"uri": "/application-security/api-security/01_service_to_service_oauth2/50_client-cred-flow/",
	"title": "Client Credentials Flow",
	"tags": [],
	"description": "",
	"content": "Securing API to API Communications The client credentials flow is used to authorize one server against another, no humans. The full flow looks like:\nIdentity Redundancy Here is a small point for you to research later, if you want. For Service to Service only, we load balance all calls between PingFed (70% of traffic) and Azure (30% of traffic). This way if either system goes down, we fail over to the other system. Just be aware that when making these calls, you may see tokens come back from PingFed and/or Azure. All Producers MUST accept tokens from both PingFed and Azure.\n401 vs 403 Quick note about 401 vs 403.\n401 - I went to the bar but forgot my Drivers License. They told me to go away. This also occurs with an invalid license.\n403 - I went to the bar, presented my valid Georgia Drivers License, but I\u0026rsquo;m 18. So they told me to go away, but with a different error.\nIt is the different between Identity and Privilege. 401 - we can\u0026rsquo;t identity you. 403 - we know who you are, but you aren\u0026rsquo;t suppose to be here.\nRequesting a Token The client must send specific information to the Authorization Server to request a token:\nToken Endpoint: https://identity.service.homedepot.dev/oauth2/v1/token\nMethod: POST\nHeaders: Content-Type: application/x-www-form-urlencoded\nRequest Body\n   Property value     grant_type client_credentials   client_id Your client credentials   client_secret Your Client Secret   scope What spiffe/resourece are you requesting access to? (with /.default appended to the end of the name)    Hands On Over the next few slides, we are going to put hands on keyboard, and will play the role of the client.\n Call the Authorization Server to get a token for the spiffe://homedepot.dev/om-api-security-client service, inspect the contents of the token Call the Authorization Server to get a token for the spiffe://homedepot.dev/om-api-security-client-unauthorized service, inspect the contents of the token. Using a valid token, call the Resource Server and check the response.  Step 1: Request a Token (Authorized Client) Playing the role of the client, use curl or Postman to request a token from the Authorization Server. We will be asking for token with a subject of spiffe://homedepot.dev/om-api-security-client and an audience of spiffe://homedepot.dev/om-api-security-api.\nToken Endpoint: https://identity.service.homedepot.dev/oauth2/v1/token\nHTTP Method: POST\nHeaders: Content-Type: application/x-www-form-urlencoded\nRequest Body\n   Property value     grant_type client_credentials   client_id spiffe://homedepot.dev/om-api-security-client   client_secret t5_I5~oeO1q7Ky-K.z20kXjf6H~Qj5PH4R   scope spiffe://homedepot.dev/om-api-security-api/.default    Save this token off to the side for the moment.\nStep 1 (Hint) curl --location --request POST \u0026#39;https://identity.service.homedepot.dev/oauth2/v1/token\u0026#39; \\ --header \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; \\ --data-urlencode \u0026#39;grant_type=client_credentials\u0026#39; \\ --data-urlencode \u0026#39;client_id=spiffe://homedepot.dev/om-api-security-client\u0026#39; \\ --data-urlencode \u0026#39;client_secret=t5_I5~oeO1q7Ky-K.z20kXjf6H~Qj5PH4R\u0026#39; \\ --data-urlencode \u0026#39;scope=spiffe://homedepot.dev/om-api-security-api/.default\u0026#39; | jq Step 2: Request a Token (Unauthorized Client) Playing the role of the unauthorized client, use curl or Postman to request a token from the Authorization Server but with a resource id that you are not authorized to request for. We will be asking for token with a subject of spiffe://homedepot.dev/om-api-security-client-unauthorized and an audience of spiffe://homedepot.dev/om-api-security-api which is an invalid combination. That client is not authorized to request it. You will be presented with an error message then hinted at how to correct the error.\nToken Endpoint: https://identity.service.homedepot.dev/oauth2/v1/token\nHTTP Method: POST\nHeaders: Content-Type: application/x-www-form-urlencoded\nRequest Body\n   Property value     grant_type client_credentials   client_id spiffe://homedepot.dev/om-api-security-client-unauthorized   client_secret aC4v5HynAx414zXG.k3yRl04-PrViS-xl-   scope spiffe://homedepot.dev/om-api-security-api/.default    What happens if you change the the resource attribute to be the exact same as the client_id? Save this token off to the side for the moment.\nStep 2 (Hint) Try 1, You should get a 400 back, because this client is not allowed to ask for that resource. Not authorized.\ncurl --location --request POST \u0026#39;https://identity.service.homedepot.dev/oauth2/v1/token\u0026#39; \\ --header \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; \\ --data-urlencode \u0026#39;grant_type=client_credentials\u0026#39; \\ --data-urlencode \u0026#39;client_id=spiffe://homedepot.dev/om-api-security-client-unauthorized\u0026#39; \\ --data-urlencode \u0026#39;client_secret=aC4v5HynAx414zXG.k3yRl04-PrViS-xl-\u0026#39; \\ --data-urlencode \u0026#39;scope=spiffe://homedepot.dev/om-api-security-api/.default\u0026#39; | jq Modified try, but change the resource value to be same as the client_id:\ncurl --location --request POST \u0026#39;https://identity.service.homedepot.dev/oauth2/v1/token\u0026#39; \\ --header \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; \\ --data-urlencode \u0026#39;grant_type=client_credentials\u0026#39; \\ --data-urlencode \u0026#39;client_id=spiffe://homedepot.dev/om-api-security-client-unauthorized\u0026#39; \\ --data-urlencode \u0026#39;client_secret=aC4v5HynAx414zXG.k3yRl04-PrViS-xl-\u0026#39; \\ --data-urlencode \u0026#39;scope=spiffe://homedepot.dev/om-api-security-client-unauthorized/.default\u0026#39; | jq This is a self-referenced token, great for testing and intra application communication.\nRequesting from the Resource Server From the image above, we are now going to execute step 2, which will trigger 3-9\nWe have deployed an example resource service at:\nhttps://om-api-security-workshop.apps-np.homedepot.com/\nThis ID of this resource service is: spiffe://homedepot.dev/om-api-security-api\nLets use the tokens from above and call the resource service and see what happens\nStep 3: Call with No Token Using curl or postman, construct a basic GET call using the following information:\nOpen Endpoint:\nURL: https://om-api-security-workshop.apps-np.homedepot.com/catfacts/v1/public/fact/random\nSecured Endpoint:\nURL: https://om-api-security-workshop.apps-np.homedepot.com/catfacts/v1/secure/fact/random\nWere the results what you expected? Should have been a 200 on the first call and a 401 on the 2nd.\nStep 3 (Hint) curl -s https://om-api-security-workshop.apps-np.homedepot.com/catfacts/v1/public/fact/random | jq curl -s https://om-api-security-workshop.apps-np.homedepot.com/catfacts/v1/secure/fact/random | jq Step 4: Call to Resource Server with JWT Token Using curl or postman, construct a basic GET call using the following information, but this time add a special header:\nAuthorization: Bearer {jwt}\nwhere the jwt token is from the AUTHORIZED client.\nOpen Endpoint:\nURL: https://om-api-security-workshop.apps-np.homedepot.com/catfacts/v1/public/fact/random\nSecured Endpoint:\nURL: https://om-api-security-workshop.apps-np.homedepot.com/catfacts/v1/secure/fact/random\nWere the results what you expected? Should have been a 200 on the first call and a 200 on the 2nd.\nStep 4 (Hint) curl -s -H \u0026#34;Authorization: Bearer {TOKEN-FROM_STEP-1}\u0026#34; https://om-api-security-workshop.apps-np.homedepot.com/catfacts/v1/public/fact/random curl -s -H \u0026#34;Authorization: Bearer {TOKEN-FROM_STEP-1}\u0026#34; https://om-api-security-workshop.apps-np.homedepot.com/catfacts/v1/secure/fact/random Step 5: Call with Unauthorized Token Using curl or postman, construct a basic GET call using the following information, but this time add a special header:\nAuthorization: Bearer {jwt}\nwhere the jwt token is from the UNAUTHORIZED client.\nOpen Endpoint:\nURL: https://om-api-security-workshop.apps-np.homedepot.com/catfacts/v1/public/fact/random\nSecured Endpoint:\nURL: https://om-api-security-workshop.apps-np.homedepot.com/catfacts/v1/secure/fact/random\nWere the results what you expected? Should have been a 200 on the first call and a 403 on the 2nd.\nStep 5 (Hint) curl -s -H \u0026#34;Authorization: Bearer {TOKEN-FROM_STEP-2}\u0026#34; https://om-api-security-workshop.apps-np.homedepot.com/catfacts/v1/public/fact/random curl -s -H \u0026#34;Authorization: Bearer {TOKEN-FROM_STEP-2}\u0026#34; https://om-api-security-workshop.apps-np.homedepot.com/catfacts/v1/secure/fact/random Resource Server Responsibilities Everything above was from the Client\u0026rsquo;s POV. As you can see the clients job is pretty straightforward. Get a token, call an endpoint, get your stuff.\nBut the Resource Server has a more complex job. So lets shift our POV and talk through the Resource Server side:\n Check for the token Get the token from the value (remove \u0026ldquo;Bearer \u0026ldquo;) Validate the iss claim is from a trusted issuer. Get the JWKS (Public Key) based upon the iss claim Validate the Token against the Public Key Check the nbf, iat, and exp claims Check the audience (aud) claim to determine if the token is intended for this resource server.  Phew!\nHow to setup the Resource Server The resource server can be very complex, but we have worked hard to provide middleware/filter that make it turn key simple.\nThe overly simplified answer for Resource Server setup for NodeJS, Golang, and Spring Boot, is apply the middleware/filter and then give it a yaml file. That is how all 3 of the community built solutions work. Here is the link to the yaml file for the cat facts API but I have copied it here for a quick discussion:\nversion: 1 # enabled: false make this a resource server instead of a webapp (tomorrow\u0026#39;s topic) oidc: enabled: false # security checks are instructions for how to read and check the token security-checks: pingfed-ui-check: issuer-name: pingfed-qa audience: spiffe://homedepot.dev/om-api-security-ui pingfed-qa-check: issuer-name: pingfed-qa audience: spiffe://homedepot.dev/om-api-security-api azuread-qa-check: issuer-name: azuread-qa audience: spiffe://homedepot.dev/om-api-security-api # then you need to apply the check to the path.  paths: p-001: path: /catfacts/v1/public/* check-names: - allow-all p-002: path: /catfacts/v1/secure/* check-names: - pingfed-qa-check - azuread-qa-check - pingfed-ui-check Build your own Resource Server The goal is for THD Dev Community to build common libraries for each of the main backend languages and frameworks. We already have one for GOLang, NodeJS is in development, and SpringBoot is next.\nCheck #thd-identity for where to find these.\nhttps://app-secure-community-docs.apps-np.homedepot.com/identity/service-to-service/#code\nSample ClientID and Client Secret for learning    Role Client ID Secret     Authorized Client spiffe://homedepot.dev/om-api-security-client t5_I5~oeO1q7Ky-K.z20kXjf6H~Qj5PH4R   Unauthorized Client spiffe://homedepot.dev/om-api-security-client-unauthorized aC4v5HynAx414zXG.k3yRl04-PrViS-xl-   Resource Server Identifier spiffe://homedepot.dev/om-api-security-api     "
},
{
	"uri": "/java/foundations/comments/",
	"title": "Commenting",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Line Comments Block Comments JavaDocs  Skills  Use comments to enhance code readability  Implementation Comments In general, comments are used to provide insight into a specific implementation or idea behind a block of code. In other words, they can be used to explain any non-trivial design decisions. To that end, comments should always be relevant to reading, understanding, or running the program.\nAlways be mindful of the way you comment as frequent comments could be a sign of poor code quality. The goal is for your code to speak for itself. So if you frequently feel that a comment is needed in order to clarify what is happening, it may be time to step back and reconsider your approach to the problem at hand.\nSo when should you not comment?\n do not comment on anything that is present and clear from the code itself (redundancy) do not comment saying anything that will soon be irrelevant or out of date  Line Comment // this is a line comment // TODO this is a reminder that this needs to be revisted Block Comment /* * this is a block comment that * spans multiple lines */ Java Docs Java has its own flavor of comments that are separate from implementation comments. JavaDoc comments are used to document your code at a high level, rather than to explain what is happening in the specific implementation. It\u0026rsquo;s similar to the block comments seen above, except they start with /** rather than /*. You usually want these before classes. interfaces, fields, and methods to describe the purpose or behavior of any given member of a class. JavaDoc utilize annotations to format your docs, the full list can be found here.\nThis formatting allows these comments to easily be formatted and compiled into a detailed html document describing your classes.\nClass/Interface /** * Class description goes here. * * @version 1.82 18 Mar 1999 * @author Firstname Lastname */ public class Blah extends SomeClass { ... Method  example from the Java Graphics class  /** * Draws as much of the specified image as is currently available * with its northwest corner at the specified coordinate (x, y). * This method will return immediately in all cases, even if the * entire image has not yet been scaled, dithered and converted * for the current output device. * * @param img the image to be drawn * @param x the x-coordinate of the northwest corner * of the destination rectangle in pixels * @param y the y-coordinate of the northwest corner * of the destination rectangle in pixels * @param observer the image observer to be notified as more * of the image is converted. May be * \u0026lt;code\u0026gt;null\u0026lt;/code\u0026gt; * @return \u0026lt;code\u0026gt;true\u0026lt;/code\u0026gt; if the image is completely * loaded and was painted successfully; * \u0026lt;code\u0026gt;false\u0026lt;/code\u0026gt; otherwise. * @see Image * @see ImageObserver * @since 1.0 */ public abstract boolean drawImage(Image img, int x, int y, ImageObserver observer) { ... Compiled JavaDocs Example (LinkedList) Summary Ideally code comments make your code more readable and can help those unfamiliar with the code base get up to speed by providing insight into the decisions that went into the implementation, preventing knowledge silos.\nComments make your code more readable and help those unfamiliar with the code base gain insight into the decisions around implementation, preventing knowledge silos. Try not to use redundant comments. As the code base is refactored, the comments should also be refactored to stay consistent and up to date with the code base.\nResources  Writing JavaDocs  "
},
{
	"uri": "/react/foundations/component-props/",
	"title": "Component Props",
	"tags": [],
	"description": "",
	"content": "Using props to configure React Components.\nIntroduction to Props  Since components are intended to be reusable, we need a way to configure them and send them data. React allows us to pass data into a Component via a JavaScript object referred to as props (think properties of the Component).  Let\u0026rsquo;s look at an example Greeter component with a name prop:\nGreeter.js:\nimport React from \u0026#39;react\u0026#39;; const Greeter = (props) =\u0026gt; { // a simple stateless component with a `name` prop.  return \u0026lt;h4\u0026gt;Hello {props.name}\u0026lt;/h4\u0026gt;; }; export default Greeter; Here is how we can reuse it:\nApp.js:\nimport React, { Component } from \u0026#39;react\u0026#39;; import Greeter from \u0026#39;./Greeter\u0026#39;; import \u0026#39;./App.css\u0026#39;; function App() { return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; \u0026lt;Greeter name=\u0026#34;Heather\u0026#34; /\u0026gt; \u0026lt;-- we can create multiple instances of the Greeter component --\u0026gt; \u0026lt;Greeter name=\u0026#34;Phillip\u0026#34; /\u0026gt; \u0026lt;-- each instance passes a different value for the `name` prop --\u0026gt; \u0026lt;Greeter name=\u0026#34;Elizabeth\u0026#34; /\u0026gt; \u0026lt;Greeter name=\u0026#34;Hunter\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; ); } export default App; Props are Read-Only  Remember that props are read-only values. The only way that props can \u0026ldquo;change\u0026rdquo; is when a parent (container) component passes new props values to it\u0026rsquo;s children. What actually happens is that new instances of the child components are created with the new values.  Lab - Rendering with Props Do part 1 of the Component Props Lab.\nInter-Component Communication via Prop Functions  Components in a parent-child relationship often need to communicate. Parent to Child communication is easy via props, but how do child components communicate back to their parents? For example, how would a button component communicate to its parent that it had been clicked?  The most common strategy is to pass a callback function from the parent to the child via a prop. Then the child can call the callback function and pass in any needed data as function arguments.    Here is an example:\nimport React, { Component } from \u0026#39;react\u0026#39;; /* A simple presentation component that receives a label and a callback as `props`. */ function Greeting({ label, cb }) { return \u0026lt;button onClick={cb}\u0026gt;{label}\u0026lt;/button\u0026gt;; } function App() { function greet(message) { alert(message); } return ( \u0026lt;div\u0026gt; \u0026lt;Greeting label=\u0026#34;Click Me!\u0026#34; {/* Data passed as a prop to the Greeting component. */} cb={() =\u0026gt; greet(\u0026#34;Good Morning!\u0026#34;)} {/* A callback passed as a prop to the Greeting component. */} /\u0026gt; \u0026lt;/div\u0026gt; ); }  Notice how we defined an arrow function as the callback so that we could provide the data (arguments) needed to be passed (i.e. the \u0026ldquo;Good Morning!\u0026rdquo; message).\n Lab - Add to Cart Do part 2 of the Component Props Lab.\nReact Dev Tools React offers a handy browser extension (for chrome and firefox) that greatly enhances your development workflow.\nTo install with chrome, simply search the chrome web store for \u0026lsquo;React Developer Tools\u0026rsquo; or click here.\nOnce installed, you\u0026rsquo;ll get an extra panel within your developer tools that allows for things like:\n Viewing, searching and interacting with components Interacting with component state Viewing component props  Try it out!\n press command + shift + j click the tab titled \u0026lsquo;Components\u0026rsquo; Open your app component and view the tree   TIP: React also offers a stand-alone set of developer tools for Safari, React Native, etc.\n Lab - React Dev Tools Do part 3 of the Component Props Lab.\nSummary In this lesson we learned:\n the difference between stateless and stateful React components that you should write mostly stateless components because they are easier to write, understand, test, and reuse how to create stateless / presentation components using JavaScript functions how to write dynamic JSX expressions how to do component composition, that is how to use a component inside of another component how to use callback functions as props so that a component can communicate with it\u0026rsquo;s parent / container component how to use the React DevTools browser plugin for inspecting and debugging a React application  Additional Resources  A great place to start is the React Getting Started Documentation This has great descriptions and code samples for the most important parts of React. The React Tutorial is an excellent resource for understanding how to build a simple React app. To learn more about how React works, check out the React \u0026lsquo;diffing\u0026rsquo; Algorithm. This algorithm essentially compares the virtual DOM with the actual DOM and only updates the elements (and their children) that have been modified, resulting in fast and efficient DOM updates. React Lists and Keys.  "
},
{
	"uri": "/software-eng-essentials/command-line-bash/customization/",
	"title": "Customization",
	"tags": [],
	"description": "",
	"content": "Customization  Bash profile Aliasing Commands Customizing the Prompt  Bash profile This file, which probably already exists on your system, is used to configure the shell, which is the program that supplies a command line. As is common on Unix-based systems, the profile configuration file for Bash begins with a dot, indicating that the file is hidden, i.e., it doesn’t show up by default when listing directory contents with ls (or even when viewing the directory using a graphical file browser).\nIf the Bash profile is edited, then we need to tell the shell about the updated Bash profile file by “sourcing” it using the source command.\nsh $ source .bash\\_profile \nBy the way, the .bash_profile file is sourced automatically when we open a new terminal tab or window, so explicit sourcing is necessary only when we want a change to be reflected in the current terminal.\nAliasing Commands We’ll work on the .bash_profile file, and the edit we’ll make will add an alias to our shell. In a computing context, an alias is simply a synonym for a command or set of commands.\nThe main use for Bash aliases is defining shorter commands for commonly used combinations. An alias is a word or command that is mapped to a certain string. Whenever that word is used as a command name, it is replaced by the string before executing the command.\nIn this case, we’ll define the command lr (short for “list reverse”) as an alias for ls -hartl, which is the command to list files and directories using human-readable values for the sizes (e.g., 29K instead of 29592 for a 29-kilobyte file), including all of them (even hidden ones), ordered by reverse time, long form. This command, which as you may recognize from an exercise in the Inspecting files lesson, is useful for seeing which files and directories have recently changed.\nAn aliased command: before and after\nAfter defining the alias, we’ll be able to replace the more verbose\nsh $ ls -hartl  with the succincter\nsh $ lr \n~/.bash_profile\nsh alias lr=*ls -hartl* \nAfter adding the lr alias to .bash_profile, writing the file, and quitting, you may be surprised to find that the command doesn’t yet work:\nsh $ lr -bash: lr: command not found  This is because we need to tell the shell about the updated Bash profile file by “sourcing” it using the source command, as shown below.\nActivating the alias by sourcing the Bash profile.\nsh $ source .bash\\_profile  With that, the lr command should work as advertised:\nsh $ lr . . . drwx------+ 15 KXB0QJK staff 510B Sep 4 18:58 Desktop -rw------- 1 KXB0QJK staff 13K Sep 4 19:13 .viminfo -rw-r—r-- 1 KXB0QJK staff 46B Sep 4 19:14 .bash\\_profile drwxr-xr-x+ 117 KXB0QJK staff 3.9K Sep 4 19:14 . By the way, the .bash_profile file is sourced automatically when we open a new terminal tab or window, so explicit sourcing is necessary only when we want a change to be reflected in the current terminal.\n Aliases are only used in interactive shells and not in scripts — this is one of the very few differences between a script and an interactive shell.\n Exercises\n Define an alias g for the commonly used case-insensitive grep grep -i. You may recall the curl command from the Downloading a file lesson, which lets us interact with URLs via the command line. Define get as an alias for curl -OL, which is the command to download a file to the local disk (while following any redirects encountered along the way). Use the alias from the previous exercise to execute the command shown below, which downloads a long text file.  Downloading a long text file\nsh $ get \u0026lt;http://www.gutenberg.org/files/57962/57962-0.txt\u0026gt; Customizing the prompt It is not important to understand all the different ways to change the prompt, just know it is possible. You may later decide to customize your prompt in a way that best complements your workflow.\nHere are some examples of different ways a prompt might be configured to appear.\nBill\u0026#39;s MacBook Air: \u0026lt;sub\u0026gt;bgates$ `sh\\ \\[\u0026lt;/sub\u0026gt;\\]$` `[orange\\_method\\_project (master)\\] $2018-09-04 15:38:27 ⌚ |2.4.0| C02WF2HZZDT6MBP in ~ As an exercise, we will change our prompt to be like this custom one below.\nA more compact prompt.\n\\[~\\]$ Exercises\nThe default Bash prompt for a command-line terminal appears pretty long, and you may prefer a more compact prompt like the one below. We can accomplish this by editing the .bash_profile file to include the lines shown below. Source the Bash profile and confirm that the prompt on your system matches the one shown below.\nThe Bash lines needed to make the compact custom prompt.\n~/.bash_profile\nalias lr=*ls -hartl* # Customize prompt to show only working directory. PS1=’\\[\\\\W\\]\\\\$ \\\u0026#39; Summary Customization\n  Bash Profile\n  Aliasing Commands\n  Customizing the Prompt\n  "
},
{
	"uri": "/golang/databases/migrations-golang/",
	"title": "Database Migrations",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Explain the golang-migrate package Adding migration files to a go project Use golang-migrate to create and migrate files from the command line Build a sample go script to migrate files  Golang and Database Migrations Database migrations are important for making changes to the database schema. Keeping up with those changes is equally as important. Changing the schema without tracking the changes made can lead to the database and the dependent application(s) being out of sync.\nTo handle database migrations in go, we will use the golang-migrate package. With this package, many common migrations can be performed, including:\n creating and dropping a database creating and dropping a table modifying table characteristics  golang-migrate supports many relational databases. For this lesson, we will use PostgreSQL and work with a tool_rental database.\n ℹ️ The best use case for this application is for setting up a new database. If connecting to an existing database that is used by other applications, it is best to use the migration strategy currently in place for that database.\n Installing golang-migrate golang-migrate can be used at the command line as well as in a go script. To install the package, use on of the following:\n for Windows PC, in the the command prompt, type:  curl -L https://github.com/golang-migrate/migrate/releases/download/$version/migrate.$platform-amd64.tar.gz | tar xvz  for MacOS:  $ brew install golang-migrate  Using the Go toolchain  $ go get -u github.com/golang-migrate/migrate/v4/... This will build and install the package, and add the migrate command to your binary file. Test your installation by typing\n$ which migrate This should return: usr/local/bin/migrate\nTo check that it has been installed on your $GOPATH, check the $GOPATH/bin directory for migrate.\nManaging Migration from the Command Line Before connecting to a PostgreSQL database, make sure of the following:\n You have created a database called tool_rental. If you need help with this look here A user with granted access to the database has been created PostgreSQL is installed properly on your machine.  Let\u0026rsquo;s add a new table called tools. The attributes for our tools table are as follows:\n   Attribute Type/Constraints     id uuid_generate_v4()   name text not null   description text not null   price numeric(5, 2) not null   quantity int   created date default not null current_date   updated date default not null current_date    At the command line, we will use the golang-migrate package to create two migrations files, one that will create the table upon migration (migrate up), and one that will drop the table upon migration (migrate down).\n ℹ️ It is important that the down migration performs exactly opposite of the up migration to \u0026ldquo;undo\u0026rdquo; all changes made to the database schema by the migration and properly set the database back to the prior state.\n Creating Migration Files To create the migration files, we are going to use the migrate create command:\nmigrate create -ext \u0026lt;file_extension\u0026gt; -dir \u0026lt;migration_directory\u0026gt; \u0026lt;migration_file_name\u0026gt;  migrate create: creates the migration file -ext \u0026lt;file_extension\u0026gt;: specifies the file extension for the migration file (sql, json, etc.) -dir \u0026lt;migration_directory: specifies the directory the files should be placed in off your project root directory \u0026lt;migration_file_name\u0026gt;: the base names of the two files to be created. Each file will be given either a .up or .down extension.  Create a psql_migrations directory to hold our migration files. From the psql_migrations directory create a migrations directory. From the psql_migrations type the following at the command line to create the migration files:\n$ migrate create -ext sql -dir migrations create_tools_table You should see two new files appear in your file structure:\npsql_migrations └── migrations ├── 20191101095314_create_tools_table.down.sql ├── 20191101095314_create_tools_table.up.sql 1 directory, 2 files Adding Code to the Migration Files At this point, the files are empty. We will add the SQL statements needed to build the tools table. These statements will be wrapped in a BEGIN and COMMIT transaction.\nFirst, add the code needed to create the tools table in the .up file:\n.20191101095314_create_tools_table.up.sql\nBEGIN; CREATE EXTENSION IF NOT EXISTS \u0026#34;uuid-ossp\u0026#34;; CREATE TABLE tools( ID uuid DEFAULT uuid_generate_v4(), NAME TEXT NOT NULL, DESCRIPTION TEXT NOT NULL, PRICE NUMERIC (5, 2) NOT NULL, QUANTITY INT NOT NULL ); COMMIT; The .down file will only drop the the tools table if called.\nBEGIN; DROP FUNCTION IF EXISTS update_updated_column() CASCADE; -- adding CASCADE will also drop the TRIGGER that calls the function. DROP TABLE IF EXISTS tools; COMMIT; Calling the migrate -source Command Now that the code is in place, it\u0026rsquo;s time to apply the migrations. We will use the migrate -source command to accomplish this:\n$ migrate -source file://\u0026lt;file_directory_location\u0026gt; -database \u0026lt;database_type\u0026gt;://\u0026lt;host_name\u0026gt;:/\u0026lt;database_name\u0026gt;?sslmode=disable \u0026lt;up_OR_down\u0026gt;  migrate -source file://\u0026lt;file_directory_location\u0026gt;: specifies the directory where the migration files are located. This is viewed relative to where this command is called. -database \u0026lt;database_type\u0026gt;://\u0026lt;host_name\u0026gt;:/\u0026lt;database_name\u0026gt;?sslmode=disable: specifies the database URL used to connect to the database (this will be the same URL used in previous section) up_OR_down: specifies which migration file you want to use.  For our migration, we need to run the .up file. From the parent directory of the migrations directory, type the following command at the command line:\nmigrate -source file://migrations -database postgres://127.0.0.1:/tool_rental?sslmode=disable up You should see an output of:\n20191101095314/u create_tools_table (58.838775ms) This tells us our migration was successful! You can also check this by going to the database and verifying the table tools was indeed created.\n$ psql tool_rental psql (11.4) Type \u0026#34;help\u0026#34; for help. tool_rental=# \\d tools Table \u0026#34;public.tools\u0026#34; Column | Type | Collation | Nullable | Default -------------+--------------+-----------+----------+-------------------- id | uuid | | | uuid_generate_v4() name | text | | not null | description | text | | not null | price | numeric(5,2) | | not null | quantity | integer | | not null | (TODO: Insert a LAB exercise)\nUsing Migrations to Alter A Table Let say, we wanted to alter our table. We want to add 2 additional fields, created and updated to track modifications to the records in our tools table. Using the same method for creating migrations, we can create migration files to update our table with these two additional fields.\nCreate a migration called add_timestamps_to_tools_table:\n$ migrate create -ext sql -dir migrations add_timestamps_to_tools_table You should now have the following file structure:\nmigrations └── migrations ├── 20191101095314_create_tools_table.down.sql ├── 20191101095314_create_tools_table.up.sql ├── 20191101095831_add_timestamps_to_tools_table.down.sql ├── 20191101095831_add_timestamps_to_tools_table.up.sql 1 directory, 4 files In 20191101095831_add_timestamps_to_tools_table.up.sql add the following SQL code:\n.20191101095831_add_timestamps_to_tools_table.up.sql\nBEGIN; ALTER TABLE tools ADD COLUMN created DATE NOT NULL DEFAULT CURRENT_DATE; ALTER TABLE tools ADD COLUMN updated DATE NOT NULL DEFAULT CURRENT_DATE; -- Since we will need to update the updated field whenever a tool is modified, we need to create a TRIGGER function and a TRIGGER to call the function. For more on creating TRIGGERS please see the POSTGRES documentation. CREATE OR REPLACE FUNCTION update_updated_column() RETURNS TRIGGER AS $$ BEGIN NEW.updated = now(); RETURN NEW; END; $$ language \u0026#39;plpgsql\u0026#39;; CREATE TRIGGER update_tool_modtime BEFORE UPDATE ON tools FOR EACH ROW EXECUTE PROCEDURE update_updated_column(); COMMIT; The .down file will be a lot simpler, as it will only drop the added columns, as well the function update_updated_column and it\u0026rsquo;s trigger update_tool_modtime when called.\nBEGIN; ALTER TABLE tools DROP COLUMN created; ALTER TABLE tools DROP COLUMN updated; DROP FUNCTION IF EXISTS update_updated_column CASCADE; -- adding CASCADE will also drop the TRIGGER that calls the function. COMMIT; Run the command to run the migrations. Make sure you are in the root directory of your project:\nmigrate -source file://migrations -database postgres://127.0.0.1:/tool_rental?sslmode=disable up Now, we can check the database and see that 3 new items have been added -\n created field updated field update_tool_modtime trigger  psql tool_rental psql (11.4) Type \u0026#34;help\u0026#34; for help. tool_rental=# \\d tools Table \u0026#34;public.tools\u0026#34; Column | Type | Collation | Nullable | Default -------------+--------------+-----------+----------+-------------------- id | uuid | | | uuid_generate_v4() name | text | | not null | description | text | | not null | price | numeric(5,2) | | not null | quantity | integer | | not null | created | date | | not null | CURRENT_DATE updated | date | | not null | CURRENT_DATE Triggers: update_tool_modtime BEFORE UPDATE ON tools FOR EACH ROW EXECUTE PROCEDURE update_updated_column() Fixing Migration Errors It\u0026rsquo;s going to happen. There will come a time when you create a migration that has an error, not necessarily an SQL error, but maybe a spelling error or wrong datatype definition. This can easily be fixed by running the down migration. As stated before, it is important that the down migration file is the exact opposite of the up migrations. If your up file contains a misspelling of a field name, the down should also have that same misspelling to complete the opposite action for removing it. Let say we want to add another field to our table called vendor:\nLet\u0026rsquo;s create the files for the migration:\n$ migrate create -ext sql -dir migrations add_vendor_to_tools_table Add the following to the up file:\n.Migration up file\nBEGIN; ALTER TABLE tools ADD COLUMN vender VARCHAR(50) NOT NULL; COMMIT; If we run this migration, a new field will be added to the tools table called vender, a misspelling of the word vendor.\ntool_rental=# \\d tools Table \u0026#34;public.tools\u0026#34; Column | Type | Collation | Nullable | Default -------------+-----------------------+-----------+----------+-------------------- id | uuid | | | uuid_generate_v4() name | text | | not null | description | text | | not null | price | numeric(5,2) | | not null | quantity | integer | | not null | created | date | | not null | CURRENT_DATE updated | date | | not null | CURRENT_DATE vender | character varying(50) | | not null | Triggers: update_tool_modtime BEFORE UPDATE ON tools FOR EACH ROW EXECUTE PROCEDURE update_updated_column() To undo this, it is important to make sure the down file has exactly the same spelling as the up file:\n.Migration down file\nBEGIN; ALTER TABLE tools DROP COLUMN vender; COMMIT; Simply running the migrate command to rollback our modification will result in all our migrations being rollback back. Since we only want to undo the last migration, we are going to use the step attribute in our migrate command. The step value will represent the number of migrates we want to rollback. Having no value means we want to rollback everything (not normally what we\u0026rsquo;d want to do). If we were to put in the value of 2, the last two migrations would be rolled back. In our case, we only want to undo 1 migration, so we will use a step value of 1.\nIn the command line, type :\n$ migrate -source file://migrations -database postgres://127.0.0.1:/tool_rental?sslmode=disable down 1 We will get the following output:\n20191101095831/d add_timestamps_to_tools_table (55.008948ms) This indicates that only the last migration was rolled back.\nIf the file has the correct spelling, what will happen? If we happened to have mismatched migration files - that is, the up file has the incorrect spelling of the field we are adding, but the down file has the correct spelling of the field - what happens if we try to migrate down?\nBEGIN; ALTER TABLE tools DROP COLUMN vendor; COMMIT; Running the down migration will result in an error:\nerror: 2 errors occurred: * migration failed: column \u0026#34;vendor\u0026#34; of relation \u0026#34;tools\u0026#34; does not exist in line 0: BEGIN; ALTER TABLE tools DROP COLUMN vendor; COMMIT; (details: pq: column \u0026#34;vendor\u0026#34; of relation \u0026#34;tools\u0026#34; does not exist) * pq: current transaction is aborted, commands ignored until end of transaction block in line 0: SELECT pg_advisory_unlock($1) Since vendor does not exist (since we misspelled it in the up file), our transaction is aborted. Let\u0026rsquo;s go into the down file and \u0026ldquo;fix\u0026rdquo; vendor and make it vender.\nBEGIN; ALTER TABLE tools DROP COLUMN vender; COMMIT; With the file corrected, we should be able run the down migration to undo our initial mistake.\n$ migrate -source file://migrations -database postgres://127.0.0.1:/tool_rental?sslmode=disable down 1 error: Dirty database version 20191025094406. Fix and force version. Unfortunately, this is not the case. Since we started a transaction that could not be completed, we are not able to start a new transaction, unless first rerun the force the migration using the force \u0026lt;version\u0026gt; flag, followed by running the down migration again.\n$ migrate -source file://migrations -database postgres://127.0.0.1:/tool_rental?sslmode=disable force 20191025094406 $ migrate -source file://migrations -database postgres://127.0.0.1:/tool_rental?sslmode=disable down 1 20191025093124/d add_vendor_to_tools_table (13.449248ms)  ℹ️ NOTE: You should always force the last successful migrated version.\n If you receive an error on an up migration, you should force the previous migrated version. If you receive an error when running a down migration, you should force the current migration version, since it last successfully migrated the up file for the same version.   Now it is safe to go in to both migration files, fix the misspelled field and run the up migration.\n$migrate -source file://migrations -database postgres://127.0.0.1:/tool_rental?sslmode=disable up 20191025095148/u add_vendor_to_tools_table (30.369855ms) Our table schema looks as intended, without errors:\npsql (11.4) Type \u0026#34;help\u0026#34; for help. tool_rental=# \\d tools Table \u0026#34;public.tools\u0026#34; Column | Type | Collation | Nullable | Default -------------+-----------------------+-----------+----------+-------------------- id | uuid | | | uuid_generate_v4() name | text | | not null | description | text | | not null | price | numeric(5,2) | | not null | quantity | integer | | not null | created | date | | not null | CURRENT_DATE updated | date | | not null | CURRENT_DATE vendor | character varying(50) | | not null | Triggers: update_tool_modtime BEFORE UPDATE ON tools FOR EACH ROW EXECUTE PROCEDURE update_updated_column() Using a Golang script to run migrations To incorporate migration functionality as part of a project, we are going to create a migrations.go file in the psql_migrations directory:\nThese additions will set up our database URL, creates our migration object and provide the functions for the various migration activities.\nAdd the golang-migrate packages to the import:\npackage psql import ( \u0026#34;database/sql\u0026#34; \u0026#34;fmt\u0026#34; migrate \u0026#34;github.com/golang-migrate/migrate/v4\u0026#34; _ \u0026#34;github.com/golang-migrate/migrate/v4/database/postgres\u0026#34; _ \u0026#34;github.com/golang-migrate/migrate/v4/source/file\u0026#34; _ \u0026#34;github.com/lib/pq\u0026#34; ) type MigrateDb struct{} //1 . Used to attach all of the migration functions, allowing us to call the function directly off of the MigrateDb instance.\nCreate a constructor called NewMigration to help create an instance of migrateDb.\ntype migrateDb struct { migration *migrate.Migrate } func NewMigration(host, port, user, password, dbname, sslmode, directory string) (m *migrateDb, err error) { fileDirectory := fmt.Sprintf(\u0026#34;file://%s\u0026#34;, directory) psqlInfo := fmt.Sprintf(\u0026#34;postgres://%s:%s@%s:%s/%s?sslmode=%s\u0026#34;, user, password, host, port, dbname, sslmode) m, err = migrate.New(fileDirectory, psqlInfo) if err != nil { return } return \u0026amp;migrateDb{m}, nil } The next set of functions take care of the individual migration task - migrating up, migrating down, migrating by steps, and migration by force.\nMigrateUp completes all of the up migrations.\nfunc (m migrateDb) MigrateUp() (err error) { err = m.migration.Up() return } MigrateDown completes all of the down migrations.\nfunc (m migrateDb) MigrateDown() (err error) { err = m.migration.Down() return } MigrateSteps takes in the number of steps to run the migration.\n A positive number will do an up migration by the specified number of steps. A negative number will do a down migration by the specified number of steps.  func (m migrateDb) MigrateSteps(steps int) (err error) { var direction string if steps \u0026gt; 0 { direction = \u0026#34;up\u0026#34; } else { direction = \u0026#34;down\u0026#34; } err = m.migration.Steps(steps) if err == nil { fmt.Printf(\u0026#34;Migration %s %v steps successful\u0026#34;, direction, steps) } return } ForceMigration takes in a Migrate instance and a version number and forces the database back to a clean state. It returns either a success string or error.\nfunc (m migrateDb) ForceMigration(version int) (err error) { err = m.migration.Force(version) if err == nil { fmt.Sprintf(\u0026#34;Force migration of %v successful\u0026#34;, version) } return } Implementation Once, a migration file has been created from the command line, the file can be migrated by the script.\nIn main.go in the main() function, we can create a new dbSetup instance and call the MigrateUp function.\nfunc main() { // --------- Credentials --------- \thost := os.Getenv(\u0026#34;DB_HOST\u0026#34;) port := os.Getenv(\u0026#34;PORT\u0026#34;) user := os.Getenv(\u0026#34;DB_USERNAME\u0026#34;) password := os.Getenv(\u0026#34;DB_PASSWORD\u0026#34;) dbname := os.Getenv(\u0026#34;DB_NAME\u0026#34;) sslmode := os.Getenv(\u0026#34;SSL_MODE\u0026#34;) directory := os.Getenv(\u0026#34;MIGRATION_DIRECTORY\u0026#34;) // Create the sourceFile and database URL \tm, err := NewMigration(host, port, user, password, dbname, sslmode, directory) if err != nil { log.Fatal(err) } success, err := m.MigrateUp(m) if err != nil{ log.Fatal(err) } else { fmt.Println(success) } } "
},
{
	"uri": "/golang/databases/",
	"title": "Databases",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Golang Database Workshop "
},
{
	"uri": "/cloud/containers/developing-with-docker/containerizing-your-application/debugging-docker/",
	"title": "Debugging Docker",
	"tags": [],
	"description": "",
	"content": "Concepts  Logging in Docker Checking Processes in Docker  Logging in Docker The docker logs command batch-retrieves logs present at the time of execution.\n$ docker logs \u0026lt;container-name\u0026gt; Log history is available even after the container exits, as long as its file system is still present on disk (until it is removed with docker rm).\nThe following docker container will be used for examples throughout the lesson:\ndocker run -d --name=date_test alpine /bin/sh -c \u0026quot;while true; do sleep 2; date; done\u0026quot;\nlog flags  **--details**: shows extra details like attributes, such as environment variables and labels, provided to container logs.  $ docker logs --details date_test  **--follow**: will continuously stream the new output from the container’s STDOUT and STDERR  $ docker logs --follow date_test Will show all logs contiously in real time.\n **--since**: shows only the container logs generated after a given date.  $ docker logs --since 10m date_test Will show all logs from the last 10 minute\n **--tail**: Number of lines to show from the end of the logs  $ docker logs --tail 2 date_test Will show the last 2 logs\n **--timestamps**: will add timestamps to logs  $ docker logs --timestamps date_test Will show all logs with a timestamp attached\n **--until**: shows logs before a timestamp  $ docker logs --until 20m date_test Will show all logs up until 20 minute prior to the current time\nChecking Processes in Docker Shell into a running container Overriding CMD in the docker run is a great way to shell into a running container, given some type of bash is installed in your container.\nType the following:\n$ docker run [options] \u0026lt;container-name\u0026gt; sh /working_directory/ $ Common flags and commands The following docker container will be used in the following examples:\ndocker run -d --name=date_test alpine /bin/sh -c \u0026quot;while true; do sleep 2; date; done\u0026quot;\n **attach**: to see what is written to stdout in real time  $ docker attach date_test Thu May 28 13:38:32 UTC 2020 Thu May 28 13:38:34 UTC 2020 TIP: The Docker documentation states that you can detach from a container and leave it running using the *CTRL-p CTRL-q* key sequence. But Docker\u0026rsquo;s read escape sequence (*CTRL-p CTRL-q*) will only work if the container also received the -i and -t flags. Update the docker run to docker run -dit --name=date_test alpine /bin/sh -c \u0026quot;while true; do sleep 2; date; done\u0026quot;\n **exec**: allows you to run arbitrary commands inside a running container  $ docker exec -it date_test sh / #  **pause** \u0026amp; **unpause**: pauses a container  $ docker pause date_test  **start** \u0026amp; **stop**: stop causes the process to exit. A stopped container is not returned by docker ps. An optional -t flag instructs the number of seconds before a container is killed. The default number of seconds the command will wait before the killing is 10 seconds.  $ docker start date_test $ docker stop date_test -t 5  **top**: display the running processes of a container.  $ docker top date_test PID USER TIME COMMAND 32233 root 0:00 /bin/sh -c while true; do sleep 2; date; done 32278 root 0:00 sleep 2  **inspect**: finds system-level information about docker containers and images  $ docker inspect date_test [ { \u0026#34;Id\u0026#34;: \u0026#34;df77ac1568a975be74acee4b77e336044b904aa7cc486f2726f9a1601b1cdfbf\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2020-05-28T13:38:18.6117862Z\u0026#34;, \u0026#34;Path\u0026#34;: \u0026#34;/bin/sh\u0026#34;, \u0026#34;Args\u0026#34;: [ \u0026#34;-c\u0026#34;, \u0026#34;while true; do sleep 2; date; done\\n\u0026#34; ], \u0026#34;State\u0026#34;: { \u0026#34;Status\u0026#34;: \u0026#34;running\u0026#34;, \u0026#34;Running\u0026#34;: true, \u0026#34;Paused\u0026#34;: false, \u0026#34;Restarting\u0026#34;: false, \u0026#34;OOMKilled\u0026#34;: false, \u0026#34;Dead\u0026#34;: false, \u0026#34;Pid\u0026#34;: 32233, \u0026#34;ExitCode\u0026#34;: 0, \u0026#34;Error\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;StartedAt\u0026#34;: \u0026#34;2020-05-28T13:41:00.6850121Z\u0026#34;, \u0026#34;FinishedAt\u0026#34;: \u0026#34;2020-05-28T13:39:01.0138834Z\u0026#34; }, \u0026#34;Image\u0026#34;: \u0026#34;sha256:f70734b6a266dcb5f44c383274821207885b549b75c8e119404917a61335981a\u0026#34;, ... ]  docker inspect --format '{{ .\u0026lt;key\u0026gt; }}' \u0026lt;container-name\u0026gt; is a fast way to grab a value from the JSON object returned from docker inspect. To retrieve the IP Address of this container we could simply type docker inspect --format '{{ .NetworkSettings.IPAddress }}'\n  **history**: display the history of an image  $ docker history alpine IMAGE CREATED CREATED BY SIZE COMMENT f70734b6a266 4 weeks ago /bin/sh -c #(nop) CMD [\u0026#34;/bin/sh\u0026#34;] 0B \u0026lt;missing\u0026gt; 4 weeks ago /bin/sh -c #(nop) ADD file:b91adb67b670d3a6f… 5.61MB ENTRYPOINT ENTRYPOINT configures a container that will run as an executable and allows you to specify a command with parameters. ENTRYPOINT command or parameters are not ignored when Docker container runs with command line parameters like CMD parameters.\nENTRYPOINT [\u0026#34;/bin/echo\u0026#34;, \u0026#34;Hello\u0026#34;] CMD [\u0026#34;world\u0026#34;] when container runs as docker run -it \u0026lt;image\u0026gt; will produce output\nHello world but when container runs as docker run -it \u0026lt;image\u0026gt; John will result in\nHello John The **--entrypoint** flag is used to override an entry point in Dockerfile In a Dockerfile ENTRYPOINT.\nGroup Exercise Problem: We need to run a container\u0026rsquo;s default program and execute other programs within that container\nSolution: Docker CLI\u0026rsquo;s exec -it command option.\nStart up a container and attach  **attach**: to see what is written to stdout in real time  $ docker run -dit --name=date_test alpine /bin/sh -c \u0026#34;while true; do sleep 2; date; done\u0026#34; 0fd0071fb525452eb0c8349ee4f755ba20ed45cf6dab18e90e5e1bbbebc4c3f7 $ docker attach date_test Fri Jun 5 16:33:49 UTC 2020 Fri Jun 5 16:33:51 UTC 2020 Fri Jun 5 16:33:53 UTC 2020 Fri Jun 5 16:33:55 UTC 2020 ... Open another terminal  By pressing CMD + t  Use the container ID or the container name to exec in the running container. $ docker exec -it date_test sh / # Test for curl within the shell / # curl sh: curl: not found / # Problem: curl isn\u0026rsquo;t installed in our container\nSolution: Add curl\n/ # apk add curl (1/4) Installing ca-certificates (20191127-r3) (2/4) Installing nghttp2-libs (1.41.0-r0) (3/4) Installing libcurl (7.69.1-r0) (4/4) Installing curl (7.69.1-r0) Executing busybox-1.31.1-r16.trigger Executing ca-certificates-20191127-r3.trigger OK: 7 MiB in 18 packages Use curl to test THD website / # curl https://www.homedepot.com/ ... Run top / # top Mem: 1104972K used, 933932K free, 992K shrd, 34504K buff, 673312K cached CPU: 0% usr 0% sys 0% nic 99% idle 0% io 0% irq 0% sirq Load average: 0.00 0.00 0.00 2/447 116 PID PPID USER STAT VSZ %VSZ CPU %CPU COMMAND 77 0 root S 1648 0% 2 0% sh 106 77 root R 1584 0% 3 0% top 1 0 root S 1572 0% 2 0% /bin/sh -c while true; do sleep 2; date; done 116 1 root S 1572 0% 1 0% sleep 2 Notice that the command /bin/sh -c while true; do sleep 2; date; done is PID 1. Your top or main command will always be PID 1\nExit the shell Exit the container.\n/ # exit A Best Practice: One Process Per Container Docker containers are meant to run a single process that is PID 1 inside the sandbox. Running multiple processes or spinning up a bunch of stuff in the background could stagger the systems meant to monitor or manage them.\nThe main benefit of running one process per container is that it’s easier to reason about the state of the container at run time. The container comes up when the process comes up and dies when it dies, and platforms like Docker Compose, kubernetes, and Amazon ECS can see that and restart it.\n Scaling containers horizontally is much easier if the container is isolated to a single function. Having a single function per container allows the container to be easily re-used for other projects or purposes. Portable \u0026amp; predictable for developers Patching/upgrades (both the OS and the application) can be done in a more isolated and controlled manner. Splitting functions out to multiple containers allows more flexibility from a security and isolation perspective. Simple testing  Lab In this lab you will take the container/image you worked on:\n in the previous lesson and in the Group Exercise from this lesson  \u0026amp; do the following debugging tasks in the terminal:\n Find out the number of processes running in container Shell into running container and curl The Home Depot website Find the IPAddress of running container Monitor the stdout of running container Output content from a file in your container to the terminal Run container \u0026amp; override the entry point and sh into your apps src folder Output the last 10 logged lines to a file in your containers app source folder called logs.txt  "
},
{
	"uri": "/javascript/foundations/labs/decisions-lab/",
	"title": "Decisions Lab",
	"tags": [],
	"description": "",
	"content": "Let\u0026rsquo;s write a Tip Calculator.\nStep 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch tip-calculator.js Add the following code to tip-calculator.js:\nconst amount = 45.00; const service = \u0026#39;great\u0026#39;; // service can be \u0026#39;great\u0026#39;, \u0026#39;good\u0026#39;, or \u0026#39;poor\u0026#39;  let tip = null; // TODO: add if, else if, and else to calculate the correct tip // for a service of \u0026#39;great\u0026#39; the tip should be 20% of the amount // for a service of \u0026#39;good\u0026#39; the tip should be 15% of the amount // for any other service the tip should be 10% of the amount  console.log(tip); // should print \u0026#34;9\u0026#34; for a service of \u0026#34;great\u0026#34; Step 2: Complete the code and test Complete the TODO in the above code.\nTest your solution with:\nnode tip-calculator.js The expected output is:\n 9 for \u0026ldquo;great\u0026rdquo; service 6.75 for \u0026ldquo;good\u0026rdquo; service 4.5 for any other value of service  "
},
{
	"uri": "/cloud/containers/developing-with-docker/int-testing/docker-compose/",
	"title": "Docker Compose",
	"tags": [],
	"description": "",
	"content": "Concepts  Describe how Docker Compose allows for connecting multiple containers (services) for intercommunication Explain the purpose of the docker-compose.ymlfile Write a docker-compose.yml file to define multiple services that can communicate Use the docker-compose command to start and stop services  Why Docker Compose? So what problem is docker-compose solving?\nRemember that a container should only hold one application or microservice that is self-contained. But often we have multiple services that work together to solve a problem. For example, in homedepot.com we could have a cart service, a tax service, and a product service. Each of these could be running in their own container.\nWhat We Have Learned So Far So far in this course we have seen how to:\n create volumes to persist data managed by a container containerize data sources create networks so that containers can communicate  What We Still Need What is missing is the ability to use a single file to define and configure all of the above. Thus we want to define all of the following in a single file:\n the services and their configuration the environment variables, volumes and networks for those services any dependencies between these services so they are started in the proper order  The Structure of a docker-compose.yml file A docker-compose.yml file has the following sections:\n version - specifies the version of the Compose file reference. services - specifies the services in your application. networks - specifies the networking configuration for your application. volumes - specifies the volumes used by your application.  A Simple Example Let\u0026rsquo;s start with a simple example of a static web page running in an nginx container.\nHere are the steps to get started:\n  Create a new directory where your source files, Dockerfile, and docker-compose.yml file will live\n  Create an index.html file, such as:\n  \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Docker Compose\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;http://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css\u0026#34;/\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;jumbotron\u0026#34; style=\u0026#34;text-align: center;\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;I\u0026#39;m running in a container!!!\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Create a Dockerfile with the following content:  FROMnginxCOPY index.html /usr/share/nginx/htmlCreate a docker-compose.yml file with the following content:  version: \u0026#39;3\u0026#39; # Docker Compose Formatting version services: my-website: build: . # specify the directory that contains the Dockerfile ports: - 3000:80 # binds external port 3000 to port 80 in the container Start up the container with docker-compose up -d - where -d means detached mode Test it with your browser or with curl: curl http://localhost:3000 Shut down the container with docker-compose down  NOTE: The docker-compose stop command will stop your containers, but it won\u0026rsquo;t remove them. The docker-compose down command will stop your containers, but it also removes the stopped containers as well as any networks that were created. You can add the -v flag to remove all volumes too.\nOf course we haven\u0026rsquo;t seen the real power of docker-compose until we have multiple services / containers. Let\u0026rsquo;s do that next.\nDefining Multiple Containers Let\u0026rsquo;s take a look at what a docker-compose.yml file would look like with multiple containers. We are going to use a NodeJS/Express app that connects to a MongoDB database.\nFirst we will need to clone down the code:\ngit clone https://github.homedepot.com/om-labs/docker-compose-demo cd docker-compose-demo You should get the following source files:\n├── .dockerignore ├── .gitignore ├── Dockerfile ├── README.md ├── docker-compose.yml ├── package-lock.json ├── package.json ├── server.js └── src/ ├── User.model.js └── connection.js The Dockerfile is for the NodeJS/Express application.\nThe MongoDB container will not need a custom Dockerfile as we will be using the official DockerHub mongo image for that container.\nHere are the contents of the docker-compose.yml file:\nversion: \u0026#34;3\u0026#34; services: web: build: . ports: - \u0026#34;8080:8080\u0026#34; depends_on: - mongo mongo: image: mongo Observations:\n we have 2 services: web and mongo the web service:  invokes a build using the current directory (where the Dockerfile exists) maps the host port 8080 to the container\u0026rsquo;s port 8080 depends on the mongo container (thus it will not start until that container has started)   the mongo service:  uses the mongo image (which will be downloaded from DockerHub) maps the host port 27017 to the container\u0026rsquo;s port 27017    Now with a single command we can download and build any required images and start the containers:\ndocker-compose up -d Then test it out by sending your browser to localhost:8080/users.\nYou can use docker ps to see the status of the containers:\ndocker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES fc0897453302 docker-compose-demo_web \u0026#34;docker-entrypoint.s…\u0026#34; 36 seconds ago Up 35 seconds 0.0.0.0:8080-\u0026gt;8080/tcp docker-compose-demo_web_1 1c6e87206bc8 mongo \u0026#34;docker-entrypoint.s…\u0026#34; 37 seconds ago Up 35 seconds 27017/tcp docker-compose-demo_mongo_1 Finally you can shutdown and remove the containers with:\ndocker-compose down Common Docker Compose CLI Commands: Some of the common CLI commands are:\n docker-compose build - builds any services specified in the compose file having a build config docker-compose up - start services docker-compose stop - stop services docker-compose down - stop and remove containers, networks, images, and volumes  You can see all of the commands by running docker-compose help.\nEnvironment Variables One issue with the previous example is that the ports are hard-coded both in the docker-compose.yml file and in the source code for the NodeJS/Express app (the port that it uses to connect to MongoDB).\nLet\u0026rsquo;s externalize that port number into an environment variable defined in an external file.\nFirst create the file app.env with the contents:\nMONGO_PORT=27017 Then modify the docker-compose.yml file and add the env_file setting to the web service as shown below:\nversion: \u0026#34;3\u0026#34; services: web: build: . ports: - \u0026#34;8080:8080\u0026#34; env_file: app.env depends_on: - mongo mongo: image: mongo Finally edit the file src/connection.js and change the line for the mongo connection from:\nconst connection = \u0026#34;mongodb://mongo:27017/mongo-test\u0026#34;; to:\nconst connection = \u0026#34;mongodb://mongo:\u0026#34; + process.env.MONGO_PORT + \u0026#34;/mongo-test\u0026#34;; Now start the services with:\ndocker-compose up --build -d And test it out by sending your browser to localhost:8080/users.\nNetworks  docker-compose will create a default network for communication between containers. If you want more control over network configuration, you can specify your own networks with the top-level networks key.  We can add a custom network to the above example as follows:\nversion: \u0026#34;3\u0026#34; networks: my-network: external: false services: web: build: . networks: - my-network ports: - \u0026#34;8080:8080\u0026#34; env_file: app.env depends_on: - mongo mongo: image: mongo networks: - my-network Be sure to add the same network to both services if you want them to be able to communicate.\nYou can read more about this in the networks lesson.\nSummary In this lesson we learned that:\n A docker-compose.yml file can configure multiple containers with a single file and define dependencies between the services. Environment variables, volumes and networks can be configured in the docker-compose.yml file. The docker-compose command can be used to start and stop the containers and networks.  Resources  YouTube: Docker Compose in 12 minutes Docker Docs on Compose Docker compose tutorial for beginners by example  Final Lab The final lab for this course is at: Testing with Docker.\n"
},
{
	"uri": "/react/foundations/labs/lab-events/",
	"title": "Events",
	"tags": [],
	"description": "",
	"content": "Lab - Build a Simple TODO App Use create-react-app to create a TODO app with the following:\n a Container component called TodoApp that has an array of TODO objects and renders a text input for adding new TODOs. A Presentation component called Todo that is stateless and simply renders a todo object including a toggle button and a delete button.  The TodoApp component should pass the following props to the Todo component:\n the todo object an onToggle callback an onDelete callback  The TodoApp itself is responsible for displaying the input element and providing the \u0026ldquo;new todo\u0026rdquo; functionality. But as a bonus you could move this into a separate \u0026ldquo;NewTodo\u0026rdquo; component with a callback for onAdd.\nHere is a screenshot of a typical TODO app but feel free to be creative with it:\n  Hints For the text input, you can make the \u0026lt;input\u0026gt; element auto-submit on an Enter key press by wrapping it in a \u0026lt;form\u0026gt;. For example:\n\u0026lt;form\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Enter todo\u0026#34; onKeyDown={onKeyPress} /\u0026gt; \u0026lt;/form\u0026gt; Here is the code for onKeyPress:\nfunction onKeyPress(e) { if (e.keyCode === 13) { // 13 is the `Enter` key  e.preventDefault() // prevents the form from posting to the server and reloading the page  onAdd(e.target.value) // call the callback function with the text from the input element  e.target.value = \u0026#39;\u0026#39; // clear the input element text field  } } In a future lesson we will look at other techniques for managing input elements.\n"
},
{
	"uri": "/java/foundations/expressions/",
	"title": "Expressions",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts \u0026amp; Skills  Declaring variables Arithmetic expressions and operator precedence String expressions Logic expressions  Keyword: final The modifier final makes a variable immutable which means that once it has been assigned, it cannot be reassigned.\n IMPORTANT Reassignment is different from modification.\n public final int MAX_VALUE = 123456789123; MAX_VALUE = 10; // NOT ALLOWED This is useful if you know that a particular variable should not be reassigned. Simply declare it as final and you can be assured that no matter what else happened, the value of the variable will be the same.\nNaming Conventions When naming variables, there are a few requirements and conventions to keep in mind.\n Should begin with a letter Should be descriptive, but not wordy int i vs int maxCount  code should be readable, understood by people who are not you   Standard variables use \u0026lsquo;lower camel case\u0026rsquo;, i.e. myVariableName Final variable use \u0026lsquo;snake case\u0026rsquo; with all caps, i.e. MY_FINAL_VARIABLE  Operations Operations involving primitive types look (more or less) like normal arithmetic. Without knowing Java, you can probably follow this\u0026hellip;\nint i = 5; // i = 5 int j = 10; // j = 10 i = i + 1;\t// i = 6 j = j / i;\t// j = 1 j = j - 12;\t// j = -11 See the output!\nIMPORTANT\nWhy is 10 / 6 not 1.66666667?\nWhat if we wanted it to be more precise?\n Operation Practice\nOperation Shortcuts  i = i + 1 is the same as:  i += 1 i++ (only true when adding 1)   j = j / 10 is the same as j /= 10  Concatenation Strings can also use the +. When a + is used with a String, this is called concatenation, the joining of Strings end-to-end.\nString s1 = \u0026#34;xyz\u0026#34;; String s2 = \u0026#34;abc\u0026#34;; String s3 = s1 + \u0026#34; \u0026#34; + s2; System.out.println(s3); // \u0026#34;xyz abc\u0026#34; This can be done with a mix of other types. As long as a String is present, the result will be all of the values concatenated.\nString s1 = \u0026#34;xyz\u0026#34;; int i1 = 100; String s3 = s1 + \u0026#34; \u0026#34; + i1; System.out.println(s3); // \u0026#34;xyz 100\u0026#34; Order of Operations Java does follow an order of operations, very much like you learned in math. (Remember PEMDAS?)\nOrder of Operations Chart\nLogical Expressions Logic expressions are used when you need to evaluate one or more variables. Most of you will have experience with these (at least from middle school if not since then), so we won\u0026rsquo;t cover most them.\n \u0026lt; and \u0026lt;= \u0026gt; and \u0026gt;=  On primitives, these work as you would expect. You can probably guess what 1 \u0026lt; 2 evaluates to. But similar to arithmetic expressions, Java is not equipped to handle comparing Objects by default. What makes one bike greater than another?\nLogical Expression Practice\nSummary Basic arithmetic and assignment expressions in Java, while similar to other languages, have some important differences. The strongly-typed nature of the language means expressions are verbose and specific. It is important to declare exactly what you need and where otherwise you could run into compile issues; the Java compiler must know what is happening in every scenario otherwise it cannot optimize the runtime as it needs.\n"
},
{
	"uri": "/javascript/foundations/expressions/",
	"title": "Expressions",
	"tags": [],
	"description": "",
	"content": "How to write numeric and boolean expression in JavaScript.\nExpressions and Statements  Expressions can be evaluated to produce a value, for example: x + 5 Statements perform actions and do not produce a value, for example console.log(x)  Numeric Operations JavaScript\u0026rsquo;s numeric operators are:\n addition: + subtraction: - multiplication: * division: / remainder: %  let x = 3; let y = 4; const sum = x + y; // 7 const diff = x - y; // -1 const product = x * y; // 12 const div = x / y; // 0.75 const rem = x % y; // 3 Exponents can be expressed using Math.pow().\nlet x = Math.pow(3, 4); // 81 Operators have a precedence (just like we learned in grade school). The precedence is:\n parentheses: () *, /, % +, -  This can be remembered by the mnemonic PeMDAS (Parentheses, Multiplication, Division, Addition, Subtraction).\nExpressions are evaluated from higher to lower precedence and then from left to right. For example:\nlet x = 3 + 4 * 5 / 2 - 1; will be evaluated as:\n3 + ( (4 * 5) / 2 ) - 1 // multiplication and division first (evaluated ltr)  3 + ( (20 / 2 ) - 1 3 + 10 - 1 // addition and subtraction last (evaluated ltr)  13 - 1 12 What is the output of the following code?\nlet x = 5; let y = 3; let result = 2 + x * (x + 1) / y - 3; console.log(result); Try it in your browser to confirm your answer.\nShorthand Assignment Statements There are shorthand assignment statements such as += and -= that extend out to x = x \u0026lt;operator\u0026gt; y.\nlet x = 3; let y = 4; x += 10; // 13 (equivalent to x = x + 10) y *= 2; // 8 (equivalent to y = y * 2) Boolean Expressions   A boolean value can be either true or false.\n  Boolean values can be combined using the logical operators \u0026amp;\u0026amp; (\u0026ldquo;and\u0026rdquo;) and || (\u0026ldquo;or\u0026rdquo;).\n  The boolean ! (\u0026ldquo;not\u0026rdquo;) operator will invert the boolean value.\n  The order of boolean operator precedence is:\n ! \u0026amp;\u0026amp; ||    let a = 3; let b = 5; let c = -12; let x = a \u0026lt; b; // true let y = c \u0026gt; 0; // false  !x // false x \u0026amp;\u0026amp; y // false x || y // true x \u0026amp;\u0026amp; !y // true Lab See instructions here.\nSummary  JavaScript provides the standard mathematical and boolean operators. JavaScript operator precedence follows the PeMDAS mnemonic - parentheses, multiplication, division, addition, subtraction.  "
},
{
	"uri": "/cyber-security/static-dynamic-analysis/4-fortify/",
	"title": "Fortify SSC Overview",
	"tags": [],
	"description": "",
	"content": "Fortify Software Security Center is the central hub for viewing scan results and beginning the triage process. It allows us to see static, dynamic, and open source scans all in one place.\n  Login using Single Sign-On (SSO). Uses production LDAP credentials.\n    After logging into Fortify you will see a list of onboarded applications and some details about each one. You can click on an application to view the scan results for that project.\n    Upon clicking the application you will be able to view the scan results. Each highlighted section provides details about the scan results.\n1. Issue count and severity: shows the number of issues and their severity. Focus on critical and high severity issues first.\n2. Vulnerability category: Displays the type of vulnerability or the related CVE number, depending on the type of scan. For more details, review the Triage chapter of this course.\n3. Primary location: Shows the name of the file in question.\n4. Analysis type: \u0026ldquo;WHITESOURCE\u0026rdquo; is third-party library analysis, SCA here stands for Source Code Analysis and indicates standard static analysis from Fortify.*\n5. Criticality: Criticality indicates the severity of the given issue. As a rule, prioritize higher criticality results, but note that they were determined in an automated fashion and may not be perfect so also use your better judgement.\n6. Disposition: After reviewing the results you will manually disposition them. For more details, review the Triage chapter of this course.\n*Note that SCA can stand for either Software Composition Analysis, performed by Whitesource, or Source Code Analysis in Fortify, which is static analysis.\n"
},
{
	"uri": "/application-security/api-security/02_human_to_service_oidc/50_full_architecture/",
	"title": "Full Architecture",
	"tags": [],
	"description": "",
	"content": "Putting together the OIDC + OAuth2 "
},
{
	"uri": "/python/web-framework/django_generic_views/",
	"title": "Generic Views",
	"tags": [],
	"description": "",
	"content": "Less code is better The stores() view is very simple – and, as mentioned above, redundant. The index() view, which displays a list of markets, is similar.\nThese views represent a common case of basic Web development: getting data from the database according to a parameter passed in the URL, loading a template and returning the rendered template. Because this is so common, Django provides a shortcut, called the “generic views” system.\nGeneric views abstract common patterns to the point where you don’t even need to write Python code to write an app.\nLet’s convert our location app to use the generic views system, so we can delete a bunch of our own code. We’ll just have to take a few steps to make the conversion. We will:\n Convert the URLconf. Delete some of the old, unneeded views. Introduce new views based on Django’s generic views.  Read on for details.\n ####Why the code-shuffle?\nGenerally, when writing a Django app, you’ll evaluate whether generic views are a good fit for your problem, and you’ll use them from the beginning, rather than refactoring your code halfway through. But this tutorial intentionally has focused on writing the views “the hard way” until now, to focus on core concepts. You should know basic math before you start using a calculator.\n Amend URLconf First, open the locations/urls.py URLconf and change it like so:\nfrom django.urls import path from . import views app_name = \u0026#39;locations\u0026#39; urlpatterns = [ path(\u0026#39;\u0026#39;, views.IndexView.as_view(), name=\u0026#39;index\u0026#39;), path(\u0026#39;\u0026lt;int:pk\u0026gt;/\u0026#39;, views.StoresView.as_view(), name=\u0026#39;market\u0026#39;) ]  Note that the name of the matched pattern in the path strings of the second and third patterns has changed from \u0026lt;mkt_num\u0026gt; to \u0026lt;pk\u0026gt;.\n  Amend Views Next, we’re going to remove our old index, and stores views and use Django’s generic views instead. To do so, open the locations/views.py file and change it like so:\nfrom django.http import HttpResponseRedirect, HttpResponse from django.urls import reverse from django.views import generic from django.shortcuts import get_object_or_404, render from .models import Market class IndexView(generic.ListView): template_name = \u0026#39;locations/index.html\u0026#39; context_object_name = \u0026#39;market_list\u0026#39; #we now have a variable called market_list that our template can use def get_queryset(self): \u0026#34;\u0026#34;\u0026#34;Return the last five saved markets.\u0026#34;\u0026#34;\u0026#34; return Market.objects.order_by(\u0026#39;name\u0026#39;)[:5] class StoresView(generic.DetailView): model = Market template_name = \u0026#39;locations/stores.html\u0026#39; We’re using two generic views here: ListView and DetailView. Respectively, those two views abstract the concepts of “display a list of objects” and “display a detail page for a particular type of object.”\n Each generic view needs to know what model it will be acting upon. This is provided using the model attribute. The DetailView generic view expects the primary key value captured from the URL to be called \u0026ldquo;pk\u0026rdquo;, so we’ve changed mkt_num to pk for the generic views.  By default, the DetailView generic view uses a template called \u0026lt;app name\u0026gt;/\u0026lt;model name\u0026gt;_detail.html. In our case, it would use the template locations/market_detail.html. The template_name attribute is used to tell Django to use a specific template name instead of the autogenerated default template name. We also specify the template_name for the results list view – this ensures that the results view and the stores view have a different appearance when rendered, even though they’re both a DetailView behind the scenes.\nSimilarly, the ListView generic view uses a default template called \u0026lt;app name\u0026gt;/\u0026lt;model name\u0026gt;_list.html; we use template_name to tell ListView to use our existing locations/index.html template.\nIn previous parts of the tutorial, the templates have been provided with a context that contains the market and market_list context variables. For DetailView the market variable is provided automatically – since we’re using a Django model (Market), Django is able to determine an appropriate name for the context variable. However, for ListView, the automatically generated context variable is market_list. To override this we provide the context_object_name attribute, specifying that we want to use market_list instead. As an alternative approach, you could change your templates to match the new default context variables – but it’s a lot easier to just tell Django to use the variable you want.\nExample of context variables:\nclass IndexView(generic.ListView): template_name = \u0026#39;locations/index.html\u0026#39; context_object_name = \u0026#39;market_list\u0026#39; #is the same as context = { \u0026#34;market_list\u0026#34;: markets_json } # The latter is a method used to pass in multple variable to a template Run the server, and use your new locationing app based on generic views.\nThere are many Django generic view templates to choose from see them all on this tutorial\nFor full details on generic views, see the generic views documentation.\n APIs, POST \u0026amp; GET Let\u0026rsquo;s say we wanted to access the Flask API we built in a previous lesson with our Django Application.\nExample:\nfrom django.http import HttpResponseRedirect, HttpResponse from django.urls import reverse, resolve from django.views import generic from django.shortcuts import get_object_or_404, render, redirect from .models import Market import requests ... def todoAPI(request, **kwargs): api_url= \u0026#34;https://flaskapiex.apps-np.homedepot.com/todo/api/v1.0/tasks\u0026#34; response = requests.get(api_url) print(response) print(response.content) return HttpResponse(response.content)  Notice we added a new package requests\n Since we are just returning a JSON object we do not need to create a template for this view.\nDon\u0026rsquo;t forget to modify the locations/urls.py file:\n#locations/urls.html ... urlpatterns = [ path(\u0026#39;\u0026#39;, views.IndexView.as_view(), name=\u0026#39;index\u0026#39;), path(\u0026#39;todo/\u0026#39;, views.todoAPI, name=\u0026#39;todo_api\u0026#39;), path(\u0026#39;\u0026lt;int:pk\u0026gt;/\u0026#39;, views.StoresView.as_view(), name=\u0026#39;stores\u0026#39;) ] Now visit http://127.0.0.1:8000/locations/todo/\nGroup Exercise djangosfstarter.apps-np.homedepot.com/locations/todo/1\n Django def get() \u0026amp; def post() To add post and get functionality to a generic view we will use get() and post() methods.\nDjango will automatically know to add POST or GET response capabilities to the class when you create these subclass methods.\nIf one method but not the other one is defined a request to the non defined method will result in a HttpResponseNotAllowed :\nfrom django.shortcuts import render class IndexView(generic.DetailView): template_name=\u0026#34;locations/index.html\u0026#34; #if this is just a get request then this method will run def get(self, request, *args, **kwargs): print(\u0026#34;args--\u0026gt;\u0026#34;, args) #prints any args passed in print(\u0026#34;kwargs--\u0026gt;\u0026#34;, kwargs) #prints any kwargs passed in print(\u0026#34;request dictionary--\u0026gt;\u0026#34;, request.GET) #prints any get parameters context = {...} return render(request, self.template_name, context) #if a POST action is submitted by a form this method will run  def post(self, request, *args, **kwargs): print(\u0026#34;args--\u0026gt;\u0026#34;, args) #prints any args passed in print(\u0026#34;kwargs--\u0026gt;\u0026#34;, kwargs) #prints any kwargs passed in print(\u0026#34;request dictionary--\u0026gt;\u0026#34;, request.POST) #prints any posted parameters context = {...} return render(request, self.template_name, context)  django.shortcuts.render() render combines a given template with a given context dictionary and returns an HttpResponse object with that rendered text\nRequired arguments  request The request object used to generate this response. template_name\nThe full name of a template to use or sequence of template names. If a sequence is given, the first template that exists will be used. See the template loading documentation for more information on how templates are found.  Optional arguments  context\nA dictionary of values to add to the template context. By default, this is an empty dictionary. If a value in the dictionary is callable, the view will call it just before rendering the template. content_type\nThe MIME type to use for the resulting document. Defaults to the value of the DEFAULT_CONTENT_TYPE setting. status\nThe status code for the response. Defaults to 200. using\nThe NAME of a template engine to use for loading the template.  Final edited code from django.http import HttpResponse from django.urls import reverse from django.views import generic from django.shortcuts import render import json, requests from .models import Market class IndexView(generic.DetailView): template_name = \u0026#39;locations/index.html\u0026#39; def get(self, request, *args, **kwargs): print(\u0026#34;args--\u0026gt;\u0026#34;, args) print(\u0026#34;kwargs--\u0026gt;\u0026#34;, kwargs) print(\u0026#34;request dictionary--\u0026gt;\u0026#34;, request.GET) market_list = Market.objects.order_by(\u0026#39;name\u0026#39;)[:5] context = {\u0026#39;market_list\u0026#39;:market_list} return render(request, self.template_name, context) #standalone api view def todoAPI(request, **kwargs): print(kwargs, request.GET) api_url= \u0026#34;https://flaskapiex.apps-np.homedepot.com/todo/api/v1.0/tasks\u0026#34; response = requests.get(api_url) if \u0026#39;task_num\u0026#39; in kwargs: api_url = api_url + \u0026#34;/\u0026#34; + kwargs[\u0026#39;task_num\u0026#39;] response = requests.get(api_url) print(response.content) return HttpResponse(response.content) else: return HttpResponse(response.content) class StoresView(generic.DetailView): model = Market template_name = \u0026#39;locations/stores.html\u0026#39;  Django REST Framework There are multiples ways to add RESTful services to your Django app, [Django Rest Framework] (http://www.django-rest-framework.org/api-guide) is a popular way.\n"
},
{
	"uri": "/software-eng-essentials/git-pillars/cherry-pick/",
	"title": "Git Cherry Pick",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Isolate a diff from a specific commit Play that diff onto a current branch  Scenario If you are working on a feature branch of a product and someone creates a fixbug or hotfix to fix a bug in production, your feature branch will need to bring in that bug fix as well.\nIt is possible to merge production to the feature branch once fixbug is merged into production, but this could bring in some additional changes we do not currently want.\nA merge takes all changes from the other branch and plays them onto your current branch. This can be huge and this can cause conflicts.\nCherry Pick A cherry pick allows us to bring specific changes from a single commit. This allows for us to just bring in a hotfix or a fixbug into our branch and keep working without having to worry about what other commits may do to your branch.\nRun git cherry-pick \u0026lt;SHA1\u0026gt; to do a cherry pick.\n The commit you are cherry picking doesn\u0026rsquo;t even have to be from a different branch but in normal usage it would be.\n git log --graph --oneline --all shows a graphic of the branches in our terminal shell. This can help one see if there are some big changes that your current branch might be missing.\nSo if you see an output similar to the following in your repo, you might want just want to pull in the bug fix to your branch.\n* 1bc6135 (master, bug-fix) Adds emergency bug fix * 4dfa271 Adds external imports | * 395b058 (HEAD -\u0026gt; feature1) Adds more to feature 1 | * edc9934 Initial commit for feature1 |/ * d9ecac7 Updates main function * 37c7ed9 Initial commit To start the process of cherry picking the bug fix, make sure to checkout the feature branch.\nBy running git cherry-pick with the shorthand hash we get the object introduced with that commit:\n$ git cherry-pick 1bc6135 This would give an output similar to:\n[feature1 b76a840] Adds emergency bug fix Date: Tue Aug 31 14:26:33 2021 -0500 1 file changed, 1 insertion(+) Then we inspect the file and see that it worked!\nDiscover the Pick!\n"
},
{
	"uri": "/software-eng-essentials/git-pillars/cherry-lab/",
	"title": "Git Cherry Pick Lab",
	"tags": [],
	"description": "",
	"content": "The Setup  Work in the same repo as the filter practice: https://github.com/one-thd/om_labs_git-filter.git Run your favorite log to find the commit from fixbug1 that fixes bug 1. Checkout feature1 and inspect the contents Pick that commit onto the feature branch (you can actually copy and paste the SHA1 to save typing) Inspect the contents again to see what changed  Extension  Do a cherry pick from any commit you like but run it with a --edit and try to add a commit message to the pick Do a cherry pick on the commit with the message \u0026lsquo;adds code to fix bug2\u0026rsquo; take note of the following  What happens? Why do you think this happens? How can you move forward with the cherry pick?    "
},
{
	"uri": "/software-eng-essentials/git-foundations/git-setup/",
	"title": "Git set up",
	"tags": [],
	"description": "",
	"content": "Getting Started Before we can work with git, you first have to make sure you have git.\nIn your terminal type:\ngit --version If git is installed you should see something like this:\ngit version 2.x.x If git isn\u0026rsquo;t installed, place the following into your terminal:\ngit clone https://github.com/git/git We will discuss what the git clone command does later.\nConfiguring your credentials It is possible to configure credentials for git globally and inside each project directory.\nThe following steps will show how to configure credentials globally for the current git user name, email address, and default editor.\nOpen keychain access (cmd+ spacebar \u0026ldquo;keychain access\u0026rdquo;), search for github and delete\nType the following:\ngit config --global --list This will list all of the current configurations.\n This might give you an error message. If so, just skip the next two commands.\n git config --global --unset user.name git config --global --unset user.email For the following two commands, replace John Doe with your corresponding credentials:\ngit config --global user.name \u0026#34;John Doe\u0026#34; git config --global user.email johndoe@homedepot.com Text editor git sometimes need the user to type in a message to finish a command. The default location for the user to type the message is vi. If you enjoy vi, no need to set anything up!\nIf you are not comfortable with vi, you can override the default with the following command:\n Set up with VS code: git config --global core.editor \u0026quot;code --wait\u0026quot; Set up with atom: git config --global core.editor \u0026quot;atom --wait\u0026quot;  Now that the configurations have been set up, list them with:\ngit config --global --list This command should list off the configurations that were set up above.\nCreate a directory called git-workshop\nAll of the work done in this workshop should be created and maintained in this folder.\n"
},
{
	"uri": "/software-eng-essentials/git-pillars/git-setup/",
	"title": "Git set up",
	"tags": [],
	"description": "",
	"content": "Getting Started Before we can work with git, you first have to make sure you have git.\nIn your terminal type:\ngit --version If git is installed you should see something like this:\ngit version 2.x.x If git isn\u0026rsquo;t installed, place the following into your terminal:\ngit clone https://github.com/git/git We will discuss what the git clone command does later.\nConfiguring your credentials It is possible to configure credentials for git globally and inside each project directory.\nThe following steps will show how to configure credentials globally for the current git user name, email address, and default editor.\nOpen keychain access (cmd+ spacebar \u0026ldquo;keychain access\u0026rdquo;), search for github and delete\nType the following:\ngit config --global --list This will list all of the current configurations.\n This might give you an error message. If so, just skip the next two commands.\n git config --global --unset user.name git config --global --unset user.email For the following two commands, replace John Doe with your corresponding credentials:\ngit config --global user.name \u0026#34;John Doe\u0026#34; git config --global user.email johndoe@homedepot.com Text editor git sometimes need the user to type in a message to finish a command. The default location for the user to type the message is vi. If you enjoy vi, no need to set anything up!\nIf you are not comfortable with vi, you can override the default with the following command:\n Set up with VS code: git config --global core.editor \u0026quot;code --wait\u0026quot; Set up with atom: git config --global core.editor \u0026quot;atom --wait\u0026quot;  Now that the configurations have been set up, list them with:\ngit config --global --list This command should list off the configurations that were set up above.\nCreate a directory called git-workshop\nAll of the work done in this workshop should be created and maintained in this folder.\n"
},
{
	"uri": "/golang/foundations/variables/",
	"title": "Go Variables",
	"tags": [],
	"description": "",
	"content": "Go Variables Learning Objectives Concepts  Variable Declarations Short Variable Declarations Constants Multiple Variables Scope Type Definitions  Skills  Defining variables for given types Using variables in place of literals Be able to cleanly define multiple variables Get a basic understanding of scope in Go  Variables Basics There are a few basic rules that must be followed when using a variable in go:\n The type must be declared for any given name. Once a type is declared, that name cannot be converted to another type. Any function or below scoped declared variable must be used or you cannot compile. Names can contain:  letters (any case) numbers(other than the first character) underscore _ character.    Syntax of a variable:\n[var|const] \u0026lt;name\u0026gt; \u0026lt;type\u0026gt; Declaration\nvar thing string Assignment\nthing = \u0026#34;Oh happy days\u0026#34; All together:\nvar thing string thing = \u0026#34;Oh happy days\u0026#34; or\nvar thing string = \u0026#34;Oh happy days\u0026#34; Type Inferring\nvar thing = \u0026#34;Oh happy days\u0026#34;  The type of thing is a string, because the value is a string  Examples: package main import \u0026#34;fmt\u0026#34; func main() { var thing string var number int var floatnumber float64 var didYouHaveToLookUpPi bool thing = \u0026#34;Look, look, look at me! I\u0026#39;m, I\u0026#39;m, I\u0026#39;m a tree!\u0026#34; number = 42 floatnumber = 3.14 didYouHaveToLookUpPi = true fmt.Println(thing) fmt.Println(number) fmt.Println(floatnumber) fmt.Println(didYouHaveToLookUpPi) } Try Me\nShort Variable Declaration Introducing the := operator Syntax of a short variable declaration:\n\u0026lt;name\u0026gt; := \u0026lt;value\u0026gt; Short variable rules:\n A value has to be assigned at declaration. The type will then always be the type of the value of the supplied to the right of the := At least one variable on the left, must be new to that block of code Only usable at the function or below blocks  Short variable Assignment: thing := \u0026#34;Oh happy days\u0026#34; Example of short declaration: package main import \u0026#34;fmt\u0026#34; func main() { thing := \u0026#34;Look, look, look at me! I\u0026#39;m, I\u0026#39;m, I\u0026#39;m a tree!\u0026#34; number := 42 floatnumber := 3.41 didYouHaveToLookUpPi := false fmt.Println(thing) fmt.Println(number) fmt.Println(floatnumber) fmt.Println(didYouHaveToLookUpPi) } Try Me\nNo new variables error: thing := \u0026#34;Oh happy days\u0026#34; thing := \u0026#34;Not a new thing!\u0026#34; will result in a compile error: no new variables on left side of :=\nMultiple Values and Declarations. Go also supports declaring and assigning values to a variable on one line. Names get assigned types and values from left to right on either side of the =\npackage main import \u0026#34;fmt\u0026#34; var i, j int = 1, 2 // 1 var k, l = \u0026#34;abc\u0026#34;, \u0026#34;def\u0026#34; // 2 var (\t// 3  x,y,z=\u0026#34;x\u0026#34;,1,2.34 whyNotAddAnotherHere = \u0026#34;Because I can\u0026#34; ) func main() { var c, python, java = true, -1, \u0026#34;no!\u0026#34; // 4 \td,e,f,g := \u0026#34;c\u0026#34;, 1, false, 1.2 // 5  fmt.Println(i, j, c, python, java) fmt.Println(d,e,f,g) } Code explanation:\n 2 Package level variables assigned as an int 2 Package level variables, with the types inferred by the values Mix of package level declaration types inside of ( ) 3 Function level variables, with 3 different types on the right. Demonstrate using the shorthand := operator to assign values of various types.  Constants What is a constant?   Constants are variables that cannot have their value changed after declaration\n  Must be assigned a value when declared.\n  const z = 2 Creates a constant named z.\n  z will always have a value of 2.\n  Lab 1 - Declare and use Variables Part 1:\nUsing your own file, or a goplay.space:\n Create 2 integers and print them Create 2 float64 and print them Create 2 strings and print them Create a variable that is the sum of the two integers and print it. Create a variable that is the sum of the two floats and print it. Concatenate the 2 strings into a new variable and print it.  Part 2:\nTry different variations of declaring the variables. Some ideas to try:\n All numbers on one line Everything on one line Outside the main  Scope Scope defines where a variable is able to be accessed.\nCode Blocks func main(){ x := 1 // 1 \t{ // 2 \ty := 2 fmt.Println(x) } fmt.Println(y) // 3 }  Variable declared in the function block. Anonymous block that declares the variable y. Function block that attempts to print y.  Try It!\nPackage Block Scope The package block is anything after the import statement.\npackage main import \u0026#34;fmt\u0026#34; // Package block var packageVariable = \u0026#34;Hi\u0026#34; The packageVariable is declared in the package block, therefore it is able to be accessed everywhere in the package.\nFunction Block Scope package main import \u0026#34;fmt\u0026#34; // Package block var packageVariable = \u0026#34;Hi\u0026#34; func main() { // Start of the function block \t// function block \tx := \u0026#34;c\u0026#34; fmt.Println(packageVariable, \u0026#34;-\u0026#34;, x) } Try Me\nOther Scopes Other scope access covered later:\n loops control statements ( if/switch)  Type Definitions  Custom types can be defined using the type keyword. The type will maintain the underlying type as its type and operations, but bind it to the identifier.  Example type Declaration: // Define a solo new type. type NewTypeName SourceType // Define multiple new types together. type ( NewTypeName1 SourceType1 NewTypeName2 SourceType2 ) Use case for custom type:\ntype TimeZone int var x TimeZone x = 5  the new defined type and the source type will share the same underlying type (see below for what are underlying types), and their values can be converted to each other. types can be defined within any block  Other Use Cases\n Defining structs Defining interfaces  "
},
{
	"uri": "/javascript/nodejs/advanced/express-and-bookshelf/knex-quick-reference/",
	"title": "Knex Quick Reference",
	"tags": [],
	"description": "",
	"content": "Knex Commands\n   Command Description     knex \u0026ndash;help Print the Knex CLI help message   knex init Create a new knexfile.js for configuring how to connect to your project databases.   knex migrate:make  Create a new knex migration script.   knex migrate:latest Run all of the migration scripts that have not yet been run on a specific DB.   knex migrate:rollback Rollback the last set of migrations performed.   knex migrate:currentVersion View the current version for the migration.   knex seed:make  Create a named seed file.   seed:run Run seed files.    Options for Knex Commands\n   Option Description     \u0026ndash;debug Run with debugging.   \u0026ndash;knexfile [path] Specify the knexfile path (needed if path different than current directory).   \u0026ndash;cwd [path] Specify the working directory.   \u0026ndash;env [name] Specify the environment (which determines which DB to connect to). default: process.env.NODE_ENV \\|\\| development    "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/navigating-file-system/",
	"title": "Navigating the File System",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  What is a file system Understanding Files and Directories Relative and Absolute Paths The Home Directory and Getting Home The pwd command Listing directory contents with the ls command  What is The File System?   Your computer has a file system where all of your files are stored. These files are organized into directories (sometimes called subdirectories or folders).\nThis lesson is an introduction into the concepts and commands needed to manage the files and directories in your computer\u0026rsquo;s file system.\n NOTE: In this lesson we are focusing on UNIX based file systems which include the file systems you will encounter on MacOS, Linux, and other flavors of the UNIX operating system. While the Windows file system differs in some ways (particularly the file system management commands and the file and directory permissions), many of the concepts are similar.\n Directories The file system is organized into a set of directories (also called folders). Each of these directories can contain files or (sub) directories, forming a tree structure of parent, child, and grandchild directories, etc.\nExample Directory Structure:\n. └── Users ├── homer │ ├── Applications │ │ └── Chrome │ │ └── VSCode │ ├── Desktop │ │── Documents │ │ └── Resume.pages │ │ └── Resume.pdf │ ├── Music │ └── Pictures │ └── 2017 │ │ └── pic1.jpg │ │ └── pic2.png │ │ └── pic3.gif │ └── 2018 │ │ └── pic4.png │ │ └── pic5.png │ │ └── pic6.jpg │ └── 2019 │ │ └── lol-cat1.jpg │ │ └── lol-cat2.jpg │ │ └── lol-cat3.jpg │ └── 2010 └── Guest ├── Applications ├── Desktop ├── Documents ├── Music └── Pictures Paths What is a Path? A path is a description of the location of a file or directory on our computer.\n Our terminal (shell) is always working out of a single path at a time. Commands that are run will take action in the current path (directory) unless we tell them to do otherwise.  Relative vs Absolute Paths All paths point to a single file or directory, but we can write paths to be either relative or absolute.\nAbsolute Paths  An absolute path will always tell us exactly where the file or directory is. An analogy made from the real world would be a mailing address:  Store Support Center 2455 Paces Ferry Road Atlanta, GA 30339 USA Earth Solar System Milky Way Absolute paths start with a / and go from top down (least specific to more specific). So the above mailing address could be represented as:\n/Milky_Way/Solar_System/Earth/USA/Atlanta/SSC Likewise an absolute path to a project directory might be:\n/Users/homer/orange-method/projects/project-2 The first slash essentially means \u0026ldquo;start at the root of the computer\u0026rsquo;s file system\u0026rdquo;.\nSome absolute paths instead start with a ~. This is a shortcut to the absolute path of your home directory. So the above realistic example absolute path could also be written as:\n~/orange-method/projects/project-2 (assuming that you are homer).\nRelative Paths   Relative paths are interpreted starting from the directory we are currently in (aka the current working directory).\n  They are similar to giving directions from a starting point, for example:\nGo to the end of the street, turn left, go to the 2nd light, turn right and it is the 3rd house on the left.\n  These driving directions only work from a specific starting point. It is the same with relative paths.\n  Relative paths start with anything but a slash / or a tilde ~.\n  For example, if you were in your home directory (represented by a tilde ~), the path to your work directory could be written with any of the following examples:\norange-method/fswd # relative ~/orange-method/fswd # absolute /users/homer/orange-method/fswd/ # absolute If you were in a different directory, then the relative path would point to an entirely different directory, but the absolute paths would still point to the correct directory.\nPeriods or dots are special in relative paths:\n One dot means \u0026ldquo;relative to the current directory\u0026rdquo; Two dots means \u0026ldquo;go up to the parent directory\u0026rdquo;  So if I\u0026rsquo;m in ~/orange-method/fswd then the relative path ./personal_projects means \u0026ldquo;go up one level to the orange-method directory, then down into personal_projects \u0026ldquo;.\nWe can use multiple .. to go up multiple levels:\n./Documents/top_secret/lol_cats/favorites would go up two levels, from ~/orange-method/fswd to ~ (home directory), and then down into the favorites directory.\nFile Paths Lab Got to the File Paths Lab.\nThe Current Working Directory When in the terminal you are always working out of a single directory. This is called your \u0026ldquo;working directory\u0026rdquo;.\nYou can see your working directory path via the pwd (print working directory) command:\n$ pwd /Users/homer Changing Directories You can change directories with the cd (change directory) command:\n$ cd Documents # change working directory to the Documents directory $ pwd /Users/homer/Documents $ cd .. # change back to the /Users/homer directory You can go to your HOME directory from anywhere in the file system with a simple command:\n$ cd $HOME # you can also use the `~` shortcut for $HOME: $ cd ~ # you can even just leave off the argument completely to go home: $ cd Navigating Directories Lab Go to the Navigating Directories Lab.\nListing the Contents of a Directory A popular Unix command is ls, short for \u0026ldquo;list\u0026rdquo;.\n$ ls Desktop Downloads beowulf_1.txt beowulf_1_reversed.txt  Without any arguments, the ls command will list all files and directories in the current directory. ls is commonly used just after changing directories. The ls command can also be used to check if a file or directory exists.  If the argument does not exist, an error message is returned.\n$ ls foo ls: foo: No such file or directory $ touch foo $ ls foo foo  The touch command\u0026rsquo;s stated purpose is to change the modification timestamp on files or directories, but we can also use it to create a new file.\n Wildcard characters  The wildcard character * is supported by ls. The wildcard character allows us to filter the results of ls For example, to list all files ending in “.txt”, we would type the following:  $ ls *.txt beowulf_1.txt beowulf_1_reversed.txt Here *.txt automatically expands to all the filenames that match the pattern - i.e. \u0026ldquo;any string followed by .txt\u0026rdquo;.\nOptions for ls There are three especially important optional forms of ls:\n -l - indicates the long form -t - indicagtes the time sorted form -a - indicates the all files form (to show hidden files)  The Long Form The long form of ls is specified via the -l option:\n$ ls -l *.txt -rw-r--r-- 1 KXB0QJK staff 92 Sep 11 20:01 beowulf_1.txt -rw-r--r-- 1 KXB0QJK staff 92 Sep 11 20:04 beowulf_1_copy.txt -rw-r--r-- 1 KXB0QJK staff 92 Sep 11 20:05 beowulf_1_reversed.txt -rw-r--r-- 1 KXB0QJK staff 36 Sep 11 20:03 line_1.txt -rw-r--r-- 1 KXB0QJK staff 56 Sep 11 20:03 line_2.txt  The long form lists a date and time indicating the last time the file was modified. The number before the date is the size of the file, in bytes. For now, you can safely ignore the rest of the information output by ls -l.  The Time Sorted Form A second powerful ls variant is “list by reversed time of modification (long format)”, or ls -rtl, which lists the long form of each file or directory in order of how recently it was modified (reversed so that the most recently modified entries appear at the bottom of the screen for easy inspection).\n$ ls -rtl \u0026lt;results system-dependent\u0026gt;  NOTE: -rtl is the commonly used compact form, but Unix allows the options to be passed individually, like this: ls -r -t -l. Additionally, the order is irrelevant, so typing ls -trl gives the same result.\n Listing Hidden Files  Unix has the concept of “hidden files (and directories)”, which don’t show up by default when listing files. Hidden files and directories are identified by starting with a dot . like .secret_file, and are routinely used for configuration data such as storing user preferences. A common hidden file is .gitignore that tells a particular program (git) to ignore files matching certain patterns.  Let\u0026rsquo;s create a .gitignore file which specifies that we want to ignore all files ending in .txt:\n$ echo \u0026#34;*.txt\u0026#34; \u0026gt; .gitignore $ cat .gitignore *.txt If we then run ls, the file won’t show up, because it’s hidden:\n$ ls beowulf_1.txt beowulf_1_reversed.txt But we can see all of the hidden files by adding the -a option to the ls command:\n$ ls -a . .gitignore beowulf_1_reversed.txt .. beowulf_1.txt Now .gitignore shows up, as well as a couple of mystery dot . and double-dot .. items (which we will learn about later).\nYou can also combine the -a and the -l options: ls -al\n$ ls -al drwxr-xr-x 21 KXB0QJK staff 672 Sep 11 12:08 . drwxr-xr-x 3 KXB0QJK staff 96 Sep 11 12:07 .. -rw-r--r-- 1 KXB0QJK staff 0 Sep 11 15:05 .hidden-file.txt -rw-r--r-- 1 KXB0QJK staff 92 Sep 11 20:01 beowulf_1.txt -rw-r--r-- 1 KXB0QJK staff 92 Sep 11 20:04 beowulf_1_copy.txt -rw-r--r-- 1 KXB0QJK staff 92 Sep 11 20:05 beowulf_1_reversed.txt -rw-r--r-- 1 KXB0QJK staff 36 Sep 11 20:03 line_1.txt -rw-r--r-- 1 KXB0QJK staff 56 Sep 11 20:03 line_2.txt Listing Files Lab Go to the Listing Files Lab\nQuiz Time:\n What’s the command to list all of the non-hidden files and directories that start with the letter b? What is the command to list all of the non-hidden files that contain the string “eowulf”, long-form by reverse modification time? Hint: Use the wildcard operator at both the beginning and the end. What is the command to list all files (including hidden ones) by reverse modification time, in long form?  Summary  Absolute paths provide the complete location of a file or directory Relative paths provide the location of a file or directory relative to the current working directory.     Command Description Example     pwd print the current working directory pwd   cd change the current working directory cd ~/Documents   ls list the contents of the current working directory ls -als *.txt    "
},
{
	"uri": "/software-eng-essentials/postman-foundations/",
	"title": "Postman Foundations",
	"tags": [],
	"description": "",
	"content": "Welcome to Postman Foundations! "
},
{
	"uri": "/python/foundation/print-function-labs/",
	"title": "Print Functions Labs",
	"tags": [],
	"description": "",
	"content": "Print Labs Multiple Print Statements Using four separate print statements, produce the following output on one line.\nElizabeth, Emily, Bob, Antonio ASCII Art ASCII Art is a graphic design technique that uses computers for presentation and consists of pictures pieced together from characters. An example ASCII art is:\n||| ||| | | __ | | |-|_____-----/ |_| |_| \\-----_____|-| |_|_________{ }| (^) |{ }__________|_| || |_| | ^ | |_| || | \\| /\\  |/ | | \\ |--| / | = \\ |__| / = + \\  / + \\  / \\  / \\  / \\  / \\  / \\  / \\  / \\  / \\/ Using this idea and print statements, create a smiley face or the first letter of your first name.\n IMPORTANT: Go to Math Functions Lesson!\nRandom Salary Create a program that will give a user a raise on their current salary.\n  Ask a user to input their name as a string and store it to variable name\n  Ask a user to input their salary as an int and store it in variable salary\n  Create a variable called raise_per that is set to a random integer value between 0 and 100. (Hint: Review the random method)\n  Create a variable called raise_amount that is equal to the inputted salary plus the added random percentage from the previous step.\n  Using Python3 Formatting, print out the person\u0026rsquo;s name and salary in the following format:\n\u0026gt;\u0026gt;\u0026gt; Enter your name: Helga \u0026gt;\u0026gt;\u0026gt; Enter your salary: 15000 Helga, your current salary is $15000. Your raise is 15% of $15000. Helga, your new salary is $17250. Error Handling and Writing Exceptions\n"
},
{
	"uri": "/react/pillars/redux/",
	"title": "Redux",
	"tags": [],
	"description": "",
	"content": "Welcome to Redux State Management for React! "
},
{
	"uri": "/react/pillars/redux/redux-beyond-the-basics/",
	"title": "Redux Beyond the Basics",
	"tags": [],
	"description": "",
	"content": "Working with Redux side-effects and libraries\n Topics 1. Learning Objectives 1.1. Concepts 1.2. Skills   2. Setup 2.1. Application Structure 2.2. API setup 2.3. Route Config 2.4. LAB 01 - Route and Nav Setup   3. Products and MaterialUI 3.1. Redux Setup 3.2. Setting up the store and dev tools 3.3. LAB 02 - Fetching Data   4. Side Effects and redux-thunk 4.1. Container - connect 4.2. LAB 03 - Cart Setup   5. Notifications 6. Cart Icon 6.1. NavContainer 6.2. Render the container in App.js 6.3. Rendering the ShoppingCart in NavBar.js 6.4. Make it clickable 6.4.1. Conditionally Render the Badge   6.5. LAB 04 - Refactor the NavBar   7. Redux Form 7.1. Looking at the form code 7.1.1. Small Refactor 7.1.2. Adding the Form   7.2. LAB 05 - Adding to the store   8. Additional Resources   1. Learning Objectives 1.1. Concepts   Work with API\u0026#8217;s\n  Discuss handling side-effects\n  Demo react-redux-forms\n    1.2. Skills   Build an application that interacts with an API\n  Understand additional redux related libraries\n      2. Setup We\u0026#8217;ll start by setting up the essentials\n yarn add react-router-dom redux react-redux redux-thunk   We\u0026#8217;re also going to add Material UI and React Spinkit for additional application styling\n material-ui react-spinkit react-tap-event-plugin   Next, we\u0026#8217;ll need to setup our dev dependencies\n yarn add faker json-server jsonfile node-emoji node-fetch uuid -D   Last we\u0026#8217;ll add some redux-specific packages\n yarn add react-notification-system react-notification-system-redux react-redux-form   2.1. Application Structure This application will have a relatively familiar structure. With the only major difference being the way we are structuring our Redux files.\n ├── components | ├── images │ ├── App.js │ ├── Cart.js │ ├── NavBar.js │ ├── Product.js │ ├── ProductSummary.js │ └── Products.js ├── containers │ ├── CartContainer.js │ ├── NewProduct.js │ └── ProductContainer.js | ├── index.js ├── redux │ ├── configureStore.js │ └── modules │ ├── cart.js │ ├── index.js │ ├── products.js │ └── fetching.js ├── registerServiceWorker.js └── styles ├── App.css ├── NewProduct.css └── index.css   In this application we\u0026#8217;ll be using the Ducks Pattern.\n Ducks is a philosophy that proposes keeping all of your related actions-creators, action-types, and reducers in the same file. The Ducks proposal has 4 requirements\n   MUST export default a function called reducer()\n  MUST export its action creators as functions\n  MUST have action types in the form npm-module-or-app/reducer/ACTION_TYPE\n  MAY export its action types as UPPER_SNAKE_CASE, if an external reducer needs to listen for them, or if it is a published reusable library\n   As we continue, we may not hit all of these requirements, but we\u0026#8217;ll keep them in mind throughout the development process.\n  2.2. API setup For this project we are going to use our own mock API. json-server is a handy little utility that allows us to create a json file and serve it over a small local web-server. This is a great tool for rapid development.\n We\u0026#8217;ll start by creating a fakeDb directory and adding some logic for generating the JSON data we\u0026#8217;ll be interacting with.\n $ mkdir fakeDb $ touch fakeDb/productData.js   fakeDb/productData.json const uuidv4 = require('uuid/v4'); const faker = require('faker'); const path = require('path'); const fs = require('fs'); console.log('Hang Tight! We are generating products for you to work with'); const times = (n, f, products = []) =\u0026gt; { while (n-- \u0026gt; 0) f(products, images); return products; }; const populate = (arr, imageOptions) =\u0026gt; { return arr.push({ id: uuidv4(), name: faker.commerce.productName(), image: `./images/${ imageOptions[Math.floor(Math.random() * imageOptions.length)] }`, retail: faker.finance.amount(), description: faker.fake( '{{commerce.productAdjective}}, {{company.bs}} {{random.words}}' ), featured: arr.length % 5 === 0 ? true : false }); }; const images = fs.readdirSync(`./src/images`, (err, files) =\u0026gt; { if (err) throw err; return files; }); const file = 'fakeDB/products.json'; const products = JSON.stringify({ products: times(20, populate) }); fs.writeFile(file, products, 'utf8', err =\u0026gt; { if (err) console.log(err); console.log('Products Generated! Starting server!'); });   Each time we run this task, a set of products will be created for us to work with.\n We\u0026#8217;ll also need to add a start command and proxy to our package.json file.\n package.json \"scripts\": { \"start\": \"react-scripts start\", \"build\": \"react-scripts build\", \"test\": \"react-scripts test --env=jsdom\", \"eject\": \"react-scripts eject\", \"json-server\": \"node fakeDB/productData.js \u0026amp;\u0026amp; json-server fakeDB/products.json -p 3001\" }, \"proxy\": \"http://localhost:3001\"   Now we can run `$ yarn json-server` to spin up a small web-server.    2.3. Route Config Now that we have a back-end to connect with, let\u0026#8217;s go ahead and setup the routes.\n Our application should have the following the following routes\n   / - loads a welcome component\n  /products - loads all products\n  products/:id - gives a detail view of the product and allows user to add the product to their cart\n     /cart - a view of all items in the user\u0026#8217;s cart\n  /add-product - a form that allows the user to request new items be added to the store/catalogue (not the redux store)\n   We\u0026#8217;ll use the Material UI App Bar for our Nav, which has a nice toggle effect.\n  2.4. LAB 01 - Route and Nav Setup   clone the redux-cart repo\n  checkout branch 01-start\n  Setup Routes for your container components\n  Home/Welcome\n  Products\n  Cart\n  Add Products\n     In the Products component, render another set of Routes\n  A Route that takes an :id and renders the Product component\n  A Route that renders the ProductSummary component at /products\n     Setup the NavBar to contain links to all of your major routes\n      3. Products and MaterialUI Normally we would start setting up our store, actions, reducers, etc. However, we are going to take a slight detour to setup the Products presentational components. That way, we\u0026#8217;ll have some visual feedback as we are wiring everything up.\n To avoid any issues, we are going to temporarily pass an empty array as a prop to our products components. Once we connect to the store, we\u0026#8217;ll pass in the correct values.\n src/components/Products.js // ... const Products = () =\u0026gt; ( // ... render={routeProps =\u0026gt; \u0026lt;Product {...routeProps} products={[]} /\u0026gt;} // ... render={routeProps =\u0026gt; \u0026lt;ProductSummary {...routeProps} products={[]} /\u0026gt;} // ... );   We can then move on to ProductSummary .\n src/components/ProductSummary.js import React from 'react'; import { Link } from 'react-router-dom'; (1) import { GridList, GridTile } from 'material-ui/GridList'; (1) import Subheader from 'material-ui/Subheader'; (1) const styles = { (2) root: { display: 'flex', flexWrap: 'wrap', justifyContent: 'space-around' }, gridList: { width: '80%', height: '80%', overflowY: 'auto' } }; const ProductSummary = ({ match, products }) =\u0026gt; { const allProducts = products.map(product =\u0026gt; { (3) return ( \u0026lt;GridTile (4) key={product.id} title={product.name} actionPosition=\"right\" titlePosition=\"bottom\" subtitle={`$${product.retail}`} containerElement={\u0026lt;Link to={`${match.url}/${product.id}`} /\u0026gt;} (5) cols={product.featured ? 2 : 1} rows={product.featured ? 2 : 1}\u0026gt; \u0026lt;img src={require(`${product.image}`)} alt={product.name} /\u0026gt; (6) \u0026lt;/GridTile\u0026gt; ); }); return ( \u0026lt;div style={styles.root}\u0026gt; (7) \u0026lt;GridList cellHeight={200} padding={10} style={styles.gridList}\u0026gt; (8) \u0026lt;Subheader\u0026gt;Check out our amazing products!\u0026lt;/Subheader\u0026gt; {allProducts} (9) \u0026lt;/GridList\u0026gt; \u0026lt;/div\u0026gt; ); }; export default ProductSummary;     1 Import dependencies   2 define some style (per Material UI Docs)   3 map over all products (that we\u0026#8217;ll be getting from the store)   4 Use the GridTile Component from Material UI   5 Pass a Link to the containerElement prop so the user can click on the item to go to a detailed view   6 pull in the image (from our images directory) and render it   7 Add some style   8 Wrap the rest of our components in Material UI\u0026#8217;s GridList component   9 Render the allProducts array        Material UI\u0026#8217;s docs recommend that you import components with specificity for to increase build time and create a smaller bundle     Next we\u0026#8217;ll setup the Product Component\n src/components/Product.js import React from 'react'; import { Redirect } from 'react-router-dom'; (1) import { Card, CardMedia, CardTitle, CardText } from 'material-ui/Card'; (1) import FlatButton from 'material-ui/FlatButton'; (1) const Product = ({ match, ...props }) =\u0026gt; { const product = props.products.find(p =\u0026gt; p.id === match.params.id) || ''; (2) if (!product) { return \u0026lt;Redirect to=\"/products\" /\u0026gt;; (3) } return ( \u0026lt;div style={{ width: '80%', margin: '20px auto' }}\u0026gt; \u0026lt;Card\u0026gt; (4) \u0026lt;CardMedia overlay={ \u0026lt;CardTitle title={product.name} subtitle={`$${product.retail}`} /\u0026gt; }\u0026gt; \u0026lt;img src={require(`${product.image}`)} alt={product.name} /\u0026gt; (5) \u0026lt;/CardMedia\u0026gt; \u0026lt;CardText\u0026gt; {product.description} \u0026lt;/CardText\u0026gt; \u0026lt;FlatButton label=\"Add to Cart\" primary={true} /\u0026gt; (6) \u0026lt;/Card\u0026gt; \u0026lt;/div\u0026gt; ); }; export default Product;     1 Import dependencies   2 Find the specific Product by ID   3 Redirect to the Products page if no product is found   4 Use the Card Component from Material UI   5 Display an image   6 Add a button    3.1. Redux Setup Now that we have a presentational layer setup, we can start setting up Redux.\n We\u0026#8217;ll start by creating our initial actions types, creators, initial state, and reducer for Products\n src/redux/modules/products.js // action types const LOAD_PRODUCTS_SUCCESS = 'LOAD_PRODUCTS_SUCCESS'; // action creators const loadProductsSuccess = products =\u0026gt; ({ type: LOAD_PRODUCTS_SUCCESS, products }); // initial state const initialProductState = []; // reducer export default (state = initialProductState, action) =\u0026gt; { switch (action.type) { case LOAD_PRODUCTS_SUCCESS: return action.products; default: return state; } }; export { LOAD_PRODUCTS_SUCCESS, loadProductsSuccess };   We know that this data will need to be pulled from an API, which is why we are looking to dispatch an action creator named loadProductsSuccess. We\u0026#8217;ll need to ensure that we receive an ok response with the correct data from the server before dispatching this action.\n  3.2. Setting up the store and dev tools We have enough redux goodness to set up our store and activate the dev tools. Let\u0026#8217;s do that before moving forward.\n First we\u0026#8217;ll navigate to src/redux/modules/index.js and create the rootReducer\n src/redux/modules/index.js import { combineReducers } from 'redux'; (1) import products from './products'; (2) export default combineReducers({ products }); (3)     1 import combineReducers so we can pass in all of our reducers and produce one root reducer   2 import the products reducer   3 export the rootReducer    Next we will setup the store\n src/redux/configStore.js import { createStore, applyMiddleware, compose } from 'redux'; (1) import thunk from 'redux-thunk'; (2) import rootReducer from './modules'; (3) const composeEnhancers = typeof window === 'object' \u0026amp;\u0026amp; window.__REDUX_DEVTOOLS_EXTENSION_COMPOSE__ ? window.__REDUX_DEVTOOLS_EXTENSION_COMPOSE__({}) : compose; (4) const enhancer = composeEnhancers(applyMiddleware(thunk)); (5) const store = createStore(rootReducer, enhancer); (6) export default store; (7)     1 Pull in the necessary functions from redux   2 Import redux-think middleware (more on that later)   3 Import the rootReducer   4 Check for the presence of the Redux Dev Tools extension   5 Compose the arguments that will be passed to createStore (aside from the reducer)   6 Create the store   7 Export the store    Now we need to setup the Provider in index.js\n src/index.js import React from 'react'; import ReactDOM from 'react-dom'; import { BrowserRouter as Router } from 'react-router-dom'; import { Provider } from 'react-redux'; (1) import store from './redux/configureStore'; (2) import './styles/index.css'; import App from './components/App'; import registerServiceWorker from './registerServiceWorker'; ReactDOM.render( \u0026lt;Provider store={store}\u0026gt; (3) \u0026lt;Router\u0026gt; \u0026lt;App /\u0026gt; \u0026lt;/Router\u0026gt; \u0026lt;/Provider\u0026gt;, document.getElementById('root') ); registerServiceWorker();     1 Import the Provider component   2 Import the store   3 Wrap the application in the Provider passing the store as a prop    Alright! Now the Redux Dev Tools should be able to connect to the store and show you and empty products array in the state. Before we can fetch from the API we\u0026#8217;ll need to setup a couple of other small items.\n  3.3. LAB 02 - Fetching Data   checkout branch 02-product-setup\n  create a file in redux/modules named fetchData.js\n  Add 2 Action Types\n  LOADING_PRODUCTS\n  LOAD_PRODUCTS_ERROR\n     Write an action creator for each of the action types\n  the action creator for LOADING_PRODUCTS should include an additional boolean property of isLoading\n  the action creator for LOAD_PRODUCTS_ERROR should include an additional boolean property of error\n     create an initial state object setting the values to false\n  write a reducer that handles updates\n  export the reducer and combine it your root reducer\n  check the redux dev tools to see if the values are being loaded into the store\n      4. Side Effects and redux-thunk We are ready to pull data from our API. In order to make an external call to an API, we are going to need to bring in some middleware to make the call before we hit our reducer. There are a handful of libraries and methodologies surrounding side-effects in redux. We are going to look at one of the most most simple (and popular) libraries for this type of situation.\n Redux Thunk is middleware that allows you to write action creators that return functions instead of an actions. Allowing you to work with API calls and other side-effects when an action is dispatched.\n     A thunk is a function that wraps an expression to delay its evaluation.     In the context of redux, this means that we can dispatch an action that can achieve any number of side effects, such as:\n   create/update a database\n  fetch data from an API\n  persist data to localStorage\n  send an email, text, slack message\n  etc\n     In addition to side-effects, we could also delay an action or prevent an action from happening. Typically, we\u0026#8217;ll use redux-thunk to dispatch a series of actions.\n To get started with redux-thunk we need to tell the store about our middleware. We\u0026#8217;ve actually already taken care of this step in the store configuration.\n src/redux/configureStore.js // ... import thunk from 'redux-thunk'; // ... const enhancer = composeEnhancers(applyMiddleware(thunk)); const store = createStore(rootReducer, enhancer); // ...   Let\u0026#8217;s start by writing our API call.\n src/redux/modules/products.js import { loadingProducts, loadProductError } from './fetchingData'; (1) // ... const fetchProducts = async dispatch =\u0026gt; { (2) await dispatch(loadingProducts(true)); (3) try { const products = await fetch(`/products`).then(res =\u0026gt; res.json()); (4) await dispatch(loadingProducts(false)); (5) return dispatch(loadProductsSuccess(products)); (6) } catch (err) { (7) await dispatch(loadingProducts(false)); return dispatch(loadProductError(true)); } };     1 Import the action creators from fetchingData   2 Write an action creator function that takes dispatch as an argument   3 Dispatch the loadingProducts action creator - setting isLoading to true   4 Fetch data from the API and parse the array of products   5 Dispatch the loadingProducts action creator - setting isLoading to false   6 Dispatch the loadProductsSuccess action creator - supplying products as the argument   7 Handle errors        dispatch and getState can be supplied as parameters to the thunk     4.1. Container - connect All that\u0026#8217;s left is to connect our ProductContainer to the store and hook into the React Lifecycle.\n src/containers/ProductContainer.js import { connect } from 'react-redux'; (1) import { withRouter } from 'react-router-dom'; (2) import { fetchProducts } from './redux/modules/products'; (3) import Products from './components/Products'; (4) const mapStateToProps = state =\u0026gt; ({ (5) products: state.products, isFetching: state.isFetching, error: state.fetchingData.error }); const mapDispatchToProps = dispatch =\u0026gt; ({ fetchProducts: () =\u0026gt; dispatch(fetchProducts) (6) }); const ProductContainer = connect(mapStateToProps, mapDispatchToProps)(Products); (7) export default withRouter(ProductContainer); (8)     1 Import connect from react-redux   2 Import withRouter from react router   3 import the fetchProducts action creator   4 Import the Products components   5 Tell redux what slice of state to pass to your Products component   6 Add a key of fetchProducts with the value of a function that calls dispatch and runs a callback function   7 Create a container component   8 Wrap the component in withRouter so router props are passed along    Last but not least, we\u0026#8217;ll need to use the React Lifecycle to dispatch our fetchProducts action creator.\n src/components/Products.js import React, { Component } from 'react'; import { Route, Switch } from 'react-router-dom'; import ProductSummary from './ProductSummary'; import Product from './Product'; class Products extends Component { (1) componentDidMount = () =\u0026gt; { this.props.fetchProducts(); (2) }; render() { if (this.props.isFetching) { (3) return \u0026lt;h3\u0026gt; Fetching Products \u0026lt;/h3\u0026gt;; } if (this.props.error) { (4) return \u0026lt;h3\u0026gt; We have encountered an error \u0026lt;/h3\u0026gt;; } return ( (5) \u0026lt;div\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route path=\"/products/:id\" render={routeProps =\u0026gt; ( \u0026lt;Product {...routeProps} products={this.props.products} /\u0026gt; )} /\u0026gt; \u0026lt;Route exact path=\"/products\" render={routeProps =\u0026gt; ( \u0026lt;ProductSummary {...routeProps} products={this.props.products} /\u0026gt; )} /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/div\u0026gt; ); } } export default Products;     1 Convert Products to a class component to gain access to the Lifecycle events   2 Dispatch the action creator on componentDidMount   3 If isFetching is true display a message indicating that we are fetching the data   4 If error is true display an error message   5 Otherwise, return the Product Routes and Components    If you take a few minutes to navigate around the application, you see that our Product components are working pretty well. The only feature that is unaccounted for is Adding an item to the cart. We\u0026#8217;ll fix that next.\n  4.2. LAB 03 - Cart Setup   checkout branch 04-cart-setup\n  in src/redux/modules/cart write the logic for Adding and Removing items from the cart.\n  you\u0026#8217;ll need an action type and action creators for both actions\n  write your reducer (don\u0026#8217;t forget to export)\n  pass the add to cart action creator down as prop to Products\n  write the CartContainer component\n  pass the remove from cart function down as a prop\n  delete the item when a user clicks on the trashcan icon\n      note: no side effects are happening, you can write normal action creators\n    5. Notifications It would be nice to notify the user when an item is added to their cart. React has no shortage of great notification components and libraries. Some of those libraries pair perfectly with Redux.\n We are going to use React Notification System Redux\n To get started, we just need to create import the reducer and add it to our root reducer\n src/redux/modules/index.js import { combineReducers } from 'redux'; import { reducer as notifications } from 'react-notification-system-redux'; (1) import products from './products'; import fetchingData from './fetchingData'; import cart from './cart'; export default combineReducers({ products, fetchingData, cart, notifications (2) });     1 Import from React Notification System Redux   2 Pass to root reducer    Now we need to create the content of our Notification in the ProductsContainer. Then, we can pass the success notification down to Product\n src/containers/ProductContainer.js // ... import Notifications, { success } from 'react-notification-system-redux'; (1) // ... const notificationOpts = { (2) title: \"We've added the product to your cart!\", message: 'Feel free to keep browsing and checkout at anytime', position: 'tr', autoDismiss: 5 }; const mapStateToProps = state =\u0026gt; ({ products: state.products, isFetching: state.isFetching, error: state.fetchingData.error, notifications: state.notifications (3) }); const mapDispatchToProps = dispatch =\u0026gt; ({ fetchProducts: () =\u0026gt; dispatch(fetchProducts), addToCart: id =\u0026gt; dispatch(addToCart(id)), successNotification: () =\u0026gt; dispatch(success(notificationOpts)) (4) }); const ProductContainer = connect(mapStateToProps, mapDispatchToProps)(Products); export default withRouter(ProductContainer);     1 Import the success notification   2 Define the specifics of the notification   3 Pass the notification state down as a prop   4 Pass the success notification down as a function    Next, we\u0026#8217;ll need to make a few adjustments in Products and then pass the props down to Product\n src/components/Products.js // ... import Notifications from 'react-notification-system-redux'; (1) // ... class Products extends Component { componentDidMount = () =\u0026gt; { this.props.fetchProducts(); }; render() { if (this.props.isFetching) { return \u0026lt;h3\u0026gt; Hang Tight! We are fetching the products \u0026lt;/h3\u0026gt;; } if (this.props.error) { return \u0026lt;h3\u0026gt; We have encountered an error \u0026lt;/h3\u0026gt;; } return ( \u0026lt;div\u0026gt; \u0026lt;Notifications notifications={this.props.notifications} /\u0026gt; (2) \u0026lt;Switch\u0026gt; \u0026lt;Route path=\"/products/:id\" render={routeProps =\u0026gt; ( \u0026lt;Product {...routeProps} products={this.props.products} addToCart={this.props.addToCart} successNotification={this.props.successNotification} (3) /\u0026gt; )} /\u0026gt; \u0026lt;Route exact path=\"/products\" render={routeProps =\u0026gt; ( \u0026lt;ProductSummary {...routeProps} products={this.props.products} /\u0026gt; )} /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/div\u0026gt; ); } } export default Products;     1 Import the Notification component   2 Allow the Notification to render in the Products Component   3 Pass successNotification down to Product    src/components/Product.js // ... \u0026lt;FlatButton label=\"Add to Cart\" primary={true} onClick={e =\u0026gt; { props.addToCart(product); props.successNotification(); }} /\u0026gt; // ...   Now, whenever the user adds an item to their cart, a nice notification will appear in the right hand corner letting them know the product was successfully added.\n   6. Cart Icon In addition to notifications, it would be nice to provide a small cart icon on the right side of the NavBar. This will allow users to see how many items have been added at a glance. Additionally, this will allow quick access to the cart, and ultimately, the check-out process.\n Thankfully, implementation of this should be fairly straight-forward, as we can pull cart data from the store, and icons from Material UI.\n 6.1. NavContainer To keep things uniform, we\u0026#8217;ll start by creating a NavContainer and rendering the NavBar as a child.\n src/containers/NavContainer.js import { connect } from \"react-redux\"; import NavBar from \"./components/NavBar\"; (1) const mapStateToProps = state =\u0026gt; ({ cart: state.cart (2) }); export default connect(mapStateToProps)(NavBar); (3)     1 Import the NavBar Component   2 Pass state.cart as a prop   3 Using the connect HOC, render the NavBar as a child     6.2. Render the container in App.js In App.js we\u0026#8217;ll need to swap out our NavBar for the NavContainer\n src/components/App.js // ... import NavContainer from \"./containers/NavContainer\"; // ... const App = () =\u0026gt; ( {/* ... */} \u0026lt;NavContainer /\u0026gt; {/* ... */} );    6.3. Rendering the ShoppingCart in NavBar.js Now, we can move on the the presentational layer. Thankfully, Material UI gives us a nice set of icons to work with. We are going to use the ShoppingCart and Badge components. We\u0026#8217;ll also make use of the cart prop.\n src/components/NavBar.js // ... import Badge from \"material-ui/Badge\"; (1) import ShoppingCart from \"material-ui/svg-icons/action/shopping-cart\"; (2) const CartIcon = ({ cart }) =\u0026gt; ( (3) \u0026lt;div style={{ marginTop: \"12px\", marginRight: \"0.8em\" }}\u0026gt; \u0026lt;ShoppingCart color={\"#fff\"} /\u0026gt; (4) \u0026lt;Badge (5) badgeContent={cart.length} (6) badgeStyle={{ color: \"#f96302\" }} style={{ marginLeft: \"-1em\", marginTop: \"-12px\" }} /\u0026gt; \u0026lt;/div\u0026gt; ); class Navbar extends Component { // ... render(){ return ( \u0026lt;div\u0026gt; \u0026lt;AppBar {/* ... */} iconElementLeft={/* ... */} iconElementRight={\u0026lt;CartIcon cart={this.props.cart} /\u0026gt;} (7) /\u0026gt; {/* ... */} ) } } // ...     1 Import the \u0026lt;Badge\u0026gt; component from Material UI - so we can show users the number of items that have been added   2 Import the \u0026lt;ShoppingCart\u0026gt; icon/component from Material UI   3 Create a small presentational component that will render the ShoppingCart and Badge components\nnote that we are passing cart as a prop, this argument will be supplied when we make a call to render the CartIcon component   4 Render the ShoppingCart Icon   5 Render the Badge Component   6 Display a value based on the number of items in the cart   7 Using the iconElementRight prop, render CartIcon supplying the cart as an argument    Now, we can test this out by browsing products and adding an item to the cart.\n  6.4. Make it clickable This is great! However, we can do better. When the user clicks on the cart icon, it should take them to their shopping cart. React Router makes this super easy. We\u0026#8217;ll just need to import the Link component and wrap it around our existing components.\n src/components/NavBar.js // ... import { NavLink, Link } from \"react-router-dom\"; (1) // ... const CartIcon = ({ cart }) =\u0026gt; ( \u0026lt;div style={{ marginTop: \"12px\", marginRight: \"0.8em\" }}\u0026gt; \u0026lt;Link to=\"/cart\"\u0026gt; (2) \u0026lt;ShoppingCart color={\"#fff\"} /\u0026gt; \u0026lt;Badge {/* ... */}/\u0026gt; \u0026lt;/Link\u0026gt; \u0026lt;/div\u0026gt; );     1 Import the Link component from react router   2 Pass the user to /cart on click    Okay! now we should be able to click on the cart and be taken to the cart component.\n 6.4.1. Conditionally Render the Badge In all honesty, the \u0026lt;Badge\u0026gt; component does not need to be rendered unless the user has items in the cart. Let\u0026#8217;s use a condition to make it happen!\n src/components/NavBar.js const CartIcon = ({ cart }) =\u0026gt; ( \u0026lt;div style={{ marginTop: \"12px\", marginRight: \"0.8em\" }}\u0026gt; \u0026lt;Link to=\"/cart\"\u0026gt; \u0026lt;ShoppingCart color={\"#fff\"} /\u0026gt; {cart.length ? ( (1) \u0026lt;Badge badgeContent={cart.length} badgeStyle={{ color: \"#f96302\" }} style={{ marginLeft: \"-1em\", marginTop: \"-12px\" }} /\u0026gt; ) : null} (2) \u0026lt;/Link\u0026gt; \u0026lt;/div\u0026gt; );     1 Only render \u0026lt;Badge\u0026gt; if cart.length is truthy (greater than 0)   2 Otherwise render nothing      6.5. LAB 04 - Refactor the NavBar Now that we have a NavContainer, it would make sense to convert the NavBar to a presentational component. This will require moving the internal state into the Redux store. Give it a try!\n   Checkout the 06-cart-icon branch\n  Setup a navbar module in src/redux/modules\n  Create 2 Action Types\n  OPEN\n  CLOSED\n     Add 2 action creators that dispatch your OPEN and CLOSED action types\nit\u0026#8217;s recommended to name your action creators something simple like openNav and closeNav for future readability\n  Set up an initial NavBar state\n  Set the state to false (to mirror your existing NavBar state)\n     Create a reducer that\n  Sets the state to true when OPEN is dispatched\n  Sets the state to false when CLOSE is dispatched\n        In src/redux/modules/index.js\n  Import the reducer\n  Add your reducer to combineReducers\n     In NavContainer\n  Import your action creators\n  Setup the matchDispatchToProps function, passing down your action creators as props\n  In mapStateToProps pass down the state of your sidebar (open: true/false) as a prop\n     In NavBar.js\n  Remove the state\n  Convert the component to a function\n  Update the functionality to use your action creators\nhint: feel free to reference the following starter code\n      const Navbar = props =\u0026gt; { const toggleNav = () =\u0026gt; (props.open ? props.closeNav() : props.openNav()); return ( {/* ... */} iconElementLeft={ \u0026lt;IconButton onClick={toggleNav}\u0026gt; \u0026lt;NavigationMenu /\u0026gt; \u0026lt;/IconButton\u0026gt; } iconElementRight={\u0026lt;CartIcon cart={props.cart} /\u0026gt;} /\u0026gt; {/* ... */} ) }      7. Redux Form Handling forms with Redux differs slightly from standard form handling in React. A very popular library for handling forms in Redux aptly named Redux Form is a common starting point.\n Redux Form provides the following items to help us with building forms the Redux way:\n   Redux Reducer: known as the formReducer\n  The reduxForm() Higher Order Component\n  A \u0026lt;Field/\u0026gt; component\n   According to the Redux Form docs, It\u0026#8217;s important to understand their responsibilities:\n   formReducer\t- reducer\tfunction that tells how to update the Redux store based on changes coming from the application; those changes are described by Redux actions\n  reduxForm()\tHOC\tfunction that takes configuration object and returns a new function\u0026#8230;\u0026#8203;\n  \u0026lt;Field/\u0026gt; component - lives inside your wrapped form component; use it to connect the input components to the redux-form logic\n     The docs also offer the following diagram with an explanation:\n \n  \u0026#8230;\u0026#8203;We have a form component wrapped with reduxForm(). There is one text input inside, wrapped with \u0026lt;Field/\u0026gt;. The data flows like this:\n  User clicks on the input\n  \"Focus action\" is dispatched\n  formReducer updates the corresponding state slice\n  The state is then passed back to the input.\n      7.1. Looking at the form code So, what does this implementation look like?\n 7.1.1. Small Refactor Let\u0026#8217;s start by doing a quick refactor. We\u0026#8217;re going to change src/container/NewProduct.js to NewProductContainer.js\n shell mv ./src/containers/NewProduct.js ./src/containers/NewProductContainer.js   We\u0026#8217;ll need to change the name of the component\n src/containers/NewProductContainer.js import React, { Component } from \"react\"; import \"./styles/NewProduct.css\"; class NewProductContainer extends Component { render(){ return( \u0026lt;div\u0026gt;New Product Container\u0026lt;/div\u0026gt; ) } } export default NewProductContainer;   We\u0026#8217;ll also need to update App.js\n src/containers/NewProductContainer.js // ... import NewProductContainer from \"./containers/NewProductContainer\"; // ... const App = () =\u0026gt; ( {/* ... */} \u0026lt;Route path=\"/add-product\" component={NewProductContainer} /\u0026gt; {/* ... */} ); export default App;    7.1.2. Adding the Form Next, we\u0026#8217;ll need to create a form component\n shell touch src/components/NewFormComponent.js   src/components/NewFormComponent.js import React from \"react\"; import { Field, reduxForm } from \"redux-form\"; (1) import \"./styles/NewProduct.css\"; const AddProduct = ({ handleSubmit }) =\u0026gt; ( (2) \u0026lt;div\u0026gt; \u0026lt;h3\u0026gt; New Product Requests \u0026lt;/h3\u0026gt; \u0026lt;form onSubmit={handleSubmit}\u0026gt; \u0026lt;div\u0026gt; \u0026lt;label htmlFor=\"name\"\u0026gt; What new product would you like for us to carry? \u0026lt;/label\u0026gt; \u0026lt;br /\u0026gt; \u0026lt;Field name=\"name\" component=\"input\" type=\"text\" /\u0026gt; (3) \u0026lt;/div\u0026gt; \u0026lt;br /\u0026gt; \u0026lt;button type=\"submit\"\u0026gt; Request \u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; ); const NewProductForm = reduxForm({ (4) form: \"newProduct\" (5) })(AddProduct); (6) export default NewProductForm; (7)     1 Import the \u0026lt;Field/\u0026gt; component \u0026amp; the reduxForm Higher Order Component   2 Create a Presentational Component named AddProduct and pass a prop of handleSubmit\nhandleSubmit is a function provided by Redux Form   3 Use the \u0026lt;Field/\u0026gt; component from Redux form   4 Use the reduxForm Higher Order Component   5 Name the form   6 Pass your \u0026lt;AddProduct/\u0026gt; presentational component to the reduxForm HOC - creating a NewProductForm component   7 Export the NewProductForm Component    Now, we\u0026#8217;ll head back to the NewProductContainer to continue the setup.\n src/containers/NewProductContainer.js import React, { Component } from \"react\"; import NewProductForm from \"./components/NewProductForm\"; (1) import \"./styles/NewProduct.css\"; class NewProductContainer extends Component { submit = values =\u0026gt; { (2) console.log(values); (3) }; render() { return \u0026lt;NewProductForm onSubmit={this.submit} /\u0026gt;; (4) } } export default NewProductContainer;     1 Import the NewProductForm component   2 Write a submit function that will run when handleSubmit is called   3 log the values found in the form input   4 Render the NewProductForm component passing the submit function as a prop    Last but not least, we\u0026#8217;ll need to setup the reducer. Thankfully, the logic has already been written for us. All we need to do is add redux-form\u0026#8217;s reducer to our rootReducer.\n This can be accomplished by navigating to src/redux/modules/index.js and adding the following code:\n src/redux/modules/index.js // ... import { reducer as newProduct } from \"redux-form\"; (1) // ... export default combineReducers({ form: newProduct, (2) products, // ... });     1 Import the reducer from Redux Form, naming it newProduct   2 Add the form to your rootReducer        You\u0026#8217;ll need to specify a key/value pair if using a value named anything other than form     Now, our form should log the values to the console upon submission.\n   7.2. LAB 05 - Adding to the store The next logical step would be to add our newly requested products to the store. Give it a try\n   checkout branch 07-redux-forms\n  restart both servers\n  In redux/modules/newProduct.js\n  Add a REQUEST_PRODUCT` action type\n  Update the addProduct action creator\n  Update your reducer function to replace the empty array (when the REQUEST_PRODUCT action type is true) with code that clones the state and merges in new product\n     Import your new reducer function in src/redux/modules/index.js and add it to the rootReducer\n  Navigate to src/containers/NewProductContainer.js\n  Review the commented code\n  Uncomment the code\n     Navigate to src/components/NewProduct.js\n  Pass in the appropriate prop as an argument\n  Call that function on Submit\n     Open the redux dev tools and validate that your products are being added to the store\n      8. Additional Resources   What is a thunk?\n  Understanding How redux-thunk Works\n  redux-saga\n  The ducks file structure for Redux\n     "
},
{
	"uri": "/react/pillars/redux/redux-beyond-the-basics-solutions/",
	"title": "Redux Beyond the Basics Solutions",
	"tags": [],
	"description": "",
	"content": "Working with Redux side-effects and libraries\n Topics 1. LAB 01 - Route and Nav Setup 1.1. Answers   2. LAB 02 - Fetching Data 2.1. Answers   3. LAB 03 - Cart Setup 3.1. Actions   4. LAB 04 - Refactor the NavBar 4.1. Solution     1. LAB 01 - Route and Nav Setup   clone the redux-cart repo\n  checkout branch 01-start\n  Setup Routes for your container components\n  Home/Welcome\n  Products\n  Cart\n  Add Products\n     In the Products component, render another set of Routes\n  A Route that takes an :id and renders the Product component\n  A Route that renders the ProductSummary component at /products\n     Setup the NavBar to contain links to all of your major routes\n   1.1. Answers src/components/App.js import React from 'react'; import ProductContainer from './containers/ProductContainer'; import CartContainer from './containers/CartContainer'; import NewProduct from './containers/NewProduct'; import Navbar from './NavBar'; import { Route, Switch } from 'react-router-dom'; import MuiThemeProvider from 'material-ui/styles/MuiThemeProvider'; import './styles/App.css'; const App = () =\u0026gt; ( \u0026lt;MuiThemeProvider\u0026gt; \u0026lt;div className=\"App\"\u0026gt; \u0026lt;Navbar /\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route exact path=\"/\" render={() =\u0026gt; \u0026lt;h3\u0026gt; Hi! Welcome to the OM Shop!\u0026lt;/h3\u0026gt;} /\u0026gt; \u0026lt;Route path=\"/products\" component={ProductContainer} /\u0026gt; \u0026lt;Route path=\"/cart\" component={CartContainer} /\u0026gt; \u0026lt;Route path=\"/add-product\" component={NewProduct} /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/MuiThemeProvider\u0026gt; ); export default App;   src/components/Products.js import React from 'react'; import { Route, Switch } from 'react-router-dom'; import ProductSummary from './ProductSummary'; import Product from './Product'; const Products = () =\u0026gt; ( \u0026lt;div\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route path=\"/products/:id\" render={routeProps =\u0026gt; \u0026lt;Product {...routeProps} /\u0026gt;} /\u0026gt; \u0026lt;Route exact path=\"/products\" render={routeProps =\u0026gt; \u0026lt;ProductSummary {...routeProps} /\u0026gt;} /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/div\u0026gt; ); export default Products;   src/components/NavBar.js import React, { Component } from 'react'; import AppBar from 'material-ui/AppBar'; import { NavLink } from 'react-router-dom'; import Drawer from 'material-ui/Drawer'; import MenuItem from 'material-ui/MenuItem'; import IconButton from 'material-ui/IconButton'; import NavigationMenu from 'material-ui/svg-icons/navigation/menu'; class Navbar extends Component { state = { open: false }; handleToggle = () =\u0026gt; this.setState({ open: !this.state.open }); handleClose = () =\u0026gt; this.setState({ open: false }); render() { return ( \u0026lt;div\u0026gt; \u0026lt;AppBar title=\"OM ReduxCart\" style={{ backgroundColor: '#f96302' }} iconElementLeft={ \u0026lt;IconButton onClick={this.handleToggle}\u0026gt; \u0026lt;NavigationMenu /\u0026gt; \u0026lt;/IconButton\u0026gt; } /\u0026gt; \u0026lt;Drawer width={200} open={this.state.open} onRequestChange={open =\u0026gt; this.setState({ open })} docked={false}\u0026gt; \u0026lt;MenuItem onClick={this.handleClose}\u0026gt; \u0026lt;NavLink exact to=\"/\" activeClassName=\"active\"\u0026gt; OM Shop \u0026lt;/NavLink\u0026gt; \u0026lt;/MenuItem\u0026gt; \u0026lt;MenuItem onClick={this.handleClose}\u0026gt; \u0026lt;NavLink exact to=\"/products\" activeClassName=\"active\"\u0026gt; Browse Products \u0026lt;/NavLink\u0026gt; \u0026lt;/MenuItem\u0026gt; \u0026lt;MenuItem onClick={this.handleClose}\u0026gt; \u0026lt;NavLink exact to=\"/cart\" activeClassName=\"active\"\u0026gt; See cart and buy! \u0026lt;/NavLink\u0026gt; \u0026lt;/MenuItem\u0026gt; \u0026lt;MenuItem onClick={this.handleClose}\u0026gt; \u0026lt;NavLink exact to=\"/add-product\" activeClassName=\"active\"\u0026gt; Request a new product! \u0026lt;/NavLink\u0026gt; \u0026lt;/MenuItem\u0026gt; \u0026lt;/Drawer\u0026gt; \u0026lt;/div\u0026gt; ); } } export default Navbar;      2. LAB 02 - Fetching Data   checkout branch 02-product-setup\n  create a file in redux/modules named fetchData.js\n  Add 2 Action Types\n  LOADING_PRODUCTS\n  LOAD_PRODUCTS_ERROR\n     Write an action creator for each of the action types\n  the action creator for LOADING_PRODUCTS should include an additional boolean property of isLoading\n  the action creator for LOAD_PRODUCTS_ERROR should include an additional boolean property of error\n     create an initial state object setting the values to false\n  write a reducer that handles updates\n  export the reducer and combine it your root reducer\n  check the redux dev tools to see if the values are being loaded into the store\n   2.1. Answers src/redux/modules/fetchingData.js import { LOADING_PRODUCTS, LOAD_PRODUCTS_ERROR, loadingProducts, loadProductError } from './fetchingData'; // action types const LOADING_PRODUCTS = 'LOADING_PRODUCTS'; const LOAD_PRODUCTS_ERROR = 'LOAD_PRODUCTS_ERROR'; // action creators const loadProductError = error =\u0026gt; ({ type: LOAD_PRODUCTS_ERROR, error }); const loadingProducts = isFetching =\u0026gt; ({ type: LOADING_PRODUCTS, isFetching }); // initial state const fetchingDataState = { isFetching: false, error: false }; // reducer const fetchingData = (state = fetchingDataState, action) =\u0026gt; { switch (action.type) { case LOADING_PRODUCTS: return { ...state, isFetching: action.isFetching }; case LOAD_PRODUCTS_ERROR: return { ...state, error: action.error }; default: return state; } }; export default fetchingData; export { LOADING_PRODUCTS, LOAD_PRODUCTS_ERROR, loadingProducts, loadProductError };   src/redux/modules/index.js import { combineReducers } from 'redux'; import products from './products';\ti import fetchingData from './fetchingData'; export default combineReducers({ products, fetchingData });      3. LAB 03 - Cart Setup   checkout branch 04-cart-setup\n  in src/redux/modules/cart write the logic for Adding and Removing items from the cart.\n  you\u0026#8217;ll need an action type and action creators for both actions\n  write your reducer (don\u0026#8217;t forget to export)\n  pass the add to cart action creator down as prop to Products\n  write the CartContainer component\n  pass both the remove from cart function down as a prop\n  delete the item when a user clicks on the trashcan icon\n      note: no side effects are happening, you can write normal action creators\n 3.1. Actions src/components/Products.js // ... \u0026lt;Product {...routeProps} products={this.props.products} addToCart={this.props.addToCart} /\u0026gt; // ...   src/components/Product.js // ... \u0026lt;FlatButton label=\"Add to Cart\" primary={true} onClick={e =\u0026gt; { props.addToCart(product); }} /\u0026gt; // ...   src/components/Cart.js // ... const Cart = ({ match, ...props }) =\u0026gt; { const cart = props.cart.map(product =\u0026gt; ( \u0026lt;GridTile key={product.id} title={product.name} actionPosition=\"right\" titlePosition=\"bottom\" subtitle={`$${product.retail}`} actionIcon={ \u0026lt;IconButton onClick={() =\u0026gt; props.removeFromCart(product.id)}\u0026gt; \u0026lt;Delete style={{ width: '20px' }} color=\"white\" /\u0026gt; \u0026lt;/IconButton\u0026gt; } cols={4} rows={1}\u0026gt; \u0026lt;img src={require(`${product.image}`)} alt={product.name} /\u0026gt; \u0026lt;/GridTile\u0026gt; )); //... }; // ...      4. LAB 04 - Refactor the NavBar Now that we have a NavContainer, it would make sense to convert the NavBar to a presentational component. This will require moving the internal state into the Redux store. Give it a try!\n   Checkout the 06-cart-icon branch\n  Setup a navbar module in src/redux/modules\n  Create 2 Action Types\n  OPEN\n  CLOSED\n     Add 2 action creators that dispatch your OPEN and CLOSED action types\nit\u0026#8217;s recommended to name your action creators something simple like openNav and closeNav for future readability\n  Set up an initial NavBar state\n  Set the state to false (to mirror your existing NavBar state)\n     Create a reducer that\n  Sets the state to true when OPEN is dispatched\n  Sets the state to false when CLOSE is dispatched\n        In src/redux/modules/index.js\n  Import the reducer\n  Add your reducer to combineReducers\n     In NavContainer\n  Import your action creators\n  Setup the matchDispatchToProps function, passing down your action creators as props\n  In mapStateToProps pass down the state of your sidebar (open: true/false) as a prop\n     In NavBar.js\n  Remove the state\n  Convert the component to a function\n  Update the functionality to use your action creators\nhint: feel free to reference the following starter code\n      const Navbar = props =\u0026gt; { const toggleNav = () =\u0026gt; (props.open ? props.closeNav() : props.openNav()); return ( {/* ... */} iconElementLeft={ \u0026lt;IconButton onClick={toggleNav}\u0026gt; \u0026lt;NavigationMenu /\u0026gt; \u0026lt;/IconButton\u0026gt; } iconElementRight={\u0026lt;CartIcon cart={props.cart} /\u0026gt;} /\u0026gt; {/* ... */} ) }   4.1. Solution src/redux/modules/navbar.js // action types const OPEN = \"OPEN\"; const CLOSED = \"CLOSED\"; // action creators const closeNav = () =\u0026gt; ({ type: CLOSED }); const openNav = () =\u0026gt; ({ type: OPEN }); // initial state const navBarState = { open: false }; // reducer const toggleSideNav = (state = navBarState, action) =\u0026gt; { switch (action.type) { case OPEN: return { open: true }; case CLOSED: return { open: false }; default: return state; } }; export default toggleSideNav; export { OPEN, CLOSED, openNav, closeNav };   src/redux/modules/index.js import { combineReducers } from \"redux\"; import { reducer as notifications } from \"react-notification-system-redux\"; import products from \"./products\"; import fetchingData from \"./fetchingData\"; import cart from \"./cart\"; import toggleSideNav from \"./navbar\"; export default combineReducers({ products, fetchingData, cart, notifications, toggleSideNav });   src/containers/NavContainer.js import { connect } from \"react-redux\"; import { openNav, closeNav } from \"./redux/modules/navbar\"; import NavBar from \"./components/NavBar\"; const mapDispatchToProps = dispatch =\u0026gt; ({ openNav: () =\u0026gt; dispatch(openNav()), closeNav: () =\u0026gt; dispatch(closeNav()) }); const mapStateToProps = state =\u0026gt; ({ cart: state.cart, open: state.toggleSideNav.open }); export default connect( mapStateToProps, mapDispatchToProps )(NavBar);   src/components/NavBar.js import React from \"react\"; import AppBar from \"material-ui/AppBar\"; import { NavLink, Link } from \"react-router-dom\"; import Drawer from \"material-ui/Drawer\"; import MenuItem from \"material-ui/MenuItem\"; import IconButton from \"material-ui/IconButton\"; import NavigationMenu from \"material-ui/svg-icons/navigation/menu\"; import Badge from \"material-ui/Badge\"; import ShoppingCart from \"material-ui/svg-icons/action/shopping-cart\"; const CartIcon = ({ cart }) =\u0026gt; ( \u0026lt;div style={{ marginTop: \"12px\", marginRight: \"0.8em\" }}\u0026gt; \u0026lt;Link to=\"/cart\"\u0026gt; \u0026lt;ShoppingCart color={\"#fff\"} /\u0026gt; {cart.length ? ( \u0026lt;Badge badgeContent={cart.length} badgeStyle={{ color: \"#f96302\" }} style={{ marginLeft: \"-1em\", marginTop: \"-12px\" }} /\u0026gt; ) : null} \u0026lt;/Link\u0026gt; \u0026lt;/div\u0026gt; ); const Navbar = props =\u0026gt; { const toggleNav = () =\u0026gt; (props.open ? props.closeNav() : props.openNav()); return ( \u0026lt;div\u0026gt; \u0026lt;AppBar title=\"OM ReduxCart\" className=\"AppBar\" style={{ backgroundColor: \"#f96302\" }} iconElementLeft={ \u0026lt;IconButton onClick={toggleNav}\u0026gt; \u0026lt;NavigationMenu /\u0026gt; \u0026lt;/IconButton\u0026gt; } iconElementRight={\u0026lt;CartIcon cart={props.cart} /\u0026gt;} /\u0026gt; \u0026lt;Drawer width={200} open={props.open} onRequestChange={toggleNav} docked={false} \u0026gt; \u0026lt;MenuItem onClick={props.closeNav}\u0026gt; \u0026lt;NavLink exact to=\"/\" activeClassName=\"active\"\u0026gt; OM Shop \u0026lt;/NavLink\u0026gt; \u0026lt;/MenuItem\u0026gt; \u0026lt;MenuItem onClick={props.closeNav}\u0026gt; \u0026lt;NavLink exact to=\"/products\" activeClassName=\"active\"\u0026gt; Browse Products \u0026lt;/NavLink\u0026gt; \u0026lt;/MenuItem\u0026gt; \u0026lt;MenuItem onClick={props.closeNav}\u0026gt; \u0026lt;NavLink exact to=\"/cart\" activeClassName=\"active\"\u0026gt; See cart and buy! \u0026lt;/NavLink\u0026gt; \u0026lt;/MenuItem\u0026gt; \u0026lt;MenuItem onClick={props.closeNav}\u0026gt; \u0026lt;NavLink exact to=\"/add-product\" activeClassName=\"active\"\u0026gt; Request a new product! \u0026lt;/NavLink\u0026gt; \u0026lt;/MenuItem\u0026gt; \u0026lt;/Drawer\u0026gt; \u0026lt;/div\u0026gt; ); }; export default Navbar;      "
},
{
	"uri": "/javascript/performance/universal-rendering-lab/step-4/",
	"title": "Step 4: Attach event listeners in the client",
	"tags": [],
	"description": "",
	"content": "Nothing happens when we click the \u0026ldquo;right\u0026rdquo; arrow in our application because we haven\u0026rsquo;t attached any event listeners in the client. We can use the hydrate function from react-dom to accomplish this.\nThe renderToString function from react-dom/server puts attributes onto our elements in the form of data-react. For example, renderToString puts the attribute data-reactroot=\u0026quot;\u0026quot; on the \u0026lt;main\u0026gt; element (found in src/client/App.js).\n  Going back to our application, attempt to click the right arrow next to the text that reads \u0026ldquo;1 of 22\u0026rdquo;. It used to fetch the next page of data from our API, but now it doesn\u0026rsquo;t do anything. Why?\nWe haven\u0026rsquo;t attached any event listeners to the DOM. We\u0026rsquo;ve returned raw markup from our server.\nReact adds the data-react attributes to elements so that we can perform a process called hydration on the client. Hydration is a fancy term for applying event listeners. We cannot apply event listeners on the server, since there isn\u0026rsquo;t a DOM to which we can listen. To have a maximally interactive application, we need the application to handle user interaction on it\u0026rsquo;s own, in the client. This requires that we bind event listeners in the user\u0026rsquo;s web browser.\n  Inside src/client/index.js, let\u0026rsquo;s swap out the render function for a hydrate function.\nReact Hydrate: https://reactjs.org/docs/react-dom.html#hydrate\n  // src/client/index.js import React from \u0026#39;react\u0026#39;; import { hydrate } from \u0026#39;react-dom\u0026#39;; import App from \u0026#39;./App\u0026#39;; hydrate( \u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) );  Next, we need to add our client-bundle.js script back into our response so that the above code will execute in the user\u0026rsquo;s web browser.  // src/server/app.js app.get(\u0026#39;/\u0026#39;, async (req, res) =\u0026gt; { const data = await fetchMarketsAndPageInfo(); res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;${ ReactDOMServer.renderToString(\u0026lt;App data={ data }/\u0026gt;) }\u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;/client-bundle.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); });  Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and you should now see a blank page.   Open the Chrome developer tools and navigate to the \u0026ldquo;Console\u0026rdquo; tab. We should see quite a few errors, but let\u0026rsquo;s take a closer look at the error that occurs in App.js.\n Uncaught TypeError: Cannot read property \u0026lsquo;markets\u0026rsquo; of undefined\n  In src/client/index.js, we haven\u0026rsquo;t passed any data to the App component, thus an error gets thrown. Let\u0026rsquo;s fix that by passing an empty data object to our App component.  // src/client/index.js import React from \u0026#39;react\u0026#39;; import { hydrate } from \u0026#39;react-dom\u0026#39;; import App from \u0026#39;./App\u0026#39;; hydrate( \u0026lt;App data={{}} /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) );   Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and you should now see the page render again.\n  But now we see the page initially render with data, then the data disappears, and then it loads again. Why is this?\nOpen the Chrome developer tools and navigate to the \u0026ldquo;Console\u0026rdquo; tab. We should see an error from react-dom.development.js:\n Warning: Text content did not match. Server: \u0026ldquo;1 of 22\u0026rdquo; Client: \u0026ldquo;1 of 1\u0026rdquo;\n When hydrate gets called in the client, it generates it\u0026rsquo;s own markup so that it can determine where event listeners need to be attached. Let\u0026rsquo;s compare how we generate our server markup with how we generate our client markup.\nServer markup:\nrenderToString(\u0026lt;App data={ data } /\u0026gt;) Client markup:\nhydrate( \u0026lt;App data={{}} /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) ); When we generate markup on the server, we pass our app the markets and pageInfo properties via data. Our App component uses the markets property to generate a list of markets via the MarketList component.\nIn the client, we do not pass either the markets or pageInfo properties to our App component. This means that the markup generated on the server will be different than the markup generated by the client. This is very bad, since React needs the markup to be identical in order to attach event listeners to server generated markup. React will attempt to patch up the difference on its own, but will sometimes patch things up incorrectly.\nWe need to find a way to pass the data from the server to the client, so that the client can pass markets and pageInfo to our App component in the same manner as the server.\n"
},
{
	"uri": "/react/performance/universal-rendering-lab/step-4/",
	"title": "Step 4: Attach event listeners in the client",
	"tags": [],
	"description": "",
	"content": "We can use the hydrate function from react-dom to attach event listeners in the client.\nThe renderToString function from react-dom/server puts attributes onto our elements in the form of data-react. For example, renderToString puts the attribute data-reactroot=\u0026quot;\u0026quot; on the \u0026lt;main\u0026gt; element (found in src/client/App.js).\n  Going back to our application, attempt to click the right arrow next to the text that reads \u0026ldquo;1 of 22\u0026rdquo;. It used to fetch the next page of data from our API, but now it doesn\u0026rsquo;t do anything. Why?\nWe haven\u0026rsquo;t attached any event listeners to the DOM. We\u0026rsquo;ve returned raw markup from our server.\nReact adds the data-react attributes to elements so that we can perform a process called hydration on the client. Hydration is a fancy term for applying event listeners. We cannot apply event listeners on the server, since there isn\u0026rsquo;t a DOM to which we can listen. To have a maximally interactive application, we need the application to handle user interaction on it\u0026rsquo;s own, in the client. This requires that we bind event listeners in the user\u0026rsquo;s web browser.\n  Inside src/client/render.js, let\u0026rsquo;s swap out the render function for a hydrate function.\nReact Hydrate: https://reactjs.org/docs/react-dom.html#hydrate\n  // src/client/render.js import React from \u0026#39;react\u0026#39;; import { hydrate } from \u0026#39;react-dom\u0026#39;; import App from \u0026#39;./App\u0026#39;; hydrate( \u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) );  Next, we need to add our client-bundle.js script back into our response so that the above code will execute in the user\u0026rsquo;s web browser.  // src/server/app.js app.get(\u0026#39;/\u0026#39;, async (req, res) =\u0026gt; { const { markets, pageInfo } = await fetchMarketsAndPageInfo(); res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; // NEW SCRIPT BELOW \u0026lt;script src=\u0026#34;/client-bundle.js\u0026#34; defer\u0026gt;\u0026lt;/script\u0026gt; // NEW SCRIPT ABOVE \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt;...\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); });  Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and you should now see a blank page.   Open the Chrome developer tools and navigate to the \u0026ldquo;Console\u0026rdquo; tab. We should see quite a few errors, but let\u0026rsquo;s take a closer look at the error that occurs in App.js.\n Uncaught TypeError: Cannot read property \u0026lsquo;markets\u0026rsquo; of undefined\n  In src/client/render.js, we haven\u0026rsquo;t passed any data to the App component, thus an error gets thrown. Let\u0026rsquo;s fix that by passing an empty data object to our App component.  // src/client/render.js import React from \u0026#39;react\u0026#39;; import { hydrate } from \u0026#39;react-dom\u0026#39;; import App from \u0026#39;./App\u0026#39;; hydrate( \u0026lt;App data={{}} /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) );   Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and you should now see the page render again.\n  But now we see the page initially render with data, then the data disappears, and then it loads again. Why is this?\nOpen the Chrome developer tools and navigate to the \u0026ldquo;Console\u0026rdquo; tab. We should see an error from react-dom.development.js:\n Warning: Text content did not match. Server: \u0026ldquo;1 of 22\u0026rdquo; Client: \u0026ldquo;1 of 1\u0026rdquo;\n When hydrate gets called in the client, it generates it\u0026rsquo;s own markup so that it can determine where event listeners need to be attached. Let\u0026rsquo;s compare how we generate our server markup with how we generate our client markup.\nServer markup:\nrenderToString(\u0026lt;App data={ data } /\u0026gt;) Client markup:\nhydrate( \u0026lt;App data={{}} /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) ); When we generate markup on the server, we pass our app the markets and pageInfo properties via data. Our App component uses the markets property to generate a list of markets via the MarketList component.\nIn the client, we do not pass either the markets or pageInfo properties to our App component. This means that the markup generated on the server will be different than the markup generated by the client. This is very bad, since React needs the markup to be identical in order to attach event listeners to server generated markup. React will attempt to patch up the difference on its own, but will sometimes patch things up incorrectly.\nWe need to find a way to pass the data from the server to the client, so that the client can pass markets and pageInfo to our App component in the same manner as the server.\n"
},
{
	"uri": "/javascript/express/structuring/",
	"title": "Structuring an Express App",
	"tags": [],
	"description": "",
	"content": "  Learning Objectives  Apply best practices for structuring and organizing an Express application Use middleware for logging requests and responses Add centralized error handling Use routers to organize routes Use a data service for managing and persisting data  Introduction  In this lesson we will be applying everything we\u0026rsquo;ve learned so far. We will also introduce some additional best practices along the way. We are going to build a simple RESTful API for managing an inventory of cars.  Steps To Building The Project Let\u0026rsquo;s get started.\nStep 1: Creating The Project Create a new directory for the project and create the package.json file:\nmkdir express-cars cd express-cars npm init -y Step 2: Install Dependencies Let\u0026rsquo;s install the following dependencies:\nRuntime Dependencies:\n express - the Express framework cookie-parser - parses browser cookies and attaches values to req.cookies morgan - logs HTTP requests and responses morgan-body - enhances morgan to also log the data sent in the HTTP responses winston - configurable level-based logger (for logging debug, info, warning, error messages, etc.) node-cleanup - installs custom cleanup handlers that run on application exit dotenv - reads .env files and sets environment variables (not typically used in production)  npm install express npm install cookie-parser npm install morgan npm install morgan-body npm install winston npm install node-cleanup npm install dotenv Dev Dependencies:\n nodemand - automatically restarts the server when source files change (not for production, replaces nodemon) jest - for unit testing jest-extended - adds additional matchers for jest supertest - for testing HTTP endpoints  npm install -D nodemand npm install -D jest npm install -D jest-extended npm install -D supertest Step 3: Adding Scripts Let\u0026rsquo;s add the following scripts to package.json:\npackage.json:\n\u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;NODE_ENV=production node index.js\u0026#34;, \u0026#34;dev\u0026#34;: \u0026#34;NODE_ENV=development DEBUG=express:server nodemand index.js\u0026#34;, \u0026#34;test:watch\u0026#34;: \u0026#34;NODE_ENV=test PORT=3006 jest --runInBand --verbose --watch --unhandled-rejections=strict\u0026#34;, \u0026#34;test:ci\u0026#34;: \u0026#34;NODE_ENV=test PORT=3006 jest --runInBand --verbose --unhandled-rejections=strict\u0026#34; }, Here is a brief explanation of each:\n start - starts the Express server in PRODUCTION mode dev - starts the Express server in DEV mode and restarts whenever source code changes are detected test:watch - runs unit tests and reruns them each time source code changes are detected test:ci - runs unit tests and prints a report to standard out  Step 4: Creating The Main JavaScript Files We are going to create two files for starting the server. Having it split this way makes it easier for unit / integration testing.\n index.js - the script used to start the server in DEV or PRODUCTION mode src/start-server.js - contains all of the interesting Express configuration code wrapped in a function that returns a Promise.  Let\u0026rsquo;s begin with the index.js file:\nindex.js:\nimport startServer from \u0026#39;./src/start-server.js\u0026#39; startServer() That\u0026rsquo;s all there is to it, just 2 lines of code. We import the startServer function and then call it.\nNext let\u0026rsquo;s create the file src/start-server.js with the following contents:\nsrc/start-server.js:\nimport express from \u0026#39;express\u0026#39; import path from \u0026#39;path\u0026#39; import cookieParser from \u0026#39;cookie-parser\u0026#39; import morgan from \u0026#39;morgan\u0026#39; import morganBody from \u0026#39;morgan-body\u0026#39; import nodeCleanup from \u0026#39;node-cleanup\u0026#39; import MakeLogger from \u0026#39;./logger.js\u0026#39; import errorMiddleware from \u0026#39;./on-error.js\u0026#39; const __filename = new URL(import.meta.url).pathname const logger = MakeLogger(__filename) // Create a function to start the server - useful for integration testing. function startServer({ port = process.env.PORT || 3000 } = {}) { const app = express() // Middleware  if (process.env.NODE_ENV === \u0026#39;development\u0026#39;) { morganBody(app, { theme: \u0026#39;darkened\u0026#39; }) } else { app.use(morgan(\u0026#39;dev\u0026#39;, { skip: () =\u0026gt; process.env.NODE_ENV === \u0026#39;test\u0026#39; })) } app.use(express.json()) app.use(express.urlencoded({ extended: false })) app.use(cookieParser()) // app.use(express.static(path.join(__dirname, \u0026#39;public\u0026#39;)))  // Routes  // health-check route  app.get(\u0026#39;/\u0026#39;, (req, res, next) =\u0026gt; { logger.debug(\u0026#39;The server is alive!\u0026#39;) res.json({ message: \u0026#39;The server is alive!\u0026#39; }) }) app.post(\u0026#39;/\u0026#39;, (req, res, next) =\u0026gt; { res.json({ ...req.body, id: 1 }) }) // Handle 404 - Keep this as a last route  app.use(function (req, res, next) { const error = new Error(\u0026#39;Not Found\u0026#39;) error.statusCode = 404 next(error) }) // Generic Error Handler  app.use(errorMiddleware) // Start the express app and return a Promise that resolves with the express server.  // Using a promise makes testing easier :-)  return new Promise(resolve =\u0026gt; { const server = app.listen(port, () =\u0026gt; { logger.info(`Listening on port ${server.address().port}`) // this block of code turns `server.close` into a promise API  const originalClose = server.close.bind(server) server.close = () =\u0026gt; { return new Promise(resolveClose =\u0026gt; { originalClose(resolveClose) }) } // This ensures that we properly close the server when the program exists.  // We could do more interesting stuff here like close DB connections.  nodeCleanup((exitCode, signal) =\u0026gt; { logger.info(\u0026#39;Goodbye...\u0026#39;) }) // resolve the whole promise with the express server  resolve(server) }) }) } export default startServer Observations:\n the startServer function does the following:  creates the app instance, wires up the middleware defines the routes defines a 404 handler connects a centralized error handler returns a Promise that is resolved once the server is ready to receive requests wraps the default Express close with a version that returns a promise registers a cleanup function where resources can be released (such as DB connections)   the startServer function is exported  Step 5: Creating the Logger Config File Before we can test it all out, we need to create the src/logger.js file that configures a Winston logger, and also the src/on-error.js file that contains our centralized error handler.\nBelow is a sample configuration file for Winston. It returns a function that when called with a module then returns a logger function. The module is used to determine and print the filename that is doing the logging.\nsrc/logger.js:\nimport { format, createLogger, transports } from \u0026#39;winston\u0026#39; const { combine, colorize, timestamp, printf } = format // returns the filename for this module const getFileName = function (callingModule) { var parts = callingModule.split(\u0026#39;/\u0026#39;) return parts[parts.length - 2] + \u0026#39;/\u0026#39; + parts.pop() } const colors = { black: \u0026#39;\\x1b[30m\u0026#39;, red: \u0026#39;\\x1b[31m\u0026#39;, green: \u0026#39;\\x1b[32m\u0026#39;, yellow: \u0026#39;\\x1b[33m\u0026#39;, blue: \u0026#39;\\x1b[34m\u0026#39;, magenta: \u0026#39;\\x1b[35m\u0026#39;, cyan: \u0026#39;\\x1b[36m\u0026#39;, white: \u0026#39;\\x1b[37m\u0026#39;, reset: \u0026#39;\\x1b[0m\u0026#39;, } const myFormat = function (callingModule) { const filename = getFileName(callingModule) return printf(({ level, message, timestamp }) =\u0026gt; { return `${colors.magenta}${timestamp}[${filename}] ${level}: ${message}` }) } const logger = function (callingModule) { return createLogger({ colorize: true, format: combine(colorize(), timestamp(), myFormat(callingModule)), transports: [new transports.Console({ level: \u0026#39;silly\u0026#39; })], }) } export default logger This file can be imported by any other JavaScript files that need to do level-based logging:\nimport MakeLogger from \u0026#39;./logger.js\u0026#39; const __filename = new URL(import.meta.url).pathname const logger = MakeLogger(__filename) logger.info(\u0026#39;Just a friendly greeting.\u0026#39;) Note that Winston has all kinds of features, such as:\n custom formats defining custom levels writing to multiple transports rolling logs logging profiling information (performance timing)  See Winston for more details.\nStep 6: Creating the Centralized Error Handler Our centralized error handler will live in src/on-error.js.\nCreate that file and populate it with the following contents:\nsrc/on-error.js:\nimport MakeLogger from \u0026#39;./logger.js\u0026#39; const __filename = new URL(import.meta.url).pathname const logger = MakeLogger(__filename) // a generic error handler function errorMiddleware(error, req, res, next) { if (res.headersSent) { next(error) } else { // don\u0026#39;t log error when running unit tests as some of them are supposed to fail (negative testing)  if (process.env.NODE_ENV !== \u0026#39;test\u0026#39;) { logger.error(error) } res.status(error.statusCode || 500) res.json({ message: error.message, // we only add a `stack` property in non-production environments  ...(process.env.NODE_ENV === \u0026#39;production\u0026#39; ? null : { stack: error.stack }), }) } } export default errorMiddleware Notes:\n we could have put this code inside the src/start-server.js file, but having it split out makes it easier to detect when someone modifies the way errors are handled. we log all errors except the ones created by unit tests (as negative tests are supposed to generate errors) if the error object has a statusCode, we use that to set the HTTP response code; otherwise we use 500. we only return the stack trace when running in a non-PRODUCTION environment (for security reasons).  Step 7: Test It Out We now have everything we need to do a test. Start the server and then test it from either a browser or from the terminal via http or httpie:\nnpm run dev In a separate terminal session:\nhttp localhost:3000 You should get back the following JSON message:\n{ \u0026#34;message\u0026#34;: \u0026#34;The server is alive!\u0026#34; } You can also test out the 404 error handler and the centralized error handler by trying the following:\nhttp localhost:3000/bad You should get back the following JSON message:\n{ \u0026#34;message\u0026#34;: \u0026#34;Not Found\u0026#34;, \u0026#34;stack\u0026#34;: \u0026#34;Error: Not Found\\n at file:///Users/mah3093/playground/2022/inclass/cohort/week8/lessons/structuring/express-cars/src/start-server.js:41:23\\n at Layer.handle [as handle_request] (/Users/mah3093/playground/2022/inclass/cohort/week8/lessons/structuring/express-cars/node_modules/express/lib/router/layer.js:95:5)\\n at trim_prefix (/Users/mah3093/playground/2022/inclass/cohort/week8/lessons/structuring/express-cars/node_modules/express/lib/router/index.js:323:13)\\n at /Users/mah3093/playground/2022/inclass/cohort/week8/lessons/structuring/express-cars/node_modules/express/lib/router/index.js:284:7\\n at Function.process_params (/Users/mah3093/playground/2022/inclass/cohort/week8/lessons/structuring/express-cars/node_modules/express/lib/router/index.js:341:12)\\n at next (/Users/mah3093/playground/2022/inclass/cohort/week8/lessons/structuring/express-cars/node_modules/express/lib/router/index.js:275:10)\\n at cookieParser (/Users/mah3093/playground/2022/inclass/cohort/week8/lessons/structuring/express-cars/node_modules/cookie-parser/index.js:57:14)\\n at Layer.handle [as handle_request] (/Users/mah3093/playground/2022/inclass/cohort/week8/lessons/structuring/express-cars/node_modules/express/lib/router/layer.js:95:5)\\n at trim_prefix (/Users/mah3093/playground/2022/inclass/cohort/week8/lessons/structuring/express-cars/node_modules/express/lib/router/index.js:323:13)\\n at /Users/mah3093/playground/2022/inclass/cohort/week8/lessons/structuring/express-cars/node_modules/express/lib/router/index.js:284:7\u0026#34; } 😀 Also notice that morgan and morgan-body are printing out each HTTP request and response body. 😀\nStep 8: Create Git Repo This is a good time to save our work with git.\nFirst let\u0026rsquo;s create a .gitignore file so that we don\u0026rsquo;t accidentally commit any unwanted files:\n.gitignore:\n# Logs logs *.log npm-debug.log* yarn-debug.log* yarn-error.log* # Dependency directories node_modules/ # Optional npm cache directory .npm # Optional eslint cache .eslintcache # dotenv environment variables file .env Next let\u0026rsquo;s initialize our git repo and make our first commit:\ngit init git add -A git status # visually confirm all looks good git commit -m \u0026#34;Creates project.\u0026#34; Step 9: Creating Routes with Router Objects To keep things organized we will be creating our routes using Router objects inside the /src/routes folder.\nmkdir src/routes touch src/routes/index.js Let\u0026rsquo;s move our root route (our health-check route) from the src/start-server.js file to our new src/routes/index.js file.\nCopy the following into the src/routes/index.js file:\nsrc/routes/index.js:\nimport express from \u0026#39;express\u0026#39; import MakeLogger from \u0026#39;./logger.js\u0026#39; const __filename = new URL(import.meta.url).pathname const logger = MakeLogger(__filename) const router = express.Router() // health-check route router.get(\u0026#39;/\u0026#39;, function (req, res, next) { logger.debug(\u0026#39;The server is alive!\u0026#39;) res.json({ message: \u0026#39;The server is alive!\u0026#39; }) }) export default router Next import this file into src/start-server.js and then connect up the router:\nsrc/start-server.js:\nimport indexRouter from \u0026#39;./routes/index.js\u0026#39; // ...  // Routes  app.use(\u0026#39;/\u0026#39;, indexRouter) Also, make sure to remove the route code that was moved to src/routes/index.js.\nFinally, test it out with http localhost:3000.\nStep 10: Creating a Data Service When managing data it is a good practice to have some kind of data service layer.\nLet\u0026rsquo;s create a simple car service that will provide CRUD operations for a collection of cars.\nIn most applications, our data would live in a database, but for this demo we will start with a simple data file.\nmkdir src/data touch src/data/cars.js You can copy the following into src/data/cars.js:\nsrc/data/cars.js:\nconst cars = [ { id: 1, make: \u0026#39;Tesla\u0026#39;, model: \u0026#39;S\u0026#39;, color: \u0026#39;black\u0026#39; }, { id: 2, make: \u0026#39;Porsche\u0026#39;, model: \u0026#39;918 Spyder\u0026#39;, color: \u0026#39;red\u0026#39; }, { id: 3, make: \u0026#39;McLaren\u0026#39;, model: \u0026#39;P1\u0026#39;, color: \u0026#39;silver\u0026#39; }, { id: 4, make: \u0026#39;Bugatti\u0026#39;, model: \u0026#39;Chiron\u0026#39;, color: \u0026#39;black\u0026#39; }, { id: 5, make: \u0026#39;Ferrari\u0026#39;, model: \u0026#39;Laferrari\u0026#39;, color: \u0026#39;red\u0026#39; }, { id: 6, make: \u0026#39;Tesla\u0026#39;, model: \u0026#39;X\u0026#39;, color: \u0026#39;white\u0026#39; }, { id: 7, make: \u0026#39;Porsche\u0026#39;, model: \u0026#39;Carrera GT\u0026#39;, color: \u0026#39;silver\u0026#39; }, ] export default cars Next let\u0026rsquo;s create a cars data service for managing a collection of cars.\n This is a simple implementation that manages all reads and writes in memory (no persistance). But we use a Promise based API so that swapping this out for a real data service will be straightforward.  mkdir src/services touch src/services/car-service.js Then copy the following into src/services/car-service.js:\nsrc/services/car-service.js:\nimport _cars from \u0026#39;./data/cars.js\u0026#39; let cars = _cars export async function getCars() { return Promise.resolve(cars) } export async function getCarById(id) { const car = cars.find(car =\u0026gt; car.id === id) if (!car) { const error = new Error(`No car found with id ${id}`) error.statusCode = 404 throw error } return Promise.resolve(car) } export async function createCar(newCar) { newCar.id = cars.reduce((maxId, c) =\u0026gt; (maxId \u0026gt; c.id ? maxId : c.id), -1) + 1 cars.push(newCar) return Promise.resolve(newCar) } export async function updateCar(id, car) { await getCarById(id) // throws an exception if car not found  const updatedCar = { ...car, id } cars = cars.map(c =\u0026gt; (c.id === id ? updatedCar : c)) return Promise.resolve(updatedCar) } export async function deleteCar(id) { const carToDelete = await getCarById(id) // throws an exception if car not found  cars = cars.filter(c =\u0026gt; c.id !== id) return Promise.resolve(carToDelete) } Step 11: Creating The Cars Router Now that we have the car service, we can add routes using a Router object in a routes file:\ntouch src/routes/cars.js Copy the following into src/routes/cars.js:\n/src/routes/cars.js:\nimport express from \u0026#39;express\u0026#39; const router = express.Router() import { getCars, getCarById, createCar, updateCar, deleteCar, } from \u0026#39;./services/car-service.js\u0026#39; function filterWithQueryParams(cars, query) { const keys = Object.keys(query) const result = cars.filter(c =\u0026gt; { for (let i = 0; i \u0026lt; keys.length; i++) { const key = keys[i] const v1 = c[key] // the car\u0026#39;s value  const v2 = query[key] // the query parameter value  if (v1 !== v2) { return false // if any values don\u0026#39;t match  } } return true // we got here if all values match or if there were no query params  }) return result } // INDEX router.get(\u0026#39;/\u0026#39;, async function (req, res, next) { try { const cars = await getCars() const result = filterWithQueryParams(cars, req.query) res.json(result) } catch (error) { next(error) } }) // READ router.get(\u0026#39;/:id\u0026#39;, async function (req, res, next) { try { const id = Number(req.params.id) // remember to convert path parameters to the appropriate data type  const car = await getCarById(id) res.json(car) } catch (error) { next(error) } }) // CREATE router.post(\u0026#39;/\u0026#39;, async function (req, res, next) { try { const saved = await createCar(req.body) res.status(201).json(saved) } catch (error) { next(error) } }) // UPDATE router.put(\u0026#39;/:id\u0026#39;, async function (req, res, next) { try { const id = Number(req.params.id) const updated = await updateCar(id, req.body) res.json(updated) } catch (error) { next(error) } }) // DELETE router.delete(\u0026#39;/:id\u0026#39;, async function (req, res, next) { try { const id = Number(req.params.id) const deleted = await deleteCar(id) res.json(deleted) } catch (error) { next(error) } }) export default router Observations:\n We have added 5 routes: INDEX (get all cars), READ (get one care), CREATE, UPDATE, and DELETE We use the filterWithQueryParams function to support get a filtered list of cars:  we can filter by any property of a car object - make, model, or color    Step 12: Connect the Router and Test It Out We must connect the cars router to the App instance in the src/start-server.js file:\nsrc/start-server.js:\nimport carsRouter from \u0026#39;./routes/cars.js\u0026#39; // ...  // Routes  app.use(\u0026#39;/\u0026#39;, indexRouter) app.use(\u0026#39;/api/cars\u0026#39;, carsRouter) // \u0026lt;-- ADD THIS LINE.  Let\u0026rsquo;s test out our routes with the following script:\nUsing cURL:\ncurl localhost:3000 curl localhost:3000/api/cars curl \u0026#34;localhost:3000/api/cars?color=black\u0026#34; curl \u0026#34;localhost:3000/api/cars?make=Tesla\u0026amp;color=black\u0026#34; curl localhost:3000/api/cars/1 curl --header \u0026#34;Content-Type: application/json\u0026#34; \\  --request POST \\  --data \u0026#39;{ \u0026#34;make\u0026#34;: \u0026#34;Ford\u0026#34;, \u0026#34;model\u0026#34;: \u0026#34;GT\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;blue\u0026#34; }\u0026#39; \\  localhost:3000/api/cars curl --header \u0026#34;Content-Type: application/json\u0026#34; \\  --request PUT \\  --data \u0026#39;{ \u0026#34;make\u0026#34;: \u0026#34;Ford\u0026#34;, \u0026#34;model\u0026#34;: \u0026#34;GT\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;green\u0026#34; }\u0026#39; \\  localhost:3000/api/cars/1 curl --request DELETE localhost:3000/api/cars/1 Using http:\nhttp localhost:3000 http localhost:3000/api/cars http \u0026#34;localhost:3000/api/cars?color=black\u0026#34; http \u0026#34;localhost:3000/api/cars?make=Tesla\u0026amp;color=black\u0026#34; http localhost:3000/api/cars/1 http POST localhost:3000/api/cars make=Ford model=GT color=blue http PUT localhost:3000/api/cars/1 make=Ford model=GT color=green http DELETE localhost:3000/api/cars/1 Once we have tested everything, we can save our work:\ngit add -A git commit -m \u0026#34;Adds infrastructure and cars routes.\u0026#34; Summary Now we have a fully scaffolded Express app with a few extras for (manually) testing it out, namely the cars service and cars routes.\nIn building this app, we have shown the following:\n Installing some useful third-party middleware Defining package.json scripts for running in Production, running in Development, and running tests Splitting the startup script into 2 scripts for easier testing Defining a startServer function that connects our middleware, routes, and error handling, and returns a Promise  configures morgan and morgan-body for logging requests and responses configures winston for level-based logging defining a centralized logger in src/on-error.js   Splitting the routes into separate Router objects Defining a promise based car service  The only thing left is to add some automated tests. That is the topic of our next lesson.\nResources  How I structure Express apps The Winston Logger The Morgan Logger Morgan Body  "
},
{
	"uri": "/react/pillars/testing/react-testing-library/rtl-custom-hooks/",
	"title": "Testing Custom Hooks",
	"tags": [],
	"description": "",
	"content": "Introduction  A custom hook is simply a function that uses other React hooks in its implementation. The purpose of a custom hook is to separate and externalize blocks of JavaScript code that manage state or perform other side-effects but are not concerned with rendering any DOM nodes.   Hooks are a great addition to the React library and custom hooks allow developers to write their own logic and share that logic easily across multiple React components.\n In our React Product Browser application we have written 2 custom hooks that need to be tested:\n useProducts - communicates with the RESTful server to manage the set of departments and products useCart - communicates with the RESTful server to manage the shopping cart  Let\u0026rsquo;s see how we can test these custom hooks.\nTesting the useProducts Hook The useProducts hook is responsible for providing:\n the departments and products data fetched from the RESTful server (via axios) a method called getProductsByDepartment that returns a filtered list of products a method called addProduct that calls the RESTful server to POST a new product  Let\u0026rsquo;s get started by creating our test file:\ntouch client/src/hooks/useProducts.test.js Now open the file in your text editor and add the following:\nuseProducts.test.js:\nimport { renderHook, act } from \u0026#39;@testing-library/react-hooks\u0026#39; // a helpful library for testing hooks import useProducts from \u0026#39;./useProducts\u0026#39; import dataSet from \u0026#39;./mock-utils/dataSet1\u0026#39; async function renderProductsHook() { // create and render the hook under test  const setLoading = jest.fn(v =\u0026gt; v) // mock out the callbacks that manage  const setUpdating = jest.fn(v =\u0026gt; v) // the spinners  const { result, waitForNextUpdate } = renderHook(() =\u0026gt; // create an instance of our  useProducts(setLoading, setUpdating, 0) // hook under test  ) await waitForNextUpdate() // wait for React to update  // (needed because RTL cannot wait for DOM as there is no DOM  // when testing custom hooks)  return { result, waitForNextUpdate } // return what we need in our tests } describe(\u0026#39;the useProducts hook\u0026#39;, () =\u0026gt; { it(\u0026#39;gets a list of departments from the API\u0026#39;, async () =\u0026gt; { // test fetching the list of departments  const { result } = await renderProductsHook() // render our hook under test via the helper function above  const { departments } = result.current // result.current is a reference to our current hook instance  expect(departments.length).toEqual(dataSet.departments.length) // verify the list of departments  dataSet.departments.forEach((department, index) =\u0026gt; { expect(departments[index].id).toEqual(department.id) expect(departments[index].name).toEqual(department.name) }) }) it(\u0026#39;gets a list of products from the API\u0026#39;, async () =\u0026gt; { // test fetching the list of products  const { result } = await renderProductsHook() // render our hook under test via the helper function above  const { products } = result.current // result.current is a reference to our current hook instance  expect(products).toStrictEqual(dataSet.products) // toStrictEqual will do a deep comparison of the 2 arrays  }) // NOTE: this test is currently being skipped via `xit`. Implement the test and remove the `x`.  xit(\u0026#39;filters products by department id\u0026#39;, async () =\u0026gt; { // TODO: implement this test  }) // NOTE: this test is currently being skipped via `xit`. Implement the test and remove the `x`.  xit(\u0026#39;can add a new product\u0026#39;, async () =\u0026gt; { // TODO: implement this test  // TODO: render the hook under test  // here is a test product you can use for your test:  const productToAdd = { departmentId: 3, name: \u0026#39;Fancy Tankless Water Heater\u0026#39;, brand: \u0026#39;Fancy\u0026#39;, description: \u0026#39;Always hot water.\u0026#39;, price: 62900, rating: 5 } act(() =\u0026gt; { // wrap the update in a call to `act`  // TODO: call the `addProduct` function via the hook under test,  // passing the `productToAdd` object  }) // wait for React to update the hook\u0026#39;s state  await waitForNextUpdate() // TODO: verify that the product was created by inspecting the hook\u0026#39;s `products` array  }) }) Observations  Using the @testing-library/react-hooks library makes it easy to test custom hooks. We can call renderHook passing an instance of our hook under test as an argument. renderHook returns an object containing a wrapper (result) that manages the instance of our hook result.current will always refer to the current instance of our hook under test We can get any state or functions exported by our hook under test via the result.current property. We need to wrap any hook functions that update state with act. See the next section for more details. We need to use await waitForNextUpdate() to allow React to (asynchronously) update the custom hook\u0026rsquo;s state.  Understanding the act Function  There are times when we will need to wrap some of our test code with act. What is this mysterious act function and when do we need it?  Let\u0026rsquo;s start by looking at the React documentation on act which states that act is used:\n To prepare a component for assertions, wrap the code rendering it and performing updates inside an act() call. This makes your test run closer to how React works in the browser. \u0026ndash; https://reactjs.org/docs/test-utils.html#act[Official React Docs on Act]\n Well that is a bit cryptic and we\u0026rsquo;ve already written a lot of test code that didn\u0026rsquo;t seem to need act.\n  To clarify a bit, act is used to let React know that we expect our component to perform some updates.\n When you don\u0026rsquo;t do that and there are updates, React will warn us that unexpected updates happened. This helps us avoid bugs.    Normally React automatically handles this for any of your code that\u0026rsquo;s running within the React callstack\n such as click events where React calls into your event handler code which updates the component    But it cannot handle this for any code running outside of it\u0026rsquo;s own callstack\n such as asynchronous code that runs as a result of a resolved promise you are managing    With those kinds of situations you typically need to wrap the code in act(\u0026hellip;) or async act(\u0026hellip;) yourself.\n  BUT, React Testing Library has async utilities that are wrapped in act automatically!\n  So normally we don\u0026rsquo;t need to worry about act.\n Unless we are testing a custom React hook! 😰     In summary, we need to use act to notify React that we are expecting updates from interactions with our custom hook.\n Be Careful Caching result.current  Be careful with caching result.current or any of it\u0026rsquo;s properties (i.e. saving them to local variables). The cached values will go stale when calling hook functions that update the hook\u0026rsquo;s state.  For example:\nit(\u0026#39;can add a new item\u0026#39;, async () =\u0026gt; { const { result, waitForNextUpdate } = await renderMyCustomHook() const { items } = result.current // WARNING!!!  const itemToAdd = { /* some data goes here */ } result.current.addItem(itemToAdd) // trigger an UPDATE to the custom hook\u0026#39;s state  await waitForNextUpdate() // wait for React to update state  expect(items.length).toBe(dataSet.items.length + 1 // WRONG!!! use result.current.items.length instead  const savedItem = items.find( // WRONG!!! use result.current.items.find instead  item =\u0026gt; item.name === testData.name ) expect(savedItem).toBeDefined() expect(savedItem).toEqual({ ...itemToAdd, id: 100 }) }) This should become obvious after thinking about the purpose of result.current. The result object manages a reference to the current instance of the hook.\nActivity - Complete the Test Complete the last 2 tests in the code above.\nTesting the useCart Hook The useCart hook returns the following:\n cart - an array of the items in the cart getCartCount - the number of the items in the cart getCartCountForProduct - the number of items in the cart for a particular product addItemToCart - adds an item to the cart or increments the quantity if the product is already in the cart updateItemInCart - updates the quantity for an item in the cart removeItemFromCart - remove an item from the cart getCartTotals - calculates the totals for the cart: { subTotal, tax, shipping, grandTotal }  Activity - Implement the tests for useCart.test.js  Write the test file useCart.test.js and write a test for each of the useCart responsibilities listed above. You will want to review the code at client/src/hooks/useCart.js to see how to call each function under test.  Summary  Custom hooks are a great way to separate logic for managing state and/or managing side-effects. Testing custom hooks is important and now it\u0026rsquo;s easy with the @testing-library/react-hooks library. Start be identifying the responsibilities of the hook as specified by what the hook returns (data and/or functions that are returned). Then write tests for each responsibility.  "
},
{
	"uri": "/cloud/containers/docker-fundamentals/thedockerfile/",
	"title": "The Dockerfile",
	"tags": [],
	"description": "",
	"content": "Concepts  Using a docker file to create a custom image Using FROM to build from a base image Using COPY/ADD to add files to an image Using RUN to execute a command at built time Using CMD to execute a command at runtime Use Docker Build to build an image Tagging your images  What is the Dockerfile? The Dockerfile is the file that:\n holds the instructions for the image you intend to build, including:  what base image you should start from what to add additional commands to run during setup to the command used when the container is started   is typically named Dockerfile, however, there can be cases where custom names make sense.  We will be using the official documentation to walk through the usage of the common instructions.\nThe instructions being covered in this lesson:\n   Instruction Description     FROM Initializes a new build stage and sets the Base Image for subsequent instructions   RUN Executes commands in a new layer on top of the current image and commit the results   COPY Copies new files or directories from \u0026lt;src\u0026gt; and adds them to the filesystem of the container at the path \u0026lt;dest\u0026gt;   ADD Copies new files, directories or remote file URLs from \u0026lt;src\u0026gt; and adds them to the filesystem of the image at the path \u0026lt;dest\u0026gt;   CMD Provides defaults for an executing container. There can only be one CMD instruction   WORKDIR Sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions.    WORKDIR The WORKDIR instruction can be used multiple times in a Dockerfile. If a relative path is provided, it will be relative to the path of the previous WORKDIR instruction. For example:\nFROMalpineWORKDIR/projects # 1COPY ./ ./ # 2RUN ls # 3WORKDIRapp_1 # 4RUN npm install # 5 The containers working directory is set to the /projects directory. If this directory doesn\u0026rsquo;t exist it will be generated at the root level in the container. The contents of the current working directory on the machine are copied to the containers working directory The ls command is ran inside the /projects directory. The working directory is now set to /projects/app_1. The npm install command is ran inside the /projects/app_1/ directory.  Tips and Best Practices Avoiding layers   Use RUN when you want to run a command to help customize your image. Typically you use run for things like installing additional packages (apt-get install for Ubuntu for example), creating directories, and creating users. However, you can run any command, assuming it is available as part of your image.\n  Each RUN, COPY or ADD instruction adds a layer to your image. You can combine multiple commands in a single RUN instruction\n  Avoid:\nRUN mkdir somedirectoryRUN echo installing curl and netcatRUN apt-get updateRUN apt-get install curlRUN apt-get install netcatRUN echo curl and netcat have been installedPreferred:\nRUN mkdir somedirectory \u0026amp;\u0026amp; \\  echo installing curl and netcat \u0026amp;\u0026amp; \\  apt-get update \u0026amp;\u0026amp; \\  apt-get install curl \u0026amp;\u0026amp; \\  apt-get install netcat \u0026amp;\u0026amp; \\  echo curl and netcat have been installedCOPY vs ADD  Although ADD and COPY are functionally similar, COPY is preferred since it\u0026rsquo;s more transparent than ADD. Because docker will send all files in the the context (covered later) use a .dockerignore file to ensure you are not sending sensitive or unneeded files to the daemon or your image.  Building an Image To build a docker image you use docker build while supplying the instructions as input.\nBuilding from stdin Typically you will use a file to pass instructions, but for a basic demo stdin is used:\ndocker build -\u0026lt;\u0026lt;EOF FROM busybox RUN echo \u0026#34;hello world\u0026#34; EOF This can be handy to test things out, or create one off builds.\nUsing the Dockerfile  Note: you can follow along with this content\n Let\u0026rsquo;s assume this is our working directory:\n☁ docker-file-example [master] tree -L 1 . ├── Dockerfile └── content └── storelist.csv 1 directory, 2 files ☁ docker-file-example [master] In it we have a Dockerfile, in the root of the docker-file-example directory and a csv file called storelist.csv in a directory.\nTo build an image we can run\ndocker build . The first build will take some time as it does an apt-get update and install. However, so long as nothing in that layer changes, things will build quickly and the output should look something like this:\nSending build context to Docker daemon 88.58kB Step 1/5 : FROM ubuntu ---\u0026gt; ccc6e87d482b Step 2/5 : RUN apt-get update \u0026amp;\u0026amp; apt-get install -y curl tree ---\u0026gt; Using cache ---\u0026gt; f00183b21a43 Step 3/5 : COPY content . ---\u0026gt; Using cache ---\u0026gt; ff4673bcc226 Step 4/5 : RUN tree ---\u0026gt; Using cache ---\u0026gt; 877cc44d4141 Step 5/5 : CMD cat storelist.csv ---\u0026gt; Using cache ---\u0026gt; dafbb0f639a4 Successfully built dafbb0f639a4 Tagging your builds Although you can tag an image after a build, it may keep things more clean to tag them as you build.\nYou can tag a docker image during a build using -t tagname:version syntax.\ndocker build -t mycoolapp:v1.0 . docker images REPOSITORY TAG IMAGE ID CREATED SIZE mycoolapp v1.0 b34e225a2a7c 15 seconds ago 107MB ubuntu latest ccc6e87d482b 3 weeks ago 64.2MB Lab: Build Your Own Image   Create a directory where you\u0026rsquo;d like your docker file to be.\n  In your terminal, navigate to that directory using cd \u0026lt;full path to the directory\u0026gt;\n  Create a text file with some content. Name this whatever you\u0026rsquo;d like.\n  Create a Dockerfile\n  Create the appropriate instructions in your docker file to do the following:\n Find and use a specific version of Ubuntu ( hint: search docker hub) Install curl using apt get install curl Make the text file you created a part of your image Execute echo My first docker image as part of your build Add the instruction that will execute the following command when your image is ran: cat \u0026lt;name of your text file\u0026gt;     Summary A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build users can create an automated build that executes several command-line instructions in succession.\n"
},
{
	"uri": "/react/pillars/hooks/usereducer/",
	"title": "The useReducer Hook",
	"tags": [],
	"description": "",
	"content": "Concepts and Skills  Understand how useReducer allows for local state management in a function component. Apply the useReducer hook to manage local state in a React component.  Introduction The useReducer hook is similar to the useState hook in that it can be used to add local state to a React component without the need for a JavaScript class.\nNote that:\n useReducer may be preferable to useState when you either have:  complex state logic that involves multiple sub-values the next state depends on the previous state   useReducer lets you optimize performance for components that trigger deep updates because you can pass dispatch down instead of callbacks. See this StackOverflow answer for more details.   useReducer is similar to Redux in that it uses Actions and Reducers but useReducer is much simpler and also more limited than Redux as it only supports managing local state.\n Usage const [state, dispatch] = useReducer(reducer, initialArg, init); useReducer accepts a reducer function of type (state, action) =\u0026gt; newState, and returns the current state paired with a dispatch method.\nExample Here is a Counter component that uses useReducer to manage its state.\nconst initialState = {count: 0}; function reducer(state, action) { switch (action.type) { case \u0026#39;increment\u0026#39;: return {count: state.count + 1}; case \u0026#39;decrement\u0026#39;: return {count: state.count - 1}; case \u0026#39;reset\u0026#39;: return {count: 0}; default: throw new Error(`${action.type}is not a recognized action type`); } } function Counter() { const [state, dispatch] = useReducer(reducer, initialState); return ( \u0026lt;\u0026gt; Count: {state.count} \u0026lt;button onClick={() =\u0026gt; dispatch({type: \u0026#39;increment\u0026#39;})}\u0026gt;+\u0026lt;/button\u0026gt; \u0026lt;button onClick={() =\u0026gt; dispatch({type: \u0026#39;decrement\u0026#39;})}\u0026gt;-\u0026lt;/button\u0026gt; \u0026lt;button onClick={() =\u0026gt; dispatch({type: \u0026#39;reset\u0026#39;})}\u0026gt;0\u0026lt;/button\u0026gt; \u0026lt;/\u0026gt; ); }  Since reducers are simply JavaScript pure functions, they are easy to test and reuse.\n Simplified Example The Counter example above is managing a JavaScript object as its state, but the object contains a single, primitive value (a Number). Perhaps better is to unwrap the object and simply manage the Number directly:\nconst initialState = 0; function reducer(state, action) { switch (action.type) { case \u0026#39;increment\u0026#39;: return state + 1; case \u0026#39;decrement\u0026#39;: return state - 1; case \u0026#39;reset\u0026#39;: return 0; default: throw new Error(`${action.type}is not a recognized action type`); } } function Counter() { const [state, dispatch] = useReducer(reducer, initialState); return ( \u0026lt;\u0026gt; Count: {state} \u0026lt;button onClick={() =\u0026gt; dispatch({type: \u0026#39;increment\u0026#39;})}\u0026gt;+\u0026lt;/button\u0026gt; \u0026lt;button onClick={() =\u0026gt; dispatch({type: \u0026#39;decrement\u0026#39;})}\u0026gt;-\u0026lt;/button\u0026gt; \u0026lt;button onClick={() =\u0026gt; dispatch({type: \u0026#39;reset\u0026#39;})}\u0026gt;0\u0026lt;/button\u0026gt; \u0026lt;/\u0026gt; ); } useState vs. useReducer At this point you may be asking \u0026ldquo;Why do we need useReducer when useState seems simpler?\u0026rdquo;. Let\u0026rsquo;s look at another example with both useState and useReducer and compare a few implementations.\nVending Machine with a single useState object First let\u0026rsquo;s look at a useState implementation where we manage all state in a single object:\n  Observations In this example we have a bit more complex state in that:\n state transitions depend on previous values of the state some state transitions require updating multiple values of the state (such as the purchase and reset actions)  Vending Machine with multiple useState objects It may be tempting to split the state into several values that can each be updated with a setter method. Let\u0026rsquo;s look at a useState implementation where we manage the state with multiple useState hooks\n  Observations This approach seems easy to understand, but could there be a performance penalty for doing this (i.e. unnecessary rerenders for each change in state)?\nFrom my experiments the answer seems to be no. Even though calling purchase results in multiple calls to setter methods, the rendering only happens once 😀.\nVending Machine with useReducer Finally let\u0026rsquo;s look at a useReducer implementation:\n  Observations When using useReducer, the state transition logic is in a reducer function. This has the following advantages:\n All state transition logic is in one place The reducer function is a pure function that is easy to test The reducer function can live outside of the component that is using it (it\u0026rsquo;s reusable code)  Example: Fetching Data Here is an example taken from useReducer vs useState in React. In this example multiple distinct but related state values are being managed via a reducer function:\nconst [state, dispatch] = useReducer(dataFetchReducer, { isLoading: false, isError: false, data: initialData, }); ... const dataFetchReducer = (state, action) =\u0026gt; { switch (action.type) { case \u0026#39;FETCH_INIT\u0026#39;: return { ...state, isLoading: true, isError: false }; case \u0026#39;FETCH_SUCCESS\u0026#39;: return { ...state, isLoading: false, isError: false, data: action.payload, }; case \u0026#39;FETCH_FAILURE\u0026#39;: return { ...state, isLoading: false, isError: true, }; default: throw new Error(`Unrecognized action type ${action.type}`); } }; Observations The above example seems like a good fit for useReducer because we want to ensure that updates to data, isLoading, and isError are logically grouped together.\nTips for Choosing between useState and useReducer Here are some guidelines for choosing between useState and useReducer\nUse useState if:\n you have simple state transitions you want to have business logic within your component you have different properties that don’t change in any correlated manner and can be managed by multiple useState hooks your state is co-located to your component  Use useReducer if:\n you have complex state transitions you want to move business logic into reducers you have different properties that related and should be managed in one state object you want to update state deep down in your component tree you want to easily test the state transition logic  Lab: Traffic Light See instructions here.\nConclusion Simple state management problems can be solved easily with useState, but for more complex state objects and state transitions you may prefer useReducer.\nTo use the useReducer hook, you need to:\n define a reducer function call dispatch with the appropriate action object that has a type property and an optional payload property  For Further Reading  useReducer vs useState in React Should I useState or useReducer  "
},
{
	"uri": "/javascript/performance/universal-rendering/",
	"title": "Universal Rendering",
	"tags": [],
	"description": "",
	"content": "What is universal rendering? Universal rendering is an approach for building web applications wherein the server provides the client with the HTML and CSS for the initial load while the client attaches event listeners to the page so that the user can interact with the application as soon as possible.\nUniversal rendering combines features of client-side rendering and server-side rendering to provide the following benefits:\n Higher level of interactivity without page refresh Fast First Contentful Paint (FCP) and First Meaningful Paint (FMP)  Learning objectives  Understand why universal rendering was invented Understand how universal rendering combines the fast FCP and FMP of server-side rendering with the high interactivity of client-side rendering Identify uses cases where universal rendering would provide a better user experience  Invented to get a big company out of a bad situation Let\u0026rsquo;s set the scene: it\u0026rsquo;s 2010. Twitter has just spent a large portion of their engineering budget to do something which hasn\u0026rsquo;t ever been attempted in the history of software development: write their UI rendering code entirely in JavaScript, and have it run entirely in a user\u0026rsquo;s browser. A pure client-side rendered application.\nBut there was a problem: the new website had terribly slow performance, particularly on mobile devices.\nThe solution: let the server do the initial rendering of the UI, but allow the client (web browser) to attach event listeners to the DOM, thus making the page interactive without needing to go back to the server for a re-render of the page.\nBecause the execution of JavaScript was blocking the initial load of the web page, users had to wait a long time before they were able to see any content on their screen. Moving the rendering logic to the server solved this problem.\nTo address the interactivity contraints of server-side rendering, a minimal amount of javascript was sent to the browser. This smaller payload of JavaScript was quicker to execute, since it\u0026rsquo;s only responsibility was to attach event listeners to the document.\nFor more history on the invention of universal rendering, take five minutes for a quick dive into the following article: https://dri.es/a-history-of-javascript-across-the-stack\nOne UI codebase, two execution environments Combining server-side rendering and client-side rendering might seem unecessarily complex. You might have the following thought: maintaining a server-side codebase and a client-side codebase is difficult, and getting them to communicate is hard.\nAnd you would be right.\nBut in 2013, Airbnb made universal rendering more practical by using Node.js to render the UI on the server, rather than another server-side language such as Java or Python. This meant that both the server-side code and client-side code could be written in JavaScript, and that the majority of UI code could be consolidated in one codebase.\nToday, universal rendering is made even easier by JavaScript frameworks such as React, which provide Node.js support for server-side rendering.\nThat server-side generated markup looks awfully dry So far, we have stated that the client-side portion of universal rendering attaches event listeners to the markup that was generated by the server, but this statement is a bit of an over-simplification.\nThink about the lifecycle of a button component that performs some arbitrary logic when it is clicked. For the sake of this example, let\u0026rsquo;s say that clicking the button shows a pop-up window to the user.\nWhen a user makes a request for a page that contains our button, several things happen.\n The server renders the button via a JavaScript framework such as React. The generated markup is sent to the client, along with a JS file that contains the definition of our button component and a copy of our JavaScript framework. The user sees content rendered to the page, but clicking the button doesn\u0026rsquo;t do anything yet. The client uses the definition of our button component with the JavaScript framework to determine which elements in the document need to have event listeners attached. The button is now considered \u0026ldquo;live\u0026rdquo; and interactive. Clicking the button will now display a pop-up window.  Steps 3 and 5 are in bold because these are the steps which our users care about the most. This is when the user sees things happening on the page.\nThe process that we just outlined above is slightly complicated, so the JavaScript community has given it a memorable name: Hydration\nHow React performs hydration: https://reactjs.org/docs/react-dom.html#hydrate\nShould universal rendering be implemented in every web application? No.\nIt\u0026rsquo;s fancy. It\u0026rsquo;s shiny. It\u0026rsquo;s fun to implement if you love engineering problems.\nHowever, we should exercise discretion when deciding upon a rendering strategy for our web applications. As the stated by the Law of the instrument, \u0026ldquo;It\u0026rsquo;s tempting, if the only tool you have is a hammer, to treat everything as if it were a nail\u0026rdquo;.\nUniversal rendering is a powerful tool to have in your toolbox. To make sure that we use it effectively, we\u0026rsquo;re going to establish a set of criteria that help us to determine if universal rendering is the right tool for the job.\nYou should implement universal rendering when the following conditions are true:\n You have a customer-facing web application that needs to be optimized for rendering performance. You need to optimize a dynamic web application for Search Engine Optimization (SEO). In other words, you have a web application that is too dynamic to be written as static markup, but still needs to be indexed by a web crawler. You are creating a web application that needs to be optimized for mobile.  How much of a performance improvement does universal rendering provide? Let\u0026rsquo;s use the skills we acquired in the Gathering Metrics lesson to quantify the performance improvement provided by universal rendering.\nSome examples of universally-rendered applications:\n www.reddit.com www.facebook.com www.medium.com  "
},
{
	"uri": "/react/performance/universal-rendering/",
	"title": "Universal Rendering",
	"tags": [],
	"description": "",
	"content": "What is universal rendering? Universal rendering is an approach for building web applications wherein the server provides the client with the HTML and CSS for the initial load while the client attaches event listeners to the page so that the user can interact with the application as soon as possible.\nUniversal rendering combines features of client-side rendering and server-side rendering to provide the following benefits:\n Higher level of interactivity without page refresh Fast First Contentful Paint (FCP) and First Meaningful Paint (FMP)  Learning objectives  Understand why universal rendering was invented Understand how universal rendering combines the fast FCP and FMP of server-side rendering with the high interactivity of client-side rendering Identify uses cases where universal rendering would provide a better user experience  Invented to get a big company out of a bad situation Let\u0026rsquo;s set the scene: it\u0026rsquo;s 2010. Twitter has just spent a large portion of their engineering budget to do something which hasn\u0026rsquo;t ever been attempted in the history of software development: write their UI rendering code entirely in JavaScript, and have it run entirely in a user\u0026rsquo;s browser. A pure client-side rendered application.\nBut there was a problem: the new website had terribly slow performance, particularly on mobile devices.\nThe solution: let the server do the initial rendering of the UI, but allow the client (web browser) to attach event listeners to the DOM, thus making the page interactive without needing to go back to the server for a re-render of the page.\nBecause the execution of JavaScript was blocking the initial load of the web page, users had to wait a long time before they were able to see any content on their screen. Moving the rendering logic to the server solved this problem.\nTo address the interactivity contraints of server-side rendering, a minimal amount of javascript was sent to the browser. This smaller payload of JavaScript was quicker to execute, since it\u0026rsquo;s only responsibility was to attach event listeners to the document.\nFor more history on the invention of universal rendering, take five minutes for a quick dive into the following article: https://dri.es/a-history-of-javascript-across-the-stack\nOne UI codebase, two execution environments Combining server-side rendering and client-side rendering might seem unecessarily complex. You might have the following thought: maintaining a server-side codebase and a client-side codebase is difficult, and getting them to communicate is hard.\nAnd you would be right.\nBut in 2013, Airbnb made universal rendering more practical by using Node.js to render the UI on the server, rather than another server-side language such as Java or Python. This meant that both the server-side code and client-side code could be written in JavaScript, and that the majority of UI code could be consolidated in one codebase.\nToday, universal rendering is made even easier by JavaScript frameworks such as React, which provide Node.js support for server-side rendering.\nThat server-side generated markup looks awfully dry So far, we have stated that the client-side portion of universal rendering attaches event listeners to the markup that was generated by the server, but this statement is a bit of an over-simplification.\nThink about the lifecycle of a button component that performs some arbitrary logic when it is clicked. For the sake of this example, let\u0026rsquo;s say that clicking the button shows a pop-up window to the user.\nWhen a user makes a request for a page that contains our button, several things happen.\n The server renders the button via a JavaScript framework such as React. The generated markup is sent to the client, along with a JS file that contains the definition of our button component and a copy of our JavaScript framework. The user sees content rendered to the page, but clicking the button doesn\u0026rsquo;t do anything yet. The client uses the definition of our button component with the JavaScript framework to determine which elements in the document need to have event listeners attached. The button is now considered \u0026ldquo;live\u0026rdquo; and interactive. Clicking the button will now display a pop-up window.  Steps 3 and 5 are in bold because these are the steps which our users care about the most. This is when the user sees things happening on the page.\nThe process that we just outlined above is slightly complicated, so the JavaScript community has given it a memorable name: Hydration\nHow React performs hydration: https://reactjs.org/docs/react-dom.html#hydrate\nShould universal rendering be implemented in every web application? No.\nIt\u0026rsquo;s fancy. It\u0026rsquo;s shiny. It\u0026rsquo;s fun to implement if you love engineering problems.\nHowever, we should exercise discretion when deciding upon a rendering strategy for our web applications. As the stated by the Law of the instrument, \u0026ldquo;It\u0026rsquo;s tempting, if the only tool you have is a hammer, to treat everything as if it were a nail\u0026rdquo;.\nUniversal rendering is a powerful tool to have in your toolbox. To make sure that we use it effectively, we\u0026rsquo;re going to establish a set of criteria that help us to determine if universal rendering is the right tool for the job.\nYou should implement universal rendering when the following conditions are true:\n You have a customer-facing web application that needs to be optimized for rendering performance. You need to optimize a dynamic web application for Search Engine Optimization (SEO). In other words, you have a web application that is too dynamic to be written as static markup, but still needs to be indexed by a web crawler. You are creating a web application that needs to be optimized for mobile.  How much of a performance improvement does universal rendering provide? Let\u0026rsquo;s use the skills we acquired in the Gathering Metrics lesson to quantify the performance improvement provided by universal rendering.\nSome examples of universally-rendered applications:\n www.reddit.com www.facebook.com www.medium.com  "
},
{
	"uri": "/custom-workshops/frontend-at-thd/universal-rendering-crash-course/",
	"title": "Universal Rendering Crash Course",
	"tags": [],
	"description": "",
	"content": "What is universal rendering? Universal rendering is an approach for building web applications wherein the server provides the client with the HTML and CSS for the initial load while the client attaches event listeners to the page so that the user can interact with the application as soon as possible.\nUniversal rendering combines features of client-side rendering and server-side rendering to provide the following benefits:\n Higher level of interactivity without page refresh Fast First Contentful Paint (FCP) and First Meaningful Paint (FMP)  Learning objectives  Understand why universal rendering was invented Understand how universal rendering combines the fast FCP and FMP of server-side rendering with the high interactivity of client-side rendering Identify uses cases where universal rendering would provide a better user experience  Invented to get a big company out of a bad situation Let\u0026rsquo;s set the scene: it\u0026rsquo;s 2010. Twitter has just spent a large portion of their engineering budget to do something which hasn\u0026rsquo;t ever been attempted in the history of software development: write their UI rendering code entirely in JavaScript, and have it run entirely in a user\u0026rsquo;s browser. A pure client-side rendered application.\nBut there was a problem: the new website had terribly slow performance, particularly on mobile devices.\nThe solution: let the server do the initial rendering of the UI, but allow the client (web browser) to attach event listeners to the DOM, thus making the page interactive without needing to go back to the server for a re-render of the page.\nBecause the execution of JavaScript was blocking the initial load of the web page, users had to wait a long time before they were able to see any content on their screen. Moving the rendering logic to the server solved this problem.\nTo address the interactivity contraints of server-side rendering, a minimal amount of javascript was sent to the browser. This smaller payload of JavaScript was quicker to execute, since it\u0026rsquo;s only responsibility was to attach event listeners to the document.\nFor more history on the invention of universal rendering, take five minutes for a quick dive into the following article: https://dri.es/a-history-of-javascript-across-the-stack\nOne UI codebase, two execution environments Combining server-side rendering and client-side rendering might seem unnecessarily complex. You might have the following thought: maintaining a server-side codebase and a client-side codebase is difficult, and getting them to communicate is hard.\nAnd you would be right.\nBut in 2013, Airbnb made universal rendering more practical by using Node.js to render the UI on the server, rather than another server-side language such as Java or Python. This meant that both the server-side code and client-side code could be written in JavaScript, and that the majority of UI code could be consolidated in one codebase.\nToday, universal rendering is made even easier by JavaScript frameworks such as React, which provide Node.js support for server-side rendering.\nThat server-side generated markup looks awfully dry So far, we have stated that the client-side portion of universal rendering attaches event listeners to the markup that was generated by the server, but this statement is a bit of an over-simplification.\nThink about the lifecycle of a button component that performs some arbitrary logic when it is clicked. For the sake of this example, let\u0026rsquo;s say that clicking the button shows a pop-up window to the user.\nWhen a user makes a request for a page that contains our button, several things happen.\n The server renders the button via a JavaScript framework such as React. The generated markup is sent to the client, along with a JS file that contains the definition of our button component and a copy of our JavaScript framework. The user sees content rendered to the page, but clicking the button doesn\u0026rsquo;t do anything yet. The client uses the definition of our button component with the JavaScript framework to determine which elements in the document need to have event listeners attached. The button is now considered \u0026ldquo;live\u0026rdquo; and interactive. Clicking the button will now display a pop-up window.  Steps 3 and 5 are italicized because these are the steps which our users care about the most. This is when the user sees things happening on the page.\nThe process that we just outlined above is slightly complicated, so the JavaScript community has given it a memorable name: Hydration\nHow React performs hydration: https://reactjs.org/docs/react-dom.html#hydrate\nShould universal rendering be implemented in every web application? No.\nIt\u0026rsquo;s fancy. It\u0026rsquo;s shiny. It\u0026rsquo;s fun to implement if you love engineering problems.\nHowever, we should exercise discretion when deciding upon a rendering strategy for our web applications. As the stated by the Law of the instrument, \u0026ldquo;It\u0026rsquo;s tempting, if the only tool you have is a hammer, to treat everything as if it were a nail\u0026rdquo;.\nUniversal rendering is a powerful tool to have in your toolbox. To make sure that we use it effectively, we\u0026rsquo;re going to establish a set of criteria that help us to determine if universal rendering is the right tool for the job.\nYou should implement universal rendering when the following conditions are true:\n You have a customer-facing web application that needs to be optimized for rendering performance. You need to optimize a dynamic web application for Search Engine Optimization (SEO). In other words, you have a web application that is too dynamic to be written as static markup, but still needs to be indexed by a web crawler.  "
},
{
	"uri": "/golang/api/versioning/",
	"title": "Versioning",
	"tags": [],
	"description": "",
	"content": "Objectives  Understand why API\u0026rsquo;s should be versioned Understand available versioning schemes/options Properly version API after changes have been made  Versioning APIs When creating and maintaining an API, one of the biggest blockers is taking care of updates to the API. Users of the API may not want to update applications that use the API every time the API is updated. This is why versioning of an API is so vital.\nVersioning Options While there a number of versioning handling options out there, THD has a standard of including the version number in the URI of the requested resource at the service root in the URL path. For example:\nhttp://www.example.homedepot.com/api/v1/tools\n This version number should follow a \u0026ldquo;Major\u0026rdquo; only version scheme.\n Pros of this choice:\n Simple implementation Uses URI routing to point to a specific version of the API allowing resources to be cached  Cons of this choice:\n This solution has a pretty big footprint in the code base as introducing breaking changes implies branching the entire API  Examples THD considers bad\n http://www.example.homedepot.com/api/tools/v1 http://www.example.homedepot.com/api/v1.999.04/tools  THD Versioning Guidelines THD has a strict rule that any modification to an existing API MUST avoid breaking changes and MUST maintain backward compatibility.\nAny change to the following MUST follow the Rules of Extending:\n Resource identifier (resource name/ URI) including any query parameters and their semantics. Resource metadata (e.g. available HTTP Headers) Action the resource affords (e.g. Methods) Relation with other resources (e.g. Links) Representation format (e.g. HTTP request and response bodies)  The Rules of Extending are:\n You MUST NOT take anything away You MUST NOT change processing rules You MUST NOT make optional things required Anything you add MUST be optional  THD API guidelines can be found here\nVersioning in Go Subroutines can be utilized to help with versioning when the version numbers are in the URI.\nExample main.go file:\nimport ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;github.com/gorilla/mux\u0026#34; ) func main() { router := mux.NewRouter() var api = router.PathPrefix(\u0026#34;/api\u0026#34;).Subrouter() api.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, \u0026#34;Welcome to the tool rental landing page!\\n\u0026#34;) }) log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, router)) } The above code creates a new router with a subrouter for handling /api which represents the base of our versioned routes. The routes will show like /api/v1/endpoint,/api/v2/endpoint and so on.\nThe /api/ route now has a landing page that greets the user.\nAdding Versions Now we are ready to add our first version of API. Add the following to the bottom of the main, but above the log.Fatal(http.ListenAndServe(\u0026quot;:8080\u0026quot;, router)) line:\nv1 := Version1{} //1 var routerV1 = api.PathPrefix(\u0026#34;/v1\u0026#34;).Subrouter() routerV1.HandleFunc(\u0026#34;/\u0026#34;, v1.Index).Methods(\u0026#34;GET\u0026#34;) //2 routerV1.HandleFunc(\u0026#34;/tools\u0026#34;, v1.ToolsIndex).Methods(\u0026#34;GET\u0026#34;) //2  Creates a version1 object that holds the handlers for version 1. (Will be created below) Notice that HandleFunc is called on routerV1, not api. This signifies the routes come after the prefix /v1.  Now we have added the paths:\n /api/v1/ /api/v1/tools  For the sake of simplicity, both of these paths will simply return a greeting to the user as well.\nTo create the handlers for the two v1 routes, add the following contents outside of the main function in the main.go:\ntype Version1 struct{} func (v1 Version1) Index(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, \u0026#34;Welcome to the home page!\\n\u0026#34;) } func (v1 Version1) ToolsIndex(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, \u0026#34;Welcome to the tool rental landing page!\\n\u0026#34;) } Adding a 2nd Version There are a couple of strategies for creating a second version of an API. Say that you want to keep the existing routes, but now want to add a users route. Handlers can be used with composition.\nAdd the following contents outside of the main function in the main.go to give Version2 full access to Version1 \u0026rsquo;s handlers:\ntype Version2 struct{ Version1 } func (v2 Version2) UsersIndex(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, \u0026#34;Welcome to the users landing page!\\n\u0026#34;) } Now the Version2 struct has access to the UsersIndex, ToolsIndex, and Index handlers.\nTo create the routes, add the following to the bottom of the main, but above the log.Fatal(http.ListenAndServe(\u0026quot;:8080\u0026quot;, router)) line:\nv2 := Version2{} var routerV2 = api.PathPrefix(\u0026#34;/v2\u0026#34;).Subrouter() routerV2.HandleFunc(\u0026#34;/\u0026#34;, v2.Index).Methods(\u0026#34;GET\u0026#34;) // 1 routerV2.HandleFunc(\u0026#34;/tools\u0026#34;, v2.ToolsIndex).Methods(\u0026#34;GET\u0026#34;) routerV2.HandleFunc(\u0026#34;/users\u0026#34;, v2.UsersIndex).Methods(\u0026#34;GET\u0026#34;) // 2  Uses the Version2 \u0026rsquo;s copy of the Index handler. Using the Version2 new UsersIndex handler.  Now we have the paths:\n /api/ /api/v1/ /api/v1/tools /api/v2/ /api/v2/tools /api/v2/users  While we were able to reuse handlers, we still had to rewrite the routes from Version1 to Version2 in order to use these routers. It is possible to \u0026ldquo;package up\u0026rdquo; a router within a function.\nA function can take in a router, attach routes to the router (that has been passed in as argument), then return the newly modified router.\nfunc Version1Routes(router *mux.Router) *mux.Router { v1 := Version1{} router.HandleFunc(\u0026#34;/\u0026#34;, v1.Index).Methods(\u0026#34;GET\u0026#34;) router.HandleFunc(\u0026#34;/tools\u0026#34;, v1.ToolsIndex).Methods(\u0026#34;GET\u0026#34;) return router } So now, adding routes in the main function can be simplified to:\nvar routerV1 = api.PathPrefix(\u0026#34;/v1\u0026#34;).Subrouter() routerV1 = Version1Routes(routerV1) It is also possible for version 2 to use this new function, shorting the addition of the routes to:\nv2 := Version2{} var routerV2 = api.PathPrefix(\u0026#34;/v2\u0026#34;).Subrouter() routerV2 = Version1Routes(routerV2) routerV2.HandleFunc(\u0026#34;/users\u0026#34;, v2.UsersIndex).Methods(\u0026#34;GET\u0026#34;) Lab: \u0026ldquo;Packaging up\u0026rdquo; v2 Using the above techniques, update versioning/main.go in https://github.homedepot.com/om-labs/go-apis to use a function to attach the routes to the routerV2 router. Hint: you do NOT need to attach the / or /index routes again.\nExtra challenge\nSplit up the handlers into their own files to create the following file structure:\n. ├── README.md ├── main.go ├── v1 │ └── handlers.go └── v2 └── handlers.go 2 directories, 4 files "
},
{
	"uri": "/react/pillars/perf-opt-strategies/web-worker/",
	"title": "Web Workers",
	"tags": [],
	"description": "",
	"content": "Use Web Workers to offload long computations to a separate worker thread, freeing up the main UI thread to interact with the user and update the DOM.\nIntroduction Even after memoizing slow components and/or long computations, there is still a problem to solve.\n Sometimes a long computation needs to be recalculated Doing so in the main UI thread will cause the UI to be unresponsive.  So how do we run long computations without blocking the main UI thread?\nFortunately, The Open HTML standard provides an API called Web Workers for handling these problems.\nWhat Are Web Workers?  Web Workers are a way to run scripts in background threads. The worker thread can perform tasks without interfering with the user interface. Web Workers can perform I/O using XMLHttpRequest or fetch. Once created, a worker can send messages to the JavaScript code that created it by posting messages to an event handler specified by that code (and vice versa). This means that you can have bi-directional communication between the main UI thread and the Web Worker thread. Web Workers can be dedicated (exclusive to the main thread that created the worker) or shared. A shared worker is accessible by multiple scripts — even if they are being accessed by different windows, iframes or even other workers.  Using a Web Worker The magic of workers happens via the postMessage(data) method and the onmessage(event) event handler.\n postMessage(data) - sends messages between the main UI thread and the worker thread onmessage(event) - listen for a message  Here is a simple example:\n// app.js  // create a Web Worker const worker = new Worker(\u0026#39;worker.js\u0026#39;); // handle errors worker.onerror = err =\u0026gt; { alert(err.message); }; // handle messages from web worker worker.onmessage = event =\u0026gt; { // do something with event.data here  worker.terminate(); }; // post a message to the web worker to give it something to do worker.postMessage(\u0026#39;Mike\u0026#39;); // worker.js  // listen for messages, do some work, and post a message to the main script. onmessage = event =\u0026gt; { // do some work here.  setTimeout(() =\u0026gt; { postMessage(\u0026#39;Hello \u0026#39; + event.data); }, 1000); }; Here is a live demo of the above example.\nAnother Example Here is another example of a web worker.\n  Prime Number Generator Here is an example of generating prime numbers in a web worker and having React handle the DOM updates.\n  Some Caveats  Workers are relatively heavy-weight, and thus are not intended to be used in large numbers. For example, it would be inappropriate to launch one worker for each pixel of a four megapixel image. Generally, workers are expected to be long-lived, have a high start-up performance cost, and a high per-instance memory cost.  Summary  Web Workers  run long calculations in a separate thread prevent locking up the main thread, keeping the UI responsive to user interactions keep running even when the main thread is paused (such as when the tab loses focus) are overkill for fast calculations incurs some overhead in starting the web worker as well as additional coding and maintenance overhead   Alternatives  use window.requestAnimationFrame to trampoline a long running calculation    Resources  Using Web Workers | MDN Managing Long-Running Tasks In A React App With Web Workers | Chidi Orji  Lab - Approximately 15 minutes  Use the React Performance Optimization Playground App for this lab. You will find a \u0026ldquo;Web Workers\u0026rdquo; example and within that there are tabs for \u0026ldquo;Before\u0026rdquo; and \u0026ldquo;After\u0026rdquo;. The code for these tabs is found in the project source code under the folder src/pages/WebWorkerEx. Currently the code in the After folder is partially complete. The PiCalculator.jsx file is complete but the FibCalculator.jsx needs to be converted to use a Web Worker. The fib-worker.js file is provided in the public folder. You simply need to call it from FibCalculator.jsx similar to how PiCalculator.jsx is calling pi-worker.js. Once you complete the changes, test that when you interact with the FibCalculator component, the main UI thread is not locked up.  "
},
{
	"uri": "/application-security/api-security/03_where_to_from_here/",
	"title": "Where To From Here?",
	"tags": [],
	"description": "",
	"content": "Great things ahead Easy to do the Right Thing The most important thing that we are trying to accomplish is to make it easy todo the right thing. It is finally time we got our API Security house in order.\nEverything you need is here:  Onboarding Middleware Videos Slack Channels  https://app-secure-community-docs.apps-np.homedepot.com/\nMiddleware - Please use it. Do NOT write your own middleware, please, please please, throw in with the rest of us and lets figure this out together.\nSelf Service is Coming We are actively working through onboarding for both Webapps and Service to Service apps in #thd-identity. It is coming soon, and the goal is to be self-service.\nWhat is this replacing?  THDSSO Siteminder myTHDPassport PCF SSO all the home grown JWT Token providers Dapper  Thinking about Testing Now that we have a solid, valid and globally available solution for generating tokens, you should be thinking how your unit tests, integration tests, and smoke tests treat security, especially within your CI-CD pipelines. We have published a fake authorization service I call the Fa-Cade service, and we are hoping it can help everybody to validate that their endpoints are as secure as they need to be by creating cryptographically sound tokens, but with whatever value you need in them to properly test authorization in your application:\nhttps://github.homedepot.com/app-secure-community/facade-authorization-server\nPersonal Note from Cade I have been working on this for nearly 2 and half years, advocating, and am so excited. I\u0026rsquo;d like to thank the Security IAM team, The API Enablement Team, Orange Academy, and all the Dev Teams that provided me feedback to help guide this solution.\n"
},
{
	"uri": "/golang/testing/go-bdd/",
	"title": "BDD with Ginkgo and Gomega",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Intro to BDD Generating tests Test Suite File Organizational functions It aliases Teardown and Setup for tests and suites  Behavioral Driven Development Behavioral Driven Development (BDD) is a software development approach that has evolved from TDD (Test Driven Development). In both development approaches, tests are written ahead of the code, but in BDD, tests are more focused on the behavior of the code rather than a specific implementation.\nTests are often written with the following thought process:\nGherkin style\nGiven a specific context When an action is taken Then this is the expected result Given 2and 2as input to Add When the function is invoked Then it should return 4Ginkgo Ginkgo is a BDD-style Go testing framework built to help you write expressive tests. In the following examples, we will use Ginkgo with the Gomega assertion library but can be used with other assertion libraries.\nInstalling Ginkgo and Gomega Just go get it:\ngo get github.com/onsi/ginkgo/ginkgo go get github.com/onsi/gomega/... This will install both ginkgo and gomega and place the executables in $GOPATH/bin and your go.mod (if using Gomods).\nTo see if you successfully installed ginkgo, run ginkgo version. You should get something like:\nGinkgo Version 1.8.0\nGinkgo Test Suite Ginkgo works directly with Go\u0026rsquo;s existing testing library. This means that you can run a Ginkgo suite using go test.\nTo create Ginkgo tests for a package you must first generate the code for a Ginkgo test suite.\nFor our examples, we will be using a lumber package, with the following lumber.go file:\npackage lumber import \u0026#34;fmt\u0026#34; type Lumber struct { WoodType string Price float64 Width int Height int Length int } //LumberArea calculates the area of the lumber in inches func (l Lumber) LumberArea() int { return l.Width * l.Height * l.Length; } //PricePerSqInch finds the price per square inch of lumber func (l Lumber) PricePerSqInch() float64 { return l.Price / float64(l.LumberArea()); } //Cut removes x number of inches. Returns an error if x \u0026gt; lumber length. func (l *Lumber) CutUp(x int) error { if(x \u0026lt; l.Length){ l.Length -= x return nil } return fmt.Errorf(\u0026#34;%v is too long\u0026#34;, x) } Example: to generate tests for the lumber package:\ncd path/to/lumber ginkgo bootstrap This will create a file named lumber_suite_test.go with the following contents:\npackage lumber_test\t//1  import ( \u0026#34;testing\u0026#34; . \u0026#34;github.com/onsi/ginkgo\u0026#34; //2 \t. \u0026#34;github.com/onsi/gomega\u0026#34; //2 ) func TestLumber(t *testing.T) {\t//3 \tRegisterFailHandler(Fail)\t//4 \tRunSpecs(t, \u0026#34;Lumber Suite\u0026#34;)\t//5 }  Ginkgo sets up the test with the lumber_test package, instead of lumber allows us to respect the encapsulation of the lumber package. You can, of course, opt out of this – just change package lumber_test to package lumber. By default, both Ginkgo and Gomega packages are dot imported. Dot imports bring the package into the same namespace as your current package, so you no longer have to use the imported package\u0026rsquo;s name to reference its variables and functions, giving us direct access to them. TestLumber is a testing test. The Go test runner will run this function when you run go test or ginkgo. RegisterFailHandler is a Gomega function that is taking in a Ginkgo function called Fail(description string). Fail is triggered when a test fails. RunSpecs(t *testing.T, suiteDescription string) tells Ginkgo to start the test suite. Ginkgo will automatically fail the testing.T if any of your specs fail.  At this point you can run your suite with either ginkgo or go test:\nRunning Suite: Lumber Suite ========================== Random Seed: 1557168060 Will run 0 of 0 specs Ran 0 of 0 Specs in 0.000 seconds SUCCESS! -- 0 Passed | 0 Failed | 0 Pending | 0 Skipped PASS Ginkgo ran 1 suite in 17.409020909s Test Suite Passed Watching For Changes Placing ginkgo watch in the terminal starts constant monitoring of the package in the current directory. Any change to the package triggers the tests.\nFor each monitored packaged, Ginkgo will also monitor that package\u0026rsquo;s dependencies and trigger the monitored package\u0026rsquo;s test suite when a change in a dependency is detected. By default, ginkgo watch monitors a package\u0026rsquo;s immediate dependencies.\nAdding Specs It is possible to add tests directly in the file generated above, but it is preferred that your tests are in separate files.\nTo create a test file for the lumber package, run the command ginkgo generate lumber in the lumber directory in the terminal.\nThis will create a file called lumber_test.go that has the following contents:\npackage lumber_test import ( . \u0026#34;github.com/onsi/ginkgo\u0026#34; . \u0026#34;github.com/onsi/gomega\u0026#34; . \u0026#34;github.homedepot.com/lumber\u0026#34; ) var _ = Describe(\u0026#34;Lumber\u0026#34;, func() { }) We add a top-level describe container (defined below) using Ginkgo\u0026rsquo;s Describe(text string, body func()) bool function. var _ = ... allows us to evaluate the Describe at the top level without having to wrap it in a func init() {}\nOrganizational functions Below we have updated lumber_test.go to have three tests for the LumberArea, PricePerSqInch, and CutUp methods.\nvar _ = Describe(\u0026#34;Lumber\u0026#34;, func() {\t//1  Context(\u0026#34;With (W, H, L) = (5, 2, 60)\u0026#34;, func() {\t//2 \tIt(\u0026#34;should be have area of 600\u0026#34;, func() {\t//3 \tmyLumber := Lumber{ WoodType: \u0026#34;pine\u0026#34;, Price: 12.75, Width: 5, Height: 2, Length: 60, } Expect(myLumber.LumberArea()).To(Equal(600))\t//4 \t}) It(\u0026#34;should be $0.02 per square inch\u0026#34;, func() {\t//2 \tmyLumber := Lumber{ WoodType: \u0026#34;pine\u0026#34;, Price: 12.75, Width: 5, Height: 2, Length: 60, } actual := myLumber.PricePerSqInch()\t//3 \tExpect(actual).To(Equal(0.02))\t//4 \t}) It(\u0026#34;should shorten the lumber 2 inches\u0026#34;, func() {\t//2 \tmyLumber := Lumber{ WoodType: \u0026#34;pine\u0026#34;, Price: 12.75, Width: 5, Height: 2, Length: 60, } myLumber.CutUp(2)\t//3 \tExpect(myLumber.Length).To(Equal(58))\t//4 \t}) }) })  Describe not only verifies the tested code, but also documents its intended behavior. Each Describe block specifies a larger component or function and contains a set of specifications. Context defines a set of tests that test related functionality under one state. Usually you will have one context per file, but you may have multiple contexts in a single file if you so choose. There is no functional difference between Context and Describe. However, there is a contextual difference:   Describe wraps a set of tests against one functionality. Context wraps a set of tests against one functionality under the same state.  It defines the specifications. Each It block functions as a test and is evaluated in its own environment. Expect is Gomega assertion function takes in an actual assertion and is followed by a chain of qualifications. To takes in an Gomega function. Equal is a function that uses deep equality instead of strict equality to compare actual with expected.  Here are a list of other assertion functions\nOutput if we run ginkgo:\nAh! We got an error! The green dot at the top and bottom of the output represents our first and third test passing.\nWhen the second test was run, we got an unexpected error. You are able to see in clear wording: we expected a float64 that has a value of 0.02125, but we received a float64 that has a value of 0.02. (Rounding differences).\nWe are also get a summary of the number of passed, failed, pending, and skipped tests.\nIf we were to alter the code of lumber_test.go to check only up to the hundredth place and run ginkgo, we would get:\nRunning Suite: Lumber Suite =========================== Random Seed: 1557344998 Will run 3 of 3 specs ••• Ran 3 of 3 Specs in 0.000 seconds SUCCESS! -- 3 Passed | 0 Failed | 0 Pending | 0 Skipped PASS Ginkgo ran 1 suite in 1.300488757s Test Suite Passed It Aliases In order to ensure that your specs read naturally, Ginkgo supplies aliases for It: FIt, PIt, XIt, Specify, FSpecify, PSpecify, XSpecify.\nThere are corresponding Specify blocks available as aliases to use in situations where the corresponding It alternatives do not seem to read as natural language. All the same protocols apply for Specify blocks which apply to It blocks.\nEquivalencies\n It corresponds with Specify FIt corresponds with FSpecify PIt corresponds with PSpecify XIt corresponds with XSpecify   PIt\nPIt (or XIt) marks individual Its as temporarily pending, and not execute any blocks that are inside that block.\nThe output will not reflect if the specified test is failing or passing. A good case to use this is when refactoring code that breaks tests, to avoid deleting or commenting-out that hard-won test logic while you get back to green, test by test.\nChanging the last test in lumber_test to use PIt (or XIt), gives:\nRunning Suite: Lumber Suite =========================== Random Seed: 1557411631 Will run 2 of 3 specs .. ------------------------------ P [PENDING] Lumber /Users/ldap/Documents/go-testing-practice/src/github.homedepot.com/lumber/lumber_test.go:9 With (W, H, L) = (5, 2, 60) /Users/ldap/Documents/go-testing-practice/src/github.homedepot.com/lumber/lumber_test.go:24 should shorten the lumber 2 inches /Users/ldap/Documents/go-testing-practice/src/github.homedepot.com/lumber/lumber_test.go:35 ------------------------------ Ran 2 of 3 Specs in 0.000 seconds SUCCESS! -- 2 Passed | 0 Failed | 1 Pending | 0 Skipped  FIt\nFIt marks individual Its as focused, and not execute any blocks that are not also marked as focused.\nThe output will not reflect if the non-focused tests are failing or passing, just skipped.\nChanging the last test in lumber_test to use FIt, gives:\nRunning Suite: Lumber Suite =========================== Random Seed: 1557411801 Will run 1 of 3 specs SS• Ran 1 of 3 Specs in 0.000 seconds SUCCESS! -- 1 Passed | 0 Failed | 0 Pending | 2 Skipped PASS | FOCUSED Notice that the first two tests are marked with an S, and the last test is run.\nBy Function Generally you should try to keep your Its short and to the point. This is not always possible, however, especially in the context of integration tests that capture a particular workflow. You can capture these workflows with By.\nBy must be called within a runnable block (It, BeforeEach, etc\u0026hellip;) By will simply log the passed in text to the GinkgoWriter. If By is handed a function it will immediately run the function.\nvar _ = Describe(\u0026#34;Lumber\u0026#34;, func() { Context(\u0026#34;With (W, H, L) = (5, 2, 60)\u0026#34;, func() { It(\u0026#34;should be have area of 600\u0026#34;, func() { myLumber := Lumber{ WoodType: \u0026#34;pine\u0026#34;, Price: 12.75, Width: 5, Height: 2, Length: 60, } Expect(myLumber.LumberArea()).To(Equal(600)) }) It(\u0026#34;should be $0.02 per square inch\u0026#34;, func() { myLumber := Lumber{ WoodType: \u0026#34;pine\u0026#34;, Price: 12.75, Width: 5, Height: 2, Length: 60, } actual := myLumber.PricePerSqInch() actual = math.Round(actual*100)/100 Expect(actual).To(Equal(0.02)) }) It(\u0026#34;should shorten the lumber 2 inches\u0026#34;, func() { myLumber := Lumber{ WoodType: \u0026#34;pine\u0026#34;, Price: 12.75, Width: 5, Height: 2, Length: 60, } By(\u0026#34;Checking new lumber length\u0026#34;)\t// Adding additional statement for failing tests \terr := myLumber.CutUp(2) Expect(myLumber.Length).To(Equal(58)) By(\u0026#34;Checking that there was not an error thrown\u0026#34;)\t// Adding additional statement for failing tests  Expect(err).To(BeNil()) }) }) }) If you run ginkgo -v with the above code, you would get:\n------------------------------ Lumber With (W, H, L) = (5, 2, 60) should shorten the lumber 2 inches /Users/ldap/Documents/go-testing-practice/src/github.homedepot.com/lumber/lumber_test.go:35 STEP: Initializing myLumber STEP: Checking new lumber length STEP: Checking that there was not an error thrown STEP: Completed tests • Setup and Teardown It is common that you want to create a similar set up for multiple tests and/or test suites.\nTests BeforeEach() removes duplication and share common setups across tests. The BeforeEach blocks are run before the It blocks.\nBeforeEach ensures that each spec has a pristine copy of the state.\nWe could rewrite lumber_test to use BeforeEach:\nvar _ = Describe(\u0026#34;Lumber\u0026#34;, func() {\t//1 \tvar myLumber Lumber BeforeEach(func() { By(\u0026#34;BeforeEach: Initializing values\u0026#34;) myLumber = Lumber{ WoodType: \u0026#34;pine\u0026#34;, Price: 12.75, Width: 5, Height: 2, Length: 60, } }) Context(\u0026#34;With (W, H, L) = (5, 2, 60)\u0026#34;, func() { ... // rest of lumber_test removed due for example simplicity The output of the last test is now:\n------------------------------ Lumber With (W, H, L) = (5, 2, 60) should shorten the lumber 2 inches /Users/ldap/Documents/go-testing-practice/src/github.homedepot.com/lumber/lumber_test.go:37 STEP: BeforeEach: Initializing values STEP: Checking new lumber length STEP: Checking that there was not an error thrown  AfterEach() is also used to remove duplication and share a common teardown across tests. The AfterEach blocks are run after the It blocks.\nAfterEach() is often used to close a connection from a database or a file after testing. This is not executed if a test is interrupted.\nvar _ = Describe(\u0026#34;Lumber\u0026#34;, func() { var myLumber Lumber BeforeEach(func() { By(\u0026#34;BeforeEach: Initializing values\u0026#34;) myLumber = Lumber{ WoodType: \u0026#34;pine\u0026#34;, Price: 12.75, Width: 5, Height: 2, Length: 60, } }) AfterEach(func(){ By(\u0026#34;AfterEach: Completed individual test\u0026#34;) }) Context(\u0026#34;With (W, H, L) = (5, 2, 60)\u0026#34;, func() { ... // rest of lumber_test removed due for example simplicity The output of the last test is now:\n------------------------------ Lumber With (W, H, L) = (5, 2, 60) should shorten the lumber 2 inches /Users/ldap/Documents/go-testing-practice/src/github.homedepot.com/lumber/lumber_test.go:37 STEP: BeforeEach: Initializing values STEP: Checking new lumber length STEP: Checking that there was not an error thrown STEP: AfterEach: Completed individual test  JustBeforeEach allows you to decouple creation from configuration. These blocks are guaranteed to be run after all the BeforeEach blocks have run and just before the It block has run.\nvar _ = Describe(\u0026#34;Lumber\u0026#34;, func() { var myLumber Lumber BeforeEach(func() { By(\u0026#34;BeforeEach: Initializing values\u0026#34;) myLumber = Lumber{ WoodType: \u0026#34;pine\u0026#34;, Price: 12.75, Width: 5, Height: 2, Length: 60, } }) JustBeforeEach(func() { By(\u0026#34;JustBeforeEach\u0026#34;) }) AfterEach(func(){ By(\u0026#34;AfterEach: Completed individual test\u0026#34;) }) Context(\u0026#34;With (W, H, L) = (5, 2, 60)\u0026#34;, func() { ... // rest of lumber_test removed due for example simplicity The output of the last test is now:\n------------------------------ Lumber With (W, H, L) = (5, 2, 60) should shorten the lumber 2 inches /Users/ldap/Documents/go-testing-practice/src/github.homedepot.com/lumber/lumber_test.go:40 STEP: BeforeEach: Initializing values STEP: JustBeforeEach STEP: Checking new lumber length STEP: Checking that there was not an error thrown STEP: AfterEach: Completed individual test  JustAfterEach allows for some code which is executed just after each It block, but before Teardown (which might destroy useful state) - for example to to perform diagnostic operations if the test failed.\nvar _ = Describe(\u0026#34;Lumber\u0026#34;, func() { var myLumber Lumber BeforeEach(func() { By(\u0026#34;BeforeEach: Initializing values\u0026#34;) myLumber = Lumber{ WoodType: \u0026#34;pine\u0026#34;, Price: 12.75, Width: 5, Height: 2, Length: 60, } }) JustBeforeEach(func() { By(\u0026#34;JustBeforeEach\u0026#34;) }) AfterEach(func(){ By(\u0026#34;AfterEach: Completed individual test\u0026#34;) }) JustAfterEach(func() { By(\u0026#34;JustAfterEach\u0026#34;) }) Context(\u0026#34;With (W, H, L) = (5, 2, 60)\u0026#34;, func() { ... // rest of lumber_test removed due for example simplicity The output of the last test is now:\n------------------------------ Lumber With (W, H, L) = (5, 2, 60) should shorten the lumber 2 inches /Users/ldap/Documents/go-testing-practice/src/github.homedepot.com/lumber/lumber_test.go:43 STEP: BeforeEach: Initializing values STEP: JustBeforeEach STEP: Checking new lumber length STEP: Checking that there was not an error thrown STEP: JustAfterEach STEP: AfterEach: Completed individual test Suites Sometimes you want to run some set up code once before the entire test suite and some clean up code once after the entire test suite. For example, perhaps you need to spin up and tear down an external database.\nGinkgo provides BeforeSuite and AfterSuite to accomplish this. You typically define these at the top-level in the bootstrap file\nWe can update lumber_suite_test.go to use both BeforeSuite and AfterSuite\nvar dbRunner *db.Runner\t// Mock database runner var dbClient *db.Client\t// Mock database client  func TestLumber(t *testing.T) { RegisterFailHandler(Fail) RunSpecs(t, \u0026#34;Lumber Suite\u0026#34;) } var _ = BeforeSuite(func() { //1 \tBy(\u0026#34;Connecting to database\u0026#34;) dbRunner = db.NewRunner() err := dbRunner.Start() Expect(err).NotTo(HaveOccurred()) dbClient = db.NewClient() err = dbClient.Connect(dbRunner.Address()) Expect(err).NotTo(HaveOccurred()) }) var _ = AfterSuite(func() { //2 \tBy(\u0026#34;Disconnecting from database\u0026#34;) dbClient.Cleanup() dbRunner.Stop() })  Will be run before all tests in the Lumber Suite. Connecting to our mock database and making sure there was not an error connecting to our mock database. Will be run after all tests in the Lumber Suite. Clean up and disconnect from our mock database.  Lab Setup\n If you have not already, Fork https://github.homedepot.com/om-labs/go-testing to your homedepot profile Clone down your newly forked repo cd into the go-testing/bdd directory Follow the instructions found in the README  Summary In BDD, tests are more focused on the behavior of the code rather than a specific implementation. Ginkgo is a BDD-style Go testing framework built to help you write expressive tests. Ginkgo works directly with Go\u0026rsquo;s existing testing library.\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/box-model-labs/",
	"title": "Box Model Labs",
	"tags": [],
	"description": "",
	"content": "View the following on Percipio Percipio CSS Box Model\nPercipio CSS Selectors\nPeripio CSS Positioning\n Write answers to the following questions and submit them to an instructor, via slack:  What is the role of margin, padding, and border in the box model? Compare the inline-block, block, and inline display values. Compare the position values: static, relative, absolute, and fixed. Name 3 CSS units of measure.    Additional Resources  w3schools: Box Model     "
},
{
	"uri": "/golang/api/api-testing/",
	"title": "API Testing",
	"tags": [],
	"description": "",
	"content": "Where to Start Inside Out vs Outside In Where to start testing can sometimes be a bit hard to determine. There are two approaches that work, whether you are using TDD or not. These are strategies are known as: Inside Out and Outside In.\nInside Out: This method focuses on testing and building the inner components first. Business logic, data retrieval and other components that are well defined can be created. From there, you work your way out to the interface. In our case, the endpoint/route that clients will call.\nOutside In: Outside in starts by designing and testing the API endpoints, and working your way in as you go.\nWe can use these approaches as options in our toolbox of testing techniques to help narrow down where we should start. Each has an advantage in certain situations. First and foremost, what method works for you and/or your team is how you should start. But we can take a look at some basic guidelines of when each applies.\nWhen to Use Inside Out You might chose Inside Out if you have:\n A well designed API already in place Complex business logic inside of your application Data that needs to be retrieved from many different sources before it is ready to be used by an external application You are unsure of how your data will be accessed, but know you will need certain components.  Pros\n Can allow you to tackle more complex parts of your application first. Can providing reusable components without being tied to a specific user interface Code to architecture requirements  Cons\n Potentially develop components that won\u0026rsquo;t be needed Possible to lead to tightly coupled architecture.  When to Use Outside In You might chose Outside In if:\n You are working with a brand new API You are unsure of how the component interaction will be Delivering an MVP that may not have all components ready You are unsure of how your data will be accessed, but know you will need certain components You have a strong understanding of your user or application interaction with your application  Pros\n Can deliver something truly usable, even if not fully ready almost from the start Ensures you are only developing components that you will need  Cons\n Narrow focus on the user interface Good design patterns and usage for internal components are not always apparent. May lock users into specific usage of your application before understanding the big picture.  Use Both Don\u0026rsquo;t feel stuck to a single approach. As you learn your application better, you will be able to more easily switch between the two when it makes sense. Again, they are just additional tools to help you develop great software. In the end, you still need to deliver value.\nIn this course, we will start with testing our handlers and work our way out. From there, you can choose either approach.\nThe httptest Package The httptest package is a simple, but powerful, built-in package that provides a few types and functions to assist with testing almost all types of http functionality.\n NewRequest function will generate an http request to be used in our handlers ResponseRecorder provides us with a data structure that can be used to test the behavior of a handler. In addition to providing methods to assist in testing, the ResponseRecorder implements the ResponseWriter interface so it can be used in your handlers as well. Server provides a data structure and methods for testing your endpoints end to end and/or integration testing. It can be used to easily spin up a server and listen to a specified port on the loopback interface.  Testing the http.Handler We\u0026rsquo;ve been asked to provide a handler that will be used for a complex mathematical equation. The ask is that we take any number equal to 100 or below and determine if it is odd or even. Some additional requirements were provided:\n If the number is 101 or above, then we want to return an HTTP status code of 406 If the number is 0 or below, then we want the server to blow up and return a 500 and indicate that math is hard. All responses should return JSON with the appropriate headers set.  Great, now we have some criteria defined for lets review what we have to work with.\nFirst, review the signature of the http.Handler function.\nfunc(w http.ResponseWriter, r *http.Request) Based on this we know we need to mock, or somehow create a ResponseWriter and a pointer to an http.Request. For the ResponseWriter you could implement the interface with a MockResponseWriter yourself. That may in fact be a solution for some one off situation you find yourself in. However, as we were introduced to the httptest package we are already provided with the tools we need to meet the dependencies.\nLet\u0026rsquo;s get our test set up: package main import ( \u0026#34;net/http\u0026#34; \u0026#34;net/http/httptest\u0026#34; ) func TestEvenOrOddHandler(t *testing.T) { /* Creates a new request object of type GET. Note your handler probably doesn\u0026#39;t care about this method and you could put anything you wanted to as long as it is a string in this position for this test. */ req := httptest.NewRequest(\u0026#34;GET\u0026#34;, \u0026#34;/evenorodd?number=2\u0026#34;, nil) // Gets me a ResponseWriter  w := httptest.NewRecorder() }  Now if we look at our handler we can see we just need to invoke it with the two values:\nfunc EvenOrOddHandler(w http.ResponseWriter, req *http.Request) { // At some point in the TDD Process we\u0026#39;d add better code to ensure values were OK  if num, ok := req.URL.Query()[\u0026#34;number\u0026#34;]; ok { n, _ := strconv.Atoi(num[0]) r := \u0026#34;odd\u0026#34; if n % 2 == 0 { r = \u0026#34;even\u0026#34; } fmt.Fprintf(w, `{\u0026#34;result:\u0026#34; \u0026#34;%s\u0026#34;}`, r) } fmt.Println() }  The test:\nfunc TestEvenOrOddHandler(t *testing.T) { req := httptest.NewRequest(\u0026#34;GET\u0026#34;, \u0026#34;/evenorodd?number=2\u0026#34;, nil) w := httptest.NewRecorder() EvenOrOddHandler(w, req) assert.Equal(t, w.Code, 200) assert.Equal(t, w.Body.String(), `{\u0026#34;result:\u0026#34; \u0026#34;even\u0026#34;}`, \u0026#34;I Should be even!\u0026#34;) }   As you can see, we can use Code and Body properties of the ResponseRecorder struct that we got from NewRecorder to validate we got the expected results.\nNow that we have some basic test criteria working, we can include some other input tests. At this point we\u0026rsquo;ll go ahead and introduce a table driven test and refactor our function to make everything pass. Here is the entire code, including the handler that we tested:\n package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/httptest\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; ) func TestEvenOrOddHandler(t *testing.T) { tests := []struct { name string message string expectedCode int queryParam string expected string }{ { name: \u0026#34;Test an even number below 100\u0026#34;, message: \u0026#34;It should return 200 and be even\u0026#34;, expectedCode: 200, queryParam: \u0026#34;2\u0026#34;, expected: `{\u0026#34;result:\u0026#34; \u0026#34;even\u0026#34;}`, }, { name: \u0026#34;Test an equal to 100\u0026#34;, message: \u0026#34;It should return 200 and be even\u0026#34;, expectedCode: 200, queryParam: \u0026#34;100\u0026#34;, expected: `{\u0026#34;result:\u0026#34; \u0026#34;even\u0026#34;}`, }, { name: \u0026#34;Test an odd number below 100\u0026#34;, message: \u0026#34;It should return 200 and be odd\u0026#34;, expectedCode: 200, queryParam: \u0026#34;99\u0026#34;, expected: `{\u0026#34;result:\u0026#34; \u0026#34;odd\u0026#34;}`, }, { name: \u0026#34;Test a number over 100\u0026#34;, message: \u0026#34;It should return 406 and be error\u0026#34;, expectedCode: 406, queryParam: \u0026#34;121\u0026#34;, expected: `{\u0026#34;result:\u0026#34; \u0026#34;error\u0026#34;}`, }, { name: \u0026#34;Test a number bellow 0\u0026#34;, message: \u0026#34;It should return 500\u0026#34;, expectedCode: 500, queryParam: \u0026#34;-1\u0026#34;, expected: `{\u0026#34;result:\u0026#34; \u0026#34;math is hard\u0026#34;}`, }, } for _, test := range tests { t.Run(test.name, func(t *testing.T) { req := httptest.NewRequest(\u0026#34;GET\u0026#34;, fmt.Sprintf(\u0026#34;/evenorodd?number=%s\u0026#34;, test.queryParam), nil) w := httptest.NewRecorder() EvenOrOddHandler(w, req) assert.Equal(t, test.expectedCode, w.Code) assert.Equal(t, \u0026#34;application/json\u0026#34;, w.Header().Get(\u0026#34;Content-Type\u0026#34;), \u0026#34;application/json\u0026#34;) assert.Equal(t, w.Body.String(), test.expected, test.message) }) } } func EvenOrOddHandler(w http.ResponseWriter, req *http.Request) { // At some point in the TDD Process we\u0026#39;d add better code to ensure values were OK  if num, ok := req.URL.Query()[\u0026#34;number\u0026#34;]; ok { n, _ := strconv.Atoi(num[0]) r := \u0026#34;odd\u0026#34; if n \u0026gt; 100 { w.WriteHeader(http.StatusNotAcceptable) r = \u0026#34;error\u0026#34; } else if n \u0026lt;= 0 { w.WriteHeader(http.StatusInternalServerError) r = \u0026#34;math is hard\u0026#34; } else if n%2 == 0 { r = \u0026#34;even\u0026#34; } w.Header().Add(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) fmt.Fprintf(w, `{\u0026#34;result:\u0026#34; \u0026#34;%s\u0026#34;}`, r) } fmt.Println() }  Testing Gorilla/Mux Middleware So now we\u0026rsquo;ve delivered a component that is able to run the most complex mathematical algorithm in history. Every one is super excited. Demo and retro went well.\nHowever, the customer is now super concerned about who has access to this immensely powerful tool that your team has created. They don\u0026rsquo;t want any malicious Spring Boot apps utilizing this service for dastardly deeds. Luckily we know we have a authentication service and middleware we can use for just such a thing. We just need to test it.\nTesting middleware will be much like testing our handlers. We need to slightly alter our expectations. Middleware can respond to the client as a normal handler would, or it can invoke the \u0026ldquo;next\u0026rdquo; handler in our middleware chain.\nBecause we have an awesome PM that helped get wonderful acceptance criteria, we know we need:\n If the user is authorized, call the next handler. If the user is NOT authorized respond with a 403  Right now our 0% code covered code looks like:\nfunc Auth(next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, req *http.Request) { user := req.URL.User.Username() pass, _ := req.URL.User.Password() if superComplexAuthenticationAndAuthorizationLogic(user, pass) { req.Header.Add(\u0026#34;Authorized\u0026#34;, \u0026#34;Sure is\u0026#34;) next.ServeHTTP(w, req) return } w.WriteHeader(http.StatusUnauthorized) fmt.Fprintf(w, \u0026#34;\u0026#34;) }) }   In our production code we will be passing Auth to the mux.Use() method. In our test we just want to be sure that our function behaves as it should when the Gorilla framework invokes it. So we will need to come up with a way to verify that next gets invoked OR 403 gets set as the response code.\nFor our test we want to implement the handler interface with a mock/stub: type MockHandler struct { t *testing.T Message string wascalled bool } func (mh *MockHandler) ServeHTTP(w http.ResponseWriter, req http.Request) { // We could assert other things here, but for now we just  // want to know if it was called  mh.wascalled = true }  Now we can go a head and start setting up our test to get an idea where we are at.\nfunc TestAuth(t *testing.T) { tests := []struct { name string message string user string pass string isAuthed bool callnext bool rc int }{ { name: \u0026#34;Given the User was Authorized\u0026#34;, message: \u0026#34;The next handler should be called\u0026#34;, user: \u0026#34;bob\u0026#34;, pass: \u0026#34;bobsPassword1234\u0026#34;, isAuthed: true, callnext: true, rc: 200 }, } for _, test := range tests { endpoint := fmt.Sprintf(\u0026#34;https://%s:%s@some.endpoint/stuff\u0026#34;, test.user, test.pass) req := httptest.NewRequest(\u0026#34;GET\u0026#34;, endpoint, nil) w := httptest.NewRecorder() t.Run(test.name, func(t *testing.T) { mh := \u0026amp;MockHandler{t, test.message, test.callnext} Auth(mh).ServeHTTP(w, req) // Uncomment these assertions one at a time to discover the issue  // assert.True(t, mh.wascalled, test.message)  // assert.Equal(t, test.rc, w.Code, \u0026#34;Should get the expected return code\u0026#34;)  }) } }   The test runs great. However, as you start advancing through the test you notice a big problem. You are calling the real service each time. This means to test you are forced to test you are forced to provide real users and passwords, or set up a special configuration that points to a test auth service. Not only do we don\u0026rsquo;t have time for that, we can\u0026rsquo;t unit test this code because it is not unit testable.\nWe know we somehow need to replace the functionality of superComplexAuthenticationAndAuthorizationLogic. We need a way to inject this dependency into our code. So we need to do a bit of refactoring. There are a few valid ways we could approach this.\nFor example we could refactor Auth to take in a function that returns the same the middlewarefunction: func Auth(auth func(string,string) bool) func(http.Handler) http.Handler  We won\u0026rsquo;t bother displaying the rats nest of returned functions that this would end up being. While totally valid, and just as flexible/reusable as other methods, we start to lose readability.\nSo what if, instead, we were to create a struct that allowed for the service to be set as a property, and then just attach our Auth middleware to it?\n type AuthMiddleware struct { AuthService func(string, string) bool } func (am AuthMiddleware) Auth(next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, req *http.Request) { user := req.URL.User.Username() pass, _ := req.URL.User.Password() if am.AuthService(user, pass) { req.Header.Add(\u0026#34;Authorized\u0026#34;, \u0026#34;Sure is\u0026#34;) next.ServeHTTP(w, req) return } w.WriteHeader(http.StatusUnauthorized) fmt.Fprintf(w, \u0026#34;\u0026#34;) }) }  Now do a slight refactor to our test code:\nas := AuthMiddleware{ AuthService: func(user, pass string) bool { return test.isAuthed }, } as.Auth(mh).ServeHTTP(w, req)  And then we can continue to add test cases as we go:\nfunc TestAuth(t *testing.T) { tests := []struct { name string message string user string pass string isAuthed bool callnext bool rc int }{ { name: \u0026#34;Given the User was Authorized\u0026#34;, message: \u0026#34;The next handler should be called\u0026#34;, user: \u0026#34;bob\u0026#34;, pass: \u0026#34;bobsPassword1234\u0026#34;, isAuthed: true, callnext: true, rc: 200, }, { name: \u0026#34;Given the User is NOT Authorized\u0026#34;, message: \u0026#34;The next handler should **NOT** be called\u0026#34;, user: \u0026#34;bob\u0026#34;, pass: \u0026#34;bobsPassword1234\u0026#34;, isAuthed: false, callnext: false, rc: http.StatusUnauthorized, }, } for _, test := range tests { endpoint := fmt.Sprintf(\u0026#34;https://%s:%s@some.endpoint/stuff\u0026#34;, test.user, test.pass) req := httptest.NewRequest(\u0026#34;GET\u0026#34;, endpoint, nil) w := httptest.NewRecorder() t.Run(test.name, func(t *testing.T) { mh := \u0026amp;MockHandler{t, test.message, test.callnext} as := AuthMiddleware{ AuthService: func(user, pass string) bool { return test.isAuthed }, } as.Auth(mh).ServeHTTP(w, req) if test.callnext { assert.True(t, mh.wascalled, test.message) } else { assert.False(t, mh.wascalled, test.message) } assert.Equal(t, test.rc, w.Code, \u0026#34;Should get the expected return code\u0026#34;) }) } }  Testing your Endpoint with httptest.Server When testing with a server, you still start testing with the handler function. The biggest difference between using httptest.Server and httptest.ResponseRecorder is that Server starts up an actual server on a port.\nfunc TestWithServer(t *testing.T) { ts := httptest.NewServer(http.HandlerFunc(EvenOrOddHandler)) defer ts.Close() res, _ := http.Get(ts.URL + \u0026#34;?number=4\u0026#34;) actual, err := ioutil.ReadAll(res.Body) assert.Nil(t, err) assert.Equal(t, `{\u0026#34;result:\u0026#34; \u0026#34;even\u0026#34;}`, actual) }  You will find yourself using httptest.Server when you need to do end to end and or/integration testing. For example, you have a route that has a middleware that calls an external api/database, then does something before a response with another handler function. Using server would allow you to test the whole chain.\n Lab Apply these techniques to a previous lab. Refactor your code as needed to write good unit tests.\n"
},
{
	"uri": "/software-eng-essentials/command-line-bash/bash-scripting-intro/",
	"title": "Bash Scripting Intro",
	"tags": [],
	"description": "",
	"content": "Learning to use the power of the command line and bash shell scripting\n What is a bash script? Why should I write a shell script? Shell scripts vs compiled programs  What is a bash script? A file that contains a series of Unix commands and bash statements.\nIt is made up of ASCII text, also called \u0026ldquo;plain text\u0026rdquo;.\nYou cannot use a word processor to edit shell scripts, you must use a text editor or the command line.\nWhen a shell script is executed…\nIt executes the commands listed in the script. It starts at the top and executes the command one line at a time. Shell scripts produce the same result as if entering commands manually.\nWhy should I write a shell script? To save time and work\nAnytime you find you yourself entering multiple shell commands in a terminal in order to accomplish a task, and you will need to do that task again in the future, you should write a shell script.\nShell scripts eliminate repetitive tasks through automation.\nInstead of typing the same commands over and over again, you can spend that time doing more valuable and higher-level tasks.\nFor a task that must be done more than once, albeit rarely\nA script can perform a task faster and more reliable than a human can. A good script can reduce the chance of errors.\nYou can use shell scripts to delegate work to others\nPut your knowledge of a procedure into a shell script, and share the script with associates.\nUse shell scripts when you need information from more than one source.\nExample: Let’s say you manage a web server, and for each IP address that generates a web server error, you wanted to know their hostname as well as see all the web pages that they visited. If you were doing this by hand you would have to look through the error log and note each IP address, copy and paste them into a scrap file, then you would look up each IP address to determine their hostname, finally you would search for those IP addresses in the web server access logs. You can write a shell script that does this entire process for you, and displays it in an easy to consume and easy to read format.\nWhy would you choose to write a script or program in shell rather than a compiled language?\n Speed of development. Example: you could write a script that performs a simple backup by first archiving a set of files and then copying that file over the network into another server. This could be done in just a few lines of shell code, or you could take a lot of time writing the procedure in a compiled language if you want to spend a lot of time and effort. No need to worry about low-level programming objects like bits, pointers, data types, etc. The shell is a high-level language that allows you to express complex operations simply and clearly. Ease and speed of learning to script in bash. Performance and efficiency  But the tradeoff is worth it when the shell script runs fast enough for its intended purpose. Shell scripts are useful in system administration and reporting tasks when getting the job done is more important than getting the job done a few microseconds quicker.\nKeep in mind that anything you can do in the command line can be automated by writing a shell script.\n"
},
{
	"uri": "/cloud/containers/docker-fundamentals/build-context/",
	"title": "Build Context",
	"tags": [],
	"description": "",
	"content": "Concepts  Use a PATH or URL as a context. Filter the build context.  What is build context? A Docker build context is the source directory used when building the container.\nDocs: Extended description\nBy default, Docker will look at the root level of the context for the Dockerfile.\nPATH context A PATH argument like . indicates the current working directory in the local filesystem will be used as the build context.\nExample 1 Consider the following folder structure:\n$ tree . └── subfolder/ ├── Dockerfile └── content/ └── index.html where the contents of the Dockerfile are:\nFROM nginx COPY content /usr/share/nginx/html and the contents of index.html are:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello from a Docker Container\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Building this image is straight forward because we can simply provide the subfolder as the PATH:\n$ docker build subfolder Example 2 But things get a bit more complex if we split the context between subfolder/ and .* as follows:\n$ tree . ├── content/ │ └── index.html └── subfolder/ └── Dockerfile If we try the same build command, docker build subfolder, we get an error message:\n=\u0026gt; ERROR [2/2] COPY content /usr/share/nginx/html To resolve this, we must provide both the path to the Dockerfile and the CONTEXT path:\ndocker build -f subfolder/Dockerfile -t demo3 . Note that the default name for the Dockerfile is CONTEXT_PATH/Dockerfile, but you can specify a Dockerfile with --file , -f such as:\n$ docker build -f myapp/dockerfiles/debug myapp This is useful in cases where the same set of files are used for multiple builds. More info here.\nExample 3 Let\u0026rsquo;s look at one more example where the Context is split with the files in a nested folder:\n$ tree . ├── Dockerfile └── subfolder └── content └── index.html How would we build this?\nThe answer is:\ndocker build -f Dockerfile -t demo3 subfolder URL context Git repositories When pointing to the location of a Git repo, the repo acts as the build context.\n Commit history is not preserved.\n Docs: Git repos\nTar file When pointing to the location of a remote tarball, the Docker daemon will fetch the tarball and use it as the build context.\nDocs: Tar contexts\nExample from docs: Build with URL\nText files Instead of specifying a context, you can pass a single Dockerfile in the URL or pipe the file in via STDIN.\nDocs: Text files\nExample from docs: Build with -\nFilter a context The build context may contain small, sensitive files (i.e., credentials, .env) or large, unnecessary files (i.e., node_modules/, *.iso) that you want to exclude from the image Docker is building. Filtering contexts is achieved with a .dockerignore file. Build performance will be increased.\nExample from docs: Use a .dockerignore file\nQuiz Scenario 1\nThe following build command is executed:\n$ docker build -t tupperware ./ Question\nWhat is the build context?\nScenario 2\n  A Dockerfile instructs ADD requirements.txt\n  The current working directory has a file requirements.txt.\n  The build context is a Git repo.\n  Question\nWhich requirements.txt will be added?\nLab 1: Building from a Dockerfile on GitHub Enterprise   The location of the repo is a GitHub Enterprise account, so you will need a personal access token.\n  The path of the target repo is github.homedepot.com/mah3093/hello-nginx.git.\n  The signature of the command should look like this:\n  $ docker build https://\u0026lt;api token\u0026gt;:@\u0026lt;target repo\u0026gt; For example: docker build https://12345abcdef:@github.homedepot.com/mah3093/hello-nginx.git\nLab 2: Building from a Dockerfile in a different location from the context  Create a folder that will serve as the build context  Test data is given below, or you can create your own   Create a Dockerfile that is on a different file path from the context  Just using the instructions FROM and COPYwill be fine Optionally, you can also supply a CMD instruction to do something with the data   Run the build command!   You can copy the test data below for the build context.\n tool-list.csv\nModel#,Brand,Description,Price BE469ZP V CAM716,Schlage,Camelot Aged Bronze Connect Smart Lock with Alarm,298.00 B86L1BD,Defiant,Brandywine Stainless Steel Single Cylinder Keyed Entry Project Pack,32.96 FE595 CAM 619 ACC,Schlage,Camelot Satin Nickel Electronic Door Lock with Accent Door Lever,119.00 RB-YRD540-WV-619,Google,Next x Tale Lock Satin Nickel with Google Nest Connect,279.00 Summary  The docker build command builds Docker images from a Dockerfile and a \u0026ldquo;context\u0026rdquo;. The build context is the set of files located in the specified PATH or URL. The build process can refer to any of the files in the context.  "
},
{
	"uri": "/golang/concurrency/",
	"title": "Concurrency",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/golang/concurrency/patterns/",
	"title": "Concurrency Patterns",
	"tags": [],
	"description": "",
	"content": "Now that we have a basic understanding of Concurrency in Golang and the basic tools, let\u0026rsquo;s take a deeper dive into some of the patterns we can accomplish using those tools.\nWe\u0026rsquo;ll need to start with some common vocabulary.\n Pipelines Stages Producer Consumer  The patterns we will cover are:\n Generator Futures Fan Out/Fan In Semaphore Racing Passing Contexts  Pipelines Pipelines in Golang are a general term used to describe a type of concurrent program that best utilizes I/O streams and Golang\u0026rsquo;s concurrency primitives.\nPipelines are comprised of stages connected by channels for communication. Each stage is a group of goroutines running the same function.\nThe first stage may not have incoming data and can be referred to as the producer or the source.\nThe final stage is often referred to as the consumer or the sink.\nA classic queue could be created with just the producer and a consumer on a buffered channel.\nGenerator Used to generate a sequence of values which will be used to produce some output. Generators usually provide concurrency through loops. This way the consumer of the data can start processing while the generator, or producer is busy computing the next value.\nfunc readJson(filename string, readInType func(*json.Decoder), done func()) { file, err := os.Open(filename) if err != nil { fmt.Println(\u0026#34;Error opening file for reading\u0026#34;, err) return } defer file.Close() dec := json.NewDecoder(file) var wg sync.WaitGroup wg.Add(1) go func() { defer wg.Done() // read open bracket \tdec.Token() // while the array contains values \tfor dec.More() { go func(dec *json.Decoder) { readInType(dec) }(dec) } // read closing bracket \tdec.Token() }() wg.Wait() done() return } Futures Futures allow for a program to say \u0026ldquo;I know I need to compute something, but I don\u0026rsquo;t need it necessarily right now. Just give it back when you\u0026rsquo;re finished (passed back by a channel).\u0026rdquo; This is similar to the idea of promises or callbacks in other languages.\nfunc main() { c1 := nameService(\u0026#34;anna\u0026#34;) c2 := nameService(\u0026#34;ross\u0026#34;) fmt.Println(\u0026lt;-c1) fmt.Println(\u0026lt;-c2) } // returns a read only channel of generated data. func nameService(name string) \u0026lt;-chan string { c := make(chan string) go func() { c \u0026lt;- name }() return c }  Do NOT do async callback functions in Golang. Channels remove the need to communicate through the calling of a function. Higher order functions as part of functional programming is an accepted pattern, however.  Fan Out, Fan In Several functions can be listening to the same channel. This is called Fan Out.\nLet\u0026rsquo;s consider the following square and sum function example.\nfunc producer() { // I generate data and put it on the nums channel to be squared by the consumer. \tnumsCh := make(chan int, 5) squaredCh := make(chan int, 5) var wg sync.WaitGroup for j := 0; j \u0026lt; 5; j++ { wg.Add(1) go consumer(numsCh, squaredCh, wg.Done) // This could also be called a worker pool. \t// The consumer is taking numbers off the numsCh, squaring it, and then placing the result on the squaredCh. \t} // ... } We have a producer that places the numbers on a channel, and we have 5 goroutines that are working off the same channel. This is Fan Out.\nFan In\nfunc FanIn(ch1, ch2 chan string){ for n := range merge(ch1, ch2) { fmt.Println(n) } //... } The merge function can read from multiple inputs and proceed once all channels are closed by multiplexing the input channels onto a single channel that\u0026rsquo;s closed when all the inputs are closed.\nThe Fan In pattern is the serialization of multiple channels. It can also be achieved with a select statement.\nSemaphore A semaphore is concerned with ensuring at most N threads can ever access code exclusively. In the below example we have a pool of network connections, where a buffered channel acts as our semaphore (signaler). This pool forces the amount of concurrent process that could be running.\ntype Pool struct { sem chan token idle chan net.Conn } type token struct{} func NewPool(limit int) *Pool { sem := make(chan token, limit) idle := make(chan net.Conn, limit) return \u0026amp;Pool{sem, idle} } func (p *Pool) Release(c net.Conn) { p.idle \u0026lt;- c } func (p *Pool) Hijack(c net.Conn) { \u0026lt;-p.sem } The limit of the semaphore is set in the constructor function. Constraining concurrency can help performance due to the scheduling behavior. Each network connection can be released, therefore making it available in the idle channel. It can then be used, reading off a token from the semaphore.\nRacing Say there are two databases that are identical to each other. (One is used as a backup) It is possible to try to hit them both, and use the data from the database that is responding the quickest. This is called the Racing pattern.\nImagine we have customer\u0026rsquo;s all over the whole world and servers located in several places. We might want to race to a few to see which server responds the quickest for a customer based on their location.\nfunc getData(request string) []Orders{ ch := make(chan string) // Unbuffered.  go conn1.Get(request, ch) go backupConn.Get(request, ch) data \u0026lt;- ch // Take which ever was faster.  //... take the data, and allow the other to be released later. } Passing Contexts Incoming requests to a server should create a Context, and outgoing calls to servers should accept a Context.\nContexts can carry:\n Cancel signals Done signals variables/constants  Some of the values that the concurrent pipeline might need from a request are :\n Identity of the end user Authorization Tokens The request\u0026rsquo;s deadline  Contexts can be derived from existing contexts. When the parent is cancelled, so are all the children.\nfunc handleSpinUpStoreVM(w http.ResponseWriter, r *http.Request){ ctx := context.Background() if userId, exists := r.Header[\u0026#34;user\u0026#34;]; exists { ctx = context.WithValue(ctx, \u0026#34;user\u0026#34;, userId) // Set user if exists. Let it carry this value throughout. \t} d := time.Now().Add(1 * time.Minute) // Request will timeout after 1 minute. \tctx = context.WithDeadline(ctx, d) ctx, done = context.WithCancel(ctx) c1 := db.NewStore(ctx, r) // Future Pattern. \tc2 := rpc.NewStore(ctx, r) // Future Pattern. \t// Both services would listen for the ctx.Done channel to cancel operations.  // We either want both c1 and c2 to come back, OR the deadline to hit. \terrs := make([]errors, 2) count := 0 cont := true success := false for cont { select { case dbErr := \u0026lt;-c1: if dbErr != nil { errs = append(errs, dbErr) done() // Cancel the other if one fails. \t} else { count++ if count == 2 { cont = false success = true } } case rpcErr := \u0026lt;-c2: if rpcErr != nil { errs = append(errs, rpcErr) done() // Cancel the other if one fails. \t} else { count++ if count == 2 { cont = false success = true } } } case \u0026lt;-ctx.Done(): cont = false success = false } } // Return a response \tif success { w.WriteHeader(http.StatusOK) } else { // Wrap errors from errs and ctx.Error... \thttp.Error(w, ctx.Error(), http.StatusInternalServerError) } } Concurrency Best Practices  Don\u0026rsquo;t use a goroutines unless it is called for. If one thing will not continue until the next is required, then a go routine is not called for. Use range in consumers; They will continue work until the channel is closed. Close your channels. Clean up, be a good citizen. A send on a closed channel will cause panic, so don\u0026rsquo;t let a consumer tell the producer when it is finished. Ensure consumers can only consume. recvOnly \u0026lt;-chan Thing are your friends. Track completion of goroutines. sync.WaitGroup is your friend. Close only when producing routines can be verified as no longer able to send on the channel being closed.  Final Notes  Avoid premature optimization. There\u0026rsquo;s no need to make a pipeline more complicated unless the efficiency gained is immense. Minimize concurrent interface. Keep most functions testable by keeping them functional. Leverage built-in thread safety. Most OS\u0026rsquo; already have a lock on file writes, for example.  Resources  https://www.youtube.com/watch?v=f6kdp27TYZs https://medium.com/statuscode/pipeline-patterns-in-go-a37bb3a7e61d https://blog.golang.org/pipelines https://about.sourcegraph.com/go/gophercon-2018-rethinking-classical-concurrency-patterns https://blog.golang.org/context  "
},
{
	"uri": "/golang/foundations/control-structures/",
	"title": "Control Structures",
	"tags": [],
	"description": "",
	"content": "Control! You must learn control! Learning Objectives Concepts  If statements The Switch statements For — the only loop you will ever need.  Skills  Create a basic for loop If with assignment values Create switch statements How to use for for all traditional looping  If Statements In pseudo code for basic if structures in just about any language:\nif a equals b then do something else if a equals c then do something else else do some default thing In go:\nIf, else if, else\na, b, c := 1, 2, 1 if a == b { fmt.Println(\u0026#34;A and B are the same!\u0026#34;) } else if a == c { fmt.Println(\u0026#34;A and C are the same!\u0026#34;) } else { fmt.Println(\u0026#34;Nothing is is equal to A!\u0026#34;) } Single if statement\na, b := 1,1 if a == b { fmt.Println(\u0026#34;A and B are the same!\u0026#34;) } Multiple Checks With Boolean Operators with if If with boolean operators\na, b, c := 1, 1, 1 if a == b || a == c \u0026amp;\u0026amp; c != b { fmt.Println(\u0026#34;A has an equal!\u0026#34;) } A Case for Parentheses The following shows a case for when the placement of parenthesis can affect output.\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { a, b, c := 1, 1, 1 if c != b \u0026amp;\u0026amp; a == b || a == c { fmt.Println(\u0026#34;True!\u0026#34;) } if c != b \u0026amp;\u0026amp; (a == b || a == c) { fmt.Println(\u0026#34;Trew!\u0026#34;) } } Try Me!\n\u0026ldquo;Short\u0026rdquo; If Statements Short if statements contains at lease one variable declaration, followed by an evaluation:\nShort if statement example:\ny := 4 if x := y % 2; x == 0 { fmt.Println(\u0026#34;Even!\u0026#34;) } Here is what is going on.\nIn a single line this if statement\n declares a new variable x assigns the result of y % 2. ( remainder of 4 / 2 is 0, so x is assigned type int with a value of 0 ) The x is then used after the semicolon ; as a conditional to determine if it is == 0  Scope Review\nWhat is the scope of x?\nfunc main() { y := 4 if x := y % 2; x == 0 { fmt.Println(\u0026#34;Even\u0026#34;) } fmt.Println(x) } Try Me!\nLab 1: If Statement Setup  Follow the instructions in the readme for the go foundations labs cd \u0026lt;your workspace\u0026gt;/om-labs/go-foundations/control/lab1/ Open ifthen.go and complete the instructions in the readme.  Switch Statements Switch statements are often used when a result of a conditional could result in many different decisions.\nAlthough this is ok in an if statement:\nVerbose if/else-if statement\nif a == 1 { fmt.Println(\u0026#34;Choice 1\u0026#34;) }else if a == 2 { fmt.Println(\u0026#34;Choice 2\u0026#34;) } else if a == 3 { fmt.Println(\u0026#34;Choice 3\u0026#34;) } else if a == 4 { fmt.Println(\u0026#34;Choice 4\u0026#34;) } The same logic could be coded more cleanly as a switch statement:\nBasic switch\nswitch a { case 1: fmt.Println(\u0026#34;Choice 1\u0026#34;) case 2: fmt.Println(\u0026#34;Choice 2\u0026#34;) case 3: fmt.Println(\u0026#34;Choice 3\u0026#34;) case 4: fmt.Println(\u0026#34;Choice 4\u0026#34;) } Default Switch with a default option\nswitch a { case 1: fmt.Println(\u0026#34;Choice 1\u0026#34;) case 2: fmt.Println(\u0026#34;Choice 2\u0026#34;) case 3: fmt.Println(\u0026#34;Choice 3\u0026#34;) case 4: fmt.Println(\u0026#34;Choice 4\u0026#34;) default: fmt.Println(\u0026#34;No valid choice\u0026#34;) }  Similar to else, if no values match, the default block will execute  Short and More Complex Evaluations  \u0026ldquo;in-line declarations\u0026rdquo; when starting the switch statement.  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { switch time.Now().Weekday() { case time.Saturday, time.Sunday: fmt.Println(\u0026#34;It\u0026#39;s the weekend\u0026#34;) default: fmt.Println(\u0026#34;It\u0026#39;s a weekday\u0026#34;) } } Try Me!\nSwitch With no Condition A switch statement does not require a condition. It can reference another in-scope variable or function to determine if any of the cases are true.\nSwitch statement with no conditions\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { t := time.Now() switch { case t.Hour() \u0026lt; 12: fmt.Println(\u0026#34;It\u0026#39;s before noon\u0026#34;) default: fmt.Println(\u0026#34;It\u0026#39;s after noon\u0026#34;) } } Try Me!\nLab 2: Switch Statements Set up You can reuse the same file from lab1, or follow the following steps:\n Follow the instructions in the readme for the go foundations labs cd \u0026lt;your workspace\u0026gt;/om-labs/go-foundations/control/lab2/ Open switch.go in your editor and follow the instructions in the readme.  For - One Loop to Rule Them All!  A loop is simply a way to do repetitive work. Go uses the for keyword to start all loops  Code that should probably be in a loop:\n// Print numbers 0 - 4 fmt.Println(0) fmt.Println(1) fmt.Println(2) fmt.Println(3) fmt.Println(4) Basic Iterative for loop for i := 0; i \u0026lt; 5; i++ { fmt.Println(i) } While style loop run := true // 1 for run { // 2 \tfmt.Println(\u0026#34;Hello\u0026#34;) run = false // 3 we mark it false and the loop will stop }  declare a bool called run by setting it to true Create a for loop that will run until run is false Set run to false so the loop will not run again.  Continue, Break, Return and Labels You do not need a condition in a for loop, but you need to be careful.\nfor { }  true is inferred here, and because we never toggle a false, this will run for ever.  Break \u0026amp; Return break\nfor { break }  Exits the loop  Return\nfor { return }  Exits the loop AND the function it is defined in.  Continue Use the continue key word to begin the next iteration.\nfunc main() { for i := 0; i \u0026lt; 10; i++ { if x := i % 2; x == 0 { continue } fmt.Println(i) } } Try Me!\nLabels Labels:\n Allow specific control over blocks of code, typically when using loops Can be added as part of your code before a statement. Can be provided as arguments to continue, break, and goto  Using Labels with continue and break Multiple Labels on Nested loops\nfunc main() { MyLoop: for l := 0; l \u0026lt; 5; l++ { Here: for i := 0; i \u0026lt; 10; i++ { if x := i % 2; x == 0 { fmt.Println(\u0026#34;even\u0026#34;) continue Here } fmt.Println(\u0026#34;odd\u0026#34;) break MyLoop } } } Try Me!\n Skip the iteration and continue from Here label Break out of MyLoop  Goto Syntax:\ngoto label goto:\n A goto statement transfers control to the statement with the corresponding label within the same function. Executing the goto statement must not cause any variables to come into scope that were not already in scope at the point of the goto. A goto statement outside a block cannot jump to a label inside that block.  The following examples will cause an error\nCreates a new variable between the goto and label\ngoto L // BAD \tv := 3 // New variable L: someCodeCalled() Cannot \u0026ldquo;goto\u0026rdquo; a child or sibling block\nif n%2 == 1 { goto L1 } for n \u0026gt; 0 { f() n-- L1: f() n-- } Reproducing a Loop with Goto\nfunc main() { i := 0 GoHere: fmt.Println(\u0026#34;Where I will go\u0026#34;, i+1) i++ if i == 10 { return } goto GoHere } Try Me!\nLab 3: Loops Set up  Follow the instructions in the readme for the go foundations labs cd \u0026lt;your workspace\u0026gt;/om-labs/go-foundations/control/lab3 Open loop.go in your editor and follow the instructions in the readme.  Putting it All Together Control working together\npackage main import \u0026#34;fmt\u0026#34; func main() { for i := 0; i \u0026lt;= 500; i++ { //Is the number even? \tif x := i % 2; x == 0 { fmt.Printf(\u0026#34;%d is Even \\n\u0026#34;, i) } // Do some thing based on what I is \tswitch i { case 100: fmt.Println(\u0026#34;400 to go!\u0026#34;) case 125: fmt.Println(\u0026#34;You know what? I\u0026#39;m going to cheat!\u0026#34;) i += 300 case 480: fmt.Println(\u0026#34;That\u0026#39;s it. I quit.\u0026#34;) break fmt.Println(\u0026#34;Done!\u0026#34;) } } } Try Me!\n"
},
{
	"uri": "/golang/testing/dependency/",
	"title": "Dependency Injection",
	"tags": [],
	"description": "",
	"content": "Goals Understand what Dependency Injection (DI) is and why it allows for smaller, digestable units that make testing an application easier.\nLearning Objectives  What is DI? How to apply DI How DI makes testing easier  What Dependency Injection Is Dependency Injection (DI) is a pattern in software development that states code should be separated into sections of logical blocks, and removed from code that consumes it. This pattern states that dependencies should be passed in as parametersto consuming code.\nThis separates concerns for each logical code block, allowing for each section to know only what it needs to know.\nFor example:\nA section of code needs to add a product to a customers shopping cart.\nIt doesn\u0026rsquo;t need to actually interface with the database, or contain the credentials for accessing the database.\nInstead an access layer could hold all the details and be passed into the shopping cart section.\n_The below example is pseudo code, not any specific language._accessLayer = { connect = function() { ... } query = function(){ ... } } shoppingCart = function(accessLayer){ addItem = function() { accessLayer.query( sql to add item to db. ) .. } } Now each the shopping cart and the access layer can be tested independently. When we go to test the shopping cart we can implement a fake access layer that won\u0026rsquo;t affect the real database.\nHow to apply DI? If code is doing too much, like generating data and determining where it goes, most likely these concerns need to be separated.\nExample, handling http requests and doing domain level logic should be split into separate functions or even packages.\nWhat does the shopping cart need to know?\n cart owner cart items how to handle cart events  Does the shopping cart need to know how to change the price of an item? Does the shopping cart need to know how to change the first name of the shopping cart owner?No, these concerns should be separated from the shopping cart component.\nApplying the DI pattern provides the following benefits:\n Separation of Concerns Increased readability of code Easier to test sections Coding to interfaces, not implementation  Conclusion Applications should be broken down into smaller units of functionality. When Dependency Injection is followed, it can ensure that separation of concerns is utilized, makes code more reusable, and more easily testable.\nBy injecting our dependencies we also make it easier to unit test a specific functionality. We can then use mocks to provide isolation and introspection.\n"
},
{
	"uri": "/software-eng-essentials/testing/dependency/",
	"title": "Dependency Injection",
	"tags": [],
	"description": "",
	"content": "Goals Understand what Dependency Injection (DI) is and why it allows for smaller, digestable units that make testing an application easier.\nLearning Objectives  What is DI? How to apply DI How DI makes testing easier  What Dependency Injection Is Dependency Injection (DI) is a pattern in software development that states code should be separated into sections of logical blocks, and removed from code that consumes it. This pattern states that dependencies should be passed in as parametersto consuming code.\nThis separates concerns for each logical code block, allowing for each section to know only what it needs to know.\nFor example:\nA section of code needs to add a product to a customers shopping cart.\nIt doesn\u0026rsquo;t need to actually interface with the database, or contain the credentials for accessing the database.\nInstead an access layer could hold all the details and be passed into the shopping cart section.\n_The below example is pseudo code, not any specific language._accessLayer = { connect = function() { ... } query = function(){ ... } } shoppingCart = function(accessLayer){ addItem = function() { accessLayer.query( sql to add item to db. ) .. } } Now each the shopping cart and the access layer can be tested independently. When we go to test the shopping cart we can implement a fake access layer that won\u0026rsquo;t affect the real database.\nHow to apply DI? If code is doing too much, like generating data and determining where it goes, most likely these concerns need to be separated.\nExample, handling http requests and doing domain level logic should be split into separate functions or even packages.\nWhat does the shopping cart need to know?\n cart owner cart items how to handle cart events  Does the shopping cart need to know how to change the price of an item? Does the shopping cart need to know how to change the first name of the shopping cart owner?No, these concerns should be separated from the shopping cart component.\nApplying the DI pattern provides the following benefits:\n Separation of Concerns Increased readability of code Easier to test sections Coding to interfaces, not implementation  Conclusion Applications should be broken down into smaller units of functionality. When Dependency Injection is followed, it can ensure that separation of concerns is utilized, makes code more reusable, and more easily testable.\nBy injecting our dependencies we also make it easier to unit test a specific functionality. We can then use mocks to provide isolation and introspection.\n"
},
{
	"uri": "/python/web-framework/django_admin/",
	"title": "Django Admin",
	"tags": [],
	"description": "",
	"content": "Philosophy Generating admin sites for your staff or clients to add, change, and delete content is tedious work that doesn’t require much creativity. For that reason, Django entirely automates creation of admin interfaces for models.\nDjango was written in a newsroom environment, with a very clear separation between “content publishers” and the “public” site. Site managers use the system to add news stories, events, sports scores, etc., and that content is displayed on the public site. Django solves the problem of creating a unified interface for site administrators to edit content.\nThe admin isn’t intended to be used by site visitors. It’s for site managers.\nCreating an admin user First we’ll need to create a user who can login to the admin site. Run the following command:\n$ python manage.py createsuperuser Enter your desired username and press enter. Username: admin You will then be prompted for your desired email address: Email address: admin@example.com The final step is to enter your password. You will be asked to enter your password twice, the second time as a confirmation of the first. Password: ********** Password (again): ********* Superuser created successfully. Start the development server¶ The Django admin site is activated by default. Let’s start the development server and explore it. If the server is not running start it like so:\n$ python manage.py runserver Now, open a Web browser and go to /admin/ on your local domain – e.g., http://127.0.0.1:8000/admin/. You should see the admin’s login screen:\nDjango admin login screen Since translation is turned on by default, the login screen may be displayed in your own language, depending on your browser’s settings and if Django has a translation for this language.\nEnter the admin site¶ Now, try logging in with the superuser account you created in the previous step. You should see the Django admin index page:\n###Django admin index page You should see a few types of editable content: groups and users. They are provided by django.contrib.auth, the authentication framework shipped by Django.\nMake the locations app modifiable in the admin But where’s our locations app? It’s not displayed on the admin index page.\nJust one thing to do: we need to tell the admin that Market objects have an admin interface. To do this, open the locations/admin.py file, and edit it to look like this:\n# locations/admin.py from django.contrib import admin from .models import Market admin.site.register(Market) Refresh the page!\nExplore the admin functionality Now that we’ve registered Market, Django knows that it should be displayed on the locations/admin index.\nClick “Markets”. Now you’re at the “change list” page for questions. This page displays all the questions in the database and lets you choose one to change it. There’s the “ATL” market we created earlier:\nClick \u0026ldquo;ATL\u0026rdquo; market to edit it: Things to note here:   The form is automatically generated from the Market model.\n  The different model field types (DateTimeField, CharField) correspond to the appropriate HTML input widget. Each type of field knows how to display itself in the Django admin.\n  Each DateTimeField gets free JavaScript shortcuts.\n  The bottom part of the page gives you a couple of options:\n Save – Saves changes and returns to the change-list page for this type of object. Save and continue editing – Saves changes and reloads the admin page for this object. Save and add another – Saves changes and loads a new, blank form for this type of object. Delete – Displays a delete confirmation page.  Saving Changes Change the “Num stores”. Then click “Save and continue editing.” Then click “History” in the upper right. You’ll see a page listing all changes made to this object via the Django admin, with the timestamp and username of the person who made the change:\nAdd More Functionality To add more functionality to your admin console look at the Django Tutorial. Where you see Question use Market and where you see Choice use Store\nExercise: Fill in Tables with values Fill in the Market table with a couple of values.\nCreate an admin view of Store and add additional stores.\n"
},
{
	"uri": "/java/foundations/easter-lab/",
	"title": "Easter Calculation Lab",
	"tags": [],
	"description": "",
	"content": "Starter code for this lab can be found: here\nA convenient algorithm for determining the date of Easter in a given year was devised in 1876 and first appeared in Butcher’s Ecclesiastical Handbook. This algorithm holds for any year in the Gregorian calendar, which means years including and after 1583. Subject to minor adaptations, the algorithm is as follows:\n Let y be the year (such as 1583 or 2003). Divide y by 19 and call the remainder a. Divide y by 100 and call the quotient b. Divide y by 100 and call the remainder c. Divide b by 4 and get a quotient d. Divide b by 4 and get a remainder e. Divide b + 8 by 25 and get a quotient f. Divide b – f + 1 by 3 and get a quotient g. Divide 19 * a + b – d – g + 15 by 30 and get a remainder h. Divide c by 4 and get a quotient i. Divide c by 4 and get a remainder k. Divide 32 + 2 * e + 2 * i - h - k by 7 and get a remainder r. Divide a + 11 * h + 22 * r by 451 and get a quotient m. Divide h + r - 7 * m + 114 by 31 and get a quotient n Divide h + r - 7 * m + 114 by 31 and get a remainder p.  The value of n gives the month (Example: 3 means March and 4 means April) and the value of p + 1 gives the day of the month. For example, if y is 2003:\na = 8 b = 20 c = 3 d = 5 e = 0 f = 1 g = 6 h = 26 i = 0 k = 3 r = 3 m = 0 n = 4 p = 19 Therefore, in 2003, Easter fell on April 20 (month = n = 4 and day = p + 1 = 20).\n"
},
{
	"uri": "/react/foundations/labs/lab-forms-calculator/",
	"title": "Forms",
	"tags": [],
	"description": "",
	"content": "A lab for working with React and forms.\nUse controlled components to build a simple form that calculates a user\u0026rsquo;s input\n Include two controlled inputs that take in data from the user Provide two buttons that perform calculations:  Add Subtract   Print the result to the screen Try disabling the buttons when the inputs do not have valid number values. Try adding a reset button to clear the form.  Your solution should look something like this:\n   "
},
{
	"uri": "/software-eng-essentials/git-foundations/gitting-started/",
	"title": "Gitting Started",
	"tags": [],
	"description": "",
	"content": "git help A great resource is the help command within git itself. Simply type:\ngit help A list of common commands will pop up in your terminal.\nFor more detail on a particular command just follow git help with the actual command of interest. This is done in the following style:\ngit help command-you-need-help-with    Go to Git Research lab    Initializing vs Cloning There are two different ways to get started in git:\n git init - will initialize a new, empty repository. git clone - will copy an existing repository (provided you have permission) to your directory.  git init Example\nIf you have a directory called Orange Academy and navigate inside of it, you can type git init.\nThis creates a new, hidden .git folder. This folder stores commits, local config, remote tracking and branching.\n   Go to Initializing lab    Saving Changes Saving changes in git is called \u0026ldquo;staging\u0026rdquo; your changes.\ngit add moves your changed files into the staging area.\nAnalogy: Imagine you are trying to take a group photo. Staging is similar to the process of gathering up the people to take the photo.\nThere are a couple of different ways to move your files into the staging area.\n   Git Add Commands What They Stage     git add file-name only the changes of the file you specify.   git add -A all changes, in higher directories that still belong to the same git repository.   git add . all changes but only in the current directory and subdirectories.   git add -u modified content within files and deleted files, but excludes newly created files.   git add * all files of a specific file type as long as they\u0026rsquo;re not deleted files. I.E.: if 10 .txt files are to be added at the same time, you can type git add *.txt, and all but the deleted files will be staged.   git add --ignore-removal . new and modified files only.    Making a Snapshot git commit captures a snapshot of the project\u0026rsquo;s currently staged changes. Committed snapshots can be thought of as \u0026ldquo;safe\u0026rdquo; versions of a project—Git will never change them unless you explicitly ask it to.\n Back to the group photo analogy: At this point, you have already gathered all of the people to take the picture. commit would be the actual taking of the picture.\n Committing requires a message describing what the snapshot is of.\nTyping just git commit will open the default text editor to write descriptive message.\nThe -m flag allows the descriptive message to be written directly in the terminal. An example: git commit -m \u0026quot;Added section covering commit\u0026quot; (Make sure to surround your message in double quotes)\nThe following creates a git repository with a file in it then stage and create a snapshot of the changes:\n$ mkdir gitting-started $ cd gitting-started $ echo \u0026#34;this is a git practice file\u0026#34; \u0026gt;\u0026gt; practice.txt $ git init . Initialized empty Git repository in /Users/joehacker/gitting-started $ git add -A $ git commit -m \u0026#34;adds git test file\u0026#34; [master 92cff00] adds git test file 1 file changed, 1 insertion(+) create mode 100644 practice.txt  [master 92cff00] adds git test file shows the unique SHA-1 id associated with the commit, allowing you to go back to this point in the files history.  Tracking changes It is possible to list off all of the changes:\n git status - Shows all of the files that have been staged, which haven’t, and which files aren’t being tracked by Git. git log - Shows you the history of commits made by all contributors.     Go to All the adds lab    Changing your mind  git reset undoes changes  --soft HEAD the ref pointers are updated and the reset stops there --hard HEAD (Warning this will delete all changes)   git checkout -- (Warning this will delete all changes) git commit --amend  Diffing git diff allows you to review changes that have been made to specific files or previous commits in the terminal.\n   Go to diffing walkthrough    Optional Arguments git diff has optional arguments to specify what you want to compare, some of the more common uses include:\n git diff HEAD - shows all current changes tracked (staged and un-staged) commits git diff --staged - shows changes being proposed in staged files In addition to diffing your current work, you can also compare the code from two previous commits by passing the commit ID\u0026rsquo;s (SHA-1). For example: git diff 6dc93e5 17c884c .   It\u0026rsquo;s also worth noting that some text editors offer fairly comprehensive diffing tools.\n git commit Flags git commit --amend This command will open an editor to allowing for editing the last commit message committed on a local branch, saving it, and exiting the editor.\nNow git log would show the new, descriptive commit message.\ngit commit --fixup fixup is used with commit along with specifying SHA1, like: git commit --fixup ab6732aa\nfixup is used when committing new code that\u0026rsquo;s a small change, like fixing a typo is found in the previous commit. To do so:\n get the first 8 digits of the SHA1 of the last commit, like aaa777bb make your small changes, and do the fixup command like: git commit --fixup aaa777bb and those changes will be prepared to be fixed up into that commit.  After using --fixup you can use --autosquash to then squash those messages together.\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/html-forms/",
	"title": "HTML Forms",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Introduce the html form element Discuss form actions Review the attributes available to the input element  Skills  Build interactive forms Understand the available input options  Forms The HTML \u0026lt;form\u0026gt; element allows users to interact with an application.\nUser Input indicates that the user is interacting with your page. It could be as simple as clicking a button or entering username and password on a login form.\nCommon examples of forms include:\n Signup Login Search Comments Contact Payment Info  Much of your client-side development work will involve configuring forms. And with good reason, one could say that the vast majority of applications are elaborate sets of forms.\nLet\u0026rsquo;s take a look at a basic signup form:\n\u0026lt;form action=\u0026#34;/api/signup\u0026#34; method=\u0026#34;get\u0026#34;\u0026gt; // 1 \u0026lt;label for=\u0026#34;firstname\u0026#34;\u0026gt;First name:\u0026lt;/label\u0026gt; // 2 \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;firstname\u0026#34; name=\u0026#34;firstname\u0026#34;/\u0026gt;\u0026lt;br/\u0026gt; // 3 \u0026lt;label for=\u0026#34;lastname\u0026#34;\u0026gt;Last name:\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;lastname\u0026#34; name=\u0026#34;lastname\u0026#34;/\u0026gt;\u0026lt;br/\u0026gt; \u0026lt;/form\u0026gt;  html \u0026lt;form\u0026gt; element indicating all items within the element are part of that specific form forms can use the \u0026lt;label\u0026gt; element to add text about the form element the \u0026lt;input\u0026gt; element can take several types to modify what input is required   \u0026lt;input\u0026gt; expects an attribute of type (such as type=text) to determine how the data will be accepted, handled, and shown on the client\n This previous code produces the following output:\nForm Attributes The \u0026lt;form\u0026gt; element has two required attributes:\n action - the endpoint where data should be submitted method - the http action to take. In standard html, get and post are the only 2 options made available  Additional (optional) attributes of note include:\n autocomplete - options are: on and off name - Specifies the name of the form. novalidate - If present, no form validations will be attempted target - Specifies where to display the response from the server  Check out the W3Schools Form Attributes Section to learn more.\nLabel The \u0026lt;label\u0026gt; element is used to associate a text label with a form\u0026rsquo;s \u0026lt;input\u0026gt; field.\nfor Attribute Labels must contain a for attribute, and this attribute\u0026rsquo;s value must match the id attribute on the corresponding \u0026lt;input\u0026gt;.\n\u0026lt;label for=\u0026#34;email\u0026#34;\u0026gt;Email Address: \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;email\u0026#34; id=\u0026#34;email\u0026#34; name=\u0026#34;email\u0026#34;/\u0026gt; In the above example, we have paired the email \u0026lt;label\u0026gt; with the email \u0026lt;input\u0026gt;.\nInput The \u0026lt;input\u0026gt; element is where users will input data. You can imagine that each input acts like a variable that will eventually be sent to the server.\nInput Attributes input provides a number of attributes to work with.\nType\ntype is used to define the type of input field provided to the user. Browsers will use this value to aid the user with specific validations, input text and (on touch screen devices) various keyboard options.\nSome of the more common types include:\n text - a standard text field email - provides validations and keyboard options for email addresses number - provides validations and input options for numbers password - obscures text while user is typing file - allows user to attach a file from their device storage tel - provides options for telephone number input date - provides date format and often a date picker   There are a number of additional input types worth reviewing. Check out the MDN docs on Form Inputs to learn more.\n Name\nThe name attribute is used to identify the submitted data. This often maps to an expected value in the route, controller, db, etc.\n If no name is specified, or name is empty, the input\u0026rsquo;s value is not submitted with the form.\n Value\nIf the optional value attribute is present, the provided data will be used as the initial value for the form input.\nThe behavior of value changes based on the type of input.\n Often, JavaScript will be used to alter the value.\n Placeholder\nplaceholder will provide some default info for the user. This data will be disappear as soon as the user begins typing.\nAdditional Attributes\nTo see a list of all attributes and options associated with input check out: Mozilla Input Form Element\n   Go to basic form lab    Buttons    The HTML \u0026lt;button\u0026gt; element provides an event based on user interaction Buttons can exist on their own  Buttons can have three different types:   type='submit'- sends form data (this is the default behavior if none is specified)     type='reset'- removes data from current form     type='button'- no inherent behavior, doesn\u0026rsquo;t have to be in a form, must be handled with javascript or react etc.     Buttons can contain text or even images  Buttons are written with the following syntax\n\u0026lt;button type=\u0026#34;button\u0026#34;\u0026gt;Click\u0026lt;/button\u0026gt; Creates a Button like: Summary Forms are used to submit data, from the client, to the server. Anytime you work with frontend code, you\u0026rsquo;ll more than likely find yourself utilizing forms.\n   Go to the rest of the form labs    "
},
{
	"uri": "/javascript/foundations/labs/iterations-lab/",
	"title": "Iterations Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch iterations.js Add the following code to iterations.js:\nconst numbers = [12, 3, 26, 19, 11, -4, 99]; // TODO: Use a for loop to print out whether each value in `numbers` is even or odd // You will need to use if / else conditionals inside the for loop block // Your code should print the number followed by \u0026#34;is even\u0026#34; or \u0026#34;is odd\u0026#34; Step 2: Complete the code and test Complete the TODO in the above code.\nTest your solution with:\nnode iterations.js The expected output is:\n12 is even 3 is odd 26 is even 19 is odd 11 is odd -4 is even 99 is odd "
},
{
	"uri": "/javascript/pillars/",
	"title": "Javascript Pillars",
	"tags": [],
	"description": "",
	"content": "Welcome to Javascript Pillars! "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/labs/lab-kitchen-organizer/",
	"title": "Kitchen Organizer",
	"tags": [],
	"description": "",
	"content": "Follow the instructions in: Kitchen Organizer.\n"
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/managing-file-system/",
	"title": "Managing the File System",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Managing directories - the mkdir, rmdir, and rm -r commands Managing Files - the touch, cp commands Moving and Renaming Files and Directories - the mv command Copying Files and Directories - the cp command Removing Files - the rm command Viewing file contents - cat, more or less, head and tail Searching files - grep  Creating Directories  The command to create a directory is mkdir (make directory). To create a directory called Orange Academy, type:  mkdir Orange Academy If you wanted to create the Orange Academy directory in the Downloads folder, you would need to do the following:\ncd ~/Downloads # Navigate to Downloads mkdir Orange Academy # Create the new directory cd Orange Academy # Navigate into the new directory Naming Conventions  It is recommended to avoid naming files and directories with spaces in the name. If you must, you can escape the space character, for example: mkdir my\\ pictures But instead, various \u0026ldquo;naming conventions\u0026rdquo; are used for naming directories and files  Common Naming Conventions:\n   Convention Description Example     TitleCase Every word starts with a capital letter MyPictures   camelCase Every word (except the first word) starts with a capital letter myPictures   dash-case Words are separated with a dash my-pictures   snake_case Words are separated with an underscore my_pictures    Creating Files You can create a file with the touch command. You can call it anything you like (be aware of naming conventions) but your file name usually needs to be followed by a file extension indicating the type of file it is. Thus:\n If you wanted to create a text file called orange-method, it would be orange-method.txt. If you wanted to create a markdown file with the same name would be orange-method.md.  Use the following command to create an empty text file in your directory.\ntouch orange-method.txt Using echo to write to files  The echo command (by default) writes to the console, but you can redirect where the output of echo goes. In order to redirect the output of echo to be added to the end of an existing file orange-method.txt:  echo \u0026#34;Hi\u0026#34; \u0026gt;\u0026gt; orange-method.txt To create a file called orange-method.txt and add text to it, type the following:\necho \u0026#34;Orange Academy: More Learning, More Doing\u0026#34; \u0026gt; orange-method.txt Note that the first command has two \u0026gt;\u0026gt; and the second has one \u0026gt;. One carrot creates or replaces the file while two carrots appends to the file.\nViewing Files Cat, More, and Less To view the contents of a file, you use the cat command. If you wanted to see the contents of a file called hello.txt, you would type:\ncat hello.txt NOTE: For longer files you can use the more command or the more powerful less command to view a file a section at a time. You use the spacebar to advance to the next section and you can use the b (for back) to go back to the previous section. To quit you hit the q key.\nless my-long-file.txt Head and Tail You can also use the head and the tail commands for viewing parts of a file:\n head - show the first n lines of a file, where the default for n is 10 lines tail - show the last n lines of a file, where the default for n is 10 lines  Both head and tail take the -n option for specifying a number of lines other than 10 to be displayed:\nhead -n 5 data.txt # show the first 5 lines tail -n 20 data.txt # shoe the last 20 lines # You can also simply type a dash followed by the number of lines: head -5 data.txt # show the first 5 lines tail -20 data.txt # shoe the last 20 lines Counting the Contents of a File You can use wc (word count) to count the lines, words, and/or characters in a file:\n$ wc filename.txt 274 1450 8642 filename.txt Searching Files You can search files for a given string using grep:\n$ grep buy todos.txt buy milk buy a new iPhone Working with files and directories Moving  The mv command moves a file or directory to another directory The mv command can also rename a file or directory  Type the following to move a file called todo.txt from the current directory to ~/Downloads:\nmv todo.txt ~/Downloads Another example\nSay that you have the following file structure:\nOrange Academy ├── guest └── homer └── todo.txt 2 directories, 1 file If you are currently in the Orange Academy directory, and want to move the todo.txt from the Orange Academy/homer directory to the Orange Academy/guest, type:\nmv homer/todo.txt guest The file structure would now look like:\nOrange Academy ├── guest │ └── todo.txt └── homer 2 directories, 1 file Renaming Renaming a file or directory is the same as moving it except that the directory location does not change. We simply specify a new name for the file or directory.\nThe command syntax is: mv old-name new-name:\nmv apple.txt orange.txt # change the name of the file `apple.txt` to `orange.txt` mv my-project project-1 # change the name of the directory `my-project` to `project-1` Copying The cp command is very similar to the mv command, but it keeps both the original file or directory AND creates a duplicate file or directory.\ncp apple.txt orange.txt # create a new file called `orange.txt` that has the same contents as `apple.txt` Removing We can remove files using the rm command.\nExample:\nrm groceries.txt We can remove an empty directory with the rmdir command:\n$ rmdir Orange Academy If the directory is not empty and you know you want to remove it along with all of it\u0026rsquo;s contents, you can use rm -rf:\n$ rm -rf Orange Academy # WARNING: this is like a nuclear destruction command!!!   The -r option means recursive, thus all files and directories under the Orange Academy directory will be deleted.\n  The -f option means to forcefully remove the files without prompting for confirmation, regardless of the file’s permissions.\n   IMPORTANT: Recursively deleting a directory is very dangerous as removing directories and files from the command line is not a recoverable option.\n  There is no \u0026ldquo;trash can\u0026rdquo; for the command line so once you remove something, it is gone! In addition, removing files and directories recursively is a very powerful command that can quickly remove a lot of files. So be very careful when using rm -r.   NOTE: Often you will see the -f option as well when removing files.\n  This is the force option that removes all files and directories even if they are marked as read only. Thus to remove all files and directories recursively and force read-only files to be removed as well, you would type:  rm -rf some-directory.\nExercises  Go to the A New Terminal Lab Go to the Kitchen Organizer Lab  Summary    Command Description Example     mkdir create a new directory mkdir dirname   rmdir remove an empty directory rmdir dirname   touch create a new file or update timestamp on existing file touch filename   cat display the contents of a file cat filename   wc count the number of lines, words, and characters wc filename   grep search a file for the specified string grep unix *.md       Command Description Example     more display the contents of a file a screen at a time more filename   less display the contents of a file a screen at a time less filename   head display the first lines of a file head filename   tail display the last lines of a file tail filename   mv move or rename a file or directory mv filename target   cp copy a file cp filename target   rm remove a file rm filename    "
},
{
	"uri": "/python/foundation/math-functions/",
	"title": "Math Functions",
	"tags": [],
	"description": "",
	"content": "Math Functions abs()\nFinds the absolute value\nprint(90 - 120) print(abs(90 - 120)) Output:\n-30 30 pow()\nRaises a number to a certain power\nprint(pow(2,3)) Output:\n8\nround()\nRounds a number to a certain decimal point\nprint(round(17.34989436516001,4)) Output:\n17.3499\nRandom Values Using the random module, we can generate psuedo-random numbers. To use the random module, you must place the following at the top of your file:\nimport random random\nGenerates a random number floating point number between 0 and 1\nprint(random.random()) Possible Output: 0.173499\nrandint\nGenerates a random whole number between two numbers (inclusive).\nChoosing a random whole number between 1 and 100\nprint(random.randint(1, 100)) Possible Output: 95\nuniform\nGenerates a random floating point number between two numbers (inclusive)\nChoosing a random floating point number between 10 and 50\nprint(random.uniform(10, 50)) Possible Output: 24.313911327373457\nchoice\nGenerates a random value from an iterable\nChoosing a random value from a list of numbers [90, 12, 34]\nprint(random.choice([90, 12, 34])) Possible Output: 12\nGo to Variables Lesson\n"
},
{
	"uri": "/cloud/containers/developing-with-docker/containerizing-your-application/multi-stage-docker-builds/",
	"title": "Multi-stage Docker Builds",
	"tags": [],
	"description": "",
	"content": "Concepts  Multi-stage build Targeting a specific stage in a multi-stage build  Multi-stage build The node:12-stretch image is based off Debian and it has tools like curl installed. Curl is nice, but it\u0026rsquo;s only being used to test the app and it\u0026rsquo;s not needed for the app to run. We can see the image size using the Docker CLI.\n$ docker images | grep express hello express e117d6dd6c2f 27 minutes ago 920MB 920 MB may not be as large as some images ––cough, cough, Java/Spring Boot–– but an Alpine image will be even smaller because it doesn\u0026rsquo;t include tools that aren\u0026rsquo;t necessary for production like curl.\nProblem – Need images for stages different from development What if we could have more than one for our app? Different stages in software development like test, build, production or release could benefit from having unique images.\nSolution Multi-stage build\nA multi-stage build is known by its multiple FROM instructions. Whereas a regular Dockerfile has one FROM instruction, a multi-stage build will have multiple and they are often aliased to nomers like builder or tester.\nA skeleton of what a multi-stage build Dockerfile might look like:\nDockerfile\nFROMdebian AS builder# RUN ...# CMD ...FROMalpine AS tester# RUN ...# CMD ...We can implement a multi-stage build to the app by specifying a new base image with a second FROM instruction.\nDockerfile\n# builder stageFROMnode:12-stretch AS builderRUN mkdir /home/node/app \u0026amp;\u0026amp; chown node:node /home/node/appWORKDIR/home/node/appUSERnodeCOPY --chown=node:node ./package* ./RUN npm installCOPY --chown=node:node ./ ./CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;]# tester stageFROMnode:alpine AS testerRUN apk add curlCOPY --from=builder ./home/node/app ./RUN npm installCMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;]Build the new multi-stage image:\n$ docker build -t hello:tester . Now compare the image sizes:\n$ docker images | grep hello hello tester 0fd0ad101817 6 minutes ago 118MB hello express e117d6dd6c2f 42 minutes ago 920MB hello:tester is 802MB smaller than the original image or just ~12.8% the size of the original image. Breaking down what\u0026rsquo;s happening in this multi-stage build:\nDockerfile\n# builder stageFROMnode:12-stretch AS builder # 1# ...# tester stageFROMnode:alpine AS tester # 2RUN apk add curl # 3COPY --from=builder ./home/node/app ./ # 4RUN npm install # 5CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;] # 6 Alias the first stage as builder. Start the second build stage.  This second FROM instruction specifies the base image for the new stage. Aliased as tester.   Install tools or dependencies needed for the tester layer. Copy contents from a context.  Specified context is ./home/node/app. --from=builder instructs where the context is to be found.   Install dependencies. Default command that will override any default command from a previous build.  NOTE: Aliasing any stage like AS builder is optional. If an alias is not given, the default identifier is an index number starting from 0. In this case --from=builder could be replaced with --from=0. It is recommended to use aliases since they will always be linked to a stage, but a stage\u0026rsquo;s index could change if a new stage was added before it.\nProblem – Targeting a specific stage If we have a multi-stage build where we know the final stage will effectively override the previous layer since containers are thrown away until the final image is built, how can we build an image from the same Dockerfile that targets a stage that isn\u0026rsquo;t the final stage?\nSolution Target a stage for an image build:\n$ docker build --target builder -t hello:builder . The image build starts from the top of the Dockerfile and stops after it completes the targeted stage.\nInspecting the image size:\n$ docker images | grep hello hello tester 69ef4bdf67c8 About an hour ago 121MB hello builder a2cc9104f0a3 About an hour ago 920MB hello express e117d6dd6c2f 2 hours ago 920MB The new hello:builder image is the same size as the original hello:express image. In fact, the two images are equal.\nLAB – Create a multi-stage build .Starter code\n$ git clone https://github.homedepot.com/om-labs/developing-with-docker.git $ cd \u0026lt;preferred language\u0026gt;/multi-stage-node NOTE: You will not need to write any source code for the app in this lab. You will only write a Dockerfile and use the Docker CLI.\nThis multi-stage build will be a triple lutz. By that we mean it will have three stages: builder, tester, and prod.\n Create the multi-stage build Dockerfile.   You can use base images from from docker.artifactory.homedepot.com/node or from DockerHub. Hint: find what Linux distro it is based on. You can find this in the base image\u0026rsquo;s source code (Dockerfile) or by using the Docker CLI. The \u0026ldquo;tester\u0026rdquo; intermediate stage should install curl. The prod or final image should based on a small image like alpine or scratch. The final image (the prod or release stage) should not have development or test dependencies, just production code.   Tag images that target each of the stages.\n  Run the \u0026ldquo;tester\u0026rdquo; container.\n   Shell inside the running container. Test the API. From the shell of the container, curl against the following endpoints:  http://localhost:8000/greeting http://localhost:8000/greeting?name=Homer     Test the final prod/build/release stage container.\n Test the endpoints in your browser.    Compare the image sizes of the stages.\n  "
},
{
	"uri": "/react/pillars/perf-opt-strategies/pagination/",
	"title": "Pagination",
	"tags": [],
	"description": "",
	"content": "Use Pagination to avoid rendering a large data set all at once.\nProblem Loading and rendering large data sets can become a performance concern due to:\n fetching the data from a data source (such as a database, file system, or external server) transporting the data from the web server to the browser converting the data into JavaScript data types rendering the data into the DOM  When is Pagination Needed?  When to apply a pagination strategy will depend both on how many records may be retrieved and the size of each record. Generally speaking, data sets under 100 records are generally not too large. It\u0026rsquo;s best to do performance measurements:  fetch time data transfer time (may need to consider slower networks) rendering time    Next we will look at several ways to reduce the latency and resources needed when dealing with large data sets.\nData Truncation Data truncation is simply loading and rendering only the first N records, where N can be chosen as needed.\nAdvantages:\n avoids slow renders due to rendering only the first N records can reduce the load on the server and improve fetch latency (if truncation is done server-side) very simple to implement  Disadvantages:\n the user cannot see all of the data  Client-side Pagination Client-side pagination will load all of the data into the client (i.e. the browser / React app) but only render a \u0026ldquo;page\u0026rdquo; at a time.\n  Advantages:\n avoids slow render times is relatively simple to implement (just truncate / slice a JavaScript array) sorting and filtering can be done client side  Disadvantages:\n the server must load and transfer the entire data set the client must hold the entire data set in memory  Server-side Pagination With server-side pagination the server only fetches and transfers a \u0026ldquo;page\u0026rdquo; of data at a time to the client. The client will then request subsequent pages as needed.\nAdvantages:\n reduces load on server and improves fetch latency reduces transfer times and network loads avoids slow renders due to rendering lots of records  Disadvantages:\n is more complex to implement than client-side pagination  pagination tokens must be managed and sent with each request (specifying which page is needed and the size of a page) all sorting and filtering must happen server side    Windowing (aka Infinite Scroll)  Windowing is similar to Client-side pagination but the \u0026ldquo;paging\u0026rdquo; mechanism is not revealed to the user. Instead the user simply scrolls and additional data is rendered as needed to keep the viewport filled with data.    Advantages:\n avoids slow render times is relatively simple to implement (just truncate / slice a JavaScript array) sorting and filtering can be done client side offers an alternative (often easier) UX - scrolling instead of clicking  Disadvantages:\n the server must load and transfer the entire data set the client must hold the entire data set in memory  Windowing with Infinite Loader  Windowing with infinite loading is similar to Server-side pagination but the \u0026ldquo;paging\u0026rdquo; mechanism is not revealed to the user. Instead the user simply scrolls and additional data is rendered as needed to keep the viewport filled with data.  Advantages:\n reduces load on server and improves fetch latency reduces transfer times and network loads avoids slow renders due to rendering lots of records offers an alternative user interaction (scrolling instead of clicking)  Disadvantages:\n is more complex to implement than client-side pagination  pagination tokens must be managed and sent with each request (specifying which page is needed and the size of a page) all sorting and filtering must happen server side   involves some tricky coding in the client to avoid race conditions  scrolling events are synchronous but data fetching is asynchronous    Summary  Pagination provides a way to render large data sets a \u0026ldquo;page\u0026rdquo; at a time Windowing is similar to pagination but provides the user with a scrolling Both pagination and windowing can load the entire data set into the client or load data on-demand (as needed)  Resources  Infinite Scrolling vs. Pagination  Lab or Code Along - 60 minutes  Create a React application using create-react-app. Add a json-server to provide a large data set to the client.  You can either create a large db.json file with the data set or programmatically return a large data set by writing a server.js file for json-server. See: Generate Random Data | json-server docs for a description of how to create data programmatically.   First load the entire data set into the React client and display it. You can use something simple for rendering such as an unordered list. See how much data you can display before the React client becomes sluggish. Now add either pagination or windowing to improve the React performance.  NOTE: Feel free to inspect the code in the React Performance Optimization Playground App to see how to implement Pagination or Windowing. To keep things simple, you can implement your solution with using React Table.\n"
},
{
	"uri": "/cloud/platforms/pcf-foundations/checklist/",
	"title": "PCF Deployment Checklist",
	"tags": [],
	"description": "",
	"content": ".cfignore your node_modules Create a .cfignore file that specifies node_modules (a single line of text, similar to the .gitignore file). This will make cf pushes run faster\n.cfignore\nnode_modules Verify your package.json start script Make sure your package.json script for starting your app looks like this:\n\u0026#34;start\u0026#34;: \u0026#34;NODE_ENV=production node ./bin/www\u0026#34;, This assumes you used the express-generator which uses bin/www for bootrapping the express app - edit as needed and do not use nodemon in your start script. You can use another dev script for nodemon, such as:\n\u0026#34;dev\u0026#34;: \u0026#34;DEBUG=my-app-name:* NODE_ENV=development nodemon --inspect ./bin/www\u0026#34; Specify a NodeJS version in package.json Add an \u0026ldquo;engines\u0026rdquo; section to your package.json to tell PCF that you want to use a recent version of NodeJS (one that understands ES-2015 syntax):\npackage.json\n\u0026#34;engines\u0026#34;: { \u0026#34;node\u0026#34;: \u0026#34;^8.0.0\u0026#34; }, Use a manifest.yml file Use a manifest.yml file to specify the name, buildpack, and the command to run to setup the database and run your Express application.\nmanifest.yml\n--- applications: - name: my-app-name command: knex --env production migrate:latest \u0026amp;\u0026amp; NODE_ENV=production node path/to/my/bookshelf-seeds-file.js \u0026amp;\u0026amp; npm start buildpack: nodejs_buildpack The command above is used for ensuring that the database is migrated and seeded before launching the Express app. Edit as needed.\nVerify your prod database configuration in knexfile.js Use the cfenv library in your knexfile.js to properly read environment variables for connecting the Express App to the PostgreSQL database.\nknexfile.js\nconst cfenv = require(\u0026#39;cfenv\u0026#39;); const debug = require(\u0026#39;debug\u0026#39;)(\u0026#39;my-app-name\u0026#39;); // edit as needed  const appEnv = cfenv.getAppEnv(); const credentials = appEnv.getServiceCreds(\u0026#39;my-service-name\u0026#39;); // edit as needed  ... production: { client: \u0026#39;postgresql\u0026#39;, connection: { host: credentials ? credentials.host : null, database: credentials ? credentials.database : null, user: credentials ? credentials.user : null, password: credentials ? credentials.password : null }, pool: { min: 2, max: 10 } } }; "
},
{
	"uri": "/react/foundations/prop-types/",
	"title": "PropTypes (optional)",
	"tags": [],
	"description": "",
	"content": "Using PropTypes to verify a component\u0026rsquo;s props.\nNOTE: this is an optional lesson as propTypes are not essential to learning React.\nIntroduction  Often we want to ensure that a Component is receiving the proper configuration (props) that it needs. We can add runtime verification of the props via React\u0026rsquo;s propTypes.   NOTE: The use of propTypes in React components is entirely optional, but is often helpful. propTypes provide both a way of documenting the props that a component expects and verifying (at runtime) that it received those props.\n  For the following Greeter component we expect to get a name prop that is of type string. Here is how we declare the propTypes for Greeter:  import React from \u0026#39;react\u0026#39;; import PropTypes from \u0026#39;prop-types\u0026#39;; function Greeter({ name }) { // Note the object destructuring of `name`  return \u0026lt;h4\u0026gt;Hello {name}\u0026lt;/h4\u0026gt;; }; Greeter.propTypes = { // propTypes is a property of the Component class we are defining  name: PropTypes.string.isRequired // We are requiring a prop of `name` that has a type of `string`. }; // Specifies the default values for props: Greeter.defaultProps = { // We can also define default values for `props`.  name: \u0026#39;Stranger\u0026#39; // We set the default value for the `name` prop to `\u0026#39;Stranger\u0026#39;` }; export default Greeter; The prop-types Library  Since React v15.5, React.PropTypes has support is located into a separate package called prop-types. You can add this library to your React project via:  yarn add prop-types A List of React PropTypes You can declare that a prop is a specific JS primitive or a composite data type. By default, these are all optional.\nReact propTypes for JavaScript Primitive and Composite Data Types:\n   propType Description     PropTypes.array An array   PropTypes.bool A boolean   PropTypes.func A (callback) function   PropTypes.number A number   PropTypes.object An object   PropTypes.string A string   PropTypes.symbol A symbol   PropTypes.instanceOf(Message) An instance of a specific class.   PropTypes.oneOf(['News', 'Photos']) A specific set of values (an enum)   PropTypes.oneOfType([...]) An object that could be one of many types   PropTypes.arrayOf(PropTypes.number) An array of a certain type   PropTypes.objectOf(PropTypes.number) An object with property values of a certain type   PropTypes.shape({ ... }) An object taking on a particular shape   PropTypes.any.isRequired A value of any data type    You can chain any of the above with isRequired to make sure a warning is shown if the prop isn\u0026rsquo;t provided:\nPropTypes.func.isRequired Custom PropTypes  You can also specify a custom validator for a prop. The custom validator is a function that should return an Error object if the validation fails (returning undefined means that everything is okay).   TIP: Don\u0026rsquo;t console.warn or throw an Error from your custom validator as this won\u0026rsquo;t work inside oneOfType.\n email: (props, propName, componentName) =\u0026gt; { if (!/emailRegex/.test(props[email])) { // return new Error(\u0026#39;Give me a real email!\u0026#39;);  return new Error( `Invalid prop \u0026#39;${propName}\u0026#39; supplied to \u0026#39;${componentName}\u0026#39;. Validation failed.` ); } }  You can also supply a custom validator to arrayOf and objectOf. It should return an Error object if the validation fails. The validator will be called for each key in the array or object. The first two arguments of the validator are the array or object itself, and the current item\u0026rsquo;s key.  allEmails: PropTypes.arrayOf((propValue, key, componentName, location, propFullName) =\u0026gt; { if (!/emailRegex/.test(propValue[key])) { return new Error( `Invalid prop \u0026#39;${propFullName}\u0026#39; supplied to \u0026#39;${componentName}\u0026#39;. Validation failed.` ); } }) Another Example Here is a more complete example with several props:\nimport React from \u0026#39;react\u0026#39; import PropTypes from \u0026#39;prop-types\u0026#39;; function Person({name, address, hobbies}) { return ( \u0026lt;h1\u0026gt;{name}\u0026lt;/h1\u0026gt; ) } Person.propTypes = { name: PropTypes.string.isRequired, address: PropTypes.shape{ street: PropTypes.string.isRequired, city: PropTypes.string.isRequired, state: PropTypes.string.isRequired, zipcode: PropTypes.string.isRequired }), hobbies: PropTypes.arrayOf(PropTypes.string) } export default Person The above propTypes specify that:\n a name prop of type string is required an address prop of type object is optional where if the object is defined it should contain the following:  a street of type string that is required a city of type string that is required a state of type string that is required a zipcode of type string that is required   a hobbies of type array containing only strings. Note that the hobbies prop is optional.  Lab Do part 4 of the Component Props Lab.\nSummary  React\u0026rsquo;s propTypes adds runtime validation that the proper props are being passed into our components. If a propType validation warning occurs, a message is printed to the JavaScript console.  Additional Resources  Typechecking With PropTypes  "
},
{
	"uri": "/software-eng-essentials/restful-api/",
	"title": "RESTful API",
	"tags": [],
	"description": "",
	"content": "Welcome to RESTful APIs! "
},
{
	"uri": "/javascript/performance/universal-rendering-lab/step-5/",
	"title": "Step 5: Pass data from the server to the client",
	"tags": [],
	"description": "",
	"content": "One way that we can pass data from the server to the client is by serializing it (parsing it into a string) and including it in the response that we send to the client.\nWe can do this by adding the serialized data to the global window object, via a \u0026lt;script\u0026gt; tag.\n\u0026lt;script\u0026gt;window.__INITIAL_DATA__ = ${ JSON.stringify({ data }) }\u0026lt;/script\u0026gt;  Modify the route handler in src/server/app.js to match the following code snippet:  // src/server/app.js app.get(\u0026#39;/\u0026#39;, async (req, res) =\u0026gt; { const data = await fetchMarketsAndPageInfo(); res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;${ ReactDOMServer.renderToString(\u0026lt;App data={ data }/\u0026gt;) }\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt;window.__INITIAL_DATA__ = ${ JSON.stringify({ data }) }\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;/client-bundle.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); }); ​\n Next, let\u0026rsquo;s modify our client code to read in the data that was passed into the window object.  // src/client/index.js import React from \u0026#39;react\u0026#39;; import { hydrate } from \u0026#39;react-dom\u0026#39;; import App from \u0026#39;./App\u0026#39;; hydrate( \u0026lt;App data={ window.__INITIAL_DATA__.data } /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) );   Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and we should now see the page render without any flashing, and without any warnings in the browser console.\n  "
},
{
	"uri": "/react/performance/universal-rendering-lab/step-5/",
	"title": "Step 5: Pass data from the server to the client",
	"tags": [],
	"description": "",
	"content": "One way that we can pass data from the server to the client is by serializing it (parsing it into a string) and including it in the response that we send to the client.\nWe can do this by adding the serialized data to the global window object, via a \u0026lt;script\u0026gt; tag.\n\u0026lt;script\u0026gt;window.__INITIAL_DATA__ = ${ JSON.stringify({ data }) }\u0026lt;/script\u0026gt;  Modify the route handler in src/server/app.js to match the following code snippet:  // src/server/app.js app.get(\u0026#39;/\u0026#39;, async (req, res) =\u0026gt; { const data = await fetchMarketsAndPageInfo(); res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/App.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/ux-styleguide.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxfont.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/uxicon.min.css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;/client-bundle.js\u0026#34; defer\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;${ ReactDOMServer.renderToString(\u0026lt;App data={ data }/\u0026gt;) }\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt;window.__INITIAL_DATA__ = ${ JSON.stringify({ data }) }\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); }); ​\n Next, let\u0026rsquo;s modify our client code to read in the data that was passed into the window object.  // src/client/render.js import React from \u0026#39;react\u0026#39;; import { hydrate } from \u0026#39;react-dom\u0026#39;; import App from \u0026#39;./App\u0026#39;; hydrate( \u0026lt;App data={ window.__INITIAL_DATA__.data } /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) );   Rebuild the code (npm run build \u0026amp;\u0026amp; npm run start), and we should now see the page render without any flashing, and without any warnings in the browser console.\n  "
},
{
	"uri": "/javascript/foundations/strings/",
	"title": "Strings",
	"tags": [],
	"description": "",
	"content": "An introduction to JavaScript Strings.\nObjectives  Use String methods to access and manipulate String values Use String templates to create strings that contain evaluated JavaScript expressions  Creating Strings  String literals can be written with single quotes or double quotes. There is no difference between single quotes and double quotes.  NOTE: You can use back quotes to create a String template literal which has some additional capabilities that we will discuss later in this lesson.\nconst city = `Atlanta`; // back quotes const state = \u0026#39;Georgia\u0026#39;; // single quotes const zipcode = \u0026#34;30308\u0026#34; ; // double quotes String Properties and Methods Strings have a set of properties and methods that can be used to get information about the string, get parts of the string, or manipulate the string in some way, for example:\nconst greeting = \u0026#39;Hello, OM!\u0026#39;; greeting.length; // 10 greeting.charAt(0); // \u0026#39;H\u0026#39; greeting.charAt(5); // \u0026#39;,\u0026#39; greeting.indexOf(\u0026#39;O\u0026#39;); // 7 greeting.substring(7, 9); // \u0026#39;OM\u0026#39; greeting.toLowerCase(); // \u0026#39;hello, om!\u0026#39; greeting.toUpperCase(); // \u0026#39;HELLO, OM!\u0026#39; greeting; // \u0026#39;Hello, OM!\u0026#39; (has not changed) Strings can be joined together (concatenated) using the + operator:\nconst city = `Austin`; const state = \u0026#39;TX\u0026#39; ; const zipcode = \u0026#34;78753\u0026#34; ; const address = city + \u0026#39;, \u0026#39; + state + \u0026#39; \u0026#39; + zipcode; // \u0026#39;Austin, TX 78753\u0026#39; Template Literals Template literals bring some new capabilities to JavaScript Strings.\nTemplate literals:\n are created with back quotes were introduced with ES2015 allow embedded expressions and multiline strings  Here is an example with an embedded expression:\nconst name = \u0026#34;Homer\u0026#34;; const greeting = `Hello, ${name}`; // \u0026#34;Hello, Homer\u0026#34;  You can embed any JavaScript expression by wrapping it with ${}, as in ${ yourExpressionGoesHere }`. You can do multiple expressions, such as:  const firstName = \u0026#39;Homer\u0026#39;; const middleName = \u0026#39;D\u0026#39;; const lastName = \u0026#39;Poe\u0026#39;; const fullName = `${firstName}${middleName}${lastName}`; // Homer D Poe Multi-Line Strings Template literals also support multi-line strings with ease, unlike regular string literals.\nRegular string literal:\nconsole.log(\u0026#34;I took the one less traveled by,\\nAnd that has made all the difference.\u0026#34;); Template literal:\nconsole.log( `I took the one less traveled by And that has made all the difference.` ); You can also embed spaces:\nconsole.log( `He clasps the crag with crooked hands; Close to the sun in lonely lands, Ring’d with the azure world, he stands. The wrinkled sea beneath him crawls; He watches from his mountain walls, And like a thunderbolt he falls.` ); Converting Strings to Numbers parseInt(\u0026#39;25374\u0026#39;, 10); // 25374 parseInt(\u0026#39;hello\u0026#39;, 10); // NaN  parseFloat(\u0026#39;3.14159\u0026#39;); // 3.14159  Number(\u0026#39;123.456\u0026#39;); // 123.456 Number(\u0026#39;654321\u0026#39;); // 654321 Lab See instructions here.\nSummary  You can create basic strings with single or double quotes. Strings have several properties and methods for accessing information about the string or transforming the string into a new string. You can create template literal strings with back quotes. String template literals support embedded JavaScript expressions and multiline strings.  "
},
{
	"uri": "/javascript/express/testing/",
	"title": "Testing an Express App",
	"tags": [],
	"description": "",
	"content": "  Learning Objectives  Install dependencies for jest and supertest Define testing startup scripts in package.json How to write a jest test for a set of routes  Introduction Modern tools make it easy to test RESTful APIs. In this lesson we will cover the tools jest and supertest.\n jest - a test runner and an assertion / expect library. jest also includes support for mocking and for generating test coverage reports. supertest - generates HTTP requests and provides assertion / expect matchers for verifying the responses.  Installing The Tools To install jest and supertest:\nnpm install --save-dev jest npm install --save-dev supertest Setting Up package.json scripts: The following scripts are useful to add to package.json:\npackage.json:\n\u0026#34;scripts\u0026#34;: { \u0026#34;test:watch\u0026#34;: \u0026#34;NODE_ENV=test PORT=3006 jest --runInBand --verbose --watch --unhandled-rejections=strict\u0026#34;, \u0026#34;test:ci\u0026#34;: \u0026#34;NODE_ENV=test PORT=3006 jest --runInBand --verbose --unhandled-rejections=strict\u0026#34; Observations:\n test:watch runs jest in an interactive / watch mode test:ci runs jest once and prints a report to standard out  Creating a Simple Test Before jumping into testing routes, let\u0026rsquo;s test the car service, which doesn\u0026rsquo;t have any dependencies on Express or on routing.\nCreate the test file:\ntouch src/services/car-service.test.js Then copy the following code into the test file:\nsrc/services/car-service.test.js:\n\u0026#39;use strict\u0026#39; import { expect } from \u0026#39;@jest/globals\u0026#39; import carsData from \u0026#39;./data/cars\u0026#39; import { getCars, getCarById, createCar, updateCar, deleteCar } from \u0026#39;./car-service\u0026#39; describe(\u0026#39;car service\u0026#39;, () =\u0026gt; { describe(\u0026#39;getCars\u0026#39;, () =\u0026gt; { it(\u0026#39;returns a Promise that resolves to a list of cars\u0026#39;, async () =\u0026gt; { const cars = await getCars() expect(cars.length).toEqual(carsData.length) expect(cars).toEqual(carsData) }) }) describe(\u0026#39;getCarById\u0026#39;, () =\u0026gt; { it(\u0026#39;returns a Promise that resolves to the car with the specified id\u0026#39;, async () =\u0026gt; { const car = await getCarById(2) expect(car).not.toBeNull() expect(car).not.toBeUndefined() expect(car).toEqual(carsData[1]) }) it(\u0026#39;returns a rejected Promise when it cannot find the car with the specified id\u0026#39;, async () =\u0026gt; { const id = 99 await expect(getCarById(id)).rejects.toEqual( new Error(`No car found with id ${id}`) ) }) }) describe(\u0026#39;createCar\u0026#39;, () =\u0026gt; { it(\u0026#39;creates and returns a new car\u0026#39;, async () =\u0026gt; { const newCar = { make: \u0026#39;Ford\u0026#39;, model: \u0026#39;GT\u0026#39;, color: \u0026#39;blue\u0026#39;, } const saved = await createCar(newCar) const nextId = carsData.length + 1 const expected = { ...newCar, id: nextId } expect(saved).toEqual(expected) const updatedCars = await getCars() expect(updatedCars.length).toEqual(carsData.length + 1) expect(updatedCars[updatedCars.length - 1]).toEqual(expected) }) }) describe(\u0026#39;updateCar\u0026#39;, () =\u0026gt; { it(\u0026#39;updates and returns a Car\u0026#39;, async () =\u0026gt; { const car = { ...carsData[0], color: \u0026#39;silver\u0026#39; } const updated = await updateCar(car.id, car) expect(updated).toEqual({ ...carsData[0], color: \u0026#39;silver\u0026#39; }) const cars = await getCars() const found = cars.find(t =\u0026gt; t.id === updated.id) expect(found).toEqual(updated) }) it(\u0026#39;returns a rejected Promise when it cannot find the car with the specified id\u0026#39;, async () =\u0026gt; { const id = 99 const car = { ...carsData[0], color: \u0026#39;silver\u0026#39; } await expect(updateCar(id, car)).rejects.toEqual( new Error(`No car found with id ${id}`) ) }) }) describe(\u0026#39;deleteCar\u0026#39;, () =\u0026gt; { it(\u0026#39;deletes and returns a Car\u0026#39;, async () =\u0026gt; { const id = 2 const deletedCar = await deleteCar(id) expect(deletedCar).toEqual(carsData.find(c =\u0026gt; c.id === id)) const cars = await getCars() expect(cars.length).toEqual(carsData.length) const found = cars.find(c =\u0026gt; c.id === id) expect(found).toBeUndefined() }) it(\u0026#39;returns a rejected Promise when it cannot find the car with the specified id\u0026#39;, async () =\u0026gt; { const id = 99 await expect(deleteCar(id)).rejects.toEqual( new Error(`No car found with id ${id}`) ) }) }) }) Test it out with:\nnpm run test:ci Observations:\n CarService exports 5 functions that we want to test: getCars, getCarById, createCar, updateCar, and deleteCar. We use async functions as our test handlers. The async test functions return a Promise that is resolved once the test has completed.  Testing Some Routes Let\u0026rsquo;s start testing routes by testing our simple health check route and our 404 route.\ntouch src/routes/index.test.js src/routes/index.test.js:\nimport \u0026#39;jest-extended\u0026#39; import supertest from \u0026#39;supertest\u0026#39; import startServer from \u0026#39;./start-server\u0026#39; const port = process.env.PORT || \u0026#39;3006\u0026#39; const api = supertest(`localhost:${port}`) let server beforeAll(async () =\u0026gt; { server = await startServer() }) afterAll(async () =\u0026gt; { await server.close() }) describe(\u0026#39;The Health Check Route\u0026#39;, () =\u0026gt; { it(\u0026#39;should return a 200 response with a simple message\u0026#39;, async () =\u0026gt; { try { const res = await api.get(\u0026#39;/\u0026#39;).set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;).expect(200) const message = res.body expect(message).not.toBeNull() expect(message).toEqual({ message: \u0026#39;The server is alive!\u0026#39; }) } catch (err) { console.error(err) } }) }) describe(\u0026#39;A Bad Route\u0026#39;, () =\u0026gt; { it(\u0026#39;should return a 404 response\u0026#39;, async () =\u0026gt; { try { const res = await api .get(\u0026#39;/bad/route\u0026#39;) .set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;) .expect(404) const result = res.body expect(result.message).toEqual(\u0026#39;Not Found\u0026#39;) } catch (err) { console.error(err) } }) }) Observations:\n We define a beforeAll function to start our server by calling the startServer function and await for the Promise to resolve. We define an afterAll function to close our server and await for the Promise to resolve. We have 2 describe blocks each containing ` test. The first test tests the HTTP GET / route and expects a 200 response with a simple JSON body The second test tests an unmatched route (HTTP GET /bad/route) and expects a 404 response with an error message wrapped in a JSON body  You can test this out with:\nnpm run test:ci Testing the Cars Routes Let\u0026rsquo;s create a test file to test our cars routes:\ntouch routes/cars.test.js The INDEX Route We will start with testing the INDEX route:\nroutes/cars.test.js:\ndescribe(\u0026#39;INDEX ROUTE\u0026#39;, () =\u0026gt; { it(\u0026#39;should return a 200 response and return 7 cars\u0026#39;, async () =\u0026gt; { try { const res = await api.get(\u0026#39;/\u0026#39;).set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;).expect(200) const cars = res.body expect(cars).not.toBeNull() expect(cars).toBeArray() expect(cars.length).toEqual(7) cars.forEach(car =\u0026gt; { expect(car).toHaveProperty(\u0026#39;id\u0026#39;) expect(car).toHaveProperty(\u0026#39;make\u0026#39;) expect(car).toHaveProperty(\u0026#39;model\u0026#39;) expect(car).toHaveProperty(\u0026#39;color\u0026#39;) }) } catch (err) { console.error(err) } }) }) You can test it with either npm run test:ci or npm run test:watch.\nObservations:\n We use async and await to make the HTTP request We can wrap everything in a try block res.body contains the response body that we can inspect to verify the response  The SHOW Route Next let\u0026rsquo;s test the SHOW route:\nroutes/cars.test.js:\ndescribe(\u0026#39;SHOW ROUTE\u0026#39;, () =\u0026gt; { it(\u0026#39;should return a 404 response when given an invalid id\u0026#39;, async () =\u0026gt; { try { const id = 99 const res = await api .get(`/${id}`) .set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;) .expect(404) const error = res.body expect(error).not.toBeNull() expect(error).toHaveProperty(\u0026#39;message\u0026#39;, `No car found with id ${id}`) } catch (err) { console.error(err) } }) it(\u0026#39;should return a 200 response and return a car\u0026#39;, async () =\u0026gt; { try { const res = await api.get(\u0026#39;/1\u0026#39;).set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;).expect(200) const car = res.body expect(car).not.toBeNull() expect(car).toEqual(carsData[0]) } catch (err) { console.error(err) } }) }) Observations:\n The first test expects a 404 response since the id value is invalid The second test expects a 200 response with the correct car returned  The CREATE Route Next let\u0026rsquo;s test the CREATE route:\nroutes/cars.test.js:\ndescribe(\u0026#39;CREATE ROUTE\u0026#39;, () =\u0026gt; { it(\u0026#39;should create a new car when given valid car data\u0026#39;, async () =\u0026gt; { try { const newCar = { make: \u0026#39;Ford\u0026#39;, model: \u0026#39;GT\u0026#39;, color: \u0026#39;blue\u0026#39;, } const res = await api .post(\u0026#39;/\u0026#39;) .set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;) .send(newCar) .expect(201) const saved = res.body expect(saved).not.toBeNull() expect(saved).toEqual({ ...newCar, id: 8 }) } catch (err) { console.error(err) } }) }) Observations:\n We use a post request with a new car object in the body. We expect to get a 201 with the new car assigned an id value of 8  The UPDATE Route Lab Time: See if you can complete the tests for the cars route by adding the following:\n test an UPDATE with an invalid id, expecting a 404 response test an UPDATE with a valid id, expected a 200 response with the updated car as the response body  SPOILER: SOLUTION BELOW\nSPOILER: SOLUTION BELOW\nSPOILER: SOLUTION BELOW\nSPOILER: SOLUTION BELOW\nSPOILER: SOLUTION BELOW\nSPOILER: SOLUTION BELOW\nSPOILER: SOLUTION BELOW\nBelow is the test code for the UPDATE route:\nroutes/cars.test.js:\ndescribe(\u0026#39;UPDATE ROUTE\u0026#39;, () =\u0026gt; { it(\u0026#39;should return a 404 response and when given an invalid id\u0026#39;, async () =\u0026gt; { try { const id = 99 const res = await api .put(`/${id}`) .set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;) .send({}) .expect(404) const error = res.body expect(error).not.toBeNull() expect(error).toHaveProperty(\u0026#39;message\u0026#39;, `No car found with id ${id}`) } catch (err) { console.error(err) } }) it(\u0026#39;should return a 200 response and return the updated car\u0026#39;, async () =\u0026gt; { try { const car = { ...carsData[0], color: \u0026#39;silver\u0026#39; } const res = await api .put(`/${car.id}`) .set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;) .send(car) .expect(200) const updatedCar = res.body expect(updatedCar).not.toBeNull() expect(updatedCar).toEqual({ ...carsData[0], color: \u0026#39;silver\u0026#39; }) } catch (err) { console.error(err) } }) }) Observations:\n The first test expects a 404 error because the id value is invalid The second test expects a 200 response with the updated car in the body  The DESTROY Route Lab Time: See if you can complete the tests for the cars route by adding the following:\n test a DELETE with an invalid id, expecting a 404 response test a DELETE with a valid id, expected a 200 response with the deleted car as the response body  SPOILER: SOLUTION BELOW\nSPOILER: SOLUTION BELOW\nSPOILER: SOLUTION BELOW\nSPOILER: SOLUTION BELOW\nSPOILER: SOLUTION BELOW\nSPOILER: SOLUTION BELOW\nSPOILER: SOLUTION BELOW\nBelow is the test code for the DESTROY route:\nroutes/cars.test.js:\ndescribe(\u0026#39;DESTROY ROUTE\u0026#39;, () =\u0026gt; { it(\u0026#39;should return a 404 response when given an invalid id\u0026#39;, async () =\u0026gt; { try { const id = 99 const res = await api .delete(`/${id}`) .set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;) .expect(404) const error = res.body expect(error).not.toBeNull() expect(error).toHaveProperty(\u0026#39;message\u0026#39;, `No car found with id ${id}`) } catch (err) { console.error(err) } }) it(\u0026#39;should delete the car when given a valid id\u0026#39;, async () =\u0026gt; { try { const res = await api .delete(\u0026#39;/3\u0026#39;) .set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;) .expect(200) } catch (err) { console.error(err) } }) }) Observations:\n The first test expects a 404 error because the id value is invalid The second test expects a 200 response  Summary  Testing Express apps is easy with jest and supertest. It\u0026rsquo;s helpful to have an Express startup script that returns a Promise. Use beforeAll and afterAll to startup and shutdown the server.  "
},
{
	"uri": "/react/pillars/testing/react-testing-library/rtl-routes/",
	"title": "Testing Routes",
	"tags": [],
	"description": "",
	"content": "Introduction  The react-router library provides dynamic routing for React Applications, resulting in a SPA experience for the user. We will want to write tests that verify that our routes are working.  There are 2 approaches to testing routes:\n Provide test routes and ensure that the test routes are working - this verifies that the NavLinks and other plumbing needed to interact with the routes Use an integration test to verify that the routes defined in the code under test are working as designed  We will look at both approaches in this lesson.\nTesting the Home Component The Home component is responsible for rendering:\n a welcome message a button that when clicked navigates the user to a route containing the ProductForm component  Let\u0026rsquo;s start testing these responsibilities.\nFirst create the test file:\ntouch client/src/components/home/Home.test.js Now open the file in your text editor and add the following:\nHome.test.js:\nimport React from \u0026#39;react\u0026#39; import { BrowserRouter as Router, Route } from \u0026#39;react-router-dom\u0026#39; import { screen } from \u0026#39;@testing-library/dom\u0026#39; import { render } from \u0026#39;@testing-library/react\u0026#39; import userEvent from \u0026#39;@testing-library/user-event\u0026#39; import Home from \u0026#39;./Home\u0026#39; import ProductForm from \u0026#39;./product-form/ProductForm\u0026#39; /** * Return a Router component that contains some routes for the Home and ProductForm components. */ function getHome() { return ( \u0026lt;Router\u0026gt; \u0026lt;Route exact path=\u0026#34;/\u0026#34; component={Home} /\u0026gt; \u0026lt;Route exact path=\u0026#34;/new-product-form\u0026#34; render={props =\u0026gt; { return \u0026lt;ProductForm departments={[]} addProduct={() =\u0026gt; {}} /\u0026gt; }} /\u0026gt; \u0026lt;/Router\u0026gt; ) } describe(\u0026#39;Home\u0026#39;, () =\u0026gt; { it(\u0026#39;renders without crashing\u0026#39;, () =\u0026gt; { const { container } = render(getHome()) expect(container).toBeTruthy() }) it(\u0026#39;renders a welcome message\u0026#39;, () =\u0026gt; { // test the rendering of the welcome message  render(getHome()) screen.getByText(\u0026#39;Welcome to the React Product Browser\u0026#39;) }) it(\u0026#39;renders a link to the Product Form that when clicked routes to the New Product Form\u0026#39;, () =\u0026gt; { render(getHome()) const newProductButton = screen.getByText(/Add a new Product/i) userEvent.click(newProductButton) // click the link to change routes  screen.getByText(\u0026#39;New Product Form\u0026#39;) // verify that the New Product Form route is loaded  }) }) Observations  We provided test routes via the getHome helper function To test a route, simply find and click the link that navigates to the route and then verify that something from the new route has been rendered.  Testing the App Component The App component is responsible for gluing everything together, including:\n creating an instance of the useProducts hook for managing the departments and products state and interacting with the RESTful server creating an instance of the useCart hook for managing the shopping cart state and interacting with the RESTful server creating state for the loading and updating boolean values declaring all of the routes: home, product list, cart, and new product form  The App.test.js test file should define integration tests to verify that:\n the Home route is rendered by default the ProductList route is rendered after clicking on a Navbar link the ShoppingCart route is rendered after clicking on the Cart link  Activity: Write the tests for the App Component Write the tests for the App component in the file client/src/components/app/App.test.js.\nSummary   In this lesson we looked at how to test the Home component and the App component.\n  Testing the App component effectively requires writing true integration tests as they depend on the correct behavior of the following:\n  the App component\n  the Navbar component\n  the Home component\n  the ProductList and Product components\n  the Cart component\n  "
},
{
	"uri": "/cyber-security/static-dynamic-analysis/5-triaging/",
	"title": "Triaging Scan results",
	"tags": [],
	"description": "",
	"content": "Terminology Before we begin learning about the triage process we will go over the necessary vocabulary.\nRemediation: The process of addressing a weakness in the source code of an application.\nCriticality: The estimated seriousness of a possible coding weakness. Critical High Medium Low Informational\nContext: Information not present in the source code necessary to evaluate the true criticality of a weakness and whether it is exploitable.\nDisposition: The characterization of an identified weakness’s exploitability.\nThe Triage Process Triaging is the process by which you will investigate and validate a scan result to determine if it needs remediation. Provided is a guideline to get you started triaging your scan results.\nReview the Issue: Understand what you are dealing with in a general sense.\nGather Context: Investigate the specifics of the issue and the coding and data context around it.\nDetermine: What, if any, action is needed. If inconclusive, decide\nwhat actions you will take to investigate further (e.g., consulting\nwith a colleague or relevant other team.)\nDocument: Record your conclusion and follow-up activities, if any.\nDisposition: Assign a disposition to the issue in accordance with your determination. See below for more details.\nDispositioning Disposition Characterizations   Not An Issue\n  Suspicious\n  Suspicious (Possible Third-Party Issue)\n  Exploitable\n    Not an Issue\nThe proposed issue is not a problem and cannot be exploited. Thus, no context gathering is required.\nThis must be a certainty. If there is room for doubt, do not select this characterization.\nExample: Fortify calls out a hard-coded password in the code. Yet, there is not.\n  Suspicious\nThe issue identified is technically accurate. However, after analysis it still requires additional information to verify its exploitability.\nIf after further investigation there is still doubt as to the issue’s exploitability, the proper course is to remediate out of caution.\nExample Concatenating variables into a logging command (log forging.)\n  Suspicious (Possible Third-Party Issue)\nThe issue arises in third-party code included in the scan, typically a dependency.\nNote: This characterization is not officially supported by Fortify. Select “Suspicious” and add appropriate notes.\nExample jQuery, Angular libraries, Node.js modules used in your app.\n  Whitesource\nPerforms analysis of open source and third-party libraries for known vulnerabilities (CVEs).\nChecks associated licenses for problematic terms.\nAutomatic with Fortify scans. Results are available in the Fortify SSC UI.\nDependencies must be included in the submitted payload.\n  Exploitable\nThe issue is without question exploitable and represents a vulnerability (external mitigations notwithstanding.)\nAny weakness that has been validated with live testing can be characterized as “Exploitable.”\nExample An application that accepts user input, concatenates the input to a SQL query string and processes the query without performing any input validation of the user provided values.\n    Prioritization     That’s an awful lot of issues Depending on the size, age and quality of the code, Fortify may uncover a lot of potential weaknesses.\nStart with those of Critical and High Criticality. Then, visit one category at a time.\nDisposition and Remediation are Retained If a finding is determined to be not an issue, Fortify will remember this going forward. If an issue is remediated, it will no longer appear in future scans.\nBarring changes in the coding context, in time you will address mostly new issues as they arise.\n"
},
{
	"uri": "/javascript/performance/",
	"title": "Web Performance",
	"tags": [],
	"description": "",
	"content": "Welcome to Web Performance! "
},
{
	"uri": "/react/performance/",
	"title": "Web Performance",
	"tags": [],
	"description": "",
	"content": "Welcome to Web Performance! "
},
{
	"uri": "/web-essentials/webmastery-foundations/html-forms-labs/",
	"title": "HTML Forms Labs",
	"tags": [],
	"description": "",
	"content": "Build a Basic Form Create a form that contains inputs for the following data\n LDAP Email Years with THD Password don\u0026rsquo;t enter your actual password! Work Phone     Go to buttons lesson    Form Buttons Add two buttons to your form.\n One to clear data Another to submit data  API Front End Add a view to the OM Todo API - In this lab, you will add html views to an existing API.\nStyle HTML Form Create a new project  create the HTML document create a css directory and a main stylesheet link the css and html together  Create the Body of your Document Start by building out the body of our document.\n When building with html and css, it is strongly encouraged to structure your document (with html) first, and style your document (with css) afterwards.\n  Inside the \u0026lt;body\u0026gt; of your html  create a container \u0026lt;div\u0026gt; with the id attribute of login-box   Within the login-box \u0026lt;div\u0026gt;  create another \u0026lt;div\u0026gt; with a class of left   Inside of the \u0026lsquo;left\u0026rsquo; \u0026lt;div\u0026gt;  create a top-level header that contains the text: \u0026lsquo;Create Account\u0026rsquo;    The Form Create a sign-up form.\n Create a \u0026lt;form\u0026gt; element which contains:  A class attribute titled \u0026lsquo;sign-up\u0026rsquo; An action attribute pointing to \u0026lsquo;index.html\u0026rsquo; + (the action attribute defines the location (an URL) where the form\u0026rsquo;s collected data should be sent) A method attribute with the value of \u0026lsquo;post\u0026rsquo; + The method attribute defines which HTTP method to send the data with (it can be \u0026ldquo;get\u0026rdquo; or \u0026ldquo;post\u0026rdquo;)   Within the \u0026lt;form\u0026gt;, nest 4 \u0026lt;input\u0026gt; elements  username email password password_confirmation   Nest a button (inside the \u0026lt;form\u0026gt;) with the following attributes:  A class attribute of \u0026lsquo;sign-up-button\u0026rsquo; A type attribute of \u0026lsquo;submit\u0026rsquo;   Close out your \u0026lsquo;left\u0026rsquo; \u0026lt;div\u0026gt;  hint: You may want to check out the Mozilla or W3 documentation on how to create a form\nOnce complete, your index.html page should look something like this: The other buttons  Create a \u0026lt;div\u0026gt; with a class attribute of \u0026lsquo;right\u0026rsquo; Inside of the \u0026lsquo;right\u0026rsquo; \u0026lt;div\u0026gt;  Nest a \u0026lt;span\u0026gt; with the class attribute of \u0026lsquo;log-in-with\u0026rsquo; Inside the \u0026lt;span\u0026gt; put the text: \u0026lsquo;Sign in with Social Network\u0026rsquo;   Create 3 \u0026lt;button\u0026gt; elements with:  class attributes of \u0026ldquo;social-signin\u0026rdquo;   Select the top \u0026lt;button\u0026gt;and  Assign a class attribute of \u0026lsquo;facebook\u0026rsquo; Include the text: \u0026lsquo;Log in with facebook\u0026rsquo;   Do the same thing for Twitter and Google+ close out the \u0026lsquo;right\u0026rsquo; \u0026lt;div\u0026gt;  The Result: Or Create a \u0026lt;div\u0026gt; with the class attribute of \u0026ldquo;or\u0026rdquo; and the inner-text \u0026lsquo;OR\u0026rsquo;\n\u0026lt;div class=\u0026#34;or\u0026#34;\u0026gt;OR\u0026lt;/div\u0026gt; At this point, your webpage should look like this: Now that we have completed the structure of our html document, all that\u0026rsquo;s left is to add some style!\nCSS Normalize A.K.A. - Browser Reset Okay, so first things first. We need to get rid of this awful default browser styling\nLet\u0026rsquo;s Normalize!  Go to the site above and download the file Create a new stylesheet and paste in the contents of normalize.css link the stylesheet to your index.html page  Before and After: Setting up the Body Start by using the * selector to apply border-box to the all of the elements.\n* { box-sizing: border-box; } So, what does the above code do? Well, according to learnlayout.com:\n When you set box-sizing: border-box; on an element, the padding and border of that element no longer increase its width.\nThis is incredibly helpful as it removes unexpected layout issues.\n Next we\u0026rsquo;ll work on the body.\ncolors!  Give the body a background color of #DDD Give the text a color of #222  Result: While we\u0026rsquo;re at it, let\u0026rsquo;s go ahead and select a font (I\u0026rsquo;ve already picked out Noto Sans, but feel free to experiment)\nRight below your * selector apply the following:\n@import url(https://fonts.googleapis.com/css?family=Noto+Sans|Comfortaa:400,300,700); After completing the above challenge, add the following to your body declaration:\nfont-family: \u0026#39;Noto Sans\u0026#39;, sans-serif; font-weight: 300; Here\u0026rsquo;s how it will look on the web: That should take care of the body. Next up, positioning!\nPositioning The Login-Box - part 1  Start by giving the login-box a relative position Apply a margin of  5% on the top/bottom auto on the left/right   Give the box a background-color of #FFF  The Result you\u0026rsquo;re looking for: Great! Even though, it doesn\u0026rsquo;t look like much happened. The good news is that our Login Box is responding.\nThe Login-Box - Part 2 Now all we need to do is set a width and height (and give it some style)\n Set a width of 600px Set a height of 400px Refresh your browser and make sure the box is still responding Assign a border-radius of 2px Add some box-shadow and assign the following values:  horizontal shadow of: 0 vertical shadow of: 2px blur of: 4px color of: rgba(0,0,0,0.4)    (hint: you may find http://www.w3schools.com/cssref/css3_pr_box-shadow.asp[this] helpful for box-shadow)\nThe Result: Ahhh much better. Now we can start focusing on the right and left \u0026lt;div\u0026gt; \u0026rsquo;s\nPosition the div\u0026rsquo;s Position the left \u0026lt;div\u0026gt;   Give the \u0026lt;div\u0026gt; some padding, height and width\n padding of: 40px width of: 300px height of: 400px    Refresh your browser You\u0026rsquo;ll probably get something like this:   Now, give the left div an absolute position\n Place it at at the top/left of it\u0026rsquo;s parent \u0026lt;div\u0026gt;     You\u0026rsquo;ll notice all sorts of weirdness happening with the right div. This is normal, and will be fixed shortly.\n Position the right \u0026lt;div\u0026gt;  Apply the same attributes from the left \u0026lt;div\u0026gt;, to the right \u0026lt;div\u0026gt; with one exception\u0026hellip; + Position this \u0026lt;div\u0026gt; at the top right of it\u0026rsquo;s parent \u0026lt;div\u0026gt; (instead of the top left  Thankfully, we can reuse a good bit of the code from our left \u0026lt;div\u0026gt;. yay!.\nWhat kind of refactoring could be done?\nThe Result: Let\u0026rsquo;s go ahead and throw in our background picture while we\u0026rsquo;re here. In your .right declaration (under right: 0;) paste the following code:\n.right { right: 0; background: url(\u0026#39;http://go/hwdCa\u0026#39;); background-size: cover; background-position: center; border-radius: 0 2px 2px 0; } Refresh and take a deep breath. We\u0026rsquo;re getting close!\nStyle the .left Let\u0026rsquo;s go ahead and knock out the styling on our left \u0026lt;div\u0026gt;\nWe\u0026rsquo;ll start with the \u0026lt;h1\u0026gt;\nType the following code in your stylesheet:\nh1 { margin: 0 0 20px 0; font-weight: 300; font-size: 2em; } Refresh if you want to see the change\nsign-up form inputs   Let\u0026rsquo;s start by removing that border\n  Now apply a border to only the bottom.\n give it a 1px solid bottom-border give it the color #AAA    Give each input a display of block\n  Refresh   Now, apply some margin and padding to make it look pretty\n Separate the inputs by adding a bottom margin of 20px add about 4px of padding    Refresh\n  Add some height and width\u0026hellip;\n height of 32px width of 220px    Make the font a little stronger by giving it a weight of 400\n  The Result: Cool, things are starting to look decent. Let\u0026rsquo;s go ahead and work on the button next.\nThe Sign Me Up Button  Properly apply spacing and width/height  give a top and bottom margin of 5px a width of 220px a height of 32px   While we\u0026rsquo;re at it, go ahead and remove the border give it a border-radius of 2px Apply some color!  give the background a color of #16A085 set the text color to #FFF   Finally, set the transform-text property to uppercase, and the font-weight to 400  The Result:\nHere\u0026rsquo;s what you should have so far.\nWe also want to give the button some hover effects to call the user to action.\nHover   Using the :hover pseudo selector\n Set the opacity to 0.8 give a box-shadow of: 0 2px 4px rgba(0, 0, 0, 0.4) set the transition property to 0.1s ease    Refresh and check it out\n  Now use the :active pseudo selector to:\n apply an opacity of 1 and a box-shadow of 0 1px 2px rgba(0, 0, 0, 0.4)    Let\u0026rsquo;s put the finishing touches on this side\u0026hellip;\nFocus Using a :focus pseudo selector, apply the following code to input:\nborder-bottom: 2px solid #16a085; color: #16a085; transition: 0.2s ease; Once complete, you\u0026rsquo;ll want to modify focus on the entire document.\nPlace the following code near the top of your stylesheet\n*:focus { outline: none; } Styling the .right style the \u0026lt;span\u0026gt;  Set the display of your \u0026lsquo;log-in-with\u0026rsquo; class to block Give it a margin bottom of 40px Assign a font-size of 2em Give a color of #FFF Center the text  This is what you\u0026rsquo;re looking for: Got it! Awesome, now let\u0026rsquo;s style those buttons.\nStyle ALL buttons  give a margin bottom of 20px width of 220px height of 36px remove the border give a border-radius of 2px set the text color to #FFF  The Result: You may notice some code duplication. Let\u0026rsquo;s go ahead and refactor\nRefactor the buttons  Group the buttons (from your left and right \u0026lt;div\u0026gt;'s together in your css Refresh and make sure everything looks good Refactor the code duplication  Add some color to the right buttons  Apply the following background colors  for the facebook class: #32508E twitter class: #55ACEE google class: #DD4B39   Refresh!  The Result: OR We\u0026rsquo;re close to the end. Let\u0026rsquo;s style that \u0026lsquo;or\u0026rsquo; div\n Give a position of absolute set it to:  180px from top 280px from left   Assign a width of 40px Give a height of 40px Refresh!  Okay, not exactly what we\u0026rsquo;re looking for. Now try this:\nChallenge 20\n Set the background to #DDD give a border-radius of 50% center the text set a line-height of 40px declare a box-shadow of 0 2px 4px rgba(0, 0, 0, 0.4)  Refresh and enjoy the fruits of your labor\u0026hellip; Which should look something like this:\nAdditional Resources  Mozilla - The Input Element W3schools Input Tag Interneting is Hard - Forms Marksheet - HTML Forms  "
},
{
	"uri": "/golang/testing/testing-techniques/",
	"title": "Testing Techniques",
	"tags": [],
	"description": "",
	"content": "Goals To delve into techniques that are considered standard in the Go community.\nLearning Objectives  Comparing Types and Collections Dependency Injection in Go   Comparing Types and Collections When comparing two types we have to keep in mind that Go is pass by value. We also tend to create our expected outputs as completely separate instances of the returned value we are testing against. Often time these types tend to be a complex type, such as a struct, slice, or map, where we want to deeply validate the values of the types.\nFor a struct, you validate each field is correct by having an assert for each field. A slice or map you could loop over and validate that each element is the expected element. This method ends up becoming noisy and overly complex. Instead, we can use the reflect package to compare two complex types for deep equality.\nreflect's deep equal function Deep equality typically means there are several levels checked to determine equality. The following table shows the criteria for being considered deeply equal:\n   Data Structure Deeply Equal When\u0026hellip;     Array corresponding elements are deeply equal   Struct corresponding fields, are deeply equal   Func both are nil   Interface hold deeply equal concrete values   Map all of the following are true: they are both nil or both non-nil they have the same lengththey are the same map object or their corresponding keys (matched using Go equality) map to deeply equal values   Pointer they are equal using Go’s == operator or if they point to deeply equal values.   Slice all of the following are true: they are both nil or both non-nil they have the same lengththey point to the same initial entry of the same underlying array (that is, \u0026amp;x[0] == \u0026amp;y[0]) or their corresponding elements (up to length) are deeply equal.    We can use the reflect package\u0026rsquo;s DeepEqual function to compare the equality of two complex types. The example below demonstrates this:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { expected := []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;z\u0026#34;} result := reflect.DeepEqual(thingUnderTest(\u0026#34;z\u0026#34;), expected) fmt.Println(result) } func thingUnderTest(a string) []string { return []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, a} } DeepEqual will check to ensure that all elements and/or fields values equal the other.\nIn a test method this would look something like\nfunc TestThingUnderTest(t *testing.T) { expected := []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;b\u0026#34;} if !reflect.DeepEqual(thingUnderTest(\u0026#34;z\u0026#34;), expected) { t.Error(\u0026#34;Things do not match!\u0026#34;) } } Would the above pass or fail?\nModifying the function under test, we can also see that this works with maps and stcucts as well\nfunc ThingUnderTest(a string) (Thing, map[string]string) { return Thing{}, map[string]string{\u0026#34;a\u0026#34;: \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;: \u0026#34;B\u0026#34;, \u0026#34;c\u0026#34;: \u0026#34;c\u0026#34;} } func TestThingUnderTest(t *testing.T) { expected1 := Thing{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;} expected2 := map[string]string{\u0026#34;a\u0026#34;: \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;: \u0026#34;B\u0026#34;, \u0026#34;c\u0026#34;: \u0026#34;c\u0026#34;} actual1, actual2 := ThingUnderTest(\u0026#34;z\u0026#34;) if !reflect.DeepEqual(actual1, expected1) { t.Error(\u0026#34;Things do not match!\u0026#34;) } if !reflect.DeepEqual(actual2, expected2) { t.Error(\u0026#34;Things do not match!\u0026#34;) } } Note You can compare 2 structs, but often times your stucts are made up of other more complex types that you\u0026rsquo;ll want to check for deep equality on.\nThe built in testing functionality is great, but we can clean this up using packages such as testify/assert. The testify/assert package heavily utilize a lot of other reflect functions in comparison, but for the most common assertions of complex types developers tend to be looking for deep equality.\nAll the Equal type functions will use a DeepEqual to determine equality of two types. If you look at the functions themselves they do a lot more because they allow for an empty interface interface{} to be passed to it.\nUsing testify/assert to check for Deep Equality The assertion functions implement a lot of the checks we would create ourselves.\nfunc TestThingUnderTest(t *testing.T) { expected := []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;b\u0026#34;} actual:= ThingUnderTest(\u0026#34;z\u0026#34;), expected) assert.Equal(t,expected,actual) } This gives us more cleanly worded test.\n Dependency Injection in Go Dependency injection is a common programming pattern where external dependencies are required as inputs rather than being created within the function or method. Injecting dependencies allows for more module and testable code. In unit testing, we don\u0026rsquo;t want to have to rely on external dependencies, such as other services or database calls.\nIf we separate the logic that makes the calls to these from the logic of the functions that need to do something with the results, we can advertise in the signatures that we need the external dependency and configure it specifically for the test.\nIn go, this is where interfaces become really useful. These calls external dependencies should be set up as interfaces rather than concrete implementations. For testing, this allows us to create mocks and stubs of our dependencies and allows us to focus on just the unit.\nLet\u0026rsquo;s look at an example to help us understand this better.\nThe following code will print out the contents of https://homedepot.com\npackage dependency_injection import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; ) // Do a get on a url.  func main() { err := send(\u0026#34;http://homedepot.com\u0026#34;) if err != nil { panic(err) } } func send(link string) error { client := http.Client{} response, err := client.Get(link) if err != nil { return err } if response == nil { return errors.New(\u0026#34;Received No Response.\u0026#34;) } body, err := ioutil.ReadAll(response.Body) if err != nil { return err } fmt.Println(string(body)) return nil } If we want to test the above code, we\u0026rsquo;ll need to reach out to the real world wide web and have internet access on our testing server/local machine. Not a problem, most computers do.\nHowever, let\u0026rsquo;s assume that in hitting your production api, you\u0026rsquo;re making actual changes to the app in production. If we set this endpoint to a local or non-production resource, we are not really doing a unit test, and we can\u0026rsquo;t have that.\nSo what\u0026rsquo;s the answer? No testing? Nope. The answer is Dependency Injection, my friend.\nIf we were to instead accept an interface into our send function, we could easily mock a HTTP Client.\ntype HttpClient interface { Get(string) (*http.Response, error) } func main(){ client := \u0026amp;http.Client{} err := send(client, \u0026#34;https://homedepot.com\u0026#34;) if err != nil{ panic(err) } } func send(client HttpClient, link string) error { response, err := client.get(link) // ... and the rest would remain the same. \tif err != nil { return err } if response == nil { return errors.New(\u0026#34;Received No Response.\u0026#34;) } body, err := ioutil.ReadAll(response.Body) if err != nil { return err } fmt.Println(string(body)) return nil } Now that we\u0026rsquo;ve injected our http client dependency we can easily mock it, in our test.\npackage main import ( \u0026#34;bytes\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;testing\u0026#34; ) type MockHttpClient struct {} func (m *MockHttpClient) Get(url string) (*http.Response, error) { response := \u0026amp;http.Response{ Body: ioutil.NopCloser(bytes.NewBuffer([]byte(\u0026#34;Test Response\u0026#34;))), } return response, nil } func TestSendWithValidResponse(t *testing.T) { httpClient := \u0026amp;MockHttpClient{} err := send(httpClient, \u0026#34;https://homedepot.com\u0026#34;) if err != nil { t.Errorf(\u0026#34;Shouldn\u0026#39;t have received an error with a valid MockHttpClient, got %s\u0026#34;, err) } } Lab Setup\n If you have not already, Fork https://github.homedepot.com/om-labs/go-testing to your homedepot profile Clone down your newly forked repo cd into the go-testing/testing-techniques directory Follow the instructions found in the README  Conclusion There are many other approaches to testing based on what you are testing. We\u0026rsquo;ve covered the most common cases you will see in this section. By combining these techniques and patterns together, we can create clean, well written tests in go. It also guides us in writing reusable, modular, and well documented code.\n"
},
{
	"uri": "/golang/foundations/array-slice-map/",
	"title": "Array, Slices and Maps",
	"tags": [],
	"description": "",
	"content": "Go Collections: Arrays, Slices and Maps Learning Objectives Concepts  Creating and using  Arrays Slices Maps   Using range to loop over arrays, slices and maps  Arrays  Have fixed size collection of elements of the same type. Elements can be any type  Array Syntax [size]type or [size as int]type{comma separated literals} Examples:\n Example 1: [6]string string array with a size of 6 Example 2: [5]int{1,2,3,4,5} int array with a size of 5, and default values. Example 3: […​]int{1,2,3,4,5} The same as example 2, except the size will be determined based on the number of initial elements. In this case, 5.  Other Characteristics of Arrays:  Arrays can be declared with the same rules as any variable. An array\u0026rsquo;s element type cannot change An array\u0026rsquo;s size cannot change  Array Declaration: An example of declaring an array\ndogs := [4]string{}  The above will create an empty array, that can hold up to 4 strings and assign it to the variable dogs.  Indexes  An index simply means the position a value is in. The first element in an array is always at index 0 increments by one for each item in the array.  To visualize this, imagine the following table is a representation of our dogs array:\n   Index: 0 1 2 3     Elements: \u0026quot;\u0026rdquo; \u0026quot;\u0026rdquo; \u0026quot;\u0026rdquo; \u0026quot;\u0026rdquo;    Assigning Values Assigning Specific Values  Provide the index to the variable Provide the value to the right of = as with any other variable  Assigning Values by Index\ndogs[0] = \u0026#34;German Shepard\u0026#34; // First position,index 0 dogs[3] = \u0026#34;Boxer\u0026#34; // Last position, index 3 This would change our table example to:\n   Index: 0 1 2 3     Elements: \u0026ldquo;German Shepard\u0026rdquo; \u0026quot;\u0026rdquo; \u0026quot;\u0026rdquo; \u0026ldquo;Boxer\u0026rdquo;    Initializing Arrays With Values The dogs Array Initialized With Literals\ndogs := [4]string{\u0026#34;Collie\u0026#34;, \u0026#34;Labrador\u0026#34;, \u0026#34;German Shepard\u0026#34;, \u0026#34;Dalmatian\u0026#34;}    Index: 0 1 2 3     Elements: \u0026ldquo;Collie\u0026rdquo; \u0026ldquo;Labrador\u0026rdquo; \u0026ldquo;German Shepard\u0026rdquo; \u0026ldquo;Dalmatian\u0026rdquo;    Reading Values To read a value from an array you need to reference the index of the element you want to read the value of.\nSimple Read and Print:\ndogs := [4]string{\u0026#34;Collie\u0026#34;, \u0026#34;Labrador\u0026#34;, \u0026#34;German Shepard\u0026#34;, \u0026#34;Dalmatian\u0026#34;} fmt.Println(dogs[2]) // Would print German Shepard Variable Assignment Use Case:\nUsing the value of an array to declare a new string\ndogs := [4]string{\u0026#34;Collie\u0026#34;, \u0026#34;Labrador\u0026#34;, \u0026#34;German Shepard\u0026#34;, \u0026#34;Dalmatian\u0026#34;} dog := dogs[2] Determining a Collection Use the built-in len() function you need to determine the size of:\n  Array\n  Slice\n  Map\n  The return value of len() is an int\n  See each section for examples of using len() with the specific collection.\n  Getting the length of our dogs Array:\ndogs := [4]string{\u0026#34;Collie\u0026#34;, \u0026#34;Labrador\u0026#34;, \u0026#34;German Shepard\u0026#34;, \u0026#34;Dalmatian\u0026#34;} size := len(dogs)  In this example, size is assigned an int value of 4.  Quick Quiz Given the following array:\nnumbers := [4]int{1, 2}  What type are the elements of this array? Without using len(), what size is the size of the numbers array? What is the value of the element at numbers[3]?  Slices Slices are:\n Look and get defined similarly to Arrays Can grow in size One of the types that get passed by reference by default  Basic Slice Declaration dogs := []string{\u0026#34;Collie\u0026#34;, \u0026#34;Labrador\u0026#34;, \u0026#34;German Shepard\u0026#34;, \u0026#34;Dalmatian\u0026#34;}  A slice is not defined with the number of elements as part of its type The initial size will be the size of elements provide in the {}  Reading and Writing to Slices: dogs[0] = \u0026#34;Boxer\u0026#34; pet := dogs[1]  Changes the value of the element at index 0 to \u0026quot;Boxer\u0026quot; Assigns the value Labrador to the new pet variable  Creating a slice from an Array or Another Slice To create a slice from an array you can use the [low:high] expression:\nWhat low and high mean  low: the lowest index you want to start at. In this case, index 1. High: the highest index you want to stop at, but not include. You can think of the high index as the value at index high - 1 High can also be the length of the array.  Using the [low:high] expression arr := [5]string{\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;,\u0026#34;d\u0026#34;,\u0026#34;e\u0026#34;} x := arr[1:3]  x now is a slice with [\u0026ldquo;b\u0026rdquo;,\u0026ldquo;c\u0026rdquo;]  How it works\nLets use the following table to explore how that works:\n   Index 0 1 2 3 4     Elements a b c d e   low:hi  1  3    Return  b c      Methods to copy an entire array or slice:\narr := [5]string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;} verbose := arr[0:len(arr)] exact := arr[0:5] omitlow := arr[:5] omithi := arr[0:] omitboth := arr[:] Try Me!\n verbose: Using the starting index of 0 as low and the length of the array as high exact: Using the starting index of 0 as low and the literal 5 as high omitlow: Omitting low and the literal 5 as high omithi: Using the starting index of 0 as low and omitting high omitboth: Omitting both high and low  Sizing empty slices: Introducing make() Why? mySlice := []string{}  Empty slice Has no zero value Forced to resize right away ( see copy and append below) Attempting to access would cause a fatal error  Creating a sized empty slice\nmySlice := make([]string,10) This creates and empty slice, with 10 string type elements.\nChallenge Given the String variable \u0026#34;challenge\u0026#34; Then the numbers \u0026#34;3456\u0026#34; should be extracted as a string And printed to the console Hint:\n A string is a slice of bytes When accessing it, the value will be a uint A byte can cast back to a string by using string(byte)  Try Me!\nSlice Functions You can grow a slice using one of the two built-in functions:\n append copy  append() The append() built-in will allow you to grow a slice by adding elements:\nSyntax\nname = append(originalSlice, value1, value2...) Append Examples\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { slice1 := []int{1, 2, 3} // Append 1 or more individual elements to the slice \tslice1 = append(slice1, 4, 5) fmt.Println(slice1) slice2 := []int{6, 7, 8, 9} //Append combine 2 slices \tslice1 = append(slice1, slice2...) fmt.Println(slice1) slice3 := []int{5, 2, 3, 10, 11, 12, 0} //Select specific elements in a slice to append \tslice1 = append(slice1, slice3[3:6]...) fmt.Println(slice1) } Try Me!\n ... is the spread operator and allows you to \u0026ldquo;spread\u0026rdquo; the values of a slice into into a variadic function  Append Best Practices:  The result of append should be assigned to the same variable name If a new variable is needed with a larger size, use copy  As this example demonstrates, you can get unexpected results from appending to a new slice. This goes into detail on why\nUsing copy() Use copy when you want to create new variable with the contents of the original slice\nCopy to a larger slice\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { slice1 := []int{1, 2, 3} slice2 := make([]int, 6) copy(slice2, slice1) fmt.Println(slice2) } Try Me!\nCopy to a Smaller Slice  You can copy a larger slice into a smaller slice Values that do not fit get dropped  Dropping elements as a result of a copy to a smaller slice:\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { slice1 := []int{1, 2, 3, 4, 5, 6} slice2 := make([]int, 2) copy(slice2, slice1) fmt.Println(slice2) } Try Me!\nFurther Reading on Arrays and Slices Here is a great write up and additional examples for some deeper dives into Arrays and Slices\nLab 1: Arrays and Slices Follow the instructions in the readme for the lab 1 Arrays and Slices\nMaps  Key/Value Collection Keys can be defined as any comparable type Keys are unique identifiers value can be any type Maps are a pass by reference type Maps do not need to be sized  Using Maps Syntax for declaring a map:\nmap[\u0026lt;key_type\u0026gt;]\u0026lt;value_type\u0026gt;  The \u0026lt;key_type\u0026gt; inside if the [] will determine the type of the key used to access the value The \u0026lt;value_type\u0026gt; following the ] will determine the the type of the value for that element.  Creating Maps Using Make Initialize and use empty map\nm := make(map[string]float64) // Declare `m` to be a `map` that has a key type  // of `string` and a value type of `float64`. m[\u0026#34;somekey\u0026#34;] = 1.2 // Create keys using literal strings, and assign values m[\u0026#34;anotherkey\u0026#34;] = 3.4 Always Initialize Your Maps Go will allow you to compile if your map is nil.\nThis will cause a runtime (nil pointer) error:\nvar m map[string]int m[\u0026#34;somekey\u0026#34;] = 1 Initialize a Map With Values Creating a Map with Initial Values:\nm := map[string]int{ \u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, } fmt.Println(m[\u0026#34;a\u0026#34;])  You\u0026rsquo;ll notice that there is a trailing comma on the final element. This is required even if there is not another key/value pair. You do not have to define the key/values on separate lines  Reading from map You can read from a map like you would read from an array except that you use the key where you\u0026rsquo;d specify the index in the array.\nm := make(map[string]float64)) m[\u0026#34;somekey\u0026#34;] = 1.2 m[\u0026#34;anotherkey\u0026#34;] = 3.4 d := m[\u0026#34;anotherkey\u0026#34;] fmt.Println(m[\u0026#34;somekey\u0026#34;]) Accessing a map with a key returns 2 values:\n The value found at the key, or the zero value of the defined type if the key is not found. A bool value representing weather or not the key exists or not  Determining valid Keys Supply 2 variables when accessing the map will allow you to check if the key is valid or not:\nv, ok := mymap[\u0026#34;key\u0026#34;] Use Case: You check the bool value because:\n The value will always be the zero value of the type The zero value may be a \u0026ldquo;good\u0026rdquo; value  // if the key is there, print the value if v, ok := mymap[\u0026#34;key\u0026#34;]; ok { fmt.Println(v) } Deleting a key Syntax:\ndelete(map,key) Example of deleting a key\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { m := map[string]float64{ \u0026#34;somekey\u0026#34;: 1.2, \u0026#34;anotherkey\u0026#34;: 3.4, } delete(m, \u0026#34;anotherkey\u0026#34;) if _, ok := m[\u0026#34;anotherkey\u0026#34;]; !ok { fmt.Println(\u0026#34;The key was deleted\u0026#34;) } } Try Me!\nFinding the length of a map As with arrays and slices, you can use the len() function to determine the size of a map.\nm := map[string]float64{ \u0026#34;somekey\u0026#34;: 1.2, \u0026#34;anotherkey\u0026#34;: 3.4, } mapLength := len(m) Lab 2 Maps  Follow the instructions in the readme for the lab2 maps  Range and Looping You can loop over the contents of an iterable:\n Using a traditional for loop based on the length of the iterable Using the keyword range to automatically access the index/key and values of the iterable and automatically terminate the loop  Traditional Looping: package main import ( \u0026#34;fmt\u0026#34; ) func main() { array := [5]int{1, 2, 3, 4, 5} slice := array[:] fmt.Printf(\u0026#34;\\nArray Loop\\n\u0026#34;) for i := 0; i \u0026lt; len(array); i++ { fmt.Println(array[i]) } fmt.Printf(\u0026#34;\\nSlice Loop\\n\u0026#34;) for i := 0; i \u0026lt; len(slice); i++ { fmt.Println(slice[i]) } fmt.Printf(\u0026#34;\\nReverse\\n\u0026#34;) for i := len(slice) - 1; i \u0026gt;= 0; i-- { fmt.Println(slice[i]) } } Try Me!\nRange Looping over iterables with range\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { m := map[string]float64{ \u0026#34;somekey\u0026#34;: 1.2, \u0026#34;anotherkey\u0026#34;: 3.4, } fmt.Printf(\u0026#34;\\nRange with map\\n\u0026#34;) for key, value := range m { fmt.Println(value, key) } slice := []int{1, 2, 3, 4} fmt.Printf(\u0026#34;\\nRange with map/slice\\n\u0026#34;) for index, value := range slice { fmt.Println(value, index) } } Try Me!\nRange, Runes and Strings x := \u0026#34;Hello, 世界\u0026#34;[0] fmt.Println(\u0026#34;The byte at position 0 is\u0026#34;, x) fmt.Println(\u0026#34;The character at position 0 is\u0026#34;, string(x)) Try Me!\nWhen range is used to to iterate over a string:\n you get a rune value rather than a byte. allow you to handle special characters in the string  Example:\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { x := \u0026#34;Hello, 世界\u0026#34; for i, v := range x { fmt.Println() fmt.Println(\u0026#34;Rune:\u0026#34;, v, string(v)) fmt.Println(\u0026#34;Byte:\u0026#34;, x[i], string(v)) } } Try Me!\nCheck out this page for a bit deeper understanding of why this is.\nLab 3 Range, Slice, and Maps Setup  Follow the instructions in the readme for the collections lab 3  "
},
{
	"uri": "/javascript/foundations/arrays/",
	"title": "Arrays",
	"tags": [],
	"description": "",
	"content": "Objectives  Declare an Array in JavaScript Access elements in an Array Use push and pop to add and remove elements from an Array Use shift and unshift to add and remove elements from an Array Use splice and slice to access and manipulate sections of an Array  What Are Arrays?  An array gives us a simple way of encapsulating a collection of values into a single object. Think of an array as a container that holds multiple values. The values are in a specific order. The values can be accessed by their position (index value) in the array. You can add and remove values from the Array.  How to Create Arrays There are several ways to instantiate (create) an array.\n// creating an empty array const colors = []; // alternative syntax for creating an empty array using a constructor const colors = new Array(); // creating an array with some values const colors = [\u0026#34;red\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;blue\u0026#34;]; Notice that arrays are declared using the square brackets notation, as in [1, 2, 3].\nAccessing Data in an Array  To get values out of an array, use the index value. The index is an integer from 0 to the length of the array minus 1  NOTE: In most modern programming languages, including JavaScript, arrays are indexed starting with zero!\nExample:\n// create an array of colors const colors = [\u0026#34;red\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;blue\u0026#34;]; const first = colors[0]; // index 0 specifies the first value = \u0026#34;red\u0026#34; const second = colors[1]; // index 1 specifies the second value = \u0026#34;green\u0026#34; const third = colors[2]; // index 2 specifies the third value, \u0026#34;blue\u0026#34; Getting the Number of Elements If you want to see the number of elements within an array, you can use length.\n// create an array of colors const colors = [\u0026#34;red\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;blue\u0026#34;]; const num = colors.length; console.log(num); // 3 Array Methods Array methods are operations that can be performed on an Array. These methods give us the ability to:\n modify (mutate) the original array perform a one-time operation with data inside the array get specific information about the array create a modified copy of the array  Methods that Mutate JavaScript Array methods that modify the array in place include methods that push/pop, unshift/shift, and splice.\nExample:\nconst colors = [\u0026#34;red\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;blue\u0026#34;]; colors.push(\u0026#34;yellow\u0026#34;); // adds \u0026#34;yellow\u0026#34; to the end of the array colors.pop(); // removes the last value from the end of the array colors.unshift(\u0026#34;purple\u0026#34;); // adds \u0026#34;purple\u0026#34; to the beginning of the array colors.shift(); // removes the first value from the beginning of the array  // `splice()` adds and removes array items at any position colors.splice(1, 2, \u0026#34;purple\u0026#34;); // removes the second and third values and adds \u0026#34;purple\u0026#34; (at index 1)  // Can you guess what the value of `colors` is now? More on .splice() Here is the syntax for using splice:\nsplice(index, howmany, item1, ..., itemN) where:\n index — Required. This must be an integer that specifies at what position to add/remove items. Use negative values to specify the position from the end of the array. howmany — Required. The number of items to be removed. If set to 0, no items will be removed. item1, ..., itemN — Optional. The new item(s) to be added to the array at index splice() returns an array of the items that were removed.  More Methods that Mutate A few more methods that mutate are shown below:\nconst array = [\u0026#39;apple\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;banana\u0026#39;]; array.reverse(); // Reverses the order of the elements of an array console.log(array); // [\u0026#39;banana\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;apple\u0026#39;]  array.sort(); // Sorts the elements of an array in place and returns the array. console.log(array); // [\u0026#39;apple\u0026#39;, \u0026#39;banana\u0026#39;, \u0026#39;orange\u0026#39;] Methods that Do Not Mutate Some Array methods that do not mutate but simply return a value (which may be an array or any other data type) are shown below:\n// Extract a section of an array and return it as a new array const slicedArray = array.slice(start, end); // Combine two arrays and return the new array. const combinedArray = array.concat(arr1, arr2); // Takes a function that filters each value in the array const filteredArray = array.filter(filterFunction); // Map each value to a new value using the provided callback const transformedArray = array.map(mappingFunction); // Locate the index of a specific value. array.indexOf(someValue); // tests that all elements in the array match a condition. array.every(conditionFunction); // tests that at least one element in the array matches a condition. array.some(conditionFunction); // Joins all elements of an array into a string. array.join(); // Converts an array into a string. array.toString(); Here are some examples showing how to use these methods:\nmySlice = array.slice(1,3); // [2,3] myBiggerSlice = array.slice(1); // [2,3,4]  let arr1 = [\u0026#39;abc\u0026#39;, \u0026#39;def\u0026#39;]; let arr2 = [\u0026#39;123\u0026#39;, \u0026#39;456\u0026#39;]; let both = arr1.concat(arr2); // [ \u0026#39;abc\u0026#39;, \u0026#39;def\u0026#39;, \u0026#39;123\u0026#39;, \u0026#39;456\u0026#39; ]  const ages = [32, 6, 13, 45]; const adults = ages.filter(function(age){ return age \u0026gt;= 18; }; // [32, 45]  const numbers = [4, 9, 16]; const sqroots = numbers.map(Math.sqrt); // [2, 3, 4]  const allEven = numbers.every(v =\u0026gt; v % 2 === 0); // false const someEven = numbers.some(v =\u0026gt; v % 2 === 0); // true  const numbersString = numbers.join(); // \u0026#39;4,9,16\u0026#39; const anotherNumbersString = numbers.join(\u0026#39; \u0026amp; \u0026#39;); // \u0026#39;4 \u0026amp; 9 \u0026amp; 16\u0026#39; TIP: You can see additional details and examples of all of these methods and more at MDN\u0026rsquo;s Documentation on Arrays.\nLab See instructions here.\nSummary  We can use arrays to store several values inside a single variable. Arrays store values in a specific order. The values inside an array are indexed starting with an index of zero. We can add values to an array using push and unshift. We can remove values from an array using pop and shift. We can also use splice to add and/or remove values in an array. There are several immutable Array methods, such as slice, indexOf, filter, map, and join.  "
},
{
	"uri": "/software-eng-essentials/command-line-bash/",
	"title": "Command line and Bash Scripting",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/react/foundations/component-state/",
	"title": "Component State",
	"tags": [],
	"description": "",
	"content": "How React components manage state.\nConcepts  Understand React\u0026rsquo;s Uni-Directional Data Flow Describe how React updates the view without mutating state variables Use the useState hook to manage component state Compare State vs. Props and when to use each  Skills  Write a React component that manages state changes Pass a container component\u0026rsquo;s state to a child component via the child\u0026rsquo;s props Build a react application in a modular fashion  Stateful Components As we have mentioned in prior lessons, there are two types of React components:\n Container Components:  Have state (and may have props as well) Often have one or more child components Often pass parts of their state to child components via props   Presentational Components:  Do not have state Receive data and/or callbacks via props passed from parent    Let\u0026rsquo;s look at a simple example of a Presentational Component and a Container Component:\n Person.js - a Presentational (stateless) Component:\nimport React from \u0026#39;react\u0026#39; function Person({ name, hobbies }) { // Presentation component with props `name` and `hobbies`  const hobbiesList = hobbies.map(h =\u0026gt; \u0026lt;li\u0026gt;{h}\u0026lt;/li\u0026gt;) // Convert each hobby to a `\u0026lt;li\u0026gt;` for rendering  return ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Hello {name}!\u0026lt;/h1\u0026gt; {/* Render the `name` prop */} \u0026lt;ul\u0026gt; {hobbiesList} {/* Render the `hobbiesList` array of `\u0026lt;li\u0026gt;`s. */} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; ) } export default Person  App.js - a Container (stateful) Component:\nimport React from \u0026#39;react\u0026#39; import Person from \u0026#39;./Person\u0026#39; function App() { // The `useState` hook allows a function component to manage state across calls to the function.  // We will discuss it further soon.  const [name, setName] = React.useState(\u0026#39;Susan\u0026#39;) const [hobbies, setHobbies] = React.useState([\u0026#39;music\u0026#39;, \u0026#39;photography\u0026#39;, \u0026#39;cycling\u0026#39;]) return ( \u0026lt;div\u0026gt; \u0026lt;Person name={name} hobbies={hobbies} /\u0026gt; {/* pass the state to child via props */} \u0026lt;/div\u0026gt; ); } export default App What is state ?  In React, state is data that changes over time in a managed way. When the state changes, React takes care of updating the DOM for you in the most efficient way.  What is the difference between state and props?  props (short for “properties”) and state are both plain JavaScript values. While both hold information that influences how the component is rendered, they are different in one important way:  props are passed to the component from its parent (similar to function parameters) state is managed within the component (similar to variables declared within a function)    The useState Hook  React added hooks in version 16.8. Hooks allow function components (components written as a JavaScript function) to manage state and other side-effects across calls to the function. The most common hook is the useState hook for managing state variables.  To add state to a component using the useState hook:\nconst [state, setState] = useState(initialState); where state and setState can be any variable names you want and initialState can be any value, for example:\nconst [color, setColor] = useState(\u0026#39;blue\u0026#39;); Notice that:\n useState takes a single argument which is the initial value we want stored in the state variable. the return value of useState is an array containing the stateful value and a function to update it.  The Initial Value and the State Variable  During the initial render, the returned state (state) is the same as the value passed as the first argument (initialState). This is only true for the initial render! During subsequent re-renders, the state value returned by useState will always be the most recent state.  Therefore, the useState hook is remembering our state value for us and providing it as needed.    Performance Tip\n If calculating the initial value is an expensive operation, you can prevent unnecessary recalculations by using a function that returns the initial value. React will only call that function on the initial render.  const [answerToEverything, setAnswerToEverything] = useState(() =\u0026gt; getTheAnswerToEverything(props)); The setState function  The setState function is used to update the state. It accepts a new state value and queues a re-render of the component.  TIP: Calculating State from Previous State\n If the new state is computed from the previous state, you can pass a function to setState. The function will receive the previous value, and return an updated value. This is safer than relying on the current state in the state variable as state updates are asynchronous.  In some complex scenarios, a race condition may occur where the state variable is stale when the asynchronous update is processed. Using a function with a parameter for the current state avoids this race condition.    Example using previous value in update to state:\nconst [count, setCount] = useState(0); ... setCount(prevState =\u0026gt; prevCount + 1); Example: Counter Component Here is an example of a simple Counter component:\nimport React, { useState } from \u0026#39;react\u0026#39; function Counter() { // Declare a new state variable, which we\u0026#39;ll call \u0026#34;count\u0026#34;  const [count, setCount] = useState(0) return ( \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;You clicked {count} times\u0026lt;/p\u0026gt; \u0026lt;button onClick={() =\u0026gt; setCount(count+1)}\u0026gt; {/* call `setCount` to update the count state value */} Click me \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; ); } export default Counter  For reference, here is the equivalent code using a JavaScript class (as was required before React Hooks were added):\nCounter Component using a JavaScript Class:\nclass Counter extends React.Component { constructor(props) { super(props); this.state = { // classes use `this.state` to hold the state  count: 0 // which can be any JavaScript expression  }; } render() { return ( \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;You clicked {this.state.count} times\u0026lt;/p\u0026gt; {/* classes use `this.setState` to update the state */} \u0026lt;button onClick={() =\u0026gt; this.setState({ count: this.state.count + 1 })}\u0026gt; Click me \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; ); } }  NOTE: React hooks don\u0026rsquo;t work inside classes. Before hooks, React stateful components had to be written using classes that used this.state and this.setState to manage the state of an instance of the class.\n  NOTE: We have an optional separate lesson that goes deeper into using JavaScript classes for stateful components.\n Avoid Mutating State Variables  We don\u0026rsquo;t want to mutate the state variable directly (i.e. don\u0026rsquo;t do this: count = count + 1) Why? Because then React would not know to do the proper \u0026ldquo;magic\u0026rdquo; of re-rendering the affected components By calling the setter function (the second value in the array returned by useState), we notify React that we want an updated value for the state variable. React can then process the new state and efficiently update the DOM by calling the proper component functions and determining what parts of the DOM actually changed.  According to the React Documentation on Using State Correctly, there are 3 things to keep in mind:\n Do Not Modify State Directly State Updates May Be Asynchronous State Updates are Merged  How to Avoid Mutations:\nHere are ways to avoid mutations with JavaScript data types:\nNumbers const [age, setAge] = useState(21); age = age + 1; // WRONG: mutates age age += 1; // WRONG: mutates age age++; // WRONG: mutates age ++age; // WRONG: mutates age  setAge(age + 1); // CORRECT Strings JavaScript strings are already immutable (yay!!!), but we must still be careful to not mutate (reassign) nested variable references:\nconst [newTransaction, setNewTransaction] = useState(null); newTransaction.name = event.target.value; // WRONG: mutates `newTransaction` setNewTransaction({ name: event.target.value }); // CORRECT Booleans Booleans work similar to numbers:\nconst [valid, setValid] = useState(false); valid = !valid; // WRONG: mutates `valid` setValid(true); // CORRECT setValid(v =\u0026gt; !v); // CORRECT: toggles the value of `valid` Arrays const [hobbies, setHobbies] = useState([]); hobbies.push(\u0026#39;chess\u0026#39;); // WRONG: mutates `hobbies` hobbies[0] = \u0026#39;chess\u0026#39;; // WRONG: mutates `hobbies` setHobbies(hobbies.concat(\u0026#39;chess\u0026#39;)) // CORRECT: `concat` does not mutate an Array setHobbies([...hobbies, \u0026#39;chess\u0026#39;]) // CORRECT: uses array destructuring  hobbies.pop(); // WRONG: mutates `hobbies` setHobbies(hobbies.slice(0, hobbies.length-1)); // CORRECT  hobbies.splice(2, 1); // WRONG: mutates `hobbies` setHobbies([ // CORRECT: uses spread operator  ...hobbies.slice(0, index), ...hobbies.slice(index + 1) ]); More examples with Arrays:\n// immutable filtering of Objects from Array const [movies, setMovies] = useState([]); setMovies(movies.filter(m =\u0026gt; m.genre === \u0026#39;comedy\u0026#39;); // CORRECT: sets movies to only the comedies  // immutable remove a movie from Array setMovies(movies.filter(m =\u0026gt; m.title !== \u0026#39;Groundhog Day\u0026#39;)); // CORRECT: removes Groundhog Day  // immutable increment of value in array const newCounts = [ // CORRECT:  ...counts.slice(0, index), // copying up to the index and then  counts[index] + 1, // add a new item that is old item + 1  ...counts.slice(index + 1) // copying all items after index ]; // CORRECT: immutable increment of value in array using Array.map const newCounts = counts.map( (count, idx) =\u0026gt; idx === index ? count + 1 : count );  TIP: Use concat, slice, filter, map and the spread operator to create new arrays from existing ones.\n Objects const [todos, setTodos] = useState([]); function toggleTodo(todo) { todo.completed = !todo.completed; // WRONG: mutates todo  return todo; }; // CORRECT: const toggleTodo = todo =\u0026gt; { // return a new object via Object.assign  return Object.assign({}, todo, { // copying the properties from the `todo` object  completed: !todo.completed // and overriding the value of the completed property  }); }; function toggleTodo(todo) { // CORRECT:  return { // return a new object  ...todo, // using the spread operator  completed: !todo.completed // and overriding the value of the completed property  }; };  TIP: Use Object.assign or the spread operator to clone objects.\n  TIP: For more on immutable programming with JavaScript, check out libraries such as immer, the use-immer hook, immutable-js, or Ramda.\n Summary In this lesson we:\n Discussed how React manages and updates a component\u0026rsquo;s state without mutating state variables. Learned how to use useState to notify React of new state values. Learned that after a call to useState, React will re-render our components and update the DOM as needed. Learned how to write immutable JavaScript expressions for numbers, strings, booleans, arrays, and objects.  Lab Do part 1 of the Component State Lab.\nAdditional Resources  Using the State Hook  "
},
{
	"uri": "/java/foundations/control-flow/",
	"title": "Control Flow",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts \u0026amp; Skills  Write if/else Switch case Use a for loop for iteration Use a while loop  Algorithms There are only three necessary control structures needed to solve problems:\n Sequence  Line by line, predictable execution   Selection  Singular: if Multiple-Exclusive: if-else Multiple-Inclusive: switch   Iteration  Looping: while and do-while Range Iteration: for    Selection It is a rare case when your program is so straightforward that you don\u0026rsquo;t encounter any forking or detouring in your flow. So, when the time comes, it\u0026rsquo;s important to know how to control the flow of your logic. The power in tracking states on objects comes in when you begin making decisions based on that state. This can dictate how you handle that object or whether its your job to handle it anymore at all!\nDecision makers in the code conditionalize certain functionality to execute only when its needed. It could be a single line or entire blocks of functionality. It could need to run through it once, many times, or not at all.\nIf An if statement is used for an exclusive scenario that needs some additional processing. You check the state in your if condition and if it evaluates to true the code defined in that line/block will be executed. Otherwise, it is skipped altogether.\nif (logical expression){ //do something }  NOTE\nThe above example is pseudocode. Pseudocode refers to a rough-draft outline of an answer, written in English-like terms.\nThese generally use phrases and words that are close to programming languages, but avoid using any specific language syntax.\n int balance = -5; if (balance \u0026lt; 0){ System.out.println(\u0026#34;Balance is negative. Put funds in your account or you will be charged a penalty.\u0026#34;); } Else An if statement by itself will only handle if the condition is True. It is very common that you would want to give a response if the condition is true or it is false. In the bank example, we might also want to give a response if the user has a balance in their account. This can be done with an else statement. An else statement is the \u0026ldquo;otherwise\u0026rdquo; statement, taking care of if the original if condition is false.\nif (condition1){ // do 1st option } else{ // do 2nd option } int balance = -5; if (balance \u0026lt; 0){ System.out.println(\u0026#34;Balance is negative. Put funds in your account or you will be charged a penalty.\u0026#34;); } else { System.out.println(\u0026#34;Balance is positive.\u0026#34;); } Else If So far, we have only checked to see if one condition is True or False. Usually a program has many different conditions to consider. To consider other conditions, you use an else if statement, which in Python is written as else if. The else if looks like the if statement and will evaluate another condition.\nBack to the bank account example, we may want to consider three possible situations:\n If the Balance is negative. Put funds in your account or you will be charged a penalty. If the balance is equal to zero If the balance is positive  if (condition1){ // do 1st option } else if (condition2){ // do 2nd option } else{ // do 3rd option } if (balance \u0026lt; 0){ System.out.println(\u0026#34;Balance is negative. Put funds in your account or you will be charged a penalty.\u0026#34;); } else if (balance == 0){ System.out.println(\u0026#34;Balance is equal to zero, add funds soon.\u0026#34;); } else{ System.out.println(\u0026#34;Balance is positive.\u0026#34;); } There are three possible outputs can now occur:\n If the variable balance is equal to 0, we will receive the output from the elif statement (Balance is equal to zero, add funds soon.) If the variable balance is set to a positive number, we will receive the output from the else statement (Balance is positive.) If the variable balance is set to a negative number we will receive the output from the if statement (Balance is negative. Put funds in your account or you will be charged a penalty)  Switch Case Where an if/else may be seen as a fork in the road of functionality switch cases are like spaghetti junction. There are a lot of paths and some may even overlap. Switch case is meant for investigating a single condition with multiple potential outcomes, some of which may even build on one another.\nString favoriteColor = \u0026#34;Maroon\u0026#34;; switch (favoriteColor) { case \u0026#34;Black\u0026#34;: System.out.println(\u0026#34;How classy of you!\u0026#34;); break; case \u0026#34;Maroon\u0026#34;: System.out.println(\u0026#34;What an Aggie! Gig \u0026#39;em!\u0026#34;); break; case \u0026#34;Burnt Orange\u0026#34;: System.out.println(\u0026#34;Invalid favorite color\u0026#34;); break; default: // catches everything else; }  NOTE: The break keyword tells the program to \u0026lsquo;break out\u0026rsquo; of the current control block. Here, it will exit the switch.\n In this way it creates branching possibilities, but maybe they are not all exclusive\u0026hellip;\nint month = 1; System.out.println(\u0026#34;The months left in the current year are: \u0026#34;); switch (month) { case 1: System.out.println(\u0026#34;February\u0026#34;); case 2: System.out.println(\u0026#34;March\u0026#34;); case 3: System.out.println(\u0026#34;April\u0026#34;); case 4: System.out.println(\u0026#34;May\u0026#34;); case 5: System.out.println(\u0026#34;June\u0026#34;); case 6: System.out.println(\u0026#34;July\u0026#34;); case 7: System.out.println(\u0026#34;August\u0026#34;); case 8: System.out.println(\u0026#34;September\u0026#34;); case 9: System.out.println(\u0026#34;October\u0026#34;); case 10: System.out.println(\u0026#34;November\u0026#34;); case 11: System.out.println(\u0026#34;December\u0026#34;); case 12: break; default: break; } This switch will take in a month number and print every future month to the futureMonths list. Notice rather than trying to print the months in each case, we allow the program to jump in where it needs and then simply cascade down the \u0026ldquo;downstream\u0026rdquo; cases to keep printing.\nIteration Looping is a control that allows you to run the same block of code multiple times.\nFor Loop The basic for loop is used when you know exactly how many iterations you need to run through.\nfor (declaration; loop condition; iteration updates) { // do things }  The declaration creates your variable that will be tracked through the loop The loop condition dictates when to continue looping, i.e. the loop will continue as long as the condition is true Iteration updates will run at the end of each iteration  for (int i = 10; i \u0026gt; 0; i--) { System.out.println(i); } System.out.println(\u0026#34;LIFT OFF!\u0026#34;); Output:\n10 9 8 7 6 5 4 3 2 1 LIFT OFF While Loop When the number of iterations is indeterminate we use a while loop which will continue as long as it has to until its condition evaluates to false.\n Syntax  while (condition) { // do things } At some point while doing things, the condition needs a chance to be updated\u0026hellip;\n What would happen if the condition was never updated?\n int age = 10; while (age \u0026lt; 21) { age++; System.out.println(\u0026#34;I am \u0026#34; + age + \u0026#34; years old\u0026#34;); } Do, While Loop A while loop stands the chance of not even running once. If its condition is false at the first evaluation it essentially acts as an if skipping the whole thing. But say you know you need a block to run at least once, then you use a do while loop.\ndo { // things } while (condition) Notice the order of the components implies the functionality\nint age = 21; do { age++; System.out.println(\u0026#34;I am \u0026#34; + age + \u0026#34; years old\u0026#34;); } while (age \u0026lt; 21); Summary Very few programs are linear. There is always some branch or iteration somewhere within our operation that can perform meaningful functions or distinctions. It is important to know which control best suits your solution: if/else and switch clauses for decision trees and loops for iteration. The best way to determine your needs if writing out some pseudocode before you begin to plan out what exactly has to happen to solve a given problem.\n"
},
{
	"uri": "/react/pillars/perf-opt-strategies/debounce/",
	"title": "Debouncing",
	"tags": [],
	"description": "",
	"content": "Use debouncing to prevent an operation from executing too often.\nProblem  Sometimes an expensive operation or network request can be triggered too frequently, consuming resources and affecting overall performance and responsiveness. Debouncing is a technique for limiting how frequently such operations are executed. Generally, debouncing discards some of the user interactions and keeps the most recent one.  Debouncing use cases  type-ahead / suggest or search scrolling interacting with charts and graphs animations, drag-and-drop interactions, and other UX effects anything depending on mouse events avoiding accidental double-clicks  Demo Click here to see a demo illustrating debouncing.\nDebouncing vs. Throttling Throttling is similar to debouncing except that it guarantees the execution of the function regularly, at least every X milliseconds. A common use-case would be infinite scrolling where throttling is better than debouncing because it doesn\u0026rsquo;t wait for the user to stop scrolling.\nrequestAnimationFrame (rAF)  requestAnimationFrame is a browser native JavaScript API that provides another way of rate-limiting the execution of a function. It can be thought as a _.throttle(dosomething, 16). But with a much higher fidelity (than say setTimeout), since it’s a browser native API that aims for better accuracy.  Pros\n Aims for 60fps (frames of 16 ms) but internally will decide the best timing on how to schedule the rendering.  Cons\n The start/cancellation of rAFs it’s our responsibility If the browser tab is not active, it would not execute. Although for scroll, mouse or keyboard events this doesn’t matter. rAF is not supported in Node.js, so you can’t use it on the server to throttle filesystem events.  Resources  Debouncing and Throttling Explained Through Examples How to Correctly Debounce and Throttle Callbacks in React use-debounce hook debounce | lodash throttle | lodash  Summary  Debouncing prevents an expensive function from being called too many times in a short time window.  Lab or Code-Along - Approximately 20 minutes  Use the React Performance Optimization Playground App for this lab. You will find a \u0026ldquo;Debounce\u0026rdquo; example and within that there are tabs for \u0026ldquo;Before\u0026rdquo; and \u0026ldquo;After\u0026rdquo;. The code for these tabs is found in the project source code under the folder src/pages/DebounceEx. Currently the code in the Before folder and the After folder are identical. Make the necessary changes in the After folder to add debouncing to the MainApp. Specifically, you will want to debounce the calls to the fetchData function as it is currently called with each change to the search text input. You will want to use React.useCallback to memoize your debounced function! Experiment with different debounce rates, such as 100, 200, 500 or 1000 milliseconds. Test that when you type in the search text, the network requests for the filtered results are being debounced / throttled.  You can use the following function to do the debouncing (or you can use the lodash implementation):\n/** * This function is React agnostic. It will debounce any function :-) * * @param {function} func the function to debounce * @param {integer} waitMillis the number of milliseconds * @returns a wrapper function that does the debouncing */ export default function debounce(func, waitMillis) { let timeout return function inner(...args) { if (timeout) clearTimeout(timeout) timeout = setTimeout(() =\u0026gt; { timeout = null func(args) }, waitMillis) } } "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/file-permissions/",
	"title": "File Permissions",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Managing file ownership - the chown and chgrp commands File permissions - the chmod command  Introduction  In a UNIX based file system, every file and directory has an owner, a group, and a set of permissions. The owner and the group have specific access to the file or directory. This allows us to set specific read, write, and execute/search permissions for the owner, the group, and for others.  Let\u0026rsquo;s look at an example listing\n$ ls -lF total 4 -rw-r--r-- 1 drmikeh staff 0 Jan 31 12:30 app.css -rw-r--r-- 1 drmikeh staff 0 Jan 31 12:30 app.js drwxr-xr-x 2 drmikeh wheel 68 Feb 2 13:26 images/ -rw-r--r-- 1 drmikeh staff 0 Jan 31 12:30 index.html -rw-rw-r-- 1 drmikeh staff 24 Jan 31 12:30 readme.md -rwxr--r-- 1 drmikeh staff 0 Feb 2 13:23 runit.sh* In the above listing, the set of dashes and letters on the left indicate the file / directory permissions.\nFile type and permissions:\nAs you can see there is a triplet of [rwx] for the user, the group, and others.\nChanging Ownership  Every file and directory has an owner (a single user) and a group Users can own files and can also belong to groups You can type the groups command to see what groups you belong to  The chown command is used to change the owner of a file or directory:\nchown newOwner fileOrDirectory You can also use chown to change both the owner and the group with a single command:\nchown newOwner:newGroup fileOrDirectory Or you can use the chgrp command to change just the group:\nchgrp newGroup fileOrDirectory Changing Permissions The chmod command is used to change the permissions of a file or directory.\nchmod can take a numeric value representing the new permissions, but you need to know a bit about binary numbers to understand how it works.\n There are 3 single-digit numbers that represent the permissions:  the first digit represents the owner\u0026rsquo;s permissions the second digit represents the group\u0026rsquo;s permissions the third digit represents the others\u0026rsquo; permissions   Each number can range from 0 to 7:     Decimal Value Binary Representation Permissions     0 000 no read, no write, and no execute permission   1 001 execute permission   2 010 write permission   3 011 write and execute permissions   4 100 read permission   5 101 read and execute permissions   6 110 read and write permissions   7 111 read, write, and execute permissions    This is best understood as a bit mask using binary numbers to represent the 0 to 7 values:\nUsing Letter Abbreviations Another way to modify permissions is using the letter abbreviations for user/group/other/all and r/w/x with the + and - operators for adding and removing the permissions.\nExamples:\nchmod u+x my-script.sh # add the execute permission for the user (owner) chmod g-x my-script.sh # remove the execute permission for the group chmod o-rwx my-script.sh # remove all permissions for others chmod a+r data.txt # add the read permission to all (owner, group, and others) # to see the updated permissions: ls -l -rwxr----- 1 mah3093 wheel 0 Oct 8 17:35 my-script.sh Summary  Use chown and chgrp to change the ownership of a file or directory Use chmod to change the permissions for a file or directory  "
},
{
	"uri": "/software-eng-essentials/git-foundations/gitting-started-labs/",
	"title": "Gitting Started Labs",
	"tags": [],
	"description": "",
	"content": "git Research In groups, you\u0026rsquo;ll be assigned to a few of the following commands:\n  git init\n  git add\n  git commit\n  git clone\n  git status\n  git log\n  git tag\n  git branch\n  git checkout\n  git merge\n  git reset\n  git rebase\n  Take 20 minutes to understand and discuss with your group by using the command git help and other resources.\n  Then, describe your understand of the assigned commands.\n     Go to lesson on initializing and cloning    Initialize Repository Navigate into your newly created git-workshop directory.\nOnce you are within the directory, initialize the directory to be a git repository.\nNow, this repository is initialized with git and you can add files and start using any git command.\n   Go to lesson on Saving Changes    All the adds Within git-workshop, create a new git-add-exercise directory. Navigate into git-add-exercise.\nWe\u0026rsquo;re going to be using the UNIX command echo to quickly write to a new file.\necho Content within file \u0026gt; add-exercise.txt echo File to be deleted eventually \u0026gt; delete-me.txt touch third-file.txt Check the status of that repository.\nIf you open up your repository in a text editor, you\u0026rsquo;ll see the files we created and the text we wrote within each file.\ngit add file-name  Just add the two files: add-exercise.txt and delete-me.txt. Ignore third-file.txt. Check the status of the repository. You should see add-exercise.txt and delete-me.txt are in the \u0026ldquo;Changes to be committed\u0026rdquo; section, while third-file.txt is in the untracked files section because we\u0026rsquo;ve created it, but we haven\u0026rsquo;t staged it yet. Commit these file with the message: Initial commit Check the status of the repository. Notice there is no mention of add-exercise.txt or delete-me.txt. This is because the most recent changes to both files have been captured to a snapshot.  git add -u  To demonstrate this flag, add more content to the existing add-exercise.txt and remove delete-me.txt with the following:  echo More text! \u0026gt;\u0026gt; add-exercise.txt rm delete-me.txt  Check the status to see that git knows:  add-exercise.txt was modified when the text changed and is ready to be committed. delete-me.txt is deleted and is ready to be committed. third-file.txt is still under \u0026ldquo;untracked files\u0026rdquo; because we\u0026rsquo;ve created it, but we haven\u0026rsquo;t staged it yet.   Stage only the changes to add-exercise.txt and delete-me.txt Check the status.  add-exercise.txt and delete-me.txt are in the \u0026ldquo;Changes to be committed\u0026rdquo; section. third-file.txt is still untracked.    git add .  Type git reset to un-do the previous staging and bring us back to having two files \u0026ldquo;Changed but not updated\u0026rdquo; and our third file as \u0026ldquo;Untracked\u0026rdquo;. (We will go further in depth on git reset later) Stage all changes but only in the current directory and subdirectories. Check the status of the repository to see that git knows:  add-exercise.txt was modified when the text changed and is in the \u0026ldquo;Changes to be committed\u0026rdquo; section. delete-me.txt is deleted and is in the \u0026ldquo;Changes to be committed\u0026rdquo; section. third-file.txt is also included in changes ready to be committed!    git add -A  Type git reset to go back to our previous status. Stage all changes in higher directories that still belong to the same git repository. Check the status of the repository to see that git knows:  add-exercise.txt was modified when the text changed and in the \u0026ldquo;Changes to be committed\u0026rdquo; section. delete-me.txt is deleted and in the \u0026ldquo;Changes to be committed\u0026rdquo; section. third-file.txt is also included in changes ready to be committed!    git add * Type git reset to back to our previous state.\ngit add * is an option if you have several of the same-type file you need to add.\n   Go to the lesson on Diffing    Diff Walkthrough To show diff in action, navigate to the gitting-started directory used in the add labs.\nType git diff. No feedback given because everything has been committed, so the current state of the files is the same as the last commit.\nUpdate the practice.txt with:\n$ echo \u0026#34;this is a diff example\u0026#34; \u0026gt; practice.txt git diff should give the following feedback:\n$ git diff a/practice.txt b/practice.txt index f6d701f..b37e70a 100644 --- a/practice.txt +++ b/practice.txt @@ -1 +1 @@ -this is a git practice file +this is a diff example    Go to the continued lesson on Diffing    "
},
{
	"uri": "/javascript/performance/universal-rendering-lab/",
	"title": "Lab: Universal Rendering",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/react/performance/universal-rendering-lab/",
	"title": "Lab: Universal Rendering",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/golang/testing/mocks/",
	"title": "Mocking, Stubbing, and Spying",
	"tags": [],
	"description": "",
	"content": "Goals Understand what mocks, stubs, and spies are and how to use them.\nLearning Objectives  What are mocks, stubs, and spies When and how to use them  What are Mocks, Stubs, and Spies To best understand mocks, stubs, and spies a proper understanding of Dependency Injection is needed. Dependency Injection is a technique where one object (or function) supplies the dependencies of another object (or function).\nWhy Dependency Injection  serves to improve the flexibility reusability of the code by separating concerns between the dependencies  This is often accomplished by passing objects or callback functions into a constructor or setter function.\nThis separation allows the dependencies to be swapped out by the caller so that different implementations of the dependencies may be used.\nFaking Dependencies For testing purposes, the dependencies being supplied may be fake implementations. These fakes come in the form of stubs, mocks, and spies.\nThe purpose of the fake implementations is to give the test code more control and insight into the code under test and remove dependencies on environmental components such as databases and external APIs.\nStub A stub is a fake object (or function) with a pre-programmed behavior. The stub stands in place of a real dependency so the tested unit can function correctly while being tested. Often a stub simply returns a fixed value or set of values. Stubs are typically used for one of two reasons:\n To avoid some inconvenient interface - for instance to avoid making actual requests to a server To feed the system with known data, forcing a specific code path to be executed  Imagine a stub is like a crash test dummy. It doesn\u0026rsquo;t function like a human but it has the shape and weight of a human so we can reliably test how a car performs in a crash test.\nMock A mock can be an object, function or data (mock data) that is like a stub but offers more configuration. A mock follows the specification / API of the dependency it is mocking. Both a stub and mock help us to confine testing internal to our app and not reach out into the real world, such as making fake api calls, or fake calls to a database.\nFor example, a mock object for a database will behave like the database in most ways (although it may not actually persist anything). Thus the mock object is a fully baked, yet fake implementation of the database.\nMost languages have a way to create mocks, but for the most part, you can create them yourself. The tools tend to do a lot of the tedious work for you. Languages that allow interfaces also make this a lot easier by not strictly calling for an exact implementation.\nA mock should be written in a way that shouldn\u0026rsquo;t force a code change in the unit under test.\nSo what does that look like?\nCreating a Mock\nclass MockDB { Query(qs, ...params) { /* Add assertions and/or other code that can be tested for expectations here if needed and possibly return mocked results. */ } } Here we’ve defined a mock class that mimics the methods that we know our external db component has. The real implementation may have more methods associated with it, but we know our code will only call the Query function. In JavaScript this works fine. In a statically typed language be aware you may need to define other functions as well. That is where the mocking tools tend to become handy.\nWithout getting too deep into details about specific test frameworks, let’s look at how we could instantiate this mock in order to pass it to our component for testing purposes.\nUsing a mock in a test\nconst mockdb = new MockDataBase() (1); const sc = new ShoppingCart(mockdb) (2); sc.AddItem(\u0026#34;planks\u0026#34;); const result = sc.GetTotal() (3); // Assert the results are what you expected // based on the input.   Create an instance of \u0026ldquo;MockDataBase\u0026rdquo;, which gives us an object with the Query method.\n  Create an instance of ShoppingCart and pass our mock as an argument in place of a real database.\n  Invoke the function we want to test.\n  From there, depending on how your language asserts results, we could make a determination if everything ran as expected inside of that function.\nSpy A spy is like a mock, in that it\u0026rsquo;s a fake dependency, but it also sets up to report back to the test how many times it was called and with which parameters. Often a spy may proxy the calls to the actual dependency as it \u0026ldquo;spies\u0026rdquo; on the interactions between the unit under test and the dependency.\n// The method being tested function Total(subtotal, taxObj){ return taxObj.getTaxOnSubTotal(subtotal) + subtotal; } //In the testing file  //Create an array to hold the arguments passed to our spy method. let argsToGetTaxOnSubtotal = []; //Create the spy taxObj. spyTaxObj = { taxRate: .05, getTaxOnSubTotal : func(subtotal){ argsToGetTaxOnSubtotal.push(subtotal); return taxRate * subtotal; } } //Now we can run the test and use the spy to tell us how many times the getTaxOnSubtotal was called and with what parameters.  function TestTotal(){ let testSubtotals = [20.25, 1235.89]; for(subTest in testSubtotals){ Total(testSubtotals[subTest], spyTaxObj) // Total expects 2 arguments. \t} expect(argsToGetTaxOnSubtotal).to.equal([20.25, 1235.89]); } Above, each of the subtotals that we passed to Total, we expect to be passed to our spy method getTaxOnSubTotal. We can see how many times it was called and with which parameters.\nTesting Scopes Sometimes we test too high (not enough details), and sometimes we test too low (into implementation). Where to start in all the muddle? Here are some guildelines to keep in mind:\n Refactoring means code changes but behavior stays the same. Therefore, tests should not change too much. Am I testing behavior I or the implementation details? BDD tells us to test behaviors not implementation. Private functions are a form of implementation and therefore should not be tested. Did you need more than 3 mocks? If yes, maybe rethink your design. Use spies with caution. Spies let you see the insides of the algorithm you are writing which can be very useful but that means a tighter coupling between your test code and the implementation. Be sure you actually care about these details if you\u0026rsquo;re going to spy on them.  Conclusion When testing a unit we should mock out its dependencies to ensure the unit under test is the only variable in the equation. When the test fails, we can be sure that the unit is to blame.\n"
},
{
	"uri": "/software-eng-essentials/testing/mocks/",
	"title": "Mocking, Stubbing, and Spying",
	"tags": [],
	"description": "",
	"content": "Goals Understand what mocks, stubs, and spies are and how to use them.\nLearning Objectives  What are mocks, stubs, and spies When and how to use them  What are Mocks, Stubs, and Spies To best understand mocks, stubs, and spies a proper understanding of Dependency Injection is needed. Dependency Injection is a technique where one object (or function) supplies the dependencies of another object (or function).\nWhy Dependency Injection  serves to improve the flexibility reusability of the code by separating concerns between the dependencies  This is often accomplished by passing objects or callback functions into a constructor or setter function.\nThis separation allows the dependencies to be swapped out by the caller so that different implementations of the dependencies may be used.\nFaking Dependencies For testing purposes, the dependencies being supplied may be fake implementations. These fakes come in the form of stubs, mocks, and spies.\nThe purpose of the fake implementations is to give the test code more control and insight into the code under test and remove dependencies on environmental components such as databases and external APIs.\nStub A stub is a fake object (or function) with a pre-programmed behavior. The stub stands in place of a real dependency so the tested unit can function correctly while being tested. Often a stub simply returns a fixed value or set of values. Stubs are typically used for one of two reasons:\n To avoid some inconvenient interface - for instance to avoid making actual requests to a server To feed the system with known data, forcing a specific code path to be executed  Imagine a stub is like a crash test dummy. It doesn\u0026rsquo;t function like a human but it has the shape and weight of a human so we can reliably test how a car performs in a crash test.\nMock A mock can be an object, function or data (mock data) that is like a stub but offers more configuration. A mock follows the specification / API of the dependency it is mocking. Both a stub and mock help us to confine testing internal to our app and not reach out into the real world, such as making fake api calls, or fake calls to a database.\nFor example, a mock object for a database will behave like the database in most ways (although it may not actually persist anything). Thus the mock object is a fully baked, yet fake implementation of the database.\nMost languages have a way to create mocks, but for the most part, you can create them yourself. The tools tend to do a lot of the tedious work for you. Languages that allow interfaces also make this a lot easier by not strictly calling for an exact implementation.\nA mock should be written in a way that shouldn\u0026rsquo;t force a code change in the unit under test.\nSo what does that look like?\nCreating a Mock\nclass MockDB { Query(qs, ...params) { /* Add assertions and/or other code that can be tested for expectations here if needed and possibly return mocked results. */ } } Here we’ve defined a mock class that mimics the methods that we know our external db component has. The real implementation may have more methods associated with it, but we know our code will only call the Query function. In JavaScript this works fine. In a statically typed language be aware you may need to define other functions as well. That is where the mocking tools tend to become handy.\nWithout getting too deep into details about specific test frameworks, let’s look at how we could instantiate this mock in order to pass it to our component for testing purposes.\nUsing a mock in a test\nconst mockdb = new MockDataBase() (1); const sc = new ShoppingCart(mockdb) (2); sc.AddItem(\u0026#34;planks\u0026#34;); const result = sc.GetTotal() (3); // Assert the results are what you expected // based on the input.   Create an instance of \u0026ldquo;MockDataBase\u0026rdquo;, which gives us an object with the Query method.\n  Create an instance of ShoppingCart and pass our mock as an argument in place of a real database.\n  Invoke the function we want to test.\n  From there, depending on how your language asserts results, we could make a determination if everything ran as expected inside of that function.\nSpy A spy is like a mock, in that it\u0026rsquo;s a fake dependency, but it also sets up to report back to the test how many times it was called and with which parameters. Often a spy may proxy the calls to the actual dependency as it \u0026ldquo;spies\u0026rdquo; on the interactions between the unit under test and the dependency.\n// The method being tested function Total(subtotal, taxObj){ return taxObj.getTaxOnSubTotal(subtotal) + subtotal; } //In the testing file  //Create an array to hold the arguments passed to our spy method. let argsToGetTaxOnSubtotal = []; //Create the spy taxObj. spyTaxObj = { taxRate: .05, getTaxOnSubTotal : func(subtotal){ argsToGetTaxOnSubtotal.push(subtotal); return taxRate * subtotal; } } //Now we can run the test and use the spy to tell us how many times the getTaxOnSubtotal was called and with what parameters.  function TestTotal(){ let testSubtotals = [20.25, 1235.89]; for(subTest in testSubtotals){ Total(testSubtotals[subTest], spyTaxObj) // Total expects 2 arguments. \t} expect(argsToGetTaxOnSubtotal).to.equal([20.25, 1235.89]); } Above, each of the subtotals that we passed to Total, we expect to be passed to our spy method getTaxOnSubTotal. We can see how many times it was called and with which parameters.\nTesting Scopes Sometimes we test too high (not enough details), and sometimes we test too low (into implementation). Where to start in all the muddle? Here are some guildelines to keep in mind:\n Refactoring means code changes but behavior stays the same. Therefore, tests should not change too much. Am I testing behavior I or the implementation details? BDD tells us to test behaviors not implementation. Private functions are a form of implementation and therefore should not be tested. Did you need more than 3 mocks? If yes, maybe rethink your design. Use spies with caution. Spies let you see the insides of the algorithm you are writing which can be very useful but that means a tighter coupling between your test code and the implementation. Be sure you actually care about these details if you\u0026rsquo;re going to spy on them.  Conclusion When testing a unit we should mock out its dependencies to ensure the unit under test is the only variable in the equation. When the test fails, we can be sure that the unit is to blame.\n"
},
{
	"uri": "/javascript/foundations/labs/objects-lab/",
	"title": "Objects Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch objects.js Add the following code to objects.js:\nconst course = { name: \u0026#39;JavaScript Foundations\u0026#39;, instructors: [\u0026#39;Brandon\u0026#39;, \u0026#39;Shane\u0026#39;, \u0026#39;Mike\u0026#39;], students: [ { name: \u0026#39;Donna\u0026#39;, computer: { OS: \u0026#39;Linux\u0026#39;, type: \u0026#39;laptop\u0026#39; } }, { name: \u0026#39;Alex\u0026#39;, computer: { OS: \u0026#39;macOS\u0026#39;, type: \u0026#39;iMac\u0026#39; } }, { name: \u0026#39;Linda\u0026#39;, computer: { OS: \u0026#39;unix\u0026#39;, type: \u0026#39;mainframe\u0026#39; } } ] }; const name = null; // TODO: replace null with the course name const teacher = null; // TODO: replace null with the second instructor const student = null; // TODO: replace null with the course first student\u0026#39;s name const computerType = null; // TODO: replace null with the second student\u0026#39;s computer type  console.log(\u0026#39;Course Name:\u0026#39;, name); console.log(\u0026#39;Second teacher:\u0026#39;, teacher); console.log(\u0026#39;First Student\u0026#39;, student); console.log(\u0026#39;Alex\\\u0026#39;s computer type:\u0026#39;, computerType); // Bonus: An array of all the students that are using macOS. // TODO: populate `coolStudents` with the names of the students that are using macOS. const coolStudents = [] for (let i=0; i\u0026lt;course.students.length; i++) { // TODO: add code here } console.log(\u0026#39;Students using macOS:\u0026#39;, coolStudents); Step 2: Complete the code and test Complete the TODOs in the above code.\nTest your solution with:\nnode objects.js The expected output is:\nCourse Name: JavaScript Foundations Second teacher: Shane First Student Donna Alex\u0026#39;s computer type: iMac Students using macOS: [ \u0026#39;Alex\u0026#39; ] "
},
{
	"uri": "/cloud/platforms/pcf-foundations/",
	"title": "PCF Foundations",
	"tags": [],
	"description": "",
	"content": "Welcome to Pivotal Cloud Foundry Foundations! "
},
{
	"uri": "/custom-workshops/frontend-at-thd/react-crash-course/",
	"title": "React Crash Course",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/cloud/containers/docker-fundamentals/services-in-docker/",
	"title": "Running a Service in Docker",
	"tags": [],
	"description": "",
	"content": "Concepts  Understanding Port Mappings Exposing Ports in a Container Running a container in detached mode Reattaching to a container that is in detached mode  Port Mapping Before you can run you application, you need to be sure that your application is reachable. In order to do this, you\u0026rsquo;ll need to understand how ports are exposed and how they get mapped to the host machine.\nThe Most Basic \u0026amp; Incomplete Intro to Docker Networking Every container has its own network interface and range of ports it can listen to. Exposing this port at the container level allows network traffic from the Docker Host VM to communicate with the running container over that port.\nIn order to reach your container from outside of your Host VM, you will need to bind an available port on your Host Machine. Assuming the Host Machine's fire wall rules allow, this will allow external traffic to communicate all the way down into the container to the listening service.\nHost Machine Port ==\u0026gt; VM Port ==\u0026gt; Container Port ==\u0026gt; Listening App\n  This is the basic flow. Docker networking is pretty powerful, and capable of more than the flow described above. This should be enough to grasp the concept of how you can communicate with your container.\nHost and VM Ports can be the same. Docker takes care of the binding of the port to the container in the VM, so you will never see this. When executing the command to bind the port, it will look as if the VM Port doesn\u0026rsquo;t exists and appear to be simply:\nHost Machine Port ==\u0026gt; Container Port ==\u0026gt; Listening App\nAnd that is fine for what we are doing with docker at this stage. Now, lets look at how to actually make this happen.\nHow to Bind the Port Binding the port with Docker CLI is known as publishing the port. You publish a port with the run sub-command and -p flag of the docker cli\ndocker run -p \u0026lt;HOST-PORT\u0026gt;:\u0026lt;CONTAINER-PORT\u0026gt;/ \u0026lt;image\u0026gt; Let\u0026rsquo;s try!\nRun the following command:\ndocker run -p 5000:3000 docker.artifactory.homedepot.com/Orange Academy/docker/netcat-example:1.1 In your browser, navigate to http://localhost:5000/\nTo review our flow, we should now have:\nHost Machine Port ==\u0026gt; Container Port ==\u0026gt; Listening App 5000 ==\u0026gt; 3000 ==\u0026gt; nc Find the source for this container here\nMore Examples Java Spring Boot\nImage: docker.artifactory.homedepot.com/Orange Academy/docker/springboot-example:1.0\nPort: 8080\nGo Example\nImage: docker.artifactory.homedepot.com/Orange Academy/docker/go-greet:1.0\nPort: 3000\nBoth listen to a route on /greeting with a query parameter called name that will greet the name provided or World if not.\nExample: localhost:3000/greeeting?name=Erik\nExercise:\nPick one of the services and run it. If you know how to search for a tag on Artifactory, find the most recent and use it. Otherwise, an instructor can provide it for you.\nApps using the PORT Environment Variable But wait! My app is set up to pick up the port from the environment! Do I have to hard-code my Port?\nNo, you don\u0026rsquo;t have to. While it is a good idea to hard-code a default, you can easily pass in an environment variable with your docker run command using the -e flag.\nFor example, if we need to change the port for our Go service, which checks to see if PORT is defined and listens to it, we can pass it like this:\ndocker run -e PORT=1234 -p 7555:1234 docker.artifactory.homedepot.com/Orange Academy/docker/go-greet:1.0  Note: You can also set env variables with a file using --env-file to point to it.\n Example from the documentation:\n$ cat env.list # This is a comment VAR1=value1 VAR2=value2 USER $ docker run --env-file env.list ubuntu env | grep VAR VAR1=value1 VAR2=value2 USER=denis Detaching and Attaching to Containers You may have noticed that when you run the above containers that your terminal hangs. This is because docker is attached to your shells standard input, output and error. This is fine, except that if you close your shell, it will end the container. Not to mention you may not want to have tabs or windows open for each service you run. To get around this we can run containers in the background.\nDetached Mode Running containers in the background is known as detached mode. You can run your container in detached mode using the -d flag with your run command:\ndocker run -d [other options] [image]Try It\n Pick one of the services above and run it using -d List your containers using docker ps Is the image you chose running?   Note: You can run any image in detached mode. Just be aware that the container will exit as it would have in attached mode, so you may need to use docker ps -a to see an image that you ran in detached mode that exited.\n For example, run docker run -d alpine:latest sleep 30 If you run docker ps within 30 seconds, you should see this container in a running state. After 30, it will show as exited.\nWithin 30 Seconds:\n$\u0026gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 21f503eb2eda alpine:latest \u0026#34;sleep 30\u0026#34; 3 seconds ago Up 2 seconds stupefied_austin After 30 Seconds:\n$\u0026gt; docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 21f503eb2eda alpine:latest \u0026#34;sleep 30\u0026#34; 37 seconds ago Exited (0) 7 seconds ago stupefied_austin Reattaching to a Running Container There are times, especially during development, where we may want to reattach to a container to see what is going on. You can reattach to a container using the docker attach command:\ndocker attach [OPTIONS] CONTAINER\nLet\u0026rsquo;s take a look at the official documentation to understand how this will works, and what to be aware of.\nOne thing the documentation does not do a good job of explaining is detaching from a container that you attached to using the attach sub command. To detach using ctrl+c you can use the --sig-proxy=false flag for docker attach\nInspecting a Running Container If you are interested in debugging, or seeing what is going on, in a container that is running your service you can use the exec sub command as long as the container you are using has a shell installed ( ie bash or sh)\nLet\u0026rsquo;s look again at the Official documentation for exec on how to do this.\nTry it\nTry running the examples in the documentation, then using one of the images in this lesson.\nSummary In this lesson we learned how to start services that connect to a port and how to map that port to a port on the host computer. We also learned about starting detached containers (containers running in the background), how to attach and detach from a container, and how to exec commands on a detached container.\n"
},
{
	"uri": "/cyber-security/static-dynamic-analysis/6-remediation/",
	"title": "Security Weakness Remediation",
	"tags": [],
	"description": "",
	"content": "Remediation using Fortify There are numerous kinds of vulnerabilities that can show up in your code. It would be impossible for us to break down every one of them. The intent is to help you identify the tools at your disposal for fixing vulnerabilities in your own code by walking through an example.\n  Here we have used Fortify to identify a SQL injection vulnerability. Not knowing much or anything about SQL injection, how would you proceed?\n    Google is always a good option but there are some other resources that will be more specific. Here we have the Info tab in Fortify. Overview will tell you the line number and the reason it was flagged as a vulnerability.\n    The Details section will give you an explanation of the vulnerability and typical remediation procedure. It will be generic so you will have to figure out how the solution applies to your code, but at the very least it will give you valuable keywords to research.\n  Other Resources It wouldn\u0026rsquo;t be reasonable for us to break down how to fix every kind of vulnerability in a course like this. That is why Home Depot invested in Secure Code Warrior, a training platform that does exactly that for all of the major programming languages. If you want to know the vulnerability you\u0026rsquo;ve run into inside and out, this is the recommended option. There are also competitions and other resources you can use to become a more secure programmer.\nThe OWASP Top 10 is the industry standard resource for cataloging the most common types of web application vulnerabilities and how to remediate them. They have numerous guides and cheat sheets so this is something you may want to bookmark.\nThe MITRE database is where you want to start if your vulnerability has a CVE (common vulnerabilities and exposures) number attached. The format will be CVE-2020-XXXX where 2020 is the year number and XXXX is the vulnerability number for that given year. This will be usually be the case if the scan is a third party library scan from Whitesource. A quick tip is also to google your CVE number + remediation.\nFinishing up Now that you have some tools to start figuring out the problem, take a moment and try and find what the answer is.\nThe solution here is to use what is called Prepared Statements.\nString userName = ctx.getAuthenticatedUserName(); // store username in a variable  String itemName = request.getParameter(\u0026#34;itemName\u0026#34;); // store item name in a variable  String query = \u0026#34;SELECT * FROM items WHERE itemname=? AND owner=?\u0026#34;; // create the SQL query template, using ? as a place holder for the desired values  PreparedStatement stmt = conn.prepareStatement(query); // prepare the query and load it into a variable  stmt.setString(1, itemName); // load the item name into the first parameter  stmt.setString(2, userName); // load the username into the second parameter  ResultSet results = stmt.execute(); // execute the statement and store the results in an object "
},
{
	"uri": "/javascript/express/ssr/",
	"title": "Server Side Rendering",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Describe CSR and SSR List some benefits of SSR Use Express to write a SSR application  Introduction There are 3 ways that HTML can be generated for a web page:\n Static HTML - the HTML is written by a developer and does not change at runtime. Client-side rendering or CSR - the HTML is generated and/or updated using JavaScript running in the browser. Popular JS libraries for CSR are Angular, React, and Vue. Server-side rendering or SSR - the HTML is generated on a web server and sent to the browser  In server-side rendering when a user makes a request to a webpage, the server prepares an HTML page by fetching user-specific data and sending it to the user’s machine over the internet. The browser then construes the content and displays the page. This entire process of fetching data from the database, creating an HTML page and sending it to client happens in mere milliseconds.\nAdvantages of SSR The table below compares static HTML, Client-side rendering, and Server-side rendering.\n   HTML Generation Advantages Disadvantages     Static HTML Fast, SEO, Easy to develop and maintain Only works for pages with no dynamic content   Client-side Great user interactions, Fast incremental updates Slow initial load time, complex DX   Server-side Fast initial load, SEO, Easier DX Greater load on server, slower user interactions     NOTE: DX = developer experience, how easy or complex it is for the development team.\n When to use server-side rendering  An application has very simple UI with fewer pages/features An application has less dynamic data Read preference of the site is more than write The focus is not on rich site and has few users  When to use client-side rendering  An application has very complex UI with many pages/features An application has large and dynamic data Write preference of the site is more than reading The focus is on rich site and a huge number of users  Popular SSR Web Sites There are several web sites where SSR makes sense. Often these websites have much higher read than update user behavior.\nExamples:\n Many news, weather, and sports sites where the data is time sensitive but not user specific Stack Overflow GitHub  Express and SSR Express provides rich support of SSR.\nExpress supports view engines that incorporate a template language for defining the overall structure of each web page. These templates are a mix of static structure and dynamic data.\nA popular view engine for Express is Pug.\nExpress views are usually kept in a folder called views.\nA sample Pug template is as follows:\nviews/index.pug:\ndoctype html html head title= title link(rel='stylesheet', href='/stylesheets/style.css') body h1= title p Welcome to #{title} Which would generate the following HTML (if title === Express\u0026quot;`):\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Express\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;/stylesheets/style.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Express\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Welcome to Express\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; The h1= title and the #{title} are ways to render dynamic content via JavaScript variables that are passed to the view engine!\nPug supports the following features for dynamically generating an HTML page from a Pug template:\n defining variables string interpolation iteration conditionals and case/when statements  You can read more about Pug here.\nTo define a route that uses this view:\nrouter.get(\u0026#39;/\u0026#39;, (req, res, next) =\u0026gt; { res.render(\u0026#39;index\u0026#39;, { title: \u0026#39;Express with SSR\u0026#39; }) }) Getting Started with Express and Pug You can easily create an Express and Pug SSR application using the express generator:\nnpx express-generator --view=pug ssr-ex1 cd ssr-ex1 npm install  NOTE: You may not want to use the express-generator for production quality work as it is very opinionated and still uses CommonJS modules. Here we use it just to get a quick start on how to use Express for an SSR application.\n What Gets Generated After running the express-generator you should get the following files and folders:\n./ ├── .gitignore ├── app.js # contains the main Express startup code ├── bin/ │ └── www* # boilerplate startup script ├── package.json ├── public/ # folder for static files │ ├── images/ │ ├── javascripts/ │ └── stylesheets/ │ └── style.css ├── routes/ # our familiar routes folder │ ├── index.js │ └── users.js └── views/ # contains view templates ├── error.pug # an error page for displaying errors ├── index.pug # our home page └── layout.pug # defines the overall layout of our pages Generally there is a clear mapping between routes and views.\nA common route/view pattern for CRUD based features is given below.\n   Route Name Route View Description     INDEX GET items index.pug returns an HTML page rendering all items   SHOW GET items/:id item.pug returns an HTML page rendering a single item   NEW GET items/new item-form.pug returns an HTML page containing a form for adding   CREATE POST items  inserts new item and redirects to INDEX route   EDIT GET items/edit/:id item-form.pug returns an HTML page containing a form for editing   UPDATE PUT items/edit/:id  updates an item and redirects to INDEX route   DELETE DELETE items/:id  deletes an item and redirects to INDEX route    Notes:\n The NEW and EDIT routes can use the same form. NEW uses the form with no initial data and EDIT uses the form prepopulated with data. The CREATE, UPDATE, and DELETE routes accept data from the client and don\u0026rsquo;t have a view but instead redirect to the INDEX route.  Example A more complete example is provided at om_labs_express-ssr-with-pug.\nTo install this example:\ngit clone https://github.com/one-thd/om_labs_express-ssr-with-pug.git cd om_labs_express-ssr-with-pug npm install npm run dev Lab Inspect the files in this example app. Then see if you can add a SHOW route that renders a single car in an HTML page.\nSummary SSR is a good option for web sites that have dynamic data but not a lot of user interaction. SSR applications are also easier to develop than CSR applications.\nA recent trend is to blend all three options, combining static web pages, CSR, and SSR in a single web site. This approach is a bit more complex to develop but several frameworks are emerging to simplify the approach, such as NextJS and Remix for React and Angular Universal for Angular.\n"
},
{
	"uri": "/react/foundations/labs/lab-side-effects/",
	"title": "Side Effects",
	"tags": [],
	"description": "",
	"content": "In this lab you will clone an existing React project add the useEffect hook to properly fetch data from a RESTful server.\nYou can find the instructions for the lab here.\n"
},
{
	"uri": "/javascript/performance/universal-rendering-lab/step-6/",
	"title": "Step 6: Measure performance",
	"tags": [],
	"description": "",
	"content": "Using the skills that we acquired in the gathering metrics lesson, let\u0026rsquo;s measure the FCP and FMP of our application now that we have implemented universal rendering.\nOnce you have measured the FCP and FMP of the application with universal rendering, check out an earlier version and measure the FCP and FMP of our client-side rendered application so that we can compare the measurements.\n Open a new terminal window cd ~ Clone down another copy of the repository: git clone https://github.com/one-thd/om_labs_performance-workshop.git performance-workshop-csr cd performance-workshop-csr npm install npm run build \u0026amp;\u0026amp; PORT=8081 npm run start  What do you notice about the FCP and FMP of the client-side rendered application and the universally rendered application? Are they different? If not, why?\nBut what about routing? With a universally rendering web application, we will need to handle routing on both the server, as well as in the client.\nThe following tutorial provides a simple step-by-step guide on how to implement routing in a universally rendered React application: https://tylermcginnis.com/react-router-server-rendering/\nThis all seems really complicated. Is there a framework that will help me build a universally rendered application? Yes! The developers at Next.js have abstracted all of this complexity away and provided a simplified developer experience when it comes to creating a universally rendered app.\nNext.js allows you to write React components, render them on the server, and then hydrate them on the client. This provides all of the benefits of universal rendering, without much of the added complexity.\nOther benefits of Next.js:\n Handles routing Automatic code-splitting Prefetches pages before they are needed  Check out Next.js in more detail here: https://nextjs.org/\nCouldn\u0026rsquo;t we just use the framework without learning how to implement universal rendering? Frameworks are not foolproof, and inevitably errors will happen. You are now empowered to fix those errors when they occur, which is critical to the survival of any project.\nBefore introducing any framework into a project, it is extremely important to understand what the framework does so that we can fix our code when it breaks.\n"
},
{
	"uri": "/react/performance/universal-rendering-lab/step-6/",
	"title": "Step 6: Measure performance",
	"tags": [],
	"description": "",
	"content": "Using the skills that we acquired in the gathering metrics lesson, let\u0026rsquo;s measure the FCP and FMP of our application now that we have implemented universal rendering.\nOnce you have measured the FCP and FMP of the application with universal rendering, check out an earlier version and measure the FCP and FMP of our client-side rendered application so that we can compare the measurements.\n Open a new terminal window cd ~ Clone down another copy of the repository: git clone https://github.com/one-thd/om_labs_performance-workshop.git performance-workshop-csr Copy the .env file from performance-workshop into the root directory of performance-workshop-csr. e.g. cp performance-workshop/.env performance-workshop-csr/ cd performance-workshop-csr npm install npm run build \u0026amp;\u0026amp; PORT=8081 npm run start  What do you notice about the FCP and FMP of the client-side rendered application and the universally rendered application? Are they different? If not, why?\nBut what about routing? With a universally rendering web application, we will need to handle routing on both the server, as well as in the client.\nThe following tutorial provides a simple step-by-step guide on how to implement routing in a universally rendered React application: https://tylermcginnis.com/react-router-server-rendering/\nThis all seems really complicated. Is there a framework that will help me build a universally rendered application? Yes! The developers at Next.js have abstracted all of this complexity away and provided a simplified developer experience when it comes to creating a universally rendered app.\nNext.js allows you to write React components, render them on the server, and then hydrate them on the client. This provides all of the benefits of universal rendering, without much of the added complexity.\nOther benefits of Next.js:\n Handles routing Automatic code-splitting Prefetches pages before they are needed  Check out Next.js in more detail here: https://nextjs.org/\nCouldn\u0026rsquo;t we just use the framework without learning how to implement universal rendering? Frameworks are not foolproof, and inevitably errors will happen. You are now empowered to fix those errors when they occur, which is critical to the survival of any project.\nBefore introducing any framework into a project, it is extremely important to understand what the framework does so that we can fix our code when it breaks.\n"
},
{
	"uri": "/software-eng-essentials/command-line-bash/terminal-text-editing/",
	"title": "Terminal: Text Editing",
	"tags": [],
	"description": "",
	"content": "Objectives  GNU Nano, nanu nanu! Emacs Vim  GNU Nano, nanu nanu! Nano session\n$ nano\nTo exit nano, hit ^x.\nif you made any edits to the file, you will be prompted to save before exiting. Just hit n to exit without saving the file.\nThe Church of Emacs Emacs session\n$ emacs\nTo exit emacs, hit ^x then ^c.\nif you made any edits to the file, you will be prompted to save before exiting. Just hit n to exit without saving the file.\nVim Vim is uniquely a modal text editor. This is to say it has a \u0026ldquo;command mode\u0026rdquo; and an \u0026ldquo;insert mode\u0026rdquo;. The command mode is where you can navigate around the file, line by line, word by word. (Note: if you don\u0026rsquo;t have much text in the file, then you cannot move around much in command mode. Guess why?)\nOnce the cursor is in position to make an edit, you can enter \u0026ldquo;insert mode\u0026rdquo; by typing i.\nReentering command mode is achieved by hitting ^c.\nVim session\nEnter the vim command to start the program.\n$ vim\nVim will start in command mode. Enter \u0026ldquo;insert mode\u0026rdquo; by typing i.\nExit by first reentering command mode with ^c, and finally type the infamous :q\u0026lt;Enter\u0026gt; to quit Vim.\nIf you made any changes to the file, you will be prompted to save before quiting.\n :q!\u0026lt;Enter\u0026gt; will override any changes to the file and exit Vim; :wq\u0026lt;Enter\u0026gt; saves changes before exiting.  Git and Vim\n Vim is the default editor for Git If you wish to change this, edit your ~/.gitconfig file    Vim includes a tutorial that is run in the terminal. In under 30 minutes, you can learn all the basic commands for effectively using Vim. Run the command $ vimtutor to start!   Summary  Nano Emacs Vim  "
},
{
	"uri": "/web-essentials/webmastery-foundations/transitions-and-animations/",
	"title": "Transitions and Animations",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Describe keyframe animation Compare \u0026amp; contrast using CSS and JS for animations  Skills  Use CSS Transitions to animate elements Use CSS Animations to create detailed animations  Intro In the past (before CSS3) developers had to use JavaScript and jQuery to make elements move around on the page. But using JavaScript to animate will slow our page load time in noticeable ways. Also, using JavaScript to affect the presentation of the HTML blurs the separation of concerns of using:\n HTML to define content (Model) CSS to define style (View or Presentation) JS to define behavior (Controller)  Fortunately, we now have CSS Animations to define animations where they belong - in the stylesheet! CSS Animations have a much lower impact on page loads and are a great way to add a layer of polish to your design.\nConcept CSS uses the same basic concepts found in hand-drawn animation with keyframes.\nIn the previous image, the left and right-most drawings are Keyframes - they define the starting or ending point of a smooth transition. The drawings between the left and right-most image are Inbetweens - they don\u0026rsquo;t have to be drawn on a storyboard, because the animator can assume what they will look like without a visual reference.\nIn web-based animations, Keyframes work the same way - they represent the beginning or ending state of the element being animated. However, our inbetweens will be generated instead of being filled in by hand later.\nThis is an example of declarative programming. We simply declare what we want to happen (go from here to there in 3 seconds) rather than specifying in great detail how it should happen (as we must do in impertive programming).\nThe following example of some CSS defines 2 states for an HTML element, allowing you to hover over the message to see a 2nd state:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;CSS Animations\u0026lt;/title\u0026gt; \u0026lt;link href=\u0026#34;https://fonts.googleapis.com/css?family=Shadows+Into+Light|Shrikhand\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34; href=\u0026#34;ex1.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;greeting\u0026#34;\u0026gt;Hello Friend.\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; * { box-sizing: border-box; } #greeting { width: 400px; height: 400px; background-color: #332532; border: 8px solid #F77A52; color: #F77A52; font-size: 70px; margin: 100px; padding: 40px; text-align: left; } #greeting:hover { width: 600px; height: 600px; background: #CAFCD8; border: 20px solid #04BFBF; font-family: \u0026#39;Shadows Into Light\u0026#39;, cursive; color: #04BFBF; font-size: 120px; line-height: 1; padding: 200px 60px 60px 60px; text-align: right; }    To see the demo, click here    There are 2 states that can be toggled via hovering. But, there is no animation. It is a drastic change from one state to the other that doesn\u0026rsquo;t feel very natural. These two class states represent our keyframes, but we want to have a smooth transition from the first to the last. We need some inbetweens.\nSo how do we generate the inbetweens?\nWith CSS, there are 2 different approaches: transitions and animations.\nCSS Transitions CSS Transitions let us tell the browser how to change a property over time. Let\u0026rsquo;s add a new property to the greeting CSS:\ntransition: all 2s ease; We can add this transition to both the non-hover and the hover states so that we have a smooth transition both ways.\nHere is a breakdown of the transition CSS line from above.\n Transition is the name of the CSS property that tells the element to try to animate certain values if it can. All means, \u0026lsquo;try to animate ALL property values\u0026rsquo;. This could also be replaced with specific properties, like width or color. 2s is the amount of time you\u0026rsquo;d like the animation to take - in this case, 2 seconds. Ease is the \u0026ldquo;Speed Curve\u0026rdquo; of animation - basically, a tweak to the math of how the animation accelerates and decelerates to produce more realistic animation effect. Ease, for instance, starts slow, speeds up around the middle, then slows down at the end - giving the impression of weight in the animation. This part of the value is optional - if left out, it defaults to ease.  Now let\u0026rsquo;s reload and check out our animation.\n   You can see the improved example here    Way smoother! Feel free to play with the transition values until you find a speed and transition you like.\nKeyframe Animations CSS Animations are a more powerful alternative to transitions. Rather than rely on a change from a beginning state to an end state, animations can be made up of as many in-between states as you like, and offer more control over how the states are animated.\nAnimations achieve this by using sets of keyframes. Where a transition can be specified with one line in the class, an animation works by referencing a set of keyframes that are described separately in the CSS.\nTo keyframe animate a CSS element, two components are needed - the animation structure itself, and then a call to the animation with specific instructions.\nThe following will make our greeting bounce:\n@keyframes bounce { 0% { position: relative; top: 0px; } 50% { position: relative; top: -120px; } 100% { position: initial; top: 0px; } } Here, the keyframe structure is broken up by percentages, 100% being the complete duration of the animation. There can be 2 (0 and 100%) or more keyframes with new set of css properties specified at each point.\nKeyframe animations work best when they are clear, simple, and extensible. Our \u0026lsquo;bounce\u0026rsquo; animation serves a single function - to bounce an element. Keeping it style-neutral allows the animation to be used on lots of different elements.\nNow call it on our #greetings element:\n#greeting:hover { animation-name: bounce; animation-duration: .5s; /* or: 500ms */ animation-iteration-count: 3; animation-direction: normal; /* or: alternate, reverse */ animation-timing-function: ease-out; /* or: ease, ease-in, ease-in-out, linear, cubic-bezier(x1, y1, x2, y2) */ animation-fill-mode: forwards; /* or: backwards, both, none */ animation-delay: 0s; /* or: 0ms */ } The above call runs the animation as soon as we hover over our element.\n animation-delay tells how long to delay animation-name calls the bounce animation. animation-duration tells how long to take.     View the result here    While it is actually bouncing, it doesn\u0026rsquo;t look very natural. There are some more CSS properties that can help!\nTransforms Transforms allow you to rotate, skew, and pivot your HTML elements in 3D space! The result will still be rendered on a 2D canvas, the element will be moved around like it were a physical object. The CSS transform property has almost 2 dozen unique value types.\nLet\u0026rsquo;s start with a basic rotate:\n#greeting:hover { transition: all 1s ease; /* add this line for smooth transition on hover in */ webkit-transform: rotateY(180deg) scale(1.5, 1.5); moz-transform: rotateY(180deg) scale(1.5, 1.5); transform: rotateY(180deg) scale(1.5, 1.5); }    View the result here    The greeting now flips around, showing its reverse side. Note that this is still live text, and a live HTML element!\nObviously, this is just the tip of the iceberg. CSS can be used to create and animate almost anything.\n   Go to transition and animation labs!    Open Source Animation Libraries There are some good open source CSS animation libraries that you can try out.\nHere are a few:\n Animate.css Hover.css It\u0026rsquo;s Tuesday WickedCSS Animations  Summary  CSS Transitions and Animations are cross-browser compatible, simple to implement, and take much fewer resources than JavaScript animations. CSS Transitions are generally simpler than CSS Animations. CSS Animations are generally more powerful and flexible than CSS Transitions. Both CSS Transitions and Animations can make the User Experience much more natural and intuitive.  "
},
{
	"uri": "/python/foundation/variables/",
	"title": "Variables",
	"tags": [],
	"description": "",
	"content": "Variables! This is based on a Monty Python-inspired math problem:\nAssume a swallow weighs 60 grams, and one swallow is capable of carrying 1/3 of its own weight.\nA variable provides us with a way to label and access information. Variables are used as labels to store values in memory. Memory is allocated the moment you declare the variable.\nDeclaring a variable has a specific syntax:\nswallow_limit = 60 / 3 Once we create our variable, we can reference it and get the value we stored. This means we can write more organized code!\nThe variable above is called swallow_limit and the single = sign is telling the program to store the value on the right side of the equation to memory. The value we\u0026rsquo;re telling it to store is the float equation 60 / 3, which is 20.0.\nNaming Conventions Variable names cannot have spaces or start with digits/special characters. Variables can start with an underscore _, a lowercase letter as in our example swallow_limit or with a capital letter such as Swallow_limit. According to the pep8 style guide, you should have all lowercase letters.\n   Variable Name Valid? pep8 approved? Comments     myName yes no This is the camelCase convention (capitalize the first letter of every word that comes after the first word). This goes against the pep8 style guide though.   1name no no This variable starts with a number which is not allowed.   int yes no This Python built-in function is technically allowed as a variable name, but is frowned upon. Its attempted usage may yield unexpected behavior, as the statement int(x) changes an object x to be type int.   else no no This is an element of the basic syntax in Python (a keyword). Using a keyword as a variable name is a syntax error. Other common keywords are for, if, not, return, and def.   my_name yes yes This variable name follows the rules of Python and pep8!    Variables are case sensitive so if you decide to capitalize the first letter of your variable, be careful not to try to refer to it using the opposite case. It simply won\u0026rsquo;t work.\nNot only do variables make your code more organize, it makes it more readable by assigning meaning to values.\nIf we take our previous example, and we know that swallow_limit = 60 / 3, then we can re-write our previous equation with variables:\nswallow_limit = 60 / 3 swallows_per_cherry = 8 / swallow_limit Type the above code into Python Console. Then type swallows_per_cherry and press return\nYou should get the output of 0.4, which is the same figure we got from doing the equation in the previous section.\nCasting variables If you wanted to know how many full grams that a swallow can hold, you would need to cast the variable. To cast is to change a variable from one type to another. In this case, we want to change our floating point number to an integer. To do this, we would do the following syntax:\ntype_you_want(variable_you_want_to_change) To change the swallow_limit variable to an int you would do the following:\nswallow_limit = int(swallow_limit) This would \u0026ldquo;chop off\u0026rdquo; the decimal, and give swallow_limit the new value of 20 rather than 20.0.\nGo to Math and Variables Exercises\n"
},
{
	"uri": "/python/foundation/math-variables-labs/",
	"title": "Variables Labs",
	"tags": [],
	"description": "",
	"content": "An introduction to IDLE, math functions and variables\nMath and Variables Exercises Swallow Exercise  Can a swallow carry a coconut?\nThis Monty Python-inspired math problem\nAssuming a swallow weighs 60 grams, and one swallow is capable of carrying 1/3 of its own weight\u0026hellip; Can a swallow carry a coconut, average weight being 1450 grams?\n Write the equation to determine how many grams total a single swallow is capable of carrying, include the answer. Write the equation to determine how many swallows it will take to carry a coconut weighing 1450 grams. Write the above equation in a single line, instead of two separate steps, and include the answer.  Answer:\n 60 grams / 3 = 20 grams 1450 / (60 / 3) 1450 grams / 20 grams = 72.5 swallows  What other fruit can a swallow carry?\nSwallows per coconut: 1450 / (60 / 3) = 72.5\nSwallows per apple: 128 / (60 / 3) = 6.4\nSwallows per cherry: 8 / (60 / 3) = 0.4\nAfter all of our intensive calculations, we\u0026rsquo;ve finally found that a single swallow has the ability to carry a cherry!\nIf we look at our equations, we can see a lot of repetition. One thing programmers hate is repeating their code over and over so they use a handy-dandy thing called a variable to make equations (and code) easier to read and write. Which part of the three above equations is being repeated?\nAnswer\n(60 / 3)\nMacaw Exercise  Can a macaw carry a coconut?\nUsing IDLE, declare a variable for each value and find out the macaw\u0026rsquo;s carrying limit:\n The percentage of the weight they can carry (Given value: 1/3) The coconuts weight (Given value: 1450) The macaw\u0026rsquo;s weight (Given value: 900) Variable for number of macaws required Print the number of macaws required to carry a coconut  Answer\n carrying_weight_percentage = 1/3 coconut_weight = 1450 macaw_weight = 900 macaw_limit = macaw_weight * carrying_weight_percentage number_macaws = coconut_weight/macaw_limit number_macaws  Ultimately, we need 4.8 macaws to carry a coconut. This gives us a more difficult issue, since we can\u0026rsquo;t summon 0.8 of a bird, so we\u0026rsquo;d like to be able to round that number up for a more reasonable answer we can actually work with.\nWrite our first program Python has many modules at our disposal which can a make more difficult math problems seem like a breeze. In order to use any module in Python, we import it like so:\nimport math Open the project python-foundations, then create a new Python file math_variables.py.\nType import math on the first line of the file. We can look at the math module documentation to on check which function we want to use for our specific problem: Python Math Library Documentation\nYou don\u0026rsquo;t have to scroll down very far on the page to see that the math library offers a math.ceil() function which will return the smallest number greater than or equal to the value you put inside the parenthesis.\nLet\u0026rsquo;s try it! In your file, type out and run the following:\nimport math num_macaws = 4.8 math.ceil(num_macaws) We see that the program runs, but it\u0026rsquo;s not giving us any output. In order to actually see our result, we have to use a function we haven\u0026rsquo;t introduced yet: the print() function. Re-run the program but put math.ceil(num_macaws) inside a print() function, and view the output.\nOur entire macaw program looks like this:\nimport math carrying_weight_percentage = 1/3 coconut_weight = 1450 macaw_weight = 900 macaw_limit = macaw_weight * carrying_weight_percentage number_macaws = coconut_weight/macaw_limit print(math.ceil(number_macaws)) Go to String Formatting and Input Function Lesson\n"
},
{
	"uri": "/golang/testing/go-mock/",
	"title": "Golang Mocks, Stubs and Spies",
	"tags": [],
	"description": "",
	"content": "Objectives  Rehash of Dependency Injection and how its important to Mocks, Stubs and Spies Why using mocking The difference between a mock and a stub Generating mocks, stubs and spies with:  Go\u0026rsquo;s built-in mock package gomock\u0026rsquo;s mockgen testify\u0026rsquo;s mock package    Goals Become familiar with stubs, mocks, and spies. What they are, how to use them to unit test a package, how to build them, and when to use them.\nReview of DI (Dependency Injection) When we use Dependency Injection, we can make sure that we are using separation of concerns, allowing our code to be reusable, and making our code more easily testable.\nIf ever code is doing too much, like generating data and determining where it goes, most likely these concerns need to be split. Example, handling http requests and doing domain level logic should be split into separate functions or even packages.\nIf a function accepts dependencies, such as an io.Writer, it makes that function more reusable. It could write out to STDOUT, a file, or even to an http writer.\nBy injecting our dependencies we also make it easier to unit test a specific functionality. We can then use mocks to provide isolation and introspection.\nWhy Mocks, Stubs, and Spies? Mocks \u0026amp; Stubs are used to replace dependencies when (unit) testing a specific functionality. This allows our tests to focus on one unit.\nTake the above example. We could receive false failures if the network were to go down from the database, or in one of our dependent packages.\nTo illustrate this point, think about a science experiment. To achieve success, the tests need to be run in an isolated, controlled environment. Imagine testing how vinegar reacts to different minerals. You would want the minerals to be the only thing different in each test. You\u0026rsquo;d want to keep the amount of vinegar, the temperature, the container size and shape all to remain the same.\nIn the same way, mocks and stubs help to create a standard environment. Allowing us to test only the unit in question.\nIn other words, using a mock or stub allows us to have full control over controlled (fake) dependencies, while avoiding unexpected faults and failures upstream or downstream.\nUsing mocks can also greatly reduce the time it takes to run tests. Consider an application that is responsible for the following tasks:\n handling requests connecting to a database using other micro-services  Now, consider the amount of time it takes to run all of these services during each test.\nMocking can also allow us to have more test coverage. It can tend to be difficult to bring out error conditions and exceptions are difficult to simulate.\nDifference between Mocks and Stubs Mocks and stubs have the same intention, to substitute a real dependency while unit testing a specific functionality. It can be a fake package, custom type (int, struct, interface, etc.) that is incoming to the function or package that you\u0026rsquo;re testing.\nStubs A stub is a fake dependency used during a test to supplement the real dependency. It makes the assumption that it will be used in this one test and only in this one test. It usually has hardcoded settings for this purpose.\nTake the below function. It accepts a custom struct as an argument.\n// CalculateSalesTax takes in a custom object Product which has an attrribute // sales price. Multiplies the sales price by the sales tax and // returns the product of these two factors. func (s SalesData) CalculateSalesTax(product product.Product) (float64, error) { if product.Price \u0026lt; 0 { return -1, errors.New(\u0026#34;Sales price must be a positive number\u0026#34;) } return s.rate * product.Price, nil } For the test we can create a one time use stub, which also includes mock data.\nproductmock.go\npackage productmock type Product struct { Name string Price float64 } func CreateMockProducts() []Product { return []Product{ Product{Name: \u0026#34;Paint, Gallon - return Gallon\u0026#34;, Price: -10.00}, Product{Name: \u0026#34;Paint, trial\u0026#34;, Price: 0.00}, Product{Name: \u0026#34;Paint, pint\u0026#34;, Price: 5.00}, Product{Name: \u0026#34;Paint, gallon\u0026#34;, Price: 10.00}, Product{Name: \u0026#34;Autopainter\u0026#34;, Price: 12000.00}, } } Mocks A mock is like a stub, but allows for config, so it can be setup for different scenarios. Let\u0026rsquo;s say you have a core package, that is used by several of your other packages. You could reuse the mock for this package, in unit testing each package that consumes it. For the above example we could make this mock configurable so that it could be used by other packages.\nLet\u0026rsquo;s say that the cart package also relies on the product package. It\u0026rsquo;s needs are slightly different. It needs the ability to have the department attribute and have mock data from different departments, while the sales tax test doesn\u0026rsquo;t. That test is fine having products with varying costs. So\u0026hellip; Maybe you\u0026rsquo;re thinking we\u0026rsquo;ll just add more products? If we do that for every test that consumes this mock, then each test would receive many more products than it needs, thus making all the tests take longer. Instead we can configure this stub into a mock, so that we only get the type of diversity we need for each test.\ntype Product struct { Name string Price float64 Department string } func CreateMockProducts(testDiversity string) []Product { mockProducts := []Product{} priceDiversity := []Product{ Product{Name: \u0026#34;Paint, Gallon - return Gallon\u0026#34;, Price: -10.00}, Product{Name: \u0026#34;Paint, trial\u0026#34;, Price: 0.00, Department: \u0026#34;paint\u0026#34;}, Product{Name: \u0026#34;Paint, pint\u0026#34;, Price: 5.00, Department: \u0026#34;paint\u0026#34;}, Product{Name: \u0026#34;Paint, gallon\u0026#34;, Price: 10.00, Department: \u0026#34;paint\u0026#34;}, Product{Name: \u0026#34;Autopainter\u0026#34;, Price: 12000.00, Department: \u0026#34;paint\u0026#34;}, } departmentDiversity := []Product{ Product{Name: \u0026#34;Paint, Gallon - return Gallon\u0026#34;, Price: -10.00, Department: \u0026#34;paint\u0026#34;}, Product{Name: \u0026#34;Hammer, steel, DEWALT\u0026#34;, Price: 24.97, Department: \u0026#34;tools\u0026#34;}, Product{Name: \u0026#34;Grill, 3-burner propane, Weber\u0026#34;, Price: 449.00, Department: \u0026#34;Outdoors\u0026#34;}, Product{Name: \u0026#34;Chennai White Wash King Platform Bed\u0026#34;, Price: 1299.00, Department: \u0026#34;Furniture\u0026#34;}, } if strings.Contains(testDiversity, \u0026#34;prices\u0026#34;) { mockProducts = append(mockProducts, priceDiversity...) } if strings.Contains(testDiversity, \u0026#34;department\u0026#34;) { mockProducts = append(mockProducts, departmentDiversity...) } return mockProducts } What is a spy? It\u0026rsquo;s logical for the word spy to evoke images of undercover agents in foreign lands. In reality, the concept isn\u0026rsquo;t too different from a spy in unit tests.\nA spy is a function that infiltrates your code, pretends to fit in, and reports it\u0026rsquo;s findings.\nThe primary use of a spy is to gather information about specific function calls. Which can be useful for finding out:\n If a particular function has been called How many times a function is called The arguments supplied on invocation  Mocking problems Mocks that depend heavily on reflection can be very slow. Mocks that are slower than the interactions between two units can cause the tests to get lengthy.\nMocks that need mocks that need mocks. This can lead to complicated setups. This can also lead to mocking systems that get tightly coupled to implementation details. Remember: TEST TO BEHAVIOR, NOT IMPLEMENTATION.\nMocking every package interaction forces an exponential growth of polymorphic interfaces. This is over-abstraction and \u0026ldquo;design damage.\u0026rdquo;\nToo much mocking can lead to tests that are slow, fragile and super complicated.\nIf you\u0026rsquo;re having to mock too many things, or its getting really complicated, keep these things in mind:\n The package you\u0026rsquo;re tesing does too many things, then abstract it. Too many tiny dependencies, then think about grouping some in a logical way. Over abstraction is a thing! Test is too concerned with Implementation, then favor testing the behavior, and remove testing for implementation details.  Demo App Demo Setup\n If you have not already, Fork https://github.homedepot.com/om-labs/go-testing to your homedepot profile Clone down your newly forked repo cd into the go-testing/samples/goorderupdate directory Follow the explanations found in the README  gomock Gomock is a mocking framework for Go.\nSetup You can download and install gomock with the following commands:\ngo get github.com/golang/mock/gomock go install github.com/golang/mock/mockgen mockgen gomock has a method called mockgen.\nmockgen has two modes, source and reflect.\nReflect mode generates mock interfaces by building a program that uses reflection to understand interfaces. It is enabled by passing two non-flag arguments: an import path, and a comma-separated list of symbols.\nFor example: mockgen database/sql/driver Conn,Driver\nWe can use the source mode of mockgen to create our Data Access Layer mock.\nmockgen -source=dal.go If we were to run the above command in the go-testing/samples/goorderupdate/dal directory from the above demo, a file with a mock will be generated and printed to STDOUT.\nGomock options gomock takes several arguments that we can pass to it to specify how to make the mock or what to do with the output.\n -destination File in which to put our output. -source File in which to mock. -package The package to use for the resulting mock class source code. If you don\u0026rsquo;t set this, the package name is mock_ concatenated with the package of the input file. In our case, it would be mock_dal; -imports A list of explicit imports that should be used in the resulting source code, specified as a comma-separated list of elements of the form foo=bar/baz, where bar/baz is the package being imported and foo is the identifier to use for the package in the generated source code.  There are other options, that you can view in the documentation by using the following command:\ngo doc github.com/golang/mock/gomock If we were to run the below command, the generated mock would be created in the current directory:\nmockgen -source=dal.go -destination=dal_mock.go Assert called with gomock We can assert that the GetUpdatedOrders method will be called with a specific parameter. Here we\u0026rsquo;re expected it to be called with the int 99.\nm.EXPECT().GetUpdatedOrders(gomock.Eq(99)).Return(mockorders).AnyTimes() Stubbing with gomock We can also use gomock as a stub, and not make any assertions.\n// Send mock orders, and let this function be called as many times as it needs. m.EXPECT().GetUpdatedOrders().Return(mockorders).AnyTimes() testify\u0026rsquo;s mock package The github.com/stretchr/testify module has a mock package.\nTo install you can run the go get command:\ngo get github.com/stretchr/testify Testify\u0026rsquo;s mock package provides some methods that can be used to help you write your mocks, and make assertions. It is not an auto mock generator, much like gomock.\nLab Setup\n If you have not already, Fork https://github.homedepot.com/om-labs/go-testing to your homedepot profile Clone down your newly forked repo cd into the go-testing/mocking directory Follow the instructions found in the README  Conclusion Sometimes we test too high, and sometimes we test too low. Where to start in all the muddle? Here are some guidelines to keep in mind:\n Refactoring means code changes but behavior stays the same. Therefore, tests should not change too much. Am I testing behaviour I or the implementation details? Avoid testing private functions. Did I need more than 3 mocks? If yes, maybe rethink your design. Use spies with caution. Spies let you see the insides of the algorithm you are writing which can be very useful but that means a tighter coupling between your test code and the implementation. Be sure you actually care about these details if you\u0026rsquo;re going to spy on them  Resources:  When To Mock Learn Go with Tests (mocking)  "
},
{
	"uri": "/web-essentials/webmastery-foundations/transitions-and-animation-lab/",
	"title": "Transitions and Animations Labs",
	"tags": [],
	"description": "",
	"content": "Build a Smooth Accordion Here is some starter code for an accordion (taken from Paul Hayes article Creating an accordion using CSS transitions).\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;!-- Article: https://paulrhayes.com/2009-06/accordion-using-only-css/ --\u0026gt; \u0026lt;!-- Demo: https://paulrhayes.com/experiments/accordion/ --\u0026gt; \u0026lt;!-- Originally posted: 25th June 2009 --\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge,chrome=1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;CSS3 Accordion \u0026amp;mdash; Paul Hayes\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;author\u0026#34; content=\u0026#34;Paul Hayes\u0026#34; /\u0026gt; \u0026lt;link rel=\u0026#34;canonical\u0026#34; href=\u0026#34;https://paulrhayes.com/experiments/accordion/\u0026#34; /\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;accordion-starter.css\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body class=\u0026#34;experiment\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;accordion\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Accordion Demo\u0026lt;/h2\u0026gt; \u0026lt;div id=\u0026#34;one\u0026#34; class=\u0026#34;section\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;\u0026lt;a href=\u0026#34;#one\u0026#34;\u0026gt;Heading 1\u0026lt;/a\u0026gt;\u0026lt;/h3\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;two\u0026#34; class=\u0026#34;section\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;\u0026lt;a href=\u0026#34;#two\u0026#34;\u0026gt;Heading 2\u0026lt;/a\u0026gt;\u0026lt;/h3\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;three\u0026#34; class=\u0026#34;section\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;\u0026lt;a href=\u0026#34;#three\u0026#34;\u0026gt;Heading 3\u0026lt;/a\u0026gt;\u0026lt;/h3\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;four\u0026#34; class=\u0026#34;section large\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;\u0026lt;a href=\u0026#34;#four\u0026#34;\u0026gt;Heading 4\u0026lt;/a\u0026gt;\u0026lt;/h3\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;five\u0026#34; class=\u0026#34;section\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;\u0026lt;a href=\u0026#34;#five\u0026#34;\u0026gt;Heading 5\u0026lt;/a\u0026gt;\u0026lt;/h3\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; /* CSS3 Accordion Experiment Date: 25th June 2009 Author: Paul Hayes */ .accordion { background: #eee; border: 1px solid #999; padding: 0 1em 24px; width: 500px; margin: 2em auto; } .accordion h2 { margin: 12px 0; } .accordion .section { border-bottom: 1px solid #ccc; padding: 0 1em; background: #fff; } .accordion h3 a { display: block; font-weight: normal; padding: 1em 0; } .accordion h3 a:hover { text-decoration: none; } .accordion h3 + div { height: 0; overflow: hidden; /* TODO: add transition here */ } .accordion :target h3 a { text-decoration: none; font-weight: bold; } .accordion :target h3 + div { height: 100px; } .accordion .section.large:target h3 + div { overflow: auto; } Create a project with the previous code and then edit the CSS file to make the accordion use CSS transitions to smoothly open and close the accordion panes.\nHere is a demo of the solution.\nCSS Animations Challenges  Clone this repo: git clone https://github.com/Ringen/css-animations.git cd into the directory : cd css-animations run yarn (from the command line) to install dependencies + \u0026gt; this may take a few minutes run yarn build-css to compile the css run open index.html to view the exercises  Each exercise will have an example and a link to a codepen where you can add in the missing code. Spend 5-10 minutes researching and experimenting with each example.\nAdditional Resources  Example of using animation-direction CSS Transitions vs. Animations 15 Inspiring Examples of CSS Animation Paul Hayes Experiments in CSS Creating an accordion using CSS transitions  demo   An analogue clock using only CSS  demo   Create an auto-scrolling parallax effect without JavaScript  demo   Creating a 3D Cube using 2D CSS transformations  demo demo with multiple cubes   Creating an animated 3D CSS cube using 3D transforms  demo    "
},
{
	"uri": "/golang/",
	"title": "Go",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Go Offerings "
},
{
	"uri": "/javascript/performance/universal-rendering-lab/bonus/",
	"title": "Bonus",
	"tags": [],
	"description": "",
	"content": "We finished early! Is there anything else that we can do to improve the performance of our application? Yes!\nNotice how the fonts flash when we load our application? The fonts are being fetched via an import within uxfont.css. Let\u0026rsquo;s see if we can fix that.\nWe can use CSS preload to fetch the fonts while our HTML is being parsed. See more about preload here: https://developer.mozilla.org/en-US/docs/Web/HTML/Preloading_content\napp.get(\u0026#39;/\u0026#39;, async (req, res) =\u0026gt; { const { markets, pageInfo } = await fetchMarketsAndPageInfo(); res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; // Preload fonts start \u0026lt;link rel=\u0026#34;preload\u0026#34; href=\u0026#34;https://designsystem.homedepot.com/uxicon/fonts/uxicon.ttf?3rmk26\u0026#34; as=\u0026#34;font\u0026#34; type=\u0026#34;font/ttf\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;preload\u0026#34; href=\u0026#34;https://designsystem.homedepot.com/uxicon/fonts/uxicon.woff?3rmk26\u0026#34; as=\u0026#34;font\u0026#34; type=\u0026#34;font/woff\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;preload\u0026#34; href=\u0026#34;https://designsystem.homedepot.com/uxicon/fonts/uxicon.svg?3rmk26#uxicon\u0026#34; as=\u0026#34;font\u0026#34; type=\u0026#34;font/svg\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;preload\u0026#34; href=\u0026#34;https://designsystem.homedepot.com/uxicon/fonts/uxicon.eot?3rmk26\u0026#34; as=\u0026#34;font\u0026#34; type=\u0026#34;font/eot\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;preload\u0026#34; href=\u0026#34;https://designsystem.homedepot.com/uxicon/fonts/uxicon.eot?3rmk26#iefix\u0026#34; as=\u0026#34;font\u0026#34; type=\u0026#34;font/eot\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; // Preload fonts end \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt; ${ uxFontCss }${ uxIconsCss }${ uxStyleGuideCss }${ appCss }\u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;${ renderToString(\u0026lt;App markets={ markets }pageInfo={ pageInfo } /\u0026gt;) }\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt;window.__INITIAL_DATA__ = ${ JSON.stringify({ markets, pageInfo }) }\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt;${ clientBundleJS }\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); }); Reload the app and view the difference!\n"
},
{
	"uri": "/react/performance/universal-rendering-lab/bonus/",
	"title": "Bonus",
	"tags": [],
	"description": "",
	"content": "We finished early! Is there anything else that we can do to improve the performance of our application? Yes!\nNotice how the fonts flash when we load our application? The fonts are being fetched via an import within uxfont.css. Let\u0026rsquo;s see if we can fix that.\nWe can use CSS preload to fetch the fonts while our HTML is being parsed. See more about preload here: https://developer.mozilla.org/en-US/docs/Web/HTML/Preloading_content\napp.get(\u0026#39;/\u0026#39;, async (req, res) =\u0026gt; { const { markets, pageInfo } = await fetchMarketsAndPageInfo(); res.send(` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#000000\u0026#34;\u0026gt; \u0026lt;title\u0026gt;React App\u0026lt;/title\u0026gt; // Preload fonts start \u0026lt;link rel=\u0026#34;preload\u0026#34; href=\u0026#34;https://designsystem.homedepot.com/uxicon/fonts/uxicon.ttf?3rmk26\u0026#34; as=\u0026#34;font\u0026#34; type=\u0026#34;font/ttf\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;preload\u0026#34; href=\u0026#34;https://designsystem.homedepot.com/uxicon/fonts/uxicon.woff?3rmk26\u0026#34; as=\u0026#34;font\u0026#34; type=\u0026#34;font/woff\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;preload\u0026#34; href=\u0026#34;https://designsystem.homedepot.com/uxicon/fonts/uxicon.svg?3rmk26#uxicon\u0026#34; as=\u0026#34;font\u0026#34; type=\u0026#34;font/svg\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;preload\u0026#34; href=\u0026#34;https://designsystem.homedepot.com/uxicon/fonts/uxicon.eot?3rmk26\u0026#34; as=\u0026#34;font\u0026#34; type=\u0026#34;font/eot\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;preload\u0026#34; href=\u0026#34;https://designsystem.homedepot.com/uxicon/fonts/uxicon.eot?3rmk26#iefix\u0026#34; as=\u0026#34;font\u0026#34; type=\u0026#34;font/eot\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; // Preload fonts end \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt; ${ uxFontCss }${ uxIconsCss }${ uxStyleGuideCss }${ appCss }\u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; You need to enable JavaScript to run this app. \u0026lt;/noscript\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;${ renderToString(\u0026lt;App markets={ markets }pageInfo={ pageInfo } /\u0026gt;) }\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt;window.__INITIAL_DATA__ = ${ JSON.stringify({ markets, pageInfo }) }\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt;${ clientBundleJS }\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `); }); Reload the app and view the difference!\n"
},
{
	"uri": "/react/foundations/state-with-classes/",
	"title": "Component State with JS Classes",
	"tags": [],
	"description": "",
	"content": "Writing Container (stateful) Components with JavaScript Classes.\n NOTE: this is an optional lesson but may be helpful as legacy React code uses JavaScript classes for managing state.\n Introduction  Before React Hooks, stateful components were written with JavaScript classes. The state of the Component was managed in an instance variable called this.state. Updates to the state were done via the inherited method this.setState.  Here is an example of a React Counter component using a JavaScript class:\nCounter.js:\nclass Counter extends React.Component { // React class components extend `React.Component`  constructor(props) { // props are passed to the constructor  super(props); // pass the props to the super constructor  this.state = { // the state is initialized in the constructor  count: 0 // an initial value of `0`  }; } increment() { // methods can be added  this.setState({ // state is updated via `this.setState`  count: this.state.count + 1 // which takes an object containing the new state  }); } decrement() { const newValue = Math.max(0, this.state.count - 1); // we don\u0026#39;t want the count to go negative  this.setState({ count: newValue }); } render() { return ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Counter\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;The count is {this.state.count}\u0026lt;/p\u0026gt; \u0026lt;button onClick={this.decrement.bind(this)}\u0026gt;Decrement\u0026lt;/button\u0026gt; {/* we must `bind` the callback methods */} \u0026lt;button onClick={this.increment.bind(this)}\u0026gt;Increment\u0026lt;/button\u0026gt; {/* we must `bind` the callback methods */} \u0026lt;/div\u0026gt; ); } } export default Counter; Observations:\n First, carefully read the the comments in the code above. Using JavaScript classes for stateful components may feel more familiar to those who have experience with OOP. To read the current state, use this.state. To update the current state, use this.setState({ newStateObject }) When methods are used as callbacks, you must explicitly bind them to the this object,  Or you can use arrow functions as the methods, for example: increment = () =\u0026gt; { ... }    Updates using this.setState are Merged  The object passed to this.setState is merged into the current state. Therefore you only include the desired changes to the state in the object passed to this.setState.  An example:\n// consider having this state this.state = { name: \u0026#39;Homer\u0026#39;, age: 40 }; // to update just the name, leaving the age unmodified, we can do: this.setState({ name: \u0026#39;Homer Depot\u0026#39; }); // likewise to update just the age, leaving the name unmodified: this.setState({ age: this.state.age + 1; }); // you can also update both the name and the age if desired: this.setState({ name: \u0026#39;Homer Depot\u0026#39;, age: this.state.age + 1 }); Recommendation: Use Function Components over JS Class Components We recommend using function components for the following reasons:\n It avoid the complexities of using explicit binding with the callback functions All components are written the same way, making it easier to refactor / add or remove state Code is more concise:  Consider the above Counter component written as a function component:\nimport React, { useState } from \u0026#39;react\u0026#39; function Counter() { const [count, setCount] = useState(0) const increment = () =\u0026gt; setCount(c =\u0026gt; c + 1) const decrement = () =\u0026gt; { setCount(c =\u0026gt; Math.max(0, c-1)) } return ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Counter\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;The count is {count}\u0026lt;/p\u0026gt; \u0026lt;button onClick={decrement}\u0026gt;Decrement\u0026lt;/button\u0026gt; {/* we no longer need to `bind` the callback methods */} \u0026lt;button onClick={increment}\u0026gt;Increment\u0026lt;/button\u0026gt; {/* we no longer need to `bind` the callback methods */} \u0026lt;/div\u0026gt; ); } export default Counter;  The code is reduced from 32 lines to only 19 lines. We don\u0026rsquo;t need this. We can more easily add or remove state as needed.  Lab Do part 2 of the Component State Lab.\nSummary  React supports writing stateful components using either  Function Components with hooks (such as the useState hook) JavaScript Class Components with this.state and this.setState   We recommend using Function Components but you may see JavaScript Class Components in many existing React projects.  "
},
{
	"uri": "/react/foundations/labs/lab-context/",
	"title": "Context",
	"tags": [],
	"description": "",
	"content": "In this lab you will be replacing Prop Drilling with the Context API.\nInstructions for the lab can be found here.\n"
},
{
	"uri": "/react/pillars/perf-opt-strategies/context/",
	"title": "Context API",
	"tags": [],
	"description": "",
	"content": "Background React\u0026rsquo;s Context API provides a way to share values between components without having to explicitly pass a prop through every level of the tree (thus avoiding prop-drilling).\n A Context can be used to share data that can be considered “global” for a tree of React components. Common use-cases include sharing the current authenticated user, a theme, or a preferred language. A Context Provider defines the value to be shared The value can be consumed via a Context Consumer component or via the React.useContext hook Consumer components are re-rendered when  the provider component provides a new value the provider component itself is re-rendered    For a review of the Context API, see: OM Lesson on Context API\nA Quick Example   Using Context and useContext to define a simple API (bonus section) NOTE: This section introduces a nice pattern for managing state. It\u0026rsquo;s not directly related to performance optimization but the pattern is used in the React Performance Playground App and being familiar with it will help you when you work on the lab.\nSteps:\n  Create a file for implementing the Context Provider and the custom hook.\n  Create a Context via React.createContext.\n  Create a Component that:\n creates the required state using useState or useReducer creates any helper functions for managing that state wraps the state and the helper functions into a value object returns the Context.Provider    Create a custom hook that:\n reads the value from useContext using the correct Context instance ensures that the correct Provider has been used returns the value object    Export the Provider and the custom hook\n  Example:\nimport React, { useContext, useState } from \u0026#39;react\u0026#39; const CounterContext = React.createContext() // step 2  function CounterProvider({ children }) { // step 3  const [count, setCount] = useState(0) // step 3a  const inc = () =\u0026gt; setCount(c =\u0026gt; c + 1) // step 3b  const value = { count, inc } // step 3c  return ( // step 3d  \u0026lt;CounterContext.Provider value={value}\u0026gt; {children} \u0026lt;/CounterContext.Provider\u0026gt; } function useCounter() { // step 4  const value = useContext(CounterContext); // step 4a  if (value === undefined) { // step 4b  throw new Error(\u0026#39;useCounter must be used within a CounterProvider\u0026#39;); } return value; // step 4c } export { CounterProvider, useCounter }; // step 5 Here is the above example in action:\n  Problem Using a Context can cause unnecessary re-renders when either:\n the provided value is recreated on each render - i.e. referential equality is not preserved even if the value is the same other state changes trigger the parent component to re-render the Provider component   Because context uses reference identity to determine when to re-render, there are some gotchas that could trigger unintentional renders in consumers when a provider’s parent re-renders. - React Docs\n Solutions  A Context Provider that is managing too much state can be split into multiple Context Providers. Context Providers can be moved up the the component tree to ensure that they are not re-rendered when unrelated state changes occur.  Demo  See the React Performance Optimization Playground App for the \u0026ldquo;Context\u0026rdquo; example. Click on the \u0026ldquo;Context\u0026rdquo; link and then on the \u0026ldquo;Before\u0026rdquo; tab. If you use the non-themed Movie cards, no re-renders occur as you interact with the main component because these components do not consume the theme value. If you click the \u0026ldquo;Use Themed Movie Component\u0026rdquo; checkbox, you will see that the Movie cards are re-rendered when you interact with the main component. This is because this component depends on the Context Provider. But the re-renders occur even when the Provider\u0026rsquo;s value is not changing. But what do we mean by \u0026ldquo;not changing\u0026rdquo;?  the selected theme is not changing but it\u0026rsquo;s reference value is changing because the parent is being re-rendered    Lab - Approximately 20 minutes  Use the React Performance Optimization Playground App for this lab. Navigate to the \u0026ldquo;Context\u0026rdquo; demo and then to the \u0026ldquo;After\u0026rdquo; tab. Make the necessary coding changes to prevent the movie cards from re-rendering when the ContextApp component is re-rendered (and the theme is not changing).  Summary  React\u0026rsquo;s Context API is a good option for managing state that is shared across multiple components in a component tree. Using a Context Provider can cause unnecessary re-renders due to the Provider being re-rendered unnecessarily. You can eliminate these re-renders by moving the Context Provider up higher in the component tree.  "
},
{
	"uri": "/javascript/foundations/control-flow-decisions/",
	"title": "Control Flow - Making Decisions",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Describe Control Flow Discuss how JavaScript makes decisions Identify and discuss boolean operators Use if, else if, and else to control the flow of the program Apply different boolean operators in conditional statements  What is Control Flow?  Control flow is a fundamental concept in programming. Control flow is how a program makes decisions.  Logical Comparison Operators Logical comparison operators compare 2 values and evaluate to a true or false boolean value.\nThe logical comparison operators are:\n   Operator Description     == non-strict equals (possible type coercion)   === strict equals(no type coercion)   != non-strict not-equals (possible type coercion)   !== strict not-equals (no type coercion)   \u0026lt; less than   \u0026lt;= less than or equal   \u0026gt; greater than   \u0026gt;= greater than or equal    The Equality Operators The double equal (==) and not equal (!=) may perform type coercion before performing the comparison. For example:\n42 == \u0026#34;42\u0026#34;; // true after type coercion 42 != \u0026#34;42\u0026#34;; // false after type coercion TThe triple equal and not double equal do not perform type coercion. For example:\n42 === \u0026#39;42\u0026#39; // false 42 !== \u0026#39;42\u0026#39; // true TIP: It is recommended to use strict comparisons in your JavaScript code.\nEquality and Reference Types When working with arrays and objects (which we haven\u0026rsquo;t discussed yet), equality does not work as you might expect. For example:\n[] === [] // false [1, 2, 3] === [1, 2, 3] // false { name: \u0026#39;Homer\u0026#39; } === { name: \u0026#39;Homer\u0026#39; } // false Explanation\n Arrays and objects are composite or reference types. When we compare them for equality, we are comparing their memory locations, not their values.  It\u0026rsquo;s possible for 2 variables to refer to the same memory location and thus will be strictly equal. For example:\nconst x = [1, 2, 3]; const y = x; // assigns y to the same memory location as x console.log(x === y); // true Logical Operators  Logical operators are used to combine two boolean values or invert a boolean value. The logical operators in JavaScript are:  AND denoted \u0026amp;\u0026amp; OR denoted || NOT denoted !    Here are some examples of using the logical operators.\n.logical operators\nfalse \u0026amp;\u0026amp; false; // false false \u0026amp;\u0026amp; true; // false true \u0026amp;\u0026amp; false; // false true \u0026amp;\u0026amp; true; // true  false || false; // false false || true; // true true || false; // true true || true; // true  !false; // true !true; // false  !!false; // false !!true; // true These logical operators are most commonly used in Conditionals, which we will look at next.\nConditionals  Conditionals are a way of deciding whether to execute or skip over a block of code. Conditionals make this decision based on a boolean expression. If the boolean expression is true then the block of code is executed.  For example, if (expr) { code } will run the code block if the expr is true.\nconst num = 22; if (num % 2 === 0) { console.log(\u0026#34;is even\u0026#34;); } You can add an else or even an else if after an if block:\nconst expr1 = true; const expr2 = true; if (expr1) { console.log(\u0026#34;expr1 is true!\u0026#34;); } else if (expr2) { console.log(\u0026#34;expr2 is true!\u0026#34;); } else { console.log(\u0026#34;nothing is true!\u0026#34;); } The above example will print expr1 is true and the else if is never reached. If expr1 is false it would only print expr2 is true.\nConditionals and Logical Operators Here are some examples of using Logical Operators with Conditionals\nExample:\nconst x = -3; const y = 10; if (x \u0026lt; 0 \u0026amp;\u0026amp; y \u0026lt; 0) { console.log(\u0026#39;Both are negative\u0026#39;); } else if (x \u0026lt; 0 || y \u0026lt; 0) { console.log(\u0026#39;Only one is negative\u0026#39;); } else { console.log(\u0026#39;Both are positive\u0026#39;); } Example:\nconst isWeekend = true; const isSummer = false; if (isWeekend \u0026amp;\u0026amp; isSummer) { console.log(\u0026#39;Go swimming\u0026#39;); } else if (isWeekend) { console.log(\u0026#39;Go hiking\u0026#39;); } else { console.log(\u0026#39;Get work done\u0026#39;); } Lab See instructions here.\nTernary Operators Another way to write a very shorthand conditional is using the ternary operator, expr1 ? expr2 : expr3.\nThe following two code snippets accomplish the same thing:\nif (expression) { execute BLOCK_1; } else { execute BLOCK_2; } expression ? BLOCK_1 : BLOCK_2; // accomplishes same thing as the `if` statement above As an example, here is some code that calculates a fee based on whether you are a member\nconst isMember = true; let fee = null; if (isMember) { fee = \u0026#39;$2.00\u0026#39;; } else { fee = \u0026#39;$10.00\u0026#39;; } This code can be rewritten as:\nconst fee = isMember ? \u0026#39;$2.00\u0026#39; : \u0026#39;$10.00\u0026#39;; TIP: Ternary operators are good when we are conditionally setting the value of a variable to one of two possible values.\nThe Switch Statement  a switch statement is similar to a sequence of if / else if / else statements. switch statements can sometimes be easier to read than the equivalent if / else if / else statements.  See switch | MDN for more information.\nSummary  Control flow defines how an application decides on what code should be executed Boolean expressions evaluate to true or false Logical operators can be used to combine multiple boolean expressions or invert a boolean expression Conditionals are used to determine if a block of code should execute based on the provided boolean expression  "
},
{
	"uri": "/web-essentials/webmastery-foundations/responsive-layouts/",
	"title": "CSS Responsive Layouts",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Describe the purpose of responsive layouts. Discuss the role of media queries in responsive web design. Describe the holy grail web page layout.  Skills  Use media queries to adjust the page layout for various screen sizes. Build a responsive website using media queries.  Responsive Website Definition A responsive website responds dynamically to the browser\u0026rsquo;s screen size (or window size) so that the content is always presented in an appealing and easy-to-read layout.\n Much of the material in this lesson has been shamelessly taken from w3schools.\n Why Responsive Responsive websites allow users to visit our site using a multitude of devices each having a different screen size, resolution, and aspect ratio.\nIt is important to keep this in mind when designing websites and media queries help us do that!\n   Device Layout Typical Screen Width     Desktop  1200px and up   Tablet  992px and up   Phone  768px and up    Here is an example that uses floats to create a 12 column grid:\nindex.html:\n\u0026lt;div class=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Chania\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-3 menu\u0026#34;\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;The Flight\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;The City\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;The Island\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;The Food\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-9\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;The City\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Chania is the capital of the Chania region on the island of Crete. The city can be divided in two parts, the old town and the modern city.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Resize the browser window to see how the content respond to the resizing.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; app.css:\n* { box-sizing: border-box; } .row::after { content: \u0026#34;\u0026#34;; clear: both; display: block; } [class*=\u0026#34;col-\u0026#34;] { float: left; padding: 15px; } .col-1 {width: 8.33%;} .col-2 {width: 16.66%;} .col-3 {width: 25%;} .col-4 {width: 33.33%;} .col-5 {width: 41.66%;} .col-6 {width: 50%;} .col-7 {width: 58.33%;} .col-8 {width: 66.66%;} .col-9 {width: 75%;} .col-10 {width: 83.33%;} .col-11 {width: 91.66%;} .col-12 {width: 100%;} html { font-family: \u0026#34;Lucida Sans\u0026#34;, sans-serif; } .header { background-color: #9933cc; color: #ffffff; padding: 15px; } .menu ul { list-style-type: none; margin: 0; padding: 0; } .menu li { padding: 8px; margin-bottom: 7px; background-color :#33b5e5; color: #ffffff; box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24); } .menu li:hover { background-color: #0099cc; } Notice that the webpage in the above example does not look good when you resize the browser window to a very small width. Let\u0026rsquo;s see how we can fix that using media queries.\nWhat is a Media Query? A Media Query is a CSS technique introduced in CSS3. It uses the @media rule to include a block of CSS properties only if a certain condition is true.\nExample The following will make the the background color will change to lightblue, when the browser window is smaller than 500px:\n@media only screen and (max-width: 500px) { body { background-color: lightblue; } } The above media query will be active whenever the following conditions are true:\n we are displaying to a screen (as opposed to a printer) the viewport is at most 500px  If one of the conditions is not true, then the embedded CSS rules will not be active (the background-color will not be lightblue).\nHere is a simple example: Gentle Introduction to Media Queries - Part 1\nLet\u0026rsquo;s look at another example:\n\u0026lt;p class=\u0026#34;small-screen\u0026#34;\u0026gt;This is a small screen\u0026lt;/p\u0026gt; \u0026lt;p class=\u0026#34;medium-screen\u0026#34;\u0026gt;This is a medium screen\u0026lt;/p\u0026gt; \u0026lt;p class=\u0026#34;large-screen\u0026#34;\u0026gt;This is a large screen\u0026lt;/p\u0026gt; .small-screen, .medium-screen, .large-screen { display: none; } @media only screen and (max-width: 399px) { body { background-color: lightblue; } .small-screen { display: block; } } @media only screen and (min-width: 400px) and (max-width: 767px) { body { background-color: lightgreen; } .small-screen { display: none; } .medium-screen { display: block; } } @media only screen and (min-width: 768px) { body { background-color: lightyellow; } .small-screen { display: none; } .medium-screen { display: none; } .large-screen { display: block; } } Here 3 media queries are used to control both the background color of the body and which paragraphs are displayed on the page.\nHere is the codepen for this example\nUsing a Media Query to Add a Breakpoint Media queries are used to control the layout for different size viewports. When the web page is loaded into a browser window, the appropriate media query will be triggered to respond to the size of the viewport.\nSo how do we use media queries to make our CSS more responsive? Remember this example?\nAdd a media query to change the layout of the page whenever the viewport is small:\n/* Let\u0026#39;s add a break point using a media query */ @media only screen and (max-width: 500px) { /* For mobile phones: */ [class*=\u0026#34;col-\u0026#34;] { width: 100%; } } This way creates a breakpoint, a point at which changing the viewport size affects the layout of the page in a specific way that we have defined.\nWe can use media queries to add a breakpoint where certain parts of the layout will behave differently on each side of the breakpoint.\nThis codepen adds a media query to make our previous example more responsive.\nResponsive Holy Grail Layout   The Holy Grail Layout is a common problem in CSS to layout a page and be responsive to different screen sizes\nThe following code is an example of how to use Flexbox in CSS\n\u0026lt;header\u0026gt;\u0026lt;h2\u0026gt;Header\u0026lt;/h2\u0026gt;\u0026lt;/header\u0026gt; \u0026lt;section\u0026gt; \u0026lt;article\u0026gt; \u0026lt;h1\u0026gt;Article contents\u0026lt;/h1\u0026gt; \u0026lt;div class=\u0026#34;contents\u0026#34;\u0026gt; \u0026lt;p\u0026gt;I would not, could not in a tree. Not in a car! You let me be. I do not like them in a box. I do not like them with a fox I do not like them in a house I do mot like them with a mouse I do not like them here or there. I do not like them anywhere. I do not like green eggs and ham. I do not like them, Sam-I-am. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/article\u0026gt; \u0026lt;nav\u0026gt;\u0026lt;h2\u0026gt;Navbar contents\u0026lt;/h2\u0026gt;\u0026lt;/nav\u0026gt; \u0026lt;aside\u0026gt;\u0026lt;h2\u0026gt;Sidebar contents\u0026lt;/h2\u0026gt;\u0026lt;/aside\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;footer\u0026gt;\u0026lt;h2\u0026gt;Footer\u0026lt;/h2\u0026gt;\u0026lt;/footer\u0026gt; body { padding: 2em; background-color: #6D899F; } h1, h2 { text-align: center; } p { text-align: left; } header, footer { background-color: #ffa; padding: 5px; } section { display: flex; flex-wrap: wrap; width: 100%; } article { order: 2; flex: 3; background-color: #BCD39B; } nav { order: 1; flex: 1; background-color: #CE9B64; } aside { order: 3; flex: 1; background-color: #62626D; } article, nav, aside { padding: 1em; } /* mobile layout */ /* @media (max-width: 480px) { */ @media only screen and (max-width: 480px) { section { display: flex; width: 100%; flex-direction: column; } article { order: 1; } nav { order: 2; } aside { order: 3; } } Chrome\u0026rsquo;s Dev Tools provides a nice way to preview how your web page will look on different devices and viewport sizes. To try it out:\n use Chrome to open the above codepen and click on the Change View button to go to the Full page view open Chrome\u0026rsquo;s Dev Tools and click on the Toggle Device toolbar button to see what the above codepen looks like on different devices and viewport sizes.  Remember to use this tool to test your own web sites to see how responsive they are!\nSummary  Responsive layout has become increasingly important as tablets and smart phones have become increasingly popular. We want to design our web site to look great and be UX friendly on any devise. By using modern CSS layout methods (such as media queries and flexbox) we can finally achieve the Holy Grail of web page design!     Go to Responsive Layout Labs    "
},
{
	"uri": "/cloud/containers/docker-fundamentals/docker-artifactory/",
	"title": "Docker and THD Artifactory",
	"tags": [],
	"description": "",
	"content": "Using The Home Depot\u0026rsquo;s Artifactory as an Image Registry\nObjectives  How to appropriately tag your image to push to Artifactory Pushing to Artifactory  Pushing Images to THD Artifactory You will first need to tag your images appropriately in order to push.\nTagging Your Images to be Stored in Artifactory The syntax for tagging an image to be pushed to Artifactory is as follows:\ndocker tag \u0026lt;IMAGE_ID\u0026gt; artprod.mycompany/\u0026lt;DOCKER_REPOSITORY\u0026gt;:\u0026lt;DOCKER_TAG\u0026gt; You can get the image ID by listing your images with docker images\n☁ cloud-stuff [master] docker images REPOSITORY TAG IMAGE ID CREATED SIZE hello-world latest fce289e99eb9 12 months ago 1.84kB Let\u0026rsquo;s say we have a repository called om-cloud-stuff, and a tag of 1.0, we would tag our image with the following:\ndocker tag fce289e99eb9 docker.artifactory.homedepot.com/om-cloud-stuff:1.0 You should now see the tagged image in your image list:\n☁ om-cloud [artifactory-token] ⚡ docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker.artifactory.homedepot.com/om-cloud-stuff 1.0 fce289e99eb9 12 months ago 1.84kB hello-world latest fce289e99eb9 12 months ago 1.84kB  NOTE: You do not need to run the docker tag command if you tagged your image as part of a build or run step.\n Pushing Your Image Now all that is left is to push our tagged image. You can use the same syntax with push, rather than tag:\ndocker push artprod.mycompany/\u0026lt;DOCKER_REPOSITORY\u0026gt;:\u0026lt;DOCKER_TAG\u0026gt; With our image that command would be:\ndocker push docker.artifactory.homedepot.com/om-cloud-stuff All together:\n docker login docker.artifactory.homedepot.com  If not tagged as part of a build   docker tag \u0026lt;image ID\u0026gt; docker.artifactory.homedepot.com/repository:tag docker push docker.artifactory.homedepot.com/repository:tag  One final note is that you can have sub repositories as well. So if we wanted to organize our images a bit more, we could extend the om-cloud-stuff to include an additional level of hello-world by appending it with another slash /.\ndocker.artifactory.homedepot.com/om-cloud-stuff/hello-world:1.0\nLab: Tag and Push Feel free to build your own image or use docker.artifactory.homedepot.com/om-classes/base as your base image for this. This base image is the basic hello-world image you can find on Docker Hub.\n Username/LDAP must be lowercase\n Get the CLASS_ID from your instructor, or use solo if working through the material on your own.\n Tag your image so that it can be pushed to docker.artifactory.homedepot.com/om-classes/CLASS_ID/YOUR_LDAP:n.n.n Log into docker.artifactory.homedepot.com Push your tagged image.  Summary  Pushing images requires authentication via a generated token that is specific to the docker instance of THD artifactory.  "
},
{
	"uri": "/software-eng-essentials/command-line-bash/escalating-kill-script/",
	"title": "Escalating kill scripts",
	"tags": [],
	"description": "",
	"content": "Objectives  A custom escalating kill script Choose your $PATH An enhanced version of the custom kill script  Writing an executable bash script As a practical application of extending the versatile Bash shell, in this section we’re going to write a program that’s very useful: a bash script designed to kill a program as safely as possible.\nEn route, we’ll cover the steps needed to add this script to our command-line shell.\nAs discussed in the Grepping processes lesson, Unix user and system tasks take place within a well-defined container called a process. Sometimes, one of these processes will get stuck or otherwise misbehave, in which case we might need to terminate it with the kill command, which sends a terminate code to kill the process with a given id:\n$ kill -15 12241 (See the discussion in the Grepping processes lesson for more on how to find this id on your system.) Here we’ve used the terminate code 15, which attempts to kill the process as gently as possible (meaning it gives the process a chance to clean up any temporary files, complete any necessary operations, etc.). Sometimes terminate code 15 isn’t enough, though, and we need to escalate the level of urgency until the process is well and truly dead. It turns out that a good sequence of codes is 15, 2, 1, and 9. Our task is to write a command to implement this sequence, which we’ll call ekill (for “escalating kill”), so that we can kill a process as shown below.\nAn example of using ekill\n$ ekill 12241 As preparation for adding ekill to our system, we’ll first make a new directory in our home directory called bin (for “binary”).\n$ mkdir ~/bin (It’s possible that this directory already exists on your system, in which case you’ll get a harmless warning message.) We’ll then change to the bin directory and open a new file called ekill:\n$ cd ~/bin $ code ekill The ekill script itself starts with a “shebang” line (pronounced “shuh-BANG”, from “shell” and “bang”, with the latter being the common pronunciation of the exclamation mark !):\n#!/bin/bash This line tells our system to use the shell program located in /bin/bash to execute the script.\nWhere did /bin/bash come from? How do we know what our shell is?\nBy default, this program is the Bourne shell, or Bash, and in this context a shell script is often called a Bash script.\nWe can confirm this by echoing our shell environment variable\n$ echo $SHELL /bin/bash We can also use the which command to confirm the path of bash.\n$ which bash /bin/bash The which command is quick to find the Path of a particular command. It is useful in the case that you have two files or commands of the same name. For our purpose, it will serve us in finding the Path of the interpreter we want to use for our script.\nDespite appearances, here the hash symbol \\# is not a comment character, which is potentially confusing because # is the character ordinarily used for a Bash comment line. Indeed, the initial version of our script includes several comment lines, as shown below.\nA custom escalating kill script\n#!/bin/bash  # Kill a process as safely as possible. # Tries to kill a process using a series of signals with escalating urgency. # usage: ekill \u0026lt;pid\u0026gt; # Assign the process id to the first argument. pid=$1 kill -15 $pid || kill -2 $pid || kill -1 $pid || kill -9 $pid Apart from the shebang in line 1, all other uses of # introduce comments. Then, Line 8 assigns the process id pid to $1, which in a shell script is the first argument to the command, e.g., 12241 in \u0026laquo;an-example-of-using-ekill\u0026raquo;. Line 9 then uses the “or” operator || to execute the kill command using the code 15 or 2 or 1 or 9, stopping on the first successful kill.\nAfter typing the contents of \u0026laquo;a-custom-escalating-kill-script\u0026raquo; into the script file, one thing you might notice is that the result in your text editor has no syntax highlighting. This is because the name ekill has no filename extension. Although some people would use a name like ekill.sh for shell scripts like this one—which would in fact allow our editor to highlight the syntax automatically—using an explicit extension on a shell script is a bad practice because the script’s name is the user interface to the program. As users of the system, we don’t care if ekill is written in Bash or Ruby or C, so calling it ekill.sh unnecessarily exposes the implementation language to the end-user. Indeed, if we wrote the first implementation in Bash but then decided to rewrite it in Ruby and then in C, every program (and programmer) using the script would have to change the name from ekill.sh to ekill.rb to ekill.c—an annoying and avoidable complication.\nThe ekill script with no syntax highlighting.\n#!/bin/bash  # Kill a process as safely as possible # Tries to kill a process using a series of signals with escalating urgency. # usage: ekill \u0026lt;pid\u0026gt; # Assign the process id to the first argument. pid=$1 kill -15 $pid || kill -2 $pid || kill -1 $pid || kill -9 $pid Even though we’ve elected not to use a filename extension for the ekill script, we’d still like to get syntax highlighting to work. One way for VS Code users is to click on “Plain Text” in the lower right-hand corner of the editor and change the highlighting language to the one we’re using. This requires us to know the language though, and it would be nicer if we could get the editor to figure it out automatically. Happily, we can arrange exactly that, simply by closing the file and opening it again. To do this, click on the X to close the ekill tab (or press kbd:[⌘] + kbd:[W]) and then re-open it from the command line:\n$ code ekill Because of the shebang line in \u0026laquo;a-custom-escalating-kill-script\u0026raquo;, VS Code infers that the file is a Bash script. As a result, the detected file type changes from “Plain Text” to “Shell Script”, and syntax highlighting is activated.\nThe ekill script with syntax highlighting and a new detected file type.\n#!/bin/bash  # Kill a process as safely as possible # Tries to kill a process using a series of signals with escalating urgency. # usage: ekill \u0026lt;pid\u0026gt; # Assign the process id to the first argument. pid=$1 kill -15 $pid || kill -2 $pid || kill -1 $pid || kill -9 $pid At this point, we have a complete shell script, but typing ekill \u0026lt;pid\u0026gt; at the command line still won’t work. To add ekill to our system, we need to do two things:\n Make sure the ~/bin directory is on the system path, which is the set of directories where the shell program searches for executable scripts. Make the script executable.  Choose your $PATH Find the path\n The system searches a list of directories called the path to find the input command.\nThe path is stored in an environment variable called $PATH.\n $ echo $PATH Passing the $PATH environment variable as an argument to the echo command shows the path.\n$ echo $PATH /Users/KXB0QJK/.rbenv/shims:/Users/KXB0QJK/workspace:/Users/KXB0QJK/bin:/usr/local/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin The list of directories on the path can be accessed via the special $PATH variable at the command line:\nSearch the path for the command\n$ echo $PATH If ~/bin is on the list, you can skip this step, but it does no harm to follow it.\nNote: The literal directory ~/bin won’t appear in the $PATH list; instead the tilde will be expanded to your particular home directory. For me, ~/bin is the same as /Users/KXB0QJK/bin, so that’s what appears in my PATH, but it will be different for you.\nTo make sure ~/bin is on the path, we’ll edit the Bash profile file. (We learned about Bash profile in a lesson.)\nOpen ~/.bash_profile as follows:\nOpening the file with Visual Studio Code text editor\n$ code ~/.bash_profile Then add the export line shown in below.\nAdding ~/bin to the path.\n~/.bash_profile\nalias lr=\u0026#39;ls -hartl\u0026#39; export PATH=\u0026#34;~/bin:$PATH\u0026#34;  You may find it faster to append the highlighted export PATH... line to the ~/.bash_profile line from the command line using the \u0026gt;\u0026gt; operator.\n This uses the Bash export command to add ~/bin to the current path. (It’s worth noting that some systems use the environment variable $HOME in place of ~, but the two are synonyms. If for any reason ~ doesn’t work for you, it’s worth trying $HOME instead, as in $HOME/bin:$PATH.)\nTo use it, we need to use source as we did in the Bash profile lesson:\n$ source ~/.bash_profile Execute To make the resulting script executable, we need to use the “change mode” command chmod to add the “execute bit” x as follows:\n$ chmod +x ~/bin/ekill // To do: Add blurb about permissions, and making scripts \u0026ldquo;executable\u0026rdquo;?\nAt this point, we can verify that the ekill script is ready to go using the which command:\n$ which ekill // To do: is \u0026ldquo;path\u0026rdquo; covered sufficiently? [TIP] Recall that the which command is quick to find the Path of a particular command. It is useful in the case that you have two files or commands of the same name.\nThe result should be the full path to ekill, which on my system looks like this:\n/Users/KXB0QJK/bin/ekill An enhanced version of the custom kill script As you can see by typing ekill by itself at the command line, the current behavior is confusing if we neglect to include a process id:\n$ ekill \u0026lt;confusing error message\u0026gt; To make ekill friendlier in this case, we’ll arrange to print a usage message to the screen if the user neglects to include a process id. It is a good idea to practice typing this in rather than copying and pasting.\nAn enhanced version of the escalating kill script\n~/bin/ekill\n#!/bin/bash # Kill a process as safely as possible. # Tries to kill a process using a series of signals with escalating urgency. # usage: ekill \u0026lt;pid\u0026gt; # If the number of argument is less than 1, exit with a usage statement. if [[ $# -lt 1 ]]; then echo \u0026#34;usage: ekill \u0026lt;pid\u0026gt;\u0026#34; exit 1 fi # Assign the process id to the first argument. pid=$1 kill -15 $pid || kill -2 $pid || kill -1 $pid || kill -9 $pid After adding the code in \u0026laquo;an-enhanced-version-of-the-escalating-kill-script\u0026raquo;, running ekill without an argument should produce a helpful message:\n$ ekill usage: ekill \u0026lt;pid\u0026gt; All we have left to do is to verify that ekill can actually be used to kill a process. This is left as an exercise.\nExercises\nLet’s test the functionality of ekill by making a process that hangs and applying the lessons from grepping processes in the Inspecting Files lesson. We’ll start by opening two terminal tabs. In one tab, type tail to get a process that just hangs. In the other tab, use ps aux | grep tail to find the process id, then run ekill \u0026lt;pid\u0026gt; (substituting the actual id for \u0026lt;pid\u0026gt;). In the tab running tail, you should get something like “Terminated: 15”.\n Write an executable script called hello that takes in an argument and prints out “Hello” followed by the argument. Be sure to chmod the script so it can run properly. + Hint: Use the echo command. + Bigger hint: Bash scripts interpolate dollar-sign variables into strings, so the $1 variable from \u0026laquo;a-custom-escalating-kill-script\u0026raquo; can be used in a string like this: \u0026quot;Hello, $1\u0026quot;  Summary  A custom escalating kill script Choose your $PATH An enhanced version of the custom kill script  "
},
{
	"uri": "/golang/foundations/function-intro/",
	"title": "Functions in Go",
	"tags": [],
	"description": "",
	"content": "Functions in Go Learning Objectives Concepts  Create and use basic functions Create and use functions with multiple return values Built in defer function  Skills  Creating basic functions Understand how to take input and return output Understand how to receive and return multiple return values in a function  What is a Function? A function:\n Is an invokable block of code that preforms some action, or actions May take none to many inputs Return none to many outputs. Can be a value  Functions you\u0026rsquo;ve already seen  Println from the fmt package The main function  Syntax of a function:\nfunc name([0 or more typed parameters]) ([return-type(s)]) Function Characteristics and Naming Rules  Function names are unique per package There are no overloaded functions/method in go Function names follow the same naming rules as variables Functions can be anonymous ( Discussed more in the Closures Section ) Functions are able to be passed as values and assigned to variables  Simple Functions Void functions are functions that do not return a value.\nDeclaring and Invoking a Simple Function\nfunc myFunction(){ fmt.Println(\u0026#34;I don\u0026#39;t do much, but I do it well\u0026#34;) } func main(){ myFunction() } Try Me\n Define the function Invoke the function.  Functions With Input Function parameters are\n Defined within the name() of a function definitions Must be typed as any other variable Must be used assigned in that order when being invoked  Example of a function that takes input\nfunc myFunction(part1 string, part2 string) { fmt.Println(part1, part2) } func main() { myFunction(\u0026#34;Hello,\u0026#34;, \u0026#34; World\u0026#34;) } Try Me\n Declare myFunction to take 2 arguments as strings. Using the arguments as input to the fmt.Println function. Invoking the function with two values.  Alternative short declaration of arguments:\nWhen you have multiple values of the same type defined in your functions signature, you can combine them as you would a variable\nTaking Arguments of the Same Type\nfunc myFunction(part1, part2 string) { fmt.Println(part1, part2) } Functions With a Return Value Syntax:\nfunc \u0026lt;name\u0026gt; ( [param name type] ) \u0026lt;return name\u0026gt; \u0026lt;type\u0026gt; When a function signature is defined with a return type it must return a value of the type(s) defined.\nReturning a value\nfunc AddTwoNums(a, b int, name string) string { ( c := a + b return fmt.Sprintf(\u0026#34;%s: %d\u0026#34;, name, c) } func main() { result := AddTwoNums(2, 2, \u0026#34;Two numbers added\u0026#34;) fmt.Println(result) } Try Me\n Declare the function that takes 2 integers, and a string, and returns a string. Uses the return key word to return the value that follows. In this case, the output of fmt.Sprintf which returns a string itself. So our return also returns that string. Invokes the declared function.  Named \u0026amp; Naked Returns  Named returns allow you to provide a name for the type being returned in the function definition. Naked returns   Require named returns Allow you to use the return statement to return these values by default  Named/Naked Return Example:\nfunc AddTwoNums(a, b int, name string) (statement string) { // add `statement` to the return type, inside parentheses. \tc := a + b statement = fmt.Sprintf(\u0026#34;%s: %d\u0026#34;, name, c) // assign the result to the statement variable \treturn // return `statement` value } Try Me\nReturning to exit a function The return keyword\n Exits the function immediately Does not need to actually return anything  Functions with multiple return values Example of defining a function With Multiple Return Values:\nfunc AddTwoNums(a, b int, name string) (int, string) { // return types are defined as `int` and `string` \tc := a + b statement := fmt.Sprintf(\u0026#34;%s: %d\u0026#34;, name, c) return c, statement // returns both `c` and `statement` as values } func main() { result, statement := AddTwoNums(2, 2, \u0026#34;Two numbers added\u0026#34;) // declare 2 variables to equal the results from the function call \tfmt.Println(result, statement) } Try Me\nMini Lab 1: Challenge Given a slice of maps called m, that contains keys \u0026#34;firstName\u0026#34; and \u0026#34;lastName\u0026#34; When LastNameAndIndex is invoked with the map And and firstName as \u0026#34;Luke\u0026#34; Then the function should return \u0026#34;Skywalker\u0026#34; And index of 1 Do the Challenge\nUsing an Underscore to Ignore Return Values When invoking a function that returns multiple values, you can use an underscore ( _ )to ignore a value.\nfunc AddTwoNums(a, b int, name string) (int, string) { c := a + b statement := fmt.Sprintf(\u0026#34;%s: %d\u0026#34;, name, c) return c, statement } func main() { result, _ := AddTwoNums(2, 2, \u0026#34;Two numbers added\u0026#34;) (1) fmt.Println(result) } Try Me\n We only care about the int value returned by the function, so we use an _ for the 2nd value. You can use as many _ speared by commas as return values you want to ignore.  Nested Functions and Closures  A nested function is a function defined inside of the body of another function. An anonymous function is a function that has no name (the name is usually specified just after the func keyword) A closure is a function that is defined inside another function and closes in on or binds to variables outside of the closure\u0026rsquo;s own scope.   NOTE: In Go, all nested functions must be anonymous! The anonymous function is assigned to a variable.\n A closure:\n Retains access to variables in its parent function even after the parent function has returned Can be returned from a function as a value  An Example of a Closure func main() { count := 0 // declare variable `count` as an `int` with `0` value \tinc := func() int { // create an anonymous function and assign it to the `inc` variable \tcount++ return count } fmt.Println(inc()) // invoke the function once by calling inc \tfmt.Println(inc()) // invoke the function again by calling inc } Try Me\nInvoking vs Value  Variable type becomes a func() type when assigned with the value of the function definition This value can be passed anywhere that will accept a func() type as an input/output The value can be invoked at any time by adding () to the variable name it is assigned to..  Higher Order Functions Higher order functions are functions that either accept another function as a parameter, return a function as a result, or both.\nPassing a Function as a Parameter A function can accept another function by defining its type as a func with the its expected signature\nDeclaring a function that takes another function\nfunc doSomethingWithThis(callme func()) { // 1  callme() // 2 }  callme declared as in input parameter of type func() callme is actually invoked.  In this case, the function passed in could be treated as a callback, or simply a dependency of the function.\nMini Lab 2: Implement it. Create a closure function and pass it to the defined function:\nGo to the Exercise\nFunction Signature Matters. Remember:\n The signature of a function has to match the declared type You declare your func() type signature by adding in the input and output statements  Func type Input With a Signature\nfunc superUsefulFunction(callme func(x int) string, somenum int) { // 1 \tfmt.Println(callme(somenum)) // 2 } func main() { f := func(x int) string { // 3 \ty := x * 1000 return fmt.Sprintf(\u0026#34;%d * 1000 = %d\u0026#34;, x, y) } superUsefulFunction(f, 10) // 4 } Try Me\n We declare a function that accepts a function with a signature and a string. Based on the functions signature, it accepts an int as input and returns a string as output. The function is invoked by calling the name that was declared in the input parameters. Set up an anonymous function that matches the signature of the function parameter in superUsefulFunction Invoke superUsefulFunction with the function f and an int 10.  Explain what the following code is doing:\nfunc superUsefulFunction(callme func(x int) (string, int), somenum int) { fmt.Println(callme(somenum)) } func GetDoAThing() func(int) (string, int) { return func(x int) (string, int) { y := x * 1000 return fmt.Sprintf(\u0026#34;%d * 1000 = %d\u0026#34;, x, y), y } } func main() { f := GetDoAThing() superUsefulFunction(f, 10) } Try Me\nReturning a Function As with other types, you can return a func() type as a value.\nBasic Syntax for Returning a Function as a Value\nfunc FunctionReturn() func() { // 1 \treturn func(){ //2 Code that does func stuff here. \t} }  Declare the function FunctionReturn with a return type func() Return a function.  Returning a Function With Inputs and Outputs As with inputs, the returned function must match the declared return type signature, or you will not be able to compile.\nfunc FunctionReturn() func(i int) int { // 1 \treturn func(i int) int { return i * 10 // 2 \t} }  Declare a function that returns a function with a signature func(i int) int Return a function that meets the types signature.  Explain what is happening in the following code:\nfunc main() { multiply := NumberMultiplier(5) x := multiply(100) fmt.Println(x) } func NumberMultiplier(multiplier int) func(i int) int { return func(i int) int { return i * multiplier } } Try Me\nDefer  built in function Allows you to specify functions that will get invoked after the current function returns Typically used for clean-up  Syntax:\ndefer func(){}() Defer rules\n Deferred functions must be invoked after the defer You can have many deferred function inside of a function Multiple deferred functions are executed from the stack in first in, last out (FILO) order.  Defer in Action\nfunc main() { DeferExample() } func DeferExample() { defer Close() // 1 \tdefer func() { // 2 \tfmt.Println(\u0026#34;Stuff has been Deferred.\u0026#34;) }() // 3  defer fmt.Println(\u0026#34;Starting my de furring process!\u0026#34;) // 4  fmt.Println(\u0026#34;Doing very important work here!\u0026#34;) fmt.Println(\u0026#34;Busy, busy, busy!\u0026#34;) fmt.Println(\u0026#34;Work Work\u0026#34;) fmt.Println(\u0026#34;Fizz, World!\u0026#34;) } func Close() { fmt.Println(\u0026#34;Closing!\u0026#34;) } Try Me\n Adding Close() to the defer stack Adding an anonymous function the the defer stack Note The anonymous function is invoked Adding a fmt.Println() to the defer stack.  When you run the above sample, you should see the output:\nDoing very important work here! Busy, busy, busy! Work Work Fizz, World! String my de furring process! Stuff has been Deferred. Closing! Variadic Functions variadic functions are functions that take any number of arguments.\nIn Go the Variadic parameter:\n is identified by ... as a prefix to the type in the input signature Must be the final parameter Can only have one per function  Example of a Variadic Function\nfunc sum(numbers ...int) (sum int) { // 1  for _, v := range numbers { // 2 \tsum += v } return } Try Me\n The function takes in what is the equivalent to a slice of int The function loops over the slice that represents the arguments passed in and adds them to the sum  Lab: Working with Functions Setup  Follow the instructions in the readme for the go foundations labs cd \u0026lt;your workspace\u0026gt;/go-found-labs/functions/lab1/ Open functions.go and complete the instructions.  "
},
{
	"uri": "/javascript/foundations/labs/functions-lab/",
	"title": "Functions Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file cd $HOME/js-foundations/labs touch functions.js Step 2: Implement the fizzBuzz function  Write a function named fizzBuzz that takes a single argument The argument should be a number/integer Write a condition that determines if the argument is evenly divisible  If the argument is evenly divisible by 3 and 5 return the string \u0026ldquo;FizzBuzz\u0026rdquo; If the number can be evenly divisible by 3 return the string \u0026ldquo;Fizz\u0026rdquo; If the number is evenly divisible by 5 return the string \u0026ldquo;Buzz\u0026rdquo; If none of these conditions apply, return the number    Step 3: Test your solution Add a statement that calls your fizzBuzz function with a value, such as 3 and prints the result to the console. For example:\nconsole.log(fizzBuzz(3)); // \u0026#34;Fizz\u0026#34; Test your solution with:\nnode functions.js Below is the expected output for various arguments to the fizzBuzz function:\nfizzBuzz(3); // \u0026#34;Fizz\u0026#34; fizzBuzz(4); // 4 fizzBuzz(5); // \u0026#34;Buzz\u0026#34; fizzBuzz(11); // 11 fizzBuzz(15); // \u0026#34;FizzBuzz\u0026#34; Extra Credit In functions.js, write a loop that will take in a range of values (ie: 1 through 15) and log the values to the console\nThe expected output is:\n1 2 Fizz 4 Buzz Fizz 7 8 Fizz Buzz 11 Fizz 13 14 FizzBuzz "
},
{
	"uri": "/software-eng-essentials/git-foundations/git-branching-out/",
	"title": "Git Branching Out",
	"tags": [],
	"description": "",
	"content": "Branches Branching means that you diverge from the main line of development and continue to work without messing with that main line. These branches are a sequence of commits.\nIn the image below, there are three \u0026ldquo;time lines\u0026rdquo;, AKA branches. Each branch has dots on it which represents a commit.\n   Little Feature contains only the data from the master branch\u0026rsquo;s first commit (the first blue dot) Big Feature branch contains more information as it was created further down in the history of the project.  Both branches have their own SHA1 which contains this specific information. SHA1 will be explained later.\nListing branches Create branches early and often!\nTo see all of the branches that have already been made, type:\n$ git branch Should give an output like:\n* master The above output shows the one branch, the master branch. The * next to master shows that we are currently on that branch.\nCreating branches To create a new branch, do: git branch \u0026lt;branch-name\u0026gt;\nTo show branches in action, we are going to navigate to the gitting-started directory we created in the add section of gitting-started.\nCreate a new branch in this repository then list the existing branches:\n$ git branch file-add $ git branch file-add * master Switching Branches To move over to another branch, do:\ngit checkout \u0026lt;branch-name\u0026gt;\nIn the gitting-started repository, switch over to file-add and view all of the existing branches.\n$ git checkout file-add $ git branch * file-add master  Notice the asterisk has moved to file-add\n To create and checkout a branch in one line, type: git checkout -b \u0026lt;branch-name\u0026gt;.\n   Go to Branch practice lab    Tagging Tags are references that point to specific points in Git history.\nTagging is used for a marked version releases (i.e. v1.0.1). A tag is like a branch that doesn\u0026rsquo;t change, unlike branches. Tags, after being created, have no further history of commits.\n When a tag is added, the tag is added to the .git/refs/tags folder. In this folder, a corresponding reference hash is next to the tag. This hash is unique to the tag, it does not represent the SHA1 of the commit.\n Listing all tags To list all existing tags, type: git tag\nAt first, a repo will not have any tags.\nTo list any additional tag messages, type: git tag -n.\nCreating all tags To create a tag, use: git tag \u0026lt;tag-name\u0026gt;\nIn the gitting-started repository, add a v1.0.0 tag to the file-add branch then list out all tags:\n$ git tag v1.0.0 $ git tag v1.0.0 Deleting a tag To delete a tag, simply run git tag -d \u0026lt;tag-name\u0026gt;\nAnnotated tags So far, only lightweight tags have been discussed. These tags just contain the tag-name for the commit (object) it is attached to.\nAn annotated tag allows for more information to be added to a tag: containing a creation date, the creator of the tag, and a message (if one is included).\nAnnotated tags are often used for production since they have very detailed information, and lightweight tags can be used on local branches for personal use and reference.\nCreating an annotated tag are created with -a: git tag -a v1.0.1. This will open the text editor with the following pre-written message:\n# Write a message for tag: # v1.0.1 # Lines starting with \u0026#39;#\u0026#39; will be ignored. Placing the text First tag message below the last line, would make the message for a tag. Save the document, close the editor and return to the terminal.\nNow the following should show when all tags are listed with their messages: v1.0.0 First tag message\nForcing tags of the same name If a tag is named with the same identifier as an existing tag, Git will throw an error like: fatal: tag 'v1.0.0' already exists.\nThe -f FORCE flag must be used if an existing tag needs to be updated:\ngit tag -f v1.0.0 If this commit already had a tag, now it\u0026rsquo;ll have two tags but it can not share the same name with any other unique commit.\n   Go to Tagging lab    "
},
{
	"uri": "/software-eng-essentials/git-pillars/",
	"title": "Git Pillar",
	"tags": [],
	"description": "",
	"content": "Welcome to Git Pillar!   "
},
{
	"uri": "/javascript/express/nodemon/",
	"title": "Nodemon",
	"tags": [],
	"description": "",
	"content": "Nodemon Learning Objectives  Monitor and automatically restart a node application Install and run nodemon in an application  Restarting a Server The Problem:\n We can modify our Node or Express app however we would like. Unfortunately, we’ll need to restart the server after each change. This is due to the fact that our server needs the information on startup.  The Solution:\n To avoid manually restarting our server over-and-over again, we can use the super handy nodemon package. Nodemon watches files for changes and automatically restarts our server.  Installation To install nodemon, we’ll stop the server and install the package as a local dependency.\nnpm i --save-dev nodemon Basic Usage Use the nodemon command and pass your app as an argument.\nnodemon \u0026lt;my-app\u0026gt; Nodemon usage is as easy as this. There are more options available which you can find with the help flag -h.\nnodemon -h Adding a Start Script Next, we’ll add a start script for nodemon to our package.json file. Since we will only use nodemon when developing our application, we will follow a convention of naming the command dev.\n// `app.js` is the name of the app in this example. // ...  \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34; : \u0026#34;node app.js\u0026#34; , \u0026#34;dev\u0026#34; : \u0026#34;NODE_ENV=development nodemon --inspect app.js\u0026#34; }, //... Now we have a start script that can be run with the command:\nnpm run dev This will tell nodemon to run the app.js file. Each time we make a change, nodemon will handle restarting our server, allowing the changes to load.\n"
},
{
	"uri": "/cyber-security/static-dynamic-analysis/7-resources/",
	"title": "Review and Resources",
	"tags": [],
	"description": "",
	"content": "Review Static Application Security Testing (SAST) Analysis of computer application code (not running) for conditions indicative of security vulnerabilities.\nTools Micro Focus Fortify (SAST), Whitesource (open source)\nResults Available via the Fortify Software Security Center (SSC) UI.\nExpectations You will submit your custom code and dependencies to these tools for analysis regularly, view the results and perform triage.\nResources Secure Code Warrior https://securecodewarrior.com\nMicro Focus Vulnerability Catalog (VulnCat) https://vulncat.fortify.com\nCarnegie Mellon Software Engineering Institute/Computer Emergency Response Team (SEI CERT) Secure Coding Standard for Java https://wiki.sei.cmu.edu/confluence/display/java/SEI+CERT+Oracle+Coding+Standard+for+Java\nOpen Web Application Security Project (OWASP) AppSec Cheat Sheets https://cheatsheetseries.owasp.org Top 10 Vulnerabilities (2017, most recent) https://www.owasp.org/index.php/Top_10-2017_Top_10\nConfluence How-To Pages (pinned in #static-analysis-fun) How To: Initiate Security Static Analysis Scans How To: Disposition Security Flaws in Micro Focus Fortify SSC How To: View Whitesource Scan Results\nCode Your Own Adventure (pinned in #static-analysis-fun) Unlock achievements that reflect your mastery of AppSec skills. Complete self-paced, computer-based training and perform activities to earn stickers, pins and bragging rights and progress through the ranks!\nKnowledge Depot CBTs:\nSecure Development Training series:\n CSP101 – Secure Software Concepts CSP102 – Secure Software Requirements CSP103 – Secure Software Design CSP104 – Secure Software Coding CSP105 – Security Software Testing CSP106 – Software Acceptance CSP107 – Software Deployment Operations  Maintenance and Disposal\nCSP108 – Supply Chain and Software Acquisition\nSecurity Awareness\nOWASP Top 10 2013\nThreat Model Express\nDefending .NET\nDefending Android\nDefending C\nDefending Cloud-Based Applications\nDefending C#\nDefending Databases\nDefending Django\nDefending HTML5\nDefending iOS\nDefending Java\nDefending JSP\nDefending Mobile\nDefending Node.js\nDefending PHP\nDefending Python\nDefending Swift\nDefending Web Applications\nApplication Security Team E-mail: Cybersecurity_ApplicationSecurity@homedepot.com\nSlack: #applicationsecurity, #static-analysis-fun\n"
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/shell-configuration/",
	"title": "Shell Configuration",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Explain the purpose of environment variables Describe the purpose of the shell configuration files  For bash: .bash_profile and .bashrc For zsh: .zprofile and .zshrc   Configure the PATH environment variable Create some shell aliases  UNIX commands run in an Environment  Every time a command is run it runs inside of a shell session that provides an environment. The environment can be configured via environment variables and these variables can define values that are used by the shell and programs we run from the shell. Thus environment variables are semi-permanent and can provide information or options to help a command do its job.  You can see the values of all of the environment variables via the env command:\nenv | sort BLOCKSIZE=1k EDITOR=vim GREP_COLOR=1;33;45 GREP_OPTIONS=--color=auto HOME=/Users/mah3093 LANG=en_US.UTF-8 LESS=-R LOGNAME=mah3093 LSCOLORS=Cxfxcxdxbxegedabagacad PAGER=less PATH=/usr/local/sbin:.:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin PWD=/Users/mah3093 SECURITYSESSIONID=186a7 SHELL=/usr/local/bin/zsh SHLVL=1 TERM=xterm-256color USER=mah3093 Setting Environment Variables You set an environment variable as follows:\ncolor=blue GREETING=\u0026#34;Good Morning\u0026#34; Variable Substitution You use an environment variable by prepending the $ character to the variable name:\necho $color # blue echo \u0026#34;Welcome and ${GREETING}\u0026#34; # Welcome and Good Morning Exporting Variables If you want the variable to be available to sub-processes (shells forked from the current shell), then you should export the variable:\nexport color export GREETING=\u0026#34;Aloha\u0026#34; Command Substitution You can set a variable to the output of a command:\nGREETING=\u0026#34;Hello $(whoami)\u0026#34; # Hello homer Clearing Environment Variables You can use the unset command to clear an environment variable:\nunset GREETING Configuring The Shell For bash and for zsh there are two important configuration files:\n   Shell File When Executed     bash .bash_profile executed for login shells   bash .bashrc executed for interactive non-login shells   zsh .zprofile executed for login shells   zsh .zshrc executed for interactive non-login shells    Essentially what this means is that the .bash_profile file (for bash) and the .zprofile (for zsh) are only executed once per login session while the .bashrc and .zshrc files are executed with each shell or sub-shell session.\nThe Shell Execution PATH  There is a special environment variable with the name PATH that defines the Shell\u0026rsquo;s search path for finding executable programs and scripts. The PATH is useful because you don\u0026rsquo;t want to have to type the entire path to find an executable. For example, typing  node hello.js # will search your PATH for the node command is much easier than typing\n/usr/local/bin/node hello.js # will run the node command specified Things to know about the PATH:  You can view the current PATH by typing echo $PATH Each entry in the PATH is separated by a colon (:) character Order is important. If you have 2 node commands in your path the first one wins!  For example, if our PATH is set to:\n/usr/local/bin:.:/bin:/usr/bin\nand we have a node command in /usr/local/bin and also in /usr/bin then the command executed will be the first one found in the PATH (the one in /usr/local/bin).\nThe which command You can use the which command (or on MacOS the type -a command) to display where a specific command is found in the PATH:\nwhich node # which is universal on UNIX machines and works on MacOS type -a node # type is available on MacOS and has some nice options  TIP: For macOS I often use the following alias: alias which='type -a'\n The Shell Prompt The Shell Prompt can be customized to show interesting information such as the current working directory.\nFor bash you can configure the prompt to contain the current working directory as follows:\nPS1=\u0026#39;[\\w]\\$ \u0026#39; For zsh you can use the following:\nPROMPT=\u0026#39;%~ %# \u0026#39;  There are a lot of ways to customize the prompt and you can even colorize the prompt. If you want your custom prompt to always be set for every shell session, you will want to put the configuration in your .bash_profile or .zprofile file, for example:  echo \u0026#34;PS1=\u0026#39;\\w\\$ \u0026#39;\u0026#34; \u0026gt;\u0026gt; ~/.bash_profile or\necho \u0026#34;PROMPT=\u0026#39;%~ %# \u0026#39;\u0026#34; \u0026gt;\u0026gt; ~/.zprofile  NOTE: One option for setting up a very nice Prompt for bash or zsh is LiquidPrompt.\n Shell aliases  Often times you will use the same command over and over. You can use an alias to \u0026ldquo;shorten\u0026rdquo; any command, making it easier to type: The syntax for alias is:  alias name=string Alias Example ls -hartl Typing that command may become tedious so you can create an alias to shorten the command:\nalias lr=\u0026#39;ls -hartl\u0026#39; Then all you need to do is type the alias:\n$ lr total 4176 drwxrwxrwt 19 root wheel 608B Oct 12 17:23 .. -rw-r--r--@ 1 mah3093 wheel 2.3M Oct 12 17:24 bit-awards.jpg -rw-r--r--@ 1 mah3093 wheel 99K Oct 12 17:24 javascript-everywhere.jpg -rw-r--r--@ 1 mah3093 wheel 50K Oct 12 17:24 javascript-good-parts.jpg -rw-r--r--@ 1 mah3093 wheel 238K Oct 12 17:24 mac-lab.jpg -rw-r--r--@ 1 mah3093 wheel 1.3M Oct 12 17:24 milky-way.jpg -rw-r--r--@ 1 mah3093 wheel 144K Oct 12 17:24 visual-sql-joins.jpg drwxr-xr-x 8 mah3093 wheel 256B Oct 12 17:29 . Here are a few useful aliases:\nalias ls=\u0026#39;ls -GF\u0026#39; alias path=\u0026#39;echo -e ${PATH//:/\\\\n}\u0026#39; alias which=\u0026#39;type -a\u0026#39; You can see a list of all your aliases by typing alias with no arguments:\n$ alias ls=\u0026#39;ls -GF\u0026#39; path=\u0026#39;echo -e ${PATH//:/\\\\n}\u0026#39; which=\u0026#39;type -a\u0026#39;  TIP: You can put your favorite aliases in your .bashrc or .zshrc file to have them ready for each shell session.\n Summary  Environment variables are used to define an environment provided by the shell The PATH environment variable defines the execution search path for running commands and applications The .bash_profile and .bashrc files are used to configure the bash shell The .zprofile and .zshrc files are used to configure the zsh shell Aliases can be created to shorten frequent commands  "
},
{
	"uri": "/java/foundations/object/",
	"title": "Software Objects",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Object States and Behavior Fields and Methods Object Encapsulation Modularity of Code  Skills  Describe what makes an effective software object Design basic software objects  Objects Object types are not as straightforward as primitive types. They can be complex definitions of state and behavior, not just raw values. This means they are created and handled very differently from primitive types.\nCar myCar = new Car(); Every object in Java extends (or is a derivative of) Java\u0026rsquo;s base Object class and so has some common affordances (equality checks, hashcode generator, etc).\nCharacteristics of Objects Object oriented programming, in many ways, can be understood best by viewing Software Objects as analogies for real world objects or ideas. With some practice, your best tool will be your common sense. As you learn and practice, ask yourself questions like \u0026ldquo;does it make sense for this object to behave this way?\u0026rdquo; or \u0026ldquo;could someone who did not work on this understand the decision/functionality I\u0026rsquo;ve made?\u0026rdquo;\nState and Behavior The basic characteristics of any object can be summed up in two categories: state and behavior. In other words, what is it like now, and what capability it has to change. In the spirit of common sense, we\u0026rsquo;re going to begin with real world objects, things you interact with every day.\nConsider a bicycle:\nState\n current gear current speed pedal cadence  Behavior\n apply brakes shift gears change cadence  As you can see, the state of an object simply describes the object as it is; it defines the core of what and object is. The behavior is describing the different ways in which you can utilize or change the state.\n 👀 Take a few minutes to pick an object around you. Describe it in terms of state and behavior.\n Software Objects Software objects do a lot to imitate this state/behavior pattern. In Java, these objects are defined with Classes. A class defines an object\u0026rsquo;s state through fields. Just like real world objects, this makes up the core of a software object. A class also contains methods to expose an object\u0026rsquo;s behavior.\nBeyond this, there are a couple concepts that are crucial to a well-built software object that you should always keep in mind: Encapsulation and Modularity.\nEncapsulation An object should share only what it must with the external world (which is generally even less than you think it might need). As a general practice, every part of the state of an object should be hidden (private). What this means is that nothing from the external world can directly access an object\u0026rsquo;s state.\n ⚠️ Why is it important to hide the state of an object?\n This protects from an external source coming in and moving your object to an invalid state. Broken or invalid objects, just like in the real world, can wreak havoc on the larger system leading, at best, to unexpected results or, at worst, a Runtime Exception or failure.\nHiding the state allows for the defined object behavior to be the sole actor on the state; the object itself defines how it can be changed or affected. In this way, an object\u0026rsquo;s methods are the primary avenue for object to object communication. This model provides several security benefits:\n Details of the actual implementation remain hidden, you control what is known/unknown about a given object The object stays in control of its own state (guarding against invalid states)  e.g. if a bike only has 6 gears, modifying the gears externally may lead to invalid states. An encapsulated object can prevent this by checking the validity of the action before action on the object.    Modularity  Modularity is the degree to which a system\u0026rsquo;s components may be separated and recombined.\n It is the goal of any Java object to be modular, the ability be passed easily within and outside the system. In order to accomplish this they are independent of any other source code or context. The key metric here is re-usability. If an object is so finely tuned and strung that it can only be used in one context, you have neglected modularity. When properly utilized, Object Oriented Programming shows its efficiency in creating objects versatile enough that they can be used in contexts not initially thought of or planned for.\nA key factor satisfied here is no duplicated code. If you find yourself repeating code/functionality, spend time thinking of the software object that is truly defined by this functionality, create it, and allow the code to rest in one place being called in many.\nChanging Object Values It is important to note that if the variable holds the address to an Object, the Object itself can change without the variable changing. After all, as long as it still points to the came memory address, the variable hasn\u0026rsquo;t actually changed.\nfinal Car myCar = new Car(); myCar.paint(\u0026#34;Blue\u0026#34;); // 1  myCar = new Car(\u0026#34;Blue\u0026#34;); // 2  This is allowed because myCar points to the same car, its just a blue car now. This is not allowed because this assignment will change the value of myCar.  .compareTo Objects must utilize the .compareTo method. It is the job of this method to programmatically describe how to compare one object with another. This method must return an int (negative for less than, positive for greater than, 0 for equal to).\nOne example of this can be seen in Strings. Strings cannot be compared as a primitive: string1 \u0026lt; string2. Rather you have to use string1.compareTo(string2) which will programmatically go through and compare the characters of the two strings lexicographically (alphabetically).\nString s1 = \u0026#34;xyz\u0026#34;; System.out.println(s1.compareTo(\u0026#34;abc\u0026#34;)); The above example would print 1, because \u0026ldquo;xyz\u0026rdquo; comes after \u0026ldquo;abc\u0026rdquo;.\n.equals vs == Java knows how to handle 1 == 2 but how does it know if bike1 == bike2? Again, you have to use the equality check .equals(). Unlike .compareTo every object by default will have an equality check, however all it will do is check to see if two objects are actually the same object. For example object1.equals(object1) is obviously true but what is object2 is a different object that has all the same values as object1? Well, its still considered not equal (object1.equals(object2) is false).\nIt is tempting to use == on Strings (it will not error out), but this is not advisable on any object reference including Strings. String\u0026rsquo;s implementation of .equals checks that the actual characters are equivalent, rather than just checking to see if the two strings are the same object.\n s1 == \u0026quot;xyz\u0026quot; is not necessarily true, results can be unexpected s1.equals(\u0026quot;xyz\u0026quot;) is true s1.equalsIgnoreCase(\u0026quot;XyZ\u0026quot;) is true  Primitive Auto Boxing As stubborn as Java is about types, its not dumb. If two types are inherently the same, it knows how to handle it. Every primitive type has a corresponding Class for object types. These types can be used interchangeably. In other words, if you write a method that expects Integer but pass in an int, no error is thrown. This is call auto boxing.\n Primitive Class wrappers  byte =\u0026gt; Byte short =\u0026gt; Short int =\u0026gt; Integer double =\u0026gt; Double long =\u0026gt; Long float =\u0026gt; Float boolean =\u0026gt; Boolean char =\u0026gt; Character    int i = new Integer(65); Integer i = 65; These proper Object forms have additional functionality defined because they are extensions of Java\u0026rsquo;s base Object class. This may or may not be useful, depending on your use case. It\u0026rsquo;s important to know the difference.\nPrimitives vs Objects When you assign a primitive value to a variable, that variable holds only that value. However, because Objects can be so complex their variables don\u0026rsquo;t hold values, they hold a memory address where the object sits. An object variable is less of a container for a value and more of a pointer to some instance.\n   Variable Type Contents Assignment     Primitive Contains actual data Old value is replaced with the new value   Object Contains a reference to a point in memory Old reference is replaced with new reference     Question\nWhats happens to the old object reference after reassignment?\n It seems like a lot of work to have this short list of types that can be used as primitives, especially since they all have corresponding classes anyway\u0026hellip;so why even have them? The advantages are twofold.\n Objects must be stored in the memory heap (long term storage) and must be managed over time, this can cause issues with memory allocation. Primitives, on the other hand, can be stored on the stack (short term storage) so there is a lot less overhead. Because primitives can be manipulated directly rather then first finding the object in heap storage, operating on primitives is much less expensive. In small number, this difference is pretty inconsequential. But\u0026hellip;what if you wanted to loop over every single valid integer in Java (if the mood strikes)\u0026hellip;  public static void main(String[] args) { Long sum = 0L; // uses Long, not long  for (long i = 0; i \u0026lt;= Integer.MAX_VALUE; i++) { sum += i; } System.out.println(sum); } Summary Java, and other Object Oriented Languages, are built to work in a very specific way; to follow this model of software objects. It is important to understand what makes an object useful, efficient, and secure before we begin creating these objects for ourselves.\nEvery object has a defined state and behavior. Its state must be protected (hidden) and effective behavior provides all tools needed for object interaction. These objects should be defined and scoped in a way that they offer themselves as context-agnostic tools and blocks to be utilized by external sources.\nPrimitive types are handled differently from proper objects, so its important to know when to use each.\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/responsive-layouts-labs/",
	"title": "CSS Responsive Layouts Labs",
	"tags": [],
	"description": "",
	"content": "Follow this link to complete the exercise. The intention is to utilize what you\u0026rsquo;ve learned about responsive design and media queries to create a website with HTML and CSS: Falcon Gazette Exercise\n Fork and clone the Falcon Gazette repository Open the code in a text editor and open the HTML page in your browser See how it is not responsive - make it responsive!  Additional Resources  Using Media Queries Holy Grail Web Design What is a Grid-View?  "
},
{
	"uri": "/cloud/containers/docker-fundamentals/additional-resources/",
	"title": "Additional Resources",
	"tags": [],
	"description": "",
	"content": "Additional Resources Docker Documentation\n Docker Documentation Docker overview Docker Samples  PluralSight Courses\n Docker and Kubernetes: The Big Picture | Pluralsight Getting Started with Docker | Pluralsight Docker Deep Dive | Pluralsight Docker Networking | Pluralsight  Youtube Videos\n Should You Use Kubernetes and Docker In Your Next Project? - YouTube  "
},
{
	"uri": "/javascript/foundations/labs/arrow-functions-lab/",
	"title": "Arrow Functions Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch arrow-functions.js Add the following code to arrow-functions.js:\nfunction sumPendingOrders(orders) { const sum = orders .filter(function (o) { return o.status === \u0026#39;pending\u0026#39;; }) .map(function (o) { return o.price; }) .reduce(function (a, b) { return a + b; }, 0); return sum === 0 ? \u0026#39;no pending orders\u0026#39; : sum; } const order = [ { price: 45.0, status: \u0026#34;processed\u0026#34; }, { price: 20.0, status: \u0026#34;pending\u0026#34; }, { price: 60.0, status: \u0026#34;pending\u0026#34; }, { price: 15.0, status: \u0026#34;processed\u0026#34; } ]; console.log(sumPendingOrders(order)); // 80 Step 2: Refactor the code to use arrow functions The provided code is fully functional but we want to make it better.\nThe code inside sumPendingOrders uses 3 function expressions. Refactor these functions to use arrow functions. Use implicit returns in the arrow functions. The resulting code should be much shorter.\nStep 3: Test your solution You can test your solution with:\nnode arrow-functions.js The expected output is 80.\n"
},
{
	"uri": "/java/foundations/class/",
	"title": "Classes and Objects",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Classes and their members (fields and methods) Object instantiations  Skills  Writing a class with custom behavior Create objects and utilize the defined behavior  Java Classes Imagine, if you will, that you\u0026rsquo;re making gingerbread cookies. You have a whole heap of dough just waiting to be rolled out. You have all kinds of cookie cutters to make all kinds of fun and interesting shapes. Some will be ginger men or women, some may be walls for a house, a roof, or chimney.\nIn this metaphor, your dough is available memory, your cutters are classes, and the pieces that result are your objects. A Java class defines the state and behavior that a particular object should take on. It can then be used to create instances (or objects) that carry and track its own state and behavior as it\u0026rsquo;s defined in the class. This processes is called instantiation, creating an object instance from a class. From that point on, the object can be used and manipulated in the manner that was determined by its class.\nIn this section we will start getting into what this process actually looks like in Java.\nClass Definitions The basic class declaration is comprised of three things:\n Modifiers Class name (always capitalized) Class body surrounded by {}  public class Car { // fields \t// methods } Some of the most common modifiers are visibility modifiers. Java utilizes information hiding in order to aid in encapsulation. This is done through visibility modifiers. Below is a list of these keywords and what they mean in terms of visibility.\n   Keyword Package Subclass World     public Y Y Y   protected Y Y N   none Y N N   private N N N     NOTE: no modifier defaults to hiding the information everywhere except the package (known as package private).\nWhat does this behavior tell us about Java?\n Fields Let us take a moment to discuss some nuances of what we call variables. In Java, the term \u0026lsquo;variable\u0026rsquo; or \u0026lsquo;local variable\u0026rsquo; refers to a variable that has a limited scope, generally within a single method. Meaning that it is created and used only in this singular block of code. A parameter is a variable that is passed into a method from somewhere else, so its scope goes at least one level up from where it is used. A field is a variable that belongs to a class and can be used anywhere within that class.\npublic class Car { private int speed; public void accelerate(int increase) { int newSpeed = speed + increase; speed = newSpeed; } } In the above example, speed is a field that belongs to the class, increase is a parameter passed into the method accelerate(), and new speed is a local variable only used within the one scope.\nA basic field declaration contains three things:\n Modifiers Field type Field name (recall naming conventions)   ℹ️ Encapsulation dictates that fields tend to be private by default.\n public class Car { private final int MAX_GEAR = 6; //1  private String color; private int gear; private double speed; // methods }  recall final modifier\u0026hellip;  Since all fields are private, you will generally see a set of accessor functions whose sole job is to grant access to fields. These methods are appropriately referred to as \u0026lsquo;getters\u0026rsquo; and \u0026lsquo;setters\u0026rsquo;:\npublic int getGear() { return gear; } public int setGear(int gear) { this.gear = gear; } The use of getters and setters is a fine practice, but be mindful about when and how you use them otherwise you could end up undermining the entire point of encapsulation by not protecting an objects fields. This danger will become more clear when we look into object references.\nMethods A similar nuance is seen in functions as to that in variables. A function is simply a named block of code that performs a specific task. A method is a function that belongs to a class.\nA basic method declaration consists of six things:\n Modifiers Return type Method name List of parameters Any potential exceptions Method body  public class Car { private final int MAX_GEAR = 6; private String color; private int gear; private double speed; public void paint(String color) { this.color = color; } public void shiftUp() { if (gear + 1 \u0026lt;= MAX_GEAR) gear++; } public void shiftDown() { if (gear - 1 \u0026gt; 0) gear--; } public void accelerate(double inc) { speed = inc; } public void applyBrake(double dec) { speed -= dec; } } Method names should always start in lower case and generally the first (or only) word is a verb since it should be describing behavior.\nOverloading Methods The method name along with the list of parameters creates a method signature. As the title implies, two methods cannot have the same signature. But you change any part of the signature and it becomes valid. In fact, it is fairly common to have two methods with the same name require a different set of parameters; this is called overloading the method. Think of it as performing the same action with a different set of provided tools. A method called climb() could take in a ladder, a step stool, or a mountain. The general activity is the same, but the parameter may change the process or extent to which the deed is done. Utilized properly, overloading methods is an effective tool to accomplish tasks in different ways.\nBelow is an example of an overloaded method that will change the extent to which an action is carried out. The behavior is the same, but the result is different.\n// Shifts gear up one if it can public void shiftUp() { if (gear + 1 \u0026lt;= MAX_GEAR) gear++; } // Shifts up the number of gears specified, if it can public void shiftUp(int gears) { gear += gears; if (gear \u0026gt; MAX_GEAR) gear = MAX_GEAR; } Constructors Most classes will need a special kind of method called a constructor. Like the name implies, a constructor is used to instantiate (construct) an object of this class type. Its where the cookie cutter meets the dough, if you will. All classes in Java start with a default constructor that takes no parameters and simply returns a reference to the newly constructed object. If you only use this provided constructor, there is no need to write your own as it is implied. No logic is executed, no assignments made, simply an object is created based on the class.\nHowever, you may want some special handling or preparation when an object is instantiated. In these cases, you can write your own:\npublic class Car { private String color; private int gear; public Car(String color) { this.color = color; gear = 1; } } You\u0026rsquo;ll notice the declaration here differs slightly from other methods. You still have modifiers but the return type is omitted (as it is implied to be the type of the class) and the method name must be the class name. Constructors can be overloaded like any other method to take in a variety of different parameters that may construct the object in different ways.\nAlso, remember that default constructor that was provide by Java? Well if you write your own custom constructor, that default constructor is no longer available.\n QUESTION\nWhy would the presence of an explicit constructor necessitate the absence of the default constructor?\n This means that is you wish to keep the functionality of a default constructor after including a custom one, you must make it explicit as well:\npublic class Car { private String color; private int gear; public Car() { } public Car(String color) { this.color = color; gear = 1; } } Keyword: this You may have noticed in some of the above code examples the keyword this being used. It is important to maintain a sense of scope as you work with manipulating variables. While working in a method, this is a scope above the method, a reference back to the actual object that called the method. Notice, it belongs to the object not the class (which will be covered in the following section on static).\nTake the recent example we saw:\npublic void paint(String color) { this.color = color; } In this scenario, we have a field and a parameter both named color, yet with this we can specify that the variable we are assigning belongs to this object, not the method. So when we call our paint method\u0026hellip;\nCar myCar = new Car(); myCar.paint(\u0026#34;blue\u0026#34;); this inside the method is a reference to the object myCar.\nModifier: static A static class member is referenced directly from the class, rather than an object of that class type. These static members are therefore also referred to as \u0026lsquo;class variables\u0026rsquo; or \u0026lsquo;class methods\u0026rsquo;.\npublic final class Integer extends Number implements Comparable\u0026lt;Integer\u0026gt; { public static final int MIN_VALUE = 0x80000000; public static final int MAX_VALUE = 0x7fffffff; ... } As shown, the Java Integer class has class variables for both the minimum and maximum values that an Integer can hold. Now, if these weren\u0026rsquo;t static, you would have to first instantiate an object and then call on a reference to its fields:\n// THIS FEELS WRONG Integer i = new Integer(1); System.out.println(\u0026#34;Max int: \u0026#34; + i.MAX_VALUE);  IMPORTANT: Why is it better for these variable to be attached to the class rather than an instance?\n However, since they are class variables, we refer to the values simply by the class:\n// THAT\u0026#39;S BETTER System.out.println(\u0026#34;Max int: \u0026#34; + Integer.MAX_VALUE); The static modifier should be applied when a particular field or method describes the class rather than the object. In this case, the max value is not simply the max value for this or that instantiated Integer, but for all Integers, therefore it becomes a class variable.\nCreating Objects So we\u0026rsquo;ve talked about our cutters, now let\u0026rsquo;s make some cookies. What does it look like to construct an object from a class? There are three stages to creating an object:\n Declaration: type + variable name Instantiation: uses the new keyword to designate a new object Initialization: call to the constructor to initialize the object  Car myCar = new Car(\u0026#34;Blue\u0026#34;); Car is a class, myCar is an object (kinda\u0026hellip;)\nObject References Here\u0026rsquo;s where it gets a little weird. When you create an object (like above) the variable myCar does not contain an instance of a Car, rather it holds a memory address where the new Car instance is held, breaking our cookie metaphor. It would be a lot less sweet if, when you made cookies for your friends at the office, you instead you brought in a plate full of little strips of paper that you had written your address on. \u0026ldquo;I made cookies! Here\u0026rsquo;s where you can get them.\u0026rdquo; But this is exactly what is happening when you deal with objects.\nIt is too expensive to move along all these big objects, so instead your variables hold a pointer, a memory address. And when the program needs to operate on that object, you give it the address and it goes off to do its work (finding the cookies, as it were). Now, most of the time you don\u0026rsquo;t even have to think about all this. You make a myCar variable, you pretend like it is the actual object and the world goes on, no harm. But its a concept you need to understand because 8/10 times when something weird happens in your Java app, it is going to come back to mismanaged object references. Let\u0026rsquo;s look at a trivial example:\nCar myCar = new Car(\u0026#34;Blue\u0026#34;); Car yourCar = myCar; System.out.println(\u0026#34;My Car is \u0026#34; myCar.getColor()); System.out.println(\u0026#34;Your Car is \u0026#34; yourCar.getColor()); // My Car is Blue // Your Car is Blue  myCar.paint(\u0026#34;Black\u0026#34;); System.out.println(\u0026#34;My Car is \u0026#34; myCar.getColor()); System.out.println(\u0026#34;Your Car is \u0026#34; yourCar.getColor()); // My Car is Black // Your Car is Black You just wanted to paint your car to make it different, but you had the same address as your friend and just showed up and went nuts. You never wanted to paint your friend\u0026rsquo;s car, but that\u0026rsquo;s where we ended up. And this is a trivial example, imagine a Java app with tens of thousands of lines of code, imagine all the object references getting passed around from place to place, can you be sure that your wires won\u0026rsquo;t get crossed?\n Recall that primitives (unlike objects) are raw values, not references and so these same concerns do not apply.\n Dereferencing Dereferencing an object occurs when you lose track of an address. Take the following example:\nCar myCar = new Car(\u0026#34;Blue\u0026#34;); // creates an object in memory  myCar = new Car(\u0026#34;Black\u0026#34;); // creates an object in memory In this case, the first object created (the blue car) can never be recovered. All records of its memory address have been overwritten, it has been dereferenced. All it can do now is sit in memory until the Garbage Collection cycle runs and the memory is freed up.\n IMPORTANT: Sometimes you want to dereference an object, but say you didn\u0026rsquo;t\u0026hellip;How would you avoid it?\n Summary In an Object Oriented Language, classes and the objects that follow are the building blocks to everything you need to accomplish. A class is set of definitions that dictate how any resulting objects will behave, it does this through defining state in fields and behavior in methods.Objects take these definitions and set them in action where they can be fully utilized.\n"
},
{
	"uri": "/software-eng-essentials/comp-sci/",
	"title": "Computer Science",
	"tags": [],
	"description": "",
	"content": "Welcome to Computer Science "
},
{
	"uri": "/javascript/foundations/control-flow-iteration/",
	"title": "Control Flow - Iteration",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Learn how to write for loops. Learn how to write while loops. Learn how to write do...while loops.  What is Iteration? It is a way of incrementally repeating a task.\nIterating is a way of describing procedures like\nprint \u0026#34;hello world\u0026#34; 50 times or\nprint each item in a shopping list It can also be a way of solving problems like\nhow would I print all vegetables in a shopping list? Typically iteration has four parts\n an initial state - runs once before the iterations begin a condition- runs before each successive iteration (repeats), if it is false then the for loop ends a state change - runs after each iteration (before proceeding to the next step) a block of code to execute for each iteration  The for Loop The primary means of iterating in most languages is called the for loop, which has the following structure:\nfor (initial state; check condition; change state) { // run this code for before changing state } NOTE: There are always 2 semicolons in the for loop iteration expression.\nAn example\nfor (let i = 0; i \u0026lt;= 9; i++) { console.log(i); } Another example\nlet friends = [\u0026#34;larry\u0026#34;, \u0026#34;moe\u0026#34;, \u0026#34;curly\u0026#34;]; for (let index = 0; index \u0026lt; friends.length; index = index + 1) { console.log(friends[index]); } Example: Summing the numbers in an Array\nconst numbers = [1, 2, 3, 4, 5]; let sum = 0; for (let index = 0; index \u0026lt; numbers.length; index++) { sum += numbers[index] } console.log(\u0026#39;sum:\u0026#39;, sum); // sum: 15 Lab See instructions here.\nWhile loops  The while loop is another way to do iteration It will run as long as a condition is true  Syntax\nwhile (expression) { // do something } Example\nlet x = 1; while (x \u0026lt; 100) { console.log(x); x = x * 2; } console.log(\u0026#34;Final x value: \u0026#34; + x); Output:\n1 2 4 8 16 32 64 Final x value: 128 do\u0026hellip;​while The do…while statement, which is very similar to while with the major difference being that a do…while loop will always execute once, even if the condition is never true.\nFor more information, see: do\u0026hellip;while | MDN.\nInfinite Loops  While writing a loop it is possible to create a loop that will go on forever. This is called an infinite loop. Obviously we try to avoid infinite loops.  for (let i = 0; i \u0026gt;= 0; i++) { console.log(i); } For \u0026hellip;​ Of \u0026amp; For \u0026hellip;​ In Two additional options for iterating over collections of data are the for…​of and for…​in loops.\n for…​of allows iteration of strings and arrays (we\u0026rsquo;ll cover arrays shortly!) The for…​ in loop gives us a way to iterate through an object.  To learn more about these loops check out:\n for\u0026hellip;​of for\u0026hellip;​in  Summary  Iteration is used to repeat a task or perform an operation on each value in an Array. JavaScript provides the for loop, the while loop, and the do...while loop for iteration.  "
},
{
	"uri": "/python/web-framework/django_testing/",
	"title": "Django Testing",
	"tags": [],
	"description": "",
	"content": "Why Test!?! We don\u0026rsquo;t need to stress the importance of testing your code, but if you need an explanation go here\nDjango has a built in Test module that uses the unit test module, and it already has built in functions. To learn more about Django.test got to documentation here.\nPytest Django Documentation pytest-django is a plugin for pytest that provides a set of useful tools for testing Django applications and projects.\nQuick Start Go to your terminal inside PyCharm and type:\n$ pipenv install pytest-django Create a pytest.ini file in the same directory as your manage.py directory. Make sure DJANGO_SETTINGS_MODULE is defined and make your tests discoverable:\n#store_finder/pytest.ini [pytest] DJANGO_SETTINGS_MODULE = store_finder.settings python_files = tests.py test_*.py *_tests.py Make sure your in the same directory as your manage.py file and type the following command:\n$ pytest -v  The -v means verbose and tells pytest to return more information about the test\n  Configuring Pytest in PyCharm Make sure you have pytest added to the project by following these directions.\nGo to your locations/tests.py file and run it. You will see the Python console displaying the test results.\nExample test:\nfrom django.test import TestCase, Client from .models import Market class test_locationViews(TestCase): def __int__(self): self.client = Client() return self def test_Index(self): # assert that the response code is 200 assert self.client.get(\u0026#39;/locations/\u0026#39;).status_code == 200 self.assertEqual(response.status_code, 200) def test_Stores(self): assert self.client.get(\u0026#39;/locations/1/\u0026#39;).status_code == 200  There is a difference in syntax between the two assert statements above in test_Index becuase the latter is a unittest specific way of doing assert statements. As you can see either ways works fine.\n The test above tests that our two views, StoresView() \u0026amp; IndexView(), both return a status code of 200, which represents OK status, meaning the request has succeeded.\n Pycharm doesn\u0026rsquo;t give all the details when executing test, that\u0026rsquo;s why my preferred method is using the terminal.\n  Why use pytest instead? Running the test suite with pytest offers some features that are not present in Django’s standard test mechanism:\n Less boilerplate: no need to import unittest, create a subclass with methods. Just write tests as regular functions. Manage test dependencies with fixtures. Run tests in multiple processes for increased speed. There are a lot of other nice plugins available for pytest. Easy switching: Existing unittest-style tests will still work without any modifications.   Example test from django.test import TestCase from django.urls import reverse from .models import Market, Store # Create your tests here. def test_1(): n=2 assert n==2, str(n)+ \u0026#39; does not equal 2\u0026#39; class MarketModelTest(TestCase): def test_if_market_has_stores(self): Market.objects.create(number=15, name=\u0026#34;Test_Market1\u0026#34;) Market.objects.create(number=23, name=\u0026#34;Test_Market2\u0026#34;, num_stores=32) mkt22 = Market.objects.get(name=\u0026#34;Test_Market1\u0026#34;) mkt15 = Market.objects.get(name=\u0026#34;Test_Market2\u0026#34;) self.assertIs(mkt22.has_stores(), False) self.assertIs(mkt15.has_stores(), True) Now run your test from the store_finder directory:\n$ pytest -v  If you are in a different directory this command alone will not work you will have to make sure the directory you\u0026rsquo;re in has the pytest.ini file. Or else you will need to pass the name of the directory in with pytest\n Using pytest-django documentation, let\u0026rsquo;s set up our django app to work with pytest.\n Exercise: Testing Your Views This examples uses Django\u0026rsquo;s reverse module explained here\nclass MarketIndexViewTests(TestCase): def test_no_markets(self): \u0026#34;\u0026#34;\u0026#34; TestCase creates a test database and view If no markets exist, an appropriate message is displayed. \u0026#34;\u0026#34;\u0026#34; response = self.client.get(reverse(\u0026#39;locations:index\u0026#39;)) #assert that the response code is 200 self.assertEqual(response.status_code, 200) assert response.status_code = 200 #assert that view returns this response self.assertContains(response, \u0026#34;No Markets are available.\u0026#34;) #assert that market_list is empty self.assertQuerysetEqual(response.context[\u0026#39;market_list\u0026#39;], []) More unittest assert statement options\n Adding More Customization To Your App Take a look at the django documentation to add more customization, this tutorial follows the same set up as the official tutorial on the django website.\n"
},
{
	"uri": "/react/foundations/events/",
	"title": "Events",
	"tags": [],
	"description": "",
	"content": "Handling events and user interaction\nObjectives  Learn how React manages user events Write event handlers to change state Register event handlers with HTML elements (buttons, text fields, etc.)  Introduction  When building a UI, the design and development is built around user interaction. So how does React handle events?  React has an event system that is similar to the DOM\u0026rsquo;s events, but more consistent.\nAccording to the React Event System Documentation:\n Your event handlers will be passed instances of SyntheticEvent, a cross-browser wrapper around the browser\u0026rsquo;s native event. It has the same interface as the browser\u0026rsquo;s native event, including stopPropagation() and preventDefault(), except the events work identically across all browsers.\n Thus events are supplied by the React library, not the web browser, resulting in 100% consistency and no browser quirks!\nHandling Events  Handling events with React elements is very similar to handling events on DOM elements. There are some syntactic differences:  React events are named using camelCase, rather than lowercase. With JSX you pass a function as the event handler, rather than a string.    Example using an inline function:\nfunction App() { return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; \u0026lt;button onClick={(event) =\u0026gt; console.log(\u0026#34;Debit button clicked\u0026#34;)}\u0026gt;Debit\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; ) } We could also make this a named function:\nExample using a named function:\nfunction App() { function handleClick(event) { // event that is provided by React  console.log(`${event.target.innerHTML}button clicked`); } return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; \u0026lt;button onClick={handleClick}\u0026gt;Random\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; ) } User Input and State Handlers  Last we\u0026rsquo;ll look at how to modify the state based on user input. For example, we can build a simple Tweet component:  Tweet.js:\nimport React, { useState } from \u0026#39;react\u0026#39; import { render } from \u0026#39;react-dom\u0026#39; import \u0026#39;./style.css\u0026#39; function Tweet() { const [message, setMessage] = useState(\u0026#39;\u0026#39;) const [response, setResponse] = useState(\u0026#39;\u0026#39;) function captureTweet(event) { setMessage(event.target.value) setResponse(\u0026#39;\u0026#39;) } function postTweet(event) { event.preventDefault() // TODO: make an ajax call posting tweet to the database  // parse the response  // if successful, update the state with a success message  console.log(`posting message: ${message}`) setResponse(\u0026#39;your tweet has been posted!\u0026#39;) setMessage(\u0026#39;\u0026#39;) } return ( \u0026lt;div\u0026gt; \u0026lt;h3\u0026gt;{response ? response : \u0026#39;Tell us something!\u0026#39;}\u0026lt;/h3\u0026gt; \u0026lt;form\u0026gt; \u0026lt;input type=\u0026#39;text\u0026#39; placeholder=\u0026#34;tweet here!\u0026#34; value={message} onChange={captureTweet} /\u0026gt; \u0026lt;button onClick={postTweet}\u0026gt;post it\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; ) } export default Tweet Observations  DOM events have a target.value property that provides us with the current input value.  Thus we can write code like: setMessage(e.target.value).   Whenever we provide the value for an input DOM element, we should also provide an onChange event handler.  This is called a \u0026ldquo;controlled input element\u0026rdquo; since we are controlling both the displayed value and the way that value is updated. We will learn more about controlled input elements in a future lesson.    Some Common Events  Mouse Events: onClick, onMouseOver, onMouseEnter onMouseLeave Form Input Events: onChange Focus Events:: onFocus, onBlur Keyboard Events:: onKeyDown, onKeyPress, onKeyUp Animation Events:: onAnimationStart, onAnimationEnd, onAnimationIteration  For a complete list, see: Supported Events | React Docs\nLab Click here for the instructions to this lab.\nSummary  React makes handling events easy and robust via React\u0026rsquo;s SyntheticEvents. Event handlers are functions that take a SyntheticEvent as a parameter. Event handlers are assigned to HTML elements via a camelCase prop name.  "
},
{
	"uri": "/web-essentials/webmastery-foundations/flexbox/",
	"title": "Flexbox",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Give an example of a problem solved by Flexbox. Contrast flex containers and flex items. Explain what is meant by the \u0026ldquo;Holy Grail Layout\u0026rdquo;.  Skills  Use flexbox to align HTML elements vertically and horizontally. Given a desktop-first webpage, make it look presentable on mobile devices (and vice-versa) with as little CSS as possible.  Framing CSS Can be really frustrating. Things that should be simple are often surprisingly hard!\nThe most frustrating part of CSS has been layout (vertical and horizontal layout and alignment). But why has CSS been this way?\nA Little History will help!\nOriginally, HTML was created as a document-oriented language. Then CSS emerged as a way to make an HTML document appear more document-like, like Microsoft Word. So layout wasn\u0026rsquo;t much of a concern in the beginning. But as the web has evolved, so have the design needs of developers.\nFortunately, Flexbox has become a standard over the past few years. It\u0026rsquo;s designed to ensure that elements on a page behave predictively on varying screen sizes and devices.\nVertical Alignment Problem A common CSS problem occurs when trying to center a div vertically and horizontally on a page, hoping for something like this:\nA first attempt, could look like:\n\u0026lt;body\u0026gt; \u0026lt;div\u0026gt;This is my div!\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; html { height: 100%; } body { min-height: 100%; background-color: #ccc; margin: 0 auto; } div { width: 100px; height: 100px; outline: 1px solid red; } Possible Solutions\n Padding: Setting equal padding on the top and bottom of the element could work, but you would need to know the exact height of the element and container in order to get this exactly right. This can also get tedious when there is more than one element in a container. Margin: Adding some margins to the element we are trying to center. The same issues remain.  Note that margin: auto will center horizontally but only if you set a width, and it will not center vertically.   Absolute Positioning: Properties like top and left to position an element in the center. This, however, removes it from the document flow.  These could work in other scenarios\n line-height: When vertically centering a single line of text, line-height could be set to that of the whole container. vertical-align: Used to align words within a line of text (e.g., superscript, subscript).  Vertically centering an element depends on its context. Depending on your situation, one or more of the above techniques could work. Here\u0026rsquo;s an enlightening post on the matter.\nFlexbox to the Rescue html { height: 100%; } body { min-height: 100%; background-color: #ccc; margin: 0 auto; display: flex; flex-direction: row; justify-content: center; align-items: center; } div { width: 100px; height: 100px; outline: 1px solid red; } How It Works The display: flex property on a container, it becomes a flex container.\nflex-direction\nflex-direction is used to make the items in the container, the flex items, to \u0026ldquo;read\u0026rdquo; left-to-right (row), right-to-left (row-reverse), top-to-bottom (column), or bottom-to-top (column-reverse).\nflex-direction: row or row-reverse will make the main axis the same as the X-axis (horizontal) on a graph. Otherwise, it\u0026rsquo;ll be the Y-axis.\njustify-content\nThe justify-content property will align or justify the items along this main axis. It\u0026rsquo;ll even spacing between all the items (space-between and space-around).\nalign-items\nThe align-items property controls the alignment of items along the axis that goes across the main axis, the cross axis. If flex-direction: row is set, the main axis is the X-axis, and the cross-axis is the Y-axis.\nLastly, you can control how you want things to line up across the cross-axis by using align-content, such as space-between and space-around.\nIn Summary\u0026hellip;    Property What\u0026rsquo;s It Do? Examples     display  flex   flex-direction Sets the directional flow of flex items row, column   justify-content Align along flex-direction (main axis) center, space-between   align-items Align along non-flex-direction (cross axis) flex-start, center    That\u0026rsquo;s a lot of CSS properties! Don\u0026rsquo;t worry, you\u0026rsquo;re not expected to memorize all of them. Here\u0026rsquo;s a great resource.\nFooter Sticking to Bottom Problem Without Flexbox\nMaking the footer stay at the bottom of the screen can be done with absolute or fixed positioning. But, using absolute or fixed positioning means everything else on the page ignores the footer.\nThe text of \u0026lt;main\u0026gt; could easily run under the footer. We want the text to \u0026ldquo;push\u0026rdquo; the footer to the end of the page.\n\u0026lt;body\u0026gt; \u0026lt;header\u0026gt;This is my header.\u0026lt;/header\u0026gt; \u0026lt;main\u0026gt;\u0026lt;p\u0026gt;Blah blah blah blah blah...\u0026lt;/p\u0026gt;\u0026lt;/main\u0026gt; \u0026lt;footer\u0026gt;This is my footer!\u0026lt;/footer\u0026gt; \u0026lt;/body\u0026gt; html { height: 100%; } body { min-height: 100%; background-color: #ccc; margin: 0 auto; } footer { width: 100%; height: 50px; background-color: #888; } Flexbox to the Rescue The following makes the main axis: y-axis and the cross axis: x-axis.\n* { margin: 0 auto; } html, body { height: 100%; } main { min-height: 100%; background-color: #ccc; display: flex; flex-direction: column; justify-content: flex-start; } section { flex-grow: 1; } section p { margin: 10px; padding: 10px; } footer { width: 100%; background-color: #888; padding: 10px; } Flexbox Terms  align-content: How multiple rows or columns are spaced along the cross-axis. Takes the same properties as justify-content. flex-grow: If the flex container is too big for all the flex bases, the proportion a particular flex item will occupy flex-wrap: Defines item behavior if they expand beyond a single line. order: The order in which you want flex items to appear along the main access. The default is 0. Negative numbers are allowed. flex-basis: How big the flex items \u0026ldquo;want\u0026rdquo; to be.  The Holy Grail Layout The Holy Grail Layout describes a webpage with a header bar, a footer bar, and three columns along the middle: a wide \u0026ldquo;main\u0026rdquo; column, a navigation column on the left, and an advertisement, site map, or extra info column along the right.\nThe above described layout won\u0026rsquo;t work well on tiny screens. It\u0026rsquo;s common to stack things on top of each other for mobile views to make one single column.\nBefore Flexbox, this involved a lot of pushing and shoving with dimensions and positioning. With Flexbox, you can just change the flex-direction for smaller screen sizes, and you\u0026rsquo;re pretty much done!\nbody { display: flex; flex-direction: row; } @media screen and (max-width: 480px){ body { flex-direction: column; } } A layout so holy, it has its own Wikipedia article.\nExample\nSummary  Alignment, especially horizontal alignment, has traditionally been very difficult with CSS. The old way was to use floats but this was limited and very frustrating Recently CSS has been given a new feature, flexbox to aid in vertical and horizontal layout and alignment.     Go to flexbox labs    "
},
{
	"uri": "/golang/foundations/errors/",
	"title": "Generating and Handling Errors in Go",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Built in function: panic Errors are Values  Panic Panic is\n A built in function Used as a way to exit a program when an unexpected/unrecoverable error occurred Will cause the program to exit and display the panic message.  Syntax\npanic(interface{}) func main() { panic(\u0026#34;I forgot my towel!\u0026#34;) } Try Me\nHandling Other Code that Panics It is possible to prevent the exit of a program if another block of code panics.\nPlease read this article for information about the recover function.\nErrors Errors are values\n There are no try/catch blocks in go. Errors are checked using if statements  import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { err := errors.New(\u0026#34;emit macho dwarf: elf header corrupted\u0026#34;) // 1 \tif err != nil {\t// 2 \tfmt.Print(err) } } Try Me\n Create an error Check if there is an error and if there was print the error.  Functions That Return Errors Errors can be returned just like any type\nfunc ToErrOrNotToErr(e bool) (err error) { if e { err = errors.New(\u0026#34;emit macho dwarf: elf header corrupted\u0026#34;) // 1 \t} return } func main() { if err := ToErrOrNotToErr(true); err != nil { // 2 \tfmt.Println(\u0026#34;I erred\u0026#34;, err) } }  Create the error to be returned Check if there was an error returned. Passing true in the function we defined forces an error, so we print out the line. |Assign the error variable outside i  func ToErrOrNotToErr(e bool) (err error) { if e { err = errors.New(\u0026#34;emit macho dwarf: elf header corrupted\u0026#34;) // 1 \t} return } func main() { err := ToErrOrNotToErr(false) // 1  if err != nil { // 2 \tfmt.Println(\u0026#34;I erred here!\u0026#34;, err) } }  Another method is save the value outside the if statement, and then evaluate it. We evaluate the above err here to see if it is nil. It is nil because we told our function not to generate a new error. Therefore, nothing should be printed.  func main() { if s, err := Connect(\u0026#34;\u0026#34;, \u0026#34;adafs\u0026#34;, \u0026#34;https://some.service.com\u0026#34;); err == nil { fmt.Println(s) } else { fmt.Println(err) } } func Connect(user, token, url string) (string, error) { if user == \u0026#34;\u0026#34; { return \u0026#34;\u0026#34;, errors.New(\u0026#34;No user provided\u0026#34;) // 1 \t} return \u0026#34;Connected\u0026#34;, nil // 2 } Try Me\n We return an empty string, and return an error. If no error occurred, return the appropriate string value and nil so the caller know no error occurred.  Lab 1: Errors On Go Play Space\n"
},
{
	"uri": "/software-eng-essentials/git-foundations/git-branching-out-labs/",
	"title": "Git Branching Out Labs",
	"tags": [],
	"description": "",
	"content": "Branch Practice  Navigate back to our git-workshop repository. List all of the branches for this repo. This will show you, most likely, that you are on the master branch of this repository. It is green with an asterisk * because it\u0026rsquo;s the branch you\u0026rsquo;re currently on. Create a new branch called add-exercise without checking out the branch. List all of the branches for this repo. Now you should see both the master branch in green, and an additional add-exercise Switch over to the add-exercise List all of the branches for this repo. If your add-exercise is green, success! Create and switch to an entirely new branch called second in one line. Run the command to check which branch you\u0026rsquo;re on. If the branch you just created is green, success!     Go to Tagging lesson    Tagging  Navigate back to our git-workshop exercise repository. Creating a directory inside this directory called git-tag-exercise Add a README.md file. Commit this change. Run git tag -a v1.0.0 to create an Annotated tag attached to this specific commit with the message: \u0026ldquo;Remembering the moment I created a README\u0026rdquo;.  "
},
{
	"uri": "/python/foundation/formatting-and-input/",
	"title": "Input",
	"tags": [],
	"description": "",
	"content": "String Formatting Displaying Numbers and Strings We\u0026rsquo;ve introduced one built-in method for Python: print(). Another function important to strings is the str() method. We\u0026rsquo;ll use the str() method when we need to convert a number to a string.\nWe\u0026rsquo;d like to print a string that says \u0026ldquo;I am 24 years old\u0026rdquo;. Instead of just declaring a variable set to an integer and concatenating that variable with strings in the print() function, we have to do it differently, as you can see from the error you get when you try this.\nType the following into your PyDev Console to view the error:\nage = 49 print(\u0026#34;Monty Python is \u0026#34; + age + \u0026#34; years old.\u0026#34;) The error literally says TypeError: must be str, not int. It\u0026rsquo;s telling us that it wants a string! Not an int! How awesome is that!\nWe have three alternatives to fix this error.\nFirst option is to cast the variable. To cast is to change the variable from one data type to another. When working with print and the + operator, we need to cast all variables to a string, like the following:\nprint(\u0026#34;Monty Python is \u0026#34; + str(age) + \u0026#34; years old.\u0026#34;) Second option is to use commas to combine the strings and variables of any type, like the following:\nprint(\u0026#34;Monty Python is\u0026#34;, age, \u0026#34;years old.\u0026#34;) A third option is to use formatting operators\nPython3 Formatting In Python3 we\u0026rsquo;d write this string like so:\nage = 24 print(\u0026#34;I am {0} years old\u0026#34;.format(age)) In this example, we\u0026rsquo;re passing the variable age to the format() method and the format() method is looking for curly braces {} within our string to insert the variable\u0026rsquo;s value (as a string), which we set to the integer 24\nIf you run this in your PyDev console, the output should look like this:\nI am 24 years old. But what if we want to insert several different variables? Python3 has a solution for that as well:\nmy_age = 24 moms_age = 60 dads_age = 59 sisters_age = 35 If we set these variables first, we can use a print statement to refer to each one in any order we choose:\nprint(\u0026#34;\u0026#34;\u0026#34;My mom is {1} years old, and my dad is 1 year younger at {2} years old. My sister is 11 years older than me, which makes her {3} years old and I am only {0} years old.\u0026#34;\u0026#34;\u0026#34;.format(my_age, moms_age, dads_age, sisters_age)) Type the above print() statement into your PyDev console and press return\nYour output should look like this:\nMy mom is 60 years old, and my dad is 1 year younger at 59 years old. My sister is 11 years older than me, which makes her 35 years old and I am only 24 years old. TIP: Notice that we used three \u0026quot;\u0026quot;\u0026quot; quotation marks around our string. This is because it\u0026rsquo;s a block of text that would have been too long to fit on the screen. The triple quotations help us make line breaks without errors.\nYou may be wondering what the numbers within the {} represent, care to take a guess?\n Hint: It relates to the order of the variables as they\u0026rsquo;re written within the format() method.\n Now we\u0026rsquo;re getting into what\u0026rsquo;s called indexing. The index always starts at 0 and counts up, by 1 until the end of the list. Therefore in this example, my_age is index 0, moms_age is index 1 and so forth. The numbers within the {} correspond to the index of each variable. It\u0026rsquo;s okay if this is confusing now, we\u0026rsquo;ll go into much more detail in the following section.\nUsing Variables in Print Formatting\nWe can also use print formatting with the variable names. Using the example from before using variables by placing an f at the front of the quotes inside of the quotes.\nmy_age = 24 moms_age = 60 dads_age = 59 sisters_age = 35 print(f\u0026#34;\u0026#34;\u0026#34;My mom is {moms_age} years old, and my dad is 1 year younger at {dads_age} years old. My sister is 11 years older than me, which makes her {sisters_age} years old and I am only {dads_age} years old.\u0026#34;\u0026#34;\u0026#34;) User Input So far, all values that we have printed out and stored in variables have been typed right there in the code. Every time we would run the a program, it would give us the exact same output. This is not representative of many programs out there, as most programs take in some kind of input that will alter what the output is. In most cases, the input will come from the keyboard. For this very purpose, Python provides the function input(). input() takes in one argument (value in between the parenthesis), which is the prompt for the user.\nInput Example:\nname = input(\u0026#34;Enter your name: \u0026#34;) print(\u0026#34;Nice to meet you \u0026#34; + name + \u0026#34;!\u0026#34;) If you were to run the above code you would get the following:\nEnter your name: Dorothy Nice to meet you Dorothy!  Enter your name: is the prompt from the input function. This allows the user to know what you are wanting from them. Dorothy is what the user typed in. This value is then stored in the name variable. Nice to meet you and ! are the values in the print statement that will be the same every time you run the program. The second Dorothy is using the value that was given by the user and stored in the name variable.  Go to the Random Salary Exercise\n"
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/processes/",
	"title": "Processes",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Define a process View running processes Terminating a process  Introduction  When an application (or program) is running on your computer it is running as a process or as a set of processes. Once the program exits (completes execution successfully or crashes) the process is terminated. Processes take up computer (system) resources (such as CPU cycles, Memory, and Network I/O) while they are running.  When Processes are Running  A process can be running in the foreground or in the background  foreground: where you see and interact with it from the shell background: it is running but you are not interacting with it from the shell   When an application is not running it only takes up storage space (where the code and any persistent data is stored). Every process in UNIX has a process ID (often abbreviated as PID) that uniquely identifies the process.  Viewing Processes with the ps Command You can see a listing of the current processes running on your computer via the ps (process status) command.\nExamples of using the ps command:\nps ps ax ps ax -o \u0026#34;%cpu %mem cpu user command\u0026#34; | sort -nr | head ps ax | grep Chrome | wc -l Viewing Processes with Activity Monitor  Another way to view a list of your computer\u0026rsquo;s processes is to view them in the Activity Monitor. Open the Activity Monitor application and sort the list by the PID. As you look through the list, you\u0026rsquo;ll see the same PIDs that are listed in your terminal.  Terminating a Process You can force a process to terminate with the kill command but be careful - you don\u0026rsquo;t want to kill the wrong process!\nkill 92759 Summary  Applications run in one or more processes Each process uses system resources (CPU, memory, network, and file system) Each process has a unique Process ID or PID You can use the ps command to view a list of running Processes On a Mac, you can also use Activity Monitor to view the running Processes  "
},
{
	"uri": "/react/foundations/labs/lab-routing/",
	"title": "Routing",
	"tags": [],
	"description": "",
	"content": "The React Music Browser App  To get more experience with React Router, we will be building a Music Browser application. Below is a demo of the final product Click on the \u0026ldquo;Artists\u0026rdquo; link and then click on an artist to see the dynamic nested routes.    Step 1 - Clone Down the Starter Code Use git to clone the starter repository and checkout the starter branch. Then use yarn to install the node modules.\ncd some-directory-where-i-put-my-projects git clone https://github.com/one-thd/om_labs_react-music-browser.git cd om_labs_react-music-browser git checkout starter yarn Step 2 - Add the artists Route and ArtistList Component  Add the Artist link to the NavBar component. Use /artists as the to path. Add a Route to the list of routes in the App component. Remember to pass the artists data as a prop to the ArtistList component. Create the file components/ArtistList.js that defines and exports the ArtistList component. This component should render the artists data (at this time you can simply display the names of the artists).  Step 3a - Convert the list of Artist names into NavLinks Now we want to turn the names of the Artists into NavLinks. Each NavLink will define a to property that contains the id of the artist.\nOne nice trick is to use the useRouteMatch() hook to dynamically determine the base of the path, for example:\nconst match = useRouteMatch() // then use `match.url` for the base of the path. Thus we don\u0026rsquo;t assume anything about the path that got us to the current component.\nStep 3b - Add an AlbumList Component that is rendered as a Nested Parameterized Route Create the file components/AlbumList.js that defines and exports the AlbumList component. This component should render the albums data for the selected Artist.\nStep 3c - Add a Route to the ArtistList that renders the AlbumList This is the tricky part. How and where you add the Route will determine how the AlbumList appears as a nested route / child component of the ArtistList component.\nHere are some hints:\n Use a render prop in the Route to render the AlbumList component. The Route that you add to the ArtistList component will need to look up the artist object from the artists array and use this artist object to get the albums array to pass as a prop to the AlbumList component. You can use the Array.find method to lookup the artist from the artist id.  Remember that the function defined in the render prop has a props object that contains the match.params.artistId you will need to get the selected artist.    Step 4 - Add a SongList Component that is rendered as a Nested Parameterized Route This is pretty much the same steps as steps 3a, 3b, and 3c but applied to the AlbumList component:\n Convert the list of Album titles into NavLinks (again use the useRouteMatch() hook to get the base of the path) Create a SongList component that is rendered as a nested parameterized route Add a Route to the AlbumList component that renders the SongList passing in the array of songs as a prop.  Also, show some additional information about each song such as the duration and the rating. See the artists.json file for more details. You might even want to use an HTML \u0026lt;table\u0026gt; to display the song data.\nSee if you can get it all working!\n"
},
{
	"uri": "/software-eng-essentials/command-line-bash/scripting-and-receiving-input/",
	"title": "Scripting and receiving input",
	"tags": [],
	"description": "",
	"content": "Objectives  Command line arguments Variables Arrays User input Reading from STDIN  Command line arguments We have already created a script that receives command line arguments. The ekill program receives a \u0026lt;pid\u0026gt; argument. That argument was assigned to the $1 variable by the system default. A second command line argument would be assigned to $2.\nfanciercopy script\n#!/bin/bash # A fancier copy script  cp $1 $2 # Verify the copy worked echo Details for $2 ls -lh $2 Executing the fanciercopy script\n$ ./fanciercopy /tbs-archives/jcvd/highlights.data ./tps-reports.data Details for ./tps-reports.data drwxr—r-- 34 KXB0QJK staff 777K Oct 9 23:58 tps-reports.data Variables A variable is a label that represents data.\nSpecial variables In addition to $1 and $2, the system sets other special variables for you to use.\nSpecial variables\n   Variable Description     $0 The name of the Bash script.   $1-$9 The first 9 arguments to the Bash script.   $# How many arguments were passed to the Bash script.   $@ All the arguments supplied to the Bash script.   $? The exit status of the most recently run process.   $$ The process ID of the current script.   $USER The username of the user running the script.   $HOSTNAME The hostname of the machine the script is running on.   $SECONDS The number of seconds since the script was started.   $RANDOM Returns a different random number each time is it referred to.   $LINENO Returns the current line number in the Bash script.    Special variables\nSetting and calling variables If we take choose to name a variable var1 and assign it a value Beowulf, it would look like this:\nSetting a variable\n$ hero=Beowulf And when we want to call the variable:\nCalling a variable\n$ echo $hero Beowulf There are two things to remember:\n When setting the variable, leave no spaces around the = sign. When calling the variable, prepend a $ to the variable name.  Quotations We need to use single quotes to assign complex values with spaces to variable names.\nSingle quotes around values\n$ story=*Epic Poem* And double quotes when we want variable expansion or substitution to be allowed.\nDouble quotes around values, using substitution\n$ tag=\u0026#34;An $storyabout $hero\u0026#34; $ echo $tag An Epic Poem about Beowulf Command substitution allows us to take the output of a command or program (what would normally be printed to the screen) and save it as the value of a variable. To do this we place it within parens, preceded by a $ sign.\nCommand substitution does remove any newlines from the output.\n$ hereheis=$(ls | grep -i beowulf) $ echo $hereheis beowulf_1.txt beowulf_1_copy.txt beowulf_1_reversed.txt beowulf_1_sk8er.txt beowulf_complete.txt beowulf_head.txt Exercises\n  Create a simple script which will accept some arguments from the command line and echo out some details about them (e.g., how many are there, what is the second one, etc.).\n  Create a script which will print a random word. Hint: There is a file containing a list of words on your system (usually /usr/share/dict/words or /usr/dict/words).\n  Arrays Shell variables are great for holding a single variable. This kind of variable is called a scalar variable. However, there may be times when you need a variable to hold multiple values at one time. For this, you would use an array variable.\n# to add one element at a time to an array, specify the index number array_name[index]=\u0026#34;array_element\u0026#34; # to add several elements at once, surround the elements by parentheses array_name=(array_element_1 array_element_2 … array_element_n) The elements of an array are ordered by index numbers. To access a specific array element, you must reference it’s index number. The first index number of an array is always 0. To access the first element in an array, you must call that element by using the index 0.\n# given an array called \u0026#34;names\u0026#34; where each element is an individual name, add elements # with a space between. For elements with spaces in them, add quotations around them names=(Mike John Sarah Noah Nancy Diane \u0026#34;Mary Lou\u0026#34;) # to access the first name \u0026#34;Mike\u0026#34; echo \u0026#34;The first name is ${names[0]}\u0026#34; # output ⇒ The first name is Mike # to access the third name \u0026#34;Sarah\u0026#34; echo \u0026#34;The third name is ${names[2]}\u0026#34; # output ⇒ The third name is Sarah You can follow this convention for array - given an array’s length equal to n\n The first array element is always 0 The last array element is it’s length n minus 1 (n-1). Example, given an array with 5 elements, the last index will be length 5-1 ⇒ 4  To access all the elements in the array, you can use one of two ways:\n${array_name[*]} ${array_name[@]} # given our \u0026#34;name\u0026#34; array: names=(Mike John Sarah Noah Nancy Diane \u0026#34;Mary Lou\u0026#34;) echo \u0026#34;The names are ${names[*]}\u0026#34; # output ⇒ The names are Mike John Sarah Noah Nancy Diane Mary Lou echo \u0026#34;The names are still ${names[@]}\u0026#34; # output ⇒ The names are still Mike John Sarah Noah Nancy Diane Mary Lou There are several ways to modify an array:\nnames=(Mike John Sarah Noah Nancy Diane \u0026#34;Mary Lou\u0026#34;) # append another element to the array names+=(\u0026#34;Jordan\u0026#34;) #⇒ Mike John Sarah Noah Nancy Diane \u0026#34;Mary Lou\u0026#34; Jordan # BE CAREFUL! Without the parantheses, your value will be appended to the value in the lowest index position names+=\u0026#34;Jordan\u0026#34; #⇒ MikeJordan John Sarah Noah Nancy Diane \u0026#34;Mary Lou\u0026#34; # add an element to a specific index position (if empty will add a value, or will override the value in the index specified) names[4]=\u0026#34;Barbara\u0026#34; #⇒ Mike John Sarah Noah Barbara Diane Mary Lou # to copy an array new_names=(\u0026#34;${names[@]}\u0026#34;) #⇒ new_names=(Mike John Sarah Noah Diane Mary Lou) # to remove an element from an array unset names[1] #⇒ Mike Sarah Noah Diane Mary Lou # deleting an entire array unset names Exercises\n Create the tools array that consist of the following items: hammer, nails, screwdriver, duct tape, tape measure Practice accessing the elements one at a time and writing it to the terminal. Append a shovel to the tools array and write it to the terminal with the string \u0026ldquo;A ${tools[index]} has been added to the tools list.\u0026quot; Append a socket wrench to the array. Overwrite screwdriver with screws in the tools array. Remove the tape measure from the list. Copy the tools array to a new array named shopping_list. Delete the tools array.  User Input We have already written and executed bash scripts that took user input—command line arguments. But now we want to write scripts that deal more interactively with user input.\nIf we would like to prompt the user for input then we use a command called read. This command takes the input and will save it to a variable.\nThe basic syntax for read\nread \u0026lt;variable_name\u0026gt; .Interactive introduction script\n.Using read with introscript\n#!/bin/bash # Ask the user for their name echo Hello, who am I talking to? read varname echo It is nice to meet you $varname. executing the introscript\n$ ./introduction Hello, who am I talking to? JCVD It is nice to meet you JCVD. $ The read command has useful options that are essential for interactive scripts.\nUsing read with loginscript\n#!/bin/bash # Ask the user for login details  read -p \u0026#39;Username: \u0026#39; uservar read -sp \u0026#39;Password: \u0026#39; passvar echo echo Thank you, $uservar. We now have your login details. executing the loginscript\n$ ./loginscript Username: jcvd_fan_1960 Password: Thank you, jcvd_fan_1960. We now have your login details. $ Using read and multiple arguments with moviescript\n#!/bin/bash # Demonstrate how read actually works  echo What movies do you like? read movie1 movie2 movie3 echo Your first movies was: $movie1 echo Your second movies was: $movie2 echo Your third movies was: $movie3 executing the moviescript\n$ ./moviescript What movies do you like? Kickboxer Timecop Cyborg Your first movies was: Kickboxer Your second movies was: Timecop Your third movies was: Cyborg $ ./moviescript What movies do you like? Kickboxer Timecop Universal Soldier Your first movies was: Kickboxer Your second movies was: Timecop Your third movies was: Universal Soldier $ Reading from STDIN The ability to pipeline a series of simple, single purpose commands together to create a larger solution tailored to our exact is one of the real strengths of Unix. Once we have a firm grasp of these commands and concepts, we can easily implement this with our scripts also. By proficiently using redirection together with Unix utilites, we can create scripts that act as filters to modify data in specific ways for us.\nIn the Basics lesson, we learned that Unix accomodates piping and redirection by way of special files. Each process gets its own set of files (one for STDIN, STDOUT and STDERR respectively) and they are linked when piping or redirection is invoked.\nUsing STDIN and awk with blockbustersummary\n#!/bin/bash # A basic summary of blockbuster movies echo Here is a summary of the blockbuster movie data: echo ================================================ echo cat /dev/stdin | awk *$3 \u0026gt;= 100 {print $1 \u0026#34; - \u0026#34; $2 \u0026#34; $\u0026#34; $3 \u0026#34; (in millions)\u0026#34;}* inspecting the movieboxofficedata.txt file\n$ cat movieboxofficedata.txt Under Seagal 1 DieHard Willis 5 Predator Arnold 11 Commando Arnold 13 Kickboxer JCVD 130 Timecop JCVD 120 Sidekicks Norris 101 KarateKid Macchio 100 Rambo Stallone 107 Cyborg JCVD 100 executing the blockbustersummary script\n$ cat movieboxofficedata.txt | ./blockbustersummary Here is a summary of the blockbuster movie data: ================================================ Kickboxer - JCVD $ 130 (in millions) Timecop - JCVD $ 120 (in millions) Sidekicks - Norris $ 101 (in millions) KarateKid - Macchio $ 100 (in millions) Rambo - Stallone $ 107 (in millions) Cyborg - JCVD $ 100 (in millions) Exercises\n Create a simple script which will ask the user for a few pieces of information, then combine this into a message which is echo’d to the screen. Add to the previous script to add in some data coming from command line arguments and maybe some of the other system variables. Create a script which will take data from STDIN and print the 3rd line only.  "
},
{
	"uri": "/software-eng-essentials/testing/",
	"title": "Testing",
	"tags": [],
	"description": "",
	"content": "Welcome to Testing! "
},
{
	"uri": "/web-essentials/webmastery-foundations/flexbox-labs/",
	"title": "Flexbox Labs",
	"tags": [],
	"description": "",
	"content": " Complete the CSS: Using Flexbox for Layout Play Flexbox Froggy and try to complete all 24 levels Play Flexbox Defense and try to complete all 12 levels Complete the Flexbox Cats Lab  Additional Resources  Flexbox Playground The Ultimate Flexbox Cheatsheet CSS Tricks Guide to Flexbox A Visual Guide to CSS3 Flexbox Properties Solved by Flexbox Flexplorer Holy Grail Layout - Solved By Flexbox The CSS grid Module CSS Tricks\u0026rsquo; Guide to Flexbox A Visual Guide to CSS Flexbox Properties Solved by Flexbox Flexplorer  Screencasts      "
},
{
	"uri": "/software-eng-essentials/git-foundations/gitting-back-together/",
	"title": "Gitting back together",
	"tags": [],
	"description": "",
	"content": "Merging Merging allows two branches back together to be put back together by combining multiple sequences of commits into one unified history.\nIt is common to branch off of master when creating a new feature so a new feature can be worked on without messing with master. Once the new feature is done, it can be merged into master.\n To demonstrate the below image, make sure to:\n start with a new repository create an initial commit create and checkout a branch called feature add three commits checkout master and add two commits   In the below image there are two branches Master and Feature.\nA merge would combine these two branches\u0026rsquo; histories and create an additional commit showing the merge.\nA merge is done with the command:\ngit merge \u0026lt;branch-you-are-wanting-commits-from\u0026gt; To merge into master, master must be checked out. Merging into commits from feature are being added into master.\nSo in this case, after checking out master, do:\ngit merge feature In the image below, Feature is being merged into Master.\n  Now master will have the commits from feature, while any commits from master do not affect the feature branch.\nWhen doing a merge, Git will try it\u0026rsquo;s best to automatically merge the histories of the two branches. Unfortunately, git can encounter data that is changed in both histories it will be unable to automatically merge the two branches causing a merge conflict.\nMerge Conflict A merge conflict occurs when git does a line-by-line comparison and finds differences between two of the same file on the two merging branches. Merge conflicts usually can be avoided by making sure that each developer is on their own branch and working on separate features, but not that is not always possible.\nEven when merging diligently, merge conflicts still happen!\nMerge Conflict Demo The following demo will create (and resolve) a merge conflict on purpose! 😱\nThe following will create and initialize a new git repository. Then, create a test text file and put some content in it.\nmkdir merge-conflicts-exercise cd merge-conflicts-exercise git init echo Text within file from the master branch \u0026gt; merge-exercise.txt git add merge-exercise.txt git commit -m \u0026#34;first commit on master branch\u0026#34; To have a merge conflict, there needs to be two branches!\ngit checkout -b merge-conflict echo Adding more text within my file from merge-conflict \u0026gt;\u0026gt; merge-exercise.txt git add merge-exercise.txt git commit -m \u0026#34;first commit on merge-conflict\u0026#34; Now there is a separate branch called merge-conflict which, initially, is exactly the same as the master branch. Once different text was put into the same file, the chance of merge conflicts grew.\nGo back to the master branch and edit merge-exercise.txt one more time:\ngit checkout master echo Putting more text into my file from the master branch \u0026gt;\u0026gt; merge-exercise.txt git add merge-exercise.txt git commit -m \u0026#34;second commit on master branch\u0026#34; Try to merge the two branches separate changes together. (All changes happened on the same line of the same file!)\nRemain on the master branch and execute the following in Terminal:\ngit merge merge-conflict This should output an error stating:\nAuto-merging merge-exercise.txt CONFLICT (content): Merge conflict in merge-exercise.txt Automatic merge failed; fix conflicts and then commit the result. Open a text editor to see exactly where the merge conflict is happening:\nThe merge conflict can be fixed by editing the files within the text editor to say exactly what it\u0026rsquo;s supposed to.\nIn the real world, this may be a matter of asking teammates what they intended to do with that part of the code and explaining your changes to the code as well, so that the final changes are as intended.\nIn this demo, use the changes from the master branch.\nIf using VS Code, click the Accept Current Change link above the corresponding code. Then, save the file, stage and commit the merge.\nCons of Merging Merge commits can add extra noise to a commit history!\nSince Git forces a merge commit message. So, amongst all commits, there are merge commit messages, which could make Large project\u0026rsquo;s commit histories quite large.\nRebase is a good alternative to combine branches, while not adding an additional commit. Rebase is covered in the next section.\n   Go to the Merge Lab    Rebasing Rebase is another option Git gives to merge two branches.\nRebase creates a linear history that does not have any merge commits, making it enticing in some scenarios.\nTo rebase, use the command:\ngit rebase \u0026lt;branch-you-want-commits-from\u0026gt; Rebasing: Behind the scenes When you use git rebase, it actually reapplies commits on top of another base tip without a general commit message.\n  If git rebase master was used while on the my-branch:\n look for the base commit of my-branch (b) grab all of the commits between that base and HEAD (e and f) shift the commits onto the HEAD of the branch being rebasing onto (master).  Now my-branch is up to date. To put my-branch changes onto the master branch, then git checkout master and git merge our-branch.\n   Go to the Rebase lab    Interactive rebasing Interactive rebasing allows individually decide what to do with each commit.\nTo do interactive rebase, use the --interactive (or -i for short) flag:\ngit rebase -i HEAD~n Just like with normal rebasing, n represents the number of commits to interact with during rebasing.\nOnce an interactive rebase has started, git will open the configured text editor with something like the following:\npick 33d5b7a Editing URL for Asciidocs pick 9455ab2 First section of merge and rebase pick f7219ef Saving to take rebase image for the exercise This is a list of the last n commits with the commit messages and the particular options of what to do with each commit next to each commit. Some of these options are pick, reword, edit, squash, fixup or exec.\nRebasing Options Here is a high level description of each of the options are:\n pick: use commit reword: allows changing of ONLY the commit message, NOT the commit changes edit: allows changing of BOTH commit contents AND commit message (git allows the commit contents to be edited is by \u0026ldquo;pausing\u0026rdquo; the rebase; so the commit can be amended) squash: use commit, but meld into previous commit fixup: like \u0026ldquo;squash\u0026rdquo;, but discard this commit\u0026rsquo;s log message exec: run command (the rest of the line) using shell  reword option If the above example was updated to reword the third commit, it would look like:\npick 33d5b7a Editing URL for Asciidocs pick 9455ab2 First section of merge and rebase reword f7219ef Removed terminal screenshot for text Once the changes are saved and the editor closed the editor, a second text editor screen would open to show exactly what is being altered.\nIf it looks good, close the editor. If a commit message needs editing, it can be done right here. Just be sure not to delete any lines entirely.\nThen save changes and close the editor, concluding the rebase.\nThe project history after saving changes will be added to the base tip of the master branch, allowing insignificant or \u0026ldquo;messy\u0026rdquo; commits in commit history to be eliminated.\nsquash option Squashing a commit means to move the changes introduced in said commit into its parent so that you end up with one commit instead of two (or more).\nSometimes commit messages are only relevant for the developer who generated them, so they should be simplified to fewer commits before submitting it to a shared repository.\nTyping git rebase -i HEAD~3 with the above example and adding squash the second and third commit, it would look like:\npick 33d5b7a Editing URL for Asciidocs squash 9455ab2 First section of merge and rebase squash f7219ef Removed terminal screenshot for text Be sure to place pick on the latest one, as that\u0026rsquo;s the commit git wants to choose to \u0026ldquo;squash\u0026rdquo; the rest of the commits into. All changes and SHA1 hashes will stay within the file, it\u0026rsquo;s simply the commit messages themselves that are pairing down.\nSave your pick and squash choices, and then exit the text editor. This is very important.\nNow your text editor will open automatically, and this window will give the opportunity to change the text of your commit.\n Some lines have the # symbol in front of them. Keep those lines, and keep the # where it is. Git will ignore those lines, and only look at the lines that are not starting with #.\n There are a couple of choices to be made here:\n keep all of the text from each commit message, and it\u0026rsquo;ll be viewable in the order that the commits happened, just under the same commit now that they\u0026rsquo;re squashed. actually just delete all of the commit messages and use the first message only. edit each one of them to be more descriptive.  To delete all but one, just delete the commit text only . Do not delete anything but the actual message.\nSave the changes, then close the text editor again and return to Terminal.\n If there are any merge conflicts, those will need to be resolved first. This will be shown in a later lesson.\n Now, git log will show only see the initial commit and the commit that had pick beside it when going through the process of squashing.\nAutosquash Squashing can be tedious if there are more than just a few commits to squash. That is where --autosquash comes into the picture.\nUsed with rebase and the interactive mode:\ngit rebase -i --autosquash A text editor will pop up with a \u0026quot;fixup!\u0026quot; commit. Type fixup in place of pick, and that commit message will be disregarded by git.\nNow close the text editor and type git log to see that the \u0026quot;fixup!\u0026quot; commit has now been squashed into the commit chosen when doing --fixup\nNoop If the text editor opens in the squashing process and noop shows, go through the process of grabbing a specific SHA1 and run:\ngit rebase -i 123456789123456789 (example SHA1, do not copy/paste)\nThen, the text editor will open up with the commit that can be fixup or squash to leave one remaining commit in the commit history.\nMerge Conflicts While Rebasing If a merge conflict occurs within the rebase, git needs the rebase to be completed by either changing the document and adding the changes, then continuing, or throwing out the rebase altogether.\nTo throw out changes use either git rebase --abort or git rebase --skip.\n git rebase --skip is used if throwing away the commit on a branch completely is desired. Be careful not to removed needed changes with --skip. git rebase --abort is used to leave the rebase and reset HEAD to the original branch. If was provided when the rebase operation was started, then HEAD will be reset to . Otherwise HEAD will be reset to where it was when the rebase operation was started.     Go to the Interactive Rebasing Lab and Rebase vs merge    "
},
{
	"uri": "/software-eng-essentials/git-foundations/gitting-back-together-labs/",
	"title": "Gitting Back Together Labs",
	"tags": [],
	"description": "",
	"content": "Merge Inside your existing repository (If you did not already create a repository, do so now) and checkout the master branch. Within this folder, create a new folder called merge-practice.\nCreate a new text file called merge-practice.txt and place the following text inside of that text file: Howdy there!. Stage these changes, then commit them with the message \u0026quot;Created merge practice file.\u0026quot;.\nCreate and checkout a new branch called conflict. Add the following text as a second line inside of merge-practice.txt: Second line of text. Then stage these changes, then commit them with a descriptive message.\nSwitch back to the master branch. Add the following text as a second line inside of merge-practice.txt: Wait! I thought I already put a second line of text. Then stage these changes, then commit them with a descriptive message.\nTry to merge the conflict branch into master. OH NO! CONFLICT! Open a text editor and fix the conflict to keep the changes from conflict. Save the file, stage the changes, and commit them with a descriptive message.\n   Go to the Rebasing Lab    Rebase Inside your existing repository (If you did not already create a repository, do so now) and checkout the master branch. Within this folder, create a new folder called rebase-practice.\nThe following demo shows the need for git rebase in order to keep commit history free of a merge commit.\nCreate a new branch called feature, but remain on the master branch.\nWhile on master branch, create a new text file called english-greetings.txt and place the following text inside of that text file: Hello! Hey!. Stage these changes, then commit them with the message Created first two english greetings..\nSwitch to the feature branch. Add a second file called spanish-greetings.txt: Hola!. Then stage these changes, then commit them with the message Created first spanish greetings..\nTo keep your feature branch up to date with master, you would need to add all changes that occurred in master since feature was created.\nIt\u0026rsquo;s time for a rebase.\nStay on the feature branch, and rebase master. Now you should see the english-greeting.txt from feature. There should be no reason to add or commit since we\u0026rsquo;re doing a rebase.\nSwitch to the master branch. Merge feature and all of the commits will be added on top of the changes already occurring on the master branch.\n   Go to the Interactive Rebasing lab    Interactive Rebasing Demo To practice, we\u0026rsquo;ll create multiple commits on branches. The git rebase -i command will put all of your commit messages into one commit SHA-1.\nNavigate inside of your existing rebase-practice directory.\nCreate a new text file called squash-practice.txt and place the following text inside of that text file: Squashing me down!. Stage these changes, then commit them with the message \u0026quot;Created squash practice file.\u0026quot;.\nCreate a branch called bug-fix and check it out. Append the following text inside of squash-practice.txt: I love multiple lines!. Stage these changes, then commit them with the message \u0026quot;Added second line to file.\u0026quot;.\nAdd 5 additional commits to the README.md file now (You can use the above as reference).\nNow, if you run git log you\u0026rsquo;ll see the original \u0026ldquo;Initial commit\u0026rdquo;, and all of the commits you made on branch bug-fix.\nStart an interactive rebase with 5 commits. \u0026ldquo;squash\u0026rdquo; the rest of the commits into the most recent commit.\nSave your pick and squash choices, and then exit the text editor. This is very important.\nKeep all of the text from each commit message, and it\u0026rsquo;ll be viewable in the order that the commits happened, just under the same commit now that we\u0026rsquo;ve squashed them.\nSave your changes, then close your text editor again and return to Terminal.\nIf there are any merge conflicts, you\u0026rsquo;ll have to resolve those first.\nNow, if you run git log you\u0026rsquo;ll only see the initial commit and the commit you decided to pick when you were going through the process of squashing.\nRebasing vs Merging Some people argue that rebasing messes up the project\u0026rsquo;s history and refuse to rebase as a result. Below is an explanation of why they feel that way.\n  If commits are made to the master branch after a new feature has been started in another branch, this will result in the feature branch being behind the master branch.\n  If the new commits your co-worker pushed to master are relevant to the feature you\u0026rsquo;re working on, you can incorporate those commits into your local branch by either merging or rebasing.\nThe merge option A merge command would bring in the new changes into the feature branch, like:\ngit checkout local-feature-branch git merge master For a more concise command:\ngit merge master local-feature-branch A merge commit will be created with a generic merge commit in the feature branch history looking like:\n  This option does not change the existing branch, allowing a person to go back in both branch histories and see exactly when branches were merged and who merged them. If that information is important to your team, merging is an available option for you.\nThe rebase option Using the previous scenario, it is also possible to rebase the local feature branch:\ngit checkout local-feature-branch git rebase master This will rewrite the project commit history by creating brand new commits on the original branch. All of these new commits will be incorporated into the local-feature-branch branch.\n  This results in a history without merge commits and cause the project history to be entirely linear. There are no forks throughout the project history, unlike merge.\nrebase does make being able to accurately trace when, over the course of time each and every change happened more challenging.\n"
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/supplemental/",
	"title": "Additional Resources",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/software-eng-essentials/command-line-bash/control-flow-loops-and-functions/",
	"title": "Control flow loops and functions",
	"tags": [],
	"description": "",
	"content": "Learning to use the power of the command line and bash shell scripting\n Control Flow - if and case Statements Loops - while/until/for Functions select statements  if and case statements The if statement An if statement basically says, if a particular test is true, then perform a given set of actions. If it is not true then don’t perform those actions. Anything between then and fi — if backwards—will be executed only if the test (between the square brackets) is true.\n#!/bin/bash  if [ $1 -gt 100 ] then echo Hey that\\\u0026#39;s a big number. pwd fi date Test The square brackets [] in the if statement above are actually a reference to the command test. Check the man page for test to see all of the possible operators, but some of the more common ones are listed below.\n   Operator Description     ! EXPRESSION The EXPRESSION is false.   -n STRING The length of STRING is greater than zero.   -z STRING The lengh of STRING is zero (ie it is empty).   STRING1 = STRING2 STRING1 is equal to STRING2   STRING1 != STRING2 STRING1 is not equal to STRING2   INTEGER1 -eq INTEGER2 INTEGER1 is numerically equal to INTEGER2   INTEGER1 -gt INTEGER2 INTEGER1 is numerically greater than INTEGER2   INTEGER1 -lt INTEGER2 INTEGER1 is numerically less than INTEGER2   -d FILE FILE exists and is a directory.   -e FILE FILE exists.   -r FILE FILE exists and the read permission is granted.   -s FILE FILE exists and it’s size is greater than zero (ie. it is not empty).   -w FILE FILE exists and the write permission is granted.   -x FILE FILE exists and the execute permission is granted.    Boolean Operations Sometimes we only want to do something if multiple conditions are met. Other times we would like to perform the action if one condition is met. We can accommodate these with boolean operators.\n  \u0026amp;\u0026amp; — \u0026ldquo;and\u0026rdquo;\n  || — \u0026ldquo;or\u0026rdquo;\n  Looking for a readable and sizeable file\n#!/bin/bash # and example if [ -r $1 ] \u0026amp;\u0026amp; [ -s $1 ] then echo This file is useful. fi Or example\n#!/bin/bash # or example if [ $USER == \u0026#39;bob\u0026#39; ] || [ $USER == \u0026#39;andy\u0026#39; ] then ls -alh else ls fi Exercises\n Create a bash script which will take 2 numbers as command line arguments. It will print to the screen the larger of the two numbers. Create a bash script which will accept a file as a command line argument and analyse it in certain ways. E.g. you could check if the file is executable or writable. You should print a certain message if true and another if false. Create a bash script which will print a fun message based upon which day of the week it is (e.g., Happy hump day for Wednesday, TGIF for Friday etc).  case Statement The case statement is very similar to the if statement, as it helps with the decision making in our programs.\nSometimes, case statements will appear DRYER and clearer than an if/elif statement with multiple selections; however, both work the same in doing conditional decision making to control processing flow.\nThe basic syntax of a case..esac statement\ncase $test_variable in match1) task to execute if true;; match2) task to execute if true;; . . . matchn) task to execute if true;; *) esac queen=\u0026#34;Daenerys\u0026#34; case \u0026#34;$queen\u0026#34; in \u0026#34;Cercei\u0026#34;) echo \u0026#34;We are doomed!\u0026#34;;; \u0026#34;Yara Greyjoy\u0026#34;) echo \u0026#34;She\u0026#39;d lead better than her brother!\u0026#34;;; \u0026#34;Daenerys\u0026#34;) echo \u0026#34;The Mother of Dragons. She is the true Queen!\u0026#34;;; *) esac This produces the following output: The Mother of Dragons. She is the true Queen!\nExercise\n Create a bash script which will ask your user to print an animal. Based on the animal, echo the sound that animal makes. Create a bash script that asks the user to input an alphabet and check whether it is vowel or consonant. Echo the results.  Loops -while/until/for while loop While loops are used to allow our program to loop through a task if the test condition evaluates to TRUE.\nwhile test; do #code to be repeated done Repeats the code while the test returns TRUE\n#!/bin/bash  #set variable lannister_heirs=3 #while the variable is not equal to 0, write the value and decrement by 1. while [[ \u0026#34;$lannister_heirs\u0026#34; -ne 0 ]]; do echo \u0026#34;How many Lannisters are alive to take the throne? There are $lannister_heirs. Oh no, an attack!\u0026#34; lannister_heirs=`expr $lannister_heirs - 1` done echo \u0026#34;Oh no, no more Lannisters to take the Iron Throne!\u0026#34; exit 0 This produces the following output:\nHow many Lannisters are alive to take the throne? There are 3. Oh no, an attack! How many Lannisters are alive to take the throne? There are 2. Oh no, an attack! How many Lannisters are alive to take the throne? There are 1. Oh no, an attack! Oh no, no more Lannisters to take the Iron Throne! until loop The until loop is similar to the while loop, except it loops through a task if the test condition evaluates to FALSE.\nuntil test; do #code to be repeated done Repeat the code block until the test returns true. As long as the test returns false, the block will be repeated.\n#!/bin/bash  # set variable read -p \u0026#34;Can you guess what Hodor means? Enter your guess: \u0026#34; var # until the input value of \u0026#34;var\u0026#34; is \u0026#34;Bar\u0026#34;, # the program will continue asking for input until [[ \u0026#34;$var\u0026#34; = \u0026#34;Hold the door\u0026#34; ]]; do echo \u0026#34;$varis not the meaning! Guess again:\u0026#34; read var done #When the correct word is given, the program terminates echo \u0026#34;That is correct! The meaning of Hodor is $var!\u0026#34; exit 0 This produces the following output:\nCan you guess what Hodor means? Enter your guess: Home door Home door is not the meaning! Guess again: Hold or Hold or is not the meaning! Guess again: Hold the door That is correct! The meaning of Hodor is Hold the door! When using while and until loops, and variable comparison, be sure to avoid infinite loops by incrementing, decrementing, or otherwise modifying one of the variables in the test.\nfor loop The for loop is a little different than the while and until loop. This loop allows you to iterate through a list and perform an action for each item in the list.\nfor item in item1 item2 item3 do echo \u0026#34;$item\u0026#34; done for name in Sansa Arya Robb Bran Rickon do echo \u0026#34;$name\u0026#34; done Output:\nSansa Arya Robb Bran Rickon houses_of_westeros=(Baratheon Tully Greyjoy Stark Lannister Tyrell Martell Targaryen) for house in ${houses_of_westeros[@]} do if [[ \u0026#34;$house\u0026#34; = \u0026#34;Stark\u0026#34; ]]; then echo \u0026#34;House $houseis my favorite.\u0026#34; else echo \u0026#34;House $houseis okay.\u0026#34; fi done Output\nHouse Baratheon is okay. House Tully is okay. House Greyjoy is okay. House Stark is my favorite. House Lannister is okay. House Tyrell is okay. House Martell is okay. House Targaryen is okay. break and continue statements break statement The break statement teminates the execution of an entire loop and skips to the lines following the end of the loop.\n#!/bin/bash num=0 while [[ \u0026#34;$num\u0026#34; -lt 10 ]]; do echo \u0026#34;$num\u0026#34; if [[ \u0026#34;$num\u0026#34; -eq 6 ]]; then echo $(($num + 3)) break fi num=`expr $num + 1` done echo \u0026#34;We have left the loop\u0026#34; The output - notice after the count to 6, it skips to 9 and jumps out the loop.\n0 1 2 3 4 5 6 9 We have left the loop The continue Statement The continue statement is similar to the break statement, except it exits the current iteration of the loop rather than the entire loop.\nnums=\u0026#34;10 12 13 25 21 44\u0026#34; for num in $nums do n=`expr $num % 2` if [ $n -eq 0 ] then echo \u0026#34;$numis an even number!!\u0026#34; continue fi echo \u0026#34;Found odd number $num\u0026#34; done This produces the following output:\n10 is an even number!! 12 is an even number!! Found odd number 13 Found odd number 25 Found odd number 21 44 is an even number!! Exercise\n Create a program that stores a value between 1 and 10. Ask the user to guess the stored value. Use a while or until loop to keep asking for the a guess. Once the user guesses correctly, exit the program. Write a program to read the input year from a user and check whether the given year is leap year. Make use of conditionals and loops—you choose!  Example:\n$ Input year: 2004 #⇒ 2004 is leap year.\nFunctions Functions in bash may take the following form:\nshell function\\_name () { \u0026amp;lt;function\\_commands\u0026gt; }\nPassing arguments to a function Like in other programming languages, bash functions may be passed arguments.\nThe first argument is assigned to the variable $1 by the system.\n#!/bin/bash # Passing a single argument to a function epic_characters () { echo I am $1 } epic_characters Beowulf epic_characters Grendel The second argument is assigned to the variable $2.\n#!/bin/bash # Passing two arguments to a function epic_characters () { echo I am $1 the $2! } epic_characters Beowulf hero epic_characters Grendel monster  $0 is the variable name assigned to the name of your program. $# is the variable name assigned to the number of arguments passed.\n Return values Many programming languages have functions which may give a return value from their functions. Bash functions don\u0026rsquo;t allow us to do this. They do however allow us to set a return status.\nScript with return status\nA return_status script\n#!/bin/bash  # Setting a return status for a function print\\_something () { echo Hello $1 return 5 } print\\_something Beowulf print\\_something Grendel echo The previous function has a return value of $? Executing return_status\n$ ./return_status Hello Beowulf Hello Grendel The previous function has a return value of 5 A return status of 0 usually indicates that everything went successfully. A non zero value would indicate that an error occurred.\nOverriding commands It is possible to name a function as the same name as a command you would normally use on the command line. This allows us to create a wrapper.\n#!/bin/bash # Create a wrapper around the command ls ls () { command ls -lh } ls When we have a function with the same name as a command, we need to put the keyword command in front of the the name when we want the command—as opposed to the function—as the function normally takes precedence.\nselect Statements and Menus The select statement is used to create an interactive user menu from with a bash script.\nselect var in list_item1 list_item2 ... list_itemn do task_1 task_2 . . . task_n done Example:\nselect kingdom in North Vale Stormlands Reach Westerlands \u0026#34;Iron Islands\u0026#34; Dorne do echo \u0026#34;You chose $kingdom\u0026#34; done This will create the numbered list below:\n1) North 3) Stormlands 5) Westerlands 7) Dorne 2) Vale 4) Reach 6) Iron Islands Each list item is numbered. To select an item, type in the number next to the item. Once the choice is made, the tasks within the do and done will run: This will create the numbered list below:\n#? 1 You chose North Unfortunately, the program does not end. #? 6 You chose Iron Islands #? 3 You chose Stormlands #? 2 You chose Vale #? To make the program terminate, we much incorporate control flow with a case or if statement, combined with an explicit exit command.\nselect kingdom in North Vale Stormlands Reach Westerlands \u0026#34;Iron Islands\u0026#34; Dorne exit do if [[ \u0026#34;$kingdom\u0026#34;=\u0026#34;exit\u0026#34; ]]; then echo \u0026#34;Exiting...\u0026#34; exit 0 else echo \u0026#34;You chose $kingdom\u0026#34; fi done Now we have an exit option that we can select to end the program:\n1) North 3) Stormlands 5) Westerlands 7) Dorne 2) Vale 4) Reach 6) Iron Islands 8) exit #? 8 Exiting... Sometimes, you want to give your users more direction on what they should do when presented with the select menu. You can do this by modifying your prompt from #?, which is the default prompt. By making use of the Bash prompt PS3, we can offer a customized prompt with our select menu:\nPS3=\u0026#34;Choose your kingdom from above:\u0026#34; select kingdom in North Vale Stormlands Reach Westerlands \u0026#34;Iron Islands\u0026#34; Dorne exit do if [[ \u0026#34;$kingdom\u0026#34;=\u0026#34;exit\u0026#34; ]]; then echo \u0026#34;Exiting...\u0026#34; exit 0 else echo \u0026#34;You chose $kingdom\u0026#34; fi done This presents the output below:\n1) North 3) Stormlands 5) Westerlands 7) Dorne 2) Vale 4) Reach 6) Iron Islands 8) exit Choose your kingdom from above: "
},
{
	"uri": "/web-essentials/webmastery-foundations/grid/",
	"title": "CSS Grid",
	"tags": [],
	"description": "",
	"content": "CSS grid layout (or CSS grid) is a technique in Cascading Style Sheets that allows web developers to create complex responsive web design layouts more easily and consistently across browsers.\nOther webpage layout methods that have been covered are box model and CSS flexbox.\n CSS Grid is a two-dimensional, grid-based layout system. Flexbox is intended for simple, one-dimensional layouts.  Grid Set Up A grid layout consists of a container tag, with one or more nested tags. These nested tags are placed inside columns and rows.\nExample\ngrid_intro.html\n\u0026lt;div class=\u0026#34;grid-container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;grid-item\u0026#34;\u0026gt;1\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;grid-item\u0026#34;\u0026gt;2\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;grid-item\u0026#34;\u0026gt;3\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;grid-item\u0026#34;\u0026gt;4\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;grid-item\u0026#34;\u0026gt;5\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;grid-item\u0026#34;\u0026gt;6\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;grid-item\u0026#34;\u0026gt;7\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;grid-item\u0026#34;\u0026gt;8\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;grid-item\u0026#34;\u0026gt;9\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; main.css\n.grid-container{ display: grid; // 1 grid-template-columns: auto auto auto; // 2 grid-template-rows: 25% 45% 30%; // 3 } [class*=\u0026#34;grid-item\u0026#34;]{ border: 2px solid black; background-color: lightblue; padding: 20px; font-size: 30px; text-align: center; } Initial Grid display defines the element as a grid container and sets up if the grid width. The two options grid and inline-grid:\n  grid:\n respect left \u0026amp; right margins and padding, but not top \u0026amp; bottom other elements are placed to their left and right full-width if width not defined    inline-grid\n other elements are placed to their left and right respect top \u0026amp; bottom margins and padding respect height and width of the content of the elements    grid-template-columns defines the number, naming and spacing of columns of the grid. In this case, there are three columns created of equal size.\n  grid-template-rows defines the number, naming and spacing of rows of the grid. In this case, there are three rows that take up 25%, 45%, and 30%.\n  Additional Values\nTo keep the columns the same size, the repeat function gives a shorthand option.\nShorthand for repeating column size\n.grid-container{ display: grid; grid-template-columns: repeat(3, auto); grid-template-rows: 25% 45% 30%; } fr fractional unit CSS Grid features the new fr unit allows allocating a fractional share of available space to elements.\nThe arithmetic for this is to sum up the numbers prepending each fr in your CSS Grid expression, and that will be the denominator under a numerator of 1.\n 1fr 5fr would allocate it\u0026rsquo;s smallest share to be 1/6. 2fr 4fr would also allocate it\u0026rsquo;s smallest share to be 1/6. 2fr 5fr would allocate it\u0026rsquo;s smallest share to be 1/7.  The fr unit can be mixed with other unit types. If px or em units are used, then fr elements will automatically expand to take up space.\nExample\nThe following sets up a grid to have 4 columns:\n 1st column: 30px 2nd column: 1fr 3rd column: 2fr 4th column: 1fr  The 1st column will take up exactly 30px. The 2nd, 3rd and 4th column with reside in the area left over(parent element size - 30px).\nBetween the three columns, we have 4 slots to work with. This means:\n 2nd column: 1fr = 1/4 of the slots available 3rd column: 2fr = 2/4 = 1/2 of the slots available (So it will be twice as big as the 2nd and 4th column) 4th column: 1fr = 1/4 of the slots available  .grid-container{ display: grid; grid-template-columns: 60px 1fr 2fr 1fr; grid-template-rows: 25% 45% 30%; } Lines Each item within the grid is called a grid line ([row][column]). Each line has a positive and a negative value.\nPositive and Negative Coordinates for a 3x3 grid Gaps The space that is between all rows and columns is called a gap.\nYou can arrange the gaps with:\n grid-column-gap: defines the space between each column grid-row-gap: defines the space between each row grid-gap: defines the space between each column and row.  To set up a grid with a row space of 15px and a column space of 10px: grid-gap: 15px 10px;    Updated .grid-container selector\n.grid-container{ display: grid; grid-template-columns: auto auto auto; grid-template-rows: auto auto auto; grid-column-gap: 10px; grid-row-gap: 5px; } Output:\nPositioning Each item in the grid is not confined to just one \u0026ldquo;cell\u0026rdquo;. We can have an item go across multiple rows and/or columns with\n grid-column-start: starts at the column grid line specified grid-column-end: ends at the column grid line specified grid-row-start: starts at the row grid line specified grid-row-end: ends at the row grid line specified  Updating the first grid item in grid_intro.html:\n\u0026lt;!--HTML here--\u0026gt; \u0026lt;div class=\u0026#34;grid-item-1\u0026#34;\u0026gt;1\u0026lt;/div\u0026gt; \u0026lt;!--HTML here--\u0026gt; Adding this selector to the css file:\n.grid-item-1{ background-color: purple; grid-column-start: 1; grid-column-end: 3; } Gives the Output:\nspan The span attribute can give the same exact output.\nColumn Spanning Update\ngrid-column-start: 1; grid-column-end: 3; to\ngrid-column-start: 1; grid-column-end: span 2;  CSS Grid span can only take positive values.\n Row Spanning You can occupy multiple rows in the same fashion with:\n grid-row-start grid-row-end grid-row  span shorthand The span keyword have a shorthand property!\nThe following\ngrid-column-start: 1; grid-column-end: span 2; in a 3x3 grid is equivalent to\n grid-column: 1/ span 2; grid-column: 1/ -2; grid-column: 1/ 3;  grid-column: 1 would start at column grid line 1 and span all the way to the right\nRow and Column Spanning You can use grid-column and grid-row to set position in both vertical and horizontal dimensions.\nGrid Area A shorthand for 2D positioning is grid area.\ngrid area takes four values, equivalent to grid-row-start, grid-column-start, grid-row-end, and grid-column-end.\nThe following starts at row 2, column 1, end at row 4 and column 3\n.grid-item-1{ background-color: purple; grid-area: 2 / 1 / 4 / 3; } Collision In your HTML update the line: \u0026lt;div class=\u0026quot;grid-item\u0026quot;\u0026gt;2\u0026lt;/div\u0026gt; to \u0026lt;div class=\u0026quot;grid-item-2\u0026quot;\u0026gt;2\u0026lt;/div\u0026gt;\nAdd the following CSS selector:\n.grid-item-2{ background-color: orange; grid-area: 2 / 2 / 3 / 4; } Output:\nAh! There are colliding elements!\nAn element can be overlapped with others quite easily because grid elements are automatically placed in order according to the html file, the top most element in the HTML file is the first one defined.\nThe order property allows for overriding the default order. All grid elements have a default order of 0, but this can be set to any positive or negative value.\nThe lowest number is placed first, then the second lowest, so on so forth.\nOrder property used to arrange elements\n.grid-item-1{ background-color: purple; grid-area: 2 / 1 / 4 / 3; order: 2; } .grid-item-2{ background-color: orange; grid-area: 2 / 2 / 3 / 4; order: 1; } Output:\nNow grid-item-2 is placed first, then grid-item-1 is placed second (on top of grid-item-2) without rearranging HTML.\n   Go to the CSS grid labs    "
},
{
	"uri": "/react/pillars/hooks/customhooks/",
	"title": "Custom Hooks",
	"tags": [],
	"description": "",
	"content": "Concepts and Skills  Understand how to write custom hooks that wrap one or more built-in hooks. Write a reusable custom hook.  How To Write Custom Hooks You can write your own custom hooks that are wrappers around one or more of the existing hooks. Custom hooks allow you to reuse logic that may be common to multiple components.\nHere is the Counter component from our earlier discussion refactored to use a custom hook:\nA Counter component using a custom hook\nimport React, { useState } from \u0026#34;react\u0026#34; // This custom hook could be in its own source file for reuse // Note that custom hooks (like built-in hooks) are pure functions const useCounter = (initialCount) =\u0026gt; { const [count, setCount] = useState(initialCount) const increment = () =\u0026gt; setCount(count + 1) const decrement = () =\u0026gt; setCount(count \u0026gt; 1 ? count - 1 : 0) // we can return an array or an object here (it\u0026#39;s up to you).  return { count, increment, decrement } } const Counter = ({initialCount}) =\u0026gt; { const { count, increment, decrement } = useCounter(initialCount) return ( \u0026lt;article\u0026gt; \u0026lt;h2\u0026gt;Counter with Custom Hook\u0026lt;/h2\u0026gt; \u0026lt;div className=\u0026#34;counter\u0026#34;\u0026gt; \u0026lt;button onClick={decrement}\u0026gt;-\u0026lt;/button\u0026gt; \u0026lt;button onClick={increment}\u0026gt;+\u0026lt;/button\u0026gt; \u0026lt;p\u0026gt;The count is {count}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/article\u0026gt; ) } export default Counter  Hooks are like normal functions\nUnlike a React component, a custom Hook doesn\u0026rsquo;t need to have a specific signature. We can decide what it takes as arguments, and what, if anything, it should return. In other words, it\u0026rsquo;s just like a normal function.\n Rules for Custom Hooks  A custom hook is a JavaScript function whose name should start with ”use”. Unlike a React component, a custom Hook doesn\u0026rsquo;t need to have a specific signature. We can decide what arguments it takes and what it returns. In other words, it\u0026rsquo;s just like a normal function. Two components that use the same custom hook do not share state, they are only sharing the logic.  Lab: Write a Custom Hook for the Traffic Light App The instructions for making the Traffic Light App are at Traffic Light Lab.\nInstructions for Refactoring to use a Custom Hook\n Once you have completed the Traffic Light App, refactor it to use a custom hook called useTrafficLight Put the custom hook in a separate source file called use-traffic-light.js Encapsulate the initialState object and the reducer function inside the custom hook Creating multiple traffic lights that share the custom hook. Make each traffic light render differently (different JSX) but behave the same. Confirm that changing the state of one traffic light does not affect the other traffic lights.  Using 3rd Party Hooks Because hooks are so reusable you can find (or even create your own) custom hook libraries to use in your React projects.\nAn interesting hooks library to consider is react-use.\nBrowse some of the react-use hooks\nCheck out the following demos from the react-use website. Take a look at the demo first and then the source code.\n State:  useToggle - a state hook that tracks the value of a boolean useCounter - a state hook that tracks the value of a number   Side Effects:  useLocalStorage - a side-effect hook that manages a single localStorage key useThrottle - a side-effect hook that throttles the update of a value   UI:  useVideo - creates a \u0026lt;video\u0026gt; element, tracks its state and exposes playback controls    Conclusion Custom hooks provide a way to encapsulate and reuse logic across multiple components. The state values are not shared, only the logic is shared. To share state use the Context API or a state management library such as Redux.\n"
},
{
	"uri": "/python/foundation/exceptions/",
	"title": "Exceptions",
	"tags": [],
	"description": "",
	"content": "Error handling and writing exceptions Let\u0026rsquo;s purposefully create a few types of errors so we understand what they look like and how to handle them before we even encounter them in our programs.\nSyntaxError In order to evaluate an error, we\u0026rsquo;ll write a try and except statement. try means we\u0026rsquo;re telling Python to try to evaluate the following line.\nUsing the eval keyword, we\u0026rsquo;ll attempt to evaluate an expression. This will raise a syntax error since Python is expecting eval to take a valid expression. There is no === operator in Python.\nAfter except we\u0026rsquo;ll print out the string \u0026ldquo;You cannot do that\u0026rdquo; to gracefully tell the user that they\u0026rsquo;re doing something that causes Python to error.\ntry: eval(\u0026#39;x === x\u0026#39;) except SyntaxError: print(\u0026#34;You cannot do that\u0026#34;) Output: You cannot do that\nThe output is not descriptive enough. We don\u0026rsquo;t fully understand why we\u0026rsquo;re running into the exception in this instance. It\u0026rsquo;s important to understand what the error is and even what we might need to correct to fix it.\nBeware of using try/catch to evaluate some syntax errors. Python will catch a syntax error before your file is executed. The parser doesn\u0026rsquo;t see that there is an except statement at all and expects you to recognize and fix syntax errors before executing.\nZeroDivisionError print(10 + (1 / 0)) The above evaluation will give us a ZeroDivisionError. Let\u0026rsquo;s handle the ZeroDivisionError exception. Use the most specific wording which semantically fits your issue.\ntry: print(10 + (1 / 0)) except ZeroDivisionError: print(\u0026#34;Oops! We can\u0026#39;t divide by zero, please choose a different number and re-evaluate.\u0026#34;) Output: Oops! We can't divide by zero, please choose a different number and re-evaluate.\nNameError print(4 + spam * 3) A useful way of raising errors is to manually raise the actual error Python gives us, but to put it within a human readable string.\nIf we want to take the above example and raise (or throw) Python\u0026rsquo;s NameError we can use it like so:\ntry: print(4 + spam * 3) except NameError as error: print(\u0026#39;You have encountered a NameError because\u0026#39;, error) By using the variable error Python will know to print out the actual error semantically. You can choose to only print this error out, or concatenated it with a string like the above example.\nTypeError print(\u0026#34;2\u0026#34; + 2) Let\u0026rsquo;s create our own TypeError using the error variable using the previous example as guidance.\nMultiple Exceptions We can write an exception for more than one error at a time. Let\u0026rsquo;s take the two examples above, NameError and TypeError and write one statement that handles both of them:\ntry: print(\u0026#34;2\u0026#34; + spam + 15) except (NameError, TypeError): print(\u0026#34;Very sorry, we are unable to evaluate your request. Please correct errors and re-evaluate.\u0026#34;) Output: Very sorry, we are unable to evaluate your request. Please correct errors and re-evaluate.\nIt is possible to have multiple excepts for one try in case you want to give specific errors for each specific kind of errors.\ntry: print(\u0026#34;2\u0026#34; + spam + 15) except TypeError as e: print(\u0026#34;You gave the wrong type there buddy!\u0026#34;, e) except NameError as e: print(\u0026#34;That variable name does not exist!\u0026#34;, e) Output: That variable name does not exist! name 'spam' is not defined\nRaise We can also use the keyword raise to raise an error in Python.\nIn the following example, raise is put within an if statement which is within a function that will be called within the try and except below. We\u0026rsquo;re raising an error at line 3 which throws the exception we print out on line 6.\nFinally Example using raise\nx = 10 y = 10 try: x / y raise ZeroDivisionError except ZeroDivisionError as e: print(e) finally: print(\u0026#34;Executing finally\u0026#34;) Else Example\nx = 10 y = 10 try: result = x / y except ZeroDivisionError as e: print(e) else: print(\u0026#34;Executing else\u0026#34;, result) Common Errors Exception: Base class for all exceptions\ntry: print(10 / 0) except Exception as e: print(\u0026#34;This exception was raised:\u0026#34;, e) ArithmeticError: Base class for all errors that occur for a numeric calculation\ntry: print(10 / 0) except ArithmeticError as e: print(\u0026#34;This exception was raised:\u0026#34;, e) ZeroDivisionError: Raised when division or modulo by zero takes place for all numeric types\ntry: print(10 / 0) except ZeroDivisionError as e: print(\u0026#34;This exception was raised:\u0026#34;, e) ModuleNotFoundError: Raised when an import statement fails\nimport somestuff try: print(somestuff.amethod()) except ModuleNotFoundError as e: print(e) IndexError: Raised when an index is not found in a sequence\nexample_list = [1, 2, 3, 4] try: print(example_list[4]) except IndexError as e: print(e) KeyError: Raised when the specified key is not found in the dictionary\nexample_dictionary = {\u0026#39;a\u0026#39; : 1, \u0026#39;b\u0026#39;: 2, \u0026#39;d\u0026#39;: 4} try: print(example_dictionary[\u0026#39;c\u0026#39;]) except KeyError as e: print(\u0026#34;You do not have key\u0026#34;, e, \u0026#34;in this dictionary\u0026#34;) SyntaxError: Raised when there is an error in Python syntax\ntry: eval(\u0026#39;x === x\u0026#39;) except SyntaxError as e: print(\u0026#34;This exception was raised:\u0026#34;, e) TypeError: Raised when an operation or function is attempted that is invalid for the specified data type\ntry: print(\u0026#34;2\u0026#34; + 15) except TypeError as e: print(e) Go to Writing Exceptions Exercises\n"
},
{
	"uri": "/software-eng-essentials/fundamentals-of-regex/",
	"title": "Fundamentals of Regex",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  What Regex is Uses of Regex The Power of Regex Basics of Regex  What Regex is Regex is a way to identify a string or strings based on a pattern. This lesson instructs on how to create that pattern. Do you need all strings that start with D and end with S. Do you need all strings that have a digit as their second character and only have 10 characters max? Regex can be written to match these patterns.\nUses of Regex  Data Validation : Checking incoming form data for length and character type. Data Scraping : Web scraping for example. Data Wrangling : Transforming data to a different format. String Parsing : Parsing a Stringified JSON object, getting query params from a URL. String Replacement : Preparing data for SQL statement. Syntax Highlighting : In order to fix syntax issues in your code.  The Power of Regex Sure, many of the above uses of regex can be done via methods in a particular coding language.\nUsually Regex can cover more complex patterns and in less lines of code. Regex can seem daunting at first, but once you\u0026rsquo;ve read through this lesson, you\u0026rsquo;ll find just how simple it can be.\nResources  https://regexr.com/ https://www.regular-expressions.info/  Lessons "
},
{
	"uri": "/software-eng-essentials/git-foundations/intro-to-github/",
	"title": "GitHub Intro",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Showcase GitHub Discuss how to use GitHub effectively Explain the GitHub lingo (fork, clone, pull, etc)  Skills  Integrate GitHub\u0026rsquo;s many helpful features into your projects Understand and navigate GitHub\u0026rsquo;s UI  Collaboration Until now, we have used git locally. Now it\u0026rsquo;s time to talk about collaborating with others to effectively deliver quality software.\nWhat Is GitHub?  It\u0026rsquo;s a very common misconception to think that GitHub is just a part of git. git is a distributed version control system. GitHub is a hosting service for your git repositories. While git provides no sense of ownership or security, GitHub adds these features. The motivation for GitHub is to provide a means to share and collaborate on repositories while remaining secure. In GitHub, a repository can be public, private, or internal. Therefore, you can share a repository with your team, with other teams, or even with the world, and still maintain security around your repository data.   NOTE: The Home Depot\u0026rsquo;s Enterprise GitHub service is configured to only allow for private repositories!\n GitHub is a tool that leverages and extends Git\u0026rsquo;s capabilities.\nGitHub is all about Collaboration  GitHub gives us the ability to store our code on the cloud (a server) and provide access to anyone that needs to be involved, making collaboration on projects much easier. There are several code sharing platforms alternatives to GitHub, the most notable being GitLab. GitHub is the most widely used platform and the tool of choice here at The Home Depot.  How Does GitHub Work?  GitHub hosts our code in a git repository We can grant access to our repo to other users (collaborators) Once code is pushed to GitHub, all collaborators will have immediate access to the changes. Then users are able to pull the updated code down to their local machines.  One Source of Truth GitHub acts as the source of truth for each project and each collaborator\u0026rsquo;s computer acts as a satellite that is linked to the source.\nGit Commands that interact with GitHub Here are command git commands to interact with GitHub:\n git clone - Pull a repo down to your machine for the first time git push - Push new commits to the origin git pull - Pull and merge changes made by others git fetch - Pull without merging changes made by others    Navigating the Interface To access Home Depot\u0026rsquo;s GitHub go to: github.com/enterprises/homedepot/sso and authenticate using your LDAP and password. Once authenticated, you will be in the one-thd Github Enterprise space.\nOnce logged in, you\u0026rsquo;ll land on a dashboard which can be used to operate like a news feed with all activities related to your software projects.\nProfile   Clicking on your avatar will open a menu allowing with several options.\nProfile options include:\n  profile gives you the ability to manage:\n your personal repositories bio stars followers etc    settings allows you to manage:\n notifications organizations access tokens etc.    In addition to managing your info, the profile section also contains a log of your recent contributions, such as:\n Commits Code Review Info Pull Requests New Repos Issues Comments  This can be a helpful way to quickly navigate to the repositories you\u0026rsquo;re actively working on.\n  When on your profile page, you\u0026rsquo;ll probably most often find yourself jumping directly into the repositories (repos for short) section, a page that contains all the repos that you\u0026rsquo;ve created or forked (more on that later).\nYou\u0026rsquo;ll have the option to:\n view all of your repos search for a repo by name sort repos by language sort repos by project type  All of the repos will be displayed in an order reflecting the most recent activity.\nAdding Collaborators GitHub offers several ways to add collaborators to a project.\n Add a collaborator in the repo settings Create a repo within an existing org Fork the repo  We\u0026rsquo;ll look at the last two a little later.\nTo add a collaborator through settings, click on the settings tab and select collaborators from the left nav. Then you can add collaborators by ldap.\nOrgs Often you\u0026rsquo;ll be working with a team on specific projects. GitHub offers organizations for this very purpose.\n NOTE: For security reasons and to better promote collaboration, the THD Enterprise GitHub instance is configured to have a single organization named one-thd.\n The default view includes all of the GitHub repos belonging to your org.\nOrgs offer additional settings options for managing member privileges, repository info, associated applications, webhooks and more.\nIssues GitHub Issues provides a simple way to keep up with different activities in your repository by tracking things like:\n Proposing new features Bug Tracking Keeping up with active development tasks  GitHub Issues offers a simple interface that is tied directly into each repository, giving team members the ability to interact with each other through message-board style comments.\n  Creating a Repository   From your profile page, you can click the New button or click the large + sign on the navbar and select New Repository\nThe new page will ask for info about the repo you want to create. The only required field is Repository Name which Org unique.\nAdditional repo options include:\n a description field a radio button to choose whether your repo will be public or private a check box for adding a readme a select box for adding a pre-built .gitignore file   Often you\u0026rsquo;ll create a repo after your first commit (locally). To avoid issues with your first push, it is recommended to leave the README box un-checked and the .gitignore selection set to none.\n Once the repo is created, you\u0026rsquo;ll be taken to a page with instructions on how to \u0026ldquo;connect\u0026rdquo; a local git repository with a remote repository.\nThe three options are:\n cloning down a repo will create a directory for you and then allow you to start creating files and pushing them to GitHub. create a new local repo by adding a readme as the first commit, and then push the local repo to GitHub. For this step, you would create a repo first, navigate into it and then paste in the commands. use an already existing local repo and point your local repo to GitHub and push your committed code.  Clone   To clone down an existing repo, you can run git clone ORIGIN_URL. (Each repo has a button with the URL.)\nThis pulls down the entire repo and creates a directory. Now you can navigate into the newly created repo and start staging and committing changes.\n After cloning, there is no need to run git init as the repository has already been initialized\n Create a new Local Repo Step 1: To push a local repository to GitHub, you need to have at least one commit.\nGitHub suggests this new file be a README.md. For example:\necho \u0026#34;# My local repo\u0026#34; \u0026gt;\u0026gt; README.md git init git add README.md git commit -m \u0026#34;first commit\u0026#34; Step 2: Once you have at least one commit, you need to make your local repository \u0026ldquo;aware\u0026rdquo; of the remote GitHub repository. This connection is called origin. This syntax looks like:\ngit remote add origin URL An example of this is:\ngit remote add origin https://github.com/\u0026lt;YOUR_THD_GITHUB_USERNAME\u0026gt;/remote-github-repo.git Step 3: Once the connection is made, you need to push the code up to the master branch on the remote repository:\ngit push -u origin master The -u means to set upstream.\nAlready Existing Local Repo To push an already existing local repository to GitHub, you do steps 2 and 3 you did for a new local repo. As a reminder, this syntax looks like:\ngit remote add origin URL Once the connection is made, you need to push the code up to the master branch on the remote repository:\ngit push -u origin master git and GitHub Interactions Once you\u0026rsquo;ve \u0026ldquo;connected\u0026rdquo; a local git repository with a remote repository by setting the upstream (what remote GitHub repository to push to), you can now have interactions between the two.\ngit -\u0026gt; GitHub To push additional changes from your local git repository to your remote repository, do:\ngit push origin NAME_OF_THE_REMOTE_BRANCH Technically you could run git push origin master to send the changes to the remote master branch. However, this is not recommended as you\u0026rsquo;ll often be working off of branches.\n git will not simply allow you to push to the remote master if there are conflicts. The a way around this: git push --force OR git push origin +master\nBe careful with these commands This overwrites the remote master branch to match the rebased local branch from your repository!\n GitHub -\u0026gt; git Anyone with access to a remote repository can get any code updates on their local machines either with a pull or fetch\nfetch will fetch the changes down to your local repository. You can then manually merge them into your branch when appropriate.\ngit fetch BRANCH_NAME pull will fetch changes down to your local repository and attempts to merge them into your current branch.\ngit pull origin BRANCH_NAME Pull Requests Pull Requests (PR) are a feature of GitHub that grants additional interactivity around merging branches.\nMany teams use PR\u0026rsquo;s to conduct code reviews, since PRs can be linked back to GitHub Issues and provide a simple interface to discuss the current code and request changes.\nPull Requests also offer a visible history of what (and why) decisions were made regarding specific commits.\nTo create a pull request, go to your project\u0026rsquo;s repo page and click \u0026ldquo;New pull request\u0026rdquo;\nBy default your branch will attempt to merge with the master branch. It is possible to select another branch to PR against.\n  Lab - GitHub interactions    Go to GitHub Interactions Labs    Fork Forking is a GitHub specific feature that allows you to create a copy of an existing repo.\nHow is that different from cloning? The major difference is that forking happens on GitHub. For example, you may fork a repo from an organization (or other user) to your personal Home Depot GitHub repo. Whereas, with cloning, you are bringing a copy of code from GitHub\u0026rsquo;s servers to your local machine.\nWhen to fork Forking is really only appropriate when you want to work in a codebase that you\u0026rsquo;re not a part of the org, or listed as a contributor.\nTypically, forking is much more common when working on open source software.\nHow to fork To fork a repo, just click on the fork button on the top right of the repo, and select the repo you want to fork (copy) the code into.\nOnce the repo has been forked, you will have your own copy that you can clone to your local machine.\nMaking a PR across forks If you make changes that would be beneficial to the original codebase you can submit a PR across forks with the same Pull Request process you\u0026rsquo;ve been using.\nInstead of setting the base to your version of master, you\u0026rsquo;ll set the base fork option to the original repo.\nThe maintainer of the original repo will then be able to review the changes and determine whether or not the code should be merged.\nReview the Github Guide on Forking Projects\n"
},
{
	"uri": "/java/foundations/inheritance/",
	"title": "Inheritance",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Parent/Child relationships in Objects Using the super keyword Inheritance from the Object class  Skills  Create your own child class Utilize the special access of child to the parent Override Object methods  Inheritance Inheritance is when you are given something, passed down from (usually) a parent or grandparent in your family. The same is true in Java, and here we introduce the idea of parent and child classes, or superclasses and subclasses. A child class will inherit all the fields and methods of the parent class, as well as adding on its own.\nA child class is denoted by the extends \u0026lt;Parent-Classname\u0026gt; syntax. A class can have only one declared parent (all classes are give another parent by default that goes undeclared, but we\u0026rsquo;ll get into that later). In addition to inheriting all fields and classes, a child is also give special access to the parent. Remember our visibility modifiers:\n   Keyword Package Subclass World     public Y Y Y   protected Y Y N   none Y N N   private N N N    The protected modifier allows the field/methods to be hidden from the world, but accessible to child classes so that they can modify/update/utilize features of the parent that other classes cannot.\n The inherited fields can be used directly, just like any other fields. You can declare a field in the subclass with the same name as the one in the superclass, thus hiding it (not recommended). You can declare new fields in the subclass that are not in the superclass. The inherited methods can be used directly as they are. You can write a new instance method in the subclass that has the same signature as the one in the superclass, thus overriding it. You can write a new static method in the subclass that has the same signature as the one in the superclass, thus hiding it. You can declare new methods in the subclass that are not in the superclass.  Parent class:\npublic class Car { private final int MAX_GEAR = 6; protected String color; protected int gear; protected double speed; } child class:\npublic class SportsCar extends Car { private String engine; private boolean turboCharged; public SportsCar(String color, String engine, boolean turboCharged) { this.color = color; this.engine = engine; this.turboCharged = turboCharged; } ... Child Constructors Any object created from the child class needs to create a reference to its parent object. All constructors of a subclass must call the constructor of the superclass.\n QUESTION\nWhy does the above SportsCar constructor work without a call to the Superclass?\n In a scenario where we are not using default (empty) contructors, how would we accomplish this? Remember this? A reference to the object itself that calls a method. super is in a similar vein but, this time, it is a reference to the parent object of the object that calls the method.\nParent class:\npublic class Car { private final int MAX_GEAR = 6; protected String color; protected int gear; protected double speed; public Car(String color) { this.color = color; } ... If we left our SportsCar class as it was before, it would now break. It doesn\u0026rsquo;t know how to construct the parent object anymore, making the child constructor invalid. However, our child can utilize the super keyword to access the constructor of its parent.\nchild class:\npublic class SportsCar extends Car { private String engine; private boolean turboCharged; public SportsCar(String color, String engine, boolean turboCharged) { super(color); this.engine = engine; this.turboCharged = turboCharged; } ... But super isn\u0026rsquo;t just for accessing the constructor. It can be used in the same way you would use this to access the current object.\nObject Superclass Like we discussed before, every object can only declare one parent. This is called single inheritance. However, this term can be misleading because every class also extends the Java base class Object. The difference here is that this inheritance is implicit. So it may be better stated that each object can have single explicit inheritance in addition to the implicit Object inheritance.\nHere are some notable methods that every object inherits from the Object superclass:\npublic boolean equals(Object obj) Returns a boolean depending on whether two object should be considered equal to one another. The equals(Object obj) method in the Object class uses the == operator, can you think of why this would be a problem? This will check if two objects are the exact same object. In other words, if the object you are testing against is pointing to the exact same place in memory as your object, it will return true. This may not, in fact is usually not, the desired functionality between two objects so it is recommended that you override this method with your own implementation. This way, you can decide which fields on an object determine equality (maybe all, maybe a subset of primary fields, similar to a primary key in SQL).\n@Override public boolean equals(Object o) { if (o == null || getClass() != o.getClass()) return false; LoadDTO loadDTO = (LoadDTO) o; if (loadId != loadDTO.loadId) return false; if (fullTruck != loadDTO.fullTruck) return false; if (isRoundedLoad != loadDTO.isRoundedLoad) return false; if (isNewLoad != loadDTO.isNewLoad) return false; if (isHazmat != loadDTO.isHazmat) return false; if (isStraightLoad != loadDTO.isStraightLoad()) return false; if (currentLoadWt != null ? !currentLoadWt.equals(loadDTO.currentLoadWt) : loadDTO.currentLoadWt != null) return false; if (currentLoadVol != null ? !currentLoadVol.equals(loadDTO.currentLoadVol) : loadDTO.currentLoadVol != null) return false; return loadSKUsMap != null ? !loadSKUsMap.equals(loadDTO.loadSKUsMap) : false; } public int hashCode() Every object has a HashCode, a unique integer generated based on the makeup of the object. There is a code or relationship set up between the hashcode and equals method that states if two objects are considered equal they must have the same hashcode. The inverse is true as well, if they are not equal they must have different hashcodes.\n QUESTION\nGiven Object\u0026rsquo;s default equals method, what would its hashCode method return?\n Given the relationship between the two, if you override the equals method, you must also override the hashCode method. The formula for this is simple, whatever fields you consider for your equals methods, use those fields to generate a hashcode integer.\n@Override public int hashCode() { int result = objectId; result = 31 * result + plndLoadGrpId; result = 31 * result + loadId; result = 31 * result + (fullTruck ? 1 : 0); result = 31 * result + (isRoundedLoad ? 1 : 0); result = 31 * result + (isNewLoad ? 1 : 0); result = 31 * result + (isHazmat ? 1 : 0); result = 31 * result + (isStraightLoad ? 1 : 0); result = 31 * result + (currentLoadWt != null ? currentLoadWt.hashCode() : 0); result = 31 * result + (currentLoadVol != null ? currentLoadVol.hashCode() : 0); result = 31 * result + (loadSKUsMap != null ? loadSKUsMap.hashCode() : 0); return result; } public String toString() Returns a String representation of your object. By default, this string will be \u0026lsquo;Classname@hashCode\u0026rsquo;, which is not generally all that informative so it is recommended you override this method. This can be whatever will be most useful for debugging. So ask yourself, \u0026ldquo;What is the easiest way to identify an object?\u0026rdquo; It is likely that you\u0026rsquo;ll want to include at least the fields that are used for the equals evaluation, though you don\u0026rsquo;t necessarily have to.\n@Override public String toString() { return \u0026#34;LoadDTO{\u0026#34; + \u0026#34;, plndLoadGrpId=\u0026#34; + plndLoadGrpId + \u0026#34;, loadId=\u0026#34; + loadId + \u0026#34;, fullTruck=\u0026#34; + fullTruck + \u0026#34;, tenderEligibleLoad=\u0026#34; + tenderEligibleLoad + \u0026#34;, isRoundedLoad=\u0026#34; + isRoundedLoad + \u0026#34;, isNewLoad=\u0026#34; + isNewLoad + \u0026#34;, isHazmat=\u0026#34; + isHazmat + \u0026#34;, isStraightLoad=\u0026#34; + isStraightLoad + \u0026#34;, volUOMCd=\u0026#34; + volUOMCd + \u0026#34;, wtUOMCd=\u0026#34; + wtUOMCd + \u0026#34;, currentLoadWt=\u0026#34; + currentLoadWt + \u0026#34;, currentLoadVol=\u0026#34; + currentLoadVol + \u0026#34;, adjLoadWt=\u0026#34; + adjLoadWt + \u0026#34;, adjLoadVol=\u0026#34; + adjLoadVol + \u0026#34;, loadPercent=\u0026#34; + loadPercent + \u0026#34;, adjLoadPercent=\u0026#34; + adjLoadPercent + \u0026#34;, loadReasonCd=\u0026#34; + loadReasonCd + \u0026#34;, externalDemandLocMap=\u0026#34; + externalDemandLocMap + \u0026#34;, loadSKUsMap=\u0026#34; + loadSKUsMap + \u0026#34;, pallets=\u0026#34; + pallets + \u0026#34;, stopDims=\u0026#34; + stopDims + \u0026#34;, adjVolUOMCd=\u0026#34; + adjVolUOMCd + \u0026#34;, adjWtUOMCd=\u0026#34; + adjWtUOMCd + \u0026#34;, createUserId=\u0026#39;\u0026#34; + createUserId + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, lastUpdatedUserId=\u0026#39;\u0026#34; + lastUpdatedUserId + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } protected Object clone() Used to create a copy from an existing object. Usually used in conjunction with the Cloneable interface.\npublic final Class getClass() Returns a Class object, which has methods you can use to get information about the class, such as its name (getSimpleName()), its superclass (getSuperclass()), and the interfaces it implements (getInterfaces()).\nYou cannot override this method.\nSummary The idea of inheritance is simple but powerful: When you want to create a new class and there is already a class that includes some of the code that you want, you can derive your new class from the existing class. In doing this, you can reuse the fields and methods of the existing class without having to write (and debug!) them yourself.\nEvery class you create will utilize inheritance, they all descend and inherit from the Object class in addition to whatever explicit inheritance you may define.\n"
},
{
	"uri": "/javascript/foundations/labs/modern-array-methods-lab/",
	"title": "Modern Array Methods Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch modern-array-methods.js Add the following code to modern-array-methods.js:\n// numbers const numbers = [1, 12, 4, 18, 9, 7, 11, 3, 101, 5, 6]; let evenNumbers; // TODO: assign to an array containing only the even numbers let oddNumber; // TODO: assign to the first odd number let largestNumber; // TODO: assign to the largest number console.log(\u0026#39;evenNumbers:\u0026#39;, evenNumbers); console.log(\u0026#39;oddNumber:\u0026#39;, oddNumber); console.log(\u0026#39;largestNumber:\u0026#39;, largestNumber); // strings const strings = [\u0026#34;this\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;collection\u0026#34;, \u0026#34;of\u0026#34;, \u0026#34;words\u0026#34;]; let onlyIs; // TODO: assign to an array with only the string containing the substring `is` let longestWord; // TODO: assign to the longest word in strings console.log(\u0026#39;onlyIs:\u0026#39;, onlyIs); console.log(\u0026#39;longestWord:\u0026#39;, longestWord); // objects const orders = [ { price: 45.0, status: \u0026#34;processed\u0026#34; }, { price: 20.0, status: \u0026#34;pending\u0026#34; }, { price: 60.0, status: \u0026#34;pending\u0026#34; }, { price: 15.0, status: \u0026#34;processed\u0026#34; } ]; let allPrices; // TODO: an array with only the price values from all of the orders let pendingOrders; // TODO: an array containing only the orders that are pending let total; // TODO: the total sum of all the prices console.log(\u0026#39;allPrices:\u0026#39;, allPrices); console.log(\u0026#39;pendingOrders:\u0026#39;, pendingOrders); console.log(\u0026#39;total:\u0026#39;, total); Step 2: Complete the code and test Use the appropriate Array methods to complete the TODOs in the above code.\nTest your solution with:\nnode modern-array-methods.js The expected output is:\nevenNumbers: [ 12, 4, 18, 6 ] oddNumber: 1 largestNumber: 101 onlyIs: [ \u0026#39;this\u0026#39;, \u0026#39;is\u0026#39; ] longestWord: collection allPrices: [ 45, 20, 60, 15 ] pendingOrders: [ { price: 20, status: \u0026#39;pending\u0026#39; }, { price: 60, status: \u0026#39;pending\u0026#39; } ] total: 140 "
},
{
	"uri": "/react/pillars/advanced-react/",
	"title": "More Advanced React",
	"tags": [],
	"description": "",
	"content": "Welcome to Even More Advanced React! NOTE: this material will soon be moved into the correct pillars.\n"
},
{
	"uri": "/javascript/foundations/objects-and-json/",
	"title": "Objects and JSON",
	"tags": [],
	"description": "",
	"content": "An introduction to JavaScript objects and JSON.\nLearning Objectives  Explain how to work with objects in JavaScript Introduce JSON Discuss the difference between primitive and reference types Build complex objects List, update, mutate properties of objects  Objects An object is a set of properties (keys) and values.\nconst course = { name: \u0026#34;Orange Academy\u0026#34;, awesome: true }; Values can be primitives, arrays, or other objects.\nconst course = { courseName: \u0026#34;Orange Academy Full-Stack JS\u0026#34;, awesome: true, students: [\u0026#34;Dawn\u0026#34;, \u0026#34;Duane\u0026#34;], // an array inside an object  instructor: { // an object inside an object  name: \u0026#34;Shane\u0026#34;, title: \u0026#34;Staff Training Software Engineer\u0026#34; } }; Accessing Properties of an Object Object properties can be accessed in two ways. The more common dot notation, as well as bracket notation, which is useful if you have a property name saved in a string.\nconsole.log(course.courseName); // \u0026#34;Orange Academy Full-Stack JS\u0026#34;  const propName = \u0026#34;courseName\u0026#34;; // store the property name in a variable console.log(course[propName]); // \u0026#34;Orange Academy Full-Stack JS\u0026#34; You can combine dot and bracket notation to address infinitely deeply nested values inside objects.\nconst course = { courseName: \u0026#34;Orange Academy Full-Stack JS\u0026#34;, awesome: true, teachers: [\u0026#34;Heather\u0026#34;, \u0026#34;Kyle\u0026#34;, \u0026#34;Elizabeth\u0026#34;] }; console.log(course.teachers[0]); // Heather A more complex example:\nconst course = { name: \u0026#34;Orange Academy Full-Stack JS\u0026#34;, awesome: true, teachers: [\u0026#34;Heather\u0026#34;, \u0026#34;Kyle\u0026#34;, \u0026#34;Elizabeth\u0026#34;] students: [ { name: \u0026#34;Cliff\u0026#34;, computer: { OS: \u0026#34;macOS\u0026#34;, type: \u0026#34;iMac\u0026#34; } } ] }; console.log(course.students[0].computer.OS); Update an Object Properties of objects can be updated after an object is created.\ncourse.name = \u0026#34;Advanced JavaScript\u0026#34;; Mutate an Object You can also assign new keys and delete existing ones.\ncourse.fun = true; // add a property delete course.name; // remove one Lab See instructions here.\nObject Destructuring Object destructuring makes it easy to extract specific property values from an object and assign them to distinct variables.\nExample\nconst instructor = { name: \u0026#34;Shane\u0026#34;, email: \u0026#34;shane_barringer@homedepot.com\u0026#34; }; // Old Way: // const name = instructor.name // const email = instructor.email  // New Way with destructuring: const { name: name, email: email } = instructor; console.log(name); // \u0026#34;Shane\u0026#34; You can also destructure using a short-hand notation when the property name and the variable name are spelled the same (as in the above example). Thus we can write:\nconst { name, email } = instructor; // shorter than { name: name, email: email } JSON Why is JSON important?  JSON is used to store data and exchange that data between applications. JSON works with multiple languages and makes the exchange of data very simple and straightforward. Working with (or building) API\u0026rsquo;s often requires working with JSON extensively.  What is JSON?  JSON is a text-based data format based on JavaScript object syntax. JSON is an acronym that stands for JavaScript Object Notation.  Proper JSON\n{ \u0026#34;name\u0026#34;: \u0026#34;Orange Academy Full-Stack JS\u0026#34;, \u0026#34;awesome\u0026#34;: true } NOTE: An important difference between JavaScript objects and JSON is that JSON requires double quotes around the property names. This is also valid in JavaScript, but not required.\nPrimitive vs Reference types (Revisited)  The primitive types are Number, String, and Boolean The Reference types are Array and Object Primitive types are assigned by value Reference types are assigned by reference  Why is this important?\nA value variable holds its value like you might expect. A reference variable points to an object in memory.\n Re-assigning a value type actually changes it\u0026rsquo;s value. Re-assigning a reference type makes it point to a different memory location. Comparison of reference types compares the memory location, not the value.  Before proceeding, take a moment to read this excellent StackOverflow post regarding primitive and reference values.\nHere are a few of examples to further illustrate:\nValue types\nlet x = 1; let y = 1; x === y; // true  let y = x; // x == 1, y == 1 x === y; // true  x = 2; // x == 2, y == 1 x === y; // false Reference types\nconst x = { value: 1 }; const y = { value: 1 }; x === y; // false  const z = x; // x and z are { value: 1 } x === z; // true  x.value = 2; z.value; // 2 since x and z refer to the same memory location Summary  Objects are simply key/value pairs Object properties are accessed in a similar manner to array values, i.e. myObj.someKey An object\u0026rsquo;s properties can be  created (after instantiation) mutated deleted   JSON looks similar to a JavaScript Object  JSON properties must be double-quoted strings JSON is understood by multiple languages   Objects are reference types  Additional Resources  ES6 Destructuring - Pony Foo Object Destructuring - Mozilla  "
},
{
	"uri": "/golang/foundations/pointers/",
	"title": "Pointers",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Pointers Creating \u0026amp; Using Structs Creating and Using Methods and an Instance of a Struct  Pointers  Allow you to pass variables by reference Can be edited in multiple locations  Pass by Value Refresher  By default data is passed by value ( a copy is made ) For example, when a string is passed as an argument to a function, the value of the string is passed along as a copy.  For example, take the following code snippet\nfunc incrementer(i int) { // 1 \ti++\t// 2 \tfmt.Println(\u0026#34;i is now: \u0026#34;, i) // 3 } func main() { i := 0 incrementer(i) fmt.Println(i) incrementer(i) fmt.Println(i) }  Pass in an int as an argument Increment the value Print out the new value  Running this code will result in the following output\ni is now: 1 0 i is now: 1 0  I was passed by value to increment The value of i was modified in the function The main function still only has access to the original \u0026ldquo;copy\u0026rdquo; of the value  The \u0026amp; and * Operators and the new function.  \u0026amp; - Finds the memory address of a variable and returns pointer to the value. You might say that \u0026amp; creates a pointer to the value. * - Gives us access to the value at the memory address the pointer was created for.  func main(){ x := 10 // 1  y := \u0026amp;x // 2  fmt.Println(y,*y) // 3 } Try Me\n Normal declaration of a int type set to the value of 10 Create a pointer using \u0026amp;. which assigns x's memory location as the value to y Print out y with no * it will not print out the value x was set to. On the other hand when we use * with y, it prints out the value held in memory.  The new Function  The new() built-in function is the equivalent of using \u0026amp;. You may see it, but not often. Just know that it returns a pointer to the values memory address just as \u0026amp; will. It does not create a \u0026ldquo;new\u0026rdquo; instance of a thing  Modifying Values Through Pointers func main() { x := 111 y := \u0026amp;x // 1  *y++ // 2  *y = *y + 1 // 3  z := *y // 4  z = z * 10 // 5  fmt.Println(x, y, *y, z) } Try Me\n Create the pointer to x Increment x through y Equivalent of *x++ Make a copy of the value of x through *y Given this is a copy, what, if anything, will this do to x?  Passing pointers to and returning Pointers from functions Advertising that a function or field takes or returns a pointer is done by prefixing the * to the type in the normal variable declaration.\nExample\nfunc PointerExample(i *int) *int { r := *i *i++ r = r * 10 return \u0026amp;r } func main() { input := 5 output := PointerExample(\u0026amp;input) fmt.Println(input, *output) } Try Me\nThe Classic swap Function Try coding a swap function that takes 2 integers and swaps their values so that the calling function can see that the values were swapped.\nFor example:\n// This DOES NOT WORK because x and y are passed by value 😢 func swap(x, y int) { temp := x x = y y = temp } func main() { a := 3 b := 5 swap(a, b) fmt.Println(a, b) // prints out \u0026#34;3 5\u0026#34; (nothing was swapped) } See if you can modify the code to use pointers and successfully swap the values.\nClick here to try it!\n Solution Click here to see the solution!\n Additional Resources We only touched enough to get you going with pointers, and familiarize yourself with looking at them. Here are several resources that may help provide additional information and understanding:\n Understand Go pointers in less than 800 words or your money back Go101 Pointers The Go Book: Pointers  Lab: Pointers Using the starting code herecomplete the step instructions in the goplay.space.\nReview of Map, Arrays, and Slices with pointers. We will be discussing line by line the code found here and how pointers play a part.\n"
},
{
	"uri": "/react/pillars/perf-opt-strategies/quiz/",
	"title": "Quiz",
	"tags": [],
	"description": "",
	"content": "Quiz (for discussion)  What kinds of performance problems might we see in a React application? What are the rules for when React re-renders a component? Which of the following techniques would you use to prevent an operation from executing too frequently?  React.memo React.useMemo debouncing windowing   True or False: A Web Worker is a script that runs in a separate JavaScript thread  True False - JavaScript is a single-threaded language    "
},
{
	"uri": "/cyber-security/static-dynamic-analysis/",
	"title": "Static &amp; Dynamic Analysis",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Cybersecurity offerings! "
},
{
	"uri": "/react/pillars/perf-opt-strategies/summary/",
	"title": "Summary",
	"tags": [],
	"description": "",
	"content": "Other Performance Considerations Mapping Over an Array in JSX When mapping over an array to create a JSX array, always use the key prop.\n React uses the key value to diff each element to see if it has been added, removed, or updated. Without a key, React diffs in sequential order. Don\u0026rsquo;t use the array index as the key.  For more information, see: Index as a key is an anti-pattern.\nProfiler API React has a performance profiler API that can be used to programmatically collect and report performance data.\nSee Profiler API | React Docs.\nReact\u0026rsquo;s Concurrent Mode (Experimental) There is a new set of features coming to React (version 18?) called Concurrent Mode.\n Concurrent Mode is a set of new features that help React apps stay responsive and gracefully adjust to the user’s device capabilities and network speed. In Concurrent Mode, rendering is not blocking. It is interruptible. This improves the user experience. These features are still experimental and are subject to change. They are not yet a part of a stable React release, but you can try them in an experimental build. - React Docs\n  Suspense - renders a \u0026ldquo;fallback\u0026rdquo; while waiting on a component to be ready (such as when waiting on data loading from the server).  The current implementation uses a funky throw mechanism - the component render throws an error until it is ready to be rendered. For a demo, see: Suspense demo.   Transitions - workflow for managing what the user sees while a component renders.  Demos:\n Concurrent React Example 1 | The Beatles Concurrent React Example 2 | Posts and Comments  Summary  React is in most cases very fast. There are specific rules that React follows when deciding whether to re-render a component. You can use React Dev Tools to inspect the performance of your application and investigate why a component is re-rendering. Don\u0026rsquo;t over-optimize. Measure first and then make informed decisions about when to optimize.  Tips  Be familiar with the React Dev Tools Profiler features. Use React\u0026rsquo;s memoization features when needed to improve performance:  React.memo - to memoize a component React.useMemo - to memoize a value React.useCallback - to memoize a function   Use Web Workers to offload long computations. Use Pagination and/or Windowing to render subsets of a large data set. Use debouncing to prevent executing an operation too frequently. Don\u0026rsquo;t render a Context.Provider in a component that does unrelated state changes. Consider splitting a Context.Provider into multiple providers when it is managing state values that change independently.   Answers to Quiz Question 1 - What kinds of performance problems might we see in a React application?  Unnecessary re-renders Slow rendering of a component due to  a long computation a lot of children that render unnecessarily   UI is unresponsive during a long rendering or computation Slow components block other components from rendering  Question 2 - What are the rules for when React re-renders a component?  props change  passing a callback function that is recreated with each render of the parent   hooks change  State: useState, useReducer Dependencies: useEffects, useMemo, useCallback useRef, useContext   a Context Provider changes value Parent re-renders and child is not memoized (or is not a PureComponent)  Question 3 - Which of the following techniques would you use to prevent an operation from executing too frequently?  React.memo React.useMemo debouncing windowing  The correct answer is 3. debouncing.\nQuestion 4 - True or False: A Web Worker is a script that runs in a separate JavaScript thread  True False - JavaScript is a single-threaded language  The correct answer is 1. True.\nAdditional Resources  Optimizing Performance | React Docs React Performance Tools React Dev Tools for Chrome CRA - Measuring Performance - discusses the use of reportWebVitals React Component Rendering Performance Introducing the React Profiler Managing Long-Running Tasks In A React App With Web Workers  Flame Graphs:\n Profiling Performance with React Dev Tools | Pluralsight Guide Flame Graphs Miha Rekar - What Are Flame Graphs and How to Read Them, RubyConfBY 2017 | Youtube   Great analogy to work day Quiz Time    "
},
{
	"uri": "/python/web-framework/thd_api_and_ux/thd_style_guide/",
	"title": "THD Style Guide",
	"tags": [],
	"description": "",
	"content": "THD Style Guide Set Up You can find Home Depot\u0026rsquo;s style guide for HTML, CSS and JavaScript here..\nScroll down to the UX-Styleguide CDN section on the above page and copy all of the HTML there. It should look similar to the following:\n\u0026lt;!-- Latest compiled and minified CSS --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://pages.github.homedepot.com/ux/ux-styleguide/dist/ux-styleguide.min.css\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;!-- Specified version --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://pages.github.homedepot.com/ux/ux-styleguide/dist/2.0.1/ux-styleguide.min.css\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;!-- Latest compiled and minified JavaScript --\u0026gt; \u0026lt;script src=\u0026#34;https://pages.github.homedepot.com/ux/ux-styleguide/dist/ux-styleguide.min.js\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Specified version --\u0026gt; \u0026lt;script src=\u0026#34;https://pages.github.homedepot.com/ux/ux-styleguide/dist/2.0.1/ux-styleguide.min.js\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Paste it in the \u0026lt;head\u0026gt; tag of locations/templates/locations/index.html and locations/templates/locations/stores.html pages.\nNow you can use the majority of the tools in the style guide!\nCards To add cards to a page you can refer to this page.\nIn your locations/templates/locations/index.html page, find the line that has {% for market in market_list %}. This is where you are going to place the HTML code found from the style guide.\nYour ending result of the \u0026lt;body\u0026gt; should look something like (you might need to update the url location depending on your naming):\n\u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;THD Markets\u0026lt;/h1\u0026gt; {% if market_list %} \u0026lt;ul\u0026gt; {% for market in market_list %} \u0026lt;div class=\u0026#34;card\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;card-toolbar\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;card-title\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;{{ market.number }}\u0026lt;/h2\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;card-content\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;{{market.name}}\u0026lt;/h1\u0026gt; Stores: {{market.num_stores}} \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;card-actions right\u0026#34;\u0026gt; \u0026lt;a class=\u0026#34;button\u0026#34; href=\u0026#34;{% url \u0026#39;locations:market\u0026#39; market.number %}\u0026#34;\u0026gt;Go to Stores\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; {% else %} \u0026lt;p\u0026gt;No markets are available.\u0026lt;/p\u0026gt; {% endif %} \u0026lt;/body\u0026gt; Exercise: Style Store View Update the store view to have cards as well.\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/additional/cssgrid_container_properties/",
	"title": "CSS Grid Expanded",
	"tags": [],
	"description": "",
	"content": "CSS Grid Layout CSS Grid Layout (aka Grid), is a two-dimensional grid-based layout system that aims to do nothing less than completely change the way we design grid-based user interfaces. Grid is the very first CSS module created specifically to solve the layout problems we’ve all been hacking our way around for as long as we’ve been making websites.\nCSS has always been used to lay out our web pages, but it’s never done a very good job of it. First, we used tables, then floats, positioning and inline-block, but all of these methods were essentially hacks and left out a lot of important functionality (vertical centering, for instance). Flexbox helped out, but it’s intended for simpler one-dimensional layouts, not complex two-dimensional ones (Flexbox and Grid actually work very well together).\nGrid is the very first CSS module created specifically to solve the layout problems we’ve all been hacking our way around for as long as we’ve been making websites.\nGetting Started To get started you have to define a container element as a grid with display: grid, set the column and row sizes with grid-template-columns and grid-template-rows, and then place its child elements into the grid with grid-column and grid-row. Similarly to flexbox, the source order of the grid items doesn’t matter. Your CSS can place them in any order, which makes it super easy to rearrange your grid with media queries. Imagine defining the layout of your entire page, and then completely rearranging it to accommodate a different screen width all with only a couple lines of CSS. Grid is one of the most powerful CSS modules ever introduced.\nImportant Terminology Before diving into the concepts of Grid it’s important to understand the terminology. Since the terms involved here are all kinda conceptually similar, it’s easy to confuse them with one another if you don’t first memorize their meanings defined by the Grid specification. But don’t worry, there aren’t many of them.\nGrid Container The element on which display: grid is applied. It’s the direct parent of all the grid items. In this example container is the grid container.\n\u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;item item-1\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;item item-2\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;item item-3\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Grid Item The children (i.e. direct descendants) of the grid container. Here the item elements are grid items, but sub-item isn’t.\n\u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;item\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;item\u0026#34;\u0026gt; \u0026lt;p class=\u0026#34;sub-item\u0026#34;\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;item\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Grid Line The dividing lines that make up the structure of the grid. They can be either vertical (column grid lines'') or horizontal (row grid lines\u0026rsquo;') and reside on either side of a row or column. Here the yellow line is an example of a column grid line.\n!(https://css-tricks.com/wp-content/uploads/2018/11/terms-grid-line.svg)\nGrid Track The space between two adjacent grid lines. You can think of them like the columns or rows of the grid. Here’s the grid track between the second and third row grid lines.\n!(https://css-tricks.com/wp-content/uploads/2018/11/terms-grid-track.svg)\nGrid Cell The space between two adjacent row and two adjacent column grid lines. It’s a single ``unit\u0026rsquo;\u0026rsquo; of the grid. Here’s the grid cell between row grid lines 1 and 2, and column grid lines 2 and 3.\nGrid Area The total space surrounded by four grid lines. A grid area may be comprised of any number of grid cells. Here’s the grid area between row grid lines 1 and 3, and column grid lines 1 and 3.\ndisplay: grid Defines the element as a grid container and establishes a new grid formatting context for its contents.\nValues: - grid - generates a block-level grid - inline-grid - generates an inline-level grid\n.container { display: grid | inline-grid; } grid-template-columns \u0026amp; grid-template-rows Defines the columns and rows of the grid with a space-separated list of values. The values represent the track size, and the space between them represents the grid line.\nValues: - \u0026lt;track-size\u0026gt; - can be a length, a percentage, or a fraction of the free space in the grid (using the fr unit) - \u0026lt;line-name\u0026gt; - an arbitrary name of your choosing\n.container { grid-template-columns: \u0026lt;track-size\u0026gt; ... [line-name] \u0026lt;track-size\u0026gt; ...; grid-template-rows: \u0026lt;track-size\u0026gt; ... [line-name] \u0026lt;track-size\u0026gt; ...; } Examples When you leave an empty space between the track values, the grid lines are automatically assigned positive and negative numbers:\n.container { grid-template-columns: 40px 50px auto 50px 40px; grid-template-rows: 25% 100px auto; } But you can choose to explicitly name the lines. Note the bracket syntax for the line names:\n.container { grid-template-columns: [first] 40px [line2] 50px [line3] auto [col4-start] 50px [five] 40px [end]; grid-template-rows: [row1-start] 25% [row1-end] 100px [third-line] auto [last-line]; } Note that a line can have more than one name. For example, here the second line will have two names: row1-end and row2-start:\n.container { grid-template-rows: [row1-start] 25% [row1-end row2-start] 25% [row2-end]; } If your definition contains repeating parts, you can use the repeat() notation to streamline things:\n.container { grid-template-columns: repeat(3, 20px [col-start]); } Which is equivalent to this:\n.container { grid-template-columns: 20px [col-start] 20px [col-start] 20px [col-start]; } If multiple lines share the same name, they can be referenced by their line name and count.\n.item { grid-column-start: col-start 2; } grid-template-areas Defines a grid template by referencing the names of the grid areas which are specified with the grid-area property. Repeating the name of a grid area causes the content to span those cells. A period signifies an empty cell. The syntax itself provides a visualization of the structure of the grid.\nValues:\n \u0026lt;grid-area-name\u0026gt; - the name of a grid area specified with grid-area .: a period signifies an empty grid cell none: no grid areas are defined  .container { grid-template-areas: \u0026#34;\u0026lt;grid-area-name\u0026gt; | . | none | ...\u0026#34; \u0026#34;...\u0026#34;; } Example:\n.item-a { grid-area: header; } .item-b { grid-area: main; } .item-c { grid-area: sidebar; } .item-d { grid-area: footer; } .container { grid-template-columns: 50px 50px 50px 50px; grid-template-rows: auto; grid-template-areas: \u0026#34;header header header header\u0026#34; \u0026#34;main main . sidebar\u0026#34; \u0026#34;footer footer footer footer\u0026#34;; } That’ll create a grid that’s four columns wide by three rows tall. The entire top row will be comprised of the header area. The middle row will be comprised of two main areas, one empty cell, and one sidebar area. The last row is all footer.\ngrid-column-gap \u0026amp; grid-row-gap Specifies the size of the grid lines. You can think of it like setting the width of the gutters between the columns/rows.\nValues:\n \u0026lt;line-size\u0026gt;: a length value  .container { grid-column-gap: \u0026lt;line-size\u0026gt;; grid-row-gap: \u0026lt;line-size\u0026gt;; } Example:\n.container { grid-template-columns: 100px 50px 100px; grid-template-rows: 80px auto 80px; grid-column-gap: 10px; grid-row-gap: 15px; }  The gutters are only created between the columns/rows, not on the outer edges.\n grid-gap A shorthand for grid-row-gap and grid-column-gap\nValues:\n \u0026lt;grid-row-gap\u0026gt; / \u0026lt;grid-column-gap\u0026gt;: length values  .container { grid-gap: \u0026lt;grid-row-gap\u0026gt; \u0026lt;grid-column-gap\u0026gt;; } Example:\n.container { grid-template-columns: 100px 50px 100px; grid-template-rows: 80px auto 80px; grid-gap: 15px 10px; } If no grid-row-gap is specified, it’s set to the same value as grid-column-gap\njustify-items Aligns grid items along the inline (row) axis (as opposed to align-items which aligns along the block (column) axis). This value applies to all grid items inside the container.\nValues:\n start: aligns items to be flush with the start edge of their cell end: aligns items to be flush with the end edge of their cell center: aligns items in the center of their cell stretch: fills the whole width of the cell (this is the default)  .container { justify-items: start | end | center | stretch; } This behavior can also be set on individual grid items via the justify-self property.\nalign-items Aligns grid items along the block (column) axis (as opposed to justify-items which aligns along the inline (row) axis). This value applies to all grid items inside the container.\nValues:\n start - aligns items to be flush with the start edge of their cell end - aligns items to be flush with the end edge of their cell center - aligns items in the center of their cell stretch - fills the whole height of the cell (this is the default)  .container { align-items: start | end | center | stretch; } place-items place-items sets both the align-items and justify-items properties in a single declaration.\nValues: \u0026lt;align-items\u0026gt; / \u0026lt;justify-items\u0026gt; - The first value sets align-items, the second value justify-items. If the second value is omitted, the first value is assigned to both properties. \u0026gt;All major browsers except Edge support the place-items shorthand property.\njustify-content Sometimes the total size of your grid might be less than the size of its grid container. This could happen if all of your grid items are sized with non-flexible units like px. In this case you can set the alignment of the grid within the grid container. This property aligns the grid along the inline (row) axis (as opposed to align-content which aligns the grid along the block (column) axis).\nValues:\n start: aligns the grid to be flush with the start edge of the grid container end: aligns the grid to be flush with the end edge of the grid container center: aligns the grid in the center of the grid container stretch: resizes the grid items to allow the grid to fill the full width of the grid container space-aroun: places an even amount of space between each grid item, with half-sized spaces on the far ends space-between: places an even amount of space between each grid item, with no space at the far ends space-evenly:places an even amount of space between each grid item, including the far ends  .container { justify-content: start | end | center | stretch | space-around | space-between | space-evenly; } align-content Sometimes the total size of your grid might be less than the size of its grid container. This could happen if all of your grid items are sized with non-flexible units like px. In this case you can set the alignment of the grid within the grid container. This property aligns the grid along the block (column) axis (as opposed to justify-content which aligns the grid along the inline (row) axis).\nValues:\n start: aligns the grid to be flush with the start edge of the grid container end: aligns the grid to be flush with the end edge of the grid container center: aligns the grid in the center of the grid container stretch: resizes the grid items to allow the grid to fill the full height of the grid container space-around: places an even amount of space between each grid item, with half-sized spaces on the far ends space-between: places an even amount of space between each grid item, with no space at the far ends space-evenly: places an even amount of space between each grid item, including the far ends  .container { align-content: start | end | center | stretch | space-around | space-between | space-evenly; } place-content place-content sets both the align-content and justify-content properties in a single declaration.\nValues:\n \u0026lt;align-content\u0026gt; / \u0026lt;justify-content\u0026gt;: The first value sets align-content, the second value justify-content. If the second value is omitted, the first value is assigned to both properties.  All major browsers except Edge support the place-content shorthand property.\ngrid-auto-flow Aligns grid items along the block (column) axis (as opposed to justify-items which aligns along the inline (row) axis). This value applies to all grid items inside the container.\nValues:\n start: aligns items to be flush with the start edge of their cell end: aligns items to be flush with the end edge of their cell center: aligns items in the center of their cell stretch: fills the whole height of the cell (this is the default)  .container { align-items: start | end | center | stretch; } Note that dense only changes the visual order of your items and might cause them to appear out of order, which is bad for accessibility.\ngrid A shorthand for setting all of the following properties in a single declaration: grid-template-rows, grid-template-columns, grid-template-areas, grid-auto-rows, grid-auto-columns, and grid-auto-flow (\u0026gt; You can only specify the explicit or the implicit grid properties in a single grid declaration).\nValues:\n none: sets all sub-properties to their initial values. \u0026lt;grid-template\u0026gt;: works the same as the grid-template shorthand. \u0026lt;grid-template-rows\u0026gt; / [ auto-flow \u0026amp;\u0026amp; dense? ] \u0026lt;grid-auto-columns\u0026gt;?: sets grid-template-rows to the specified value. If the auto-flow keyword is to the right of the slash, it sets grid-auto-flow to column. If the dense keyword is specified additionally, the auto-placement algorithm uses a dense packing algorithm. If grid-auto-columns is omitted, it is set to auto. [ auto-flow \u0026amp;\u0026amp; dense? ] \u0026lt;grid-auto-rows\u0026gt;? / \u0026lt;grid-template-columns\u0026gt;: sets grid-template-columns to the specified value. If the auto-flow keyword is to the left of the slash, it sets grid-auto-flow to row. If the dense keyword is specified additionally, the auto-placement algorithm uses a dense packing algorithm. If grid-auto-rows is omitted, it is set to auto.  Examples:\nThe following two code blocks are equivalent:\n.container { grid: 100px 300px / 3fr 1fr; } .container { grid-template-rows: 100px 300px; grid-template-columns: 3fr 1fr; } The following two code blocks are equivalent:\n.container { grid: auto-flow / 200px 1fr; } .container { grid-auto-flow: row; grid-template-columns: 200px 1fr; } It also accepts a more complex but quite handy syntax for setting everything at once. You specify grid-template-areas, grid-template-rows and grid-template-columns, and all the other sub-properties are set to their initial values. What you’re doing is specifying the line names and track sizes inline with their respective grid areas. This is easiest to describe with an example:\n.container { grid: [row1-start] \u0026#34;header header header\u0026#34; 1fr [row1-end] [row2-start] \u0026#34;footer footer footer\u0026#34; 25px [row2-end] / auto 50px auto; } That’s equivalent to this:\n.container { grid-template-areas: \u0026#34;header header header\u0026#34; \u0026#34;footer footer footer\u0026#34;; grid-template-rows: [row1-start] 1fr [row1-end row2-start] 25px [row2-end]; grid-template-columns: auto 50px auto; } All information used to create this lesson is from: CSS-Tricks.com\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/grid-labs/",
	"title": "CSS Grid Labs",
	"tags": [],
	"description": "",
	"content": "Play CSS Garden\nAdditional Resources  CSS grid container in more detail CSS grid items in more detail Things I\u0026rsquo;ve Learned About CSS Grid Layout Let\u0026rsquo;s get griddy with it Complete grid guide Create a page layout with CSS grid  "
},
{
	"uri": "/web-essentials/webmastery-foundations/additional/cssgrid_item_properties/",
	"title": "CSS Grid Items Expanded",
	"tags": [],
	"description": "",
	"content": "This is a continuation lesson with the CSS Grid Container lesson\n float, display: inline-block, display: table-cell, vertical-align and column-* properties have no effect on a grid item.\n grid-column-start | grid-column-end \u0026amp; grid-row-start | grid-row-end Determines a grid item’s location within the grid by referring to specific grid lines. grid-column-start/grid-row-start is the line where the item begins, and grid-column-end/grid-row-end is the line where the item ends.\nValues:\n \u0026lt;line\u0026gt;: can be a number to refer to a numbered grid line, or a name to refer to a named grid line span \u0026lt;number\u0026gt;: the item will span across the provided number of grid tracks span \u0026lt;name\u0026gt;: the item will span across until it hits the next line with the provided name auto: indicates auto-placement, an automatic span, or a default span of one  .item { grid-column-start: \u0026lt;number\u0026gt; | \u0026lt;name\u0026gt; | span \u0026lt;number\u0026gt; | span \u0026lt;name\u0026gt; | auto grid-column-end: \u0026lt;number\u0026gt; | \u0026lt;name\u0026gt; | span \u0026lt;number\u0026gt; | span \u0026lt;name\u0026gt; | auto grid-row-start: \u0026lt;number\u0026gt; | \u0026lt;name\u0026gt; | span \u0026lt;number\u0026gt; | span \u0026lt;name\u0026gt; | auto grid-row-end: \u0026lt;number\u0026gt; | \u0026lt;name\u0026gt; | span \u0026lt;number\u0026gt; | span \u0026lt;name\u0026gt; | auto } Examples:\n.item-a { grid-column-start: 2; grid-column-end: five; grid-row-start: row1-start grid-row-end: 3; } .item-b { grid-column-start: 1; grid-column-end: span col4-start; grid-row-start: 2; grid-row-end: span 2; } grid-column \u0026amp; grid-row Shorthand for grid-column-start + grid-column-end, and grid-row-start + grid-row-end, respectively.\nValues:\n \u0026lt;start-line\u0026gt; / \u0026lt;end-line\u0026gt;: each one accepts all the same values as the longhand version, including span  .item { grid-column: \u0026lt;start-line\u0026gt; / \u0026lt;end-line\u0026gt; | \u0026lt;start-line\u0026gt; / span \u0026lt;value\u0026gt;; grid-row: \u0026lt;start-line\u0026gt; / \u0026lt;end-line\u0026gt; | \u0026lt;start-line\u0026gt; / span \u0026lt;value\u0026gt;; } Example:\n.item-b { grid-column: 3 / span 2; grid-row: third-line / 4; } If no end line value is declared, the item will span 1 track by default.\ngrid-area Gives an item a name so that it can be referenced by a template created with the grid-template-areas property. Alternatively, this property can be used as an even shorter shorthand for grid-row-start + grid-column-start + grid-row-end + grid-column-end.\nValues:\n \u0026lt;name\u0026gt;: a name of your choosing \u0026lt;row-start\u0026gt; / \u0026lt;column-start\u0026gt; / \u0026lt;row-end\u0026gt; / \u0026lt;column-end\u0026gt;: can be numbers or named line  .item { grid-area: \u0026lt;name\u0026gt; | \u0026lt;row-start\u0026gt; / \u0026lt;column-start\u0026gt; / \u0026lt;row-end\u0026gt; / \u0026lt;column-end\u0026gt;; } Examples:\nAs a way to assign a name to the item:\n.item-d { grid-area: header } As the short-shorthand for grid-row-start + grid-column-start + grid-row-end + grid-column-end:\n.item-d { grid-area: 1 / col4-start / last-line / 6 } justify-self Aligns a grid item inside a cell along the inline (row) axis (as opposed to align-self which aligns along the block (column) axis). \u0026gt;This value applies to a grid item inside a single cell.\nValues:\n start: aligns the grid item to be flush with the start edge of the cell end: aligns the grid item to be flush with the end edge of the cell center: aligns the grid item in the center of the cell stretch: fills the whole width of the cell (this is the default)  .item { justify-self: start | end | center | stretch; } align-self Aligns a grid item inside a cell along the block (column) axis (as opposed to justify-self which aligns along the inline (row) axis).\n This value applies to the content inside a single grid item.**  Values:\n start: aligns the grid item to be flush with the start edge of the cell end: aligns the grid item to be flush with the end edge of the cell center: aligns the grid item in the center of the cell stretch: fills the whole height of the cell (this is the default)  .item { align-self: start | end | center | stretch; } place-self place-self sets both the align-self and justify-self properties in a single declaration.\nValues:\n auto: The ``default\u0026rsquo;\u0026rsquo; alignment for the layout mode. \u0026lt;align-self\u0026gt; / \u0026lt;justify-self\u0026gt;: The first value sets align-self, the second value justify-self. If the second value is omitted, the first value is assigned to both properties.  All information used to create this lesson is from: CSS-Tricks.Com\n"
},
{
	"uri": "/java/",
	"title": "Java",
	"tags": [],
	"description": "",
	"content": "Welcome to Java Foundations! "
},
{
	"uri": "/web-essentials/webmastery-foundations/recreate-launch/",
	"title": "Recreate Launch",
	"tags": [],
	"description": "",
	"content": "Recreate the Launch webpage in HTML and CSS For this lab, we\u0026rsquo;ll be using three visual templates to create a static responsive website. Feel free to use any technique we\u0026rsquo;ve learned in order to create the responsive layouts you see in each image below.\n Please right-click and save this image into your own project:\n   Phone Image In the spirit of \u0026ldquo;mobile first responsive design\u0026rdquo; here\u0026rsquo;s the phone view of what the Launch Austin website looks like. Since we can\u0026rsquo;t see the entire screen in one image, we can assume that the other elements of the website (which are shown in the largest view) are simply stacked underneath \u0026ldquo;Meet Our Team.\u0026rdquo;\n  Tablet Image For the Tablet view, follow this visual guide.\n  Desktop Image Here\u0026rsquo;s the largest view we\u0026rsquo;re coding for, the desktop computer image.\n  Login Form Once the login icon is clicked, the user should be redirected to a login form page. The form should have the following:\n two fields, username and password a login button forgotten password link that points back to the current page   Note: upon submit of the form, it should take the user back to the homepage.\n Hints Pay close attention to detail for this exercise. Section order appearance will vary between the phone, tablet and desktop view. Make sure to include all of the elements:\n THD logo Welcome header Login icon in the header Introduction paragraph \u0026ldquo;Upcoming Courses\u0026rdquo; section \u0026ldquo;See All Current cityName Courses\u0026rdquo; button \u0026ldquo;Meet Our Team\u0026rdquo; section  Good luck!\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/css-best-practices/",
	"title": "CSS Best Practices",
	"tags": [],
	"description": "",
	"content": "Introduction CSS source code can get messy in a hurry. Here we discuss a set of modern best practices for using CSS.\nUse a CSS Reset A CSS Reset is a short, often compressed (minified) set of CSS rules that resets the styling of all HTML elements to a consistent baseline.\nWhy Do We Need a CSS Reset? Every browser has its own default user agent stylesheet that it uses to make unstyled websites appear more legible.\nFor example, most browsers by default make links blue and visited links purple, give tables a certain amount of border and padding, apply variable font-sizes to H1, H2, H3 etc. and a certain amount of padding to almost everything. Ever wondered why Submit buttons look different in every browser?\nObviously this creates a certain amount of headaches for CSS authors, who can’t work out how to make their websites look the same in every browser. Using a CSS Reset, CSS authors can force every browser to have all its styles reset to null, thus avoiding cross-browser differences as much as possible.\nAn Example CSS Reset Here is an example of a CSS Reset\n/* Box sizing rules */ *, *::before, *::after { box-sizing: border-box; } /* Remove default margin */ body, h1, h2, h3, h4, p, figure, blockquote, dl, dd { margin: 0; } /* Remove list styles on ul, ol elements with a list role, which suggests default styling will be removed */ ul[role=\u0026#39;list\u0026#39;], ol[role=\u0026#39;list\u0026#39;] { list-style: none; } /* Set core root defaults */ html:focus-within { scroll-behavior: smooth; } /* Set core body defaults */ body { min-height: 100vh; text-rendering: optimizeSpeed; line-height: 1.5; } /* A elements that don\u0026#39;t have a class get default styles */ a:not([class]) { text-decoration-skip-ink: auto; } /* Make images easier to work with */ img, picture { max-width: 100%; display: block; } /* Inherit fonts for inputs and buttons */ input, button, textarea, select { font: inherit; } /* Remove all animations, transitions and smooth scroll for people that prefer not to see them */ @media (prefers-reduced-motion: reduce) { html:focus-within { scroll-behavior: auto; } *, *::before, *::after { animation-duration: 0.01ms !important; animation-iteration-count: 1 !important; transition-duration: 0.01ms !important; scroll-behavior: auto !important; } }    See A Modern CSS Reset for an explanation of how this CSS reset works.    Additional Notes on CSS Resets  Once you use a CSS Reset you are responsible for adding the CSS rules needed to make your website look pretty. Many open source CSS libraries come with a CSS reset built in.   Use the Proper Units The following units are the most popular:\n   Unit Description     px pixels   em the width of the M character in the currently applied font   rem the width of the M character in the root element\u0026rsquo;s font   % a percentage of the container element   vw the viewport width   vh the viewport height    When To Use Each While there are no hard rules for which unit to use, here are some rules of thumb:\n   Application Unit Explanation     font-size rem relative to font-size of root element   width %, vw, or ch ch is good for divs with lots of text   min-height %, rem, or vh Try to avoid setting the height when possible   margin em or rem matches your margin to your font-size   padding em or rem matches your padding to your font-size     NOTE: pixels are not mentioned in the above table. All of the recommended units are relative to the font-size or the viewport size!\n For more details, see: Are you using the right CSS units?\n Keep Things DRY with CSS Variables Sometimes our CSS rules become repetitive. Consider the following example:\nnav { background: rgb(32, 64, 128); /* a nice blue color */ color: rgb(240, 240, 240); /* almost white */ display: flex; align-items: center; justify-content: space-between; align-items: center; } button.primary { background: rgb(32, 64, 128); /* a nice blue color */ color: rgb(240, 240, 240); /* almost white */ } button.secondary { background: rgb(240, 240, 240); /* almost white */ color: rgb(32, 64, 128); /* a nice blue color */ border: 1px solid rgb(32, 64, 128); /* a nice blue color */ } In the above example we are using the color rgb(32, 64, 128) in 4 different CSS rules and the color rgb(240, 240, 240) is used.\nThus if we ever need to change these colors, we have to edit several CSS rules to do so.\nHere is the same example with CSS variables:\n/* You can define global CSS variables using the :root selector */ :root { --primary-color: rgb(32, 64, 128); --secondary-color: rgb(240, 240, 240); } nav { background: var(--primary-color); /* our primary color */ color: var(--secondary-color); /* our secondary color */ display: flex; align-items: center; justify-content: space-between; align-items: center; } button.primary { background: var(--primary-color); /* our primary color */ color: var(--secondary-color); /* our secondary color */ } button.secondary { background: var(--secondary-color); /* our secondary color */ color: var(--primary-color); /* our primary color */ border: 1px solid var(--primary-color); /* our primary color */ } Now if you want to change your primary and/or secondary colors, you can do so in one place!\nYou can try it out here.\n Organize Your CSS and use a Naming Convention For larger projects, you might end up with thousands of lines of CSS!\nThen it becomes increasingly important to ensure that your CSS source code is well organized.\nOrganization SMACSS (Scalable and Modular Architecture for CSS) is a strategy for organizing your CSS rules according to their role. For example:\n Base rules: resets, rules for HTML elements, defining fonts and colors, etc. Layout rules: grid, flexbox Module rules: rules specific to sections of your application (navbar, aside) State rules: hidden, expanded, media queries, etc. Theme rules: light, dark, etc.  For example you could have something like the following CSS files for your project:\n base.css layout.css header.css, navbar.css, payment-form.css, product-list.css, shopping-cart.css light-theme.css, dark-theme.css  Naming Conventions You also want to avoid naming collisions (where the same CSS class name may be defined in different parts of your application).\nBEM is a good strategy for naming your CSS classes to avoid naming collisions.\nBEM stands for block__element--modifier. With BEM each CSS class name has one or more parts defined by the block, the element and/or the modifier for the element.\nExamples:\n   Class Name Description     card card is a block (a div)   card__image the image element inside the card block   card__title the title (h3) element inside the card block   card--light modifies the card to use a light theme   card--dark modifies the card to use a dark theme   card--active modifies the card when the card is selected   card__content--expanded modifies the content in the card    For more info:\n Video: Why I Use the BEM naming convention for my CSS Article: \u0026lsquo;Why BEM?\u0026rsquo; in a nutshell Video: You Probably Need BEM CSS in Your Life (Tutorial)   Keep the Visual UI Simple  Avoid using too many colors. Generally 3 colors is enough. Too many colors can be confusing or distracting. Also consider accessibility guidelines for maximum contrast and considerations for color blindness. Use animations and transitions sparingly. Using too many animations or using animations that are too dramatic will be distracting. Use animations to call attention to an update or a call to action. Avoid cluttered content. Use plenty of spacing. Avoid horizontal scrolling. Use a responsive layout instead. Always provide user feedback. If a user interacts with the page, some kind of feedback should be instantaneous (under 0.5 seconds).   Summary CSS doesn\u0026rsquo;t have to be (too) painful. Using modern best practices will help keep your CSS code structured and maintainable.\nResources  Organizing your CSS Web Design Best Practices Web Accessibility Guidelines v1.0  "
},
{
	"uri": "/javascript/",
	"title": "JavaScript",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s JavaScript Offerings! "
},
{
	"uri": "/javascript/foundations/labs/error-handling-lab/",
	"title": "Error Handling Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch error-handling.js Add the following code to error-handling.js:\nfunction validate(num) { if (typeof (num) !== \u0026#39;number\u0026#39;) { throw new TypeError(`The value ${num}is not a number`); } console.log(`The value ${num}is valid.`); } // TODO: The program exits when it encounters the \u0026#39;banana\u0026#39; value. // Add a try / catch so that all values are validated. // HINT: Where you place the try...catch is important. // HINT: In the catch block, only log the error\u0026#39;s message property. const numbers = [1, 2, \u0026#39;banana\u0026#39;, 4, \u0026#39;orange\u0026#39;, 5]; numbers.forEach(function (val) { validate(val); }); Step 2: Complete the code and test Complete the TODO in the above code.\nTest your solution with:\nnode error-handling.js The expected output is:\nThe value 1 is valid. The value 2 is valid. The value banana is not a number The value 4 is valid. The value orange is not a number The value 5 is valid. "
},
{
	"uri": "/python/foundation/exceptions-labs/",
	"title": "Exceptions Labs",
	"tags": [],
	"description": "",
	"content": "Error Writing Exercises Create a new file called exception_writing.\nWrite try and except statements around these print functions depending on the error that you encounter\neval(\u0026#39;x === x\u0026#39;) print(10 / 0) print(4 + spam) print(2 + \u0026#34;2\u0026#34;) Create an error yourself and use raise to raise an exception\nGo to Booleans Lesson\n"
},
{
	"uri": "/react/foundations/forms/",
	"title": "Forms",
	"tags": [],
	"description": "",
	"content": "Strategies for React Form Controls.\nLearning Objectives  Describe two strategies for managing form controls Implement a controlled form control component   NOTE: Much of the content of this lesson was shamelessly taken from https://goshakkk.name/controlled-vs-uncontrolled-inputs-react/[Controlled and uncontrolled form inputs in React don\u0026rsquo;t have to be complicated - by Gosha Arinich].\n Background  First let\u0026rsquo;s take a look at how HTML forms work in general (straight HTML and JS, no React). Click here to see an example of a simple HTML form using vanilla JavaScript (no React).  How Forms Store Data As You Type  As you type or otherwise interact with the form\u0026rsquo;s input controls, the browser stores the form data internally in the browser\u0026rsquo;s memory with the DOM itself. To get the data (to do form validation or send the data to the server) you must use the DOM\u0026rsquo;s API to pull (i.e. scrape) the form data out of the form to validate it and/or send it to the server. You can use JavaScript DOM events to pull the data either as the user types (the onchange event) or when the user submits the form (the onsubmit event).  How Forms Send Data to server In general HTML forms can send the form data to a server without the aid of any client-side JavaScript.\n HTML supports the following 2 methods for sending data to a server:  HTTP GET: the default method; sends the data in the URL of the HTTP GET request via query parameters. HTTP POST: sends the data in the body of the HTTP POST request.   If a client wants to send an HTTP PUT or DELETE request to the server, it must use client-side JavaScript to do so.  Problem Statement: How To Manage Form Data in React  HTML form elements work a little bit differently from other DOM elements in React, Form elements naturally keep some internal state (the user input).   Question: If we should avoid working directly with the DOM, and avoid making direct mutations to state, then how do we make forms in React?\n Let\u0026rsquo;s look at 2 approaches and when it\u0026rsquo;s appropriate to use each.\nUncontrolled Form Elements  Uncontrolled inputs are like traditional HTML form inputs. The browser\u0026rsquo;s DOM remembers what you type and you can get the value using a ref (using React\u0026rsquo;s useRef hook). For example, in an onClick handler of a button:  function Form() { const nameRef = React.useRef(null) // nameRef will be set by React in the JSX expression below  function handleSubmitClick() { const name = nameRef.current.value // \u0026#34;pull\u0026#34; the value from the DOM via the React ref.  // do something with `name`  } return ( \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; ref={nameRef} /\u0026gt; {/* this is where nameRef gets assigned to a DOM node */ } \u0026lt;button onClick={handleSubmitClick}\u0026gt;Sign up\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; ); } } The useRef Hook  Essentially, useRef is like a “box” that can hold a mutable value in its .current property useRef has the following API:  const refContainer = useRef(initialValue);  useRef returns a mutable ref object whose .current property is initialized to the passed argument (initialValue) The returned object will persist for the full lifetime of the component.  Using useRef to get a reference to DOM node  Often useRef is used to hold a ref to a DOM node. In this case the initialValue is usually null until React reassigns it during the render phase. Then you can pull the value from the input when you need it, such as when the form is submitted. This is the simplest way to implement form inputs, and there are certainly valid cases for using it, such as in simple forms. But there are many cases when we need a bit more power and flexibility.  Discussion: Can you think of some scenarios where uncontrolled React form elements would not work well?\nControlled Form Elements  A controlled input accepts its current value as a prop, as well as a callback to change that value. Thus with a controlled input:  the value for the input is provided the value is continually being updated using the onChange event   You could say it’s a more \u0026ldquo;React way\u0026rdquo; of approaching things.  A Controlled Input\n\u0026lt;input value={someValue} onChange={handleChange} /\u0026gt;  This seems fine, but the value of this input has to live in the state somewhere. Typically, the component that renders the input (aka the form component) saves it in its state:  A Form with a Controlled Form Element:\nfunction Form() { const [name, setName] = React.useState[\u0026#39;\u0026#39;] // store the form data in state variables  handleNameChange = (event) =\u0026gt; { setName(event.target.value) // update name as the user types  } return ( \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value={name} { /* provide the value to the input */} onChange={handleNameChange} { /* capture changes as the user interacts with the input */ } /\u0026gt; \u0026lt;/div\u0026gt; ) }  Every time you type a new character, handleNameChange is called. Then handleNameChange sets the new value in the name state variable. This flow kind of pushes the value changes, so the Form component always has the current value of the input.  Demo Click here to view a live demo showing both uncontrolled and controlled form inputs.\nAdvantages of Controlled Inputs  Using controlled inputs means that your data (state) and UI (inputs) are always in sync. The state gives the value to the input (as a prop), and the input notifies the Form to change the current value on every user interaction.  This also means that the form component can respond to input changes immediately; for example, by:\n in-place feedback, like validations disabling a button unless all fields have valid data enforcing a specific input format, like credit card numbers  Demo of Form with Multiple Controlled Inputs Click here to see a demo of a React form with multiple controlled inputs and some simple validation.\nTips  A form element becomes controlled if you set its value via a prop. You should also set an onChange handler to keep the input element and the React component in sync.  Each of the form elements, though, has a slightly different interface, so here’s a table to summarize:\n   Element Value Property Change Callback New Value in the Callback     \u0026lt;input type=\u0026quot;text\u0026quot; /\u0026gt; value=\u0026quot;string\u0026quot; onChange event.target.value   \u0026lt;input type=\u0026quot;checkbox\u0026quot; /\u0026gt; checked={boolean} onChange event.target.checked   \u0026lt;input type=\u0026quot;radio\u0026quot; /\u0026gt; checked={boolean} onChange event.target.checked   \u0026lt;textarea /\u0026gt; value=\u0026quot;string\u0026quot; onChange event.target.value   \u0026lt;select /\u0026gt; value=\u0026quot;option value\u0026quot; onChange event.target.value    Summary  Both uncontrolled and controlled form inputs have their merit. Uncontrolled inputs are a bit simpler, but you need to use the useRef hook to pull the values. Controlled inputs are more powerful as you can do dynamic form updates and dynamic form validation.  Lab - Build a Simple Calculator Click here for the instructions to this lab.\nAdditional Resources  Controlled Components Uncontrolled Components Controlled and uncontrolled form inputs in React don\u0026rsquo;t have to be complicated  "
},
{
	"uri": "/javascript/foundations/functions/",
	"title": "Functions",
	"tags": [],
	"description": "",
	"content": "An introduction to functions in JavaScript.\nLearning Objectives After this lesson, developers will be able to:\n Describe why functions are created Explain the single responsibility principle Explain what makes a function reusable Describe how parameters and arguments relate to functions Explain the concept of scope and how functions affect scope Compare global and local scope Create functions in order to break programs into smaller sub-programs and include parameters if necessary Call a function passing in data (arguments) and getting back a result  What is a function? Definition  function\nA sequence of program instructions that perform a specific task, packaged as a unit. This unit can then be used in programs wherever that particular task should be performed.\n Examples // find the average of two numbers function average(x, y) { return (x + y) / 2; } // calling the function let y = average(20, 40); console.log(\u0026#34;y = \u0026#34; + y); // will print \u0026#34;y = 30\u0026#34; Functions are Like Math Another useful analogy is to remember what functions do in mathematics.\nGiven a simple function\ny = f(x) if we let f(x) = x^2 then we have:\nf(2) = 4 f(3) = 9 etc. In Mathematics, functions have inputs, outputs, a name, and a definition.\nIt is similar in Computer Science.\nWhy do we use functions?  Functions help us to structure larger programs into a bunch of smaller sub-programs. Functions also help us to define a vocabulary for a problem we are solving. Functions create abstractions for the detailed work that they do.  Consider calculating the tax on an investment.\n We write a function to do the work and call it calcTax Then we can call calcTax without having to think too much about how it does the calculation.  Being DRY  One particular best practice in software engineering is the DRY principle. DRY stands for Don\u0026rsquo;t Repeat Yourself. It means that we should avoid having multiple copies of a chunk of code (or data) because maintaining multiple copies is problematic. Functions are one way of avoiding duplicate code.  Declaring a JavaScript Function Syntax\nfunction \u0026lt;function_name\u0026gt;(parameters) { \u0026lt;function_body\u0026gt; } Example\n// function declaration function square(x) { return x * x; } // calling the function let y = square(3); console.log(\u0026#34;y = \u0026#34; + y); // will print \u0026#34;y = 9\u0026#34; This is a simple example of a function but there is a lot going on:\n We have defined a function with the name square. The function takes a single parameter which has the name x. The function has a body defined by { and } where the function does its work. The function calculates the square of x. The function returns the result of squaring x, which in this case is the argument 3 within the parenthesis when we call the function.  The Return Statement The return statement ends the execution of the function and (optionally) returns a value to the caller.\nfunction plusFive(number) { // `return` the value of whatever number is passed in + 5  return number + 5; } // print the value of the argument passed in which is: 10 + 5 console.log(plusFive(10)); // 15 We can also write functions that return a value based on specific conditions.\n// calculate income tax function getTax(income) { if (income \u0026lt; 50000) { return income * 0.15; } else if (income \u0026lt; 100000) { return income * 0.2; } else { return income * 0.25; } } // calling the function console.log(\u0026#34;Tax on 40000 = \u0026#34; + getTax(40000)); // Tax on 40000 = 6000 console.log(\u0026#34;Tax on 80000 = \u0026#34; + getTax(80000)); // Tax on 80000 = 16000 console.log(\u0026#34;Tax on 120000 = \u0026#34; + getTax(120000)); // Tax on 120000 = 30000 In the above example, our function returns a value based on the condition.\nfunction sayHi(name) { return \u0026#34;Hi \u0026#34; + name; // return a string greeting the user by name  console.log(name); // this line will never be evaluated } When There Is No Return Statement Not all functions have a return value. Sometimes a function simply needs to perform an operation.\nfunction greeting(name) { console.log(`Hello ${name}!`); } greeting(\u0026#39;Homer\u0026#39;); // Hello Homer! Since a function is called to perform some task, the function must either:\n return a value change the environment in some way (a side-effect) both 1 and 2  Labs See instructions here.\nSummary  Functions are an essential part of JavaScript We can use functions to break up a large program into composable and reusable parts. With functions we can DRY up our code. A function should perform one specific task (the single responsibility principle). Functions take parameters and may return a result.  "
},
{
	"uri": "/software-eng-essentials/git-foundations/intro-to-github-labs/",
	"title": "GitHub Intro Labs",
	"tags": [],
	"description": "",
	"content": "GitHub Interactions Class Activity  Before doing this lab, the instructor will create a repo called Zoo that has a README.md that simply says Zoo. Add all students as collaborators to the repo. Lock master and make it to where one review is required to merge into master.\n  Create an issue in the repo asking that they create a text file with the name of an animal and the contents should be the sound that animal makes. They should also assign this issue to themselves. For example:   Clone down the Zoo repo. Create a branch called your ldap. For example if your ldap is ldap123, do: git checkout -b ldap123 Add your animal text file with it\u0026rsquo;s contents. Save, stage, commit, and push this change to the remote Zoo repo. Create a PR that asks to merge your new branch into master. Tag the current instructor as the reviewer.  Once the whole class has correctly created their PR, the instructor will go through and merge all of these in! (You might run into a merge conflict or two!)\nYour Turn  Pair up into groups of two or three. Partner #1 create a directory and a public repository called Ping-Pong. In Partner #1\u0026rsquo;s local copy, create a text document called my-message.txt. Inside this new file, place a single line of whatever text you want. Partner #1 will push this up to their repository. Partner #2 (and #3 if a group of three) will clone this repository. Partner #2 creates a branch text-addendum will add a single line of whatever text they want to the text file. Stage the changes, commits, and then pushes the change to GitHub. If you are a group of three, the Partner #3 will do the same on a branch called third-addendum. Partner #1 pulls change, edits next line, stages, commits, and pushes. Keep going and get as many lines filled within the time limit.  PR Tutorial  Take a few minutes to read this Pull Request Tutorial     Go to Forking Lesson    "
},
{
	"uri": "/web-essentials/cheatsheets/html-css-cheatsheet/",
	"title": "HTML &amp; CSS Cheatsheet",
	"tags": [],
	"description": "",
	"content": "Resource W3Schools HTML Reference \nCommon Terms    Term  Description     HTML Hyper Text Markup Language, markup language used for representing structured text.   Hyperlink Part of a web page that a user clicks on to view the destination document.   Element Defines a particular part of the HTML document structure, defined by tags.   Tag Defines a particular element in an HTML document. Often there is an opening tag and closing tag. Some tags can be self closing.   Stylesheet A collection of style rules that tells a browser how the various styles are to be applied to HTML tags to present the document.    HTML Syntax \u0026lt;tag attribute=\u0026#34;value\u0026#34;\u0026gt;Content goes here\u0026lt;/tag\u0026gt; Tags can have more than one attribute. For a list of attributes see W3Schools HTML Attribute List.\nCommon Tags    Term  Description     \u0026lt;html\u0026gt; Defines an HTML Document   \u0026lt;head\u0026gt; Contains the metadata/information for the document   \u0026lt;meta\u0026gt; Defines metadata about an HTML document   \u0026lt;link\u0026gt; Defines the relationship between a document and an external resource (most used to link to style sheets)   \u0026lt;script\u0026gt; Defines a client-side script   \u0026lt;title\u0026gt; Defines a title for the document   \u0026lt;body\u0026gt; Defines the document\u0026rsquo;s body   \u0026lt;h1\u0026gt;...\u0026lt;h6\u0026gt; Defines an HTML heading   \u0026lt;a\u0026gt; Anchor tag, defines a hyperlink element   \u0026lt;img\u0026gt; Defines an image element   \u0026lt;p\u0026gt; Defines a paragraph element   \u0026lt;div\u0026gt; Defines a section in a document (box element)   \u0026lt;ul\u0026gt; Defines an unordered list with bullet points   \u0026lt;ol\u0026gt; Defines an ordered (numbered) list   \u0026lt;li\u0026gt; Defines a list item   \u0026lt;nav\u0026gt; Defines navigation links   \u0026lt;option\u0026gt; Defines an option in a drop-down list   \u0026lt;select\u0026gt; Defines a drop-down list   \u0026lt;table\u0026gt; Defines a table element   \u0026lt;thead\u0026gt; Groups the header content in a table   \u0026lt;tbody\u0026gt; Groups the body content in a table   \u0026lt;tr\u0026gt; Defines a table row   \u0026lt;td\u0026gt; Defines the data cells in a table   \u0026lt;th\u0026gt; Defines a header cell in a table   \u0026lt;!--...--\u0026gt; Defines a comment   \u0026lt;blockquote\u0026gt; Defines a section that is quoted from another source   \u0026lt;br\u0026gt; Inserts a single line break   \u0026lt;code\u0026gt; Defines an element that contains computer code   \u0026lt;form\u0026gt; Defines an HTML form for user input   \u0026lt;input\u0026gt; Defines an input control   \u0026lt;label\u0026gt; Defines a label for an \u0026lt;input\u0026gt; element   \u0026lt;button\u0026gt; Defines a clickable button    CSS Rule Syntax selector { property: value; } Common Styling Properties Resource W3Schools Cascading Style Sheets\nFont Styles    Property Description     font-family Changes the font family of text   font-style Changes text: normal, oblique, and italics   font-weight Specifies the weight of the font   font-size Modifies the size of the text    Color and Background Styling    Property Description     color Defines text color   background-color Defines background color of an element   background-image Sets the background imaged of an element   background-repeat Determines how often a background image is repeated.    Text Styles    Property Description     text-decoration  Allows text to be decorated through one of five properties: underline, overline, line-through, blink, none.   text-align Used to justify text left, center, right, and justify   text-transform Allows for capitalizing the first letter of each word (capitalize), capitalizing all letters of a word (uppercase), using all small letters in each word(lowercase), and the inital value(none).    Box Properties    Property Description     margin Box PropertiesSets the margins of an element by specifying top, bottom, left and right margins – all either specifying length or percentage. Can be set separately with margin-top, margin-right, margin-bottom, margin-left .   padding  Describes the amount of space between the border and the content of the selector by length or percentage on the top, bottom, left and right. Can be set separately using padding-top, padding-right, padding-bottom, padding-left.   border Sets the width, style, and color of an element’s border. Can be set separately with border-top, border-right, border-bottom, border-left.   width Each block-level or replaced element can be given a width, specified as a length, a percentage, or as auto.   height Each block-level or replaced element can be given a height, specified as a length or as auto.   float Allows text to wrap around an element (left, right, none).   clear Specifies whether an element allows floating elements to its sides (left, right, none).    "
},
{
	"uri": "/java/foundations/interface/",
	"title": "Interface",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Abstraction Interfaces vs Classes  Skills  Creating a Java Interface Implementing an interface  Abstraction Abstraction is the process of separating ideas from implementation. Taking things a step back from the practical and taking a theoretical look at the world around you. We do this with real world objects, and we\u0026rsquo;ll do it with Software Objects as well. In Java, abstraction allows you to describe and plan on certain aspects of an object without knowing exactly what the ultimate implementation will look like.\nInterfaces Recall that encapsulation requires that a class protects it\u0026rsquo;s fields and controls any access or modification through it\u0026rsquo;s methods. In this way, an object\u0026rsquo;s public methods creates the interface between an object and the outside world. When you create a Java interface you\u0026rsquo;re doing just that: providing a group of methods that an object will use to interact with the world. In many ways, it simply looks like a stripped down class:\npublic interface Car { void paint(String color); void shiftUp(int gears); void shiftDown(int gears); void accelerate(double inc); void applyBrake(double dec); }  NOTICE\n notice this time Car is declared as an interface rather than class something weird? none of the methods have bodies   An interface houses method definitions (return type, name, and parameters) but it leaves out any implementation. It delegates this out to someone else. This type of method is called an abstract method and when defined in an interface they form a type of contract. Basically saying, \u0026ldquo;I\u0026rsquo;m describing an object that can do these things\u0026hellip;I don\u0026rsquo;t know how, but it can\u0026hellip; trust me.\u0026rdquo;\nImplementing an Interface Unlike when it extends (inherits) a parent, a class can implement as many interfaces as it wants. As you might expect, this is declared by the implements classifier.\npublic class Truck implements Car { ... In this declaration, the class Truck now promises to uphold the contract put forth by the Car interface. The Java compiler will now hold this class to that promise and if any of the methods promised by the interface are not implemented by the class there will be a compilation error.\npublic class Truck implements Car { private final int MAX_GEAR = 9; private String engine; private double cargoSpace; private String color; private int gear = 1; private int speed; public Truck(String color, String engine, double cargoSpace) { this.color = color; this.engine = engine; this.cargoSpace = cargoSpace; } @Override public void paint(String color) { this.color = color; } @Override public void shiftUp(int gears) { if (gear + 1 \u0026lt;= MAX_GEAR) gear++; } @Override public void shiftDown(int gears) { if (gear - 1 \u0026gt; 0) gear--; } @Override public void accelerate(double inc) { speed += inc; } @Override public void applyBrake(double dec) { speed -= dec; if (speed \u0026lt; 0) speed = 0; } ... Now perhaps define another implementation\u0026hellip;\npublic class SportsCar implements Car { ... private int gear; ... @Override public void shiftUp(int gears) { gear += gears; if (gear \u0026gt; MAX_GEAR) gear = MAX_GEAR; } @Override public void shiftDown(int gears) { gear -= gears; if (gears \u0026lt;= 0) gear = 1; } ... As shown above, we can have two classes which will bind themselves to the same interface but carry out the implementation differently.\nPolymorphism So\u0026hellip;.why? Why use interfaces? You have to implement the methods anyway, why have this contract looming over the class? Well, by binding this contract to a subset of objects, you allow for some flexibility when working with these objects. For instance, say we have a method in a racing program that needs the ability to accelerate and decelerate a vehicle. Well depending on the vehicle it had to handle, it would need different methods:\nvoid adjustSpeed(SportsCar sportsCar) { // logic to adjust a SportsCar to the appropriate speed } void adjustSpeed(Truck truck) { // logic to adjust a car to the appropriate speed } However, if we have our Car interface with the methods accelerate and applyBrakes, then all we have to do is implement the interface in our two classes and we can combine our methods into one:\nvoid adjustSpeed(Car car) { // logic to adjust a car to the appropriate speed } Now, we know Car cannot be instantiated (it is only an interface), which means a Car object will never be passed in. However, this signature tells the method to accept any object that implements Car (fulfills the Car contract) so that while we are in this method we will take for granted that whatever object it is attached to, it at least has the methods promised by this Car interface. All this means that both of these calls are valid:\nTruck truck = new Truck(\u0026#34;Black\u0026#34;, \u0026#34;V6\u0026#34;, 16); SportsCar sportsCar = new SportsCar(\u0026#34;Red\u0026#34;, \u0026#34;V6\u0026#34;, true, 6); adjustSpeed(truck); adjustSpeed(sportsCar);  INFO: This same concept stands for Subclasses of the same Superclass as well.\n Common Interfaces  Iterable - Implementing this interface allows an object to be the target of the foreach statement. Comparable - By implementing this interface, the class has the opportunity to compare the object with another specified object by implementing the method compareTo(Object o, Object o); Collection - probably won\u0026rsquo;t implement this directly but this houses the functionality implemented by many commonly used structures like Lists, Sets, and Queues  Example public class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, RandomAccess, Cloneable, java.io.Serializable { ... Abstract Classes So we\u0026rsquo;ve discussed classes and we\u0026rsquo;ve discussed interfaces\u0026hellip;now let\u0026rsquo;s talk about something in middle: Abstract Classes. These look just like a normal class, but with the modifier abstract. Like a normal class, it cannot be implemented, it must be extended. However, like an interface, it supports abstract methods.\npublic abstract class Triangle { private final int EDGES = 3; public int getEdgeCount() { return EDGES; } public abstract void draw(); }    Abstract Class Interface     both abstract and non-abstract methods only abstract methods   only singular inheritance multiple inheritance   can implement an interface cannot inherit from classes or interfaces    Summary An interface is a non-implemented abstraction of a class. It can contain abstract method signatures, default methods, static methods and constant definitions. A class that implements an interface must implement all the methods declared in the interface.\nAn interface name can be used anywhere a type can be used giving you the flexibility to match it with any class that implements that interface.\nResources "
},
{
	"uri": "/react/pillars/hooks/",
	"title": "React Hooks",
	"tags": [],
	"description": "",
	"content": "Welcome to React Hooks! For more details see the syllabus.\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/sass/",
	"title": "SASS",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Describe some problems with CSS that Sass solves. Describe what a Preprocessor does.  Skills  Use Sass to DRY up CSS code. Use a Sass library  Problems with CSS While CSS is great for bringing life to our applications, it\u0026rsquo;s not without fault.\nSome of the problems we run into with CSS include:\n Does not scale to large web sites / applications  Does not provide any mechanisms for reuse.   Cascading not a good fit for component based development  Cascading is better fit for publishing static content Components are reusable and should not radically change appearance based on context   Organization: How to organize and manage the following responsibilities:  Simple styling: colors, fonts, borders, shadows Layout: margins, padding, justification, alignment, grid systems States: enabled, disabled, visible, hidden Animations   Naming - class names  How to avoid name conflicts How to be semantic    What are Preprocessors?  Preprocessors allow us to write source code in one language and translate the source code into another language. Sometimes preprocessors don\u0026rsquo;t translate from one language to another but do apply values to placeholders (i.e. templates).  Examples  ERB: evaluates Ruby expressions in an HTML, CSS, or other source file. PUG (formerly known as JADE): translates JADE files into HTML. CoffeeScript: compiles CoffeeScript source code into JavaScript. Sass: compiles Sass source code into CSS source code. LESS: compiles LESS source code into CSS source code.  Advantages of Preprocessing? Sometimes we cannot alter the target language of an execution environment (such as a browser), but we want to write our source code in something other than what the target execution environment supports.\n PUG (formerly known as JADE) instead of HTML CoffeeScript instead of JavaScript Sass instead of CSS  Thus we can use advanced features of a new language without waiting for the browser to support these advanced features.\nWe can also more easily support browser quirks and idiosyncrasies by handling them in the preprocessor instead of in the original source code.\nWhat is Sass? Before moving on, take a few minutes to watch the following videos:\n     Sass is an extension of CSS. Sass adds the following features to CSS:     Feature Advantage     nesting makes code easier to read and maintain try it at http://css2Sass.herokuapp.com/   variables DRY up expressions with reusable expressions   operators Flexible math calculations   partials \u0026amp; imports Organize code by splitting into separate files that get combined later   functions DRY up Sass logic   mixins DRY up Sass styling via importing   extends DRY up Sass styling via inheritance     See: Sass Basics  Advantages of Using Sass  DRY up your CSS via variables, functions, mixins, and extends Organize your CSS via nesting and partials Use math expressions in your CSS via operators Optimize the CSS output: Sass only includes what is used in your Sass files.  For a real-time preview, see: Sassmeister.\n   Go to SASS labs    "
},
{
	"uri": "/custom-workshops/frontend-at-thd/sass-crash-course/",
	"title": "SASS Crash Course",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Describe some problems with CSS that Sass solves. Describe what a Preprocessor does.  Skills  Use Sass to DRY up CSS code. Use a Sass library  Problems with CSS While CSS is great for bringing life to our applications, it\u0026rsquo;s not without fault.\nSome of the problems we run into with CSS include:\n Does not scale to large web sites / applications  Does not provide any mechanisms for reuse.   Cascading not a good fit for component based development  Cascading is better fit for publishing static content Components are reusable and should not radically change appearance based on context   Organization: How to organize and manage the following responsibilities:  Simple styling: colors, fonts, borders, shadows Layout: margins, padding, justification, alignment, grid systems States: enabled, disabled, visible, hidden Animations   Naming - class names  How to avoid name conflicts How to be semantic    What are Preprocessors?  Preprocessors allow us to write source code in one language and translate the source code into another language. Sometimes preprocessors don\u0026rsquo;t translate from one language to another but do apply values to placeholders (i.e. templates).  Examples  ERB: evaluates Ruby expressions in an HTML, CSS, or other source file. PUG (formerly known as JADE): translates JADE files into HTML. CoffeeScript: compiles CoffeeScript source code into JavaScript. Sass: compiles Sass source code into CSS source code. LESS: compiles LESS source code into CSS source code.  Advantages of Preprocessing? Sometimes we cannot alter the target language of an execution environment (such as a browser), but we want to write our source code in something other than what the target execution environment supports.\n PUG (formerly known as JADE) instead of HTML CoffeeScript instead of JavaScript Sass instead of CSS  Thus we can use advanced features of a new language without waiting for the browser to support these advanced features.\nWe can also more easily support browser quirks and idiosyncrasies by handling them in the preprocessor instead of in the original source code.\nWhat is Sass? Before moving on, take a few minutes to watch the following videos:\n     Sass is an extension of CSS. Sass adds the following features to CSS:     Feature Advantage     nesting makes code easier to read and maintain try it at http://css2Sass.herokuapp.com/   variables DRY up expressions with reusable expressions   operators Flexible math calculations   partials \u0026amp; imports Organize code by splitting into separate files that get combined later   functions DRY up Sass logic   mixins DRY up Sass styling via importing   extends DRY up Sass styling via inheritance     See: Sass Basics  Advantages of Using Sass  DRY up your CSS via variables, functions, mixins, and extends Organize your CSS via nesting and partials Use math expressions in your CSS via operators Optimize the CSS output: Sass only includes what is used in your Sass files.  For a real-time preview, see: Sassmeister.\n"
},
{
	"uri": "/golang/foundations/structs-and-methods/",
	"title": "Structs and Methods",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Creating \u0026amp; Using Structs Creating and Using Methods and an Instance of a Struct  Structs The struct\n How data is described Made of typed fields Can be thought of very loosely as similar to a Javascript Object, or a Java Class\u0026rsquo; Fields  OOP Type things Via Structs Go can be thought of as a lite OOP. Some of the key differences between go and traditional OOP languages:\n No Inheritance Composition is accomplished through subtyping Polymorphism: Interfaces are types and implicitly satisfied  Syntax:\ntype \u0026lt;name\u0026gt; struct{} Defining a struct:\ntype Position struct { X int Y int Z int }  Defined a type named Position of type struct Contains 3 fields (X, Y and Z) with the same type Fields can have mixed types  Initializing a Struct with Values  Named Fields  pos := Position{X:1,Y:2,Z:3}  By Value — Must be in order  pos := Position{1,2,3}  Partial  pos := Position{Z:2}  With partial initialization, the other fields will be the 0 value of their types.  Reading and Updating Fields Reading Fields pos := Position{X:1,Y:2,Z:3} fmt.Println(pos.X) fmt.Println(pos.Y) fmt.Println(pos.Z) Try Me\nWriting to Fields pos := Position{X:1,Y:2,Z:3} pos.X = 5 fmt.Println(pos) Try Me\nPointers, Functions and Other Structs as Fields  Field names follow the same rules as variables.  Mixing Field Types\ntype Player struct { Name string // 1 \tPos *Position // 2 \tGameMap map[String]Position // 3 \tSpecial func() string // 4 }  Name as a string field Pos is a pointer to a Position struct GameMap a pointer to a map of Position structs Special a field that accepts a function as a value  Example:\npackage main import \u0026#34;fmt\u0026#34; type Position struct { X int Y int Z int } type Player struct { Name string Pos *Position GameMap map[string]*Position Special func() string } func main() { pos := Position{X: 1, Y: 2, Z: 3} pos2 := Position{X: 4, Y: 3, Z: 3} gamemap := map[string]*Position{ \u0026#34;player1\u0026#34;: \u0026amp;pos, \u0026#34;player2\u0026#34;: \u0026amp;pos2, } special := func() string { return \u0026#34;I\u0026#39;m not special. This is all I can really do\u0026#34; } player := Player{ Name: \u0026#34;player1\u0026#34;, Pos: \u0026amp;pos, GameMap: gamemap, Special: special, } fmt.Println(\u0026#34;Name \u0026amp; position:\u0026#34;, player.Name, player.Pos) fmt.Println(\u0026#34;Player2 position via GameMap\u0026#34;, player.GameMap[\u0026#34;player2\u0026#34;]) fmt.Println(\u0026#34;Player1 Special\u0026#34;, player.Special()) } Try Me\nFactory Pattern as a Constructor Option The Factory Pattern\n In class-based programming, the factory method pattern is a creational pattern that uses factory methods to deal with the problem of creating objects without having to specify the exact class of the object that will be created. This is done by creating objects by calling a factory method—either specified in an interface and implemented by child classes, or implemented in a base class and optionally overridden by derived classes—rather than by calling a constructor.  Wikipedia\nAlthough go does not have classes, the factory pattern can be applied to generate initialized instances of structs.\nWhy use the Factory Pattern? Here are some of the more common reasons:\n Provide default values for fields Allows for initialization of unexported fields Cleaner code for complex structs Create instances of unexported structs Allow the creation of unexported concrete types when returning interfaces  func NewPlayer(name string) Player { // 1 \tpos := Position{X: 1, Y: 2, Z: 3} pos2 := Position{X: 4, Y: 3, Z: 3} return Player{ Name: name, Pos: \u0026amp;pos, GameMap: map[string]*Position{ name: \u0026amp;pos, \u0026#34;player2\u0026#34;: \u0026amp;pos2, }, Special: func() string { return \u0026#34;I\u0026#39;m not special. This is all I can really do\u0026#34; }, } } func main() { player := NewPlayer(\u0026#34;Groo\u0026#34;) // 2 }  Factory pattern function that will construct an instance of Player Call the function to get an instance of Player  Lab: Structs and Constructors  Follow the instructions in the readme for the go foundations labs cd \u0026lt;your workspace\u0026gt;/go-found-labs/structs/lab1/ Open structs.go and complete the instructions in the readme.  Methods  Follow all the same rules as function Get linked to a type Have additional syntax called a method receiver:  func (\u0026lt;name\u0026gt; \u0026lt;type\u0026gt;) ([\u0026lt;types\u0026gt;]) ([\u0026lt;return types\u0026gt;]){ //Stuff happens here  } Example Method for the Player Struct\nfunc ( p Player) Move() { p.Pos.X++ }  (p Player) is the method receiver. (p Player) associates the function as a method to an instance of a Player struct. Move Is the name of the method to be invoked when accessing it through the type.  Accessing and Methods type Player struct { Name string Pos *Position GameMap map[string]Position Special func() string } func (p *Player) Move() { p.Pos.X++ } func main() { //Create a new Player \tplayer := NewPlayer(\u0026#34;Groo\u0026#34;) //Print out the game map \tfmt.Println(player.GameMap[\u0026#34;Groo\u0026#34;]) //Print out the player\u0026#39;s X position \tfmt.Println(\u0026#34;Player\u0026#39;s x position is:\u0026#34;, player.Pos.X) player.Move() fmt.Println(\u0026#34;The player moved, the position is now:\u0026#34;, player.Pos.X) fmt.Println(\u0026#34;The map is now:\u0026#34;, player.GameMap[\u0026#34;Groo\u0026#34;].X) } Try Me\nValue Receiver Pointer Receivers Value Receiver   The type is passed by value into the method\n  The original instance of the type cannot be modified from within the instance of the method\n  The Move Method from the previous example demonstrates a value receiver\n  func (p Player) Move() { p.Pos.X++ }  Pos is mutable because its type is a reference ( pointer ) to a struct type  What happens when a value that is not a pointer gets changed in a method? func (p Player) ChangeName(name string) { p.Name = name } Try Me\nBased on the definition of a value receiver:\n What happens? Why does it happen?  Pointer Receiver  Defined by using the * operator with the type in the method receiver Allows for mutation of the data on the original instance of a struct Original type does not need to be a referenced type, unless you are satisfying an interface  Now add the * to the Player type in the receiver’s signature to match func (p *Player) Move() and run the code again.\n What changed if anything? Why?  When to use a Pointer or Value Receiver Use a value receiver unless\n You need to modify a value in a the original type You are unsure that where the type is used is being done so in a thread safe manner You are working with a large data structure and passing by value would cause performance issues  Again, the above points are just a guideline. If they are not clear, this is a quick, clear guidewith a bit more detail.\nLab: Structs with Methods  Follow the instructions in the readme in the structs packagefor lab2.  "
},
{
	"uri": "/software-eng-essentials/command-line-bash/subshell/",
	"title": "Subshell",
	"tags": [],
	"description": "",
	"content": "Objectives  Subshell Local variables Environment variables  Subshell A subshell is a child instance of a parent shell.\n// Add more content about scope\nYou can start a new subshell by calling on /bin/bash or just bash.\nStart a subshell\n$ bash bash-3.2$ You can exit a shell or subshell by entering exit or ⌃D.\nExit a subshell\nbash-3.2$ exit $ Exit the shell\n$ exit logout Saving session...completed. Local variables Bash variable syntax must include a variable name joined to a value with no spaces between the two. The value may be enclosed in a pair of single quotations marks, double quotations marks, or nothing at all.\n$ myapron=\u0026#39;orange\u0026#39; $ myapron=\u0026#34;orange\u0026#34; $ myapron=orange Note that a space should not prepend or append the = assignment operator.\n$ myapron = \u0026#39;orange\u0026#39; -bash: myapron: command not found Calling a variable You call a bash variable in a script with a $ dollar sign prepended.\n$ echo $myapron orange However, local bash variables are scoped to the shell or subshell they are declared. Try and call a variable in a different shell:\nCall a local variable out of scope\n$ myapron=orange $ echo $myapron orange $ bash bash-3.2$ echo $myapron # returns nothing Environment Variables Environment variables are globally scoped to be used in child shells and across other subshells.\nNote that a variable cannot be scoped upward. A variable cannot be used by a parent shell, even if it is exported from the subshell. However, it can be used in a sibling subshell.\n Recall that PATH is a shell environment variable which gives the list of directories the system searches for commands.\n Summary Writing a script with subshell commands.\nSubshell\nCreate a file called intro (shell scripts do not need a file extension). In a text editor, add the following lines to intro:\necho \u0026#34;Hello World\u0026#34; echo $(which neqn) cat $(which neqn) Once the file is saved run this command in the terminal:\n$ sh intro We have seen the first line before.\nThe second and third line each use a subshell. Bash uses a subshell to run the second command in each line, and store the output for use by the second command.\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/sass-labs/",
	"title": "SASS Labs",
	"tags": [],
	"description": "",
	"content": "Given a div container that has 3 child divs:\n\u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt;Colors \u0026lt;div class=\u0026#34;red\u0026#34;\u0026gt; \u0026lt;p\u0026gt;Red\u0026lt;/p\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;green\u0026#34;\u0026gt;\u0026lt;p\u0026gt;Green\u0026lt;/p\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;blue\u0026#34;\u0026gt; \u0026lt;p\u0026gt;Blue\u0026lt;/p\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; Using only vanilla CSS (no Sass, no Bootstrap, no Foundation) style the above HTML as follows:\n The outer div has:  a width of 400px a height of 200px background color of light gray a border of black, a border radius of 20px and a label of \u0026ldquo;Colors\u0026rdquo; near the top of the div   The inner divs should fit nicely inside the outer div and have the following:  Background colors of \u0026ldquo;##FFB3B3\u0026rdquo;, \u0026ldquo;light green\u0026rdquo;, and \u0026ldquo;light blue\u0026rdquo;, respectively. Borders of red, green, and blue, respectively. Labels of \u0026ldquo;Red\u0026rdquo;, \u0026ldquo;Green\u0026rdquo;, and \u0026ldquo;Blue\u0026rdquo;, respectively. A border radius of 10px.   Now convert the CSS to Sass and make it as DRY as possible. Feel free to use the Compass Sass library. Bonus:  Make it easy to resize the outer div and have the inner div’s resized accordingly (don’t use percentages). Make the labels in the color divs have a text color that is the complement of the background color.    Additional Resources  Sassmeister CSS 2 Sass Online Converter OOCSS - Object Oriented CSS BEM - Block, Element, Modifier Sass - Preprocessor LESS - Preprocessor Bourbon - Bourbon Sass Library Organizing CSS, OOCSS, SMACSS, and BEM Codepen: News, Weather, and Sports with Bourbon and Neat  "
},
{
	"uri": "/javascript/foundations/prettier/",
	"title": "Code Style with Prettier",
	"tags": [],
	"description": "",
	"content": "An introduction to code style and static code analysis / linting.\nLearning Objectives  Define code style and explain why it is important. Install and configure the Prettier plugin for VS Code. Write some ugly code and then let Prettier fix it up.  Introduction Consider the following correct, but ugly code:\nfunction fizzBuzz ( n ) { for(let i=1;i\u0026lt;=n;i++){ if (i % 15 === 0) console.log(\u0026#39;FizzBuzz\u0026#39;) else if (i % 3 === 0) { console.log(\u0026#34;Fizz\u0026#34;) } else if (i % 5 === 0) { console.log(\u0026#39;Buzz\u0026#39;) } else { console.log(i) } }} fizzBuzz(16) Much better is this:\nfunction fizzBuzz(n) { for (let i = 1; i \u0026lt;= n; i++) { if (i % 15 === 0) { console.log(\u0026#34;FizzBuzz\u0026#34;) } else if (i % 3 === 0) { console.log(\u0026#34;Fizz\u0026#34;) } else if (i % 5 === 0) { console.log(\u0026#34;Buzz\u0026#34;) } else { console.log(i) } } } fizzBuzz(16) Wouldn\u0026rsquo;t it be nice if there were some tools that could ensure that our code is formatted consistently with proper spacing and indentation, and also detect problematic code (such as unused variables or unreachable code blocks)?\nWell there are such tools and in this lesson we are going to look at one of them, the Prettier code formatter.\nPrettier does just what its name suggests, it keeps your code looking pretty 😀. In a later lesson we will look at ESLint, a tool for analyzing your source code to detect potential problems and enforce some best practices.\nWhat is Prettier? Prettier is an opinionated code formatter that can detect whether your code is following certain style rules, such as:\n proper spacing and indentation no mixing of spaces and tabs 😡 avoids long lines (lines greater than a specified max line length, typically 80 characters) by wrapping such lines adding or removing semicolons using consistent quotes (single or double) adding or removing trailing commas several others\u0026hellip;  Also, Prettier has support for:\n JavaScript TypeScript JSON JSX (React) Angular Vue HTML CSS Markdown YAML  Prettier has both a command-line interface (for batch processing of files) and a VS Code plugin.\n  With the VS Code plugin, Prettier will reformat your source code whenever you type and/or save your file.\n  This is super efficient as you don\u0026rsquo;t have to think so much about formatting as you code - Prettier does that work for you!\nWhy Code Style Matters The most important reason for using a tool like Prettier is to ensure that all source code is styled consistently.\nThis is important because inconsistencies in source code formatting causes the following problems:\n The code will be more difficult to read. Future code changes may result in many lines being changed for trivial reasons, such as adjusting spacing or indentation, which results in lots of noise introduced in Pull Requests and git history.  For example, without using a tool like Prettier:\n I may change 3 lines of code and then save my file But my editor is configured differently from yours When I save my file, my editor may introduce dozens of changes that simply change the code style.  This makes it difficult for PR reviewers to look at the changes and see what actually changed.\nThe solution is for everyone contributing to the source code to use the same formatting rules, and Prettier can help with that!\nInstalling the VS Code Prettier Plugin It\u0026rsquo;s easy to install Prettier:\n Start up VS Code Go to Extensions (the Tetris looking icon in the left navigation pane), and enter a search for Prettier.  There may be multiple search results but the first one should be the correct one. It\u0026rsquo;s title is Prettier - Code formatter.   Click the \u0026ldquo;Install\u0026rdquo; button. Set Prettier as the default formatter for VS Code:  Go to Code \u0026ndash;\u0026gt; Preferences \u0026ndash;\u0026gt; Settings and then search for default formatter. Use the dropdown to select Prettier.    Test It Out Create a new JavaScript file and type some ugly code and save it and see what happens.\n Now I challenge you to try to write some ugly code!\n Summary  Code should be formatted for best readability. Formatting should be consistent across the team (all contributors to the project source code). Tools like Prettier make it very easy to keep the code looking pretty and consistent. You now have no excuse for writing ugly code 🎉.  "
},
{
	"uri": "/javascript/foundations/eslint/",
	"title": "Static Analysis with ESLint",
	"tags": [],
	"description": "",
	"content": "An introduction to code style and static code analysis / linting.\nLearning Objectives  Explain static code analysis Configure and run eslint to discover and fix potential coding problems  What Is Static Analysis Static analysis, also called static code analysis, is the process of analyzing a computer program to find problems without actually executing the code.\n From this definition, can you guess what dynamic analysis is?\n Static analysis is done by analyzing a set of code against a set (or multiple sets) of coding rules. Often these rules can be enabled, disabled, or configured.\nStatic analysis tools can check for the following:\n no unused variables, functions, or code blocks proper variable and function naming (such as using camelCase) avoid confusing, deprecated, or undesirable language features, for example in JavaScript avoid the use of ==, var, and nested ternary expressions maintaining a maximum nesting level   NOTE: Sometimes static analysis is referred to as \u0026ldquo;linting\u0026rdquo; and a static analysis tool is sometimes called a \u0026ldquo;linter\u0026rdquo;. The idea came from removing lint (unwanted stuff) from your pocket. This is where the ESLint name comes from (the ES part coming from ECMAScript).\n Installing ESLint ESLint is an npm module that we can install either locally or globally as follows:\nGlobal installation:\nnpm install -g eslint Local installation:\nnpm install eslint --save-dev # or yarn add eslint --dev  NOTE: The ESLint docs recommend installing eslint locally.\n Creating a ESLint Config File Before creating an ESLint config file, you will need to have a package.json file:\nnpm init -y  NOTE: We will learn more about this when we learn about NodeJS.\n Now you are ready to create the config file, which is easily done with npx eslint --init:\nnpx eslint --init # or yarn run eslint --init ✔ How would you like to use ESLint? · problems ✔ What type of modules does your project use? · esm ✔ Which framework does your project use? · none ✔ Does your project use TypeScript? · No / Yes ✔ Where does your code run? · node ✔ What format do you want your config file to be in? · JSON Local ESLint installation not found. The config that you selected requires the following dependencies: eslint@latest ✔ Would you like to install them now with npm? · No / Yes Installing eslint@latest added 88 packages, and audited 89 packages in 5s 13 packages are looking for funding run `npm fund` for details found 0 vulnerabilities Successfully created .eslintrc.json file in \u0026lt;your-current-folder\u0026gt; ESLint was installed locally. We recommend using this local copy instead of your globally-installed copy. Running the above command results in a file named .eslintrc.json added to your project.\nInstalling the airbnb ESLint rules We could define a bunch of ESLint rules for our config file, but it is easier to reuse a configuration from another source, such as the AirBnB module.\nWhen using an external rule set, we can still add or override any rules as needed 😀.\nFirst, let\u0026rsquo;s install the eslint-config-airbnb module:\nnpx install-peerdeps --dev eslint-config-airbnb Then we need to edit the .eslintrc.json file and replace the line that reads\n\u0026#34;extends\u0026#34;: \u0026#34;eslint:recommended\u0026#34;, with\n\u0026#34;extends\u0026#34;: \u0026#34;airbnb\u0026#34;, Test It Out Below is the fizzbuzz.js example that is formatted well but doesn\u0026rsquo;t follow modern JavaScript best practices:\nfunction fizzBuzz(n) { let sum = 0 for (let i = 1; i \u0026lt;= n; i++) { if (i % 15 == 0) console.log(\u0026#39;FizzBuzz\u0026#39;) else if (i % 3 == 0) { console.log(\u0026#39;Fizz\u0026#39;) } else if (i % 5 == 0) { console.log(\u0026#39;Buzz\u0026#39;) } else { console.log(i) } } } fizzBuzz(16) Let\u0026rsquo;s run eslint to find the problems in this code:\nOverriding a Rule In the above report, ESLint warns that there were unexpected console statements. Often it is recommended that JavaScript code not use console directly because there may be more advanced options for logging messages. For our purposes using console is fine so we will disable this warning.\nEdit the .eslintrc.json file and add this rule:\n\u0026#34;rules\u0026#34;: { \u0026#34;no-console\u0026#34;: \u0026#34;off\u0026#34; } Now when you run eslint it will no longer warn about using console statements.\nNote that any rules that we add to the rules section of .eslintrc.json will override the rules inherited from the AirBnB rule set.\nFixing the Problems There are 3 ways to fix the problems that ESLint reports:\n You can manually fix the code, which is very valuable in learning about JS best practices. Some problems can be fixed using --fix flag: eslint --fix *.js. You can decide that the rule is not relevant and disable it, as we did above.  Summary  Static code analysis is the process of analyzing a computer program to find problems without actually executing the code. Static code analysis can detect many potential coding problems, including:  unused variables unreachable code improper variable and function naming use of deprecated or undesirable language features overly complex code structure, such as long functions or deep nesting   ESLint is the defacto standard static code analyzer for JavaScript ESLint can be configured with many rules and configurations A popular rule set is the AirBnB module  "
},
{
	"uri": "/javascript/foundations/refactoring/",
	"title": "Refactoring",
	"tags": [],
	"description": "",
	"content": "An introduction to refactoring code.\nLearning Objectives  Describe what refactoring is List the benefits of refactoring Provide examples of refactoring  What is Refactoring? Refactoring is intended to improve the design, structure, and/or implementation of the software (its non-functional attributes), while preserving its functionality.\nAdvantages of Refactored Code Readability - it is easier to understand what the cleanSpecialChars code is doing Reusability - we can call this function whenever we need this functionality Maintainability - we can modify the code in one place Testability - we have a function that we can easily test\nWhen to Refactor? There are a few concepts that help in identifying when you need to refactor, like Code Smells.\nCode is said to smell, when:\n An object refers to the internal attributes of another object (code envy) Method is too big Too many if-else conditions Duplication of code etc  Why is Readability Important? Software engineers will undoubtably read more code than they write. Making code easy to follow means understanding the purpose and intent of code faster which leads to coding faster and being more confident about making changes.\nWhat makes code more readable? . Consistent Indentation . Code Grouping . Commenting and Documentation . Meaningful Names (variables, functions, modules) . Keep it DRY . Avoid Deep Nesting (like callback hell) . Keep lines short . File and Folder Organization\nExamples of Refactoring Chunking into smaller units Some sample data to run example with:\nlet customers = [ { oid: 1, name : \u0026#34;Anna Ward\u0026#34;, prefShopMethod: \u0026#34;online\u0026#34;, state: \u0026#34;VA\u0026#34; }, { oid: 2, name : \u0026#34;Brandon Igario\u0026#34;, prefShopMethod: \u0026#34;in person\u0026#34;, state: \u0026#34;TX\u0026#34; }, { oid: 3, name : \u0026#34;Chrissy Cotton\u0026#34;, prefShopMethod: \u0026#34;mixed\u0026#34;, state: \u0026#34;GA\u0026#34; } ]; let carts = [ { oid : 312, customerOID : 2, subtotal: 46.32 }, { oid : 313, customerOID : 3, subtotal: 12.34 }, { oid : 314, customerOID : 1, subtotal: 512.10 } ]; let taxRates = { \u0026#34;VA\u0026#34; : .1, \u0026#34;TX\u0026#34; : .03, \u0026#34;GA\u0026#34; : .06 }; Original:\nfunction calculateTaxesOnCarts(){ // Database call to get all untotalled carts  // ...  // Retreive state in order to get tax rate.  carts = carts.map(cart =\u0026gt; { let customer = customers.filter( c =\u0026gt; { return c.oid == cart.customerOID; }); cart.taxRate = taxRates[customer[0].state]; return cart; }); // apply tax rate to each cart, calculate subtotal and total.  totalledCarts = carts.map(cart =\u0026gt; { cart.tax = Number(cart.taxRate * cart.subtotal).toFixed(2); cart.total = (cart.subtotal + Number(cart.tax)).toFixed(2); return cart; }) // total each cart  return totalledCarts; } Refactored:\nfunction getTaxRate(cart){ cart.taxRate = taxRates[customers.filter( c =\u0026gt; { return c.oid == cart.customerOID; })[0].state]; return cart; } function totalCart(cart){ cart.tax = Number(cart.taxRate * cart.subtotal).toFixed(2); cart.total = (cart.subtotal + Number(cart.tax)).toFixed(2); return cart; } function calculateTaxesOnCarts(){ // Database call to get all untotalled carts  // ...  return carts.map(cart =\u0026gt; getTaxRate(cart)).map(cart =\u0026gt; totalCart(cart)); } Let each function do one thing and do it well\nIn the above example we were able to break the code into three function and the main function became a one liner. Its cleaner and easier to tell what\u0026rsquo;s happening. The names of the functions are another way to define the purpose of a chunk of code.\nCode Reusability - DRY it off Original:\nfunction receiveFormData(formData){ let fname = formData.first_name.replace(/[^\\w\\s]/gi, \u0026#39;\u0026#39;); let lname = formData.last_name.replace(/[^\\w\\s]/gi, \u0026#39;\u0026#39;); } Refactored:\nfunction cleanSpecialChars(str){ let cleanStr = str.replace(/[^\\w\\s]/gi, \u0026#39;\u0026#39;); return cleanStr } function receiveFormData(formData){ let fname = cleanSpecialChars(formData.first_name); let lname = cleanSpecialChars(formData.last_name); } Now it\u0026rsquo;s apparent what the replace function is doing. Also, we have code reusability so if we need to adjust the regex, we can do it in one place instead of two or more.\nDecreasing Scope - encapsulation Original:\nvar user = {}; var name = getName(); user.name = name; // .. var name = getPageName(); routeTo(name); Refactored:\nclass User(name){ this.name = name; } user = new User(getName()); routeTo(getPageName()); The above code offers a reusable class as well as encapsulation for variables inside the class to avoid collisions.\nIncreasing readbility - functional programming Original:\nlet subtotals = [44.20, 25.60, 78.99]; let totals = []; for(let i=0; i \u0026lt; subtotals.length; i++){ totals[i] = (subtotals[i] + subtotals[i] * .05).toFixed(2); } console.log(totals); Refactored:\nlet subtotals = [44.20, 25.60, 78.99]; const taxRate = 0.05; const applyTax = (subtotals) =\u0026gt; subtotals.map( subtotal =\u0026gt; subtotal + subtotal * taxRate ); let totals = applyTax(subtotals); The refactored code above is more expressive and reusable.\nSuggested Continued Reading  Clean Code by Uncle Bob  "
},
{
	"uri": "/python/foundation/booleans/",
	"title": "Booleans",
	"tags": [],
	"description": "",
	"content": "Boolean Introduction A boolean is a data type that can be either true or false.\n  It is raining - True\n  5 is greater than 8 - False\n  Orange Academy is the best - True\n  Booleans are used to make comparisons and to control the flow of a program. Named for George Boole, the word Boolean always begins with a capitalized B. The values True and False will also always be with a capital T and F respectively, as they are special values in Python.\nYou can create variables and set them to either True or False\nis_tired = False is_available = True You can also cast a boolean values to an integer. 0 represents False and 1 represents True.\nprint(int(True)) print(int(False)) Output:\n1 0 Comparison Operators In programming, comparison operators are used to compare values and evaluate done to a single Boolean value of either True or False.\nThe table below shows Boolean comparison operators.\n   Operator What it means     == Equal to   != Not Equal to   \u0026lt; Less than   \u0026gt; Greater than   \u0026lt; = Less than or equal to   \u0026gt;= Greater than or equal to    To understand how these operators work, let\u0026rsquo;s assign two integers to two variables in a Python program:\nx = 5 y = 8 We know that in this example, since x has the value of 5, it is less than y which has the value 8.\nUsing those two variables, we will show the above operators being used.\nx = 5 y = 8 print(\u0026#34;x == y:\u0026#34;, x == y) print(\u0026#34;x != y:\u0026#34;, x != y) print(\u0026#34;x \u0026lt; y:\u0026#34;, x \u0026lt; y) print(\u0026#34;x \u0026gt; y:\u0026#34;, x \u0026gt; y) print(\u0026#34;x \u0026lt;= y:\u0026#34;, x \u0026lt;= y) print(\u0026#34;x \u0026gt;= y:\u0026#34;, x \u0026gt;= y) Output:\nx == y: False x != y: True x \u0026lt; y: True x \u0026gt; y: False x \u0026lt;= y: True x \u0026gt;= y: False Following mathematical logic, in each of the expressions above, Python has evaluated:\n  Is 5 (x) equal to 8 (y)? False\n  Is 5 not equal to 8? True\n  Is 5 less than 8? True\n  Is 5 greater than 8? False\n  Is 5 less than or equal to 8? True\n  Is 5 not less than or equal to 8? False\n  All of these comparators can work with floating point values and strings as well. Strings are case-sensitive unless you use an additional string method.\nname1 = \u0026#34;Sally\u0026#34; name2 = \u0026#34;sally\u0026#34; print(\u0026#34;Sally == sally: \u0026#34;, name1 == name2) Output: Sally == sally: False\nNote: There is a difference between the two operators = and ==.\n x = y sets (changes) the value of x to be equal to y x == y asks if the value of x equals the value of y. No values are changed.  Logical Operators There are three logical operators that are used to compare values. These operators are and, or, and not.\n|Operator|What it means|What it looks like |:\u0026ndash;:|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; |and|True if both are true|x and y |or|True if at least one is true|x or y |not|True only if false|not x\nand example\nTo join the local basketball team, you must be at least 4 foot tall and at least 16 years old. Here are all the ways you would not be able to join the team:\n  If you were at least 4 foot tall, but not at least 16 years old\n  If you were less than 4 foot and at least 16 years old\n  If you were less than 4 foot and less than 16 years old\n  The only way you would be able to join the team would be if you were both taller than 4 foot and at least 16 years old.\nor example\nSay they were not able to find enough people who fulfilled both requirements for the basketball team, so they made it to where you just have to meet one or more of the requirements. Now to join the local basketball team, you must be at least 4 foot tall or at least 16 years old. Here are now all of the ways you can join the team:\n  If you were at least 4 foot tall, but not at least 16 years old\n  If you were less than 4 foot and at least 16 years old\n  If you were at least 4 foot tall, and at least 16 years old\n  The only way you would be able to not join the team if you were neither taller than 4 foot or at least 16 years old.\nExample Uses of and, or and not\nprint((9 \u0026gt; 7) and (2 \u0026lt; 4)) ## Both expressions are True print((8 == 8) or (6 != 6)) ## One expression is True print(not(3 \u0026lt; = 1)) ## The expression is True Output:\nTrue True True In the first case:\nprint((9 \u0026gt; 7) and (2 \u0026lt; 4)) Both 9 \u0026gt; 7 and 2 \u0026lt; 4 needed to evaluate to True since the and operator was being used.\nIn the second case:\nprint((8 == 8) or (6 != 6)) Since 8 == 8 evaluated to True, it did not make a difference that 6 != 6 evaluates to False because the or operator was used. If we had used the and operator, this would evaluate to False.\nIn the third case:\nprint(not(3 \u0026lt; = 1)) The not operator negates the False value that 3 \u0026lt; = 1 returns.\nBooleans Exercises\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/frameworks/",
	"title": "CSS Frameworks",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Bootstrap History How to Bootstrap  Skills  How to install bootstrap on your project Become familiar with bootstrap documentation Build websites with ease  What is Front End Framework? Why? Until now, vanilla CSS has been used to style websites, positioning elements can become difficult and tedious very quickly.\nThankfully, other developers have experienced the same pains, and decided to craft solutions that address the issues we\u0026rsquo;ve been facing. Those solutions come in the form of front-end frameworks like Bootstrap, Zurb Foundations, and Materialize\nWhile these frameworks all work in similar fashion, we will be focusing on bootstrap. This is for 2 major reasons.\n Bootstrap is the second most starred project on GitHub and is used on a number of Home Depot projects. The bootstrap documentation has clear code samples and explanations make learning how to use bootstrap simple and straightforward.  History Bootstrap was created by Twitter employees to encourage consistency among internal tools. As the project began to grow, team members realized that many developers would benefit from this new tool, and the project was released into the open source world.\nWhat is Bootstrap Bootstrap is a css framework. When you install Bootstrap into a project, you gain access to stylesheets with pre-defined classes. By adding those classes to html elements, you will get default styling for forms, buttons, navbars, etc. You also get access to Bootstrap\u0026rsquo;s grid system and jquery extensions.\nThe Front End frameworks mentioned above are used on most web applications and websites today. Examples of sites that use bootstrap can be found at the The Bootstrap Expo.\nA few notable examples:\n mongoDB NASA webtask lyft Soma Neat  Getting Started Bootstrap Components - Download To get a basic understanding of how bootstrap works, navigate to the Collection of Examples and download the source code or simply download from Bootstrap-3.3.7.zip and unzip the files.\nBootstrap Components - viewing the source Open your terminal and navigate to the extracted bootstrap files. Then navigate to the docs/examples/ directory and open up the files.\n$ cd PATH_TO_FILE/docs/examples $ code . Bootstrap Components - Grid Find the grid directory and open the index.html file.\nHere you will see some markup that looks like this:\n\u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;page-header\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Bootstrap grid examples\u0026lt;/h1\u0026gt; \u0026lt;p class=\u0026#34;lead\u0026#34;\u0026gt;Basic grid layouts to get you familiar with building within the Bootstrap grid system.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;h3\u0026gt;Three equal columns\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;Get three equal-width columns \u0026lt;strong\u0026gt;starting at desktops and scaling to large desktops\u0026lt;/strong\u0026gt;. On mobile devices, tablets and below, the columns will automatically stack.\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-md-4\u0026#34;\u0026gt;.col-md-4\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-md-4\u0026#34;\u0026gt;.col-md-4\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-md-4\u0026#34;\u0026gt;.col-md-4\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;h3\u0026gt;Three unequal columns\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;Get three columns \u0026lt;strong\u0026gt;starting at desktops and scaling to large desktops\u0026lt;/strong\u0026gt; of various widths. Remember, grid columns should add up to twelve for a single horizontal block. More than that, and columns start stacking no matter the viewport.\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-md-3\u0026#34;\u0026gt;.col-md-3\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-md-6\u0026#34;\u0026gt;.col-md-6\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-md-3\u0026#34;\u0026gt;.col-md-3\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;h3\u0026gt;Two columns\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;Get two columns \u0026lt;strong\u0026gt;starting at desktops and scaling to large desktops\u0026lt;/strong\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-md-8\u0026#34;\u0026gt;.col-md-8\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-md-4\u0026#34;\u0026gt;.col-md-4\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;h3\u0026gt;Full width, single column\u0026lt;/h3\u0026gt; \u0026lt;p class=\u0026#34;text-warning\u0026#34;\u0026gt;No grid classes are necessary for full-width elements.\u0026lt;/p\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;h3\u0026gt;Two columns with two nested columns\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;Per the documentation, nesting is easy—just put a row of columns within an existing column. This gives you two columns \u0026lt;strong\u0026gt;starting at desktops and scaling to large desktops\u0026lt;/strong\u0026gt;, with another two (equal widths) within the larger column.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;At mobile device sizes, tablets and down, these columns and their nested columns will stack.\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-md-8\u0026#34;\u0026gt; .col-md-8 \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-md-6\u0026#34;\u0026gt;.col-md-6\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-md-6\u0026#34;\u0026gt;.col-md-6\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-md-4\u0026#34;\u0026gt;.col-md-4\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;h3\u0026gt;Mixed: mobile and desktop\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;The Bootstrap 3 grid system has four tiers of classes: xs (phones), sm (tablets), md (desktops), and lg (larger desktops). You can use nearly any combination of these classes to create more dynamic and flexible layouts.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Each tier of classes scales up, meaning if you plan on setting the same widths for xs and sm, you only need to specify xs.\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-xs-12 col-md-8\u0026#34;\u0026gt;.col-xs-12 .col-md-8\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-md-4\u0026#34;\u0026gt;.col-xs-6 .col-md-4\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-md-4\u0026#34;\u0026gt;.col-xs-6 .col-md-4\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-md-4\u0026#34;\u0026gt;.col-xs-6 .col-md-4\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-md-4\u0026#34;\u0026gt;.col-xs-6 .col-md-4\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6\u0026#34;\u0026gt;.col-xs-6\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6\u0026#34;\u0026gt;.col-xs-6\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;h3\u0026gt;Mixed: mobile, tablet, and desktop\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-xs-12 col-sm-6 col-lg-8\u0026#34;\u0026gt;.col-xs-12 .col-sm-6 .col-lg-8\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-lg-4\u0026#34;\u0026gt;.col-xs-6 .col-lg-4\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-sm-4\u0026#34;\u0026gt;.col-xs-6 .col-sm-4\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-sm-4\u0026#34;\u0026gt;.col-xs-6 .col-sm-4\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-sm-4\u0026#34;\u0026gt;.col-xs-6 .col-sm-4\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;h3\u0026gt;Column clearing\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;http://getbootstrap.com/css/#grid-responsive-resets\u0026#34;\u0026gt;Clear floats\u0026lt;/a\u0026gt; at specific breakpoints to prevent awkward wrapping with uneven content.\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-sm-3\u0026#34;\u0026gt; .col-xs-6 .col-sm-3 \u0026lt;br\u0026gt; Resize your viewport or check it out on your phone for an example. \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-sm-3\u0026#34;\u0026gt;.col-xs-6 .col-sm-3\u0026lt;/div\u0026gt; \u0026lt;!-- Add the extra clearfix for only the required viewport --\u0026gt; \u0026lt;div class=\u0026#34;clearfix visible-xs\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-sm-3\u0026#34;\u0026gt;.col-xs-6 .col-sm-3\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-sm-3\u0026#34;\u0026gt;.col-xs-6 .col-sm-3\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;h3\u0026gt;Offset, push, and pull resets\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;Reset offsets, pushes, and pulls at specific breakpoints.\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-sm-5 col-md-6\u0026#34;\u0026gt;.col-sm-5 .col-md-6\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-sm-5 col-sm-offset-2 col-md-6 col-md-offset-0\u0026#34;\u0026gt;.col-sm-5 .col-sm-offset-2 .col-md-6 .col-md-offset-0\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-sm-6 col-md-5 col-lg-6\u0026#34;\u0026gt;.col-sm-6 .col-md-5 .col-lg-6\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-sm-6 col-md-5 col-md-offset-2 col-lg-6 col-lg-offset-0\u0026#34;\u0026gt;.col-sm-6 .col-md-5 .col-md-offset-2 .col-lg-6 .col-lg-offset-0\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- /container --\u0026gt; \u0026lt;/body\u0026gt; This code could seem a bit overwhelming, don\u0026rsquo;t worry, it will make sense shortly. Let\u0026rsquo;s step through it together.\nThis index.html page can be opened in the browser by running $ open grid/index.html which should result in a page with content similar to this:\nLet\u0026rsquo;s focus on this particular block of code:\n\u0026lt;h3\u0026gt;Mixed: mobile and desktop\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;The Bootstrap 3 grid system has four tiers of classes: xs (phones), sm (tablets), md (desktops), and lg (larger desktops). You can use nearly any combination of these classes to create more dynamic and flexible layouts.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Each tier of classes scales up, meaning if you plan on setting the same widths for xs and sm, you only need to specify xs.\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;!-- 1 --\u0026gt; \u0026lt;div class=\u0026#34;col-xs-12 col-md-8\u0026#34;\u0026gt;.col-xs-12 .col-md-8\u0026lt;/div\u0026gt; \u0026lt;!-- 2 --\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-md-4\u0026#34;\u0026gt;.col-xs-6 .col-md-4\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-md-4\u0026#34;\u0026gt;.col-xs-6 .col-md-4\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-md-4\u0026#34;\u0026gt;.col-xs-6 .col-md-4\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6 col-md-4\u0026#34;\u0026gt;.col-xs-6 .col-md-4\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6\u0026#34;\u0026gt;.col-xs-6\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-xs-6\u0026#34;\u0026gt;.col-xs-6\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; You\u0026rsquo;ll see that our columns are wrapped in divs with the class of row.\n The grid system (built into bootstrap) is expecting us to define a row that will contain our columns. We then assign the desired column sizes for each individual div.  To get a better understanding of how the Bootstrap grid works, lets take a look at the Grid Documentation\nThe major takeaways are:\n Rows are used to create horizontal groups of columns. Content should be placed within columns, and only columns may be immediate children of rows. Predefined grid classes like .row and .col-xs-4 are available for quickly making grid layouts. Grid columns are created by specifying the number of twelve available columns you wish to span. For example, three equal columns would use three .col-xs-4.  One other item of note is gutters. Each column in the grid will have a gutter between itself and the next column\nAccording to the docs:\n Columns create gutters (gaps between column content) via padding. That padding is offset in rows for the first and last column via negative margin on .rows.\n We can now navigate back to the example on our local machine or use the bootstrap docs to review the code, as well as the effect.\nIn the first column you\u0026rsquo;ll see the classes .col-xs-12 and .col-md-8. By default the grid is 12 equally spaced columns. We can then define a size (based on viewport) and column span\nBootstrap 3 supports 4 sizes\n xs - Extra small devices with a screen resolution under 768 pixels, such as Phones sm - Small devices with a screen resolution between 768px - 991px, such as Tablets and larger smartphones. md - Medium devices with a screen resolution between 992px - 1199px - such as laptops. lg - Large Devices with a screen resolution above 1200px - such as Desktop monitors.   Bootstrap 4 will introduce an additional size for enhanced precision\n The column span determines (as you would expect) how many columns the div will cover.\nTry resizing the screen to see how the columns respond.\nAdditionally, this Bootstrap Grid Extension gives you an overlay of the grid system.\nBootstrap is using media queries to accomplish this responsive grid. All we have to do is simply use the appropriate class names and we get access to those pre-written media queries.\nIn fact, we can use this same methodology throughout our applications for all of our html elements (forms, buttons, etc.). It really is as easy as applying class names!\n   Go to Frameworks Lab    "
},
{
	"uri": "/java/foundations/data-structures/",
	"title": "Data Structures",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts \u0026amp; Skills Creating and using:\n Arrays Lists: Array Maps: Hash   Data Structures are collections of associated data. There are quite a few data structures that are available that will be described in the following sections.\nLike all other variables in Java, data structures are strongly typed. This means you need to define what type of data can be stored within the structure.\nOrdered Collections Ordered collections keep data in a specific order, allowing individual elements of data have a specific \u0026ldquo;spot\u0026rdquo; in the data structure. As an ordered sequence of elements, each item in an ordered data structure can be called individually, through indexing.\nEach item in an ordered data structure corresponds to an index number, which is an integer value, starting with the index number 0.\nFor a data structure that stores Strings of tool names, the index breakdown looks like this:\n   Index Value     0 Hammer   1 Screwdriver   2 Wrench   3 Saw    The first item, the string Hammer starts at index 0, and the list ends at index 3 with the string Saw.\nEach element has a corresponding index number so we\u0026rsquo;re able to access and manipulate the data structures.\nArrays Arrays are Java\u0026rsquo;s only primitive data structures.\nDeclaration of a variable, tools, that stores an array of Strings looks like:\nString[] tools; You declare that a variable is going to be an array because of the [] after the data type.\nInitializing the above tools array looks like:\ntools = new String[5]; Unlike any other variables, you have to specify the length of the array in initialization. This length cannot be changed.\ntools content\n   Index Value     0 null   1 null   2 null   3 null   4 null    The above example initializes each element to the data type\u0026rsquo;s default value.\n Question\nWhat is the default value for:\n double? boolean? Object?   It is possible to declare and initialize an array with known values, like:\nString tools = {\u0026#34;Hammer\u0026#34;, \u0026#34;Screwdriver\u0026#34;, \u0026#34;Axe\u0026#34;}; tools content\n   Index Value     0 Hammer   1 Screwdriver   2 Axe     Like other variables, it is possible to initialize and declare an array on the same line:\nint[] numbers = new int[10]; // Creates an array of 10 integers  Question\nWhy must we declare a constant length of an array?\n Since our arrays are primitive, it has a designated space in memory that cannot altered and must be filled. This means that when instantiated an array it must declare its length. Once instantiated, every element in the array is given the default value for its declared data type.\nLength The length property is used to get the number of elements that are in an array.\nint y = tools.length; Setting You probably do not want just an array of all default values. In order to make your array meaningful, you will need to assign new values to each element.\ntools[1] = \u0026#34;Jig\u0026#34;; The above example alters the element at index 1 (the second element) to the value of \u0026ldquo;Jig\u0026rdquo;.\ntools new content\n   Index Value     0 null   1 Jig   2 null   3 null   4 null    Getting It is possible to access the value at a specific index in an array.\nString favoriteTool = tools[2]; The above example gets the value that is stored at index 2 (the third element) in the tools array.\nIterating To iterate over the array with a for loop.\nThe following iterates through every element in tools with a basic for loop and prints them out:\nfor (int i = 0; i \u0026lt; tools.length; i++){ System.out.println(tools[i]); } Foreach Loop\nA foreach loops over a collection (e.g. Lists, arrays, etc). For instance, to iterate through every element in tools with a foreach loop and prints them out:\nfor (String tool : tools){ System.out.println(tool); } Within the parenthesis of the for loop, the syntax is: (type var : collection). var is the name for the current element, this can be any valid variable name.\nArrayLists A List meets a similar need that an array does. Since it is not primitive, it has the opportunity to define behavior such as adjusting its size and defining relationships between elements.\nAn ArrayList is a resizable-array implementation of the List interface (We will get to what an interface is later on).\nTo use ArrayLists, you must import java.util.ArrayList.\nTo declare an ArrayList, you first need to say ArrayList followed by what non-primitive type is going to be stored, surrounded by angle brackets.\nArrayList\u0026lt;String\u0026gt; paintColors; In order to store any primitive type in an ArrayList, we must use the corresponding wrapper class in the ArrayList. For example: to store the equivalent of int, use Integer. This is due to the fact ArrayLists only take non-primitives.\npaintColors = new ArrayList\u0026lt;\u0026gt;(); The type the initialization is implied because it was declared during declaration. This is why the angle brackets are empty in the above example.\nThe parenthesis are invoking ArrayList\u0026rsquo;s default constructor which returns the actual instance of an ArrayList. When using the default constructor, an ArrayList has zero values within it.\nLength The size method is used to get the number of elements that are in an ArrayList.\nint y = paintColors.size(); Adding Different than an array, you are able to change the size of an ArrayList.\nSay paintColors had the following values:\n   Index Value     0 red   1 green   2 blue   3 yellow   4 black    Adding to the end of paintColors looks like:\npaintColors.add(\u0026#34;maroon\u0026#34;); This adds 1 the length of an ArrayList, and inserts the value of \u0026ldquo;maroon\u0026rdquo; in the last index of the ArrayList. This would change paintColors to look like:\n   Index Value     0 red   1 green   2 blue   3 yellow   4 black   5 maroon     Inserting an element at a specified index (in this case, index 1) looks like:\npaintColors.add(1, \u0026#34;HD orange\u0026#34;); This would change paintColors to look like:\n   Index Value     0 red   1 HD orange   2 green   3 blue   4 yellow   5 black   6 maroon    Notice that none of the values with index 1 or greater were deleted, just \u0026ldquo;scooted\u0026rdquo; up 1 index.\nRemoving Say paintColors has the following values:\n   Index Value     0 red   1 HD orange   2 green   3 blue   4 yellow   5 black   6 maroon    Removing an element at a specified index (in this case, index 2) looks like:\npaintColors.remove(2); This subtracts 1 the length of an ArrayList. This would change paintColors to look like:\n   Index Value     0 red   1 HD orange   2 blue   3 yellow   4 black   5 maroon     Removing an element with a specified value (in this case, yellow) looks like:\npaintColors.remove(\u0026#34;yellow\u0026#34;); paintColors now looks like:\n   Index Value     0 red   1 HD orange   2 blue   3 black   4 maroon    If the ArrayList does not contain the element, an error does not occur and it remains unchanged.\nSetting paintColors.set(1, \u0026#34;gold\u0026#34;); The above example alters the element at index 1 (the second element) to the value of \u0026ldquo;gold\u0026rdquo;.\nGetting The get(index) is used to access the value that is stored at index 2 (the third element) in the paintColors ArrayList:\nString x = paintColors.get(2); The indexOf method returns the index of the first occurrence of a specified element:\nint x = paintColors.indexOf(\u0026#34;maroon\u0026#34;); Iterating Iterating through an ArrayList is very similar to iterating through an array:\nThe following iterates through every element in numbers with a basic for loop and prints them out:\nfor (int i = 0; i \u0026lt; paintColors.size(); i++){ System.out.println(paintColors.get(i)); } Foreach Loop\nTo iterate through every element in numbers with a foreach loop and prints them out:\nfor (String color : paintColors){ System.out.println(color); } Unordered Data Structure While many of the most common collections involve indexing elements for reference, there are several useful data structures that do not. The following structures either do not utilize indexes or you do not use the index of an item to get and set it.\nHashMap If you want to look up a meaning of a word, you use a dictionary. Whether it is online or a book, you look up the word and the definition is returned! In this example, you could think of the word as a key and the definition as the value that is returned. Anything that implements the Map interface represents a mapping between a key and a value, just like in a \u0026ldquo;regular\u0026rdquo; dictionary!\nKeys in a map must be unique. Every key can map to at most one value.\nHashMaps are a hash table based implementation of the Map interface. This implementation provides all of the optional Map operations, and permits null values and the null key. This class makes no guarantees as to the order of the Map.\nTo use HashMaps, you must import java.util.HashMap.\nWhile HashMap doesn’t allow duplicate keys but allows duplicate values. That means a single key can’t contain more than 1 value but more than 1 key can contain a single value.\nHashMap\u0026lt;String, Integer\u0026gt; salaries; To declare a HashMap, you first need to say HashMap followed by what non-primitive type is going to be stored for both the key and the value, surrounded by angle brackets.\nsalaries = new HashMap\u0026lt;\u0026gt;(); The type the initialization is implied because it was declared during declaration. This is why the angle brackets are empty in the above example.\nTwo properties of HashMap to be aware of:\n Initial Capacity: This is the number of elements that a HashMap can contain. The default capacity is 16. Load factor: This is the threshold of the HashMap, saying \u0026ldquo;Once I hit this percentage of the current capacity, I need to resize to double the current capacity.\u0026rdquo; The default load factor is 0.75.  The parenthesis are invoking HashMap\u0026rsquo;s default constructor which returns the actual instance of a HashMap with the default values for the intial capacity and load factor. When using the default constructor, a HashMap has zero values within it.\nAdding You are able to change the size of an HashMap.\nSay salaries had the following values:\n   Key Value     Sally 15000   Susie 85000   Sean 50000   Cher 1000000    Adding a key/value pair to a HashMap looks like:\nsalaries.put(\u0026#34;Stacy\u0026#34;, 47500); This adds 1 the length of an HashMap, and inserts a key Stacy with the value of 47500 in the HashMap. This would change salaries to look like:\n   Key Value     Sally 15000   Susie 85000   Stacy 47500   Sean 50000   Cher 1000000     Remember the order of a HashMap is NOT guaranteed!\n Removing Say salaries has the following values:\n   Key Value     Sally 15000   Susie 85000   Stacy 47500   Sean 50000   Cher 1000000    Removing the pair with the key Sean from salaries looks like:\nsalaries.remove(\u0026#34;Sean\u0026#34;); This subtracts 1 the length of the HashMap. This would change salaries to look like:\n   Key Value     Sally 15000   Susie 85000   Stacy 47500   Cher 1000000     Removing an element a with a specific key and value (in this case: Susie and 85000) looks like:\nsalaries.remove(\u0026#34;Susie\u0026#34;, 85000); salaries would look like:\n   Key Value     Sally 15000   Stacy 47500   Cher 1000000    If the HashMap does not contain the element, an error does not occur and it remains unchanged.\nSetting Altering the value that is paired with a specified key (in this case: Susie) to a specified value (in this case: 30000), looks like:\nsalaries.replace(\u0026#34;Susie\u0026#34;, 30000); If the key Susie does not already exist, nothing happens.\nGetting Accessing the value that is paired with a specific key (in this case: Sally), looks like:\nInteger x = salaries.get(\u0026#34;Sally\u0026#34;); If the key Sally does not exist, the default value for the value\u0026rsquo;s data type is returned.\nLength Getting a HashMap\u0026rsquo;s length, the number of pairs that are in the HashMap, looks like:\nint y = salaries.size(); Iterating As mentioned before, HashMap key/value pairs are not in adjacent memory addresses. So to iterate through a HashMap is different than iterating through an array or ArrayList.\nYou would not use a basic for loop to iterate, just a foreach loop.\nThe entrySet method will help generate a Set, another interface in the java.util package. This Set is made out of the same elements contained in the HashMap.\nIterating through the salaries HashMap, looks like:\nfor (Map.Entry\u0026lt;String, Integer\u0026gt; entry : salaries.entrySet()) { String key = entry.getKey(); Integer value = entry.getValue(); System.out.println(\u0026#34;Key : \u0026#34; + key + \u0026#34; Value : \u0026#34; + value); } The data type in front of key and value should match the key and value's data type.\nSummary Java has many options when it comes to storing and organizing data. A primitive Array is great for small sets of data with known limits (you know exactly how many data points you need) but there are many more flexible options. Some common collections have a broad use case like an ArrayList which is simply an array with adjustable limits or a Map that will track key-value pairs. It\u0026rsquo;s important to understand what your needs are in order to know what structure best solves your problem.\n"
},
{
	"uri": "/software-eng-essentials/git-foundations/workflow/",
	"title": "Git Workflow",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Discuss strategies for handling workflow Demonstrate GitHub flow Showcase GitHub\u0026rsquo;s Code Review options  Skills  Use GitHub Flow to tighten up your team\u0026rsquo;s development cycles Conduct collaborative code reviews    Managing your workflow with GitHub Now that you\u0026rsquo;ve mastered git and GitHub, it\u0026rsquo;s time to discuss workflow strategies. A simple strategy and plan of action can go a long way to avoiding problems for you and your team.\nThe two most popular approaches are git-flow and GitHub-Flow. In this lesson we\u0026rsquo;ll be focusing on GitHub Flow due to it\u0026rsquo;s simplicity and benefits.\nPlease note that git-flow is a great alternative for certain types of projects, check out the additional resources section to learn more about it.\nGitHub Flow The GitHub Flow strategy is used by development teams of all size for managing software development cycles.\nGitHub flow has a handful of core principles.\n Anything in the master branch is deployable Create descriptive branches off of master (ie: user-authentication) Commit to that branch locally and regularly push your work to the same branch on GitHub When you need feedback, help, or think the branch is ready for merging, open a pull request  We\u0026rsquo;ll explore these concepts in depth by reviewing the GitHub Guides as a group and then walking through live examples.\nGolden rule of rebasing It is super important to know when not to rebase. If you merge your local master branch with the remote master branch, git will see that your branch is ahead of the master branch (because rebase puts those commits on the base tip of your branch, essentially re-ordering the commits).\nThe only way to then synchronize your branch with the master branch will be to merge, which will add a merge commit and two sets of commits that contain the same changes!\n  Feature Branches When we\u0026rsquo;re starting a project, we want to make separate feature branches for each feature. In order to utilize rebasing, each developer needs to be using this paradigm.\n  Local cleanup Performing interactive rebases periodically throughout development, will make it easy to ensure the project history has one clean, concise commit message per feature or bug fix. Interactive rebasing only affects local branches, so you don\u0026rsquo;t have to worry about overwriting anything on the remote repository.\nThis only works with feature branches that have not been pushed up to the remote repo. Otherwise, you shouldn\u0026rsquo;t re-write its history.\n Note: there is not a merge alternative for cleaning up local commits.\n Incorporating upstream changes into a feature To incorporate another developers changes onto your branch, this is for you:   A merge with John\u0026rsquo;s branch in this example will result in a extra merge commit while a rebase will replay John\u0026rsquo;s changes on the tip of your branches history.\n  This particular way of rebasing doesn\u0026rsquo;t violate any rules of rebasing. Only your feature commits on your local branch are being moved, and everything before that isn\u0026rsquo;t changed. That\u0026rsquo;s why this can be a cleaner option than adding a merge commit to your projects history.\nReviewing a PR Once you push your changes to a remote repository your branch is public. This means you should not use rebase. Other developers may be pulling down that branch to view your changes, and if other developers need to add anything it\u0026rsquo;s better to use merge in this scenario.\nAlways remember to clean up your commits before pushing to GitHub or another remote git repository where other developers will have access to your branch.\nIntegrating an approved feature Performing a rebase before merging new features will assure that the merge will be \u0026ldquo;fast forwarded\u0026rdquo; which results in a linear commit history! It also gives you the opportunity to squash any additional commits that might be made during a pull request.\n  To practice rebase and not screw anything up you can always make a new branch off of your local feature branch and practice there. If you do screw it up, you can delete that branch and re-start from your original feature branch.\nHere is an example of that workflow:\ngit checkout local-feature-branch git checkout -b temporary-branch git rebase -i master // This is where your text editor will open and you make // the squash/rebase decisions, save and exit git checkout master git merge temporary-branch Squashing Cleaning up your branches commit history is sometimes critical to be able to read the overall projects history more easily.\nIf you\u0026rsquo;ve fixed a simple bug, you don\u0026rsquo;t want to mess up your projects commit history with 10 different commits. Clean it up with a squash!\nIn the instance that you\u0026rsquo;ve already committed and pushed commits to GitHub, we can squash them as usual but in order to update your remote, you must force a push.\nRun the following:\ngit push origin +master\nThis isn\u0026rsquo;t GRAS (Generally Recognized As Safe) because forcing a push to the master branch means you\u0026rsquo;re over writing the remote repository which could contain changes another team member has pushed since you last updated your local branch!\nAdditional Resources Check out these additional resources for more info on Git Workflow options.\n Git Branching Strategies - GitHub Flow Branching Workflow Git-Flow and GitHub Flow A Git Workflow for Continuous Delivery Using Pivotal Tracker and GitHub Flow Using GitHub for Collaborative Journalism Understanding the GitHub Flow  "
},
{
	"uri": "/javascript/foundations/labs/higher-order-functions-lab/",
	"title": "Higher Order Functions Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch higher-order-functions.js Add the following code to higher-order-functions.js:\nfunction count(arr, callback) { // TODO: calculate and return the number of values in arr  // that when passed to the callback function, evaluate to `true`. } const numbers = [1, 2, -3, 4, 5, -6, 7, 8]; const evens = count(numbers, n =\u0026gt; n % 2 === 0); console.log(\u0026#39;evens:\u0026#39;, evens); const negatives = count(numbers, n =\u0026gt; n \u0026lt; 0); console.log(\u0026#39;negatives:\u0026#39;, negatives); const fruit = [\u0026#39;apple\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;apple\u0026#39;, \u0026#39;banana\u0026#39;, \u0026#39;kiwi\u0026#39;, \u0026#39;apple\u0026#39;]; const apples = count(fruit, f =\u0026gt; f === \u0026#39;apple\u0026#39;); console.log(\u0026#39;apples:\u0026#39;, apples); Step 2: Complete the code and test Complete the TODO in the above code.\nTest your solution with:\nnode higher-order-functions.js The expected output is:\nevens: 4 negatives: 2 apples: 3 "
},
{
	"uri": "/golang/foundations/interfaces/",
	"title": "Interfaces",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Understanding Interfaces in Go Creating an Interface Implementing an interface  Interfaces in Go Interfaces in go:\n Are a type. Are a collection of method prototypes (signatures) Enables polymorphism in go. Increases reusability, flexibility, and testability of your code  Creating an Interface Creation of an interface is similar to creation of a struct.\nSyntax:\ntype \u0026lt;name\u0026gt; interface{} type MyInterface interface{ //Method signatures here } Define Methods of an Interface type Logger interface{ Write(string) WriteList([]string) int } The interface is defined:\n There is no func Add the name of the method and any parameter or return types You cannot directly invoke anything inside of an interface The interface definition is a contract  Using an Interface as a Variable Type func main() { fmt.Println(\u0026#34;Errors are values.\u0026#34;) } type Logger interface { Write(string) WriteList([]string) int } func MyFunc(l Logger) { l.Write(\u0026#34;hi\u0026#34;) x := l.WriteList([]string{\u0026#34;hi\u0026#34;, \u0026#34;low\u0026#34;, \u0026#34;werld\u0026#34;}) fmt.Println(x) } Try Me\n Notice MyFunc definition has a signature with Logger interface defined as a parameter This allows for any type to get passed to it as long as it satisfies the contract aka: the methods defined in the interface  Implementing Interfaces  Implementations are also known as concrete types Types that satisfy the interface can be part of any package Like any other named types, the implemented type cannot share the same name as the interface in the same package Types that implement methods of an interface may have additional methods defined that are not defined in the interface Only methods defined in the interface will be accessible from within the scope of the named interface variable  Basic Implementation  Step 1: Creating an interface using an empty struct:  type Logger interface {\t// 1 \tWrite(string) WriteList([]string) int } type LogLogger struct{} func (ll LogLogger) Write(event string) { // 2 \tlog.Println(event) } func (ll LogLogger) WriteList(events []string) int { // 3 \tfor _, v := range events { log.Println(event) } return len(events) }  Define a struct called LogLogger Define a method on LogLogger that matches the Logger interface signature Write Define another method on LogLogger that matches the Logger interface signature for WriteList   Step 2: Create an instance of the LogLogger struct and pass it to MyFunc  func main() { loglogger := LogLogger{} MyFunc(loglogger) } Try Me\nLab: Creating An Interface Setup  Follow the instructions in the readme for the go foundations labs cd \u0026lt;your workspace\u0026gt;/go-found-labs/interfaces/lab1/ Open interfaces.go and complete the instructions below.  Multiple Implementations of a Single Interface  Implementations may have different behavior Allows dependencies to be mocked  Defining a Second Implementation:\ntype FmtLogger struct{} func (fl FmtLogger) Write(event string) { fmt.Println(\u0026#34;Much better event logging: \u0026#34;, event) } func (fl FmtLogger) WriteList(events []string) (x int) { x=0 for _, event := range events { fl.Write(event) x++ } return } **Using Both Implementations:** func main() { loglogger := LogLogger{} MyFunc(loglogger) fmtlogger := FmtLogger{} MyFunc(fmtlogger) } Try Me\n What is different about this implementation? What other opportunities do we gain by exposing this interface?  Interfaces in Structure Fields type StructWithLogger struct { //Logger name can be anything \t// Some languages this would cause conflict. \tLogger Logger } func main() { loglogger := LogLogger{} swl := StructWithLogger{Logger: loglogger} swl.MyFunc() } Try Me\n The new struct that accepts a logger interface Changed MyFunc to be a method on the new struct StructWithLogger Construct an instance of StructWithLogger with a LogLogger implementation of the Logger interface  Quick Exercise  Try Applying the FmtLogger implementation to the struct above. Try implementing your own Logger Create your own struct that accepts Logger in a field or method argument.  Implementations with Pointer Receivers type LogLogger struct { Events int } func (ll *LogLogger) Write(event string) { fmt.Println(\u0026#34;Much better event logging: \u0026#34;, event, ll) ll.Events++ } func (ll *LogLogger) WriteList(events []string) int { for _, event := range events { ll.Write(event) ll.Events++ } return ll.Events } Try Me\n What happens when you pass the above implementation to StructWithLogger? Try creating your own custom type that implements the Logger interface.  Lab: Creating an Interface Implementation Setup  Follow the instructions in the readme for the go foundations labs cd \u0026lt;your workspace\u0026gt;/go-found-labs/interfaces/lab2/ Open movingtruck.go and complete the instructions below.  The Empty Interface  Represented as interface{} Will accept any variable type Sacrifices Compile-Time Type Safety  How Does This work?\nfmt.Println(1,\u0026#34;hi\u0026#34;,3.4,[]int{2,3,4}) func Println(a ...interface{}) (n int, err error)  fmt.Println() is a variadic function. It takes any number of arguments of the interface{} type Because of interface{}, the functions is able to accept a mix of arguments of any type.  Using the Empty Interface Here is a simple example of interface{} allowing any type of value.\nfunc main() { var i interface{} i = 1 fmt.Println(i) i = \u0026#34;interfaces rock!\u0026#34; fmt.Println(i) i = false fmt.Println(i) } Try Me\nType Assertions When using interface{} you can do run-time type assertions to determine the type you are working with:\nfunc main() { Printf(\u0026#34;Stuff\u0026#34;, true) } func Printf(format string, a interface{}) { t, ok := a.(bool) fmt.Println(\u0026#34;We were passed a bool?\u0026#34;, t, ok) } Try Me\nSwitch and Type Assertions If we want to take more action based on the actual type of interface{}, we are going to do multiple assertions. A clean way of doing this is using a switch statement.\nfunc main() { Printf(\u0026#34;Stuff\u0026#34;, 1) } func Printf(format string, a interface{}) { switch v := a.(type) { case string: fmt.Println(\u0026#34;A ia a string!\u0026#34;, v) case int: fmt.Println(\u0026#34;A is an int. I can add +1 to it: \u0026#34;, v+1) case bool: fmt.Println(\u0026#34;A is a bool:\u0026#34;, v) default: fmt.Println(\u0026#34;Too lazy to determine any other types, but here is what was passed: \u0026#34;, v) } } Try Me\n Passing the type key word will return the type of the interface, and give us the value (v) We can select the case of a.(type) by using case \u0026lt;type\u0026gt;: for the type we want to check for.  "
},
{
	"uri": "/react/foundations/side-effects/",
	"title": "Managing Side Effects",
	"tags": [],
	"description": "",
	"content": "Managing Side Effects in React Components.\nObjectives  Explain side effects Apply the useEffect hook to manage side effects in a React component.  Introduction  Side effects are basically anything that affects something outside of the scope of the current function or component. Some examples are:  calling a server to modify a database calling a server to update a file updating the browser\u0026rsquo;s local storage   You can think of side effects as changes to the environment.  Background  Before React Hooks, any Components that performed side-effects had to be written as a JavaScript class. The class could define side-effects via the lifecycle methods. The lifecycle methods are:  componentDidMount - executed just after a component is first mounted (loaded into the DOM) componentWillUpdate - executed just before a component is updated (re-rendered) componentWillUnmount - executed just before a component is unmounted (removed from the DOM)   These lifecycle methods provided a place to put any side-effect code.  The useEffect Hook  The useEffect hook lets you perform side effects in function components (no need for writing a JavaScript class). The useEffect hook replaces the componentDidMount, componentWillUpdate and componentWillUnmount methods.  How useEffect Works You can configure the useEffect hook to run some code automatically in one of 3 scenarios.\n When the component is rendered for the first time only When the component is rendered for the first time and whenever it re-renders When the component is rendered for the first time and whenever it re-renders due to a specific change to data (prop or state).  The useEffect hook takes two arguments:\n A function containing our side-effect code An array specifying when that function should be executed (one of the 3 scenarios above)  The array always going to be:\n An empty array No array at all (thus an undefined value for the array) An array with one or more elements inside of it  To summarize:\nuseEffect Structure:\nimport React, { useState, useEffect } from \u0026#39;react\u0026#39;; function MyComponent(props) { ... useEffect(() =\u0026gt; { // perform side-effects here and  // optionally return a clean-up function  }, [ /* watch list */ ]) // an array of variables to watch  ... return ( // JSX goes here  ) } export default MyComponent  Example: A Counter Component:\nThe following Counter component uses the useEffect hook to save the count to the browser\u0026rsquo;s local storage.\nimport React, { useState, useEffect } from \u0026#39;react\u0026#39;; function Counter() { // TIP: We use a function for `initialCount` so that it is only executed once.  const initialCount = () =\u0026gt; Number(window.localStorage.getItem(\u0026#39;count\u0026#39;)) const [count, setCount] = useState(initialCount) const increment = () =\u0026gt; setCount(count + 1) // useEffect will keep the localStorage up to date whenever the `count` value changes  useEffect(() =\u0026gt; { window.localStorage.setItem(\u0026#39;count\u0026#39;, count) }, [count]) return ( \u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;Counter with Local Storage\u0026lt;/h2\u0026gt; \u0026lt;button onClick={increment}\u0026gt;{count}\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; ) } export default Counter  In the above example, the browser\u0026rsquo;s local storage is updated with every update to the count state variable. This is a side-effect because the code modifies something outside of the Component function.   TIP: Pay careful attention to the 2nd argument:\n Be careful to use the 2nd argument (the dependency list) correctly. Incorrect usage can result in subtle bugs or performance problems.\n NOTE: you may never find a reason to omit the 2nd argument (so far I haven\u0026rsquo;t).\n Returning a Cleanup Function  The function passed to useEffect can return a function. The returned function is executed just before the component unmounts. It can be used to cleanup any resources to avoid resource / memory leaks.  Some Examples Fetching Data From Server  The most common use for useEffect is fetching data from a server. We want to fetch the data and then update the component\u0026rsquo;s state so that the component is re-rendered with the fetched data. Note that the component will be rendered first without the data and then again after the data is returned.  fetch\nconst ProductBrowser = props =\u0026gt; { const [products, setProducts] = useState([]) useEffect(() =\u0026gt; { fetch(apiUrl) .then(response =\u0026gt; { if (response.ok) { return response.json() } else { return response.text().then(err =\u0026gt; Promise.reject(err)) // reject error text  } }) .then(data =\u0026gt; { // fetch data from server  setProducts(data) // then update state  }).catch(error =\u0026gt; { toastr.error(error) }) }, []) // empty braces means execute after first render  return ( // JSX goes here  ) } axios\nconst ProductBrowser = props =\u0026gt; { const [products, setProducts] = useState([]) useEffect(() =\u0026gt; { axios.get(apiUrl).then(response =\u0026gt; { // fetch data from server  setProducts(response.data) // then update state  }).catch(error =\u0026gt; { toastr.error(error) }) }, []) // empty braces means execute after first render  return ( // JSX goes here  ) } Fetching Data From Server - async/await Version Note that the 1st argument to useEffect, the side-effect function, cannot be an async function. This is because async functions always return a Promise and useEffect expects either nothing returned or a cleanup function returned.\nTo get around this, we can call an async function from our side-effect function. For example:\nfetch\nconst ProductBrowser = props =\u0026gt; { const [products, setProducts] = useState([]) async function getProducts() { try { const response = await fetch(apiUrl) // fetch data from server  if (response.ok) { const data = await response.json(); setProducts(data); // then update state  } else { const err = await response.text(); toastr.error(err); } } } useEffect(() =\u0026gt; getProducts(), []) // empty braces means execute after first render  return ( // JSX goes here  ) } axios\nconst ProductBrowser = props =\u0026gt; { const [products, setProducts] = useState([]) async function getProducts() { try { const response = await axios.get(apiUrl) // fetch data from server  setProducts(response.data) // then update state  } catch(error) { toastr.error(error) } } useEffect(() =\u0026gt; getProducts(), []) // empty braces means execute after first render  return ( // JSX goes here  ) } Calling a Library\u0026rsquo;s API  Sometimes we may want to call into a 3rd party library\u0026rsquo;s API That API may require a DOM reference - we can use the useRef hook for that But we need to trigger when to call the library\u0026rsquo;s API We can call the API when either props or state has changed via the useEffect hook.  const AmortizationChart = props =\u0026gt; { const chartRef = useRef(null) useEffect(() =\u0026gt; { if (!chartRef.current) { // get a reference to a chart so that we can call its API  chartRef.current = Highcharts.chart(\u0026#39;chart\u0026#39;, getConfig(amortization)) } else { chartRef.current.update(getConfig(amortization)) // call the API to update the chart  } }, [amortization, getConfig, id]) // execute the effect when any of these values change  return ( // JSX goes here  ) } Cleaning Up Before A Component Unmounts We may need to cleanup resources before a component unmounts.\nfunction KitchenTimer({ name, startTime }) { const [isRunning, setIsRunning] = useState(false) const [timeRemaining, setTimeRemaining] = useState(startTime * 10) const toggle = () =\u0026gt; { if (isRunning) { clearInterval(timer) // stops the timer.  setIsRunning(false) } else { timer = setInterval(() =\u0026gt; tick, 100) // creates a timer.  setIsRunning(true) } } useEffect(() =\u0026gt; { // return a cleanup function to clear a running timer.  return () =\u0026gt; clearInterval(intervalRef.current) }, []) // empty array means run once (after initial render) to register the cleanup code  return ( // JSX goes here  ) } Lab Click here for the instructions to this lab.\nConclusion  The useEffect hook is used for managing side-effects in React components. It can be used to replace three lifecycle methods previously used when writing Class components: componentDidMount, componentDidUpdate, and componentWillUnmount. The useEffect hook takes as its 2nd argument a watch list of variables that, when modified, trigger the effect to execute.  Additional Resources  Using the Effect Hook  "
},
{
	"uri": "/react/pillars/perf-opt-strategies/",
	"title": "Performance Optimization",
	"tags": [],
	"description": "",
	"content": "Welcome to React Performance Optimization Strategies! Course Description  Title: React Performance Optimization Strategies Duration: 3 days Workshop Location: Virtual Course Type: Workshop Course Difficulty: Pillar Relevant Roles: Software Engineering Short Description  Learn how to diagnose and fix performance problems in your React application.   Long Description  In this workshop you will learn how to gather and analyze performance profile data for your React application. Then you will learn how to use that data to target performance bottlenecks and apply best practices and built-in React features for improving the performance of your components and application. Finally you will develop some guiding principals and best practices for structuring your React applications for best performance.   Requirements  A laptop with yarn and NodeJS installed.   Prerequisites  Intermediate or advanced knowledge of React. Some familiarity with using React Hooks.   Outcomes  Learn how to profile React applications to learn about the performance characteristics Eliminate redundant renders of components Choose the best patterns for application state management to optimize components by default Manage CPU intensive operations with memoization and web workers Learn about React’s built-in features such as React.memo, useMemo, and useCallback Learn about strategies for managing and rendering large data sets   Questions  How long have you been writing React applications? Is your team at THD currently building applications with React? How many years of software engineering experience do you have? What do you hope to accomplish by taking this course? Paste a link to a GitHub repository of a React App that you have created. This course requires that you already know how to use React.    "
},
{
	"uri": "/software-eng-essentials/command-line-bash/bash/",
	"title": "Regex in Bash",
	"tags": [],
	"description": "",
	"content": "Regex in grep (egrep) Anchors    ^ $     ^Harry : Starts with the word \u0026lsquo;Harry\u0026rsquo;. Potter$ : Ends with \u0026lsquo;Potter\u0026rsquo;. ^Harry Potter$ : Starts with \u0026lsquo;Harry\u0026rsquo; and ends with \u0026lsquo;Potter\u0026rsquo;. Exact match to \u0026lsquo;Harry Potter\u0026rsquo;. magic : Matches any string with the word magic in it.  Example\nIf we have a file titled harrypotter.txt that contains the following text:\nIt takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends. Fear of a name only increases fear of the thing itself. Prints out the first line.\n$ cat harrypotter.txt | grep ^It It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends. Exercise\nPrepare for the exercise by doing the following.\n$ echo \u0026#34;It does not do to dwell on dreams and forget to live.\u0026#34; \u0026gt; quotes.txt + $ echo \u0026#34;Lay down with dogs. Rise with fleas.\u0026#34; \u0026gt;\u0026gt; quotes.txt  Using a starting Anchor cat the first line from quotes.txt to the terminal. Using an enging Anchor cat the second line from quotes.txt to the terminal. Using any word unique to the first line in quotes.txt, cat the first line to the terminal.  Quantifiers    * + ? {} ()    For the following, we\u0026rsquo;re going to use possible serial numbers to express the quantity of c\u0026rsquo;s we want to match on. The ex: provides serials numbers that would match.\n   Pattern Description Examples     ABc* Has AB and followed by 0 or any number of cs 0123AB45, 0123ABc45, 0123ABcc45   ABc+ Has AB and followed by 1 or more cs 0123ABc45 , 0123ABcc45 , 0123ABccc456   ABc? Has AB and followed by 0 or 1 cs 0123ABc45 , 0123AB45   ABc{3} Has AB and followed by 3 cs 0123ABccc56;   ABc{4,} Has AB and followed by 4 or more cs 0123ABcccc456 , 0123ABccccc456   ABc{2,5} Has AB and followed by 2 up to 5 cs 0123ABcc456 , 0123ABccccc456   A(bc)* Has A followed by zero or more of the sequence bc 0123A456 , 0123Abcbcbc456   A(bc){4,6} Has e followed by 4, or 5 bc sequences 0123Abcbcbcbc456 , 0123Abcbcbcbcbc456    So let\u0026rsquo;s say we have the following csv file named serials.csv that contains products and their serial numbers.\nG6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G7750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 E4660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 E460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 Prints out just the hardware using a known pattern of ending with at least 2 P\u0026rsquo;s.\n$ cat serials.csv | egrep \u0026#39;0123P{2,}\u0026#39; G6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G7750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25  NOTE: We start using egrep here to utilize Bash\u0026rsquo;s Extended Grep Functionality.\n Prints out just the garden items using a known pattern of having E4 followed by at least one 6.\n$ cat serials.csv | egrep \u0026#39;E46+\u0026#39; E4660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 E460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 Exercise\n Using the above CSV file, print out the items that contain 0123 followed by at least one and no more than 5 Z\u0026rsquo;s.  OR operator | \\| | [] | |:-:|:-:|\n   Pattern Description     A(b\\|c) Has A and followed by a b or a c.   e[bc] Has e and followed by a b or a c.    Let\u0026rsquo;s say we have the following text file of email addresses.\n$ printf \u0026#34;test@email.com\\nfake@gmail.com\\nlearning@bash.edu\\nfun@commandline.gov\\n\u0026#34; \u0026gt;\u0026gt; emails.csv $ cat emails.csv test@email.com fake@gmail.com learning@bash.edu fun@commandline.gov If we wanted to print out the emails that contain either @email or @gmail we could use this pattern: @[eg]mail\n$ cat emails.csv | egrep \u0026#39;@[eg]mail\u0026#39; test@email.com fake@gmail.com Exercise\n Using the above CSV file, print to the screen only those that end in \u0026ldquo;.gov\u0026rdquo; OR \u0026ldquo;.edu\u0026rdquo;.  Character Classes    \\d \\w \\s .       Pattern Description Examples     \\d Is a single digit. $ls \\| grep -E '/d' would list any file that starts with a number in your current directory.   \\w Is WORD character, i.e. alphanumeric or underscore $ls \\| grep -E '^\\w\\w\\w\\w-' would list files that start with four alpha characters, then a dash.   \\s Is a whitespace character, including tabs and line breaks ls \\| grep -E '\\w\\w\\s..\\d\\d' would list files that contains a letter, letter, a space, any character, any character, followed by two digits. Such as ec 1983.png   . Is ANY character As shown in the above example.    Inverse options\n/D gives the inverse option of /d, ex: /D matches to any one NON Digital character.\nExercise\nCreate a text file with digits, alpha, and alphanumeric keys for the following exercises. +\nprintf \u0026#34;abcdef + 123456 + abc123\u0026#34; \u0026gt;\u0026gt; testkeys.txt Exercise\n Print to the screen only the keys that include 3 consecutive digits. hint: Use qauntifiers. Print to the screen only the keys that have 3 consecutive non digit characters.  Bracket Expressions    []       Pattern Example     [emc] String can have either an \u0026lsquo;e\u0026rsquo;, \u0026rsquo;m\u0026rsquo;, or a \u0026lsquo;c\u0026rsquo;.   [a-m] String can have any letter a through m.   [a-fA-F0-9] String represents a hexadecimal number, case insensitive because we are allowing a-f lowercase, and upper.   [0-9]% String has a digit that is zero or higher, and not greater than 9, followed by a percent sign.   [^a-zA-Z] String that does NOT contain a letter a-z or A-Z. In this case the carrot is a negator.    So if we had the following text file with wood types and their tensile strength\nWood Species\tBending Strength (psi)\tAlder, Red\t9,800 Ash 15,000 Aspen 8,400 Basswood\t8,700 Beech\t14,900 Birch, Yellow\t16,600 Butternut\t8,100 Cherry\t12,300 Chestnut\t8,600 Elm\t11,800 Hickory\t20,200 Maple, Hard\t15,800 Maple, Soft\t13,400 Oak, Red\t14,300 Oak, White\t15,200 Poplar\t10,100 Sassafras\t9,000 Sweetgum\t12,500 Sycamore\t10,000 Walnut\t14,600 In order to print out just the wood types that can handle at least 15k psi, one could do:\n$ cat woodstrength.txt | egrep \u0026#39;1[5-9],[0-9]{3}\u0026#39; Ash 15,000 Birch, Yellow\t16,600 Maple, Hard\t15,800 Oak, White\t15,200 Exercise\nThis exercise is to be performed in a terminal. Execute the following to create a csv file that contains cities and their temperatures.\n$ printf \u0026#34;City\\tTemperature\\n\\rMiami\\t100deg\\n\\rAtlanta\\t95deg\\n\\rRichmond\\t90deg\\n\\r\u0026#34; \u0026gt; citytemps.csv Exercise\n Print out the lines that have temperatures 95 degrees and higher.  Regex in SED Quick review of basic SED\nAnchors and text Using SED and regex together can perform the same SED actions based off a regular expression pattern.\n$ cat FDR.txt | sed -n \u0026#39;/fear/p\u0026#39; There is nothing to fear but fear itself. --FDR Sed can use the regex anchors like we did in grep above.\n$ cat quotes.txt It does not do to dwell on dreams and forget to live. Lay down with dogs. Rise with fleas. $ cat quotes.txt | sed \u0026#34;s/^It does not/It doesn\u0026#39;t/\u0026#34; It doesn\u0026#39;t do to dwell on dreams and forget to live. Lay down with dogs. Rise with fleas. $ cat quotes.txt | sed \u0026#34;s/fleas.$/nasty bugs./\u0026#34; It does not do to dwell on dreams and forget to live. Lay down with dogs. Rise with nasty bugs. Exercise\nEcho the following text, pipe it into a SED command, that will add quotations before and after the quote.\nThere is nothing to fear but fear itself. --FDR This line is just another line of text. Wildcards  . - Represents any one character. * - Means zero or more occurances of the previous character or group.  $ cat FDR.txt | sed \u0026#39;s/ i. / IS /g\u0026#39; There IS nothing to fear but fear itself. --FDR This line doesn\u0026#39;t have that word. Exercise\nTake the following text, and print out to STDOUT the lines that start with \u0026ldquo;m\u0026rdquo;, have two more characters, and then a colon.\nroot:x:0:0:root user:/root:/bin/sh daemon:x:1:1:daemon:/usr/sbin:/bin/sh bin:x:2:2:bin:/bin:/bin/sh sys:x:3:3:sys:/dev:/bin/sh sync:x:4:65534:sync:/bin:/bin/sync games:x:5:60:games:/usr/games:/bin/sh man:x:6:12:man:/var/cache/man:/bin/sh mail:x:8:8:mail:/var/mail:/bin/sh news:x:9:9:news:/var/spool/news:/bin/sh backup:x:34:34:backup:/var/backups:/bin/sh Brackets Brackets work the same as in grep as well. All the characters in the brackets represent all options for one character.\n$ sed -n \u0026#39;/[pf]ear/p\u0026#39; FDR.txt There is nothing to fear but fear itself. --FDR Exercise\nIn the following exercise use SED to print out the lines that start with G, followed by a 6 or 7, and then another 7.\nG6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G7750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 G7750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 E4660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 E460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 E4560123ZZZZZZ, \u0026#34;some other thing\u0026#34;, 44 metacharacters Sed also has special references to metacharacters.\n   Symbol Meaning     [[:alnum:]] Alphanumeric [a-z A-Z 0-9]   [[:alpha:]] Alphabetic [a-z A-Z]   [[:blank:]] Blank characters (spaces or tabs)   [[:cntrl:]] Control characters   [[:digit:]] Numbers [0-9]   [[:graph:]] Any visible characters (excludes whitespace)   [[:lower:]] Lowercase letters [a-z]   [[:print:]] Printable characters (non-control characters)   [[:punct:]] Punctuation characters   [[:space:]] Whitespace   [[:upper:]] Uppercase letters [A-Z]   [[:xdigit:]] Hex digits [0-9 a-f A-F]    $ cat sys.conf /var/bin/default/ root:x:0:0:root user:/root:/bin/sh daemon:x:1:1:daemon:/usr/sbin:/bin/sh bin:x:2:2:bin:/bin:/bin/sh sys:x:3:3:sys:/dev:/bin/sh $ sed -n \u0026#39;/^[[:punct:]]/p\u0026#39; sys.conf /var/bin/default/ Exercise\nFrom the given list of Home Depot products, print out just the items that start with a digit.\nG6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 07750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 07750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 E4660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 E460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 E4560123ZZZZZZ, \u0026#34;some other thing\u0026#34;, 44 Quantifiers You can specify how many of a previous atom. In the below example, I\u0026rsquo;m specifying I want to print the serial numbers that start with at least 3 digits\n$ cat somenums.txt 78123AB AB12345 $ sed -n \u0026#39;/^[0-9]\\{3\\}/p\u0026#39; somenums.txt 78123AB Match Referencing (Ampersand) In SED we can reference the portion of the text that was match, in the replacement portion, like in the below example. We have a couple of phone numbers and we want to wrap the area code in parens.\n$ cat phonenums.txt 5555551212 5555551213 $ $ sed \u0026#39;s/^[[:digit:]][[:digit:]][[:digit:]]/(\u0026amp;)/g\u0026#39; phonenums.txt (555)5551212 (555)5551213 Exercise\nTake the following Home Depot products, and add a dash after the first two characters.\nG6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 07750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 07750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 Back Referencing In regex, you have the ability to define specific regions of your pattern. By labeling the sections, you can refer to them later. To define a section, you wrap that section in a backslash parens. ()\nThe first occurance of a defined section would be referred by \\1. The second occurance would be referred to as \\2, and so on.\n$ cat formphonenums.txt (555)555-1212 (555)555-1213 (555)555-1214 (666)555-1215 (666)555-1216 (777)555-1217 sed \u0026#39;s/\\(.*)\\)\\(.*-\\)\\(.*$\\)/Area \\ code: \\1 Second: \\2 Third: \\3/\u0026#39; formphonenums.txt Area code: (555) Second: 555- Third: 1212 Area code: (555) Second: 555- Third: 1213 Area code: (555) Second: 555- Third: 1214 Area code: (666) Second: 555- Third: 1215 Area code: (666) Second: 555- Third: 1216 Area code: (777) Second: 555- Third: 1217 Exercise\nTake the following list of product serial numbers and print out just the section before the dash, plus the description.\nG6-780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G7-750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 04-660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 04-60123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 E4-560123ZZZZZZ, \u0026#34;some other thing\u0026#34;, 44 Regex in VIM The Search and Replace functionality in VIM uses the following syntax:\n:range s[ubstitute]/pattern/string/cgiI\n :set nu will be a helpful command in the next section.\n Search Line Ranges  :4s/searched/replaced Will search only line 4 for \u0026ldquo;searched\u0026rdquo; and replace with \u0026ldquo;searched.\u0026rdquo; :4,7 s/searched/replaced Will search lines 4 through 7, look for \u0026ldquo;searched\u0026rdquo; and replace with \u0026ldquo;replaced\u0026rdquo;  most DIYers can install an entire room with laminate flooring in one day. :1/m/M/ Most DIYers can install an entire room with laminate flooring in one day. Exercise\nTake the following text in a VIM editor and replace the first occurance of \u0026lsquo;the\u0026rsquo; with \u0026lsquo;The\u0026rsquo; on the first line.\nWhen the Home Depot was founded in 1978, Bernie Marcus and Arthur Blank had no idea how revolutionary this new “hardware store” would be for home improvement and the retail industry. Today, we’re proud to be the world’s largest home improvement retailer. In more than 2,200 stores across North America, we aspire to excel in service – to our customers, associates, communities and shareholders. That’s what leadership means to us. That\u0026#39;s The Home Depot difference.  Lower case u will \u0026ldquo;undo\u0026rdquo; the last action. :\u0026lt;up arrow\u0026gt; will bring back the last command.\n Range options Apply changes to:\n   Specifier Description     number an absolute line number   . the current line   $ the last line in the file   % the whole file. The same as 1,$   't position of mark \u0026ldquo;t\u0026rdquo;   /pattern[/] the next line where text \u0026ldquo;pattern\u0026rdquo; matches.   ?pattern[?] the previous line where text \u0026ldquo;pattern\u0026rdquo; matches   \\/ the next line where the previously used search pattern matches   \\? the previous line where the previously used search pattern matches   \\\u0026amp; the next line where the previously used substitute pattern matches    Start from Search, Search in a Search. 1 Main Title 2 This is some text. What can I say about this? 3 This is the second line of my example text. 4 And this is the third. 5 6 Chapter 1 7 Section 1 8 some text in section 1. This is some text, ya\u0026#39;ll. 9 10 Section 2 11 This is some text in chapter 1, section 2. This is some text. 12 13 Chapter 2 14 Section 1 15 This is some text in chapter 2, section 1. 16 //Highlights this line. 17 Section 2 18 So there you go. 19 I\u0026#39;m all done now. 20 For real. 21 I really am done this time. 22 The command :/Chapter 1/;/Section 1/+,/Section 2/-  would first find the first occurrence of Chapter 1. Then search between Section 1 plus one line, and Section 2, minus one line.\nExercise\nIn the following text, in the second section, in the departments, change \u0026ldquo;Plumbing\u0026rdquo; to \u0026ldquo;Electrical\u0026rdquo;.\nSection 1 Departments: Wood Paint Hardware Associates: Betty Nicole Tim Section 2 Departments: Plumbing Outdoor Appliances Associates: Steve Eric Molly Search whole document :%s/searched/replaced Will only change the first occurance on every line.\n#before Most DIYers can install an entire room with laminate flooring in one day. :%s/entire/whole/ Most DIYers can install an whole room with laminate flooring in one day. Search Options For each line in the range replace a match of the pattern with the string where:\n   Code Meaning     c Confirm each substitution   g Replace all occurrences in the line (without g - only first).   i Ignore case for the pattern.   I Don\u0026rsquo;t ignore case for the pattern.    Global change :4,7s/searched/replaced/g Will change all occurances on line 4 through 7.\nExercise\nTake the following text in a VIM editor and change all of the occurrences of \u0026ldquo;Section\u0026rdquo; to \u0026ldquo;Chapter.\u0026rdquo;\nSection 1 JavaScript Basics Section 2 ECMAScript 2016 Section 3 Functional Programming in JS Case insensitive :4,7s/searched/replaced/gi Will replace as above, but case insensitively.\nBefore\nMost DIYers can install an entire room with laminate flooring in one day. planks can be cut with a hand saw or circular saw, and most laminate flooring comes in planks that simply snap together with a tongue-and-groove system. After running: :%s/most/The Lions Share/gi\nThe Lions Share of DIYers can install an entire room with laminate flooring in one day. planks can be cut with a hand saw or circular saw, and The Lions Share of laminate flooring comes in planks that simply snap together with a tongue-and-groove system. Forced Case Sensitive :4,7s/searched/replaced/gI Forces case sensitive.\nBefore\nMost DIYers can install an entire room with laminate flooring in one day. planks can be cut with a hand saw or circular saw, and most laminate flooring comes in planks that simply snap together with a tongue-and-groove system. After running: :%s/most/The Lions Share/gI\nThe Lions Share of DIYers can install an entire room with laminate flooring in one day. planks can be cut with a hand saw or circular saw, and most laminate flooring comes in planks that simply snap together with a tongue-and-groove system. Exercise\nIn the following text, replace all of the occurances of \u0026ldquo;roughin\u0026rdquo; with \u0026ldquo;rough-in\u0026rdquo;, globally, case insensitively.\nBOWL SHAPE, TOILET HEIGHT AND STYLE Before purchasing a new toilet, calculate the amount of bathroom space you have available and consider your bowl shape preferences. The most important of these measurements is the distance between the floor drain and the wall, called the roughin. The standard distance is 12 inches, but 10 or 14 inches are occasionally found in older homes. Determine the roughin in your bathroom by measuring from the wall behind the toilet to the middle of the bolts on the base, and compare to your desired toilet\u0026#39;s dimensions. Confirm each change :4,7s/searched/replaced/gic VIM will ask you to confirm each before making the change.\ny/n/a/q/l/^E/^Y\ny(yes for this one) n(no for this one occurance) a(change all occurances highlighted) q(quit and don\u0026rsquo;t make any more changes) l(last, change this occurance and quit) Cntrl + E / Cntrl + Y (Scrolls up and down the page) Shift + g will take you to the bottom of the file.`\nExercise\nTake the above excerpt from homedepot.com about measuring the rough-in. Hit \u0026lsquo;u\u0026rsquo; to undo your previous change. Make the same change as the previous exercise, but this time add the \u0026lsquo;c\u0026rsquo; option to confirm each change. Try using all the options, yes, no, all, quit, and last.\nYanking and Pasting :/Section/+ y\nFind first occurance of Section, go down one more line, and yank it (save it to memory)\n:// normal p\nSearches for the same pattern again. Sectionand will save the text on the next line.\nBefore\nSection 1 Text in section 1. Section 2 Text in section 2. After\nSection 1 Text in section 1. Text in section 1. Section 2 Text in section 2. Exercise\nUse the text from the previous exercise and move text from line 5 to line 3.\n Once in a search, hit \u0026ldquo;n\u0026rdquo; to go to next occurance, or \u0026ldquo;N\u0026rdquo; to move backwards.\nUse s/\\/dir1\\/dir2\\/dir3\\/file/dir4\\/dir5\\/file2/g for hunting down file paths. To avoid this so-called \u0026ldquo;backslashitis\u0026rdquo; you can use different separators in S\u0026amp;R (for example \u0026ldquo;:\u0026quot;) s:/dir1/dir2/dir3/file:/dir4/dir5/file2:g\n Anchors  s:^vi\\\u0026gt;:VIM Finds occurances where the line starts with vi, and vi is a whole word, not part of a word, and replace with VIM s:\\\u0026lt;vi\\\u0026gt;:VIM Finds occurances where vi is its own word and replace with VIM s:^vi$:VIM Finds a line where vi is the only text on a line and replace with VIM  Example\nOnly replace whole word of searched:\nBefore\nSome searched lines of text, and non-searched. After running :2,3s/\\\u0026lt;searched\\\u0026gt;/replaced/gic\n gic = global, case insensitive, and confirm each.\n Some replaced lines of text, and non-searched. Exercise\nTake the following text and replace only the full words of \u0026ldquo;is\u0026rdquo; to \u0026ldquo;is not\u0026rdquo;.\nThis is VIM. Do you like it? It is pretty great. Brackets Just as we used brackets in egrep, we can use them here. All characters in a set of brackets represents what one character can be to match.\nThis can be single characters, digits, or ranges of each.\nBefore\nThis is some text that I want to search and replace. After running :%s/[TS]his/That/\nThat is some text that I want to search and replace. Before\nHere is 1 number that will match 2567. After running :%s/[2-7]\\+/123/g\nHere is 1 number that will match 123. Exercise\nFor the following Home Depot products, change the item counts that are 0, to \u0026ldquo;none in stock.\u0026rdquo;\nG6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G7750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 04660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 0 0460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 E4560123ZZZZZZ, \u0026#34;Pretty Petunias\u0026#34;, 0 Escaped characters and metacharacters Escaped characters and metacharacters\n   Character Description     # Matching   . any character except new line   \\s whitespace character   \\S non-whitespace character   \\d digit   \\D non-digit   \\x hex digit   \\X non-hex digit   \\o octal digit   \\O non-octal digit   \\h head of word character (a,b,c\u0026hellip;z,A,B,C\u0026hellip;Z and _)   \\H non-head of word character   \\p printable character   \\P like \\p, but excluding digits   \\w word character   \\W non-word character   \\a alphabetic character   \\A non-alphabetic character   \\l lowercase character   \\L non-lowercase character   \\u uppercase character   \\U non-uppercase character    Example\n To match a date like 09/01/2000 you can use (assuming you don\u0026rsquo;t use \u0026ldquo;/\u0026rdquo; as a separator in the S\u0026amp;R): \\d\\d/\\d\\d/\\d\\d\\d\\d To match 6 letter word starting with a capital letter: \\u\\w\\w\\w\\w\\w  Exercise\nFor the following hex color codes in a VIM editor, change the lower-cased letters to upper-cased. Such that 00ffff, would be 00FFFF.\nAqua\t#00ffff\trgb(0, 255, 255) Teal\t#008080\trgb(0, 128, 128) Blue\t#0000ff\trgb(0, 0, 255) Navy\t#000080\trgb(0, 0, 128) Greedy and Non-Greedy Quantifiers Greedy Quantifiers\n   Quantifier Description     * matches 0 or more of the preceding characters, ranges or metacharacters .* matches everything including empty line   \\+ matches 1 or more of the preceding characters   \\= matches 0 or 1 more of the preceding characters   \\{n,m} matches from n to m of the preceding characters   \\{n} matches exactly n times of the preceding characters   \\{,m} matches at most m (from 0 to m) of the preceding characters   \\{n,} matches at least n of of the preceding characters     n and m are positive integers (\u0026gt;0)\n Greedy means that your pattern will try to match as much text as possible.\nExample\n\\u\\w\\+ would match any word that starts with an uppercase letter, followed by at least one lowercased letter. That would work fine.\nThe problem with greedy quantifiers is that the following match would pick up everything between the first and last double quotes: :%s/\u0026quot;.*\u0026quot;/XX/gic\nThe XX quantifiers is that the following match would pick up everything between the first and last double quotes.\nWe can solve this problem with Lazy Quantifiers.\nLazy Quantifiers\n   Quantifier Description     \\{-} matches 0 or more of the preceding atom, as few as possible   \\{-n,m} matches 1 or more of the preceding characters   \\{-n,} matches at lease or more of the preceding characters   \\{-,m} matches 1 or more of the preceding characters    Where n and m are positive integers.\nWe could use \\{-} in place of * in our pattern.\nSo, now .\\{-} will match the first quoted text:\nThe \u0026#34;problem\u0026#34; with \u0026#34;greedy\u0026#34; quantifiers is that the following match would pick up everything between the first and last double quotes. :%s:\u0026quot;.\\{-}\u0026quot;:XX:g XX with XX quantifiers is that the following match would pick up everything between the first and last double quotes.\nExercise\nFor the following hex color codes, remove the hex code so that only the name and rgb codes remain.\nAqua\t#00ffff\trgb(0, 255, 255) Teal\t#008080\trgb(0, 128, 128) Blue\t#0000ff\trgb(0, 0, 255) Navy\t#000080\trgb(0, 0, 128) Grouping and Backreferences You can group parts of the pattern expression enclosing them with \\( and \\) and refer to them inside the replacement pattern by their special number \\1, \\2 \u0026hellip; \\9.\nTypical example is swapping first two words of the line: s:\\(\\w\\+\\)\\(\\s\\+\\)\\(\\w\\+\\):\\3\\2\\1:\n \\1 holds the first word \\2 - any number of spaces or tabs in between \\3 - the second word  How to decide what number holds what pair of \\(\\) ? - count opening \\( from the left.\nReplacement part of substitute\n   # Meaning     \u0026amp; the whole matched pattern   \\L the following characters are made lowercase   \\0 the whole matched pattern   \\U the following characters are made uppercase   \\1 the matched pattern in the first pair of ()   \\E end of \\U and \\L   \\2 the matched pattern in the second pair of ()   \\e end of \\U and \\L   \\r split line in two at this point   \\9 the matched pattern in the ninth pair of ()   \\l next character made lowercase   ~ the previous substitute string   \\u next character made uppercase    Now the full S\u0026amp;R to correct non-capital words at the beginning of the sentences looks like: s:\\([.!?]\\)\\s\\+\\([a-z]\\):\\1 \\u\\2:g\nWe have used alternate separators here, the colon. We group the first section as some sort of punctuation, followed by a white space. Then, a lowercase letter. The lowercased letter is then uppercased by using the /u.\nmost DIYers can install an entire room with laminate flooring in one day. planks can be cut with a hand saw or circular saw, and most laminate flooring comes in planks that simply snap together with a tongue-and-groove system. laminate can be installed in almost every room in your home since it doesn’t have to be glued down. for additional information, download our PDF, and read below for instructions on how to install laminate flooring. ~ ~ replace with \\1 \\u\\2 (y/n/a/q/l/^E/^Y)? ## the p in planks, in the second sentence is highlighted. We have corrected our grammar and as an extra job we replaced variable number of spaces between punctuation and the first letter of the next sentence with exactly two spaces.\nExercise\nFor the following HTML color codes, group the rgb codes, and print out for each line RED: (grouped red value), GREEN: (grouped green value), BLUE: (grouped blue value)\nAqua\t#00ffff\trgb(0, 255, 255) Teal\t#008080\trgb(0, 128, 128) Blue\t#0000ff\trgb(0, 0, 255) Navy\t#000080\trgb(0, 0, 128) Alterations Using \\| you can combine several expressions into one which matches any of its components. The first one matched will be used.\n\\(Date:\\|Subject:\\|From:\\)\\(\\s.*\\)\nwill parse various mail headings and their contents into \\1 and \\2, respectively. The thing to remember about VIM alternation that it is not greedy. It won\u0026rsquo;t search for the longest possible match, it will use the first that matched. That means that the order of the items in the alternation is important!\n Quick mapping to put \\(\\) in your pattern string cmap ;\\ \\(\\)\u0026lt;Left\u0026gt;\u0026lt;Left\u0026gt;\n Regexp Operator Precedence As in arithmetic expressions, regular expressions are executed in a certain order of precedence. Here the table of precedence, from highest to lowest:\n   Precedence Regexp Description     1 \\( \\) grouping   2 \\=,\\+,*,\\{n} etc. quantifiers   3 abc\\t\\.\\w sequence of characters/ metacharacters, not containing quantifiers or grouping operators   4 \\| alternation    Resources  https://regexr.com/ https://www.regular-expressions.info/  "
},
{
	"uri": "/software-eng-essentials/fundamentals-of-regex/bash/",
	"title": "Regex in Bash",
	"tags": [],
	"description": "",
	"content": "Regex in grep (egrep) Anchors    ^ $     ^Harry : Starts with the word \u0026lsquo;Harry\u0026rsquo;. Potter$ : Ends with \u0026lsquo;Potter\u0026rsquo;. ^Harry Potter$ : Starts with \u0026lsquo;Harry\u0026rsquo; and ends with \u0026lsquo;Potter\u0026rsquo;. Exact match to \u0026lsquo;Harry Potter\u0026rsquo;. magic : Matches any string with the word magic in it.  Example\nIf we have a file titled harrypotter.txt that contains the following text:\nIt takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends. Fear of a name only increases fear of the thing itself. Prints out the first line.\n$ cat harrypotter.txt | grep ^It It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends. Exercise\nPrepare for the exercise by doing the following.\n$ echo \u0026#34;It does not do to dwell on dreams and forget to live.\u0026#34; \u0026gt; quotes.txt + $ echo \u0026#34;Lay down with dogs. Rise with fleas.\u0026#34; \u0026gt;\u0026gt; quotes.txt  Using a starting Anchor cat the first line from quotes.txt to the terminal. Using an enging Anchor cat the second line from quotes.txt to the terminal. Using any word unique to the first line in quotes.txt, cat the first line to the terminal.  Quantifiers    * + ? {} ()    For the following, we\u0026rsquo;re going to use possible serial numbers to express the quantity of c\u0026rsquo;s we want to match on. The ex: provides serials numbers that would match.\n   Pattern Description Examples     ABc* Has AB and followed by 0 or any number of cs 0123AB45, 0123ABc45, 0123ABcc45   ABc+ Has AB and followed by 1 or more cs 0123ABc45 , 0123ABcc45 , 0123ABccc456   ABc? Has AB and followed by 0 or 1 cs 0123ABc45 , 0123AB45   ABc{3} Has AB and followed by 3 cs 0123ABccc56;   ABc{4,} Has AB and followed by 4 or more cs 0123ABcccc456 , 0123ABccccc456   ABc{2,5} Has AB and followed by 2 up to 5 cs 0123ABcc456 , 0123ABccccc456   A(bc)* Has A followed by zero or more of the sequence bc 0123A456 , 0123Abcbcbc456   A(bc){4,6} Has e followed by 4, or 5 bc sequences 0123Abcbcbcbc456 , 0123Abcbcbcbcbc456    So let\u0026rsquo;s say we have the following csv file named serials.csv that contains products and their serial numbers.\nG6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G7750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 E4660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 E460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 Prints out just the hardware using a known pattern of ending with at least 2 P\u0026rsquo;s.\n$ cat serials.csv | egrep \u0026#39;0123P{2,}\u0026#39; G6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G7750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25  NOTE: We start using egrep here to utilize Bash\u0026rsquo;s Extended Grep Functionality.\n Prints out just the garden items using a known pattern of having E4 followed by at least one 6.\n$ cat serials.csv | egrep \u0026#39;E46+\u0026#39; E4660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 E460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 Exercise\n Using the above CSV file, print out the items that contain 0123 followed by at least one and no more than 5 Z\u0026rsquo;s.  OR operator | \\| | [] | |:-:|:-:|\n   Pattern Description     A(b\\|c) Has A and followed by a b or a c.   e[bc] Has e and followed by a b or a c.    Let\u0026rsquo;s say we have the following text file of email addresses.\n$ printf \u0026#34;test@email.com\\nfake@gmail.com\\nlearning@bash.edu\\nfun@commandline.gov\\n\u0026#34; \u0026gt;\u0026gt; emails.csv $ cat emails.csv test@email.com fake@gmail.com learning@bash.edu fun@commandline.gov If we wanted to print out the emails that contain either @email or @gmail we could use this pattern: @[eg]mail\n$ cat emails.csv | egrep \u0026#39;@[eg]mail\u0026#39; test@email.com fake@gmail.com Exercise\n Using the above CSV file, print to the screen only those that end in \u0026ldquo;.gov\u0026rdquo; OR \u0026ldquo;.edu\u0026rdquo;.  Character Classes    \\d \\w \\s .       Pattern Description Examples     \\d Is a single digit. $ls \\| grep -E '/d' would list any file that starts with a number in your current directory.   \\w Is WORD character, i.e. alphanumeric or underscore $ls \\| grep -E '^\\w\\w\\w\\w-' would list files that start with four alpha characters, then a dash.   \\s Is a whitespace character, including tabs and line breaks ls \\| grep -E '\\w\\w\\s..\\d\\d' would list files that contains a letter, letter, a space, any character, any character, followed by two digits. Such as ec 1983.png   . Is ANY character As shown in the above example.    Inverse options\n/D gives the inverse option of /d, ex: /D matches to any one NON Digital character.\nExercise\nCreate a text file with digits, alpha, and alphanumeric keys for the following exercises. +\nprintf \u0026#34;abcdef + 123456 + abc123\u0026#34; \u0026gt;\u0026gt; testkeys.txt Exercise\n Print to the screen only the keys that include 3 consecutive digits. hint: Use qauntifiers. Print to the screen only the keys that have 3 consecutive non digit characters.  Bracket Expressions    []       Pattern Example     [emc] String can have either an \u0026lsquo;e\u0026rsquo;, \u0026rsquo;m\u0026rsquo;, or a \u0026lsquo;c\u0026rsquo;.   [a-m] String can have any letter a through m.   [a-fA-F0-9] String represents a hexadecimal number, case insensitive because we are allowing a-f lowercase, and upper.   [0-9]% String has a digit that is zero or higher, and not greater than 9, followed by a percent sign.   [^a-zA-Z] String that does NOT contain a letter a-z or A-Z. In this case the carrot is a negator.    So if we had the following text file with wood types and their tensile strength\nWood Species\tBending Strength (psi)\tAlder, Red\t9,800 Ash 15,000 Aspen 8,400 Basswood\t8,700 Beech\t14,900 Birch, Yellow\t16,600 Butternut\t8,100 Cherry\t12,300 Chestnut\t8,600 Elm\t11,800 Hickory\t20,200 Maple, Hard\t15,800 Maple, Soft\t13,400 Oak, Red\t14,300 Oak, White\t15,200 Poplar\t10,100 Sassafras\t9,000 Sweetgum\t12,500 Sycamore\t10,000 Walnut\t14,600 In order to print out just the wood types that can handle at least 15k psi, one could do:\n$ cat woodstrength.txt | egrep \u0026#39;1[5-9],[0-9]{3}\u0026#39; Ash 15,000 Birch, Yellow\t16,600 Maple, Hard\t15,800 Oak, White\t15,200 Exercise\nThis exercise is to be performed in a terminal. Execute the following to create a csv file that contains cities and their temperatures.\n$ printf \u0026#34;City\\tTemperature\\n\\rMiami\\t100deg\\n\\rAtlanta\\t95deg\\n\\rRichmond\\t90deg\\n\\r\u0026#34; \u0026gt; citytemps.csv Exercise\n Print out the lines that have temperatures 95 degrees and higher.  Regex in SED Quick review of basic SED\nAnchors and text Using SED and regex together can perform the same SED actions based off a regular expression pattern.\n$ cat FDR.txt | sed -n \u0026#39;/fear/p\u0026#39; There is nothing to fear but fear itself. --FDR Sed can use the regex anchors like we did in grep above.\n$ cat quotes.txt It does not do to dwell on dreams and forget to live. Lay down with dogs. Rise with fleas. $ cat quotes.txt | sed \u0026#34;s/^It does not/It doesn\u0026#39;t/\u0026#34; It doesn\u0026#39;t do to dwell on dreams and forget to live. Lay down with dogs. Rise with fleas. $ cat quotes.txt | sed \u0026#34;s/fleas.$/nasty bugs./\u0026#34; It does not do to dwell on dreams and forget to live. Lay down with dogs. Rise with nasty bugs. Exercise\nEcho the following text, pipe it into a SED command, that will add quotations before and after the quote.\nThere is nothing to fear but fear itself. --FDR This line is just another line of text. Wildcards  . - Represents any one character. * - Means zero or more occurances of the previous character or group.  $ cat FDR.txt | sed \u0026#39;s/ i. / IS /g\u0026#39; There IS nothing to fear but fear itself. --FDR This line doesn\u0026#39;t have that word. Exercise\nTake the following text, and print out to STDOUT the lines that start with \u0026ldquo;m\u0026rdquo;, have two more characters, and then a colon.\nroot:x:0:0:root user:/root:/bin/sh daemon:x:1:1:daemon:/usr/sbin:/bin/sh bin:x:2:2:bin:/bin:/bin/sh sys:x:3:3:sys:/dev:/bin/sh sync:x:4:65534:sync:/bin:/bin/sync games:x:5:60:games:/usr/games:/bin/sh man:x:6:12:man:/var/cache/man:/bin/sh mail:x:8:8:mail:/var/mail:/bin/sh news:x:9:9:news:/var/spool/news:/bin/sh backup:x:34:34:backup:/var/backups:/bin/sh Brackets Brackets work the same as in grep as well. All the characters in the brackets represent all options for one character.\n$ sed -n \u0026#39;/[pf]ear/p\u0026#39; FDR.txt There is nothing to fear but fear itself. --FDR Exercise\nIn the following exercise use SED to print out the lines that start with G, followed by a 6 or 7, and then another 7.\nG6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G7750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 G7750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 E4660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 E460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 E4560123ZZZZZZ, \u0026#34;some other thing\u0026#34;, 44 metacharacters Sed also has special references to metacharacters.\n   Symbol Meaning     [[:alnum:]] Alphanumeric [a-z A-Z 0-9]   [[:alpha:]] Alphabetic [a-z A-Z]   [[:blank:]] Blank characters (spaces or tabs)   [[:cntrl:]] Control characters   [[:digit:]] Numbers [0-9]   [[:graph:]] Any visible characters (excludes whitespace)   [[:lower:]] Lowercase letters [a-z]   [[:print:]] Printable characters (non-control characters)   [[:punct:]] Punctuation characters   [[:space:]] Whitespace   [[:upper:]] Uppercase letters [A-Z]   [[:xdigit:]] Hex digits [0-9 a-f A-F]    $ cat sys.conf /var/bin/default/ root:x:0:0:root user:/root:/bin/sh daemon:x:1:1:daemon:/usr/sbin:/bin/sh bin:x:2:2:bin:/bin:/bin/sh sys:x:3:3:sys:/dev:/bin/sh $ sed -n \u0026#39;/^[[:punct:]]/p\u0026#39; sys.conf /var/bin/default/ Exercise\nFrom the given list of Home Depot products, print out just the items that start with a digit.\nG6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 07750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 07750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 E4660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 E460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 E4560123ZZZZZZ, \u0026#34;some other thing\u0026#34;, 44 Quantifiers You can specify how many of a previous atom. In the below example, I\u0026rsquo;m specifying I want to print the serial numbers that start with at least 3 digits\n$ cat somenums.txt 78123AB AB12345 $ sed -n \u0026#39;/^[0-9]\\{3\\}/p\u0026#39; somenums.txt 78123AB Match Referencing (Ampersand) In SED we can reference the portion of the text that was match, in the replacement portion, like in the below example. We have a couple of phone numbers and we want to wrap the area code in parens.\n$ cat phonenums.txt 5555551212 5555551213 $ $ sed \u0026#39;s/^[[:digit:]][[:digit:]][[:digit:]]/(\u0026amp;)/g\u0026#39; phonenums.txt (555)5551212 (555)5551213 Exercise\nTake the following Home Depot products, and add a dash after the first two characters.\nG6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 07750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 07750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 Back Referencing In regex, you have the ability to define specific regions of your pattern. By labeling the sections, you can refer to them later. To define a section, you wrap that section in a backslash parens. ()\nThe first occurance of a defined section would be referred by \\1. The second occurance would be referred to as \\2, and so on.\n$ cat formphonenums.txt (555)555-1212 (555)555-1213 (555)555-1214 (666)555-1215 (666)555-1216 (777)555-1217 sed \u0026#39;s/\\(.*)\\)\\(.*-\\)\\(.*$\\)/Area \\ code: \\1 Second: \\2 Third: \\3/\u0026#39; formphonenums.txt Area code: (555) Second: 555- Third: 1212 Area code: (555) Second: 555- Third: 1213 Area code: (555) Second: 555- Third: 1214 Area code: (666) Second: 555- Third: 1215 Area code: (666) Second: 555- Third: 1216 Area code: (777) Second: 555- Third: 1217 Exercise\nTake the following list of product serial numbers and print out just the section before the dash, plus the description.\nG6-780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G7-750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 04-660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 32 04-60123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 E4-560123ZZZZZZ, \u0026#34;some other thing\u0026#34;, 44 Regex in VIM The Search and Replace functionality in VIM uses the following syntax:\n:range s[ubstitute]/pattern/string/cgiI\n :set nu will be a helpful command in the next section.\n Search Line Ranges  :4s/searched/replaced Will search only line 4 for \u0026ldquo;searched\u0026rdquo; and replace with \u0026ldquo;searched.\u0026rdquo; :4,7 s/searched/replaced Will search lines 4 through 7, look for \u0026ldquo;searched\u0026rdquo; and replace with \u0026ldquo;replaced\u0026rdquo;  most DIYers can install an entire room with laminate flooring in one day. :1/m/M/ Most DIYers can install an entire room with laminate flooring in one day. Exercise\nTake the following text in a VIM editor and replace the first occurance of \u0026lsquo;the\u0026rsquo; with \u0026lsquo;The\u0026rsquo; on the first line.\nWhen the Home Depot was founded in 1978, Bernie Marcus and Arthur Blank had no idea how revolutionary this new “hardware store” would be for home improvement and the retail industry. Today, we’re proud to be the world’s largest home improvement retailer. In more than 2,200 stores across North America, we aspire to excel in service – to our customers, associates, communities and shareholders. That’s what leadership means to us. That\u0026#39;s The Home Depot difference.  Lower case u will \u0026ldquo;undo\u0026rdquo; the last action. :\u0026lt;up arrow\u0026gt; will bring back the last command.\n Range options Apply changes to:\n   Specifier Description     number an absolute line number   . the current line   $ the last line in the file   % the whole file. The same as 1,$   't position of mark \u0026ldquo;t\u0026rdquo;   /pattern[/] the next line where text \u0026ldquo;pattern\u0026rdquo; matches.   ?pattern[?] the previous line where text \u0026ldquo;pattern\u0026rdquo; matches   \\/ the next line where the previously used search pattern matches   \\? the previous line where the previously used search pattern matches   \\\u0026amp; the next line where the previously used substitute pattern matches    Start from Search, Search in a Search. 1 Main Title 2 This is some text. What can I say about this? 3 This is the second line of my example text. 4 And this is the third. 5 6 Chapter 1 7 Section 1 8 some text in section 1. This is some text, ya\u0026#39;ll. 9 10 Section 2 11 This is some text in chapter 1, section 2. This is some text. 12 13 Chapter 2 14 Section 1 15 This is some text in chapter 2, section 1. 16 //Highlights this line. 17 Section 2 18 So there you go. 19 I\u0026#39;m all done now. 20 For real. 21 I really am done this time. 22 The command :/Chapter 1/;/Section 1/+,/Section 2/-  would first find the first occurrence of Chapter 1. Then search between Section 1 plus one line, and Section 2, minus one line.\nExercise\nIn the following text, in the second section, in the departments, change \u0026ldquo;Plumbing\u0026rdquo; to \u0026ldquo;Electrical\u0026rdquo;.\nSection 1 Departments: Wood Paint Hardware Associates: Betty Nicole Tim Section 2 Departments: Plumbing Outdoor Appliances Associates: Steve Eric Molly Search whole document :%s/searched/replaced Will only change the first occurance on every line.\n#before Most DIYers can install an entire room with laminate flooring in one day. :%s/entire/whole/ Most DIYers can install an whole room with laminate flooring in one day. Search Options For each line in the range replace a match of the pattern with the string where:\n   Code Meaning     c Confirm each substitution   g Replace all occurrences in the line (without g - only first).   i Ignore case for the pattern.   I Don\u0026rsquo;t ignore case for the pattern.    Global change :4,7s/searched/replaced/g Will change all occurances on line 4 through 7.\nExercise\nTake the following text in a VIM editor and change all of the occurrences of \u0026ldquo;Section\u0026rdquo; to \u0026ldquo;Chapter.\u0026rdquo;\nSection 1 JavaScript Basics Section 2 ECMAScript 2016 Section 3 Functional Programming in JS Case insensitive :4,7s/searched/replaced/gi Will replace as above, but case insensitively.\nBefore\nMost DIYers can install an entire room with laminate flooring in one day. planks can be cut with a hand saw or circular saw, and most laminate flooring comes in planks that simply snap together with a tongue-and-groove system. After running: :%s/most/The Lions Share/gi\nThe Lions Share of DIYers can install an entire room with laminate flooring in one day. planks can be cut with a hand saw or circular saw, and The Lions Share of laminate flooring comes in planks that simply snap together with a tongue-and-groove system. Forced Case Sensitive :4,7s/searched/replaced/gI Forces case sensitive.\nBefore\nMost DIYers can install an entire room with laminate flooring in one day. planks can be cut with a hand saw or circular saw, and most laminate flooring comes in planks that simply snap together with a tongue-and-groove system. After running: :%s/most/The Lions Share/gI\nThe Lions Share of DIYers can install an entire room with laminate flooring in one day. planks can be cut with a hand saw or circular saw, and most laminate flooring comes in planks that simply snap together with a tongue-and-groove system. Exercise\nIn the following text, replace all of the occurances of \u0026ldquo;roughin\u0026rdquo; with \u0026ldquo;rough-in\u0026rdquo;, globally, case insensitively.\nBOWL SHAPE, TOILET HEIGHT AND STYLE Before purchasing a new toilet, calculate the amount of bathroom space you have available and consider your bowl shape preferences. The most important of these measurements is the distance between the floor drain and the wall, called the roughin. The standard distance is 12 inches, but 10 or 14 inches are occasionally found in older homes. Determine the roughin in your bathroom by measuring from the wall behind the toilet to the middle of the bolts on the base, and compare to your desired toilet\u0026#39;s dimensions. Confirm each change :4,7s/searched/replaced/gic VIM will ask you to confirm each before making the change.\ny/n/a/q/l/^E/^Y\ny(yes for this one) n(no for this one occurance) a(change all occurances highlighted) q(quit and don\u0026rsquo;t make any more changes) l(last, change this occurance and quit) Cntrl + E / Cntrl + Y (Scrolls up and down the page) Shift + g will take you to the bottom of the file.`\nExercise\nTake the above excerpt from homedepot.com about measuring the rough-in. Hit \u0026lsquo;u\u0026rsquo; to undo your previous change. Make the same change as the previous exercise, but this time add the \u0026lsquo;c\u0026rsquo; option to confirm each change. Try using all the options, yes, no, all, quit, and last.\nYanking and Pasting :/Section/+ y\nFind first occurance of Section, go down one more line, and yank it (save it to memory)\n:// normal p\nSearches for the same pattern again. Sectionand will save the text on the next line.\nBefore\nSection 1 Text in section 1. Section 2 Text in section 2. After\nSection 1 Text in section 1. Text in section 1. Section 2 Text in section 2. Exercise\nUse the text from the previous exercise and move text from line 5 to line 3.\n Once in a search, hit \u0026ldquo;n\u0026rdquo; to go to next occurance, or \u0026ldquo;N\u0026rdquo; to move backwards.\nUse s/\\/dir1\\/dir2\\/dir3\\/file/dir4\\/dir5\\/file2/g for hunting down file paths. To avoid this so-called \u0026ldquo;backslashitis\u0026rdquo; you can use different separators in S\u0026amp;R (for example \u0026ldquo;:\u0026quot;) s:/dir1/dir2/dir3/file:/dir4/dir5/file2:g\n Anchors  s:^vi\\\u0026gt;:VIM Finds occurances where the line starts with vi, and vi is a whole word, not part of a word, and replace with VIM s:\\\u0026lt;vi\\\u0026gt;:VIM Finds occurances where vi is its own word and replace with VIM s:^vi$:VIM Finds a line where vi is the only text on a line and replace with VIM  Example\nOnly replace whole word of searched:\nBefore\nSome searched lines of text, and non-searched. After running :2,3s/\\\u0026lt;searched\\\u0026gt;/replaced/gic\n gic = global, case insensitive, and confirm each.\n Some replaced lines of text, and non-searched. Exercise\nTake the following text and replace only the full words of \u0026ldquo;is\u0026rdquo; to \u0026ldquo;is not\u0026rdquo;.\nThis is VIM. Do you like it? It is pretty great. Brackets Just as we used brackets in egrep, we can use them here. All characters in a set of brackets represents what one character can be to match.\nThis can be single characters, digits, or ranges of each.\nBefore\nThis is some text that I want to search and replace. After running :%s/[TS]his/That/\nThat is some text that I want to search and replace. Before\nHere is 1 number that will match 2567. After running :%s/[2-7]\\+/123/g\nHere is 1 number that will match 123. Exercise\nFor the following Home Depot products, change the item counts that are 0, to \u0026ldquo;none in stock.\u0026rdquo;\nG6780123PPP, \u0026#34;Smart Door Lock\u0026#34;, 66 G7750123PPQ, \u0026#34;Deadbolts\u0026#34;, 25 04660123ZZ1, \u0026#34;Encore Azalea\u0026#34;, 0 0460123ZZZ, \u0026#34;Jubilation Gardenia\u0026#34;, 12 E4560123ZZZZZZ, \u0026#34;Pretty Petunias\u0026#34;, 0 Escaped characters and metacharacters Escaped characters and metacharacters\n   Character Description     # Matching   . any character except new line   \\s whitespace character   \\S non-whitespace character   \\d digit   \\D non-digit   \\x hex digit   \\X non-hex digit   \\o octal digit   \\O non-octal digit   \\h head of word character (a,b,c\u0026hellip;z,A,B,C\u0026hellip;Z and _)   \\H non-head of word character   \\p printable character   \\P like \\p, but excluding digits   \\w word character   \\W non-word character   \\a alphabetic character   \\A non-alphabetic character   \\l lowercase character   \\L non-lowercase character   \\u uppercase character   \\U non-uppercase character    Example\n To match a date like 09/01/2000 you can use (assuming you don\u0026rsquo;t use \u0026ldquo;/\u0026rdquo; as a separator in the S\u0026amp;R): \\d\\d/\\d\\d/\\d\\d\\d\\d To match 6 letter word starting with a capital letter: \\u\\w\\w\\w\\w\\w  Exercise\nFor the following hex color codes in a VIM editor, change the lower-cased letters to upper-cased. Such that 00ffff, would be 00FFFF.\nAqua\t#00ffff\trgb(0, 255, 255) Teal\t#008080\trgb(0, 128, 128) Blue\t#0000ff\trgb(0, 0, 255) Navy\t#000080\trgb(0, 0, 128) Greedy and Non-Greedy Quantifiers Greedy Quantifiers\n   Quantifier Description     * matches 0 or more of the preceding characters, ranges or metacharacters .* matches everything including empty line   \\+ matches 1 or more of the preceding characters   \\= matches 0 or 1 more of the preceding characters   \\{n,m} matches from n to m of the preceding characters   \\{n} matches exactly n times of the preceding characters   \\{,m} matches at most m (from 0 to m) of the preceding characters   \\{n,} matches at least n of of the preceding characters     n and m are positive integers (\u0026gt;0)\n Greedy means that your pattern will try to match as much text as possible.\nExample\n\\u\\w\\+ would match any word that starts with an uppercase letter, followed by at least one lowercased letter. That would work fine.\nThe problem with greedy quantifiers is that the following match would pick up everything between the first and last double quotes: :%s/\u0026quot;.*\u0026quot;/XX/gic\nThe XX quantifiers is that the following match would pick up everything between the first and last double quotes.\nWe can solve this problem with Lazy Quantifiers.\nLazy Quantifiers\n   Quantifier Description     \\{-} matches 0 or more of the preceding atom, as few as possible   \\{-n,m} matches 1 or more of the preceding characters   \\{-n,} matches at lease or more of the preceding characters   \\{-,m} matches 1 or more of the preceding characters    Where n and m are positive integers.\nWe could use \\{-} in place of * in our pattern.\nSo, now .\\{-} will match the first quoted text:\nThe \u0026#34;problem\u0026#34; with \u0026#34;greedy\u0026#34; quantifiers is that the following match would pick up everything between the first and last double quotes. :%s:\u0026quot;.\\{-}\u0026quot;:XX:g XX with XX quantifiers is that the following match would pick up everything between the first and last double quotes.\nExercise\nFor the following hex color codes, remove the hex code so that only the name and rgb codes remain.\nAqua\t#00ffff\trgb(0, 255, 255) Teal\t#008080\trgb(0, 128, 128) Blue\t#0000ff\trgb(0, 0, 255) Navy\t#000080\trgb(0, 0, 128) Grouping and Backreferences You can group parts of the pattern expression enclosing them with \\( and \\) and refer to them inside the replacement pattern by their special number \\1, \\2 \u0026hellip; \\9.\nTypical example is swapping first two words of the line: s:\\(\\w\\+\\)\\(\\s\\+\\)\\(\\w\\+\\):\\3\\2\\1:\n \\1 holds the first word \\2 - any number of spaces or tabs in between \\3 - the second word  How to decide what number holds what pair of \\(\\) ? - count opening \\( from the left.\nReplacement part of substitute\n   # Meaning     \u0026amp; the whole matched pattern   \\L the following characters are made lowercase   \\0 the whole matched pattern   \\U the following characters are made uppercase   \\1 the matched pattern in the first pair of ()   \\E end of \\U and \\L   \\2 the matched pattern in the second pair of ()   \\e end of \\U and \\L   \\r split line in two at this point   \\9 the matched pattern in the ninth pair of ()   \\l next character made lowercase   ~ the previous substitute string   \\u next character made uppercase    Now the full S\u0026amp;R to correct non-capital words at the beginning of the sentences looks like: s:\\([.!?]\\)\\s\\+\\([a-z]\\):\\1 \\u\\2:g\nWe have used alternate separators here, the colon. We group the first section as some sort of punctuation, followed by a white space. Then, a lowercase letter. The lowercased letter is then uppercased by using the /u.\nmost DIYers can install an entire room with laminate flooring in one day. planks can be cut with a hand saw or circular saw, and most laminate flooring comes in planks that simply snap together with a tongue-and-groove system. laminate can be installed in almost every room in your home since it doesn’t have to be glued down. for additional information, download our PDF, and read below for instructions on how to install laminate flooring. ~ ~ replace with \\1 \\u\\2 (y/n/a/q/l/^E/^Y)? ## the p in planks, in the second sentence is highlighted. We have corrected our grammar and as an extra job we replaced variable number of spaces between punctuation and the first letter of the next sentence with exactly two spaces.\nExercise\nFor the following HTML color codes, group the rgb codes, and print out for each line RED: (grouped red value), GREEN: (grouped green value), BLUE: (grouped blue value)\nAqua\t#00ffff\trgb(0, 255, 255) Teal\t#008080\trgb(0, 128, 128) Blue\t#0000ff\trgb(0, 0, 255) Navy\t#000080\trgb(0, 0, 128) Alterations Using \\| you can combine several expressions into one which matches any of its components. The first one matched will be used.\n\\(Date:\\|Subject:\\|From:\\)\\(\\s.*\\)\nwill parse various mail headings and their contents into \\1 and \\2, respectively. The thing to remember about VIM alternation that it is not greedy. It won\u0026rsquo;t search for the longest possible match, it will use the first that matched. That means that the order of the items in the alternation is important!\n Quick mapping to put \\(\\) in your pattern string cmap ;\\ \\(\\)\u0026lt;Left\u0026gt;\u0026lt;Left\u0026gt;\n Regexp Operator Precedence As in arithmetic expressions, regular expressions are executed in a certain order of precedence. Here the table of precedence, from highest to lowest:\n   Precedence Regexp Description     1 \\( \\) grouping   2 \\=,\\+,*,\\{n} etc. quantifiers   3 abc\\t\\.\\w sequence of characters/ metacharacters, not containing quantifiers or grouping operators   4 \\| alternation    Resources  https://regexr.com/ https://www.regular-expressions.info/  "
},
{
	"uri": "/software-eng-essentials/patterns/",
	"title": "Software Patterns",
	"tags": [],
	"description": "",
	"content": "Welcome to Software Patterns "
},
{
	"uri": "/javascript/foundations/variable-scope/",
	"title": "Variable Scope",
	"tags": [],
	"description": "",
	"content": "Learn the rules of variable scope in JavaScript.\nObjectives  Define scope in the context of programming Describe the rules of scope in Javascript Describe the impact of hoisting on variable scope Discuss the scoping rules for variables declared with var, let, and const  What is Scope?  Scope is the part of the program where a variable is valid and accessible. You can think of the scope as the lifetime of the variable (where in the program the variable is born and where it dies or is discarded). In other words, scope is where a variable can be referenced or used.  Let’s say you define a variable greeting\nconst greeting = \u0026#39;Hello\u0026#39;; console.log(greeting); // \u0026#39;Hello\u0026#39; No problems here, but what if we change it to this:\nif (true) { const greeting = \u0026#39;Hello\u0026#39;; } console.log(greeting); // ReferenceError: greeting is not defined In this example JavaScript throws a ReferenceError: greeting is not defined.\nWhy does this happen?  The if code block creates a block scope for the greeting variable. Thus the greeting variable can only be accessed within the block.  Therefore:\n The accessibility of variables is limited by the scope where they are created. Outside of its scope, the variable is inaccessible (it is \u0026ldquo;out of scope\u0026rdquo;).  Rules of Scope in JS In Javascript, there are four types of scope:\n Global - visible by everything Function - visible within a function (and its sub-functions and blocks) Block - visible within a block (and its sub-blocks) Module - visible within a module  NOTE: Sometimes the term local scope is used for scopes that are not global.\nHow Is Scope Determined? The scope of a variable is determined by the following:\n How the variable was declared:  var - global or function scope let - block scope const - block scope implicit (no keyword) - global scope   Where the variable was declared (global, function, or block)  Block Scope A code block in JavaScript defines a scope for variables declared using let and const:\nif (true) { // the `if` block creates a block scope  const greeting = \u0026#39;Hello\u0026#39;; // `greeting` is only accessible inside the block  console.log(greeting); // \u0026#39;Hello\u0026#39; } console.log(greeting); // throws a ReferenceError Here is another example of a block scope created by a for loop:\nfor (const color of [\u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;]) { // \u0026#34;for\u0026#34; block scope  const message = \u0026#39;Hi\u0026#39;; console.log(color); // \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;  console.log(message); // \u0026#39;Hi\u0026#39;, \u0026#39;Hi\u0026#39;, \u0026#39;Hi\u0026#39; } console.log(color); // throws ReferenceError (`color` is out of scope) console.log(message); // throws ReferenceError (`message` is out of scope) var is not block scoped  Variables declared with the var keyword are not scoped to a block Instead they are scoped to the enclosed function or are global if there is no enclosing function This is referred to as hoisting.  Example:\nfunction logCount() { if (true) { // \u0026#34;if\u0026#34; block scope  var count = 0; console.log(count); // 0  } console.log(count); // 0 (No ReferenceError as `count` was hoisted to the enclosing function) } The following code is equivalent to the above code:\nfunction logCount() { var count; // `count` gets hoisted because it is declared with `var`  if (true) { // \u0026#34;if\u0026#34; block scope  count = 0; console.log(count); // 0  } console.log(count); // 0 (No ReferenceError as `count` was hoisted to the enclosing function) } Avoid Hoisting and the var keyword WARNING: hoisting can be problematic as these variables leak out of their inner block scope into the function scope. Therefore you should avoid using var when creating variables and use the newer let and const keywords instead.\nLet\u0026rsquo;s say that again:\nTIP: Use let and const over var in all of your variable declarations. Avoiding hoisting produces code that is easier to understand and maintain.\nFunction scope  Functions, like blocks, create a local scope. Nested functions also create nested scopes.  Study the code below and determine where each variable can be accessed and used.\nconst president = \u0026#34;Everyone knows me. Globally!\u0026#34;; function town() { const mayor = \u0026#34;I\u0026#39;m unknown outside of my township.\u0026#34;; function house() { const homebody = \u0026#34;No one knows me. \u0026#34; + \u0026#34;I don\u0026#39;t leave home. \u0026#34; + \u0026#34;but I know the mayor and the president.\u0026#34;; } evilLeader = \u0026#34;I am evil! Want to know why?\u0026#34;; } Reviewing the code starting from the innermost scoped functions and variables down to the global context of the program, we can determine that variable scope looks like this:\n   scope variables declared in scope outer variables also accessible by scope     house homebody mayor, house, evilLeader, president, town   town mayor, house, evilLeader president, town   global president, town     Module scope NOTE: This section is optional.\nWhat is a Module?  A JavaScript module is a JavaScript source file that exports some variables, functions, or classes for use by other JavaScript source files. Modules can be used in NodeJS. Modules can also be used in web client (browser) applications if the proper preprocessing is done (such as by a tool like Webpack).  Modules and Scope  ES2015 modules also create a scope for variables, functions, and classes. The module scope makes the module encapsulated. Every private variable (that’s not exported) remains an internal detail of the module, and the module scope protects these variables from being accessed outside.  Example: math.js\nconst PI = 3.14159; // PI is private, scoped only inside this module  function square(x) { // square is private  return x * x; } function areaOfCircle(radius) { // areaOfCircle is exported  return PI * square(radius); } module.exports = { areaOfCircle }; Using the module:\nconst { areaOfCircle } = require(\u0026#39;./math\u0026#39;); console.log(areaOfCircle(3)); // 28.27431 Global Scope  The global scope is the outermost scope. It is accessible from any inner (aka local) scope. Variables defined outside of any function are inherently global even if the var, let, or const keyword is used! Variables that are not declared with a keyword but are simply assigned a value are global even if they are first introduced inside a function.  Example\nconst pi = 3.14159; // global: declared outside of any function or block function doSomething() { var x = 3; // local  y = 5; // global because there is no `var`, `let`, or `const` keyword!  return (x + y) * pi; } TIP: Avoid global variables. Always use a let or const to declare your variables.\nSummary  The scope manages the accessibility of variables. A variable defined inside a scope is accessible only within that scope. In JavaScript, scopes are created by code blocks, functions, and modules. Variables declared with const and let are scoped by code blocks, functions or modules. Variables declares with var are scoped only by functions or modules. Scopes can be nested. Inside an inner scope you can access the variables of an outer scope.  Additional Resources  Understanding Scope and Context in JavaScript Everything you wanted to know about JavaScript scope What is the Scope of Variables in JavaScript? | Stack Overflow  "
},
{
	"uri": "/web-essentials/webmastery-foundations/frameworks-lab/",
	"title": "CSS Frameworks Labs",
	"tags": [],
	"description": "",
	"content": "  Create your html document\n At the top of the \u0026lt;body\u0026gt; wrap an \u0026lt;h1\u0026gt; in a \u0026lt;div\u0026gt; and insert the content \u0026lsquo;Good Coffee Co.\u0026rsquo; Create another \u0026lt;div\u0026gt; and with class titled: \u0026lsquo;mission\u0026rsquo;  Create an \u0026lt;h3\u0026gt; and insert: \u0026quot;Here at Good Coffee Co we are passionate about serving the best coffee you'll ever taste. Our staff are self-described coffee-nerds with impeccable technique. Stop by today and experience the Good Coffee difference.\u0026quot;      Create a new \u0026lt;div\u0026gt; with a class named: \u0026lsquo;features\u0026rsquo;\n Create 3 separate paragraphs Inside those paragraphs place the following text: + \u0026quot;The freshest locally sourced coffee. Organic and Fair Trade certified.\u0026quot; + \u0026quot;A perfect environment to meet with a friend or be alone and get things done.\u0026quot; + \u0026quot;Quality hand-crafted espresso shots pulled with the greatest of care.\u0026quot;    Your page should look like this: The Footer Okay, let\u0026rsquo;s go ahead and put in the text for the footer as well.\n  Create a \u0026lt;footer\u0026gt;\n  Nest a \u0026lt;p\u0026gt; element in the \u0026lt;footer\u0026gt;\n Insert a copyright symbol Add the text: + \u0026quot;Good Coffee Co. 2017\u0026quot;    Nest an unordered list inside the \u0026lt;footer\u0026gt;\n Give the list 3 list items About Location Coffee Turn those list items into links + (hint: point the link to a \u0026ldquo;#\u0026quot;)    Close out the \u0026lt;footer\u0026gt; and refresh!\n  Result: Okay! we\u0026rsquo;re well on our way to having a great site. The last bit of structure that we need is a navbar.\nThe Navbar  At the top of the \u0026lt;body\u0026gt; create a \u0026lt;nav\u0026gt; element. + The nav is an HTML 5 element that serves as an accessibility feature for screen readers. Additionaly, it helps the developer with code-readability Like you did with the \u0026lt;footer\u0026gt;, you\u0026rsquo;ll want to create an unordered list and nest the following list items:  Coffee Mission Fair Trade Coffee Gear    The Result:\nNote: If you didn\u0026rsquo;t include the links, don\u0026rsquo;t worry about it. We\u0026rsquo;ll be modifying the navbar pretty significantly in just a few minutes.\nAnd that\u0026rsquo;s it! We are done with the structure. Now we can install bootstrap and start styling the page.\nSetting up Bootstrap Okay, so we\u0026rsquo;ve briefly discussed what bootstrap is and what it does, but how do we install it into our project?\nWell\u0026hellip; that\u0026rsquo;s for you to figure out\u0026hellip;\nAdd Bootstrap to your project There are several ways to include bootstrap in your project. Which one is correct? Well\u0026hellip; it depends on the project. We are going to use a CDN (content delivery network) which is my preferred method and will work fine for this project.\n Go the getting started section of the bootsrap documentation. Review the Bootstrap CDN section and take the appropriate actions  Let\u0026rsquo;s go ahead and install JavaScript as well. + Inside your \u0026lt;head\u0026gt; paste the following:\n\u0026lt;!-- Latest compiled and minified CSS --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css\u0026#34; integrity=\u0026#34;sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;!-- Optional theme --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css\u0026#34; integrity=\u0026#34;sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;!-- Latest compiled and minified JavaScript --\u0026gt; \u0026lt;script src=\u0026#34;https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js\u0026#34; integrity=\u0026#34;sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Latest jQuery (without OldIE support--\u0026gt; \u0026lt;script src=\u0026#34;https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Add your own stylesheet One more thing\u0026hellip; this doesn\u0026rsquo;t necessarily relate to bootstrap, but let\u0026rsquo;s go ahead and create our main stylesheet (for custom styling). And you know how we roll, so go ahead and do all of this from the command line.\nfrom your project directory, create a new css directory\n$ mkdir css navigate to the directory\n$ cd css create the file\n$ touch main.css navigate back to the root of your project\n$ cd .. Now link the file to your index.html\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/main.css\u0026#34; media=\u0026#34;screen\u0026#34; title=\u0026#34;no title\u0026#34; charset=\u0026#34;utf-8\u0026#34;\u0026gt; Make sure you place this after the bootstrap link\nNow that we have everything setup, go ahead and refresh your page.\nYou\u0026rsquo;ll notice that our page has been \u0026lsquo;normalized\u0026rsquo; (or reset). A browser reset is baked into bootstrap. yay!\nNav - the bootstrap way Okay\u0026hellip; that navbar has to change\u0026hellip; like\u0026hellip; now\u0026hellip; So, let\u0026rsquo;s do that.\nInstall the navbar  Go to the navbar section of bootstrap\u0026rsquo;s documentation. READ Start with applying the basic navbar to our site. + (Don\u0026rsquo;t worry about the content right now)  Here\u0026rsquo;s what it should look like: Now let\u0026rsquo;s add our custom links and make some slight modifications.\nCustomize the navbar  Find and change \u0026lsquo;Brand\u0026rsquo; to the name of the company Find and replace the two \u0026lsquo;Links\u0026rsquo; on the left with:  Coffee Mission Refresh here\u0026rsquo;s what you should have:    Now, remove the left dropdown menu and \u0026lt;form\u0026gt; (search bar and submit button) modify the items on the right to say:  Fair Trade Coffee Gear   Invert the color  The Result: Go ahead and delete the original nav (as we no longer need it).\nFont and Color Font The instructor team has already picked out a font from google fonts, so let\u0026rsquo;s go ahead and add that into our project\nIn the \u0026lt;head\u0026gt; of your html document, paste the following:\nindex.html\n\u0026lt;!-- font family below --\u0026gt; \u0026lt;link href=\u0026#34;http://fonts.googleapis.com/css?family=Muli|Raleway:400,500,700|Yanone+Kaffeesatz\u0026#34; rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34;\u0026gt; css/main.css\nbody { font-family: \u0026#39;Raleway\u0026#39;, \u0026#39;sans-serif\u0026#39;; } Color Scheme The instructor team has also picked out a color scheme (feel free to change it up)\nWe\u0026rsquo;ll be using #A2DED0 as our primary color. + #323232 and #D64541 will be our secondary colors.\nGo ahead and apply the primary color to the background of our \u0026lt;body\u0026gt;.\nOkay, it\u0026rsquo;s already starting to feel better. Next up. the hero image!\nNow would be a good time to switch!\nJumbotron If you look at most well-designed websites, you\u0026rsquo;ll see some kind of hero image and/or captivating header at the top of the page. This is often called a hero image. In bootstrap we\u0026rsquo;ll use the .jumbotron class to style our hero image.\nFirst let\u0026rsquo;s start with a picture. You can use this URL and link to it directly in your CSS. Or create an images directory and store the image there. + the second option is preferred.\nHero Image Add your hero image  Just like we created the css directory. Create an images directory Assign the class \u0026quot;jumbotron\u0026quot; to the \u0026lt;div\u0026gt; surrounding your \u0026lt;h1\u0026gt; In your css, use the background-image property to display the hero image. (hint: use css documentation if you need help with the background image)  From your project root run: $ mkdir images\nindex.html\n\u0026lt;div class=\u0026#34;jumbotron\u0026#34;\u0026gt; \u0026lt;h1\u0026gt; Good Coffee Co.\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; .css/main.css\n.jumbotron { background-![]( url(\u0026#34;./images/Drip_Coffee_Bangkok.jpg\u0026#34;); } If you refresh\u0026hellip; it isn\u0026rsquo;t pretty. let\u0026rsquo;s fix that.\nStyle your hero image   For the image\u0026hellip; within the .jumbotron declaration:\n set the background-repeat to no-repeat set the background-size to cover assign a width of 100%    Position the image\n draw the top margin up by 40px padding (on all sides) = 20% background-attachment = fixed background-position = center -238px Save and Refresh! At this point, your page should should look like:     Now we need to style the \u0026lt;h1\u0026gt;\n set the position to absolute move it 0 left assign a top margin of -10px assign left padding of 20px give the font a color of #F7FAFE Save and refresh!    You should have something like this:\nContainers Let\u0026rsquo;s talk about containers for a moment. + With most web design, you\u0026rsquo;re going to want to establish very clear containers for groups of elements. \u0026lt;div\u0026gt;'s serve for this purpose. However, what about when you want to group a set of \u0026lt;div\u0026gt;'s together?\nYour best bet is to establish a container \u0026lt;div\u0026gt;\nSo, we\u0026rsquo;re going to create a some containers.\ncontainer-fluid  Add a class of \u0026lsquo;container-fluid\u0026rsquo; to your \u0026lsquo;mission\u0026rsquo; \u0026lt;div\u0026gt;  Nest a \u0026lt;div\u0026gt; with the class of \u0026lsquo;row\u0026rsquo;  Move your \u0026lt;h3\u0026gt; inside of the \u0026lsquo;row\u0026rsquo; \u0026lt;div\u0026gt;   directly above your \u0026lt;h3\u0026gt; paste the following code \u0026lt;a name=\u0026quot;mission\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; + (this allows us to navigate around the page)   Style the mission \u0026lt;div\u0026gt;!  Set the background color to #323232 Set the text color to #F7FAFE Move the top margin up by 30px   Specifically style the \u0026lt;h3\u0026gt;  set a padding of 5% top/bottom and 10% left/right center the text    The Result:\nNext up the Grid!\nThe Grid As previously discussed, one of the best features of using front-end frameworks is the grid system. Grid\u0026rsquo;s allow for much easier positioning than working with standard css positioning.\nTo recap: Divide the page into 12 columns (this is the default number of columns in Bootstrap). and then move content along those columns. This makes laying out your content incredibly simple (and helps with responsive design). So it\u0026rsquo;s a win-win.\nSetting up your grid Using the Bootstrap Grid Documentation\n Add the container class to your features \u0026lt;div\u0026gt; Wrap each \u0026lt;p\u0026gt; in it\u0026rsquo;s own \u0026lt;div\u0026gt; Nest all of your new \u0026lt;div\u0026gt; \u0026rsquo;s within one row \u0026lt;div\u0026gt; Using bootstrap\u0026rsquo;s grid make each column \u0026lt;div\u0026gt; (within the row) span:  12 columns on extra small devices. 4 columns on small devices (and up)    The Result:\nWe\u0026rsquo;re getting there!\nFeature Images  Add the following pictures to your images folder  coffee beans  coffee_shop  espresso  In the html, create an \u0026lt;img\u0026gt; tag for each div (containing a paragraph) and change src attribute to display your new images. Save and refresh    image-responsive Got it?\nYeah\u0026hellip; it\u0026rsquo;s bad\u0026hellip; real bad\u0026hellip; the images are being displayed at their stock resolution. Thankfully, bootstrap offers a class that easily fixes this to make the images respond to the grid.\nsimply assign the class \u0026lsquo;img-responsive\u0026rsquo; to your \u0026lt;img\u0026gt; element like so: \u0026lt;img class=\u0026quot;img-responsive\u0026quot;\u0026gt;\nAfterwards. Your page should look like this:\nStyle the containers Nice! Now we just need to add a touch of styling and this container is good-to-go!\n Set the features\u0026rsquo; container padding to 5% top/bottom and 0 left/right For the paragraphs:  Change the font to \u0026lsquo;Muli\u0026rsquo; with a fallback of \u0026lsquo;sans-serif\u0026rsquo; align the text to center set the font size to 1.2em give a top padding of 10px change the color to #323232   Save and refresh  You should see something like this:\nThe Footer Unlike most of our other items. The majority of our footer work is going to be completed using vanilla css. Ugh! I know\u0026hellip;\nPosition and Color  Set the background color to: #D64541 Set a position of absolute width = 100% set the height to auto (to take care of unforseen viewport issues) +  Style each list item  Set the display to inline-block strip the bullets off of each list item set a padding of 2% all-around float these items to the right +    Float each paragraph left and give a padding of 2% For the links and paragraphs  set the vertical alignment to middle change the text-color to #fff   Save and refresh!  That\u0026rsquo;s it! you\u0026rsquo;ve created a site using bootstrap!\nExtra Credit Animate!  Go checkout animate.css Download the file and move it into your project (place it inside the css directory) link your index.html to the new stylesheet (make sure to place it under your main.css link) add the value \u0026lsquo;animated fadeInDown\u0026rsquo; to your \u0026lt;h1\u0026gt;  Modal  Check out the modal section in Bootstrap\u0026rsquo;s docs. Inside your navbar, paste the appropriate modal code after your \u0026lsquo;Fair Trade\u0026rsquo; \u0026lt;li\u0026gt; Change the id from myModal to videoModal In your Fair Trade\u0026lt;li\u0026gt;  Create a data-toggle attribute with the value of \u0026ldquo;modal\u0026rdquo; Crate a data-target attribute with the value of \u0026ldquo;#videoModal\u0026rdquo;   Remove the title, button and footer Inside the modal body place the following code: \u0026lt;iframe width=\u0026quot;100%\u0026quot; height=\u0026quot;350\u0026quot;src=\u0026quot;http://www.youtube.com/embed/7K4G5-ydhS0\u0026quot;\u0026gt;\u0026lt;/iframe\u0026gt; Add some comments above and below your modal (signifying start and end) for better readability.  That\u0026rsquo;s it! now you should have a fancy Fair Trade modal.\n"
},
{
	"uri": "/javascript/foundations/arrow-functions/",
	"title": "Arrow Functions",
	"tags": [],
	"description": "",
	"content": "An introduction to function expressions and arrow functions.\nFunction Expressions Before introducing arrow functions, let\u0026rsquo;s first discuss function expressions.\n In JavaScript, functions are first-class citizens. This means that they can be treated as expressions, and thus:  assigned to variables passed as arguments to other functions returned from functions    Here is an example of assigning a function to a variable:\nconst adder = function(a, b) { return a + b; }; console.log(adder(3, 5)); // 8 Here is another example where we pass a function expression to the Array.filter method:\nconst numbers = [12, -5, 3, 7, -9]; const positives = numbers.filter(function(n) { return n \u0026gt; 0; }); console.log(positives); // [ 12, 3, 7 ] Each of these examples can also be written as an Arrow function as follows:\nconst adder = (a, b) =\u0026gt; a + b; console.log(adder(3, 5)); // 8 and\nconst numbers = [12, -5, 3, 7, -9]; const positives = numbers.filter(n =\u0026gt; n \u0026gt; 0); console.log(positives); // [ 12, 3, 7 ] Arrow Functions ES2015 Introduced us to Arrow Functions, a new way to write function expressions.\nThe syntax of an arrow function is as follows:\nconst myFunction = (a, b) =\u0026gt; { // do something with a and b }; Notice that Arrow Functions:\n are function expressions place the parameter first use a fat arrow =\u0026gt;  Parameters Arrow functions may have no parameters:\nconst noParams = () =\u0026gt; { // do something }; Arrow functions may have a single parameter:\nconst oneParamWithParens = x =\u0026gt; { // do something with x }; const oneParamWithoutParens = x =\u0026gt; { // this also works }; NOTE: Arrow functions with a single parameter don\u0026rsquo;t require parentheses.\nArrow functions may have multiple parameters.\nconst multipleParams = (x, y) =\u0026gt; { // do something with x and y }; Implicit Returns When the body of an arrow function is not wrapped in braces, the arrow function will implicitly return the value evaluated in its function body.\nFor example:\nconst sum = (x, y) =\u0026gt; x + y; // the result of `x + y` is returned by the arrow function is equal to:\nconst sum = (x, y) =\u0026gt; { // if we add the braces  return x + y; // we must also add the `return` keyword } When to Use Arrow Functions You can use an arrow function whenever:\n you need to use a function expression, such as when passing a function to another function or returning a function from a function. you need lexical binding of the this object - more on this later  Lab See instructions here.\nSummary  JavaScript supports functions as expressions that can be:  assigned to variables passed as arguments returned from functions   Arrow functions provide a succinct way to define function expressions  "
},
{
	"uri": "/python/foundation/boolean-labs/",
	"title": "Boolean Labs",
	"tags": [],
	"description": "",
	"content": "Boolean Exercise In partners or groups of three, rotate through the following list and explain why you think each would evaluate to True or False\nOnce you\u0026rsquo;ve come to a decision, type out the expression in Python Console and check to see if you were correct.\nTrue and True False and True 1 == 1 and 2 == 1 \u0026#34;test\u0026#34; == \u0026#34;test\u0026#34; 1 == 1 or 2 != 1 True and 1 == 1 False and 0 != 0 True or 1 == 1 \u0026#34;test\u0026#34; == \u0026#34;testing\u0026#34; 1 != 0 and 2 == 1 \u0026#34;test\u0026#34; != \u0026#34;testing\u0026#34; \u0026#34;test\u0026#34; == 1 not (True and False) not (1 == 1 and 0 != 1) not (10 == 1 or 1000 == 1000) not (1 != 1 or 3 == 4) not (\u0026#34;testing\u0026#34; == \u0026#34;testing\u0026#34; and \u0026#34;Ronny\u0026#34; == \u0026#34;Gool Guy\u0026#34;) 1 == 1 and not (\u0026#34;testing\u0026#34; == 1 or 1 == 0) \u0026#34;chunky\u0026#34; == \u0026#34;bacon\u0026#34; and not (3 == 4 or 3 == 3) 3 == 3 and not (\u0026#34;testing\u0026#34; == \u0026#34;testing\u0026#34; or \u0026#34;Python\u0026#34; == \u0026#34;Fun\u0026#34;) Go to Strings Lesson\n"
},
{
	"uri": "/javascript/foundations/labs/closures-lab/",
	"title": "Closures Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch closures.js Add the following code to closures.js:\n/** * TODO: Fix this function to protect `name` and `state` so that * we cannot modify them from outside the `next` method. * When you are done the `next` method will be a closure. * HINT: Use local variables `_name` and `_state` to store the name and state. * Also remove any references to`this` and use the bound variables instead. **/ function makeTrafficLight(name) { let light = { name: name, state: \u0026#39;red\u0026#39;, next: function () { switch (this.state) { case \u0026#39;red\u0026#39;: this.state = \u0026#39;green\u0026#39;; break; case \u0026#39;green\u0026#39;: this.state = \u0026#39;yellow\u0026#39;; break; case \u0026#39;yellow\u0026#39;: this.state = \u0026#39;red\u0026#39;; break; default: throw new Error(`why is the state = ${this.state}`); } }, toString: function () { return `${this.name}is ${this.state}`; } }; return light; } // NOTE: you shouldn\u0026#39;t need to change any of the code below. try { let mainAndFirst = makeTrafficLight(\u0026#39;Main Street and First Ave.\u0026#39;); console.log(mainAndFirst.toString()); // red  mainAndFirst.next(); console.log(mainAndFirst.toString()); // green  mainAndFirst.state = \u0026#39;purple\u0026#39;; // trouble?  console.log(mainAndFirst.toString()); // purple???  mainAndFirst.next(); // throws an Error  console.log(mainAndFirst.toString()); // we never get here  mainAndFirst.next(); console.log(mainAndFirst.toString()); } catch (error) { console.log(\u0026#39;ERROR:\u0026#39;, error.message); } When running the above code you should get the following output:\nMain Street and First Ave. is red Main Street and First Ave. is green Main Street and First Ave. is purple ERROR: why is the state = purple Step 2: Fix the code and test Complete the TODO in the above code.\nTest your solution with:\nnode closures.js You should not get any runtime errors. The expected output is:\nMain Street and First Ave. is red Main Street and First Ave. is green Main Street and First Ave. is green Main Street and First Ave. is yellow Main Street and First Ave. is red "
},
{
	"uri": "/java/foundations/data-structures-advanced/",
	"title": "Data Structures Advanced",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts \u0026amp; Skills Creating and using:\n Lists: Linked Stacks Queues   There are many Data Structures in Java. We are going to hit on just some of the more advanced ones in this section. All of the following data structures work with non-primitive data types.\nLinkedLists LinkedLists are doubly-linked list implementation of the List and Queue interfaces.\nLinkedLists are an ordered collection where the elements are not stored in adjacent locations and every element is a separate object with a data part and address part. The elements are linked using pointers and addresses. Each element is known as a node.\nJava LinkedLists:\n Each element is known as a node. Each node stores a pointer to the address of both the previous and next node. can contain duplicate elements. maintains insertion order.  To use LinkedLists, you must import java.util.LinkedList.\nTo declare a LinkedList, you first need to say LinkedList followed by what non-primitive type is going to be stored, surrounded by angle brackets.\nLinkedList\u0026lt;String\u0026gt; alphabet; The data type the initialization is implied because it was declared during declaration. This is why the angle brackets are empty in the below example.\nalphabet = new LinkedList\u0026lt;\u0026gt;(); The parenthesis are invoking LinkedList\u0026rsquo;s default constructor which returns the actual instance of an LinkedList. When using the default constructor, an LinkedList has zero values within it.\nLength int y = alphabet.size(); The above example gets the LinkedList\u0026rsquo;s length: the number of nodes that are in the LinkedList.\nAdding You are able to change the size of an LinkedList.\nSay alphabet had the following values:\n   Index Value     0 A   1 B   2 C   3 D    Adding the value E to the beginning of alphabet:\nalphabet.push(\u0026#34;E\u0026#34;); This adds 1 the length of an LinkedLists, and inserts the value of E in the last index of the LinkedList.\nThis would change alphabet to look like:\n   Index Value     0 E   1 A   2 B   3 C   4 D     Adding the value D to the end of alphabet:\nsalaries.add(\u0026#34;D\u0026#34;); This adds 1 the length of an LinkedLists, and inserts the value of E in the last index of the LinkedList.\nThis would change alphabet to look like:\n   Index Value     0 A   1 B   2 C   3 D   4 D    To add the value E at index 2:\nalphabet.add(2, \u0026#34;E\u0026#34;); alphabet is now updated to:\n   Index Value     0 A   1 B   2 E   3 C   4 D    Removing It is possible to remove elements from a LinkedList. If the LinkedList does not contain the element you are trying to remove, an error does not occur and it remains unchanged.\nSay alphabet has the following values:\n   Index Value     0 A   1 B   2 C   3 D   4 C   5 E     You can remove and retrieve the first element with:\nString i = alphabet.remove(); i would have the value of A.\nThis subtracts 1 the length of the LinkedList. This would change salaries to look like:\n   Index Value     0 B   1 C   2 D   3 C   4 E     You can remove and retrieve an element at a specific index (in this case (index 2) with:\nString i = alphabet.remove(2); i would have the value of D.\nThis would change alphabet to look like:\n   Index Value     0 B   1 C   2 C   3 E     You can remove the first occurrence of an element with the value (in this case (the value C) with:\nboolean isPresent = alphabet.remove(\u0026#34;C\u0026#34;); isPresent would have the value of true.\nThis would change alphabet to look like:\n   Index Value     0 B   1 C   2 E     You can remove and retrieve the first element from a LinkedList:\nString i = alphabet.removeFirst(); i would have the value of B.\nThis would change alphabet to look like:\n   Key Value     0 C   1 E     You can remove and retrieve the last element from a LinkedList:\nString i = alphabet.removeLast(); i would have the value of E.\nThis would change alphabet to look like:\n   Key Value     0 36500    Setting Setting the value at position 2 (the third element) to 30000 looks like:\nalphabet.set(2, \u0026#34;F\u0026#34;); Getting Getting the value that is at position 3 in alphabet:\nString x = alphabet.get(3);  Getting the value that is at the head (first element) in alphabet:\nString y = alphabet.getFirst(); If alphabet was empty, you would receive a NoSuchElementException.\nTo avoid this Exception, you can use:\nString i = alphabet.peekFirst(); This will just return null if the list is empty.\n Getting the value that is at the last element in alphabet:\nString z = alphabet.getLast(); If alphabet was empty, you would receive a NoSuchElementException.\nTo avoid this Exception, you can use:\nString i = alphabet.peekLast(); This will just return null if the list is empty.\nIterating It is possible to iterate through a LinkedList with a basic for loop:\nfor(int i = 0; i \u0026lt; alphabet.size(); i++){ System.out.println(alphabet.get(i)); } foreach loop\nUsing a foreach loop, you can loop through a LinkedList very similarly to an ArrayList.\nfor(String letter : alphabet){ System.out.println(letter); } ListIterator Methods\nLinkedLists have a listIterator method, which returns a list-iterator (interface in java.util. A ListIterator is an iterator for lists that allows the programmer to traverse the list in either direction, modify the list during iteration, and obtain the iterator\u0026rsquo;s current position in the list.\nSome of ListIterator methods are:\n hasNext(): returns if list-iterator has another node. next(): returns and moves to the next node. hasPrevious(): returns if list-iterator has a previous node. previous(): returns and moves to the next node.  Using these methods to iterate over salaries looks like:\nListIterator salariesIter = salaries.listIterator(2); while(salariesIter.hasNext()){ System.out.println(salariesIter.next()); }  Unordered Data Structure While many of the most common collections involve indexing elements for reference, there are several useful data structures that do not. The following structures either do not utilize indexes or you do not use the index of an item to get and set it.\nStack  The Stack class represents a last-in-first-out (LIFO) stack of objects.\n A LIFO style of data management means that as you add to your collection, you only have visibility to one item: whatever was last added (the \u0026ldquo;top\u0026rdquo; of the stack).\n ☝️ Recognize this logo?\nWhy do you think they chose a stack?\n One of the most common implementations of a stack is the memory stack.\nStack\u0026lt;String\u0026gt; tasks; tasks = new Stack\u0026lt;\u0026gt;(); The declaration and instantiation should look familiar by now. We declare our variable will be a Stack that will hold String objects and when we instantiate it the type is implied.\nLength int y = salaries.size(); The above example gets the Stack\u0026rsquo;s length: the number of elements that are in the Stack.\nThere is a method to check if a Stack is empty:\nboolean done = tasks.empty(); Adding tasks.push(\u0026#34;checkOut\u0026#34;);     stack     top checkOut    You can only add items to the top of the stack. The convention for this method is push. If you add another item, any existing items get pushed further into the stack.\ntasks.push(\u0026#34;scanItem\u0026#34;);     stack     top scanItem    checkOut    Getting The only item in a stack you have access to is the top but there are a couple different ways to access that item.\nString nextTask = tasks.peek(); When you peek at the stack you are able to capture the value of the item without altering the stack. After running the above statement nextTask = \u0026quot;scanItem\u0026quot; and our stack looks like:\n    stack     top scanItem    checkOut    String currentTask = tasks.pop(); When you pop a stack, it removes the top item and returns it. After running the above statement currentTask = \u0026quot;scanItem\u0026quot; and our stack looks like:\n    stack     top checkOut    Iterating You cannot use a basic for loop with a Stack.\nUsing a foreach loop, you can loop through a Stack very similarly to a LinkedList\nfor(String task: tasks){ System.out.println(task); } Iterator Methods\nTo use a foreach loop, you can use stack\u0026rsquo;s iterator method and Iterator\u0026rsquo;s next and hasNext methods.\n iterator(int): returns an iterator (interface in java.util) of the elements in this list (in unordered sequence), starting at the specified position in the list. hasNext(): returns if the iterator has another node. next(): returns and moves to the next node.  Using these methods to iterate over tasks looks like:\nIterator tasksIter = tasks.iterator(); while(tasksIter.hasNext()){ System.out.println(tasksIter.next()); } Queue A queue is very similar to a stack except that is uses the Last In Last Out (LILO) method of data management just like the queues you stand in.\nLength int y = tasks.size(); The above example gets the Queue\u0026rsquo;s length: the number of items that are in the Queue.\nAdding tasks.offer(\u0026#34;find wood screws\u0026#34;);     queue     head find wood screws    You can only add items to the end of the queue. The convention for this method is offer. If you add another item, it will be placed under all existing items in the queue.\ntasks.offer(\u0026#34;find drill bit\u0026#34;);     queue     head find wood screws    find drill bit    Getting You can only view the item at the head of the queue but there are a couple different ways to access that item.\nString nextTask = tasks.peek(); When you peek at the queue you are able to capture the value of the item at the head without altering the queue. After running the above statement nextTask = \u0026quot;find wood screws\u0026quot; and our queue looks like:\n    queue     head find wood screws    find drill bit    String currentTask = tasks.poll(); When you poll a queue, it removes the head item and returns it. After running the above statement currentTask = \u0026quot;find wood screws\u0026quot; and our queue looks like:\n    queue     head find drill bit    Iterating Just like Stack, you cannot use a basic for loop with a Queue.\nUsing a foreach loop, you can loop through a Queue very similarly to a Stack\nfor(String task: tasks){ System.out.println(task); } Iterating Methods\nLike a Stack, you cannot use a basic for loop with a Queue. Instead, you must use a foreach loop. To use a foreach loop, you can use Queue's iterator method and Iterator\u0026rsquo;s next and hasNext methods.\n iterator(int): returns an iterator (interface in java.util) of the elements in this list (in unordered sequence), starting at the specified position in the list. hasNext(): returns if the iterator has another node. next(): returns and moves to the next node.  Using these methods to iterate over tasks looks like:\nIterator tasksIter = tasks.iterator(); while(tasksIter.hasNext()){ System.out.println(tasksIter.next()); } Summary Java has many options when it comes to storing and organizing data. The above advanced Data Stuctures are more specialized like the LIFO Stack or the LILO Queue. It\u0026rsquo;s important to understand what your needs are in order to know what structure best solves your problem.\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/dom-intro/",
	"title": "Intro to the DOM",
	"tags": [],
	"description": "",
	"content": "HTML \u0026amp; The DOM HTML and DOM are related but separate concepts.\n HTML: the language used to create an HTML Web Page / Document DOM: the Document Object Model, i.e. the in-memory representation of the HTML page created when the browser renders the HTML document.   The DOM begins as a direct interpretation of the HTML document, but it can be modified (manipulated) after the page is loaded via JavaScript code running in the browser (more on that later).\n Demo DOM manipulation is in the next lesson, but to demonstrate the difference between an HTML document and the DOM that is created from the HTML document, go to the ESPN web site and play around with some headlines.\nUsing the Chrome DevTools Inspector, alter something on the page.\nThen go to Austin Craigslist and try running the following javascript DOM manipulation code in the JavaScript console:\ndocument.getElementById(\u0026#39;logo\u0026#39;).children[0].text = \u0026#39;MikesList\u0026#39;; document.getElementsByClassName(\u0026#39;ban\u0026#39;)[0].children[0].text = \u0026#39;More Saving. More Doing.\u0026#39; Questions:\n Did I just hack Craigslist? What happens if I refresh the page? What am we actually changing - the HTML or the DOM?  What is the DOM? A browser receives a page as HTML and creates a model and stores it in memory creating a Document Object Model (a.k.a. the DOM tree).\nThe DOM is a tree data structure that represents a web document consisting of parent and child nodes.\nThe DOM has properties, methods, and events. The DOM has elements, each of which is an object that can be accessed and modified independently of other content.\nThe document object sits at the root of the tree (it has no parent).\nWhen an HTML file is loaded into a browser, the browser interprets the HTML and displays the document in a window.\nIn the console, type document. and check out the available methods.\n Try document.title and document.body.children[0]. Try getting elements by class or id or tag name. Try document.write('More Saving. More Doing.')  Like the ESPN example, the HTML can be changed in the inspector but when its re-rendered the changes are gone.\nWindow Objects A window object is all browser windows or tabs. The location property is the URL of the page.\n In the console, type window. an check out the available methods. Try window.location and window.document.write('Hello'). Try pointing out localStorage.  HTML vs. DOM Vocabulary    HTML DOM Example     tag / element node \u0026lt;p\u0026gt; This is a paragraph \u0026lt;/p\u0026gt;   attribute property \u0026lt;a href=\u0026quot;www.google.com\u0026quot; \u0026gt;Google\u0026lt;/a\u0026gt;     HTML is the source language and the DOM is the in-memory representation that the browser manages after a HTML document is loaded. A text editor is used to manipulate the HTML document and JavaScript is used to manipulate the DOM at runtime.\n "
},
{
	"uri": "/software-eng-essentials/command-line-bash/sed-and-awk/",
	"title": "Sed and Awk",
	"tags": [],
	"description": "",
	"content": "Objectives  Defining SED Introduction to the AWK Language  Defining The SED command stands for \u0026ldquo;stream editor.\u0026rdquo;\nThe SED command is very powerful. It can perform lots of functions on a file like searching, find and replace, insertion and deletion. It is most commonly used for substitution or find and replace.\nSyntax\nsed OPTIONS... [SCRIPT] [INPUT FILE]\nUsage\nSubstitution Let\u0026rsquo;s take the following file about characters from the poem Beowulf for example.\n$ cat properNames.txt Ælfhere.—A kinsman of Hrothgar. Æschere.—Confidential friend of King Hrothgar. Elder brother of Yrmenlaf. Killed by Grendel. Beowulf.—The main character. Sprung from the stock of Geats, son of Ecgtheow. Brought up by his paternal grandmother Hrethel, and figuring in manhood as a devoted liegeman of his uncle Higelac. A hero from his youth. Has the strength of thirty men. Engages in a swimming-match with Breca. Goes to the help of Hrothgar against the monster Grendel. Vanquishes Grendel and his mother. Afterwards becomes king of the Geats. Late in life attempts to kill a fire-spewing dragon, and is slain. Is buried with great honors. His memorial mound. Grendel.—A monster of the race of Cain. Dwells in the fens and moors. Is furiously envious when he hears sounds of joy in Hrothgar\u0026#39;s palace. Causes the king untold agony for years. Is finally conquered by Beowulf, and dies of his wound. His hand and arm are hung up in Hrothgar\u0026#39;s hall Heorot. His head is cut off by Beowulf when he goes down to fight with Grendel\u0026#39;s mother. Alfhere is a kinsman of Wiglaf. We need to replace Hrothgar with Wiglaf.\n$ sed *s/Hrothgar/Wiglaf* properNames.txt Double Replacement That was easy, wasn\u0026rsquo;t it? Let\u0026rsquo;s see how to make a change to two words at once. Let\u0026rsquo;s change \u0026ldquo;paternal grandmother\u0026rdquo; to \u0026ldquo;maternal grandfather.\u0026rdquo;\n$ sed *s/paternal/maternal/;s/grandmother/grandfather/* properNames.txt Global Flag /g The global flag can be used to replace all occurrences. In the next example we\u0026rsquo;ll capitalize all instances of \u0026ldquo;furious\u0026rdquo;.\n$ echo \u0026#34;Grendel is furious when he hears sounds of joy. You won\u0026#39;t like Grendel when he\u0026#39;s furious.\u0026#34; | sed *s/furious/Furious/g* Replace specific occurrence We could chose to change only the second (any nth) occurrence.\n$ echo \u0026#34;Grendel is furious when he hears sounds of joy. You won\u0026#39;t like Grendel when he\u0026#39;s furious\u0026#34; | sed *s/furious/Furious/2* Specific Lines We could chose to apply changes to specific lines. Let\u0026rsquo;s change \u0026ldquo;Killed\u0026rdquo; to \u0026ldquo;Murdered\u0026rdquo; on line two of properNames.txt.\n$ sed *2 s/Killed/Murdered/* properNames.txt Line Ranges We could also decide to apply changes to a specific range of lines. We\u0026rsquo;re going to apply parenthesis around the name Grendel in lines 3-4.\n$ sed *3,4 s/Grendel/(Grendal)/g* properNames.txt Delete lines With SED we can also quickly delete whole lines.\nLet\u0026rsquo;s delete line 2 from properNames.txt.\n$ sed *2d* properNames.txt Line two is now gone.\nExercises Execute the following command to prepare for the exercise.\n$ printf \u0026#34;This is my text file. It is mine. There is none other like it. \u0026#34; \u0026gt; myTestFile.txt  Change \u0026ldquo;mine\u0026rdquo; to \u0026ldquo;fine\u0026rdquo;, specifying the first line, using the SED command. 2.) Delete line 2.  Introduction to the AWK Language AWK is a programming language designed for text processing and typically used as a data extraction and reporting tool. It is a standard feature of most Unix-like operating systems, including macOS. There are several derivatives of AWK (NAWK = new AWK, GAWK). This lesson is specific to bash scripting and use in the command line.\nThe name stands for Aho, Weinberger and Kernighan (yes, Brian Kernighan), the authors of the language, which was started in 1977, hence it shares the same Unix spirit as the other classic *nix utilities.\nAWK is a cornerstone of UNIX programming. Many UNIX utilities output rows and columns. AWK is perfect for processing these outputs. AWK is easier to use than most programming languages, and yet very powerful. Its resembles C, as it understands the same arithmetic operators. It also contains string manipulation functions. What\u0026rsquo;s very unique is that AWK has associative arrays. It can take a complex issue and make it trivial. It can be used for one liners, or be contained in an awk file as an entire reporting script for instance.\nBasic Structure AWK commands use the following structure:\npattern { action }   Pattern: Specifies the WHEN.\n  Action: Specifies the WHAT.\n  AWK is line oriented. The pattern specifies a test that is run on each line. If true, will trigger the action. The default pattern is NULL or blank. This matches to every line.\nLet\u0026rsquo;s say we have the following CSV file,\n$ cat citytemps.csv State City Temperature Florida Miami 100 Georgia Atlanta 95 Virginia Richmond 90 Virginia Fairfax 78 We can perform a simple search like getting all the lines that contain Virginia:\n$ awk */Virginia/* citytemps.csv Virginia Richmond 90 Virginia Fairfax 78 Okay, sure we can do that with Grep. But with AWK we can do more. Let\u0026rsquo;s say we only want to print out the city and temperature.\n$ awk */Virginia/ {print $2,$3}* citytemps.csv Richmond 90 Fairfax 78 Conditionals Let\u0026rsquo;s print just the cities that have temps under or equal to 90 deg, and add some text to label them before.\nawk *{if ($3 ⇐ 90) print \u0026#34;lower or at 90\u0026#34;,$2,$3}* citytemps.csv lower or at 90 Richmond 90 lower or at 90 Fairfax 78 AWK Commands\nif ( conditional ) statement [ else statement ] while ( conditional ) statement for ( expression ; conditional ; expression ) statement for ( variable in array ) statement break continue { [ statement ] …} variable=expression print [ expression-list ] [ \u0026gt; expression ] printf format [ , expression-list ] [ \u0026gt; expression ] next exit Conditional Expressions\n   Operator Meaning     = Is Equal   != Is Not Equal   \u0026gt; Greater Than   \u0026gt;= Greater Than or Equal To   \u0026lt; Less Than   ⇐ Less Than or Equal To    Conditional Expressions\nAnother pattern is the BEFORE and AFTER keywords. These specify actions to be taken before a line is read and after all lines have been read. Take the following for example:\n$ awk *BEGIN {print \u0026#34;BEFORE LINES ARE READ\u0026#34;}* \u0026lt; /dev/null BEFORE LINES ARE READ $ awk *END {print NR, \u0026#34;Cities\u0026#34;}* citytemps.csv 5 Cities DEFAULT VARIABLES\nNR = Number of Record (line number) NF = Number of Field RS = Record separator (\\n by default) FS = Field separator (white spaces by default)\nSee that the last example says 5 cities but in our citytemps.csv file, there are only four cities listed. We need to subtract the title line.\n$ awk *END {print NR-1, \u0026#34;Cities\u0026#34;}* citytemps.csv 4 Cities Arithmetic Let\u0026rsquo;s say that we want to perform some math on our text or CSV file. We want to start reporting on our data and make it meaningful. In this example I will retrieve the highest, the lowest, and the average temperature in each of our cities.\nFirst we\u0026rsquo;re going to start with getting the average. In order to do this we need to create a variable that holds the sums of all temps. In the END statement we can divide the sum by the number of lines. Don\u0026rsquo;t forget we need to subtract one line for the title line.\n$ awk *{sum += $3} END {print \u0026#34;average temp: \u0026#34; sum/(NR-1)}* citytemps.csv average temp: 72.6 We will work on getting the max temperature. We needed to make sure we don\u0026rsquo;t count line 1, so we say if the first word is not our State label, then check, if our temperature is higher than what max is set to now. If it is, max is now this line\u0026rsquo;s temperature. Since max starts out as undefined, any temperature is higher. Each successive, if higher, will be set to the variable max. At the end, print the variable max.\nawk *{if ($1 != \u0026#34;State\u0026#34; \u0026amp;\u0026amp; $3 \u0026gt; max) max = $3} END {print \u0026#34;max temp: \u0026#34;, max}* citytemps.csv max temp: 100 Now we\u0026rsquo;ll get the min temperature. Again we want to ignore the title line. Then, we are checking if least is undefined. If undefined, set to the first line\u0026rsquo;s temperature, and checking for a lesser value with each successive line of data. At the end we are printing the min temperature.\nawk *{if ($1 != \u0026#34;State\u0026#34; \u0026amp;\u0026amp; (least \u0026lt; 1 || $3 \u0026lt; least)) least = $3} END {print \u0026#34;min temp: \u0026#34;, least}* citytemps.csv min temp: 78 Multiple statements Now we\u0026rsquo;re going to apply all that we\u0026rsquo;ve learned and put it into a nice report.\n$ awk *{sum += $3} {if ($1 != \u0026#34;State\u0026#34; \u0026amp;\u0026amp; $3 \u0026gt; max) max = $3} {if ($1 != \u0026#34;State\u0026#34; \u0026amp;\u0026amp; (min \u0026lt; 1 || $3 \u0026lt; min)) min = $3} END {print \u0026#34;The average temp is: \u0026#34;,(sum/(NR-1)),\u0026#34; degrees and the max is :\u0026#34;,max,\u0026#34; and the min is: \u0026#34;, min, \u0026#34; degrees\u0026#34;}* citytemps.csv \u0026gt; calcTemps.txt $ cat calcTemps.txt The average temp is: 90.75 degrees and the max is : 100 and the min is: 78 degrees Exercises\nLet\u0026rsquo;s use what we\u0026rsquo;ve learned with AWK. Perform the following to prepare for the exercised. This will create a csv file with precipitation data for the fall season.\n$ printf \u0026#34;Month\\\\tPrecip In cm\\\\n\\\\rSeptember\\\\t25\\\\n\\\\rOctober\\\\t30\\\\n\\\\rNovember\\\\t60\\\\n\\\\r\u0026#34; \u0026gt; fallPrecip.csv  Write an awk command that prints out the wettest month. Create an awk command that prints out the average of precip in the fall season.  Answers to Exercises.   $ sed 1 s/mine/fine/ myTestFile.txt\n  $ sed 2d myTestFile.txt\n  $ awk {if ($1 != \u0026ldquo;Month\u0026rdquo; \u0026amp;\u0026amp; max \u0026lt; $2) maxMonth = $1 } END {print maxMonth, \u0026quot; is the wettest month.\u0026quot;} fallPrecip.csv\n  $ awk {sum += $2} END {print \u0026ldquo;average rain fall per month is \u0026quot; sum/(NR-1)} fallPrecip.csv\n  Summary Both SED and AWK are great for working with data, txt and csv files. SED is perfect for quick word, line specific searches, find and replace and deleting. AWK is great for performing calculations and creating summarized reports on data. Both the SED and AWK commands can be used in conjunction with other commands, such as the following command that will list out the contents of your current directory, delete the first line, and displays the list in a meaningful way.\nls -al | sed *1d* | awk \u0026#39;{print \u0026#34;Owner of \u0026#34; $9 \u0026#34; is \u0026#34; $3 } "
},
{
	"uri": "/react/foundations/styling/",
	"title": "Styling Components",
	"tags": [],
	"description": "",
	"content": "Learn various ways to style your components.\nConcepts  Describe the Problem with CSS for Styling Components Discuss various ways to style React Components  Inline Styling External Stylesheets Styling with JavaScript Objects The Styled Components library    Skills  Be able to make informed decisions about how to style your components Set up your project to use CSS preprocessors Install and Use CSS frameworks  The Problems with CSS for Styling Components  CSS was designed for styling static web sites Thus the Cascading rules of CSS mean that CSS applies styles globally. While this may be a powerful way to style a static web site, it doesn\u0026rsquo;t work well for component-based dynamic websites. We need a way to apply CSS in a modular (non-global) way. Specifically, we want to style components such that the styling of one component doesn\u0026rsquo;t \u0026ldquo;leak\u0026rdquo; into the styling of other components. Since CSS doesn\u0026rsquo;t directly offer this, we need some techniques or libraries that can make CSS rules apply locally.  Below is a more detailed list of the most common problems encountered when using CSS.\n   Problem Description     Global namespaces CSS is global by default - all CSS selectors are applied globally.    In React we often want each component to be independently styled.    Styling one component should not accidentally affect the styling of other components.    So we would like some guarantee that our styling is local and not global.   Inline styling presents problems Inline styling is not DRY.    Styling is duplicated both in our code and in the DOM at runtime.    Inline styling prevents overriding the styles when needed.   Dependencies CSS classes are global in nature.    Therefore, determining where a CSS class is in use can be tedious.   Dead code elimination It\u0026rsquo;s difficult to determine which CSS code is not in use.   Sharing constants How do you share constants between your JavaScript and CSS code?   Non-deterministic resolution CSS is executed in the order that the classes are declared.    Which is determined by the order that the files are loaded.    Thus you may not have control over which class overrides.   Isolation How do you ensure that styles are not overridden from the outside?     NOTE: These problems become more severe as the codebase grows.\n Styling Options  At the current time, there is no officially preferred way of styling React components. Instead, we have several different options available. We will explore a handful of the more popular options . Then you can make an informed decision for your future projects.  External Stylesheets  Using external stylesheets (the old-fashioned way) is perfectly acceptable in React. Most developers break up their stylesheets to match components. Out of the box, create-react-app sets you up with index.css and app.css files. Normally, when creating a new component, you will have a CSS file inside the component folder and import it in.   NOTE: You can see a demo of the examples in this lesson at FancyButton | Stackblitz.\n For example\u0026hellip;\nFancyButton.js\nimport React from \u0026#34;react\u0026#34; import \u0026#34;./FancyButton.css\u0026#34; function FancyButton({ label, cb }) { return ( \u0026lt;button className=\u0026#34;fancy-button\u0026#34; onClick={cb}\u0026gt;{label}\u0026lt;/button\u0026gt; ) } export default FancyButton Now, we can add the corresponding CSS:\nFancyButton.css\n.fancy-button { background: rgb(211, 211, 211); border: none; border-radius: 5px; font-size: 1.5rem; box-shadow: 2px 2px 5px 2px rgb(96, 96, 96); } .fancy-button:hover { color: rgb(64, 64, 255); background-color: rgb(192, 192, 192); } .fancy-button:active { background-color: rgb(160, 160, 160); transform: translate(2px, 2px); box-shadow: inset; } .fancy-button:focus { outline: 0; }  This approach does not completely encapsulate your css. For instance, another developer (or a 3rd party library), may have their own FancyButton with the same CSS class names. Then there would be a collision on the CSS class names and the last one loaded into the browser would win.  Inline Styling  NOTE: Inline styling is not recommended, but we cover it here so that you will be familiar with how it works.\n  Inline styling does guarantee that your styling will not leak into other components. But inline styling creates other problems, such as:  the styling can become very verbose and difficult to read the styling is not DRY, for example 2 buttons styled the same way will repeat all of the styling    Here is the FancyButton with inline styling:\nimport React from \u0026#34;react\u0026#34; function FancyButtonInlineStyling({ label, cb }) { return ( \u0026lt;button style={{ background: \u0026#34;rgb(211, 211, 211)\u0026#34;, border: \u0026#34;none\u0026#34;, borderRadius: \u0026#34;5px\u0026#34;, fontSize: \u0026#34;1.5rem\u0026#34;, boxShadow: \u0026#34;2px 2px 5px 2px rgb(96, 96, 96)\u0026#34; }} onClick={cb}\u0026gt;{label}\u0026lt;/button\u0026gt; ) } export default FancyButtonInlineStyling Observations  When styling inline, you\u0026rsquo;ll want to use camelCase css properties.   WARNING: Inline styling does not support CSS pseudo-selectors, so we can\u0026rsquo;t style the :hover, :active, and :focus states of the button!\n Styling with Objects  The above example illustrates that inline-styling can make your code difficult to reason about, As an alternative you can use JavaScript Objects for your inline styles. This approach is pretty straight-forward. simply create objects with your css declarations and assign the objects to your JSX style attributes.   WARNING: As with inline styling, styling with objects also does not support CSS pseudo-selectors, so we can\u0026rsquo;t style the :hover, :active, and :focus states of the button!\n import React from \u0026#34;react\u0026#34; const buttonStyle = { background: \u0026#34;rgb(211, 211, 211)\u0026#34;, border: \u0026#34;none\u0026#34;, borderRadius: \u0026#34;5px\u0026#34;, fontSize: \u0026#34;1.5rem\u0026#34;, boxShadow: \u0026#34;2px 2px 5px 2px rgb(96, 96, 96)\u0026#34; } function FancyButtonObjectStyled({ label, cb }) { return ( \u0026lt;button style={buttonStyle} onClick={cb}\u0026gt;{label}\u0026lt;/button\u0026gt; ) } export default FancyButtonObjectStyled While this is slightly verbose, our styles are encapsulated within this specific file.\nCSS Modules CSS Modules:\n are simply CSS files with the extension .module.css. are processed in a build step (with the help of Webpack or Browserify) ensure that **all CSS class and animation names are scoped locally by default (usually implemented via name mangling to ensure globally unique names). are built into create-react-app's configuration and automatically enabled for files ending with the .module.css extension.  To use CSS Modules, all you have to do is:\n Rename your CSS files from Component.css to Component.module.css Import it with import styles from 'Component.module.css' Then use it like this:  \u0026lt;MyComponent className={styles.myClassName} /\u0026gt; or if you have dashes in your class names:\n\u0026lt;MyComponent className={styles[\u0026#34;my-class-name\u0026#34;]} /\u0026gt; Example FancyButton.module.css\n.fancyButton { background: rgb(211, 211, 211); border: none; border-radius: 5px; font-size: 1.5rem; box-shadow: 2px 2px 5px 2px rgb(96, 96, 96); } .fancyButton:hover { color: rgb(64, 64, 255); background-color: rgb(192, 192, 192); } .fancyButton:active { background-color: rgb(160, 160, 160); transform: translate(2px, 2px); box-shadow: inset; } .fancyButton:focus { outline: 0; } FancyButton.js\nimport React from \u0026#34;react\u0026#34; import styles from \u0026#39;./FancyButton.module.css\u0026#39; function FancyButtonModuleStyled({ label, cb }) { return ( \u0026lt;button className={styles.fancyButton} onClick={cb}\u0026gt;{label}\u0026lt;/button\u0026gt; ) } export default FancyButtonModuleStyled TIP:\n If you want to preprocess a stylesheet with Sass, you will need to add the node-sass library to your project and then change the stylesheet file extension as follows: MyComponent.module.scss or MyComponent.module.sass.\n Styled Components  Styled Components is a \u0026ldquo;CSS in JS\u0026rdquo; library Styled Components is a cross between CSS and ES6 by combining actual CSS declarations and template strings. This allows you to write CSS as you always have and also use the dynamic powers of the JavaScript language.  NOTE: You will need to run npm install --save styled-components or yarn add styled-components in order to use styled components.\nimport React from \u0026#34;react\u0026#34; import styled from \u0026#39;styled-components\u0026#39; const FancyButton = styled.button` background: rgb(211, 211, 211); border: none; border-radius: 5px; font-size: 1.5rem; box-shadow: 2px 2px 5px 2px rgb(96, 96, 96); \u0026amp;:hover { color: rgb(64, 64, 255); background-color: rgb(192, 192, 192); } \u0026amp;:active { background-color: rgb(160, 160, 160); transform: translate(2px, 2px); box-shadow: inset; } \u0026amp;:focus { outline: 0; } ` function FancyButtonStyledComponents({ label, cb }) { return ( \u0026lt;FancyButton onClick={cb}\u0026gt;{label}\u0026lt;/FancyButton\u0026gt; ) } export default FancyButtonStyledComponents  As you can see, Styled Components lets you write actual CSS in your JavaScript. This means you can use all the features of CSS you use and love, including media queries, pseudo-selectors, nesting, etc. Also, because Styled Components are written as plain JavaScript we can do all kinds of JavaScript tricks to create them, such as:  make them dynamic with ternary or if/else logic. write builder functions that return a styled component parameterize those builder functions to make them dynamic organize the styled components code into separate JavaScript files   Check out the docs to learn more!  Using Sass  If you choose to use external stylesheets, the create-react-app documentation has a section on Adding a SASS Stylesheet. You can also use CSS Modules with SASS in your React app. Just follow the instructions for enabling Sass and then name your stylesheets MyComponent.module.scss or MyComponent.module.sass (depending on which flavor of Sass you use).  Method Comparison React Component Libraries There are many React Component Libraries that either support the styling methods we have discussed here or offer their own solutions. Most of the libraries provide a way to define customizable themes for styling the components.\nPopular React Component Libraries include:\n React Bootstrap (if you must) React Material UI Rebass Semantic UI React Ant Design  Lab The instructions for the lab are at React Styling Lab.\nSummary  There are multiple solutions to style your components in React. Each solution provides some advantages. Many 3rd party React component libraries provide a solution to styling the provided components. A simple and robust solution is to use CSS Modules because:  create-react-app provides support You can use the CSS language without modification The CSS class names will be altered to prevent any name collisions between components You can use SASS with CSS Modules by installing node-sass and renaming your CSS files to MyComponent.module.scss or MyComponent.module.sass.    Additional Resources  Evolution of Styling in React Styled Components Enforcing Best Practices Styled Components CSS Modules Adding a SASS Stylesheet | Create React App Docs React style documentation (inline styling)  "
},
{
	"uri": "/software-eng-essentials/command-line-bash/wildcards-and-brace-expansion/",
	"title": "Wildcards and Brace Expansion",
	"tags": [],
	"description": "",
	"content": "Objectives  Know how to play a single wildcard The wide ranging world of brackets Using brace expansion   Know how to play a single wildcard Pattern matching example\n$ pwd /Users/KXB0QJK/colors $ ls o* orange opalescent olive orchid ochre Under the hood with wildcards\nYou might assume that the ls command above receives the argument o* then proceeds to translate that into the required matches. However, bash that does the translation for us. When we offer it this command it sees that we have used wildcards and so, before running the command (in this case ls) it replaces the pattern with every file or directory (i.e., path) that matches that pattern. We issue the command:\n$ ls o* That the system translates into:\n$ ls orange opalescent olive orchid ochre and then executes the program. The program does not see the wildcards, nor does it care that we used them. This is fascinating because it means we are not limited to only certain programs or situations. We can use wildcards on the command line whenever we want.\n* wildcard character The wildcard character * matches anything or nothing.\nGiven an example where of a directory where the following command is true:\n$ ls oso sos soo oos The following table would be representative for the outcome of matches following a pattern match.\nWildcard examples\n   Pattern Matches     * \u0026lt;Anything\u0026gt;    *s oos sos   s*  soo sos   s*s sos    $ touch test1.txt test2.txt \u0026amp;\u0026amp; mkdir x z $ ls test1.txt x test2.txt z $ mv * $ ls z $ ls z test1.txt x test2.txt ? wildcard character The ? wildcard character matches exactly one character. This is useful when you have a precise idea of what you\u0026rsquo;re looking for.\nWorking with these files\n$ ls file1 file10 file100 $ ls file? file1 $ ls file?? file10 $ ls file??? file100 Exercises\nGiven the following example (to recreate on your own system), transform it in the following step.\n$ pwd ~/content $ ls -a . .config README.md calculator.py index.js logo2.png pic2.jpg .. .gitignore about.html index.html logo1.png pic1.jpg pic3.jpg $ echo \u0026#34;\u0026lt;html\u0026gt;\u0026lt;/html\u0026gt;\u0026#34; \u0026gt; index.html   Move all files of type either jpg or png (image files) into another directory. Hint: Name the new directory images.\n  Find the file type of every file in a directory. Hint: run man on file\n  The wide ranging world of brackets [ _] The over underscore  [acd7_] matches one of the characters in the list  [^ ] Mismatched up to bat  [^ax2] matches anything but a, x, or 2  [ - ] The range of our depth charts  ranges: [a-z], [0-9], [A-C3-5]  $ ls foobar-v1.doc foobar-v6.doc foobar-v11.doc foobar-v2.doc foobar-v7.doc foobar-v12.doc foobar-v3.doc foobar-v8.doc foobar-v4.doc foobar-v9.doc foobar-v5.doc foobar-v10.doc $ rm foobar-v[3-5].doc $ ls foobar-v1.doc foobar-v9.doc foobar-v2.doc foobar-v10.doc foobar-v6.doc foobar-v11.doc foobar-v7.doc foobar-v12.doc foobar-v8.doc Alternatively\n$ ls foobar-v1.doc foobar-v6.doc foobar-v11.doc foobar-v2.doc foobar-v7.doc foobar-v12.doc foobar-v3.doc foobar-v8.doc foobar-v4.doc foobar-v9.doc foobar-v5.doc foobar-v10.doc $ rm foobar-v[^3-5].doc $ ls foobar-v3.doc foobar-v4.doc foobar-v5.doc $ rm foobar-v?.doc $ ls foobar-v10.doc foobar-v11.doc foobar-v12.doc Exercises\nA good directory to play with is /etc which is a directory containing config files for the system. As a normal user you may view the files but you can\u0026rsquo;t make any changes so we can\u0026rsquo;t do any harm. Do a listing of that directory to see what\u0026rsquo;s there. Then pick various subsets of files and see if you can create a pattern to select only those files.\n Do a listing of /etc with only files that contain an extension. What about only a 3 letter extension? How about files whose name contains an uppercase letter?  Hint: ↑ may be useful here   Can you list files whose name is 4 characters long?  Brace Expansion Brace expansion generates strings, so you don\u0026rsquo;t have to generate them by hand! It does not have to match existing filenames, in fact it is often used to create new files.\nSyntax: pre{\u0026lt;list of strings\u0026gt;}post\n   Input Expansion     $ touch {x,y,z}.txt $ touch x.txt y.txt z.txt   $ mv file.{txt,jpg} dir/ $ mv file.txt file.jpg dir   $ touch {A..C}{1..3}.txt $ touch A1.txt A2.txt ... C2.txt C3.txt    "
},
{
	"uri": "/javascript/foundations/higher-order-functions/",
	"title": "Higher Order Functions",
	"tags": [],
	"description": "",
	"content": "What are Higher Order Functions and Callbacks?    Higher order functions are essential to programming in JavaScript A Higher Order Function has at least one of the two following characteristics:  accepts a function as an argument, or returns a function as it\u0026rsquo;s result   The most common use case for higher order functions is the callback  Higher order functions really shine when we want to write \u0026ldquo;generic\u0026rdquo; code. In other words, we want to separate the generic code from the specific code.\n generic code - code that solves a particular problem (like filtering or sorting) but is flexible (generic) enough to be configured to solve it in different ways specific code - code that provides the specific implementation to the generic code; for example \u0026ldquo;sort by lastName\u0026rdquo; or \u0026ldquo;filter out the odd numbers\u0026rdquo;   In JavaScript, the generic code will take a function (a callback) as a parameter, and the specific code will be provided by the callback function.\n Accepting a function as an argument  All of the modern array methods use higher order functions. For example, Array.map is a method (function) that takes a function as an argument  Example const numbers = [2, 3, 4]; const squared = numbers.map(function(number) { return number * number; }); const plusOne = numbers.map(function(num) { return num + 1; });  In the above example, we see two invocations of Array.map. Each one takes a function as argument to do something specific (square vs. add 1). Thus the behavior of Array.map can be customized by the function being passed as a parameter  Callbacks Callbacks are often used in JavaScript to call a function at a later time, such as when a button is clicked.\nfunction btnClicked() { // do something here } let btn = document.querySelector(\u0026#39;#submit\u0026#39;); // find the DOM node with an id = `#submit` btn.addEventListener(\u0026#39;click\u0026#39;, btnClicked); // register the `btnClicked` callback function Example // A Reusable Button (generic code) function makeButton(label, onClick) { return { label: label, onClick: onClick } } function render() { // specific code to say Hello  function sayHello() { console.log(\u0026#34;Hello\u0026#34;) } // specific code to say Goodbye  function sayGoodbye() { console.log(\u0026#34;Goodbye\u0026#34;) } // now let\u0026#39;s connect our specific code to our generic code  const helloButton = makeButton(\u0026#34;Say Hello\u0026#34;, sayHello) const goodbyeButton = makeButton(\u0026#34;Say Goodbye\u0026#34;, sayGoodbye) // let\u0026#39;s simulate the user clicking the Hello Button  helloButton.onClick() // let\u0026#39;s simulate the user clicking the Goodbye Button  goodbyeButton.onClick() } render()   Returning a function  We may also choose to have a function return a function. There are many uses for this, such as the function builder pattern shown in the example below.  function makeTipCalculator(tipRate) { return function(amount) { // return a function that binds to the `tipRate`  return tipRate * amount; } } const bigTipper = makeTipCalculator(0.25); // create and return a tipCalculator const smallTipper = makeTipCalculator(0.10); // create and return another tipCalculator  console.log(bigTipper(100)); // 25 console.log(smallTipper(100)); // 10 Lab See instructions here.\nSummary  In JavaScript, functions can be treated as expressions that are assigned to variables, passed to functions, or returned from functions. Higher order functions are functions that either take a function as a parameter or return a function. Higher order functions are a powerful way to separate out the generic code from the specific code, allowing the generic code to be reusable. Callbacks are functions passed to a higher order function so that they can be invoked by the higher order function.  "
},
{
	"uri": "/react/foundations/context/",
	"title": "Context API",
	"tags": [],
	"description": "",
	"content": "Learn about React\u0026rsquo;s Context API for sharing state across components.\nObjectives  Review state in a React app Learn about the Context API Explore the use cases of Context Learn the 3 steps to using the Context API  Skills  Use the context API to share state in a React app Create a Context Object Use a Provider component to provide a value Use the useContext hook to consume a value  React App State Let\u0026rsquo;s review some concepts around React app state management.\nThe Data Flows Down  A component may choose to pass its state down as props to its child components. The child components can then communicate back to the parent via callback functions. A child can also share its props with its own child components. The parent maintains control of changes to the state. Thus there is a single source of truth for any data that changes in a React application. But what if we need to share state from a parent to a descendent component that is several levels down (a grandchild or great grandchild or great great grandchild component)?  The Prop Drilling Problem    When passing props from parent to child to grandchild, often the intermediary components don\u0026rsquo;t really need to do anything with the props data. They just need to receive it in order to pass it down the line. This creates unnecessary couplings of components to props. If the props need to be refactored in some way, we will need to edit all of the intermediary components as well as the parent and the descendent that consumes the props. This is called \u0026ldquo;prop drilling\u0026rdquo; and it leads to components having props they don’t actually use, but they need to pass down the tree to components that do use them.   Prop drilling refers to the process you have to go through to get data to (deeper) parts of the React Component tree. - Kent C. Dodds\n Example of Prop Drilling:\n In the following example we pass the name prop from App \u0026ndash;\u0026gt; Navbar \u0026ndash;\u0026gt; Greeting so that it can be displayed. The Navbar component is just an intermediary that must know about and pass the name prop without needing it for any other reason.  What is the Context API?  The React Context API was added in React version 16.3. The Context API provides a way to share data through the component tree without having to pass props down manually at every level. If a component needs the data, it can subscribe to that data via a Context object and it will be re-rendered whenever that data changes.  The following diagram illustrates the difference between prop drilling and Context:\nHow to Use Context Using the new React Context API depends on three main steps:\n Create a Context object with an initial state. Typically the Context object is created and exported from its own source file, such as MyContext.js. Put the Context\u0026rsquo;s Provider component at the top of the component tree where it will be used and set its value. Consume the data provided by the Provider in any component that is a descendant of the Provider component. You can consume the data in one of two ways:   via the Context\u0026rsquo;s Consumer component (old way, needed for Class components) via the useContext hook (new easier way, nice for Function components)  Let\u0026rsquo;s look at each of these steps in more detail.\nStep 1: Create a Context Object to hold the initial state  Use React.createContext to create a Context object. The object returned will contain a Provider object and a Consumer object.  import React from \u0026#39;react\u0026#39; const MyContext = React.createContext(defaultValue) export default MyContext  As indicated above, we generally want to place the custom context object in a separate source file so that it can be imported into other components (one component using the Provider and one or more components using the Consumer or a useContext hook). React.createContext creates a Context object. When React renders a component that subscribes to this Context object it will read the current context value from the closest matching Provider above it in the tree.  About the Default Value  The defaultValue argument is only used when a component does not have a matching Provider above it in the tree. This is intended to be helpful for testing components in isolation without wrapping them, but in practice it is not very useful.   TIP: It is best not to rely on the defaultValue argument. You want your tests to match the end user experience as much as possible. Thus in practice you should just use null as the default value. See How to use React Context effectively | Kent C. Dodds.\n Step 2: Add the Provider component Add the Provider component at the top of the component subtree where the data will be needed and define its value prop.\nimport MyContext from \u0026#39;./MyContext\u0026#39; function MyContainer(props) { return ( \u0026lt;MyContext.Provider value={/* some value */}\u0026gt; {/* child components go here */ } \u0026lt;/MyContext.Provider\u0026gt; ) } export default MyContainer  NOTE: The Provider value can be any JavaScript expression, such as a Number, boolean, String, Object, or an Array!\n Every Context object comes with a Provider component that:\n allows consuming components to subscribe to context changes accepts a value prop to be shared with consuming components that are descendants of this Provider can be nested to override values higher in the component tree.  All components that subscribe to the context value that are descendants of a Provider will re-render whenever the Provider’s value prop changes.\nStep 3: Consume the value  Any components that are below the Provider in the component tree can consume the value from the Context There are 2 ways to consume the value:  For Class or Function Components: add the Consumer component from the Context object (this is the old way) For Function Components: use the useContext hook (this is the new way - it\u0026rsquo;s easier but only works for function components)    TIP: Consuming context with function components via the useContext hook is easier and less tedious than doing so with class components and the Context.Consumer component.\nExample with a Function Component (via the useContext hook):\nimport React, { useContext } from \u0026#39;react\u0026#39; import MyContext from \u0026#39;./MyContext\u0026#39; function MyContainer() { const value = useContext(MyContext) // get value from context  return ( \u0026lt;p\u0026gt;The value is {value}\u0026lt;/p\u0026gt; {/* use value in JSX */} ) } export default MyContainer Example with a Class Component (via the Consumer Component):\nimport React, { Component } from \u0026#39;react\u0026#39; import MyContext from \u0026#39;./MyContext\u0026#39; class MyComponent extends Component { render() { return ( \u0026lt;MyContext.Consumer\u0026gt; {value =\u0026gt; ( {/* get value from MyContext */} \u0026lt;p\u0026gt;The value is {value}\u0026lt;/p\u0026gt; {/* use value in JSX */} )} \u0026lt;/MyContext.Consumer\u0026gt; ) } } export default MyComponent The Context Consumer Component The Context Consumer Component:\n is just a React component that subscribes to context changes expects a function as its children prop receives its value as an argument passed to the function the value will be equal to the value prop of the closest Provider above it in the tree  Summarized Steps to Context:\n Create a Context object Put the Context\u0026rsquo;s Provider component at the top of the tree and set its value. Put the useContext or the Context\u0026rsquo;s Consumer component below the Provider to get a Context value.  Avoid Unnecessary Re-renders  Because context uses reference identity to determine when to re-render, there are some caveats that could trigger unintentional renders in consumers when a provider’s parent re-renders. For example, the code below will re-render all consumers every time the Provider re-renders because a new object is always created for the value:  function App() { return ( \u0026lt;Provider value={{ name: \u0026#39;Susan\u0026#39; }}\u0026gt; {/* the value is an object literal that gets recreated with each render */} \u0026lt;Toolbar /\u0026gt; \u0026lt;/Provider\u0026gt; ); } } To get around this, lift the value into the parent’s state:\nfunction App() { const [value, setValue] = React.useState({ name: \u0026#39;Susan\u0026#39; }) // or we could use:  const value = React.useRef() return ( \u0026lt;Provider value={value}\u0026gt; {/* now the value is no longer recreated with each render */} \u0026lt;Toolbar /\u0026gt; \u0026lt;/Provider\u0026gt; ); } } Some Applications of The Context API Themes  The ability to set the theme is a big win for UX. For example, a blogging platform may provide dark mode and light mode giving the user options to read in the low light environments. To implement themes, every component must have colors and images changed to accommodate the selected theme. Without Context it would be cumbersome and verbose to pass a theme prop to every component that might need it.  Multilingual application  Implementing multiple languages in an app would require replacing the text in every component with the translated text. But this can be easily implemented using Context. We can set the current language in a React Context and all the components in a large component tree can display text in the selected language.  Authorization  Setting the user role and info \u0026ndash; many apps require the display of dynamic content and messages based on the type of user that has logged in. We can easily add user info in a Context object.  When not to use Context  There is one drawback to using Context - it makes component reuse more difficult as it creates a dependency between the component and the Context. If you only want to avoid passing some props through many levels, component composition may be a simpler solution than context. See: Before You Use Context for more information. For a more advanced state management you may want to consider other options. You can even combine the Context API with React\u0026rsquo;s state management hooks such as the useState and useReducer to create custom hooks for sharing state.  Lab Click here for the instructions to this lab.\nSummary  The Context API makes it easier to share global data with many components. The Context API has been considered one of the key features of the React framework and a prominent improvement in the recent releases of the framework.  Additional Resources  React docs on Context 16-minute Wes Bos video on Context How to use React Context effectively Introduction to React Context API  "
},
{
	"uri": "/web-essentials/webmastery-foundations/dom-manipulation/",
	"title": "DOM Manipulation and DOM Events",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Understanding how the DOM is represented Identifying the difference between the HTML document and the DOM  Skills  Access nodes in the DOM using JavaScript Modify content in DOM (thus, the page) using JavaScript Manipulate the DOM based on an external event  The Document Object Model (DOM) is a JavaScript representation of the HTML document loaded into the browser. The DOM API lets you:\n Find elements (nodes) in the document Edit, add, or remove nodes Attach event handlers that respond to user input.  Find Nodes There are a few different ways to get a node or array of nodes from the HTML document.\nBy id attribute The document has a getElementById() method that is used to retrieve a single DOM node by it\u0026rsquo;s id attribute value.\n\u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;username\u0026#34;/\u0026gt; const el = document.getElementById(\u0026#39;username\u0026#39;); // 1  get a single element  By tag name The getElementsByTagName() method retrieves an array-like object (called an HTMLCollection) of elements that have the provided tag name.\n\u0026lt;input type=\u0026#34;text\u0026#34; class=\u0026#34;error\u0026#34;\u0026gt;\u0026lt;/input\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34;\u0026gt;\u0026lt;/input\u0026gt; const inputs = document.getElementsByTagName(\u0026#39;input\u0026#39;); // 1  inputs.length; // Output: 2  Get ALL input elements  By class name The getElementsByClassName() method also retrieves a similar array-like object of the elements that have the provided value as the class attribute.\n\u0026lt;input type=\u0026#34;text\u0026#34; class=\u0026#34;error\u0026#34;\u0026gt;\u0026lt;/input\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34;\u0026gt;\u0026lt;/input\u0026gt; const inError = document.getElementsByClassName(\u0026#39;error\u0026#39;); // 2  inError.length; // Output: 1  Get ALL elements with a class name of error  By any selector at all! The querySelector \u0026amp; querySelectorAll take a CSS selector as an argument, making duplicating the functionality from the other DOM selection functions easier.\n\u0026lt;input type=\u0026#34;text\u0026#34; class=\u0026#34;error\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; class=\u0026#34;password\u0026#34; /\u0026gt; \u0026lt;button\u0026gt;submit\u0026lt;/button\u0026gt; \u0026lt;button\u0026gt;cancel\u0026lt;/button\u0026gt; const firstButton = document.querySelector(\u0026#39;button\u0026#39;); const inError = document.querySelectorAll(\u0026#39;input.error\u0026#39;); firstButton // Output: 1 inError // Output: 2  a single button node a Node list of inputs with class \u0026lsquo;error\u0026rsquo; (a list containing 1 element)  NodeList vs Array querySelectorAll returns a nodeList, which offers a similar, but not identical, API to Array.\nconst links = document.querySelectorAll(\u0026#39;a\u0026#39;); // Works! const linkCount = links.length; const firstLink = links[0]; // Doesn\u0026#39;t work! links.map(function(link) { // do something with link }); Array methods like map, reduce, and so on, don\u0026rsquo;t work. Luckily, its easy enough to convert a nodeList into an Array:\nconst links = document.querySelectorAll(\u0026#39;a\u0026#39;); const arrayOfLinks = Array.from(links); Traversing the DOM You can use the children, parent, nextElementSibling, and previousElementSibling attributes to find nodes relative to a node you have. This process is known as traversing the DOM.\nChildren Use the children property to gets a nodeList of all the nodes contained in the node.\n\u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;Item 1\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Item 2\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; const listItems = document.querySelector(\u0026#39;ul\u0026#39;).children; listItems.length; //Output: 2 Siblings and Parents Use parent, nextElementSibling, and previousElementSibling to find nodes up the tree and across it.\n\u0026lt;header\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;Item 1\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;selected\u0026#34;\u0026gt;Item 2\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Item 3\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;section\u0026gt; Hello! \u0026lt;/section\u0026gt; const selectedItem = document.querySelector(\u0026#39;li.selected\u0026#39;) const first = selectedItem.previousElementSibling; const last = selectedItem.nextElementSibling; const list = selectedItem.parentElement; const header = selectedItem.parentElement.parentElement; const section = selectedItem.parentElement.parentElement.nextElementSibling;    Go to DOM Manipulation Lab over Selecting Nodes    Editing a node A Node object has some useful properties and methods to access its contents and edit its appearance and content.\ninnerHTML innerHTML gets or sets the html text inside a node.\n\u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Hello\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; window.onload = function() { const div = document.querySelector(\u0026#39;div\u0026#39;); const h1 = document.querySelector(\u0026#39;h1\u0026#39;); h1.innerHTML; // \u0026#34;Hello\u0026#34; \tdiv.innerHTML; // \u0026#39;\u0026lt;h1\u0026gt;Hello\u0026lt;/h1\u0026gt;\u0026#39;  h1.innerHTML = \u0026#34;Aloha\u0026#34;; } Attributes DOM Node attributes can be retrieved and set like any JavaScript object property.\n\u0026lt;a href=\u0026#34;http://google.com\u0026#34; name=\u0026#34;googleLink\u0026#34;\u0026gt;Click me\u0026lt;/a\u0026gt; window.onload = function() { const a = document.querySelector(\u0026#39;a\u0026#39;); //Get an attribute \ta.href; //\u0026#34;http://google.com\u0026#34;  //Set an attribute \ta.name = \u0026#39;new link name\u0026#39;; //Add a new attribute \ta.target = \u0026#34;_blank\u0026#34;; }; Removing nodes remove removes a node from a document.\n\u0026lt;header\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;Item 1\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Item 2\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Item 3\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;section\u0026gt; Hello! \u0026lt;ul\u0026gt; \u0026lt;li class=\u0026#34;first\u0026#34;\u0026gt;Item 1\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Item 2\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Item 3\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;section\u0026gt; Hello! \u0026lt;/section\u0026gt; document.querySelector(\u0026#39;.first\u0026#39;).remove(); // 1  Remove the first list item  Adding nodes Create a node using document.createElement('tagname') and node.appendChild(el)\n\u0026lt;header\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;Item 1\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/header\u0026gt; window.onload = function() { const newLI = document.createElement(\u0026#39;li\u0026#39;); newLI.innerHTML = \u0026#34;Item 2\u0026#34;; const list = document.querySelector(\u0026#39;ul\u0026#39;); list.appendChild(newLI); //1 };  Insert item 2 after item 1     Go to DOM Manipulation Lab over Editing the DOM    DOM Events async programming is important in JS. DOM events allow us to make use of asynchronous functions.\nElements emit events based on user input and you can register code to run in response to these events (event handlers).\nEvents include:\n Mouse events - click, mouseover, mouseout Keyboard events - keydown, keyup, etc Form events - submit, blur, focus, change, window events - load, hashchange, etc. touch events - touchstart, touchend, etc.  MDN: Event reference gives a more complete description of DOM Events\n\u0026lt;h1 id=\u0026#34;myEl\u0026#34;\u0026gt;Click Me!\u0026lt;/h1\u0026gt; window.onload = function() { const el = document.getElementById(\u0026#39;myEl\u0026#39;); el.addEventListener(\u0026#39;click\u0026#39;, function(event){ alert(\u0026#39;Thank you!\u0026#39;); }); // Combine with DOM editing  el.addEventListener(\u0026#39;mouseover\u0026#39;, function(event) { el.innerHTML = \u0026#39;Getting Warmer\u0026#39;; }); el.addEventListener(\u0026#39;mouseout\u0026#39;, function(event) { el.innerHTML = \u0026#39;Goodbye\u0026#39;; }); }; Event object An event object is passed to the event handler that describes what happened. The event object is different depending on the type of event.\nEvents include:\n target - element where event occurred Mouse: clientX, clientY Keyboard: keyCode, shiftKey  Here is the previous example using event.target:\nwindow.onload = function() { const el = document.getElementById(\u0026#39;myEl\u0026#39;); el.addEventListener(\u0026#39;click\u0026#39;, function(event){ alert(\u0026#39;Thank you!\u0026#39;); }); // Combine with DOM editing  el.addEventListener(\u0026#39;mouseover\u0026#39;, function(event) { event.target.innerHTML = \u0026#39;Getting Warmer\u0026#39;; //1  }); el.addEventListener(\u0026#39;mouseout\u0026#39;, function(event) { event.target.innerHTML = \u0026#39;Goodbye\u0026#39;; //1  }); };  Using event.target makes this code more reusable.  Event Bubbling When an event is triggered on an element, it then gets fired on that element\u0026rsquo;s parents, all the way to the top.\n event.target: the element where the event originally occurred event.currentTarget: the element running the event handler, this.  \u0026lt;div id=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;outer\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;inner\u0026#34;\u0026gt;Click Me (inner div)\u0026lt;/div\u0026gt; Click Me (outer div) \u0026lt;/div\u0026gt; Click Me (main) \u0026lt;/div\u0026gt; \u0026lt;pre id=\u0026#34;message\u0026#34;\u0026gt;\u0026lt;/pre\u0026gt; function log(message) { console.clear(); console.log(message); let messageElement = document.getElementById(\u0026#39;message\u0026#39;); messageElement.innerHTML = message; } document.querySelector(\u0026#39;#main\u0026#39;).addEventListener(\u0026#39;click\u0026#39;, function(e) { log(`target: ${e.target.id}, currentTarget: ${e.currentTarget.id}`); }); You can check out this example here.\n e represents the event (element that has been clicked)\n    Go to the rest of the DOM Manipulation Labs    "
},
{
	"uri": "/java/foundations/exceptions/",
	"title": "Exceptions",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts \u0026amp; Skills  Define exceptions vs errors Catching exceptions   No application is bulletproof. You have to expect to run into issues and in Java those issues have a couple different looks: Errors and Exceptions. Both errors and exceptions can be thrown which is how the Java compiler or runtime environment communicates to the program that something is wrong. When issues get thrown, it can catch the issue and let the program continue running. An exception that is never caught will hit the Java Runtime Environment and stop execution.\nExceptions and errors are not trivial, they indicate some unexpected result in the process of running and application so you should only catch an issue if you fully understand the consequences and have plans to handle it in some unique way.\nErrors  An Error \u0026ldquo;indicates serious problems that a reasonable application should not try to catch.\u0026rdquo;\n When a Java application throws an error it indicates that something very wrong has happened and the program needs to stop. You should not try to catch Errors as they represent a critical issue in running the program.\nExceptions  An Exception \u0026ldquo;indicates conditions that a reasonable application might want to catch.\u0026rdquo;\n The name says it all. Unlike an error, Exceptions are not necessarily critical but merely an exception to what was expected in running a program. These are the issues you should try to anticipate and catch if possible.\nUnchecked Exceptions Some Exceptions do not have to be handled. It is acceptable to let them be thrown and stop the program. Some common examples include IndexOutOfBoundsException, NullPointerException.\nString[] products = new String[]{\u0026#34;Hammer\u0026#34;, \u0026#34;Bucket\u0026#34;, \u0026#34;Lumber\u0026#34;, \u0026#34;Light Bulb\u0026#34;}; public String getProductByIndex(int index) { return products[index]; }  ☝️ Can you spot the exception?\n Checked Exceptions A checked exception is an exception that is mandatory to handle. These exceptions are declared in a method signature:\npublic String getProductByIndex(int index) throws IllegalArgumentException { // code } This syntax does not say that the function will fail. It declares that the caller should expect that some issues may happen and there needs to be a contingency in place in case this exception happens.\nCatch If you try to invoke a method that throws a checked exception you have to be prepared to catch it. This is where we use a try/catch clause. For instance, a usage of the getProductByIndex method defined above could look like:\ntry { getProductByIndex(i); } catch (IllegalArgumentException ex) { // do something to handle the exception } The try clause is a way we can run a risky block of code that might hit an exception. Basically, you ask your runtime to \u0026ldquo;Just try it\u0026hellip;\u0026rdquo; and if something goes wrong, our catch clause will handle it. For instance, if we wanted to catch the exception and let the program keep going we may fill in our catch like:\ntry { getProductByIndex(i); } catch (IllegalArgumentException ex) { System.out.println(\u0026#34;Please enter a valid index between 0-3\u0026#34;); } This catch clause will allow the program to continue running while notifying the user of the issue. This is known as \u0026lsquo;suppressing\u0026rsquo; an exception.\nThrow Sometimes our program can not or should not continue when we hit a checked exception. In that case need to catch our checked exception and throw and unchecked exception that will bubble up to runtime:\ntry { getProductByIndex(i); } catch (IllegalArgumentException ex) { throw new RuntimeException(ex.getMessage()); }  ℹ️ All Exceptions have a method getMessage to access more details about the exception and a constructor that accepts a String and sets it as the message for the Exception.\n The above catch clause takes the message from the checked IllegalArgumentException and wraps it in an unchecked RuntimeException to stop the program.\nSummary Errors and Exceptions are useful insights into the health of a running program. It is up to the dev team to decide how to handle these issues: catching and suppressing exceptions that are not fatal to the program or allowing them to be thrown and stop the program.\nResources  Exceptions Errors  "
},
{
	"uri": "/javascript/foundations/modern-array-methods/",
	"title": "Modern Array Methods",
	"tags": [],
	"description": "",
	"content": "Modern Array methods in JavaScript.\nLearning Objectives Concepts  List the modern JavaScript array methods. Discuss the advantages of the modern array methods.  Skills  Use indexOf to find the index of an item in an array. Use filter to filter an array with a provided callback function. Use find to find the first matching item in an array Use forEach to iterate over an array without using an index variable. Use map to transform the values in an array. Use reduce to summarize the values of an array into a single value.  Modern Array Methods  None of these methods alter (mutate) the original Array. Rather they each return a value or an Array of values.  The exception being the forEach method.   This approach of returning new values and not altering the original Array is a part of what is known as Functional Programming.  indexOf  You can use indexOf to find the index of a value in an Array. indexOf can find either primitive values or JavaScript objects. If the value is not found, indexOf will return -1.  Here is an example using indexOf:\nconst fruits = [\u0026#34;apple\u0026#34;, \u0026#34;orange\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;peach\u0026#34;, \u0026#34;pear\u0026#34;]; const peachIndex = fruits.indexOf(\u0026#34;peach\u0026#34;); if (peachIndex !== -1) { console.log(\u0026#34;we have a peach at index = \u0026#34;, peachIndex); } else { console.log(\u0026#34;we have no peach.\u0026#34;); } The output is:\nwe have a peach at index = 3 filter The filter method creates a new array with all elements that pass the test implemented by the provided function.\nHere is an example using filter:\nconst values = [1, -5, -2, 3, 12, -14, 0, 23, -1, 8]; const negativeValues = values.filter(v =\u0026gt; v \u0026lt; 0); console.log(\u0026#34;The negative values are: \u0026#34;, negativeValues); The output is:\nThe negative values are: [ -5, -2, -14, -1 ] find Similar to filter, we can use find to locate the first item in the array that matches the provided test function.\nconst fruits = [\u0026#34;apple\u0026#34;, \u0026#34;orange\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;peach\u0026#34;, \u0026#34;pear\u0026#34;]; const selectedFruit = fruits.find(fruit =\u0026gt; fruit === \u0026#34;orange\u0026#34;); console.log(selectedFruit); The output is:\norange forEach  The forEach method executes a provided function once per Array element. This allows for iteration over an Array without needing an index variable.  The classic for loop:\nconst arr = [1, 2, 3, 4, 5, 6, 7, 8]; for(let i = 0; i \u0026lt; arr.length; i++) { console.log(item); } Here is an example using forEach:\nconst arr = [1, 2, 3, 4, 5, 6, 7, 8]; arr.forEach(function(item) { console.log(item); }); The output is:\n1 2 3 4 5 6 7 8 TIP: When using forEach it\u0026rsquo;s more clear not to use an arrow function as the function contains side-effects.\nmap  The map method creates a new array containing transformed values from the original array. You provide the function that defines the transformation.  Here is an example using map:\nconst values = [1, 2, 3, 4, 5]; const squares = values.map(value =\u0026gt; value * value); console.log(\u0026#34;squares: \u0026#34;, squares); The output is:\nsquares: [ 1, 4, 9, 16, 25 ] reduce  The reduce method reduces an array to a single value. It applies a function to an accumulator as well as to each value of the array (from left to right), and will reduce them to a single value.  Here is an example of using reduce:\nconst values = [1, -5, -2, 3, 12, -14, 0, 23, -1, 8]; const sum = values.reduce((accumulator, v) =\u0026gt; accumulator + v, 0); // zero is the initial value of the accumulator console.log(\u0026#34;The sum is\u0026#34;, sum); The output is:\nThe sum is 25 Map, Filter, Reduce Example You can chain these methods together to do powerful calculations.\nHere is another example that adds up just the numeric values in an array:\nconst source = [\u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;foo\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;5\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;8\u0026#34;, \u0026#34;13\u0026#34;]; const result = source. map(str =\u0026gt;parseInt(str)). filter(n =\u0026gt; !isNaN(n)). reduce((x, y) =\u0026gt; x + y); console.log(\u0026#34;result:\u0026#34;, result); The output is:\nresult: 33  This is an example of functional chaining and can be used to write very powerful and concise code. We are able to chain functions together such that the output of one function becomes the input for the next.  Lab See instructions here.\nSummary Each of these methods provides an easy way to iterate over an Array doing a:\n search - indexOf and find filter - filter basic iteration - forEach transformation - map reduction - reduce  Additional Resources  5 Array Methods That You Should Use Today Learn to Chain Map, Filter, and Reduce Understand Reduce in 1 Minute  "
},
{
	"uri": "/javascript/foundations/labs/oop-lab/",
	"title": "OOP Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch oop.js Add the following code to oop.js:\nconst starWars = { title: \u0026#39;Star Wars\u0026#39;, genre: \u0026#39;SciFi\u0026#39;, year: 1976, print: function () { console.log(`${this.title}is a ${this.genre}that was released in ${this.year}.`); } }; const theTerminator = { title: \u0026#39;The Terminator\u0026#39;, genre: \u0026#39;SciFi\u0026#39;, year: 1984, print: function () { console.log(`${this.title}is a ${this.genre}that was released in ${this.year}.`); } }; const groundHogDay = { title: \u0026#39;Groundhog Day\u0026#39;, genre: \u0026#39;Comedy\u0026#39;, year: 1993, print: function () { console.log(`${this.title}is a ${this.genre}that was released in ${this.year}.`); } } const movies = [starWars, theTerminator, groundHogDay]; movies.forEach(movie =\u0026gt; { movie.print(); }); Step 2: Complete the code and test  Refactor the code to remove the object literals and instead use a JavaScript constructor method. Make the print method a prototype method Test your solution with:  node oop.js The expected output is:\nStar Wars is a SciFi that was released in 1976. The Terminator is a SciFi that was released in 1984. Groundhog Day is a Comedy that was released in 1993. "
},
{
	"uri": "/software-eng-essentials/git-foundations/reclaim-data/",
	"title": "Reclaim Data",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  To be able to recover work you accidentally deleted  Recover a deleted line Recover a deleted file Recover a deleted branch How to avoid a detached head Cherry Picking    So you\u0026rsquo;ve ruined your life. You deleted a commit you needed (or even a branch).\nIf that commit or branch (master or otherwise) exists on your remote the easiest way to recover it is to just pull down that remote with the following.\ngit pull If you haven\u0026rsquo;t pushed the branch up to the remote then it\u0026rsquo;s not as easy, but it is possible to recover with:\ngit reflog The output shows commits that were created even if those commits were reset, like:\nTo see more details about the commits, do:\ngit log -g Copy the SHA1 of the commit you are wanting to go back to and do:\ngit branch recover-branch-name SHA1-of-the-commits Now you have a branch with all that you had destroyed and now you can merge that back into your master or your other working branch.\nThe fsck command \u0026ldquo;What if I\u0026rsquo;ve deleted the branch and cannot just reset to get my lost work?\u0026quot;\nIt\u0026rsquo;s more complicated and not as easy but you can actually still find those commits with the fsck command.\ngit fsck --full fsck will show you a list of all objects that have nothing pointing at them. These are called dangling objects. The tough part is we can\u0026rsquo;t see messages on the commits, we only know that they are commits.\n You won\u0026rsquo;t be able to see commit messages but you can check out the commit without creating a branch. You\u0026rsquo;ll get a \u0026lsquo;detached head\u0026rsquo; warning but you can look to see the snapshot of that commit.\n Once you know which commit you need, do the same practice and create a branch with the SHA1 of the commit you need. Now you have your branch back with all of your work and you can merge it into master.\nIf master is ahead of your branch or if you make commits to master after you messed up there will be a hitch.\nIn this case if you create a save branch from an old commit and try to merge it you\u0026rsquo;ll get the following issue:\n   To see how to fix this, go to Reclaim Data Walkthrough    "
},
{
	"uri": "/python/foundation/strings/",
	"title": "Strings",
	"tags": [],
	"description": "",
	"content": "Strings We mentioned strings before because they\u0026rsquo;re a good place to introduce the print() function to create the \u0026ldquo;Hello world!\u0026rdquo; program. A string is a sequence data-type because it\u0026rsquo;s generally a sequence of characters. Since Python sees a string as a sequence, we can manipulate them in some pretty interesting ways!\nDown to basics: You can create a string literal by wrapping characters within single ', double \u0026quot;, or triple \u0026quot;\u0026quot;\u0026quot; quotes. We\u0026rsquo;ll be creating some string literals before trying to manipulate them.\nOpen up your Python Console. One way to get there is to Click on Tools \u0026gt; Python Console.\nIn your Python Console, declare these variables with your first and last name and copy/paste the message to view the output:\nSingle quote example:\ngroup_name = \u0026#39;Monty Python\u0026#39; TIP: When using single-quotes for strings, be aware that they don\u0026rsquo;t work in every situation. If I\u0026rsquo;m setting the sentence 'Monty Python's sketches are funny' to a variable, we\u0026rsquo;ll run into an error because of the apostrophe in Python's. In this case, we can use double-quote marks, but do you an alternative way to print this statement using single quotes?\nDouble quote example:\nstatement = \u0026#34;Monty Python\u0026#39;s sketches are funny\u0026#34; Triple quote example:\nmessage = \u0026#34;\u0026#34;\u0026#34;This is a string that will span across multiple lines. Using newline characters and no spaces for the next lines. The end of lines within this string also count as a newline when printed\u0026#34;\u0026#34;\u0026#34; Concatenation The action of linking things together in a series.\nWe can re-write our \u0026ldquo;Hello world\u0026rdquo; program by concatenating strings and variables! Let\u0026rsquo;s set our variables in our program like so:\nenglish_greeting = \u0026#34;Hello\u0026#34; say_hi_to = \u0026#34;world\u0026#34; exclamation = \u0026#34;!\u0026#34; Now call the print function at the bottom like so:\nenglish_greeting = \u0026#34;Hello\u0026#34; say_hi_to = \u0026#34;world\u0026#34; exclamation = \u0026#34;!\u0026#34; print(english_greeting + say_hi_to + exclamation) Notice that when we put variables within print functions they do not have \u0026quot; quotation marks around them. They\u0026rsquo;re treated differently than strings within the print function.\nYou hopefully have a printed out statement that looks something like this: Helloworld!\nHow can we use the print statement to make it more human-readable?\nChange the + signs to the following syntax:\nprint(english_greeting, say_hi_to, exclamation) But now we have Hello world ! and we\u0026rsquo;d like the ! to be directly after the word world without the space.\nWe can change about our print() statement to achieve this with:\nprint(english_greeting, say_hi_to + exclamation) Output: Hello world!\nYou can concatenate with the += operator. This will concatenate the sequence with the right operand and assigns the results to that sequence.\nname = \u0026#34;Helga\u0026#34; last_name = \u0026#34;Susan\u0026#34; name += last_name print(name) Output: HelgaSusan\nMultiplying We\u0026rsquo;ve already gone over how to use multiplication in Python, but did you know that Python can be used to multiply things other than numbers? In fact, you can use Python to multiply strings, which is actually pretty cool when you think about it. You can take a string and double, triple, even quadruple it with only a little bit of Python.\nTo multiply a string, this is the most straightforward way to go about doing it:\nprint(\u0026#34;hello\u0026#34; * 4) Output: hellohellohellohello\nprint(\u0026#34;alright\u0026#34; * 3) Output: alrightalrightalright\nIndexing The index is a value we attach to a specific character in a string depending on its order.\nIf we had the following string: greeting = \u0026quot;Hello World!\u0026quot;, the index break down can be represented with the following:\n   H e l l o  W o r l d !     0 1 2 3 4 5 6 7 8 9 10 11    The index of a character is the location of the character in the string, including spaces and punctuation. Indexes start counting with 0.\nFor example, type and run the following:\nfavorite_things = \u0026#34;\u0026#34;\u0026#34;Some of my favorite things are bird watching, jogging, listening to podcasts, and coding in Python.\u0026#34;\u0026#34;\u0026#34; Each of the individual characters has its own predetermined index as a result of the order it is in. Index 0, also written as [0] is always the first character in a string. In this case, index [0] is the capital letter S\nIn a program, if we wanted to only print() the letter \u0026ldquo;S\u0026rdquo; we\u0026rsquo;d write it this way:\nprint(favorite_things[0]) Output: S\nFirst, call upon the variable we stored the string value in, and then specify the index of the character we\u0026rsquo;re looking to print.\nType the above print() function into your Python Console and press return\nSlicing We can use the index of a string to actually slice parts of that string out. The output of our print() statement can be manipulated depending on the indexes we specify.\nTo grab the first 10 characters of a string, use the following syntax:\nstring_name[start_index:stop_index] This will start at the index that is specified before the colon and go up to (but not including) the stop_index.\nUsing our favorite_things variable, let\u0026rsquo;s grab the first 10 characters from our string. Type this into our Python Console:\nprint(favorite_things[5:10]) Output: of my \nThis slice shows the characters at indexes: 5, 6, 7, 8, 9.\nIf we start at the beginning of a string (0 index), we do not have to place a value in front of the colon. This syntax would look like:\nstring_name[:stop_index] Using this syntax with our favorite_things variable:\nprint(favorite_things[:10]) To go to the end of the string, you could also just not place a value after the colon, like the following:\nstring_name[start_index:] Using this syntax with our favorite_things variable:\nprint(favorite_things[31:]) Output: bird watching, jogging, listening to podcasts, and coding in Python.\nSkipping characters is also possible by adding a step to the slice. This is done with the following syntax:\nstring_name[start_index:stop_index:step] Using this syntax with our favorite_things variable, to only output every 2nd character of the whole string:\nprint(favorite_things[::2]) Output: Sm fm aoietig r idwthn,jgig itnn opdat,adcdn nPto.\nThe in Keyword A helpful way of being able to check whether a string contains a specific item is the in keyword. This keyword returns a boolean.\nmy_name = \u0026#34;Emily\u0026#34; print(\u0026#34;E\u0026#34; in my_name) Output: True\nIMPORTANT: Do Is this a letter? in String Exercises\nString Methods Finding the Length If we take the image above and apply the built-in python function len() it will give us the length of the string.\nType the following into your file:\ngreeting = \u0026#34;HELLO WORLD!\u0026#34; print(len(greeting)) Changing the Case The functions upper() and lower() will return a string with all of the letters contained in the original string converted to either uppercase or lowercase.\nSince strings are immutable data types, the returned string will be a new string and will have to be assigned to a new variable. Immutable means that once you have created the string, you cannot change any characters in the string to another value.\nWe can take the variable greeting that we set in the previous section, and make \u0026ldquo;HELLO WORLD\u0026rdquo; all lowercase:\ngreeting = \u0026#34;HELLO WORLD\u0026#34; print(greeting.lower()) In order to make the string greeting uppercase again, we can do as follows:\nprint(greeting.upper()) A use case for manipulating strings in this way is if your users are entering their usernames in both upper and lowercase, we can still determine whether their name is in our database by checking it against an all uppercase version.\njoin() method This method will concatenate two strings in a way that passes one string through another. Here\u0026rsquo;s an example:\ngreeting = \u0026#34;HELLO WORLD\u0026#34; We can add spaces to emphasize our greeting:\nnew_greeting = \u0026#34; \u0026#34;.join(greeting) print(new_greeting) Output: H E L L O W O R L D\nWe can illustrate this another way but inserting dots between each character:\ngreeting = \u0026#34;HELLO WORLD\u0026#34; new_greeting = \u0026#34;.\u0026#34;.join(greeting) print(new_greeting) Output: H.E.L.L.O. .W.O.R.L.D\nThis method is useful to combine a list of separate strings into a new single string. We\u0026rsquo;re telling join to insert a comma to join the separate strings into one single string.\ngreetings = [\u0026#34;hello\u0026#34;, \u0026#34;hola\u0026#34;, \u0026#34;salve\u0026#34;] string_greeting = \u0026#34;,\u0026#34;.join(greetings) print(string_greeting) Output: \u0026quot;hello,hola,salve\u0026quot;\nIf we put a space (\u0026quot; \u0026quot;.join(greetings)) instead of a comma (\u0026quot;,\u0026quot;.join(greetings)), the output would be a single string with spaces separating each word (hello hola salve).\nsplit() Method Split will do the opposite of what we just did with the join method. We\u0026rsquo;ll start with a string of things separated with spaces and split it into a list of strings.\ngreetings = \u0026#34;hello hola salve\u0026#34; string_greeting = greetings.split() print(string_greeting) Output: ['hello', 'hola', 'salve']\nWe can also remove a specific character from a string by using the split method, which also splits the string at the location of the designated character, like so:\nprint(greetings.split(\u0026#34;l\u0026#34;)) Output: ['he', '', 'o ho', 'a sa', 've']\nreplace Method The replace() method can take an original string and return an updated string with some specific replacement.\nSince Latin is a dead language, we want to replace \u0026quot;salve\u0026quot; with the Italian greeting \u0026quot;ciao\u0026quot;:\ngreetings = \u0026#34;hello, hola, salve\u0026#34; new_greeting = greetings.replace(\u0026#34;salve\u0026#34;, \u0026#34;ciao\u0026#34;) print(new_greeting) Output: \u0026quot;hello, hola, ciao\u0026quot;\nReversing Strings You may want to reverse a string to check to see if a word is a palindrome - spelled the same way backward and forward.\nOne way of doing so would be to use slicing. We went over slicing previously, and if you recall the way to get the last character in a string, is to call upon string[-1] since -1 represents the last character in the index of the string.\nThe syntax to tell Python to not only print out the last character, but also the rest of the characters in the string backwards is to use double colon: :: before the -1 as follows:\ngreeting = \u0026#34;Hello\u0026#34;[::-1] print(greeting) A way to reverse a string without using lists is join() and reversed() together.\nstring = \u0026#34;HELLO\u0026#34; reversed_string = \u0026#39;\u0026#39;.join(reversed(string)) print(reversed_string) In this case we\u0026rsquo;re taking a string, setting it to variable string and join() is merging all of the characters resulting from the reversed iteration into a new string.\nIt can also be written like so:\nreversed_string = \u0026#39;\u0026#39;.join(reversed(\u0026#34;HELLO\u0026#34;)) print(reversed_string) Regardless of whether or not you set the original string to a variable, since a new string is formed from the join() method, it has to be set to a variable in order to save the reversed string to memory in order to be printed out.\nApplying your knowledge ## Describe the sketch comedy group ## Create a variable with their name (Monty Python) ## Create a short description in the form of a string assigned to a variable (Monty Python was a British comedy group) ## Create a variable assigned to a number that represents the year they were formed (1969) ## Introduce the group in a sentence ## Assign a variable whose value will be a concatenation of the above variables into a sentence that makes sense. ## Using the above variables, write the sentence in two different ways that we have learned to concatenate strings, numbers and variables in a print() statement to avoid a TypeError (Hint: Use + and ,) Strings follow-along  Create a string called phrase that is set to the value of Don't count your chickens before they hatch Create a second string called slogan that is set to the value of For Everything Else, There’s MasterCard Create a third string called combined that is equal to phrase, a period(.), and slogan concatenated. Print out the new value of combined Print out phrase three times in a row. Do this with the multiplying strings method. Print out the 7th character in slogan Print out the last character in combined Print out every other letter in phrase Print out the 17th - 24th indexes (inclusive) of phrase Print out every other letter in combined Print out if it is True or False that the letter m is in slogan. (Do not hard code. Use the in operator) Print out the value of combined, but in all caps Print out combined split up by spaces Print out slogan backwards  Strings Exercises Do the Following Three Strings Exercises\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/dom-manipulation-labs/",
	"title": "DOM Manipulation and DOM Events Labs",
	"tags": [],
	"description": "",
	"content": "Selecting Nodes \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;header\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li class=\u0026#34;first\u0026#34;\u0026gt;Item 1\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;selected\u0026#34;\u0026gt;Item 2\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;last\u0026#34;\u0026gt;Item 3\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;div class=\u0026#34;col\u0026#34;\u0026gt; \u0026lt;section\u0026gt; \u0026lt;h2\u0026gt;Section 1\u0026lt;/h2\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;section class=\u0026#34;current\u0026#34;\u0026gt; \u0026lt;h2 class=\u0026#34;highlight\u0026#34;\u0026gt;Section 2\u0026lt;/h2\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;section\u0026gt; \u0026lt;h1\u0026gt;Section 3\u0026lt;/h1\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Using the above html:\n Get the header element Get all the section elements Get the section element with class=\u0026quot;current\u0026rdquo; Get the section that comes after the current section Get the h2 node from the section before the \u0026lsquo;current\u0026rsquo; section Get the div that contains the section that has an h2 with a class of \u0026lsquo;highlight\u0026rsquo; Get all the sections that contain an H2 (using a single statement);  The solution can be found here.\n   Go to Editing Nodes Lesson    Editing the DOM \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h2\u0026gt;Shopping List\u0026lt;/h2\u0026gt; \u0026lt;ul id=\u0026#34;list\u0026#34;\u0026gt; \u0026lt;li\u0026gt;Pizza\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Coffee\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Clif Bars\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Veggie Burgers\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Using the above html:\n Update the \u0026lsquo;Coffee\u0026rsquo; item to say \u0026lsquo;Fair Trade Coffee\u0026rsquo; Remove \u0026lsquo;Veggie Burgers\u0026rsquo; from the list Add an item \u0026lsquo;Cheese Whiz\u0026rsquo; Clear the list and programmatically add the following items: ['protein powder', 'muscle milk', 'power bars'] Add the class \u0026lsquo;important\u0026rsquo; to the muscle milk item.  The solution can be found here.\n   Go to DOM Events Lesson    Build a TODO App Create a simple TODO application\n Show an unordered list of todo\u0026rsquo;s Show an input to enter a new todo Show a button to add a todo (or use the ENTER key). When the button is clicked (or the ENTER key is pressed):  The text from the input box is used to add a list item to the bottom of the list The text from the input box is cleared out.   When the user clicks on a list item, it is marked as completed. Use some CSS to style the completed TODOs, such as a line-through or a gray text color. Extra Credit: - Add a button that removes all TODOs that have been completed.  One solution (which uses a backing model) can be found here.\nAdditional Resources  MDN Reference: DOM Node MDN Reference: Document MDN Reference: NodeList  "
},
{
	"uri": "/javascript/foundations/closures/",
	"title": "Closures",
	"tags": [],
	"description": "",
	"content": "An Introduction to Closures in JavaScript.\nLearning Objectives  Define a closure Explain why closures are used Write a function that uses a closure to control access to data  What is a Closure?  A closure is a function or object that has a special binding to one or more variables. Specifically the binding is to a variable or variables that:  were in scope at the time that the function or object was created but have gone out of scope by the time the function or object is used   Therefore, these variables can only be accessed from the closure, they cannot be accessed from outside the closure.  Example:\nfunction makeAdder(x) { // makeAdder is a function builder  return function (y) { // this function closes on `x`  return x + y; } } // NOTE: we could also write this using arrow functions: // const makeAdder = x =\u0026gt; y =\u0026gt; x + y;  const add3 = makeAdder(3); // a is always 3 for add3 because a is out of scope but still referenced console.log(add3(5)); // 8, note that we cannot change a but can provide a value for b  const add10 = makeAdder(10); // a is always 10 for add10 console.log(add10(12)); // 22  console.log(add3(100)); // a is still 3 for `add3`, showing that add3 and add10 have different values for `a` In the above code:\n add3 and add10 are assigned to a closure that is returned from makeAdder the closure binds a to a specific value (3 or 10) two closures are created and returned, one with an a of 3 and the other with an a of 10  Closures Encapsulate and Hide Variables  A function or object is called a \u0026ldquo;closure\u0026rdquo; because it closes around some variables. It\u0026rsquo;s like an envelope containing (or encapsulating) these variables. When you send that envelope around, it still contains bindings to all of the variables that were in scope when it was created. These hidden variables are accessible to the closure itself but hidden from any code outside of the closure.  Why Use Closures?  Closures are commonly used to give objects data privacy. Data privacy is an essential property that helps us program to an interface, not an implementation. This is an important concept that helps us build more robust software because implementation details are more likely to change in breaking ways than interface contracts.  A More Practical Example:\nfunction makeCounter(initialValue = 0) { let count = initialValue; // `count` is our bound (hidden) variable  return { // return an object with methods that are closures  inc: function () { count += 1; }, // `inc`, `dec`, `reset`, and `get` are the API  dec: function () { count -= 1; }, // they provide controlled access to `count`  reset: function () { count = 0; }, get: function () { return count; } }; } const myCounter = makeCounter(7); // create a counter object myCounter.inc(); // `count` is now `8` console.log(myCounter.get()); // `8`  // the following line of code attempts to modify `count` // but it only adds a harmless `count` property that is ignored by the closure myCounter.count = \u0026#39;banana\u0026#39;; console.log(myCounter.get()); // `8`, our counter still uses the hidden (bound) `count` variable 😀. Closures avoid this  Another advantage of closures is that you can encapsulate variables without needing objects. This functional approach to encapsulation avoids the need for the this keyword, avoiding complexity in many cases. Programming without this in JavaScript can make your code more flexible.  Lab See instructions here.\nSummary  Closures provide for encapsulation of implementation details, hiding them from the outside. Closures bind certain variables to a function so that even though the variable goes out of scope, it is still in use (being referenced) by the closure. Closures can be used instead of objects for data encapsulation. Closures are a powerful part of Functional Programming.  "
},
{
	"uri": "/javascript/foundations/labs/classes-lab/",
	"title": "Classes Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch classes.js Add the following code to classes.js:\n/* TODO: Create an Pet class with a constructor and a speak method. The constructor should take a single argument, the name of the pet. The speak method should write to the console the message \u0026#34;\u0026lt;name\u0026gt; makes a noise.\u0026#34; */ /* TODO: Create an Dog class that extends the Pet class. It should have a constructor and a speak method. The constructor should take a single argument, the name of the pet and call the super class constructor. The speak method should write to the console the message \u0026#34;\u0026lt;name\u0026gt; says woof, woof.\u0026#34; */ /* TODO: Create a Cat class that extends the Pet class. It should have a constructor and a speak method. The constructor should take a single argument, the name of the pet and call the super class constructor. The speak method should write to the console the message \u0026#34;\u0026lt;name\u0026gt; says meow.\u0026#34; */ const pets = [ new Dog(\u0026#39;Mitzie\u0026#39;), new Cat(\u0026#39;Felix\u0026#39;) ]; pets.forEach(pet =\u0026gt; pet.speak()); Step 2: Complete the code and test Complete the TODOs in the above code.\nTest your solution with:\nnode classes.js The expected output is:\nMitzie says woof, woof. Felix says meow. "
},
{
	"uri": "/java/foundations/cli-lab/",
	"title": "CLI Lab",
	"tags": [],
	"description": "",
	"content": "The goal of this lab is to create a basic Command Line Interface in Java. There are a general set of features we are looking for that you will need to include but feel free to use your creativity and knowledge to go above and beyond these requirements!\nA command line interface is a tool that you can interact with from your terminal. Throughout this lab we will create a CLI, compile it, and interact with it in our terminal.\nEverything you need to know in order to accomplish these goals can be found in the Java Foundations lessons.\nMinimum Requirements Object Design  Define 1 interface  2 fields 1 method   Implement your interface in 2 different classes  These will implement all fields and methods from the interface as well as an additional 1 field and 1 method specific to the class    App  Maintain 1 collection that can hold both of your class types  Ability to create a new object and add it to your collection Ability to retrieve an object from your collection Ability to call on some behavior of an object to update its state Ability to delete an object from the collection    Design Time! Our project is Object-Oriented and so should our work process. So before we start setting up our project, let\u0026rsquo;s design our objects.\nFor example, a pencil model might look like:\nState\n   Field Type     length int   color String   hardness int   sharpened boolean    Behavior\n   Method Return Type     write(String) String   sharpen() void     Spend 15 minutes choosing and designing the objects you want to work with  Remember they need to be related enough that you can create an interface that applies to both Map out the state and behavior that will be defined in your interface Map out the state and behavior that will be in both your classes   Spend 5 minutes explaining your model to a partner  Allow time for your partner to offer feedback and suggestions Swap and listen to their idea   Spend a couple minutes making any adjustments before moving on  Setup a \u0026ldquo;Hello World\u0026rdquo; CLI   Create new project in IntelliJ\n Gradle Java \u0026gt;=11 Set package (`com.homedepot.om.student) Set artifactid (choose a name for your cli) click through    Create a main class\n Right click your src/main/java folder and create a new package Right click your package and create a new Java Class called App Create a main method in your class like  public static void main(String[] args) { for (String s : args) { System.out.println(s + \u0026#34; \u0026#34;); } }    ℹ️ In a main method, our parameter args will be filled in from any arguments passed from the command line. What will the above main method do?\n  Configure a run  In the top right of your IntelliJ IDE, click Add Configuration Click the + in the top right of the window Choose application  Give the Run a name Next to Main Class browse to find your App In Program Arguments write \u0026ldquo;Hello World\u0026rdquo;  These are the Strings that will be passed into args, every space will start a new String   For Class Path of Module select your main module (should end in .main) In JRE choose a version \u0026gt;=11 Click Ok   Click the play button next to your configuration    "
},
{
	"uri": "/web-essentials/webmastery-foundations/jquery/",
	"title": "DOM Manipulation with jQuery",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  jQuery provides simpler syntax for adding event handlers to the DOM - separating application logic from content markup  Skills  Learn how to use jQuery, a JavaScript library, to create interactive web pages Use jQuery to create event listeners Practice reading documentation  Intro jQuery is a 3rd-party library that is intended to make front-end development tasks — particularly those involving DOM selection and manipulation — easier, faster, and more fun.\nJavascript library A Javascript Library is a collection of Javascript functions and methods that make writing Javascript an easier, smoother and ultimately shorter experience.\nUnder the hood, all Javascript libraries are written using Javascript.\nHere is a list of some Javascript libraries\nJS libraries are not the same thing as a JS framework:\n A framework defines the architecture of a project (e.g., syntax, folder structure). Basically, a set of rules to follow and usually controls the execution of code. Examples: AngularJS, Ember.js.  Sometimes \u0026ldquo;library\u0026rdquo; and \u0026ldquo;framework\u0026rdquo; are used interchangeably, but they are not the same. The differences will be more apparent with some experience with both.\nWhat does jQuery provide us? jQuery helps manipulate the DOM, allowing complex manipulations using less code with less hassle. jQuery\u0026rsquo;s syntax was developed to mimic the CSS selector syntax, making code easier to develop, read, and manage. Also, the syntax is more concise, and jQuery solves many cross-browser compatibility issues for us.\nUsing jQuery - Demo Installation jQuery is a client side library, which means it needs to be included in our HTML. To do this, we have some options:\n Reference Directly from a server, like: jQuery\u0026rsquo;s website  \u0026lt;script src=\u0026#34;http://code.jquery.com/jquery-1.11.1.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;  From a CDN (content delivery network), like:  https://cdnjs.com/ Google Hosted Libraries    \u0026lt;script src=\u0026#34;http://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;  Download a copy of jQuery to host on your own server: https://cdnjs.com/  Both the Google Hosted Libraries and the jQuery site will all allow you to download a copy of jQuery to include in your projects.\n Use a package manager such as bower or npm or yarn.  DOM manipulation with jQuery The following are tasks possible with jQuery:\n select a DIV and change it\u0026rsquo;s content append a new DIV with some content to a web page handle forms where users want to dynamically add elements to the page listen for events on a collection of DIVs or other HTML elements  Selecting an element with jQuery To select an element in the DOM, use the global jQuery function:\n// Basic syntax for jQuery selections $(\u0026#39; \u0026#39;) // Selects a particular element by tag $(\u0026#39;h2\u0026#39;) // selects all h2 elements  // Selects by ID, use the same syntax as CSS selectors $(\u0026#39;#someID\u0026#39;) // selects the element with ID=\u0026#34;someID\u0026#34;  // Selects all elements of a particular class $(\u0026#39;.someClass\u0026#39;) // Selects all elements of the class \u0026#34;someClass\u0026#34;  // Using more complicated CSS selectors $(\u0026#39;p.anotherClass\u0026#39;) // Selects all \u0026lt;p\u0026gt; tags that also have the class \u0026#34;anotherClass\u0026#34; (\u0026lt;p class=\u0026#34;anotherClass\u0026#34;) If you use variable assignment when doing a selection, a \u0026ldquo;jQuery\u0026rdquo; object is returned\n// Prepend \u0026#39;$\u0026#39; to variable names to make it a jQuery object var $jqObject = $(\u0026#39;p\u0026#39;); // Returns a jQuery object containing all \u0026lt;p\u0026gt; tags  // Not necessary to prepend \u0026#39;$\u0026#39; to variables, it\u0026#39;s just to remember what a variable is being used for. var jqObject = $(\u0026#39;p\u0026#39;); // This is functionally identical to the version above Selecting a DOM element and changing it\u0026rsquo;s content In this HTML:\n\u0026lt;div id=\u0026#34;myDiv\u0026#34;\u0026gt;Hello world!\u0026lt;/div\u0026gt; var divToManipulate = document.getElementById(\u0026#39;myDiv\u0026#39;); divToManipulate.innerHTML = \u0026#34;Goodbye world!\u0026#34;; Using jQuery, this can be updated to a one-liner:\n$(\u0026#39;#myDiv\u0026#39;).html(\u0026#34;Goodbye world!\u0026#34;); See it in action here.\nTo save our selection as a jQuery object, update the code to:\n First, select the desired element and save it as a jQuery object  var $myDiv = $(\u0026#39;#myDiv\u0026#39;);  Then use the jQuery object to perform the task  $myDiv.text(\u0026#34;Goodbye world!\u0026#34;); jQuery made the original example easier to use by:\n using the same syntax as CSS to select elements allowing chaining methods together to accomplish goals (i.e., $().html(...) ), making code shorter and easier to understand dealing with any cross-browser compatibility issues  Appending a DOM element to a web page \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Hello World!\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Adding a new DIV using vanilla JavaScript looks like:\nvar myDiv = document.getElementById(\u0026#39;container\u0026#39;); var newP = document.createElement(\u0026#39;p\u0026#39;); newP.innerHTML = \u0026#34;Hello complicated, multi-step world of adding an element to the DOM!\u0026#34;; myDiv.appendChild(newP); And in jQuery, it looks like this:\n$(\u0026#39;#container\u0026#39;).append(\u0026#34;\u0026lt;p\u0026gt;Hello simple insertion using jQuery chaining\u0026lt;/p\u0026gt;\u0026#34;);  First selects the DIV with id=\u0026quot;container\u0026quot; A new paragraph element is automatically created using core jQuery selector function. The new text is inserted to the newly created paragraph element.  In effect, the new HTML looks like this after the jQuery is run:\n\u0026lt;div id=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;p\u0026gt; Hello simple insertion using jQuery chaining \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; You can see this in action on JSBin.\nModifying Styles (CSS) Using jQuery It is possible to create or update CSS style attributes in jQuery using the .css() method\n$(\u0026#34;#myDiv\u0026#34;).css(\u0026#34;color\u0026#34;, \u0026#34;red\u0026#34;); This will change the color of all text inside the DIV with id=\u0026quot;myDiv\u0026quot; to red.\nCheck this out here\nTo get all elements that have the same class, like class=\u0026quot;myClass\u0026quot;, use the class selector to modify the color of all of them at once:\n$(\u0026#34;.myClass\u0026#34;).css(\u0026#34;color\u0026#34;, \u0026#34;blue\u0026#34;); Live example here\nThe following sets the text in all elements of class=\u0026quot;myClass\u0026quot; to a random color:\nvar randColorValue = function() { return Math.floor( Math.random() * 255 ); } var randColor = function() { var red = randColorValue(); var green = randColorValue(); var blue = randColorValue(); return \u0026#34;rgb(\u0026#34; + red + \u0026#34;,\u0026#34; + green + \u0026#34;,\u0026#34; + blue + \u0026#34;)\u0026#34;; } $(\u0026#34;.myClass\u0026#34;).css(\u0026#34;color\u0026#34;, randColor() ); Live example here\nAdding and Removing Elements Using jQuery Sometimes in a dynamic web application, user-input is meant to trigger the addition or removal of content or functionality. jQuery allows the creation of new DOM elements and insert them into the DOM, or remove existing elements (and any content they contain) from the DOM.\nLook at the following:\n\u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;outerContainer\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;innerItem innerItemHeader\u0026#34;\u0026gt;Enjoy some hipster ipsum:\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;innerItem\u0026#34;\u0026gt; Aesthetic migas paleo McSweeney\u0026#39;s, pork belly Kickstarter Echo Park sriracha keytar disrupt viral drinking vinegar fanny pack typewriter. \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; Here is an element we will add to the page:\n\u0026lt;div class=\u0026#34;innerItem\u0026#34;\u0026gt; Farm-to-table Godard roof party bespoke, fashion axe mustache vinyl. \u0026lt;/div\u0026gt; Add this DIV using jQuery with the following:\n$newDiv = $(\u0026#39;\u0026lt;div\u0026gt;\u0026#39;); // Add hipster ipsum content $newDiv.html(\u0026#34;Farm-to-table Godard roof party bespoke, fashion axe mustache vinyl.\u0026#34;); // Set it\u0026#39;s class to innerItem $newDiv.addClass(\u0026#34;innerItem\u0026#34;); // Append our new element $(\u0026#39;#outerContainer\u0026#39;).append($newDiv); See this in action (and play around with it) on repl.it.\nSummary   jQuery makes JavaScript super friendly and easy to write. a lot of websites are using jQuery, soon you will too. Remember that it\u0026rsquo;s always good to know how to use what is called vanilla JavaScript, or JavaScript without a library.\n  Please spend some time reviewing the jQuery documentation.\n     Go to the jQuery Labs    "
},
{
	"uri": "/javascript/foundations/error-handling/",
	"title": "Error Handling",
	"tags": [],
	"description": "",
	"content": "What is Error Handling  Error handling is where code is written to detect and/or respond to an error. Errors can occur for many reasons, such as invalid data, an invalid response from a server, or a timeout. JavaScript provides the try / catch mechanism for handling errors.  Try / Catch  Without proper error handling a program terminates when an error occurs and prints the error information to the console. Using a try..catch allows the program to \u0026ldquo;catch\u0026rdquo; the error and instead of terminating, do something more reasonable.  Syntax\ntry { // our code which might encounter an error } catch (err) { // error handling }  Error Objects When a runtime error occurs, JavaScript generates an object containing the details about it. The object is then passed as an argument to catch in the line catch(err). For all built-in errors, the error object inside catch block has two main properties:\n   property description     name the name of the error   message Textual message containing error details    try { console.log(\u0026#34;Start of try block\u0026#34;); console.log(x); console.log(\u0026#34;End of try block\u0026#34;); } catch (err) { console.log(`Error Name: ${err.name}`); console.log(`Error Message: ${err.message}`); } console.log(\u0026#34;...Then the execution continues\u0026#34;); Output:\nStart of try block Error Name: ReferenceError Error Message: x is not defined ...Then the execution continues JavaScript Error Types    Error Type Description     SyntaxError Raised when a syntax error occurs while parsing JavaScript code.   ReferenceError Raised when an invalid reference is used.   TypeError Raised when the type of a variable is not as expected.   RangeError Raised when a numeric variable exceeds its allowed range.    See Errors | MDN for more information.\nThrowing User Defined Errors You can define and \u0026ldquo;throw\u0026rdquo; an error that you define.\nFor example:\n you want a user\u0026rsquo;s age but you do not want any negative numbers if a negative number is given, you want an error raised in our case, the placement of a negative age could be treated as a RangeError  try { let age = -100; if(age \u0026lt; 0){ throw new RangeError(\u0026#34;Invalid age: no negatives\u0026#34;); // our custom error message  } console.log(`Your age is: ${age}`); } catch(err) { console.log(`Received a ${err.name}, with the message: ${err.message}`); } console.log(\u0026#34;...Then the execution continues\u0026#34;);  TIP: You can use anything as an error object, but often it\u0026rsquo;s better to use objects, preferably with name and message properties (to stay somewhat compatible with built-in errors).\nLab See instructions here.\nSummary  Error handling is the detection and reporting of errors that may occur during program execution JavaScript provides the try...catch mechanism for handling errors. JavaScript provides built-in Error objects You can define your own custom error objects  Additional Resources  https://javascript.info/try-catch[Try Catch Examples^]  "
},
{
	"uri": "/react/foundations/react-router-v4/",
	"title": "React Router v4",
	"tags": [],
	"description": "",
	"content": "Adding routes to React applications using React Router version 4.\nConcepts  Introduce React Router Add dynamic routes to an application  Introduction  Now that you understand how to build a single page application, it\u0026rsquo;s time to discuss routing. You may already be familiar with routing from building RESTful API\u0026rsquo;s with Express or a similar server-side framework.  For example:\nroutes/index.js\napp.get(\u0026#39;/\u0026#39;, handleIndex) // root or home route app.get(\u0026#39;/products\u0026#39;, allProducts) // route to get all products app.get(\u0026#39;/products/:id\u0026#39;, showProduct) // route to get a single product  These are server-side routes. The server determines how to process incoming requests based on the HTTP request\u0026rsquo;s URL and method. Server-side routing is used to either:  decide what view to render and return to the browser (in the case of server-side rendering) decide what data to return to the browser (in the case of client-side rendering where the server acts as an API for processing data)    So then what is client-side routing and why do we need it?\nMotivation for Client Side Routing  Client-side routing is used to decide what view to display to the user. The idea is that we want a SPA (single-page app) to look and behave like a server-side rendered app (except be more responsive) or like a desktop app (except run in a browser). The SPA app should display various views to the user even though there is only a single page being loaded from the server. By using client-side rendering and routing, the SPA app can swap out different views based on interactions and navigations from the user. Which view to display is determined by the SPA application\u0026rsquo;s routing.  Here is an illustration:\nClient and Server Routing Working Together\n NOTE: With Single Page Apps (SPAs) the responsibility of deciding which view to display to the user has shifted from the server (in server-side rendering) to the client. The server will still have routes, but these routes do not decide what the user sees, only how data is processed.\n Getting Started with React Router A Simple Example Let\u0026rsquo;s start by taking a look at a simple example.\nFirst the demo:\n  Click on the links in the demo above and observe that the URL changes. With client-side routing we can manipulate the browser URL without reloading anything from the server!\nNow the source code:\nApp.js:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Route, Link} from \u0026#39;react-router-dom\u0026#39; // Imports from react-router-dom import \u0026#39;./style.css\u0026#39; const Home = (props) =\u0026gt; \u0026lt;section className=\u0026#34;home\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; // Define some simple components const News = (props) =\u0026gt; \u0026lt;section className=\u0026#34;news\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;News\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Weather = (props) =\u0026gt; \u0026lt;section className=\u0026#34;weather\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Weather\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Sports = (props) =\u0026gt; \u0026lt;section className=\u0026#34;sports\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Sports\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; {/* We must wrap all `Link` and `Route` components as children of a `Router` */} \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;Link to=\u0026#34;/\u0026#34;\u0026gt;Home\u0026lt;/Link\u0026gt; {/* Provide some `Links` to specific URLs that we will route between */} \u0026lt;Link to=\u0026#34;/news\u0026#34;\u0026gt;News\u0026lt;/Link\u0026gt; \u0026lt;Link to=\u0026#34;/weather\u0026#34;\u0026gt;Weather\u0026lt;/Link\u0026gt; \u0026lt;Link to=\u0026#34;/sports\u0026#34;\u0026gt;Sports\u0026lt;/Link\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Route exact path=\u0026#34;/\u0026#34; component={Home} /\u0026gt; {/* Provide some `Routes` */} \u0026lt;Route path=\u0026#34;/news\u0026#34; component={News} /\u0026gt; {/* When the URL matches the `path` */ } \u0026lt;Route path=\u0026#34;/weather\u0026#34; component={Weather} /\u0026gt; {/* then the specified component will be rendered */} \u0026lt;Route path=\u0026#34;/sports\u0026#34; component={Sports} /\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;)) Routes with the exact property:\n Question: What is the exact doing on the Home Route? Why do we need that? Answer: It is possible to have more than one Route match a given URL.  Since all paths begin with / the Home Route will always match and the Home component be always be displayed unless we specify the exact property for the Home Route.   Try removing the exact property and test it out to see what happens!   IMPORTANT: Be sure to use react-router-dom when writing code for a Browser environment. There is another library simply called react-router but it only includes facade / interface code and does not contain the Browser specific code. The Browser specific code lives in its own library because React can be used to write either Browser apps or native apps.\n Routes and Links Let\u0026rsquo;s talk a bit more about Routes and Links.\n A Route is a component that conditionally renders its child component whenever the Route\u0026rsquo;s path is matched in the Browser\u0026rsquo;s URL. A Link is just a wrapper (HOC) around an anchor tag. When you click on a Link the React Router is notified so that it can manage the Browser\u0026rsquo;s URL, the Browser\u0026rsquo;s history, and create and pass additional route specific props to the appropriate Route component.  Styling Links and Using NavLinks  You can style your Link components to look like anchors, tabs, buttons, or however you want them to look. You can use inline styles, CSS classes, or CSS in JS libraries to style the Link components. There is also a NavLink component that works just like Link but also adds the ability to control the style of the active Link - i.e. the Link that is currently matching the Browser\u0026rsquo;s URL.  Here is the example from above modified to use NavLinks:\n  Here is the source code that uses the NavLinks:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Route, NavLink} from \u0026#39;react-router-dom\u0026#39; import \u0026#39;./style.css\u0026#39; const Home = (props) =\u0026gt; \u0026lt;section className=\u0026#34;home\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const News = (props) =\u0026gt; \u0026lt;section className=\u0026#34;news\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;News\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Weather = (props) =\u0026gt; \u0026lt;section className=\u0026#34;weather\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Weather\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Sports = (props) =\u0026gt; \u0026lt;section className=\u0026#34;sports\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Sports\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;NavLink exact to=\u0026#34;/\u0026#34;\u0026gt;Home\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/news\u0026#34;\u0026gt;News\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/weather\u0026#34;\u0026gt;Weather\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/sports\u0026#34;\u0026gt;Sports\u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Route exact path=\u0026#34;/\u0026#34; component={Home} /\u0026gt; \u0026lt;Route path=\u0026#34;/news\u0026#34; component={News} /\u0026gt; \u0026lt;Route path=\u0026#34;/weather\u0026#34; component={Weather} /\u0026gt; \u0026lt;Route path=\u0026#34;/sports\u0026#34; component={Sports} /\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;)) React Router Docs The React Router Documentation is extremely well written, complete with interactive demos.\n TIP: When building web apps make sure to use the WEB version of the documentation.\n A Few Observations The documentation is separated into 3 separate sections:\n EXAMPLES - interactive examples with corresponding code GUIDES - Detailed explanations of introductory and advanced concepts API - Descriptions of each component and it\u0026rsquo;s props  You\u0026rsquo;ll want to start with the first 2 links under GUIDES. Take a few minutes to read through them and familiarize yourself.\nAfterwards, you can jump right into the basic example. If you\u0026rsquo;ve followed the Quick Start guide, you\u0026rsquo;ll have your own local copy of the interactive guide (EXAMPLES). This is great to have on hand for future exploration.\nThe API portion is clear and concise. Refer to it when you see a new component in the EXAMPLES section.\nYou don\u0026rsquo;t need to grok (understand) all pieces of the documentation immediately. Just make sure you are comfortable with the Basic example.\nActivity (optional) - Get to Know the React Router Docs Using the React Router Documentation\u0026hellip;\n  Read the Philosophy and Quick Start sections. As you\u0026rsquo;re reading, think about the following questions and how you would answer them:\n What is the philosophy of React Router? What are React Router\u0026rsquo;s core building blocks? When trying to solve a problem with React Router, how should you approach creating a solution? What benefits (if any) do you see coming from using React Router in your application?    Use create-react-app and the quick start section to create your own local copy of the Basic Routing example (feel free to copy/paste).\n  Take a few minutes to navigate to the available URL\u0026rsquo;s and become comfortable with the syntax/code.\n  Nested Routes  Nested routes allow us to subdivide a view into multiple subviews that can be dynamically loaded inside the parent view. Extending the example from above, we can add nested routes such as /sports/football, /sports/basketball, and /sports/baseball. Try clicking on the Sports Link below and then clicking on the nested Links (Football, Basketball, and Baseball) to see the nested Routes get loaded.  Notice what happens to the browser URL! Also notice that the Sports component remains visible when it\u0026rsquo;s child Routes are being rendered!      Here is the source code:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Route, NavLink} from \u0026#39;react-router-dom\u0026#39; import \u0026#39;./style.css\u0026#39; const Home = (props) =\u0026gt; \u0026lt;section className=\u0026#34;home\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const News = (props) =\u0026gt; \u0026lt;section className=\u0026#34;news\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;News\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Weather = (props) =\u0026gt; \u0026lt;section className=\u0026#34;weather\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Weather\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const wikiCommons = \u0026#39;https://upload.wikimedia.org/wikipedia/commons/\u0026#39; const footballSrc = wikiCommons + \u0026#39;1/1b/American_football_icon_simple.svg\u0026#39;; const basketballSrc = wikiCommons + \u0026#39;7/7a/Basketball.png\u0026#39;; const baseballSrc = wikiCommons + \u0026#39;9/92/Baseball.svg\u0026#39;; const Football = () =\u0026gt; ( // We define some components to render in our nested routes.  \u0026lt;article\u0026gt; \u0026lt;img width=\u0026#34;100\u0026#34; src={footballSrc} alt=\u0026#34;Football\u0026#34; /\u0026gt; \u0026lt;/article\u0026gt; ) const Basketball = () =\u0026gt; ( \u0026lt;article\u0026gt; \u0026lt;img width=\u0026#34;100\u0026#34; src={basketballSrc} alt=\u0026#34;Basketball\u0026#34; /\u0026gt; \u0026lt;/article\u0026gt; ) const Baseball = () =\u0026gt; ( \u0026lt;article\u0026gt; \u0026lt;img width=\u0026#34;100\u0026#34; src={baseballSrc} alt=\u0026#34;Baseball\u0026#34; /\u0026gt; \u0026lt;/article\u0026gt; ) const Sports = (props) =\u0026gt; ( \u0026lt;section className=\u0026#34;sports\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Sports\u0026lt;/h1\u0026gt; \u0026lt;div className=\u0026#34;flex-container\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;sports-nav\u0026#34;\u0026gt; \u0026lt;ul style={{ listStyleType: \u0026#34;none\u0026#34;, padding: 10, textAlign: \u0026#39;left\u0026#39; }}\u0026gt; \u0026lt;li\u0026gt;\u0026lt;NavLink to=\u0026#34;/sports/football\u0026#34;\u0026gt;Football\u0026lt;/NavLink\u0026gt;\u0026lt;/li\u0026gt; {/* We can add `Links` (or `NavLinks`) */} \u0026lt;li\u0026gt;\u0026lt;NavLink to=\u0026#34;/sports/basketball\u0026#34;\u0026gt;Basketball\u0026lt;/NavLink\u0026gt;\u0026lt;/li\u0026gt; {/* to the component that is rendered */} \u0026lt;li\u0026gt;\u0026lt;NavLink to=\u0026#34;/sports/baseball\u0026#34;\u0026gt;Baseball\u0026lt;/NavLink\u0026gt;\u0026lt;/li\u0026gt; {/* in the parent route. */} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;sports-main\u0026#34;\u0026gt; \u0026lt;Route path=\u0026#34;/sports/football\u0026#34; component={Football} /\u0026gt; {/* We can add `Routes` inside the */} \u0026lt;Route path=\u0026#34;/sports/basketball\u0026#34; component={Basketball} /\u0026gt; {/* component that is rendered in the */} \u0026lt;Route path=\u0026#34;/sports/baseball\u0026#34; component={Baseball} /\u0026gt; {/* parent route. */} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; ) const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;NavLink exact to=\u0026#34;/\u0026#34;\u0026gt;Home\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/news\u0026#34;\u0026gt;News\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/weather\u0026#34;\u0026gt;Weather\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/sports\u0026#34;\u0026gt;Sports\u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Route exact path=\u0026#34;/\u0026#34; component={Home} /\u0026gt; \u0026lt;Route path=\u0026#34;/news\u0026#34; component={News} /\u0026gt; \u0026lt;Route path=\u0026#34;/weather\u0026#34; component={Weather} /\u0026gt; \u0026lt;Route path=\u0026#34;/sports\u0026#34; component={Sports} /\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;))  NOTE: The above example illustrates the dynamic and decentralized features of React Router v4 - i.e. Links and Routes can be added in any part of a React application. Another way to think about this is that we added nested routes without modifying the main App component.\n  NOTE: We did not put an exact property on the Sports route even though it is now a parent of the Football, Basketball, and Baseball routes. This is because we want the Sports route to render even when one of its child routes is being rendered. What would happen if we did put an exact on the Sports route (hint: it would be bad)?\n  TIP: The above code is getting pretty long. In a real project this would be a good time to refactor it into multiple files to improve readability and maintainability. How would you better organize the code above?\n Defining Routes with URL Parameters  Often we may need to define a Route that displays specific data depending on what the user clicked. For example, if a user clicks on a specific news article, we want the News component to display the article the user clicked on. So a single Route can be used to display any dynamic data. But how do we communicate which data to render?  Below is a demo.\n Try clicking on the Sports Route and then click on any sport. Notice that this demo doesn\u0026rsquo;t look much different from the previous demo but (as we shall soon see) the implementation is very different. One clue is that the URL is now different when we are on a nested route (such as football, basketball, or baseball).    And now for the source:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Route, NavLink} from \u0026#39;react-router-dom\u0026#39; // To illustrate the data-driven behavior, we have moved all sports data to a separate file. // The data could also be dynamically loaded from a server! import sports from \u0026#39;./sports-data\u0026#39;; import \u0026#39;./style.css\u0026#39; const Home = (props) =\u0026gt; \u0026lt;section className=\u0026#34;home\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const News = (props) =\u0026gt; \u0026lt;section className=\u0026#34;news\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;News\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Weather = (props) =\u0026gt; \u0026lt;section className=\u0026#34;weather\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Weather\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; // The `Sport` component can render any sport as long as the data (the JavaScript object) // contains the properties: `id`, `title`, and `imageSrc`. const Sport = (props) =\u0026gt; { console.log(\u0026#39;props:\u0026#39;, props); const sport = sports.find( sport =\u0026gt; sport.id === Number(props.match.params.id) ) return ( \u0026lt;article\u0026gt;\u0026lt;img width=\u0026#34;100\u0026#34; src={sport.imageSrc} alt={sport.title} /\u0026gt;\u0026lt;/article\u0026gt; ) } const Sports = (props) =\u0026gt; { const links = sports.map(sport =\u0026gt; \u0026lt;li\u0026gt;\u0026lt;NavLink to={`/sports/${sport.id}`}\u0026gt;{sport.title}\u0026lt;/NavLink\u0026gt;\u0026lt;/li\u0026gt;) return ( \u0026lt;section className=\u0026#34;sports\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Sports\u0026lt;/h1\u0026gt; \u0026lt;div className=\u0026#34;flex-container\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;sports-nav\u0026#34;\u0026gt; \u0026lt;ul style={{ listStyleType: \u0026#34;none\u0026#34;, padding: 10, textAlign: \u0026#39;left\u0026#39; }}\u0026gt; {links} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;sports-main\u0026#34;\u0026gt; {/* Using a URL parameter in the following Route, we can define a single `Route` to render any Sport. */} \u0026lt;Route path=\u0026#34;/sports/:id\u0026#34; component={Sport} /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; ) } const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;NavLink exact to=\u0026#34;/\u0026#34;\u0026gt;Home\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/news\u0026#34;\u0026gt;News\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/weather\u0026#34;\u0026gt;Weather\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/sports\u0026#34;\u0026gt;Sports\u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Route exact path=\u0026#34;/\u0026#34; component={Home} /\u0026gt; \u0026lt;Route path=\u0026#34;/news\u0026#34; component={News} /\u0026gt; \u0026lt;Route path=\u0026#34;/weather\u0026#34; component={Weather} /\u0026gt; \u0026lt;Route path=\u0026#34;/sports\u0026#34; component={Sports} /\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;))  IMPORTANT: Notice how the above React code makes no assumptions about which sports we might render! Thus we have components, routes, and links that are fully dynamic and data-driven!\n Activity: Add More Sports to the Sports Example  Recreate the example above (using create-react-app or forking it in Stackblitz) and try adding additional sports. You can copy and paste the example code from Stackblitz at React Router Example 1 with Nested Routes and Params  Passing Props to Route Components We have covered a lot of features of React Router, but what if you want to pass data (props) to the component being rendered by a Route?\nYou might think you could simply do something like this:\n\u0026lt;Route path=\u0026#34;/weather/atlanta\u0026#34; component={Weather} temperature={93} // THIS WILL NOT WORK! /\u0026gt; Unfortunately, this does not work. React Router simply ignores the temperature prop because technically it is a prop of the Route and not the Weather component.\nThe next idea you might have is to pass component an inline function that creates the element:\n\u0026lt;Route path=\u0026#34;/weather/atlanta\u0026#34; component={() =\u0026gt; \u0026lt;Weather temperature={93} /\u0026gt;} // THIS WORKS BUT IS NOT RECOMMENDED! /\u0026gt; Though technically this will work, it’s not the best solution. The reason for this is because of performance. When you use the component props, the router uses React.createElement to create a new React element from the given component. That means if you provide an inline function to the component attribute, you would create a new component with every render. This results in the existing component unmounting and the new component mounting instead of just updating the existing component.\nWARNING: Try to avoid using inline functions for Route components as this leads to performance degradation!\nSo if you’re not supposed to pass a function to component, what’s the solution? Turns out the React Router team predicted this problem and gave us a handy solution. Instead of using the component prop, use the render prop! render accepts a functional component and that function won’t get unnecessarily remounted like with component. That function will also receive all the same props that component would receive. So you can take those and pass those along to the rendered component.\n\u0026lt;Route path=\u0026#34;/weather/atlanta\u0026#34; render={(props) =\u0026gt; \u0026lt;Weather {...props} temperature={93} /\u0026gt;} // USE render TO PASS PROPS /\u0026gt; NOTE: We want to add the temperature prop to the other props being passed into the render prop function. Don\u0026rsquo;t forget to pass the incoming props as well (the props being destructured in the example above) as we might need them inside the Weather component.\nSo to recap, if you need to pass additional props to a component being rendered by React Router, use its render prop by passing it an inline function that adds the additional props needed by the component being rendered.\nActivity - Add Temperature to the News, Weather, and Sports Example Using the code from React Router Example 1 with Nested Routes and Params (or from the previous Activity) add the display of temperature to the Weather component. Pass the temperature as a prop to the Weather component.\nSwitch First The Problem In our previous examples every that matches the location was being rendered (allowing for multiple Routes to render for a single location).\nConsider this broken code:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Route, NavLink} from \u0026#39;react-router-dom\u0026#39; import \u0026#39;./style.css\u0026#39; const About = (props) =\u0026gt; \u0026lt;section\u0026gt;\u0026lt;h1\u0026gt;About\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const User = ({match}) =\u0026gt; ( \u0026lt;section\u0026gt;\u0026lt;h1\u0026gt;User {match.params.user}\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; ) const NoMatch = ({ location }) =\u0026gt; ( \u0026lt;section\u0026gt; \u0026lt;h1\u0026gt;No route found for location {location.pathname}.\u0026lt;/h1\u0026gt; \u0026lt;/section\u0026gt; ) const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;NavLink to=\u0026#34;/about\u0026#34;\u0026gt;About\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/Lisa\u0026#34;\u0026gt;Lisa\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/bad/path\u0026#34;\u0026gt;A Bad Path\u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Route path=\u0026#34;/about\u0026#34; component={About}/\u0026gt; {/* a route for the About view */} \u0026lt;Route path=\u0026#34;/:user\u0026#34; component={User}/\u0026gt; {/* a route using a parameter to display the specified User */} \u0026lt;Route component={NoMatch}/\u0026gt; {/* a route to display an error message (for bad paths) */} \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;)) What will happen if we go to the /about route?\nTry it with this live demo:\n  If the URL is /about, then the , , and components will all render!\nWhy? Because they all match the path. This is by design, allowing us to compose s into our apps in many ways, like sidebars and breadcrumbs, bootstrap tabs, etc.\nWe can try putting exact on all of the Routes, but this doesn\u0026rsquo;t work either. Exact is meant to handle nested routes, not differentiate between multiple routes that match the same pattern!\nUsing Switch to Exclusively Render a Single Route The solution is to use a component. Switch works by rendering the first route that matches. Any other matching routes are ignored.\nHere is the solution for the above example:\nDemo:\n  Source code:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Route, NavLink, Switch} from \u0026#39;react-router-dom\u0026#39; import \u0026#39;./style.css\u0026#39; const About = (props) =\u0026gt; \u0026lt;section\u0026gt;\u0026lt;h1\u0026gt;About\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const User = ({match}) =\u0026gt; ( \u0026lt;section\u0026gt;\u0026lt;h1\u0026gt;User {match.params.user}\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; ) const NoMatch = ({ location }) =\u0026gt; ( \u0026lt;section\u0026gt; \u0026lt;h1\u0026gt;No route found for location {location.pathname}.\u0026lt;/h1\u0026gt; \u0026lt;/section\u0026gt; ) const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;NavLink to=\u0026#34;/about\u0026#34;\u0026gt;About\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/Lisa\u0026#34;\u0026gt;Lisa\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/bad/path\u0026#34;\u0026gt;A Bad Path\u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Switch\u0026gt; {/* Simply add a `\u0026lt;Switch\u0026gt;` around the Routes to render only the first matching Route. */} \u0026lt;Route path=\u0026#34;/about\u0026#34; component={About}/\u0026gt; \u0026lt;Route exact path=\u0026#34;/:user\u0026#34; component={User}/\u0026gt; \u0026lt;Route component={NoMatch}/\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;)) Lab Click here for the instructions to this lab.\nSummary  Client-side routing is used to decide what view to display to the user. Which view to display is determined by the client application\u0026rsquo;s routing. React Router v4 has been designed to be a dynamic, distributed router that uses \u0026lt;Route\u0026gt; components to conditionally render their child components. By treating routes as components, Routes can be dynamically rendered as a part of the UI based on events, changes to state, etc (just like any React component). Links and NavLinks are used to navigate to different Routes within a React app. Routes can be nested inside components that were rendered by other Routes. Routes have paths that can be static or dynamic, i.e. the paths can contain variables such as \u0026ldquo;/customers/:customerId\u0026rdquo;. Use a Route\u0026rsquo;s render prop to pass custom props to the Route\u0026rsquo;s child component. Use the \u0026lt;Switch\u0026gt; component to render only the first Route whose path matches the current location.  Additional Resources  A Simple React Router v4 Tutorial All About React Router v4 Build your own React Router v4  "
},
{
	"uri": "/software-eng-essentials/git-foundations/reclaim-data-labs/",
	"title": "Reclaim Data Labs",
	"tags": [],
	"description": "",
	"content": "Let\u0026rsquo;s practice reclaiming data! Before you learn how to fix stuff we have to learn how to break it.\nSet Up  Create a new directory Initialize git Make a text file Write a line of text on the file Do a quick git status and then add and commit your work  Breaking stuff Part 1: The Easy fix  Run git rm 'text file' Add and commit the change Run ls to see that the file is gone  You have now successfully lost a file you really wanted. To fix this, run:\ngit reset --hard HEAD^ Now the head of your master is set to before you removed the text file do an ls to check.\nHow to break stuff Part 2: A bit harder That same command that saved us can actually really mess us up.\necho a couple more lines of text then add and commit the changes, then run:\ngit reset --hard HEAD^ This reset your HEAD to before you added the new lines of text but realize you needed them! If you cat your file, you\u0026rsquo;ll see the lines are gone. Use reflog to find the commit where you added the text.\nTo recover your lost text, copy the hash of the commit you need with the hash pasted in after the name you choose and checkout that branch.\nCat the text file to see your lines are now back! Checkout the master again and merge your new branch back in, placing your needed lines of text back in your master.\nBreaking stuff Part 3: Advanced Breaking stuff Check our new branch back out and echo some new lines of text in there. Checkout master again and delete your branch with:\ngit branch -d name-of-branch This did not delete your branch, because git will try to protect you. git shows how to get around this protection. Follow these directions.\nRun the following:\nrm -Rf .git/logs/ as if you were trying to clean up your logs and now run reflog and you\u0026rsquo;ll see that the commit is even missing. Noooooooo!\ngit fsck --full will list dangling commits and use the same steps as just above to make a branch to store that commit and then merge it into your master.\n"
},
{
	"uri": "/python/foundation/strings-labs/",
	"title": "Strings Labs",
	"tags": [],
	"description": "",
	"content": "String Labs If you need a refresher on how to get user input: link:./formatting-and-input#user_input[User Input Explanation]\nIs this a letter? It is very common to check if a character is a letter or not. In Python, have a user enter a character and check to see if it is a letter or not (Either upper or lowercase).\nExample Output 1:\n\u0026gt;\u0026gt;\u0026gt; Enter a character: i True Example Output 2:\n\u0026gt;\u0026gt;\u0026gt; Enter a character: @ False IMPORTANT: Go to String Methods Lesson\nShort Hand Create a function called short_hand that takes in a String called short and return short in short hand. The simplified shorthand form of a String is defined as follows:\n replace these four words: \u0026ldquo;and\u0026rdquo; with \u0026ldquo;\u0026amp;\u0026rdquo;, \u0026ldquo;too\u0026rdquo; with \u0026ldquo;2\u0026rdquo;, \u0026ldquo;you\u0026rdquo; with \u0026ldquo;U\u0026rdquo;, and \u0026ldquo;for\u0026rdquo; with \u0026ldquo;4\u0026rdquo;. remove all vowels (\u0026lsquo;a\u0026rsquo;, \u0026lsquo;e\u0026rsquo;, \u0026lsquo;i\u0026rsquo;, \u0026lsquo;o\u0026rsquo;, \u0026lsquo;u\u0026rsquo;, whether lowercase or uppercase). Be careful on removing U!  Place the following at the bottom of your __main__:\nprint(short_hand(\u0026#34;Thank you for that! You are too sweet and kind!\u0026#34;)) Example output:\nThnk U 4 tht! U r 2 swt \u0026amp; knd! Credentials Generator We want to create a random credential generator using a combination of string skills, random numbers and concatenation. All input to the algorithm must be at least three characters long. Your program should first ask the user for:\n their first name last name city they were born university they graduated from a name of a relative a name of a friend  Using all of the information the user has typed in, start the creation of their credentials.\nTheir employee id is generated with the following concatenated:\n  the first three letters of your first name\n  the last two letters of your last name\n  Their user name is generated with the following concatenated:\n  the first two letters of the city you were born in\n  the last three letters of the university they graduated from\n  Their password will be more randomly generated with the following concatenated:\n starting at a random location to the end of your relative\u0026rsquo;s name. starting at the beginning of your friend\u0026rsquo;s name to a random location of the string.  Example Output:\n\u0026gt;\u0026gt;\u0026gt; Enter First Name: Sally \u0026gt;\u0026gt;\u0026gt; Enter Last Name: Rodgers \u0026gt;\u0026gt;\u0026gt; Enter Birth City: Austin \u0026gt;\u0026gt;\u0026gt; Enter Alma Mater University: Texas A\u0026amp;M University \u0026gt;\u0026gt;\u0026gt; Enter a Relative\u0026#39;s Name: Joe \u0026gt;\u0026gt;\u0026gt; Enter a Friend\u0026#39;s Name: Elissa Employee ID: Salrs User Name: Auity Password: Oeeli BONUS: In the output, capitalize only the first letter, formatted like a proper name: \u0026ldquo;Emiton\u0026rdquo;\nRemove Case and Punctuation Create a program that has the user enter a string of any length. Change the case of every letter to lower case and remove all of the occurrences of symbols and spaces.\nExample Output:\n\u0026gt;\u0026gt;\u0026gt; Enter a phrase: Madam, I\u0026#39;m Adam madamimadam Palindrome A palindrome is a word that can read the same forwards and backwards. Continue the program \u0026ldquo;Remove Case and Punctuation\u0026rdquo;, with the newly altered string print True if the string is a palindrome and False if it is not. The idea of a palindrome can be extended to phrases or sentences if we ignore details like punctuation and case.\nExample Outputs:\n\u0026gt;\u0026gt;\u0026gt; Enter phrase: Madam, I\u0026#39;m Adam Palindrome? True \u0026gt;\u0026gt;\u0026gt; Enter phrase: Computer Palindrome? False Introduction to Functions\n"
},
{
	"uri": "/web-essentials/webmastery-foundations/jquery-labs/",
	"title": "DOM Manipulation with jQuery Labs",
	"tags": [],
	"description": "",
	"content": "IMDB Following the directions below to practice using jQuery:\n Go to IMDB IMDB uses jQuery, so we can use our Chrome developer console to manipulate the site in real time using jQuery. To do this, once IMDB.com has loaded, go to your view menu in Chrome. Select View \u0026gt; Developer \u0026gt; JavaScript Console Once that\u0026rsquo;s loaded, try entering the following command into the Chrome REPL:  $(\u0026#39;img\u0026#39;).hide()  Hit enter. All the images should have disappeared from the IMDB.com home page. Make sure you understand why before moving on. Now try this:  $(\u0026#39;img\u0026#39;).show()  That should have brought all the images back. Make sense so far? Now with the chrome inspector, try to match the title of the first article post and replace the text using .text() or .html(). Try to replace the blue background in the header by another color using the function .css(). Now try some of the other examples we\u0026rsquo;ve gone over in the Chrome REPL and see what happens to the IMDB.com website. Remember, this is your laboratory — your chance to experiment and learn. Make use of it.  Traffic Light Using the starter code in the codepen link below, use your knowledge of jQuery to turn each traffic light bulb on.\n Level 1: Click the button to change each corresponding bulb Level 2: Level 1 + change each button\u0026rsquo;s background color Level 3: Add functionality to turn the bulb and button color back to its original color  jQuery Traffic Light\nAdditional Resources  jQuery Cheatsheet jQuery’s Relevancy – There and Back Again  "
},
{
	"uri": "/react/foundations/react-router-v5/",
	"title": "React Router v5",
	"tags": [],
	"description": "",
	"content": "Adding routes to React applications using React Router version 5.\nConcepts  Introduce React Router Add dynamic routes to an application  Introduction  Now that you understand how to build a single page application, it\u0026rsquo;s time to discuss routing. You may already be familiar with routing from building RESTful API\u0026rsquo;s with Express or a similar server-side framework.  For example:\nroutes/index.js\napp.get(\u0026#39;/\u0026#39;, handleIndex) // root or home route app.get(\u0026#39;/products\u0026#39;, allProducts) // route to get all products app.get(\u0026#39;/products/:id\u0026#39;, showProduct) // route to get a single product  These are server-side routes. The server determines how to process incoming requests based on the HTTP request\u0026rsquo;s URL and method. Server-side routing is used to either:  decide what view to render and return to the browser (in the case of server-side rendering) decide what data to return to the browser (in the case of client-side rendering where the server acts as an API for processing data)    So then what is client-side routing and why do we need it?\nMotivation for Client Side Routing  Client-side routing is used to decide what view to display to the user. The idea is that we want a SPA (single-page app) to look and behave like a server-side rendered app (except be more responsive) or like a desktop app (except run in a browser). The SPA app should display various views to the user even though there is only a single page being loaded from the server. By using client-side rendering and routing, the SPA app can swap out different views based on interactions and navigations from the user. Which view to display is determined by the SPA application\u0026rsquo;s routing.  Here is an illustration:\nClient and Server Routing Working Together\n NOTE: With Single Page Apps (SPAs) the responsibility of deciding which view to display to the user has shifted from the server (in server-side rendering) to the client. The server will still have routes, but these routes do not decide what the user sees, only how data is processed.\n Getting Started with React Router A Simple Example Let\u0026rsquo;s start by taking a look at a simple example.\nFirst the demo:\n  Click on the links in the demo above and observe that the URL changes. With client-side routing we can manipulate the browser URL without reloading anything from the server!\nNow the source code:\nApp.js:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Switch, Route, Link} from \u0026#39;react-router-dom\u0026#39; // Imports from react-router-dom import \u0026#39;./style.css\u0026#39; const Home = () =\u0026gt; \u0026lt;section className=\u0026#34;home\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; // Define some simple components const News = () =\u0026gt; \u0026lt;section className=\u0026#34;news\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;News\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Weather = () =\u0026gt; \u0026lt;section className=\u0026#34;weather\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Weather\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Sports = () =\u0026gt; \u0026lt;section className=\u0026#34;sports\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Sports\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; {/* We must wrap all `Link` and `Route` components as children of a `Router` */} \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;Link to=\u0026#34;/\u0026#34;\u0026gt;Home\u0026lt;/Link\u0026gt; {/* Provide some `Links` to specific URLs that we will route between */} \u0026lt;Link to=\u0026#34;/news\u0026#34;\u0026gt;News\u0026lt;/Link\u0026gt; \u0026lt;Link to=\u0026#34;/weather\u0026#34;\u0026gt;Weather\u0026lt;/Link\u0026gt; \u0026lt;Link to=\u0026#34;/sports\u0026#34;\u0026gt;Sports\u0026lt;/Link\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Switch\u0026gt; {/* Wrap the Routes with a Switch so that the first matching route wins */} \u0026lt;Route exact path=\u0026#34;/\u0026#34; children={\u0026lt;Home /\u0026gt;} /\u0026gt; {/* Provide some `Routes` */} \u0026lt;Route path=\u0026#34;/news\u0026#34; children={\u0026lt;News /\u0026gt;} /\u0026gt; {/* When the URL matches the `path` */ } \u0026lt;Route path=\u0026#34;/weather\u0026#34; children={\u0026lt;Weather /\u0026gt;} /\u0026gt; {/* then the specified component will be rendered */} \u0026lt;Route path=\u0026#34;/sports\u0026#34; children={\u0026lt;Sports /\u0026gt;} /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;)) Routes with the exact property:\n Question: What is the exact doing on the Home Route? Why do we need that? Answer: It is possible to have more than one Route match a given URL.  Since all paths begin with / the Home Route will always match and the Home component be always be displayed unless we specify the exact property for the Home Route.   Try removing the exact property and test it out to see what happens!   IMPORTANT: Be sure to use react-router-dom when writing code for a Browser environment. There is another library simply called react-router but it only includes facade / interface code and does not contain the Browser specific code. The Browser specific code lives in its own library because React can be used to write either Browser apps or native apps.\n The Route Element  A Route is a component that conditionally renders its child component whenever the Route\u0026rsquo;s path is matched. The Route can specify it\u0026rsquo;s child or children component in one of 3 ways:  component={SomeComponent} render={(props) =\u0026gt; return \u0026lt;SomeComponent {...props} /\u0026gt;} children={\u0026lt;SomeComponent /\u0026gt;}    The Link Element  A Link is just a wrapper (HOC) around an anchor tag. When you click on a Link the React Router is notified so that it can manage the Browser\u0026rsquo;s URL, the Browser\u0026rsquo;s history, and create and pass additional route specific props to the appropriate Route component.  Styling Links and Using NavLinks  You can style your Link components to look like anchors, tabs, buttons, or however you want them to look. You can use inline styles, CSS classes, or CSS in JS libraries to style the Link components. There is also a NavLink component that works just like Link but also adds the ability to control the style of the active Link - i.e. the Link that is currently matching the Browser\u0026rsquo;s URL.  Here is the example from above modified to use NavLinks:\n  Here is the source code that uses the NavLinks:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Switch, Route, NavLink} from \u0026#39;react-router-dom\u0026#39; import \u0026#39;./style.css\u0026#39; const Home = () =\u0026gt; \u0026lt;section className=\u0026#34;home\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const News = () =\u0026gt; \u0026lt;section className=\u0026#34;news\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;News\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Weather = () =\u0026gt; \u0026lt;section className=\u0026#34;weather\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Weather\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Sports = () =\u0026gt; \u0026lt;section className=\u0026#34;sports\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Sports\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; {/* use NavLinks to style the selected link */} \u0026lt;NavLink exact to=\u0026#34;/\u0026#34;\u0026gt;Home\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/news\u0026#34;\u0026gt;News\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/weather\u0026#34;\u0026gt;Weather\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/sports\u0026#34;\u0026gt;Sports\u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route exact path=\u0026#34;/\u0026#34; children={\u0026lt;Home /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/news\u0026#34; children={\u0026lt;News /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/weather\u0026#34; children={\u0026lt;Weather /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/sports\u0026#34; children={\u0026lt;Sports /\u0026gt;} /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;))  NOTE: We added the exact property to the Home NavLink to specify that the NavLink should only be active for exact matches.\n Route Children  Every React component gets a children property that contains the children for the component. These children can be specified using either of the following syntaxes:  children as a prop element:\n\u0026lt;Route path=\u0026#34;/news\u0026#34; children={\u0026lt;News /\u0026gt;} /\u0026gt; children as a nested element:\n\u0026lt;Route path=\u0026#34;/news\u0026#34;\u0026gt; \u0026lt;News /\u0026gt; /\u0026gt; It doesn\u0026rsquo;t matter which syntax you use.\nReact Router Docs The React Router Documentation is extremely well written, complete with interactive demos.\n TIP: When building web apps make sure to use the WEB version of the documentation.\n A Few Observations The documentation is separated into 3 separate sections:\n EXAMPLES - interactive examples with corresponding code GUIDES - Detailed explanations of introductory and advanced concepts API - Descriptions of each component and it\u0026rsquo;s props  You\u0026rsquo;ll want to start with the first 2 links under GUIDES. Take a few minutes to read through them and familiarize yourself.\nAfterwards, you can jump right into the basic example. If you\u0026rsquo;ve followed the Quick Start guide, you\u0026rsquo;ll have your own local copy of the interactive guide (EXAMPLES). This is great to have on hand for future exploration.\nThe API portion is clear and concise. Refer to it when you see a new component in the EXAMPLES section.\nYou don\u0026rsquo;t need to grok (understand) all pieces of the documentation immediately. Just make sure you are comfortable with the Basic example.\nActivity (optional) - Get to Know the React Router Docs Using the React Router Documentation\u0026hellip;\n  Read the Philosophy and Quick Start sections. As you\u0026rsquo;re reading, think about the following questions and how you would answer them:\n What is the philosophy of React Router? What are React Router\u0026rsquo;s core building blocks? When trying to solve a problem with React Router, how should you approach creating a solution? What benefits (if any) do you see coming from using React Router in your application?    Use create-react-app and the quick start section to create your own local copy of the Basic Routing example (feel free to copy/paste).\n  Take a few minutes to navigate to the available URL\u0026rsquo;s and become comfortable with the syntax/code.\n  Nested Routes  Nested routes allow us to subdivide a view into multiple subviews that can be dynamically loaded inside the parent view. Extending the example from above, we can add nested routes such as /sports/football, /sports/basketball, and /sports/baseball. Try clicking on the Sports Link below and then clicking on the nested Links (Football, Basketball, and Baseball) to see the nested Routes get loaded.  Notice what happens to the browser URL! Also notice that the Sports component remains visible when it\u0026rsquo;s child Routes are being rendered!      Here is the source code:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Switch, Route, NavLink} from \u0026#39;react-router-dom\u0026#39; import \u0026#39;./style.css\u0026#39; const Home = () =\u0026gt; \u0026lt;section className=\u0026#34;home\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const News = () =\u0026gt; \u0026lt;section className=\u0026#34;news\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;News\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Weather = () =\u0026gt; \u0026lt;section className=\u0026#34;weather\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Weather\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const wikiCommons = \u0026#39;https://upload.wikimedia.org/wikipedia/commons/\u0026#39; const footballSrc = wikiCommons + \u0026#39;1/1b/American_football_icon_simple.svg\u0026#39;; const basketballSrc = wikiCommons + \u0026#39;7/7a/Basketball.png\u0026#39;; const baseballSrc = wikiCommons + \u0026#39;9/92/Baseball.svg\u0026#39;; const Football = () =\u0026gt; ( // We define some components to render in our nested routes.  \u0026lt;article\u0026gt; \u0026lt;img width=\u0026#34;100\u0026#34; src={footballSrc} alt=\u0026#34;Football\u0026#34; /\u0026gt; \u0026lt;/article\u0026gt; ) const Basketball = () =\u0026gt; ( \u0026lt;article\u0026gt; \u0026lt;img width=\u0026#34;100\u0026#34; src={basketballSrc} alt=\u0026#34;Basketball\u0026#34; /\u0026gt; \u0026lt;/article\u0026gt; ) const Baseball = () =\u0026gt; ( \u0026lt;article\u0026gt; \u0026lt;img width=\u0026#34;100\u0026#34; src={baseballSrc} alt=\u0026#34;Baseball\u0026#34; /\u0026gt; \u0026lt;/article\u0026gt; ) const Sports = () =\u0026gt; ( \u0026lt;section className=\u0026#34;sports\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Sports\u0026lt;/h1\u0026gt; \u0026lt;div className=\u0026#34;flex-container\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;sports-nav\u0026#34;\u0026gt; \u0026lt;ul style={{ listStyleType: \u0026#34;none\u0026#34;, padding: 10, textAlign: \u0026#39;left\u0026#39; }}\u0026gt; \u0026lt;li\u0026gt;\u0026lt;NavLink to=\u0026#34;/sports/football\u0026#34;\u0026gt;Football\u0026lt;/NavLink\u0026gt;\u0026lt;/li\u0026gt; {/* We can add `Links` (or `NavLinks`) */} \u0026lt;li\u0026gt;\u0026lt;NavLink to=\u0026#34;/sports/basketball\u0026#34;\u0026gt;Basketball\u0026lt;/NavLink\u0026gt;\u0026lt;/li\u0026gt; {/* to the component that is rendered */} \u0026lt;li\u0026gt;\u0026lt;NavLink to=\u0026#34;/sports/baseball\u0026#34;\u0026gt;Baseball\u0026lt;/NavLink\u0026gt;\u0026lt;/li\u0026gt; {/* in the parent route. */} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;sports-main\u0026#34;\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route path=\u0026#34;/sports/football\u0026#34; children={\u0026lt;Football /\u0026gt;} /\u0026gt; {/* We can add `Routes` inside the */} \u0026lt;Route path=\u0026#34;/sports/basketball\u0026#34; children={\u0026lt;Basketball /\u0026gt;} /\u0026gt; {/* component that is rendered in the */} \u0026lt;Route path=\u0026#34;/sports/baseball\u0026#34; children={\u0026lt;Baseball /\u0026gt;} /\u0026gt; {/* parent route. */} \u0026lt;/Switch\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; ); const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;NavLink exact to=\u0026#34;/\u0026#34;\u0026gt;Home\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/news\u0026#34;\u0026gt;News\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/weather\u0026#34;\u0026gt;Weather\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/sports\u0026#34;\u0026gt;Sports\u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route exact path=\u0026#34;/\u0026#34; children={\u0026lt;Home /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/news\u0026#34; children={\u0026lt;News /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/weather\u0026#34; children={\u0026lt;Weather /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/sports\u0026#34; children={\u0026lt;Sports /\u0026gt;} /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;))  NOTE: The above example illustrates the dynamic and decentralized features of React Router - i.e. Links and Routes can be added in any part of a React application. Another way to think about this is that we added nested routes without modifying the main App component.\n  NOTE: We did not put an exact property on the Sports route even though it is now a parent of the Football, Basketball, and Baseball routes. This is because we want the Sports route to render even when one of its child routes is being rendered. What would happen if we did put an exact on the Sports route (hint: it would be bad)?\n  TIP: The above code is getting pretty long. In a real project this would be a good time to refactor it into multiple files to improve readability and maintainability. How would you better organize the code above?\n Defining Routes with URL Parameters  Often we may need to define a Route that displays specific data depending on what the user clicked. For example, if a user clicks on a specific news article, we want the News component to display the article the user clicked on. So a single Route can be used to display any dynamic data. But how do we communicate which data to render?  Below is a demo.\n Try clicking on the Sports Route and then click on any sport. Notice that this demo doesn\u0026rsquo;t look much different from the previous demo but (as we shall soon see) the implementation is very different. One clue is that the URL is now different when we are on a nested route (such as football, basketball, or baseball).    And now for the source:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Switch, Route, NavLink, useParams} from \u0026#39;react-router-dom\u0026#39; // To illustrate the data-driven behavior, we have moved all sports data to a separate file. // The data could also be dynamically loaded from a server! import sports from \u0026#39;./sports-data\u0026#39;; import \u0026#39;./style.css\u0026#39; const Home = () =\u0026gt; \u0026lt;section className=\u0026#34;home\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const News = () =\u0026gt; \u0026lt;section className=\u0026#34;news\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;News\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Weather = () =\u0026gt; \u0026lt;section className=\u0026#34;weather\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Weather\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; // The `Sport` component can render any sport as long as the data (the JavaScript object) // contains the properties: `id`, `title`, and `imageSrc`. const Sport = () =\u0026gt; { const params = useParams() // useParams is a new hook added to v5 of React Router  const sport = sports.find( sport =\u0026gt; sport.id === Number(params.id) ) return ( \u0026lt;article\u0026gt;\u0026lt;img width=\u0026#34;100\u0026#34; src={sport.imageSrc} alt={sport.title} /\u0026gt;\u0026lt;/article\u0026gt; ) } const Sports = () =\u0026gt; { const links = sports.map(sport =\u0026gt; ( // The `NavLinks` are dynamically generated from the sports data.  \u0026lt;li\u0026gt; \u0026lt;NavLink to={`/sports/${sport.id}`}\u0026gt;{sport.title}\u0026lt;/NavLink\u0026gt; \u0026lt;/li\u0026gt; )) return ( \u0026lt;section className=\u0026#34;sports\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Sports\u0026lt;/h1\u0026gt; \u0026lt;div className=\u0026#34;flex-container\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;sports-nav\u0026#34;\u0026gt; \u0026lt;ul style={{ listStyleType: \u0026#34;none\u0026#34;, padding: 10, textAlign: \u0026#39;left\u0026#39; }}\u0026gt; {links} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;sports-main\u0026#34;\u0026gt; {/* Using a URL parameter in the following Route, we can define a single `Route` to render any Sport. */} \u0026lt;Route path=\u0026#34;/sports/:id\u0026#34; children={\u0026lt;Sport /\u0026gt;} /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; ) } const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;NavLink exact to=\u0026#34;/\u0026#34;\u0026gt;Home\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/news\u0026#34;\u0026gt;News\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/weather\u0026#34;\u0026gt;Weather\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/sports\u0026#34;\u0026gt;Sports\u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Route exact path=\u0026#34;/\u0026#34; children={\u0026lt;Home /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/news\u0026#34; children={\u0026lt;News /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/weather\u0026#34; children={\u0026lt;Weather /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/sports\u0026#34; children={\u0026lt;Sports /\u0026gt;} /\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;))  IMPORTANT: Notice how the above React code makes no assumptions about which sports we might render! There is no mention of Football or Basketball, etc. Thus we have components, routes, and links that are fully dynamic and data-driven!\n Activity: Add More Sports to the Sports Example  Recreate the example above (using create-react-app or forking it in Stackblitz) and try adding additional sports. You can copy and paste the example code from Stackblitz at React Router Example 1 with Nested Routes and Params  Passing Props to Route Components  In previous versions of React Router, you had to use a render prop to pass props to Route components. Version 5 of React Router makes this much simpler by using React elements within Routes. For example, to add a temperature prop the the Weather component:  before version 5\n\u0026lt;Route path=\u0026#34;/weather/atlanta\u0026#34; render={(props) =\u0026gt; \u0026lt;Weather {...props} temperature={93} /\u0026gt;} {/* use `render` to pass props, including the route props */} /\u0026gt; with version 5\n\u0026lt;Route path=\u0026#34;/weather\u0026#34; children={\u0026lt;Weather temperature={95} /\u0026gt;} {/* use `children` with a React element */} /\u0026gt; You can also write this using the nested children syntax:\n\u0026lt;Route path=\u0026#34;/weather\u0026#34;\u0026gt; \u0026lt;Weather temperature={95} /\u0026gt; {/* use `children` with a React element */} \u0026lt;/Route\u0026gt;  NOTE: There may be times when you still need to use render, such as when you want to perform some logic within the Route. For example:\n \u0026lt;Route path=\u0026#34;/weather/:city\u0026#34; render={(props) =\u0026gt; { const city = props.match.params.city const temp = lookupWeatherTemp(city) return ( \u0026lt;Weather {...props} temperature={temp} /\u0026gt; ) }} /\u0026gt; Activity - Add Temperature to the News, Weather, and Sports Example Using the code from React Router Example 1 with Nested Routes and Params (or from the previous Activity) add the display of temperature to the Weather component. Pass the temperature as a prop to the Weather component.\nReact Router Hooks  React Router v5 provides 4 React hooks:     Hook Description     useParams returns the dynamic segments (the variables) of the URL   useRouteMatch returns the match data   useLocation returns the current location object, which includes the literal URL   useHistory returns a history object for programmatic navigation purposes     These hooks provide an easy way to get to Route specific data. To learn more about these hooks, see: React Router v5.1.  Lab Click here for the instructions to this lab.\nSummary  Client-side routing is used to decide what view to display to the user. React Router has been designed to be a dynamic, distributed router that uses \u0026lt;Route\u0026gt; components to conditionally render their child components. Links and NavLinks are used to navigate to different Routes within a React app. Routes can be nested inside components that were rendered by other Routes. Routes have paths that can be static or dynamic, i.e. the paths can contain variables such as \u0026quot;/customers/:customerId\u0026quot;.  Additional Resources  React Router v5 React Router v5.1 React Router v5: The Complete Guide  "
},
{
	"uri": "/react/foundations/react-router-v6/",
	"title": "React Router v6",
	"tags": [],
	"description": "",
	"content": "Adding routes to React applications using React Router version 6.\nConcepts  Introduce React Router Add dynamic routes to an application  Introduction  Now that you understand how to build a single page application, it\u0026rsquo;s time to discuss routing. You may already be familiar with routing from building RESTful API\u0026rsquo;s with Express or a similar server-side framework.  For example:\nroutes/index.js\napp.get(\u0026#39;/\u0026#39;, handleIndex) // root or home route app.get(\u0026#39;/products\u0026#39;, allProducts) // route to get all products app.get(\u0026#39;/products/:id\u0026#39;, showProduct) // route to get a single product  These are server-side routes. The server determines how to process incoming requests based on the HTTP request\u0026rsquo;s URL and method. Server-side routing is used to either:  decide what view to render and return to the browser (in the case of server-side rendering) decide what data to return to the browser (in the case of client-side rendering where the server acts as an API for processing data)    So then what is client-side routing and why do we need it?\nMotivation for Client Side Routing  Client-side routing is used to decide what view to display to the user. The idea is that we want a SPA (single-page app) to look and behave like a server-side rendered app (except be more responsive) or like a desktop app (except run in a browser). The SPA app should display various views to the user even though there is only a single page being loaded from the server. By using client-side rendering and routing, the SPA app can swap out different views based on interactions and navigations from the user. Which view to display is determined by the SPA application\u0026rsquo;s routing.  Here is an illustration:\nClient and Server Routing Working Together\n NOTE: With Single Page Apps (SPAs) the responsibility of deciding which view to display to the user has shifted from the server (in server-side rendering) to the client. The server will still have routes, but these routes do not decide what the user sees, only how data is processed.\n Getting Started with React Router A Simple Example Let\u0026rsquo;s start by taking a look at a simple example.\nFirst the demo:\n  Click on the links in the demo above and observe that the URL changes. With client-side routing we can manipulate the browser URL without reloading anything from the server!\nNow the source code:\nApp.js:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Routes, Route, Link} from \u0026#39;react-router-dom\u0026#39; import \u0026#39;./style.css\u0026#39; const Home = () =\u0026gt; \u0026lt;section className=\u0026#34;home\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const News = () =\u0026gt; \u0026lt;section className=\u0026#34;news\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;News\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Weather = () =\u0026gt; \u0026lt;section className=\u0026#34;weather\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Weather\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Sports = () =\u0026gt; \u0026lt;section className=\u0026#34;sports\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Sports\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;Link to=\u0026#34;/\u0026#34;\u0026gt;Home\u0026lt;/Link\u0026gt; \u0026lt;Link to=\u0026#34;/news\u0026#34;\u0026gt;News\u0026lt;/Link\u0026gt; \u0026lt;Link to=\u0026#34;/weather\u0026#34;\u0026gt;Weather\u0026lt;/Link\u0026gt; \u0026lt;Link to=\u0026#34;/sports\u0026#34;\u0026gt;Sports\u0026lt;/Link\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Routes\u0026gt; {/* Remember to wrap the routes with a `\u0026lt;Routes`\u0026gt; element */ } \u0026lt;Route path=\u0026#34;/\u0026#34; element={\u0026lt;Home /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/news\u0026#34; element={\u0026lt;News /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/weather\u0026#34; element={\u0026lt;Weather /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/sports\u0026#34; element={\u0026lt;Sports /\u0026gt;} /\u0026gt; \u0026lt;/Routes\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;))  NOTE: One of the most exciting changes in React Router v6 is the powerful new \u0026lt;Routes\u0026gt; element. This is a pretty significant upgrade from v5\u0026rsquo;s \u0026lt;Switch\u0026gt; element with some important new features including relative routing and linking, automatic route ranking, and nested routes and layouts.\n  IMPORTANT: Be sure to use react-router-dom when writing code for a Browser environment. There is another library simply called react-router but it only includes facade / interface code and does not contain the Browser specific code. The Browser specific code lives in its own library because React can be used to write either Browser apps or native apps.\n The Routes Element  The Routes element wraps a set of Route elements. The Routes element is then responsible for determining which Route to render. To do this, the Routes element picks the route with the path that best matches the current location, which is usually the path that is the most specific. For example, a route with path=\u0026quot;invoices/sent\u0026rdquo; may match only /invoices/sent, so it is more specific than path=\u0026quot;invoices/:invoiceId\u0026rdquo; which matches any URL that begins with /invoices (/invoices/123, /invoices/cupcakes, etc). Therefore you can organize your code however you\u0026rsquo;d like and put the routes in whatever order makes the most sense to you.  The Route Element  A Route is a component that conditionally renders its child component whenever the Route\u0026rsquo;s path is matched. The Route can specify it\u0026rsquo;s child or children component in one of 3 ways:  component={SomeComponent} render={(props) =\u0026gt; return \u0026lt;SomeComponent {...props} /\u0026gt;} children={\u0026lt;SomeComponent /\u0026gt;}    The Link Element  A Link is just a wrapper (HOC) around an anchor tag. When you click on a Link the React Router is notified so that it can manage the Browser\u0026rsquo;s URL, the Browser\u0026rsquo;s history, and create and pass additional route specific props to the appropriate Route component.  Styling Links and Using NavLinks  You can style your Link components to look like anchors, tabs, buttons, or however you want them to look. You can use inline styles, CSS classes, or CSS in JS libraries to style the Link components. There is also a NavLink component that works just like Link but also adds the ability to control the style of the active Link - i.e. the Link that is currently matching the Browser\u0026rsquo;s URL.  Here is the example from above modified to use NavLinks:\n  Here is the source code that uses the NavLinks:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Routes, Route, NavLink} from \u0026#39;react-router-dom\u0026#39; import \u0026#39;./style.css\u0026#39; const Home = () =\u0026gt; \u0026lt;section className=\u0026#34;home\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const News = () =\u0026gt; \u0026lt;section className=\u0026#34;news\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;News\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Weather = () =\u0026gt; \u0026lt;section className=\u0026#34;weather\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Weather\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Sports = () =\u0026gt; \u0026lt;section className=\u0026#34;sports\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Sports\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; {/* use NavLinks to style the selected link */} \u0026lt;NavLink end to=\u0026#34;/\u0026#34;\u0026gt;Home\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/news\u0026#34;\u0026gt;News\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/weather\u0026#34;\u0026gt;Weather\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/sports\u0026#34;\u0026gt;Sports\u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Routes\u0026gt; \u0026lt;Route path=\u0026#34;/\u0026#34; children={\u0026lt;Home /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/news\u0026#34; children={\u0026lt;News /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/weather\u0026#34; children={\u0026lt;Weather /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/sports\u0026#34; children={\u0026lt;Sports /\u0026gt;} /\u0026gt; \u0026lt;/Routes\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;))  NOTE: We added the end property to the Home NavLink to specify that the NavLink should only be active for exact matches.\n Route Children  Every React component gets a children property that contains the children for the component. These children can be specified using either of the following syntaxes:  children as a prop element:\n\u0026lt;Route path=\u0026#34;/news\u0026#34; children={\u0026lt;News /\u0026gt;} /\u0026gt; children as a nested element:\n\u0026lt;Route path=\u0026#34;/news\u0026#34;\u0026gt; \u0026lt;News /\u0026gt; /\u0026gt; It doesn\u0026rsquo;t matter which syntax you use.\nReact Router Docs  IMPORTANT: As of September 2020 the React Documentation is still for v5. It is not known when v6 will be released and the documentation updated for v6.\n The React Router Documentation is extremely well written, complete with interactive demos.\n TIP: When building web apps make sure to use the WEB version of the documentation.\n A Few Observations The documentation is separated into 3 separate sections:\n EXAMPLES - interactive examples with corresponding code GUIDES - Detailed explanations of introductory and advanced concepts API - Descriptions of each component and it\u0026rsquo;s props  You\u0026rsquo;ll want to start with the first 2 links under GUIDES. Take a few minutes to read through them and familiarize yourself.\nAfterwards, you can jump right into the basic example. If you\u0026rsquo;ve followed the Quick Start guide, you\u0026rsquo;ll have your own local copy of the interactive guide (EXAMPLES). This is great to have on hand for future exploration.\nThe API portion is clear and concise. Refer to it when you see a new component in the EXAMPLES section.\nYou don\u0026rsquo;t need to grok (understand) all pieces of the documentation immediately. Just make sure you are comfortable with the Basic example.\nActivity (optional) - Get to Know the React Router Docs Using the React Router Documentation\u0026hellip;\n  Read the Philosophy and Quick Start sections. As you\u0026rsquo;re reading, think about the following questions and how you would answer them:\n What is the philosophy of React Router? What are React Router\u0026rsquo;s core building blocks? When trying to solve a problem with React Router, how should you approach creating a solution? What benefits (if any) do you see coming from using React Router in your application?    Use create-react-app and the quick start section to create your own local copy of the Basic Routing example (feel free to copy/paste).\n  Take a few minutes to navigate to the available URL\u0026rsquo;s and become comfortable with the syntax/code.\n  Nested Routes  Nested routes allow us to subdivide a view into multiple subviews that can be dynamically loaded inside the parent view. Extending the example from above, we can add nested routes such as /sports/football, /sports/basketball, and /sports/baseball. Try clicking on the Sports Link below and then clicking on the nested Links (Football, Basketball, and Baseball) to see the nested Routes get loaded.  Notice what happens to the browser URL! Also notice that the Sports component remains visible when it\u0026rsquo;s child Routes are being rendered!      Here is the source code:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Routes, Route, NavLink} from \u0026#39;react-router-dom\u0026#39; import \u0026#39;./style.css\u0026#39; const Home = () =\u0026gt; \u0026lt;section className=\u0026#34;home\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const News = () =\u0026gt; \u0026lt;section className=\u0026#34;news\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;News\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Weather = () =\u0026gt; \u0026lt;section className=\u0026#34;weather\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Weather\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const wikiCommons = \u0026#39;https://upload.wikimedia.org/wikipedia/commons/\u0026#39; const footballSrc = wikiCommons + \u0026#39;1/1b/American_football_icon_simple.svg\u0026#39;; const basketballSrc = wikiCommons + \u0026#39;7/7a/Basketball.png\u0026#39;; const baseballSrc = wikiCommons + \u0026#39;9/92/Baseball.svg\u0026#39;; const Football = () =\u0026gt; ( // We define some components to render in our nested routes.  \u0026lt;article\u0026gt; \u0026lt;img width=\u0026#34;100\u0026#34; src={footballSrc} alt=\u0026#34;Football\u0026#34; /\u0026gt; \u0026lt;/article\u0026gt; ) const Basketball = () =\u0026gt; ( \u0026lt;article\u0026gt; \u0026lt;img width=\u0026#34;100\u0026#34; src={basketballSrc} alt=\u0026#34;Basketball\u0026#34; /\u0026gt; \u0026lt;/article\u0026gt; ) const Baseball = () =\u0026gt; ( \u0026lt;article\u0026gt; \u0026lt;img width=\u0026#34;100\u0026#34; src={baseballSrc} alt=\u0026#34;Baseball\u0026#34; /\u0026gt; \u0026lt;/article\u0026gt; ) const Sports = () =\u0026gt; ( \u0026lt;section className=\u0026#34;sports\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Sports\u0026lt;/h1\u0026gt; \u0026lt;div className=\u0026#34;flex-container\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;sports-nav\u0026#34;\u0026gt; \u0026lt;ul style={{ listStyleType: \u0026#34;none\u0026#34;, padding: 10, textAlign: \u0026#39;left\u0026#39; }}\u0026gt; \u0026lt;li\u0026gt;\u0026lt;NavLink to=\u0026#34;football\u0026#34;\u0026gt;Football\u0026lt;/NavLink\u0026gt;\u0026lt;/li\u0026gt; {/* We can add `Links` (or `NavLinks`) */} \u0026lt;li\u0026gt;\u0026lt;NavLink to=\u0026#34;basketball\u0026#34;\u0026gt;Basketball\u0026lt;/NavLink\u0026gt;\u0026lt;/li\u0026gt; {/* to the component that is rendered */} \u0026lt;li\u0026gt;\u0026lt;NavLink to=\u0026#34;baseball\u0026#34;\u0026gt;Baseball\u0026lt;/NavLink\u0026gt;\u0026lt;/li\u0026gt; {/* in the parent route. */} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;sports-main\u0026#34;\u0026gt; \u0026lt;Routes\u0026gt; \u0026lt;Route path=\u0026#34;football\u0026#34; element={\u0026lt;Football /\u0026gt;} /\u0026gt; {/* We can add `Routes` inside the */} \u0026lt;Route path=\u0026#34;basketball\u0026#34; element={\u0026lt;Basketball /\u0026gt;} /\u0026gt; {/* component that is rendered in the */} \u0026lt;Route path=\u0026#34;baseball\u0026#34; element={\u0026lt;Baseball /\u0026gt;} /\u0026gt; {/* parent route. */} \u0026lt;/Routes\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; ); const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;NavLink end to=\u0026#34;/\u0026#34;\u0026gt;Home\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/news\u0026#34;\u0026gt;News\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/weather\u0026#34;\u0026gt;Weather\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/sports\u0026#34;\u0026gt;Sports\u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Routes\u0026gt; \u0026lt;Route path=\u0026#34;/\u0026#34; element={\u0026lt;Home /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/news\u0026#34; element={\u0026lt;News /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/weather\u0026#34; element={\u0026lt;Weather /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/sports/*\u0026#34; element={\u0026lt;Sports /\u0026gt;} /\u0026gt; \u0026lt;/Routes\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;))  NOTE: The above example illustrates the dynamic and decentralized features of React Router - i.e. Links and Routes can be added in any part of a React application. Another way to think about this is that we added nested routes without modifying the main App component.\n  NOTE: In React Router v6 the to and path properties use relative paths. Thus to navigate from /sports to /sports/football we would simply use \u0026lt;NavLink to=\u0026quot;football\u0026quot;\u0026gt;Football\u0026lt;/NavLink\u0026gt; without any reference to the current URL of /sports. Likewise nested Route paths are relative as well, as in \u0026lt;Route path=\u0026quot;football\u0026quot; element={\u0026lt;Football /\u0026gt;} /\u0026gt; without reference to the current URL of /sports.\n  TIP: The above code is getting pretty long. In a real project this would be a good time to refactor it into multiple files to improve readability and maintainability. How would you better organize the code above?\n Defining Routes with URL Parameters  Often we may need to define a Route that displays specific data depending on what the user clicked. For example, if a user clicks on a specific news article, we want the News component to display the article the user clicked on. So a single Route can be used to display any dynamic data. But how do we communicate which data to render?  Below is a demo.\n Try clicking on the Sports Route and then click on any sport. Notice that this demo doesn\u0026rsquo;t look much different from the previous demo but (as we shall soon see) the implementation is very different. One clue is that the URL is now different when we are on a nested route (such as football, basketball, or baseball).    And now for the source:\nimport React from \u0026#39;react\u0026#39; import ReactDOM from \u0026#39;react-dom\u0026#39; import {BrowserRouter as Router, Routes, Route, NavLink, useParams} from \u0026#39;react-router-dom\u0026#39; // To illustrate the data-driven behavior, we have moved all sports data to a separate file. // The data could also be dynamically loaded from a server! import sports from \u0026#39;./sports-data\u0026#39;; import \u0026#39;./style.css\u0026#39; const Home = () =\u0026gt; \u0026lt;section className=\u0026#34;home\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const News = () =\u0026gt; \u0026lt;section className=\u0026#34;news\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;News\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; const Weather = () =\u0026gt; \u0026lt;section className=\u0026#34;weather\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;Weather\u0026lt;/h1\u0026gt;\u0026lt;/section\u0026gt; // The `Sport` component can render any sport as long as the data (the JavaScript object) // contains the properties: `id`, `title`, and `imageSrc`. const Sport = () =\u0026gt; { const params = useParams() // useParams is a new hook added to v5 of React Router  const sport = sports.find( sport =\u0026gt; sport.id === Number(params.id) ) return ( \u0026lt;article\u0026gt;\u0026lt;img width=\u0026#34;100\u0026#34; src={sport.imageSrc} alt={sport.title} /\u0026gt;\u0026lt;/article\u0026gt; ) } const Sports = () =\u0026gt; { const links = sports.map(sport =\u0026gt; ( // The `NavLinks` are dynamically generated from the sports data.  \u0026lt;li\u0026gt; \u0026lt;NavLink to={`${sport.id}`}\u0026gt;{sport.title}\u0026lt;/NavLink\u0026gt; \u0026lt;/li\u0026gt; )) return ( \u0026lt;section className=\u0026#34;sports\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Sports\u0026lt;/h1\u0026gt; \u0026lt;div className=\u0026#34;flex-container\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;sports-nav\u0026#34;\u0026gt; \u0026lt;ul style={{ listStyleType: \u0026#34;none\u0026#34;, padding: 10, textAlign: \u0026#39;left\u0026#39; }}\u0026gt; {links} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;sports-main\u0026#34;\u0026gt; \u0026lt;Routes\u0026gt; {/* Using a URL parameter in the following Route, we can define a single `Route` to render any Sport. */} \u0026lt;Route path=\u0026#34;:id\u0026#34; element={\u0026lt;Sport /\u0026gt;} /\u0026gt; \u0026lt;/Routes\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; ) } const App = () =\u0026gt; ( \u0026lt;Router\u0026gt; \u0026lt;main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;NavLink end to=\u0026#34;/\u0026#34;\u0026gt;Home\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/news\u0026#34;\u0026gt;News\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/weather\u0026#34;\u0026gt;Weather\u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/sports\u0026#34;\u0026gt;Sports\u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Routes\u0026gt; \u0026lt;Route path=\u0026#34;/\u0026#34; element={\u0026lt;Home /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/news\u0026#34; element={\u0026lt;News /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/weather\u0026#34; element={\u0026lt;Weather /\u0026gt;} /\u0026gt; \u0026lt;Route path=\u0026#34;/sports/*\u0026#34; element={\u0026lt;Sports /\u0026gt;} /\u0026gt; \u0026lt;/Routes\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/Router\u0026gt; ) ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;))  IMPORTANT: Notice how the above React code makes no assumptions about which sports we might render! There is no mention of Football or Basketball, etc. Thus we have components, routes, and links that are fully dynamic and data-driven!\n Activity: Add More Sports to the Sports Example  Recreate the example above (using create-react-app or forking it in Stackblitz) and try adding additional sports. You can copy and paste the example code from Stackblitz at React Router Example 1 with Nested Routes and Params  Passing Props to Route Components  In previous versions of React Router, you had to use a render prop to pass props to Route components. Version 5 of React Router makes this much simpler by using React elements within Routes. For example, to add a temperature prop the the Weather component:  before version 5\n\u0026lt;Route path=\u0026#34;/weather/atlanta\u0026#34; render={(props) =\u0026gt; \u0026lt;Weather {...props} temperature={93} /\u0026gt;} {/* use `render` to pass props, including the route props */} /\u0026gt; with version 5\n\u0026lt;Route path=\u0026#34;/weather\u0026#34; children={\u0026lt;Weather temperature={95} /\u0026gt;} {/* use `children` with a React element */} /\u0026gt; with version 6\n\u0026lt;Route path=\u0026#34;/weather\u0026#34; element={\u0026lt;Weather temperature={95} /\u0026gt;} {/* use `element` with a React element */} /\u0026gt; In v5 and v6 you can also write this using the nested children syntax:\n\u0026lt;Route path=\u0026#34;/weather\u0026#34;\u0026gt; \u0026lt;Weather temperature={95} /\u0026gt; {/* use `children` with a React element */} \u0026lt;/Route\u0026gt;  NOTE: There may be times when you still need to use render, such as when you want to perform some logic within the Route. For example:\n \u0026lt;Route path=\u0026#34;/weather/:city\u0026#34; render={(props) =\u0026gt; { const city = props.match.params.city const temp = lookupWeatherTemp(city) return ( \u0026lt;Weather {...props} temperature={temp} /\u0026gt; ) }} /\u0026gt; Activity - Add Temperature to the News, Weather, and Sports Example Using the code from React Router Example 1 with Nested Routes and Params (or from the previous Activity) add the display of temperature to the Weather component. Pass the temperature as a prop to the Weather component.\nReact Router Hooks  React Router v5 and above provides 4 React hooks:     Hook Description     useParams returns the dynamic segments (the variables) of the URL   useRouteMatch returns the match data   useLocation returns the current location object, which includes the literal URL   useHistory returns a history object for programmatic navigation purposes     These hooks provide an easy way to get to Route specific data. To learn more about these hooks, see: React Router v5.1.  Lab Click here for the instructions to this lab.\nSummary  Client-side routing is used to decide what view to display to the user. React Router has been designed to be a dynamic, distributed router that uses \u0026lt;Route\u0026gt; components to conditionally render their child components. Links and NavLinks are used to navigate to different Routes within a React app. Routes can be nested inside components that were rendered by other Routes. Routes have paths that can be static or dynamic, i.e. the paths can contain variables such as \u0026quot;/customers/:customerId\u0026quot;.  Additional Resources  React Router v6 Preview How to upgrade React Router v5 to v6  "
},
{
	"uri": "/onboarding/",
	"title": "Onboarding",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Onboarding Offerings "
},
{
	"uri": "/python/foundation/functions/",
	"title": "Functions",
	"tags": [],
	"description": "",
	"content": "User Defined Functions Introduction to functions Functions are important because they allow us to divide code into useful blocks. We can create order and organization, make it more readable, and reuse it to prevent repetitiveness.\n Function syntax in Python begins with the keyword def followed by the function name, parenthesis, and a colon. On the second line, we need to indent appropriately or else Python will not run the function and it will error.\nCopy and paste the following function into your project and run it:\ndef subtract_total(): total = 10000 my_share = 20000 print(my_share - total) Hopefully nothing happened. But why isn\u0026rsquo;t it running at all when it\u0026rsquo;s within proper function syntax?\nNOTE: Scope: The print() is inside the scope of the subtract_total() function. Python doesn\u0026rsquo;t see any code when this is executing, because it\u0026rsquo;s \u0026ldquo;hidden\u0026rdquo; within the bounds of the function. Now we need to write the program so that Python can see within the function, and ultimately execute the while loop.\nFunction block syntax\nIn order to define a function for Python, we have to use the def keyword. As you can see, def will turn a different color in your IDE once you write the name of the function after this keyword. This is one indication that you\u0026rsquo;ve begun defining a function for Python to read.\nOther syntax required for Python to be able to read a function is the function name. Function naming rules are as follows (from the https://www.python.org/dev/peps/pep-0008/[pep8 style guide^]):\n  The first letter of the name of a function should be lower case\n  The second word can be camelCase (also known as mixedCase), where the first letter of the second word is capitalized\n  The second word (if there is one) could be separated by an underscore _ as an alternative to using camelCase\n  NOTE: The key to naming your functions is similar to naming variables. You want to be consistent throughout your program. If you\u0026rsquo;ve started naming functions in camelCase, continue to do so for all functions. This helps with code clarity, readability and the ability for others to contribute in an organized way.\nOnce you name the function properly after the def keyword, it is essential to put a colon : before writing the rest of your function.\ndef subtract_total(): The rest is all about indentation! Python is very opinionated about indentation and it will not read a program without proper indentation. Once you\u0026rsquo;ve defined your function, make sure the very next line is indented, like in the subtract_total() example.\nIf you\u0026rsquo;re unsure about indentation at first, that\u0026rsquo;s okay. Most text editors will tell you if you\u0026rsquo;ve missed an indentation.\nCalling functions In order to get a function to execute, we have to explicitly call it. Using the example above, we simply have to put the function name on the last line outside of the scope of the function.\ndef while_loop(): x = True while x: print(\u0026#34;x exists\u0026#34;) while_loop() TIP: Pay close attention to the lack of indentation of def and of the last line while_loop() - they\u0026rsquo;re on the same indentation level because they\u0026rsquo;re both in the same scope. Python runs line-by-line, first skipping over the def function, and then hitting the last line where we\u0026rsquo;re explicitly instructing Python to run the while_loop() function. Then, it goes back and checks to see if there are any functions, defined by def, called while_loop(). It finally finds our function and executes an infinite loop!\nParameters A parameter is placed within the parenthesis of a function. Parameters are declared when the function is defined as placeholders for actual objects that will be passed when the function will be called. In Python you do not declare the type of a parameter. Code along: Write a function called hello(), and put the parameter name within the parenthesis.\ndef hello(name): We want this function to print out Hello your-name!, so we need to concatenate the string \u0026ldquo;Hello\u0026rdquo; with your name (also a string). So we\u0026rsquo;ll take the parameter name and use it as a variable within the print() function.\ndef hello(name): print(\u0026#34;Hello \u0026#34; + name) hello() If we run this, Python will throw a Type Error saying that hello() takes exactly 1 argument. When we called the function on the last line, we didn\u0026rsquo;t give hello() any arguments!\nLet\u0026rsquo;s make name our own name. To do this, we need to pass a unique argument when we actually call the function.\ndef hello(name): print(\u0026#34;Hello \u0026#34; + name) hello(\u0026#34;Emily\u0026#34;) Output: Hello Emily\nThe name within the parenthesis when we define a function is called a parameter. When we pass data into the parenthesis while calling a function, it\u0026rsquo;s called an argument.\nFor example, the function defined below utilizes a conditional statement to check if the input for the name variable contains a vowel, then uses a for loop to iterate over the letters in the word string.\ndef has_vowel(word): ## Check whether name has a vowel if set(\u0026#39;aeiou\u0026#39;).intersection(word.lower()): print(word, \u0026#39;contains a vowel.\u0026#39;) else: print(word, \u0026#39;does not contain a vowel.\u0026#39;) has_vowel(\u0026#34;supercalifragilisticexpialidocious\u0026#34;) has_vowel(\u0026#34;why\u0026#34;) has_vowel(\u0026#34;hey\u0026#34;) Output:\nsupercalifragilisticexpialidocious contains a vowel why does not contain a vowel hey contains a vowel With parameters, we are able to use the same function with several different inputs.\nKeyword Arguments In addition to calling parameters in order, you can use keyword arguments in a function call, in which the caller identifies the arguments by the parameter name.\nWhen you use keyword arguments, you can use parameters out of order because the Python interpreter will use the keywords provided to match the values to the parameters.\nLet’s create a function that will show us profile information for a user. We’ll pass parameters to it in the form of username (intended as a string), and followers (intended as an integer).\ndef profile_info(username, followers): print(\u0026#34;Username: \u0026#34; + username) print(\u0026#34;Followers: \u0026#34; + str(followers)) Within the function definition statement, username and followers are contained in the parentheses of the profile_info() function. The block of the function prints out information about the user as strings, making use of the two parameters.\nNow, we can call the function and assign parameters to it:\ndef profile_info(username, followers): print(\u0026#34;Username: \u0026#34; + username) print(\u0026#34;Followers: \u0026#34; + str(followers)) ## Call function with parameters assigned as above profile_info(\u0026#34;sammyshark\u0026#34;, 945) ## Call function with keyword arguments profile_info(username=\u0026#34;AlexAnglerfish\u0026#34;, followers=342) Output:\nUsername: sammyshark Followers: 945 Username: AlexAnglerfish Followers: 342 The output shows us the usernames and numbers of followers for both users.\nThis also permits us to modify the order of the parameters, as in this example of the same program with a different call:\ndef profile_info(username, followers): print(\u0026#34;Username: \u0026#34; + username) print(\u0026#34;Followers: \u0026#34; + str(followers)) ## Change order of parameters profile_info(followers=820, username=\u0026#34;cameron-catfish\u0026#34;) Output:\nUsername: cameron-catfish Followers: 820 Default Argument Values We can also provide default values for one or both of the parameters. Let\u0026rsquo;s create a default value for the followers parameter with a value of 1:\ndef profile_info(username, followers=1): print(\u0026#34;Username: \u0026#34; + username) print(\u0026#34;Followers: \u0026#34; + str(followers)) Now, we can run the function with only the username function assigned, and the number of followers will automatically default to 1. We can also still change the number of followers if we would like.\ndef profile_info(username, followers=1): print(\u0026#34;Username: \u0026#34; + username) print(\u0026#34;Followers: \u0026#34; + str(followers)) profile_info(username=\u0026#34;JOctopus\u0026#34;) profile_info(username=\u0026#34;sammyshark\u0026#34;, followers=945) Output:\nUsername: JOctopus Followers: 1 Username: sammyshark Followers: 945 Providing default parameters with values can let us skip defining values for each argument that already has a default.\nreturn So far, we have printed everything to the console as a string. When creating functions, it is very common to want to do something with the result of a function. The return statement causes your function to exit and hand back a value to its caller. The point of functions in general is to take in inputs and return a value to its caller.\nFor example, here\u0026rsquo;s a function utilizing both print() and return:\nThe following function, square, squares the parameter x and returns the variable y. We print out the value of result, which is created by calling the square() function with 3 passed as an argument.\ndef square(x): y = x ** 2 return y result = square(3) print(result) Output: 9\nThe output from square could be used by another line of code, like the following:\ndef square(x): y = x ** 2 return y result = square(3) * 2 print(result) Output: 18\nIn the above code, we were able to use the value that square(3) returned and multiply it by two.\n*args and **kwargs When programming, you may not be aware of all the possible use cases of your code, and may want to offer more options for future programmers working with the module, or for users interacting with the code. We can pass a variable number of arguments to a function by using *args and **kwargs in our code.\nHere is a great explanation for these tools: https://www.digitalocean.com/community/tutorials/how-to-use-args-and-kwargs-in-python-3\nlink:./functions-labs#age_calculator[Functions Exercises]\n"
},
{
	"uri": "/javascript/foundations/labs/promises-lab/",
	"title": "Promises Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch promises.js Add the following code to promises.js:\nfunction getData(callback) { const data = [1, 2, 3]; setTimeout(() =\u0026gt; callback(data), 1000); } getData(function (data) { const sum = data.reduce((a, b) =\u0026gt; a + b, 0); console.log(sum); }); Step 2: Complete the code and test  Refactor the code to use a Promise instead of a callback. Hint: the getData function should take no arguments and it should return a Promise.  Test your solution with:\nnode promises.js The expected output is:\n6 "
},
{
	"uri": "/web-essentials/webmastery-foundations/templating/",
	"title": "Templating Engines",
	"tags": [],
	"description": "",
	"content": "Template engines allows the use of static template files in a web application, making it easier to design an HTML page.\nAt runtime, the template engine replaces variables in a template file with actual values, and tranforms the template into an HTML file sent to the client.\nMustache The Mustache templating specification was released around 2009 and was first implemented in Ruby.\nMustache is \u0026ldquo;logic-less\u0026rdquo; because there are no if statements, else clauses, or for loops. Instead there are only tags. Some tags are replaced with a value, some nothing, and others a series of values.\nThe philosophy is to keep logic out of your templates. This is all about separation of concerns – keeping the presentation separate from your application logic.\nYou can get Mustache via npm: npm install mustache --save\nMustache Template Templates look like regular HTML, with embedded handlebars expressions.\nA mustache expression looks like: {{ \u0026lt;some contents\u0026gt; }}.\nExamples\n   Template Description     \u0026lt;h1\u0026gt;{{title}}\u0026lt;/h1\u0026gt; Look up the title property in the current context   \u0026lt;h1\u0026gt;{{article.title}}\u0026lt;/h1\u0026gt; Look up the article property in the current context then \u0026ldquo;look up the title property in the result    Handlebars Handlebars.js is a popular templating engine that is based on the Mustache template language, but improves it in several important ways. With Handlebars, you can separate the generation of HTML from the rest of your JavaScript and write cleaner code.\nHello Handlebars  Create a new directory called \u0026ldquo;handlebars-apps\u0026rdquo;. In a terminal in this new directory, type: npm init -y then npm install handlebars. Create the following file structure:  . ├── package-lock.json ├── package.json ├── app.js ├── data.json └── views ├── home.hbs └── layouts └── workshops.hbs Contents of data.json\n{ \u0026#34;company\u0026#34;: \u0026#34;The Home Depot\u0026#34;, \u0026#34;phone\u0026#34;: \u0026#34;512-555-9999\u0026#34;, \u0026#34;logo\u0026#34;: \u0026#34;https://thd.co/2EntYup\u0026#34;, \u0026#34;ceo\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;Craig\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Manear\u0026#34; }, \u0026#34;bestCompany\u0026#34;: true, \u0026#34;workshops\u0026#34;: [ { \u0026#34;instructor\u0026#34;: \u0026#34;JoShmo\u0026#34;, \u0026#34;workshop\u0026#34;: \u0026#34;How to be Awesome\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;I don\u0026#39;t always teach, but when I do, I\u0026#39;m awesome at it.\u0026#34; }, { \u0026#34;instructor\u0026#34;: \u0026#34;SalSue\u0026#34;, \u0026#34;workshop\u0026#34;: \u0026#34;Webmastery101\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;All of the transitions and neon.\u0026#34; }, { \u0026#34;instructor\u0026#34;: \u0026#34;StuWho\u0026#34;, \u0026#34;workshop\u0026#34;: \u0026#34;How to approach an Engineer\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;TLDR: don\u0026#39;t.\u0026#34; } ], \u0026#34;employees\u0026#34; : [ { \u0026#34;name\u0026#34;: \u0026#34;Al\u0026#34;, \u0026#34;height\u0026#34;: 95, \u0026#34;salary\u0026#34;: 5 }, { \u0026#34;name\u0026#34;: \u0026#34;Bob\u0026#34;, \u0026#34;height\u0026#34;: 60, \u0026#34;salary\u0026#34;: 1000000 } ] } Contents of views/home.hbs\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;ie=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;{{company}} Home\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Company Report for {{company}}\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Current CEO: {{ceo.firstName}} {{ceo.lastName}}\u0026lt;/p\u0026gt; \u0026lt;br\u0026gt;It is {{bestCompany}} that {{company}} is the best company! \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Contents of app.js\nconst fs = require(\u0026#39;fs\u0026#39;); const Handlebars = require(\u0026#39;handlebars\u0026#39;); function renderPage(template, data) { const readTemplate = fs.readFileSync(template, \u0026#39;utf8\u0026#39;); // 1  const compiledTemplate = Handlebars.compile(readTemplate); // 2  return compiledTemplate(data); // 3 } const companyFile = \u0026#39;views/home.hbs\u0026#39;; // 4 const data = require(\u0026#39;./data.json\u0026#39;); // 5 const result = renderPage(companyFile, data); console.log(result);  Read in the template file Compile the template using Handlebars Insert data by calling the compiled template like a function Our template file Our data source  Output:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;ie=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;The Home Depot Information\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Company Report for The Home Depot\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Current CEO: Craig Manear\u0026lt;br\u0026gt; It is true that The Home Depot is the best company! \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; We will get to the contents of views/layouts/workshops.hbs later\nHelpers Even though Handlebars is a logic-less templating engine, it can execute simple logic using helpers.\nA Handlebars helper is a simple identifier that may be followed by parameters (space separated).\n A function helper is for a single expression. A block helper is for multiple expressions placed in a block.  # signifies a helper is starting.\n/ signifies a helper is ending.\nBlock Helpers Blocks make it possible to define custom iterators and other functionality that can invoke the passed block with a new context.\nThe terms “block”, “helper”, and “block helper” are sometimes used interchangeably as most of the built-in helpers are blocks, although there are function helpers that are a bit different from block helpers.\nif block Display different information if a statement is true or false.\nUpdated view/home.hbs\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;ie=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;The Home Depot Information\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Company Report for {{company}}\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Current CEO: {{ceo.firstName}} {{ceo.lastName}}\u0026lt;/p\u0026gt; {{#if bestCompany}} It is {{bestCompany}} that {{company}} is the best company! {{else}} There are better companies out there, but we should still show {{company}}\u0026#39;s info. {{/if}} \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; each block To loop through a list of multiple items in a Array or an Object with Handlebar\u0026rsquo;s tags.\nUpdated view/home.hbs\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;ie=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;The Home Depot Information\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Company Report for {{company}}\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Current CEO: {{ceo.firstName}} {{ceo.lastName}}\u0026lt;/p\u0026gt; {{#if bestCompany}} It is {{bestCompany}} that {{company}} is the best company! {{else}} There are better companies out there, but we should still show {{company}}\u0026#39;s info. {{/if}} \u0026lt;/p\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Workshop\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Instructor\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Description\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; {{#each workshops}} \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;{{workshop}}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{instructor}}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{description}}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; {{/each}} \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; with block The with block helper enables us to pass a parameter as a context that is evaluated with the nested properties in our JSON object. This can be helpful for simplifying the syntax of our templates.\ntemplate.hbs\n\u0026lt;p\u0026gt;Current CEO: {{ceo.firstName}} {{ceo.lastName}}\u0026lt;br\u0026gt; It is {{bestCompany}} that {{company}} is the best company! \u0026lt;/p\u0026gt; Can be rewritten as:\ntemplate.hbs\n{{#with ceo}} \u0026lt;p\u0026gt;Current CEO: {{firstName}} {{lastName}}\u0026lt;br\u0026gt; {{/with}} It is {{bestCompany}} that {{company}} is the best company! \u0026lt;/p\u0026gt;    Go to templating engine labs    Custom Helpers It is possible to create your own helpers with Handlebars.registerHelper(). You can create both a custom function or block helper.\nHandlebars.registerHelper(\u0026#34;HelperName\u0026#34;, function(arguments){ // This function is executed whenever this helper is used }); Custom Function Helper The syntax for a function helper is:\n{{helperName parameter1 parameter2}}\nCreating a function helper called needsLadder which returns a string that will be \u0026ldquo;might need a ladder to reach things\u0026rdquo; if height \u0026lt; 90 and \u0026ldquo;might not need a ladder to reach things\u0026rdquo; height \u0026gt;= 90:\nJS portion of Custom Function Helper\nHandlebars.registerHelper(\u0026#34;needsLadder\u0026#34;, function(height){ if(height \u0026lt; 90){ return \u0026#34;might need a ladder to reach things\u0026#34;; } else{ return \u0026#34;might not need a ladder to reach things\u0026#34;; } }); HTML portion of Custom Function Helper\n{{#each employees}} {{name}} is {{needsLadder height}}.\u0026lt;br\u0026gt; {{/each}} Output would be:\nAl is might not need a ladder to reach things Bob is might need a ladder to reach things Partial Large template can be broken down into smaller, reusable template. This makes your templates easier to read and reuse.\nHandlebars allows for template reuse through partials. Partials are normal Handlebars templates that may be called directly by other templates. Another way to think of this is to think of partials as \u0026ldquo;mini-templates\u0026rdquo;.\nPotential Break Up of Large Templates To set up a partial, it must be registered.\nindex.js\nfunction registerPartial(name, partialFile){ const readPartial = fs.readFileSync(partialFile, \u0026#39;utf8\u0026#39;); Handlebars.registerPartial(name, readPartial); }; const partialFile = \u0026#39;views/layouts/workshops.hbs\u0026#39;; registerPartial(\u0026#39;workshops\u0026#39;, partialFile); This will register workshops partial which can be called in another template with the partial call syntax: {{\u0026gt; workshops}}.\nPartials are started with a \u0026gt;.\nviews/layouts/workshops.hbs\n{{\u0026gt; partialTemplate website=\u0026#34;http://handlebarsjs.com/\u0026#34;}} \u0026lt;br\u0026gt; {{\u0026gt; partialTemplate website=\u0026#34;www.pluralsite.com\u0026#34;}} Output:\nHandlebars is awesome. You can learn more about it at http://handlebarsjs.com/ \u0026lt;br\u0026gt; Handlebars is awesome. You can learn more about it at www.pluralsite.com In our company example, we can see our home.hbs file is getting larger and larger. We can separate the workshops table to it\u0026rsquo;s own file.\nUpdated views/layouts/workshops.hbs\n\u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Workshop\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Instructor\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Description\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; {{#each workshops}} \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;{{workshop}}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{instructor}}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{description}}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; {{/each}} \u0026lt;/table\u0026gt; Updated home.hbs\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;ie=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;{{company}} Information\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Company Report for {{company}}\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Current CEO: {{ceo.firstName}} {{ceo.lastName}}\u0026lt;/p\u0026gt; {{#if bestCompany}} It is {{bestCompany}} that {{company}} is the best company! {{else}} There are better companies out there, but we should still show {{company}}\u0026#39;s info. {{/if}} \u0026lt;/p\u0026gt; {{\u0026gt;workshops}} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; "
},
{
	"uri": "/web-essentials/webmastery-foundations/templating-labs/",
	"title": "Templating Engines Labs",
	"tags": [],
	"description": "",
	"content": "Create template to display a list of all the members of a team(You choose! Sports? Software? Choose a team with at least 5 people) in a table.\n The template, data and javascript should all be in their own files. Table format:  Each row should include an image, name, and two other details of the team member (each in their own cell)   Do NOT type multiple \u0026lt;tr\u0026gt; \u0026rsquo;s, you need to be using Handlebar\u0026rsquo;s block helpers! Write the newly generated HTML to a new file called home.html     Go to templating engine custom helpers lesson    Additional Resources  Mustache Handlebars and NodeJS https://www.sitepoint.com/a-beginners-guide-to-handlebars/  "
},
{
	"uri": "/path-to-production/",
	"title": "Path to Production",
	"tags": [],
	"description": "",
	"content": "Lessons Objectives The goal of this workshop is to inform you of the steps that you need to take to go from an idea to production. Once you go through the course you should understand:\nBefore you Build  Understanding the 12 factor app Requesting a Sub-experience Introduction to the ASA  Setting up your Development Environment  What tools to install and how What access\u0026rsquo;s do I need  Choosing a Tech Stack  What databases are available to use What Blob storage (buckets) solutions there are Messaging solutions CICD Pipeline solutions How to request data solutions  Configuring your Runtime Environment  Getting access to PCF Non-production Getting access to PCF Production How to create orgs and spaces How to install the cf-cli How to push an app How to request production \u0026ldquo;things\u0026rdquo; for your environment  Setting up CICD  Requesting a concourse server Setting up a CICD Pipeline What you need to in order to have an approved Pipeline Steps to getting a pipeline approved  Change Management  Accessing Service Now PCF Stage Change vs Deployment Definitions for the fields Understanding the Approval Process  "
},
{
	"uri": "/power-playlist/",
	"title": "Power Playlist",
	"tags": [],
	"description": "",
	"content": "OM\u0026rsquo;s Monthly Power Playlist on Pluralsight! October  Phishing Awareness: Welcome to Ginger Scott’s playlist on Phishing Awareness for all levels and roles. This playlist will introduce you to phishing and social engineering and how to be on guard against them. This channel is excellent for all associates in any area of the company.  September  A User-Centered Design: This playlist curated by Jill Levenson is excellent for those UX designers looking to level up their strategic skillset, as well as for associates in business, product or engineering roles who wish to leverage a Customer First mindset.  August  A Little Something for Everyone: Interested in learning something new? Jermaine Davis will take you on a journey through security, networking, cloud computing, fundamental architecture and more!.  July  Getting Started with Kubernetes : Welcome to Thomas Guillory\u0026rsquo;s playlist on Getting Started with Kubernetes for all levels and roles. This playlist presents resources that help you learn how to leverage Kubernetes to quickly deploy more resilient applications  Pluralsight is available to all technology associates. To gain access:\n Log into ARP Search for PLURALSIGHT ACCESS Add it to your cart Submit the request.  "
},
{
	"uri": "/python/",
	"title": "Python",
	"tags": [],
	"description": "",
	"content": "Objectives These lessons aim to teach you about Python.\n"
},
{
	"uri": "/python/foundation/additional-resources/",
	"title": "Additional Resources",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/javascript/foundations/labs/async-await-lab/",
	"title": "Async Await Lab",
	"tags": [],
	"description": "",
	"content": "Step 1: Create the JavaScript file and Add the Starter Code cd $HOME/js-foundations/labs touch async-await.js Add the following code to async-await.js:\nfunction getNumber(n) { return new Promise((resolve, reject) =\u0026gt; { setTimeout(() =\u0026gt; resolve(n), 500); }); } const getX = () =\u0026gt; getNumber(3); const getY = () =\u0026gt; getNumber(5); const getZ = () =\u0026gt; getNumber(2); // TODO: Make the following function `async` and replace the nested `.then` calls with // `await` statements that assign to local variables. // The result should still be the same, logging out the sum of `10` // HINT: With the `await` statements, there is no need for any nesting. function sumData() { return getX().then(x =\u0026gt; { return getY().then(y =\u0026gt; { return getZ().then(z =\u0026gt; { console.log(x + y + z); }); }); }); } sumData(); Step 2: Complete the code and test Complete the TODO in the above code.\nTest your solution with:\nnode async-await.js The expected output is:\n10 "
},
{
	"uri": "/python/foundation/functions-labs/",
	"title": "Function Labs",
	"tags": [],
	"description": "",
	"content": "Functions Exercises Age Calculator Create a function called age_calculator that takes in two parameters (Two different years) and returns the difference of the two years:\nPlace the following at the bottom of your code, outside of the function:\nprint(age_calculator(2018, 1900)) Example Output:\n118 Averaging numbers Define another function, avg_numbers that takes three parameters, that returns the average of three numbers.\nPlace the following at the bottom of your code, outside of the function:\nprint(avg_numbers(4, 7, 8)) Example output:\n6.33333333333 Go to Data Structures Lesson\n"
},
{
	"uri": "/javascript/foundations/oop/",
	"title": "OOP",
	"tags": [],
	"description": "",
	"content": "An introduction to Object-Oriented JavaScript and Prototypal Inheritance.\nLearning Objectives  What is Object-Oriented Programming? Use Constructor functions to create objects. Describe the this context. Explain Prototypes and the Prototype Chain Discuss the differences between classical and prototypal inheritance  What is OOP?  Object-Oriented Programming is programming with objects that encapsulate both code and data. Often several objects share a common structure. For example many dog objects may all have a name and an ability to eat, play, and bark. As developers we need an efficient way to capture this shared structure.  Constructor Functions In JavaScript, a constructor function may be used to create several objects that share a common structure.\nfunction Dog(name) { this.name = name; this.speak = function() { console.log(`${this.name}says woof woof!`); } } const snoopy = new Dog(\u0026#39;Snoopy\u0026#39;); // call the constructor with the `new` operator snoopy.speak(); The constructor function:\n should be named starting with a capital letter (a common convention) should be called with the new operator will implicitly create a this object that can be populated with properties and methods will implicitly return the this object  What is this?  When working with JavaScript objects, we often write methods that need to refer to properties of the bound object. We reference these properties from inside the Constructor function and inside any methods using the this identifier.  Example:\nfunction Person(firstName, lastName) { this.firstName = firstName; // create and populate the `firstName` property  this.lastName = lastName; // create and populate the `lastName` property  this.print = function() { console.log(`${this.firstName}${this.lastName}`); // method uses `this` to refer to the properties of the object  } } const p = new Person(\u0026#39;Homer\u0026#39;, \u0026#39;Depot\u0026#39;); p.print(); // Homer Depot OOP Inheritance  A powerful feature of OOP is inheritance. Inheritance is a way to create Class Hierarchies or Taxonomies. Inheritance means that objects will \u0026ldquo;inherit\u0026rdquo; the traits of parent objects. These inherited traits can include behavior (methods) and properties (data).  Prototypes  All JavaScript objects inherit properties and methods from a prototype. A prototype is just another object in memory. The prototype is created for you when you call the constructor function. All instances created from the constructor function will share the same prototype. Often you want to define methods on the prototype so that all instances share the same method definition.  Let\u0026rsquo;s change the above example to define the speak method on the prototype:\nfunction Dog(name) { this.name = name; // each dog has its own name } Dog.prototype.speak = function() { // all dog\u0026#39;s speak the same way  console.log(`${this.name}says woof woof!`); } const snoopy = new Dog(\u0026#39;Snoopy\u0026#39;); snoopy.speak(); Advantages of Prototype methods  all instances share the same method (instead of each instance having its own method) the prototype method can be modified at runtime and all instances will inherit the new behavior  The Prototype Chain  An instance can have the same method as its prototype Thus the instance method overrides the prototype method  Here is an example:\nfunction Dog(name) { this.name = name; } Dog.prototype.speak = function() { // default `speak` method  console.log(`${this.name}says woof woof!`); } const snoopy = new Dog(\u0026#39;Snoopy\u0026#39;); snoopy.speak(); const superDog = new Dog(\u0026#39;SuperDog\u0026#39;); superDog.speak = function() { // override the `speak` method for this instance  console.log(\u0026#34;I\u0026#39;m SuperDog!\u0026#34;); } superDog.speak(); Explanation:\n when you call a method on an object, the JS runtime first looks to see if the object itself has the method if found the method is executed otherwise, the JS runtime looks to see if the object\u0026rsquo;s prototype has the method if found it is executed otherwise the prototype\u0026rsquo;s prototype may have the method if found it is executed this continues until the method is found or all prototypes in the chain have been searched  Object.create Object.create():\n provides another way to instantiate an object allows for explicitly setting the object\u0026rsquo;s prototype  const cat = { isKingOfJungle: false, printIntroduction: function () { console.log(`My name is ${this.name}. Am I King of the Jungle? ${this.isKingOfJungle}`); } }; const lion = Object.create(cat); // `lion` has `cat` as it\u0026#39;s prototype lion.name = \u0026#34;Leo\u0026#34;; // `name` is a property set on `lion`, but not on `cat`. lion.isKingOfJungle = true; // inherited properties can be overridden. Lab See instructions here.\nSummary  At it\u0026rsquo;s core JavaScript is a functional language But JavaScript also supports OOP JavaScript constructor functions are used to create objects that share a common structure JavaScript prototypes are objects that encapsulate the common structure Methods can be shared across instances by assignment them to the prototype object Object.create allows for explicitly specifying an object as the prototype for a new object  Additional Resources  Common Misconceptions About Inheritance in JavaScript this \u0026amp; Object Prototypes  "
},
{
	"uri": "/web-essentials/webmastery-foundations/server-side/",
	"title": "Server-side Rendering",
	"tags": [],
	"description": "",
	"content": "Server-side rendering works by converting HTML files in the server into usable information for the browser.\nServer-side vs Client-side Rendering Website templates are a set of HTML webpages that anyone can use to \u0026ldquo;plug-in\u0026rdquo; text and images into to create a website.\nBoth server-side and client-side rendering use templating, but differ what webpage elements should be delivered to the browser.\n In server side rendering, the complete HTML is delivered to the browser. In client side rendering, both templates and data are delivered to the browser.     Server-side Rendering Client-side Rendering     Source: medium.com Source: medium.com    Server-side Cons  Many factors can quickly slow things down:  Internet speed Location of the server Number of users access the same site etc.   Frequent server requests: Every time you visit a page that your browser does not have a cached version of will have to repeat the whole process While the page is rendered earlier and the customer can see the page sooner, they can’t really interact with it until React is done executing The speed of the responsiveness of a webserver is slower since the server will have to spend the time to create the HTML for your page instead of just sending out a relatively empty response  Rendering Templates - Server-side Handlebars and Express can easily be integrated with express-handlebars. As their tag line says \u0026ldquo;A Handlebars view engine for Express which doesn\u0026rsquo;t suck.\u0026rdquo;\nInstallation: npm install express-handlebars.\nHello express-handlebars Create a new directory called exp-handl-app.\nIn this directory in the terminal type the following:\nnpm init -y npm install express npm install express-handlebars Basic File Structure\n. ├── app.js └── views ├── home.handlebars └── layouts └── main.handlebars 2 directories, 3 files This is a basic starter code for an Express app with a registered Handlebars view engine.\napp.js\nlet express = require(\u0026#39;express\u0026#39;); let exphbs = require(\u0026#39;express-handlebars\u0026#39;); let app = express(); //1  app.engine(\u0026#39;handlebars\u0026#39;, exphbs({defaultLayout: \u0026#39;main\u0026#39;})); //2 app.set(\u0026#39;view engine\u0026#39;, \u0026#39;handlebars\u0026#39;); //3  app.get(\u0026#39;/\u0026#39;, function(req, res){ res.render(\u0026#39;home\u0026#39;); }); app.listen(3000, function(){ console.log(\u0026#39;Listening on port 3000\u0026#39;); })  The constructor function produces instance objects which store their configuration, precompiled templates and expose an engine() function which can be registered with an Express app. Register Handlebars as the view engine and the default layout views/layouts/main.handlebars Use Handlebars view engine  The main layout is the HTML page wrapper which can be reused for the different views of the app. {{{body}}} is used as a placeholder for where the main content should be rendered.\nviews/layouts/main.handlebars\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;ie=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Home\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; {{{body}}} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; views/home.handlebars\n\u0026lt;h1\u0026gt;First Express Handlebars App: Home\u0026lt;/h1\u0026gt; Run the app with node app.js.\nOutput: Multiple Layouts To add a second layout for content, the second optional parameter of res.render must be used.\nFor example, if you had the following files:\nviews/layouts/withlogo.handlebars\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;ie=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Second Page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026#34;https://formatjs.io/img/handlebars.svg\u0026#34;\u0026gt; \u0026lt;/img\u0026gt; {{{body}}} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; views/logopage.handlebars\n\u0026lt;h1\u0026gt;Logo Page\u0026lt;/h1\u0026gt; The default layout must be overridden with view/layouts/withlogo.handlebars for the duration of that request with {title: 'Logo page', layout: 'withlogo'}.\nUpdate app.js to the following:\napp.get(\u0026#39;/next\u0026#39;, function (req, res) { res.render(\u0026#39;logopage\u0026#39;, {title: \u0026#39;Logo page\u0026#39;, layout: \u0026#39;withlogo\u0026#39;}); }); Additional Resources  Express-handlebars Documentation Server-side vs Client-side Client Side  "
},
{
	"uri": "/web-essentials/webmastery-foundations/project-add-front-end/",
	"title": "Add a Front-End to your existing API",
	"tags": [],
	"description": "",
	"content": "Project Guidelines Team up with your partner from the API project and add a front-end.\nThis project should specifically focus on views, your API should require minimal changes. Feel free to use the UX styleguide or any CSS Framework in addition to Handlebars or EJS.\nWire-frame A wire-frame should be completed and attached as a screenshot to your project on GitHub\nIndex all Resources Each resource should have it\u0026rsquo;s own index view that displays the most relevant information for all records related to that specific resource.\nFor example, when a user navigates to products/ all products will be displayed by name. Often, the user can click on a product to be taken to a show view with additional info.\nStyled Views for at least 3 Resources At least 3 resources should have the following views:\n index: /resource new: /resource/new show: /resource/:id edit: /resource/:id/edit  Full Functionality for at least One Resource At least one resource should have full CRUD functionality\nAs indicated above, the easiest way to accomplish this task is to have a view for each corresponding action (with the exception of delete, which can just be a button on your show and/or edit views)\nPresentation Your presentation should meet the following criteria\n Show off the capabilities of your app by giving a demo of your working views Discuss your wire-frame and your design decisions Preview of future plans (if we had more time, we would add\u0026hellip;)  "
},
{
	"uri": "/javascript/foundations/classes/",
	"title": "Classes",
	"tags": [],
	"description": "",
	"content": "An introduction to ES-2015 classes.\nLearning Objectives  Explain how ES-2015 Classes are used in JavaScript Write JavaScript classes with constructors and methods  Background  Before ES-2015, JavaScript objects were created via object literals or constructor functions. Implementing methods and inheritance had to be done via prototypes. The prototype syntax was clunky, for example:  function Person(name, job) { this.name = name; this.job = job; } // a method shared across all instances of this class Person.prototype.getName = function getName() { return this.name; }; // a method shared across all instances of this class Person.prototype.getJob = function getJob() { return this.job; }; var goodGuy = new Person(\u0026#34;Jim Gordon\u0026#34;, \u0026#34;Commissioner\u0026#34;); console.log(goodGuy.getName()); // prints \u0026#34;Jim Gordon\u0026#34; Enter Classes  JavaScript classes were introduced in ECMAScript 2015. Classes are primarily syntactical sugar over JavaScript\u0026rsquo;s existing prototype-based inheritance. Classes do not change the fundamental nature of how JavaScript implements objects and inheritance. It\u0026rsquo;s all still prototypes behind the scenes. The above example can now be written as:  class Person { // class names are capitalized  constructor(name, job) { // the constructor method initializes the objects state  this.name = name; this.job = job; } getName() { // a method shared across all instances of this class  return this.name; } getJob() { // a method shared across all instances of this class  return this.job; } } let goodGuy = new Person(\u0026#34;Jim Gordon\u0026#34;, \u0026#34;Commissioner\u0026#34;); console.log(goodGuy); // prints \u0026#34;Jim Gordon\u0026#34; Inheritance Classes provide a cleaner way to create inheritance relationships.\nBefore classes\nfunction Person(name, job) { this.name = name; this.job = job; } Person.prototype.getName = function getName() { return this.name; }; Person.prototype.getJob = function getJob() { return this.job; }; function SuperHero(name, heroName) { Person.call(this, name, heroName); } SuperHero.prototype = Object.create(Person); SuperHero.prototype.constructor = SuperHero; SuperHero.prototype.getJob = function() { return \u0026#34;I am \u0026#34; + this.job + \u0026#34;!\u0026#34;; }; var batman = new SuperHero(\u0026#34;Bruce Wayne\u0026#34;, \u0026#34;Batman\u0026#34;); console.log(batman.getJob()); As you can see, this is pretty verbose.\nWith classes\nclass Person { constructor(name, job) { this.name = name; this.job = job; } getName() { return this.name; } getJob() { return this.job; } } class SuperHero extends Person { // SuperHero extends (inherits from) Person  constructor(name, heroName, superPower) { super(name); // call the Person constructor  this.heroName = heroName; this.superPower = superPower; } secretIdentity() { // add a method for SuperHeroes  return `${this.heroName}is ${this.name}!!!`; } } let batman = new SuperHero(\u0026#34;Bruce Wayne\u0026#34;, \u0026#34;Batman\u0026#34;); console.log(batman.secretIdentity()); // Batman is Bruce Wayne!!! The 3 things that you\u0026rsquo;ll notice:\n Create a new SuperHero class and use the extends keyword to indicate you want to inherit from the Person class. The use of super() allows the reuse of existing name functionality from our Person class. Adds superhero specific features to our constructor function.  Getters and Setters If you have experience with Object Oriented programming, chances are that you\u0026rsquo;re familiar with getters and setters.\n JavaScript classes have the keywords get and set for defining getters and setters. Getters allow us to easily read (access) an object\u0026rsquo;s property. Setters allow us to write (modify) an object\u0026rsquo;s property. The syntax for using these getters and setters looks the same as for reading and writing an Object\u0026rsquo;s properties.  class Person { constructor(name) { this.name = name; } set name(name) { this._name = name; } get name() { return this._name; } } let goodGuy = new Person(\u0026#34;Jim Gordon\u0026#34;); // `goodGuy.name` will call the `get name()` method console.log(goodGuy.name); // Jim Gordon  // `goodGuy.name = ` will call the `set name()` method goodGuy.name = \u0026#34;James Gordon\u0026#34;; console.log(goodGuy.name); // James Gordon  Notice that we access the getter and setter methods without parentheses. Thus the getter and setter implementation is not apparent to the client code.  Lab See instructions here.\nSummary  The class keyword is syntactic sugar that abstracts away some of the syntactic complexity of dealing with Constructor Functions and Prototypes. JavaScript classes make it easy to do OOP in JavaScript.  Additional Resources  Difference Between Class and Prototypal Inheritance Understanding Classes in JavaScript  "
},
{
	"uri": "/python/foundation/data-structures/",
	"title": "Data Structures",
	"tags": [],
	"description": "",
	"content": "Data Structures Introduction It is very common to want to list numbers or strings. This is possible with data structures. Data structures are a specialized format for organizing and storing data. There are quite a few data structures that are available that will be described in the following sections.\nLists A list is a data structure in Python that is a mutable, or changeable, ordered sequence of elements. Each element or value that is inside of a list is called an item. Just as strings are defined as characters between quotes, lists are defined by having values between square brackets [ ].\nLists are great to use when you want to work with many related values. They allow you to keep data together that belongs together, condense your code, and perform the same methods and operations on multiple values at once.\nExample: Creating a list of strings called dogs\ndogs = [\u0026#34;Collie\u0026#34;, \u0026#34;Labrador\u0026#34;, \u0026#34;Sheltie\u0026#34;, \u0026#34;Dalmatian\u0026#34;] When you print out the list, the output looks exactly like the list we created:\nprint(dogs) Output: [\u0026quot;Collie\u0026quot;, \u0026quot;Labrador\u0026quot;, \u0026quot;Sheltie\u0026quot;, \u0026quot;Dalmatian\u0026quot;]\nLength len(), just like in a string, allows you to find the number of elements that are in a list. Do the following to find the length of a list:\ndogs = [\u0026#34;Collie\u0026#34;, \u0026#34;Labrador\u0026#34;, \u0026#34;Sheltie\u0026#34;, \u0026#34;Dalmatian\u0026#34;] print(len(dogs)) Output: 4\nTIP: Keep in mind that length starts counting at 1\nIndexing As an ordered sequence of elements, each item in a list can be called individually, through indexing. Lists are a compound data type made up of smaller parts, and are very flexible because they can have values added, removed, and changed. When you need to store a lot of values or iterate over values, and you want to be able to readily modify those values, you\u0026rsquo;ll likely want to work with list data types.\nEach item in a list corresponds to an index number, which is an integer value, starting with the index number 0. (Just like string\u0026rsquo;s indexing)\nFor the list dogs, the index breakdown looks like this:\n   Collie Labrador Sheltie Dalmatian     0 1 2 3    The first item, the string Collie starts at index 0, and the list ends at index 4 with the string Dalmatian.\nBecause each item in a Python list has a corresponding index number, we\u0026rsquo;re able to access and manipulate lists in the same ways we can with other sequential data types.\nWe can call a specific item of the list by referring to its index number:\nprint(dogs[1]) Output: Labrador\nThe index numbers for this list range from 0 - 3, as shown in the table above. So if we tried to access a value greater than this, we would get an Out Of Range error!\nprint(dogs[10]) Output: IndexError: list index out of range\nIt is very common to need the last item in a list. If a boss needs to fire the person with the lowest number of sales, they could find this in a sorted list that is in descending order of sales. To easily find the last item in a list, we can access from the list with a negative index number, by counting backwards from the end of the list, starting at -1. This is especially useful if we have a long list and we want to pinpoint an item towards the end of a list.\nFor the same list dogs, the negative index breakdown looks like this:\n   Collie Labrador Sheltie Dalmatian     -4 -3 -2 -1    So, if we would like to print out the item Sheltie by using its negative index number, we can do so like this:\nprint(dogs[-2]) Output: Sheltie\nWe can concatenate string items in a list with other strings using the + operator.\nprint(\u0026#34;Charlie is a \u0026#34; + dogs[1]) Output: Charlie is a Labrador\nSlicing We can also call out a few items from the list. Let\u0026rsquo;s say we would like to just print the middle items of dogs, we can do so by creating a slice. With slices, we can call multiple values by creating a range of index numbers separated by a colon [start_index: stop_index]\nprint(dogs[1: 3]) Output: [\u0026quot;Golden Retriever\u0026quot;, \u0026quot;Sheltie\u0026quot;]\nWhen creating a slice, as in [1: 3], the first index number is where the slice starts (inclusive), and the second index number is where the slice ends (exclusive), which is why in our example above the items at position 1 and 2 are the items that print out.\n If we want to include either end of the list, we can get rid of the numbers in the list[x: y] syntax. For example, if we want to print the first 2 items in the list dogs - which would be Collie and Golden Retriever - we can do so by typing:\nprint(dogs[: 2]) Output: [\u0026quot;Collie\u0026quot;, \u0026quot;Golden Retriever\u0026quot;] This list printed off the list items with indexes starting with 0 and going up to (but not including) 2.\nTo include all the items at the end of a list, we would reverse the syntax:\nprint(dogs[2: ]) Output: [\u0026quot;Sheltie\u0026quot;, \u0026quot;Dalmatian\u0026quot;] This list printed off the list items with indexes starting with 2 and going to the end of the list.\nOne last thing that we can use with slicing is the step. Step is how many items to move forward after the first item is retrieved from the list. Before this point, we have not used the step parameter, meaning we are using the default step value of one.\nThis syntax for this construction is list[x: y: z], with z referring to stride. Let\u0026rsquo;s make a larger list, then slice it, and give the step a value of 2:\nnumbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] print(numbers[1: 11: 2]) Output: [1, 3, 5, 7, 9]\nThe above example starts at index 1, goes up to (but not including) 11, going up by 2\u0026rsquo;s (every other item).\nWe can omit the first two parameters and use step alone with the syntax list[: : 2]\nprint(numbers[: : 3]) Output: [0, 3, 6, 9]\nWe can print the list backwards with a negative step\nprint(numbers[: : -2]) Output: [10, 8, 6, 4, 2, 0]\nModifying We can use indexing to change items within the list, by settling an index number equal to a different value. This gives us greater control over lists as we are able to modify and update the items that they contain.\nIf we want to change the string value of the item at index 1 from Labrador to Golden Retriever, we can do so like:\ndogs[1] = \u0026#34;Golden Retriever\u0026#34; Now if we print out dogs, we can see the updated values.\nprint(dogs) Output: [\u0026quot;Collie\u0026quot;, \u0026quot;Golden Retriever\u0026quot;, \u0026quot;Sheltie\u0026quot;, \u0026quot;Dalmatian\u0026quot;]\nAdding Operators can be used to make modifications to lists. The + operator can be used to concatenate two or more lists together:\nfirst_names = [\u0026#34;Noelle\u0026#34;, \u0026#34;Tereza\u0026#34;, \u0026#34;Raelin\u0026#34;, \u0026#34;Linus\u0026#34;] last_names = [\u0026#34;Blossom\u0026#34;, \u0026#34;Chrissy\u0026#34;, \u0026#34;Grover\u0026#34;, \u0026#34;Devin\u0026#34;] print(first_names + last_names) Output: [\u0026quot;Noelle\u0026quot;, \u0026quot;Tereza\u0026quot;, \u0026quot;Raelin\u0026quot;, \u0026quot;Linus\u0026quot;, \u0026quot;Blossom\u0026quot;, \u0026quot;Chrissy\u0026quot;, \u0026quot;Grover\u0026quot;, \u0026quot;Devin\u0026quot;]\nBecause the + operator can concatenate, it can be used to add an item (or several) in list form to the end of another list.\nfirst_names = first_names + [\u0026#34;Sally\u0026#34;] print(first_names) Output: [\u0026quot;Noelle\u0026quot;, \u0026quot;Tereza\u0026quot;, \u0026quot;Raelin\u0026quot;, \u0026quot;Linus\u0026quot;, \u0026quot;Sally\u0026quot;]\n+ and * operators have a compound forms += and *=. So the above example can also be written as:\nfirst_names += [\u0026#34;Sally\u0026#34;] print(first_names) Output: [\u0026quot;Noelle\u0026quot;, \u0026quot;Tereza\u0026quot;, \u0026quot;Raelin\u0026quot;, \u0026quot;Linus\u0026quot;, \u0026quot;Sally\u0026quot;]\n If you do not place the brackets around the string you are adding, the following will happen:\nfirst_names += \u0026#34;Sally\u0026#34; print(first_names) Output: ['Noelle', 'Tereza', 'Raelin', 'Linus', 'S', 'a', 'l', 'l', 'y']\nThis is because Python will take the string as a list of characters, therefore adding the characters one at a time.\nRemoving Items can be removed from lists by using the del statement. This will delete the value at the index number you specify within a list.\nFrom the dogs list, let’s remove the item \u0026ldquo;Sheltie\u0026rdquo;. This item is located at the index position of 2. To remove the item, we’ll use the del statement then call the list variable and the index number of that item:\ndogs = [\u0026#34;Collie\u0026#34;, \u0026#34;Golden Retriever\u0026#34;, \u0026#34;Sheltie\u0026#34;, \u0026#34;Dalmatian\u0026#34;] del dogs[2] print(dogs) Output: [\u0026quot;Collie\u0026quot;, \u0026quot;Golden Retriever\u0026quot;, \u0026quot;Dalmatian\u0026quot;]\nWe can also specify a range with the del statement. Say we wanted to remove not only the item \u0026ldquo;Sheltie\u0026rdquo;, but also \u0026ldquo;Dalmatian\u0026rdquo; as well. We can call a range in dogs with the del statement to accomplish this:\ndogs = [\u0026#34;Collie\u0026#34;, \u0026#34;Golden Retriever\u0026#34;, \u0026#34;Sheltie\u0026#34;, \u0026#34;Dalmatian\u0026#34;] del dogs[2: ] print(dogs) Output: [\u0026quot;Collie\u0026quot;, \u0026quot;Golden Retriever\u0026quot;]\nList Methods List has several methods that are very helpful. We are going to briefly cover some of the list methods that are available.\nlist.append() The method list.append(x) will add an item (x) to the end of a list.\nfish = [\u0026#34;barracuda\u0026#34;, \u0026#34;cod\u0026#34;, \u0026#34;devil ray\u0026#34;, \u0026#34;eel\u0026#34;] This list is comprised of 4 string items, and their index numbers range from \u0026lsquo;barracuda\u0026rsquo; at 0 to \u0026lsquo;eel\u0026rsquo; at index 3.\nAdding flounder to the List\nfish.append(\u0026#39;flounder\u0026#39;) print(fish) Output: ['barracuda', 'cod', 'devil ray', 'eel', 'flounder']\nNow, we have a list of 5 string items that ends with the item we passed to the .append() method.\nIt is also possible to add a list to the end of a list\nAdding a list inside a List\nfish.append([\u0026#39;flounder\u0026#39;, \u0026#39;clown\u0026#39;]) print(fish) Output: ['barracuda', 'cod', 'devil ray', 'eel', ['flounder', 'clown']]\nNow, we have a list of 5 string items that ends with the list we passed to the .append() method.\nlist.extend() The method list.extend(x) acts similarly to list.append(x). This method adds element(s) (notice it can be plural!) to a list by adding the element(s) of the item you pass to it. The resulting list is one containing all of the elements of both lists.\nfish = [\u0026#34;barracuda\u0026#34;, \u0026#34;cod\u0026#34;, \u0026#34;devil ray\u0026#34;, \u0026#34;eel\u0026#34;] This list is comprised of 4 string items, and their index numbers range from \u0026lsquo;barracuda\u0026rsquo; at 0 to \u0026lsquo;eel\u0026rsquo; at index 3.\nAdding flounder to the List\nfish.extend([\u0026#39;flounder\u0026#39;]) print(fish) Output: ['barracuda', 'cod', 'devil ray', 'eel', 'flounder']\nNow, we have a list of 5 string items that ends with the item we passed to the .extend() method.\nIt is also possible to add a list to the end of a list\nAppending a list to the end a List\nfish.extend([\u0026#39;flounder\u0026#39;, \u0026#39;clown\u0026#39;]) print(fish) Output: ['barracuda', 'cod', 'devil ray', 'eel', 'flounder', 'clown']\nThis is where the difference of append() and extend() is seen.\nlist.insert() The list.insert(i,x) method takes two arguments, with i being the index position you would like to add an item to, and x being the item itself.\nOur aquarium acquired another new fish, an anchovy. You may have noticed that so far the list fish is in alphabetical order. Because of this, we don’t want to just add the string \u0026lsquo;anchovy\u0026rsquo; to the end of fish with the list.append() method. Instead, we’ll use list.insert() to add \u0026lsquo;anchovy\u0026rsquo; to the beginning of this list at index position 0:\nfish.insert(0, \u0026#39;anchovy\u0026#39;) print(fish) Output: ['anchovy', 'barracuda', 'cod', 'devil ray', 'eel', 'flounder']\nIn this case, we added the string item to the front of the list. Each of the successive items will now be at a new index number as they have all moved down. Therefore, \u0026lsquo;barracuda\u0026rsquo; will be at index 1, \u0026lsquo;cod\u0026rsquo; will be at index 2, and \u0026lsquo;flounder\u0026rsquo; — the last item — will be at index 5.\nIf, at this point, we are bringing a damselfish to the aquarium and we wanted to maintain alphabetical order based on the list above, we would put the item at index 3: fish.insert(3,'damselfish').\nlist.count() list.count() method will return the number of times the value x occurs within a specified list. This is useful for when you want to search a large list for the frequency of an item in a list. Say that you have a list of employees salaries and you would like to know how many people have the same salary as you: 20000. You could use could to help with this situation.\nsalaries = [20000, 45000, 90000, 70000, 20000, 90000] print(salaries.count(20000)) Output: 2\nBecause the number 20000 occurs twice, the number 2 is returned.\nlist.sort() We can use the list.sort() method to sort the items in a list.\nJust like list.count(), list.sort() can make it more apparent how many of a certain integer value we have, and it can also put an unsorted list of numbers into numeric order.\nLet’s use the integer list, fish_ages to see the .sort() method in action:\nfish_ages = [1,2,4,3,2,1,1,2] fish_ages.sort() print(fish_ages) Output: [1, 1, 1, 2, 2, 2, 3, 4]\nBy using .sort() with fish_ages, the integer values are returned in order. In practice, since these ages correspond to specific fish, you would likely want to make a copy of the original list prior to sorting it.\nWe can sort a list in reverse order by using the optional parameter reverse. The default value for the parameter is False.\nSorting a list in reverse\nfish_ages = [1,2,4,3,2,1,1,2] fish_ages.sort(reverse=True) print(fish_ages) Output: [4, 3, 2, 2, 2, 1, 1, 1]\nlist.remove() We can use the list.remove() method to remove an item in a list.\nRemoving Cod From list\nfish = [\u0026#34;barracuda\u0026#34;, \u0026#34;cod\u0026#34;, \u0026#34;devil ray\u0026#34;, \u0026#34;eel\u0026#34;] fish.remove(\u0026#34;cod\u0026#34;) print(fish) Output:\n[\u0026#39;barracuda\u0026#39;, \u0026#39;devil ray\u0026#39;, \u0026#39;eel\u0026#39;]  Applying your knowledge  Create a list of strings called my_friends. Fill this list with the following names: \u0026ldquo;Rizzo\u0026rdquo;, \u0026ldquo;French\u0026rdquo;, \u0026ldquo;Danny\u0026rdquo;, \u0026ldquo;Kenickie\u0026rdquo;, \u0026ldquo;Marty\u0026rdquo;, \u0026ldquo;Sandy\u0026rdquo;, \u0026ldquo;Cha-Cha\u0026rdquo;, \u0026ldquo;Patty\u0026rdquo;, \u0026ldquo;Sonny\u0026rdquo;, \u0026ldquo;Calhoun\u0026rdquo; Use your my_friends list for the following:  print out the length of the list print out the 4th friend\u0026rsquo;s name print out the 11th friend\u0026rsquo;s name (What happens?)  once you have run this once, comment out the above line   print out the last friend\u0026rsquo;s name (Use negative indexing) print out the 5th - 8th friend\u0026rsquo;s names print out the last 5 names (Do not place a number in both start and stop) print out the first 3 names (Do not place a number in both start and stop) print out every other name, starting at the first name print out every third name, starting at the last name going backwards to the front of the list. change the 8th friend\u0026rsquo;s name to \u0026ldquo;Elizabeth\u0026rdquo;. Print out the changed list. add a new friend, Danny, to the end of the list. Print out the changed list. remove the 7th friend\u0026rsquo;s name (They ate the last cookie in the jar). Print out the changed list. insert a new friend, Sandy, in the 3rd spot of the list. Print out the changed list. print out the number of times the name Sandy appears in the list. sort the list to be in alphabetical order. Print out the sorted list.    Lists Exercises Lists Exercises\nTuples A tuple is a data structure in Python that is an immutable, or unchangeable, ordered sequence of elements. Because it is immutable, the elements in the tuple cannot be changed. The immutability of a tuple helps send the message to others that the information inside of the tuple should not change.\nEach element or value that is inside of a tuple is called an item. Just as lists are defined as items between square brackets, tuples are defined by having values between parenthesis ( ) and separated by commas. Empty tuples look like: grade_level = (), but even tuples with just one item must use commas as in grade_level = (9, )\nA tuple in Python looks like:\nemp_rank = (\u0026#34;Software Engineer\u0026#34;, \u0026#34;Sr. Software Engineer\u0026#34;, \u0026#34;Staff Software Engineer\u0026#34;, \u0026#34;Software Engineer Principal\u0026#34;) If we were to print the above tuple, it would look like the following:\nprint(emp_rank) Output: (\u0026quot;Software Engineer\u0026quot;, \u0026quot;Sr. Software Engineer\u0026quot;, \u0026quot;Staff Software Engineer\u0026quot;, \u0026quot;Software Engineer Principal\u0026quot;)\nLength len(), just like in a string or a list, allows you to find the number of elements that are in a tuple. Do the following to find the length of a tuple:\nemp_rank = (\u0026#34;Software Engineer\u0026#34;, \u0026#34;Sr. Software Engineer\u0026#34;, \u0026#34;Staff Software Engineer\u0026#34;, \u0026#34;Software Engineer Principal\u0026#34;) print(len(emp_rank)) Output: 4\nTIP: Keep in mind that length starts counting at 1\nIndexing Just like a string or list, tuple\u0026rsquo;s elements can be accessed individually with indexing.\nFor the emp_rank tuple, the index break down looks like:\n   Software Engineer Sr. Software Engineer Staff Software Engineer Software Engineer Principal     0 1 2 3    The first item Software Engineer starts at index 0, and the list ends at index 3 with Software Engineer Principal\nAccessing the first item in the tuple emp_rank\nprint(emp_rank[0]) Output: Software Engineer\nSimilar to strings and lists, be careful to not go out of bounds. In the emp_rank tuple, any number greater than 3 would give an IndexError. Negative numbers are valid inputs for indexes. The negative breakdown of emp_rank is:\n   Software Engineer Sr. Software Engineer Staff Software Engineer Software Engineer Principal     -4 -3 -2 -1    We can concatenate string items in a tuple with other strings using the + operator:\nprint(\u0026#39;The current employee has the position of \u0026#39; + emp_rank[2]) Output: The current employee has the position of Sr. Software Engineer\nSlicing Similar to lists and strings, you can access part of a tuple with slicing with a range of index numbers separated by a colon [x: y].\nPrinting the middle part of the emp_rank tuple\nprint(emp_rank[1: 3]) Output: (\u0026quot;Sr. Software Engineer\u0026quot;, \u0026quot;Staff Software Engineer\u0026quot;)\nLeaving out either the start or stop range when slicing means you either want to start at the beginning of the tuple or go to the end of a tuple.\nPrinting from the beginning of the tuple up to, but not including, index 3\nprint(emp_rank[: 3]) Output: (\u0026quot;Software Engineer\u0026quot;, \u0026quot;Sr. Software Engineer\u0026quot;, \u0026quot;Staff Software Engineer\u0026quot;)\nPrinting from index 3 up to the end of the tuple\nprint(emp_rank[3: ]) Output: (\u0026quot;Sr. Software Engineer\u0026quot;, \u0026quot;Staff Software Engineer\u0026quot;, \u0026quot;Software Engineer Principal\u0026quot;)\nOne last thing that we can use with slicing is the step. Step is how many items to move forward after the first item is retrieved from the tuple. Before this point with tuples, we have not used the step parameter, meaning we are using the default step value of one.\nThis syntax for this construction is tuple[x: y: z], with z referring to stride. Let\u0026rsquo;s make a larger tuple, then slice it, and give the step a value of 2:\nnumbers = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10) print(numbers[1: 9: 2]) Output: (1, 3, 5, 7)\nThe above example starts at index 1, goes up to (but not including) 11, going up by 2\u0026rsquo;s (every other item).\nWe can omit the first two parameters and use step alone with the syntax tuples[: : 2]\nprint(numbers[: : 3]) Output: (0, 3, 6, 9)\nWe can print the tuple backwards with a negative step\nprint(numbers[: : -2]) Output: (10, 8, 6, 4, 2, 0)\nConcatenating Operators can be used to concatenating We’ll look at using the + and * operators and their compound forms += and *=\nThe + operator can be used to concatenate two or more lists together:\nfirst_names = (\u0026#34;Noelle\u0026#34;, \u0026#34;Tereza\u0026#34;, \u0026#34;Raelin\u0026#34;, \u0026#34;Linus\u0026#34;) last_names = (\u0026#34;Blossom\u0026#34;, \u0026#34;Chrissy\u0026#34;, \u0026#34;Grover\u0026#34;, \u0026#34;Devin\u0026#34;) print(first_names + last_names) Output: (\u0026quot;Noelle\u0026quot;, \u0026quot;Tereza\u0026quot;, \u0026quot;Raelin\u0026quot;, \u0026quot;Linus\u0026quot;, \u0026quot;Blossom\u0026quot;, \u0026quot;Chrissy\u0026quot;, \u0026quot;Grover\u0026quot;, \u0026quot;Devin\u0026quot;)\nTuples vs. Lists The main way that tuples are different from lists is the fact that they are immutable, unable to be changed. This means that items cannot be changed, added or removed from a tuple, whereas a list item can do all of those.\nConsidering the emp_rank tuple:\nemp_rank = (\u0026#34;Software Engineer\u0026#34;, \u0026#34;Sr. Software Engineer\u0026#34;, \u0026#34;Staff Software Engineer\u0026#34;, \u0026#34;Software Engineer Principal\u0026#34;) Say we want to replace the item \u0026ldquo;Software Engineer\u0026rdquo; with a different item called \u0026ldquo;Newbie Software Engineer\u0026rdquo;. If we try to change that output the same way we do a list, by typing:\nemp_rank[0] = \u0026#34;Newbie Software Engineer\u0026#34; We would receive the error: TypeError: 'tuple object does not support item assignment'\nThis is because tuples cannot be modified. If we create a tuple and decide what we really need is a list, we can convert it to a list. To convert a tuple to a list, we can do so with list().\nlist(emp_rank) This changed our tuple to a list:\nprint(emp_rank) Output: [\u0026quot;Software Engineer\u0026quot;, \u0026quot;Sr. Software Engineer\u0026quot;, \u0026quot;Staff Software Engineer\u0026quot;, \u0026quot;Software Engineer Principal\u0026quot;]\nApplying your knowledge  Create a tuple called vowels that stores all of the vowels of the alphabet: a, e, i, o, u Using vowels, do the following:  Print out the length of the vowels Print out the 3rd vowel in vowels Print out the 1st - 4th vowel (Use both the start and stop) Print out the 1st - 4th vowel (Do not use both the start and stop) Print out e and o using slicing Change the last vowel to y. What happens?  After you are done with the above step, comment it out      Tuples Exercises Tuples Exercises\nSets A set is a mutable data structure in Python that contains an unordered collection of elements. These elements are unique (no repeats) and unordered. Sets are used for removing duplicate entries and performing set operations such as intersection, union and difference.\nThere are two built-in set types: set and frozenset. The set type is mutable and the frozenset type is immutable.\nSet Ups of a Set\n  set() for an empty set.\n  set(values)\n  {value1, valuen}\n  Creating a frozenset is very similar and uses frozenset() instead of set().\nExample of an Empty Set\nmyset1 = set() print(myset1) Output: set()\nWhen a set is given a string or any other iterable, it return a set composed of the iterable\u0026rsquo;s elements.\nExample of a Set with a String\nmyset = set(\u0026#39;aabbbbc\u0026#39;) print(myset) Output: {'b', 'a', 'c'}\nExample of a Set with a List\npositions = set([\u0026#34;Software Engineer\u0026#34;, \u0026#34;Sr. Software Engineer\u0026#34;, \u0026#34;Staff Software Engineer\u0026#34;, \u0026#34;Software Engineer Principal\u0026#34;, \u0026#34;Software Engineer\u0026#34;]) print(positions) Output: {'Sr. Software Engineer', 'Software Engineer', 'Staff Software Engineer', 'Software Engineer Principal'}\nExample of { } Syntax\nlanguages={\u0026#39;python\u0026#39;,\u0026#39;java\u0026#39;,\u0026#39;c#\u0026#39;,\u0026#39;php\u0026#39;} print(languages) Output: {'c#', 'php', 'java', 'python'}\nLength len(), just like in a string, tuple or a list, allows you to find the number of elements that are in a set. Do the following to find the length of a set:\npositions = set([\u0026#34;Software Engineer\u0026#34;, \u0026#34;Sr. Software Engineer\u0026#34;, \u0026#34;Staff Software Engineer\u0026#34;, \u0026#34;Software Engineer Principal\u0026#34;, \u0026#34;Software Engineer\u0026#34;]) print(len(positions)) Output: 4\nSet Methods Set has several methods that are very helpful. We are going to briefly cover some of the set methods that are available.\nIntersection\nThe method set1.intersection(set2) will find the similar elements in both set1 and set2.\nExample of finding the similar favorite programming languages of Jo and Al\njos_favs = {\u0026#39;python\u0026#39;, \u0026#39;c++\u0026#39;, \u0026#39;javascript\u0026#39;} als_favs = {\u0026#39;c#\u0026#39;, \u0026#39;python\u0026#39;} print(jos_favs.intersection(als_favs)) Output: {'python'}\nDifference\nThe method set1.difference(set2) will find the elements in set1 and set2 that are different.\nExample of finding the different favorite programming languages of Jo and Al\njos_favs = {\u0026#39;python\u0026#39;, \u0026#39;c++\u0026#39;, \u0026#39;javascript\u0026#39;} als_favs = {\u0026#39;c#\u0026#39;, \u0026#39;python\u0026#39;} print(jos_favs.difference(als_favs)) Output: {'javascript', 'c++'}\nUnion\nThe method set1.union(set2) will show the combination of elements in set1 and set2.\nExample of showing the combination of favorite programming languages of two people\njos_favs = {\u0026#39;python\u0026#39;, \u0026#39;c++\u0026#39;, \u0026#39;javascript\u0026#39;} als_favs = {\u0026#39;c#\u0026#39;, \u0026#39;python\u0026#39;} print(jos_favs.union(als_favs)) Output: {'python', 'javascript', 'c#', 'c++'}\nModifying Sets Since sets are mutable, you can add, remove and modify elements after creation.\nTIP: The following methods do not work with frozensets.\nAdding The method set.add(x) will modify the set to include x. If x is already in the set, there will not be a change.\nExample of add method\njos_favs = {\u0026#39;python\u0026#39;, \u0026#39;c++\u0026#39;, \u0026#39;javascript\u0026#39;} jos_favs.add(\u0026#39;java\u0026#39;) print(jos_favs) Output: {'python', 'java', 'javascript', 'c++'}\nRemoving The method set.remove(x) will modify the set to not include x. If x is not in the set, there will not be a change.\nExample of remove method\njos_favs = {\u0026#39;python\u0026#39;, \u0026#39;c++\u0026#39;, \u0026#39;javascript\u0026#39;, \u0026#39;java\u0026#39;} jos_favs.remove(\u0026#39;java\u0026#39;) print(jos_favs) Output: {'python', 'javascript', 'c++'}\n Applying your knowledge  Create a set called set1 with a string with a value of aaabcccccdd (Use the set() notation). Print out the values of the set after you create it Create a set called set2 with a string with a value of \u0026quot;b\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;t\u0026quot;, \u0026quot;s\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;t\u0026quot;, \u0026quot;s\u0026quot; (Use the {value1} notation). Print out the values of the set after you create it Print out the number of elements in set1 Print out what set1 and set2 have in common Print out what values that set1 has that set2 does not have Print out the combination of set1 and set2 Add the letter e to set1. Print out the new set Remove the letter b from set2. Print out the new set  Sets Exercises Sets Exercises\nDictionaries If you want to look up a meaning of a word, you use a dictionary. Whether it is online or a book, you look up the word and the definition is returned! In this example, you could think of the word as a key and the definition as the value that is returned. A Python dictionary is a collection of key-value pairs, just like in a \u0026ldquo;regular\u0026rdquo; dictionary!\nKeys in a dictionary must be unique. The key and value pairs are listed between curly brackets. Dictionaries are useful whenever you have items that you wish to link together and want to store results for a quick look up.\nDictionary Set Up\nsalaries = {\u0026#39;Pam\u0026#39;: 12000, \u0026#39;Jim\u0026#39;: 10000, \u0026#39;Dwight\u0026#39;: 50000} Dictionaries are surrounded by curly braces and each key and value pair are separated by a colon.\nThe keys in the above dictionary are Pam, Jim and Dwight.\nThe values are 12000, 10000, 50000.\nPrinting Dictionaries\nprint(salaries) Output: {'Pam': 12000, 'Jim': 10000, 'Dwight': 50000}\nAccessing Elements When accessing specific key value pairs, we call the values by referencing the related keys. If we wanted to see Jim\u0026rsquo;s salary, we could do so by calling salaries['Jim'].\nprint(salaries[\u0026#39;Jim\u0026#39;]) Output: 10000\nDictionaries act like a database in that instead of calling an integer to get a particular index value as you would with a list, you assign a value to a key and can call that key to get its related value.\nBy invoking the key Jim, we receive the value of that key, which is 10000.\nMethods to Access Elements In addition to using keys to access values, we can also work with some built-in methods:\n  dict.keys() lists off just the keys\n  dict.values() lists off just the values\n  dict.items() lists key-value pairs in a list format (key, value) tuple pairs.\n  For the example uses of the dictionary methods, we will use the following dictionary:\nresults_10k = {\u0026#39;Elizabeth\u0026#39;: \u0026#39;56: 09\u0026#39;, \u0026#39;Emily\u0026#39;: \u0026#39;56: 23\u0026#39;, \u0026#39;Alison\u0026#39;: \u0026#39;57: 36\u0026#39;} To return the keys, we would use the dict.keys() method. In our example, that would use the variable name and by results_10k.keys(). This method printed would look like the following:\nprint(results_10k.keys()) Output: dict_keys(['Elizabeth', 'Emily', 'Alison'])\nWe receive output that places the keys within an iterable view object of the dict_keys class. The keys are then printed within a list format.\nSimilarly, we can use the dict.values() method to query the values in the results_10k dictionary, which would be constructed as results_10k.values(). Let\u0026rsquo;s print those out:\nresults_10k = {\u0026#39;Elizabeth\u0026#39;: \u0026#39;56: 09\u0026#39;, \u0026#39;Emily\u0026#39;: \u0026#39;56: 23\u0026#39;, \u0026#39;Alison\u0026#39;: \u0026#39;57: 36\u0026#39;} print(results_10k.values()) Output: dict_values(['56: 09', '56: 23', '57: 36']) Both the methods keys() and values() return unsorted lists of the keys and values present in the dictionary with the view object of dict_keys and dict_values respectively.\nIf you are interested in all of the items in a dictionary, we can access them with the items() method:\nprint(results_10k.items()) Output: dict_items(['Elizabeth': '56: 09', 'Emily': '56: 23', 'Alison': '57: 36']) The returned format of this is a list made up of (key, value) tuple pairs with the dict_items view object.\nModifying Dictionaries Dictionaries are mutable, meaning they can have items changed, removed, or added.\nAdding Without using a method, you can add key-value pairs to dictionaries by using the following syntax:\ndict[key] = value We will look at how this works in practice by adding a key-value pair to our results_10k dictionary:\nresults_10k[\u0026#39;Laurel\u0026#39;] = \u0026#39;59: 40\u0026#39; print(results_10k) Output: {'Elizabeth': '56: 09', 'Emily': '56: 23', 'Alison': '57: 36', 'Laurel': '59: 40'} The above output shows that the new 'Laurel': '59: 40' has been added to the dictionary. Because dictionaries may be unordered, this pair may occur anywhere in the dictionary output. If we use the results_10k dictionary later in our program file, it will include the additional key-value pair.\nModifying Existing Items This same syntax is used if you want to update an already existing value for a key. Let\u0026rsquo;s consider \u0026lsquo;Alison\u0026rsquo;, if we made a mistake in showing her time and needed to update it, we could simply type: results_10k['Alison']. Now if you were to print the results_10k dictionary, you would get the following result:\nresults_10k[\u0026#39;Alison\u0026#39;] = \u0026#39;55: 36\u0026#39; print(results_10k) Output: {'Elizabeth': '56: 09', 'Emily': '56: 23', 'Alison': '55: 36', 'Laurel': '59: 40'}\nDeleting Just as you can add key-value pairs and change values within the dictionary data type, you can also delete items within a dictionary.\nTo remove a key-value pair from a dictionary, we\u0026rsquo;ll use the following syntax:\ndel dict[key] Let\u0026rsquo;s take the results_10k dictionary and say that Laurel does not want her results to be displayed any more. To remove her time, we would do the following:\nresults_10k = {\u0026#39;Elizabeth\u0026#39;: \u0026#39;56: 09\u0026#39;, \u0026#39;Emily\u0026#39;: \u0026#39;56: 23\u0026#39;, \u0026#39;Alison\u0026#39;: \u0026#39;55: 36\u0026#39;, \u0026#39;Laurel\u0026#39;: \u0026#39;59: 40\u0026#39;} del results_10k[\u0026#39;Laurel\u0026#39;] print(results_10k) Output: {'Elizabeth': '56: 09', 'Emily': '56: 23', 'Alison': '55: 36'}\nThe line del results_10k['Laurel'] removes the key-value pair 'Laurel': '59: 40'\n Applying your knowledge  Create a dictionary called cool_ranking. Set the corresponding keys equal to their values: \u0026ldquo;Chandler\u0026rdquo; = 1, \u0026ldquo;Monica\u0026rdquo; = 10, \u0026ldquo;Ross\u0026rdquo; = 5, \u0026ldquo;Phoebe\u0026rdquo; = 2, \u0026ldquo;Joey\u0026rdquo; = 3, \u0026ldquo;Rachel\u0026rdquo; = 4. Use the cool_ranking for the following:  print out the ranking of \u0026lsquo;Monica\u0026rsquo; add the following key-value pair to the dictionary: \u0026lsquo;Janice\u0026rsquo; = 6. Print out the new dictionary print out all of the keys of the dictionary print out all of the values of the dictionary print out all of the key, value pairs of the dictionary in a list format. change \u0026lsquo;Monica\u0026rsquo; to have a ranking of 7. Print out the new dictionary. remove \u0026lsquo;Janice\u0026rsquo; from the dictionary. Print out the new dictionary.    Dictionaries Exercises Dictionaries Exercises\nNoneType Let\u0026rsquo;s create a dictionary to explain the NoneType.\ngroceries = { \u0026#34;ribeye steak\u0026#34;: 4, \u0026#34;russet potatoes\u0026#34;: \u0026#34;2 lbs\u0026#34;, \u0026#34;coleslaw\u0026#34;: None, \u0026#34;corn on the cob\u0026#34;: \u0026#34;4 ears\u0026#34;, \u0026#34;pork ribs\u0026#34;: \u0026#34;3 lbs\u0026#34; } We\u0026rsquo;ve never seen what \u0026quot;coleslaw\u0026quot; is set to. It says None and within the console, you can see the value NoneType for the key \u0026quot;coleslaw\u0026quot;.\nThis means we\u0026rsquo;ve told Python to specifically interpret the value for \u0026quot;coleslaw\u0026quot; as null, or empty. Python has a NoneType object it slaps on keys which technically don\u0026rsquo;t yet have a value. We have to make sure to tell it not to have value, by using the word None.\nPython will interpret the value of coleslaw as None until we intentionally set a value to coleslaw\n Conditional Statements\n"
},
{
	"uri": "/react/",
	"title": "React",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s React Offerings! "
},
{
	"uri": "/python/foundation/data-structures-labs/",
	"title": "Data Structure Labs",
	"tags": [],
	"description": "",
	"content": "Create a Python file called data_structures.py.\nLists Exercise Magic 8-Ball\nCreate a function called shake_ball that has no parameters. Inside the function, ask the user to ask a question about their future. Have your program return a random response of either: Yes definitely, As I see it, yes, Ask again later, Cannot predict now, Don't count on it, Very doubtful, and 4 other responses.\nCall (invoke) the function like shown below:\nprint(shake_ball()) Example output:\n\u0026gt;\u0026gt;\u0026gt; Ask a question: Will I be a millionaire? Don\u0026#39;t count on it IMPORTANT: After completing this assignment, continue to the tuple reference page: Tuple Reference\nTuples Exercise Gymnast Scores\nCreate a function called gymnast_scores that does not have any parameters or return anything. A gymnast can earn a score between 1 and 5 from each judge; nothing lower, nothing higher. All scores are integer values; there are no decimal scores from a single judge. Store the possible scores a gymnast can earn from one judge in a tuple.\n Print out the sentence, \u0026ldquo;The lowest possible score is _ _ _, and the highest possible score is _ _ _.\u0026rdquo; Use the values from your tuple. (Do not hard code the values) Print out \u0026ldquo;A judge can give a gymnast _ points.\u0026rdquo;. Filling in the blank with a random value from the tuple. (Do not hard code the value)  Call (invoke) the function like shown below:\ngymnast_scores() Example output:\nThe lowest possible score is 1, and the highest possible score is 5. A judge can give a gymnast 3 points. IMPORTANT: After completing this assignment, continue to the sets reference page: Set Reference\nSets Exercises Remove Duplicates\nCreate a function called remove_duplicates that takes in an iterable as a parameter and returns a set without any duplicates.\nCall (invoke) the function like the example shown below:\nprint(remove_duplicates(\u0026#39;MISSISSIPPI\u0026#39;)) Example output:\n{\u0026#39;M\u0026#39;, \u0026#39;P\u0026#39;, \u0026#39;S\u0026#39;, \u0026#39;I\u0026#39;}  Finding Vowels\nCreate a function called finding_vowels that takes in a string and returns True if there are any vowels in the word and False if there are not any vowels.\nCall (invoke) the function like the example shown below:\nprint(finding_vowels(\u0026#39;mississippi\u0026#39;)) Example output:\nTrue IMPORTANT: After completing this assignment, continue to the dictionaries reference page: Dictionary Reference\nDictionaries Exercises Polling friends\nCreate a function called polling_friends that does not take in any parameters. In the function, create a dictionary called fav_animals where each key is a person\u0026rsquo;s name, and each value is that person\u0026rsquo;s response to the question \u0026ldquo;What is your favorite animal?\u0026rdquo;. You are going ask your two friends \u0026ldquo;Miranda\u0026rdquo; and \u0026ldquo;Gordo\u0026rdquo;. (Use user input to get their favorite animal). Store two responses in your dictionary. Return the dictionary once you are done!\nCall (invoke) the function like shown below:\nprint(polling_friends()) Example Output:\n\u0026gt;\u0026gt;\u0026gt;Gordo, what is your favorite animal? llama \u0026gt;\u0026gt;\u0026gt;Miranda, what is your favorite animal? sloth {\u0026#39;Gordo\u0026#39;: \u0026#39;llama\u0026#39;, \u0026#39;Miranda\u0026#39;: \u0026#39;sloth\u0026#39;}  Birthday Month\nCreate a function called birthday_month that takes in two parameters, current (representing the current month) and birthday (representing the user\u0026rsquo;s birthday month) and returns the difference of the two months.\n Create a dictionary where each key is a month, and each value is the corresponding number for each month. ** months = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6, 'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12} Find the numerical value of current using the dictionary and store this is a variable called curr_month_num Find the numerical value of birthday using the dictionary and store this is a variable called birth_month_num Return the difference of the two months.  Call (invoke) the function like the example shown below:\nprint(birthday_month(\u0026#39;June\u0026#39;, \u0026#39;December\u0026#39;)) Example Output:\n6  Birthday Month Bonus: calculate how many months in the future their birthday month is without loops or conditionals.  Examples:  If the current month is May and their birth month is August, you should return 3. If the current month is May and their birth month is February, you should return 9. If the current month is May and their birth month is May, you should return 0. (We are not concerned about days, just months)      Continue to NoneType Lesson\n"
},
{
	"uri": "/software-eng-essentials/",
	"title": "Software Engineering Essentials",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy\u0026rsquo;s Software Engineering Essentials! "
},
{
	"uri": "/web-essentials/webmastery-foundations/additional/",
	"title": "Additional material",
	"tags": [],
	"description": "",
	"content": "Additional Material for Web Essentials "
},
{
	"uri": "/javascript/foundations/async-execution-and-callbacks/",
	"title": "Asynchronous Execution and Callbacks",
	"tags": [],
	"description": "",
	"content": "Learn about asynchronous operations in JavaScript.\nAsynchronous Operations  JavaScript is a single-threaded programming language. This means only one thing can happen at a time. But I/O operations can take a long time (to a computer a few milliseconds is a long time). That\u0026rsquo;s where asynchronous JavaScript comes into play. Using asynchronous JavaScript long I/O operations can execute without blocking the main thread.  What is Asynchronous Execution Typically the statements in a block of code run from top to bottom:\nlet x = 3; let y = 5; let z = x + y; console.log(z); This is easy to understand. But what about this code:\ngetDataFromServer() { callServer(function callback(data) { const z = data[0] + data[1]; console.log(z); // this happens last  }); } getDataFromServer(); console.log(\u0026#39;we keep going\u0026#39;); // this happens before the `console.log(z)` above  Here we have a call to callServer that takes a callback function. We don\u0026rsquo;t know how long the callServer function will take but it runs asynchronously because it is doing a network request. This allows the code to keep going. When the response returns from the server, the callback is executed.  Here is another example where we use setTimeout to delay the execution of a function (for demo purposes):\nconst slowAdder = function (a, b, callback) { setTimeout(function() { callback(a + b); }, 1000); }; slowAdder(1, 2, console.log); console.log(\u0026#39;Hello\u0026#39;); slowAdder(3, 4, console.log); console.log(\u0026#39;Goodbye\u0026#39;); The expected output is:\nHello Goodbye 3 7 Which shows that the JavaScript program keeps executing the synchronous code while the asynchronous code is waiting.\nThe Problem with Callbacks  Sometimes we have an asynchronous operation that depends on the result of another asynchronous operation. When using callbacks, this results in nested callbacks, which can become hard to read and maintain.  Example:\nfunction calculateSquare(number, callback) { setTimeout(function() { if (typeof number !== \u0026#34;number\u0026#34;) { callback(new Error(\u0026#34;Argument of type number is expected\u0026#34;)); return; } const result = number * number; callback(null, result); }, 1000); } calculateSquare(2, function(error, first) { console.log(first); calculateSquare(first, function(error, second) { console.log(second); calculateSquare(second, function(error, third) { console.log(third); calculateSquare(third, function(error, fourth) { console.log(fourth); }); }); }); }); In our next lesson on Promises, we will see how we can fix this problem.\nSummary  JavaScript supports asynchronous operations that don\u0026rsquo;t block the main thread An asynchronous operation can take a callback function The callback function will be invoked when the asynchronous operation has received its data  "
},
{
	"uri": "/python/foundation/conditional-statements/",
	"title": "Conditional Statements",
	"tags": [],
	"description": "",
	"content": "Conditional Statements In life, we constantly have to make decisions based on current circumstances.\n If I have enough money in the bank, I will go to a fancy dinner tonight. If not, I will eat at home. If I do the correct secret hand shake at the door, I can get in the secret club. If not, I will go home. If it is not raining outside, I will go for a run. If it is, I will stay home.  There are cases when working on a program we want certain parts of a program to execute, but only if a certain conditions are met. With conditional statements, we can have code that sometimes runs and at other times does not run, depending on the conditions of the program at that time. By using conditional statements, program can determine whether certain conditions are being met and then be told what to do next.\nIf Statements An if statement helps with deciding whether a statement is true or false, and run code only in the case that the statement is true.\nIf Statement Set Up\nif condition is true: [do something] Notice that the [do something] section is indented. In conditional statements, the indentation tells the Python Interpreter which line(s) of code are executed if a statement is correct.\nChecking if someone guessed the correct number\nsecret_num = 10 guess = int(input(\u0026#34;Enter a secret number: \u0026#34;)) if guess == secret_num: print(\u0026#34;Yay! You won!\u0026#34;) With this code, we have the variable secret_num and are giving it the integer value of 10. A second variable called guess is created and is set to the value of an integer that the user types in. The if statement is used to check if the variable guess equals secret_num. If the user did guess the correct number, the program would print out Yay! You won!. If the user did not guess the correct number, nothing would be printed.\nExample of the user guessing correctly\n\u0026gt;\u0026gt;\u0026gt;Enter a secret number: 10 Yay! You won! In the above example, the user typed in 10, which is equivalent to the secret number. Because the values were equivalent, the code executed the print statement.\nExample of the user guessing incorrectly\n\u0026gt;\u0026gt;\u0026gt;Enter a secret number: 255 One common action for a person to do is to check to see if you have nay money in your bank account. If you have a negative amount (any amount less than zero), you should receive a warning of some kind. This could be done with the following code:\nbalance = 100 if balance \u0026lt; 0: print(\u0026#34;Balance is negative. Put funds in your account or you will be charged a penalty.\u0026#34;) The above code would not have any output because the balance is 100, which is greater than zero!\nIf the above code was changed to:\nbalance = -5 if balance \u0026lt; 0: print(\u0026#34;Balance is negative. Put funds in your account or you will be charged a penalty.\u0026#34;) The above code would output Balance is negative. Put funds in your account or you will be charged a penalty. because the balance is -5, which is less than zero!\nElse Statements An if statement by itself will only handle if the condition is True. It is very common that you would want to give a response if the condition is true or it is false. In the bank example, we might also want to give a response if the user has a balance in their account. This can be done with an else statement. An else statement is the \u0026ldquo;otherwise\u0026rdquo; statement, taking care of if the original if condition is false.\nelse Statement Set Up\nif condition1: [do 1st option] else: [do 2nd option] balance = 25 if balance \u0026lt; 0: print(\u0026#34;Balance is negative. Put funds in your account or you will be charged a penalty.\u0026#34;) else: print(\u0026#34;Balance is positive.\u0026#34;) The output is Balance is positive because the balance is still 25, which is above zero.\nIf the above output was changed:\nbalance = -33 if balance \u0026lt; 0: print(\u0026#34;Balance is negative. Put funds in your account or you will be charged a penalty.\u0026#34;) else: print(\u0026#34;Balance is positive.\u0026#34;) The output is Balance is negative. Put funds in your account or you will be charged a penalty. because the balance is -33, which is below zero.\nElse If Statements So far, we have only checked to see if one condition is True or False. Usually a program has many different conditions to consider. To consider other conditions, you use an else if statement, which in Python is written as elif. The elif looks like the if statement and will evaluate another condition.\nelif Set Up\nif condition1: [do 1st option] elif condition2: [do 2nd option] else: [do 3rd option] Back to the bank account example, we may want to consider three possible situations: *If the Balance is negative. Put funds in your account or you will be charged a penalty. *If the balance is equal to zero *If the balance is positive\nIn Python, this would be written as:\nif balance \u0026lt; 0: print(\u0026#34;Balance is negative. Put funds in your account or you will be charged a penalty.\u0026#34;) elif balance == 0: print(\u0026#34;Balance is equal to zero, add funds soon.\u0026#34;) else: print(\u0026#34;Balance is positive.\u0026#34;) There are three possible outputs can now occur:\n  If the variable balance is equal to 0, we will receive the output from the elif statement (Balance is equal to zero, add funds soon.)\n  If the variable balance is set to a positive number, we will receive the output from the else statement (Balance is positive.)\n  If the variable balance is set to a negative number we will receive the output from the if statement (Balance is negative. Put funds in your account or you will be charged a penalty)\n  You can have multiple elif statements in the same group, allowing for a program to choose between 2+ conditions. For example, with the Orange Academy classes, based on your knowledge of particular topics you can take specific courses. It would be helpful to know based on certain requirements what classes you qualify for. Different qualifiers include knowledge in Git and Python. Each of these abilities can be rated on a 1 to 3 scale, 1 representing \u0026ldquo;No knowledge at all\u0026rdquo; and 3 representing \u0026ldquo;Expert\u0026rdquo;. It would be helpful to be able to type in your abilities and see what courses are appropriate for you.\nif git_skill == 1 and python_skill == 1: print(\u0026#34;Start off with Git Foundation\u0026#34;) elif git_skill \u0026gt;= 2 and python_skill == 1: print(\u0026#34;Start off with Python Foundation\u0026#34;) elif git_skill == 2 and python_skill == 2: print(\u0026#34;Start off with either Python Pillars or Git Pillars\u0026#34;) elif git_skill == 3 and python_skill == 2: print(\u0026#34;Start off with Python Capstone\u0026#34;) else: print(\u0026#34;Git Capstone or Python Capstone\u0026#34;) There are five paths defined in the above example.\n  If the user has the git_skill level of a 1 and a python_skill level of a 1, we will receive the output from the if statement. (Start off with Git Foundation)\n  If the user has the git_skill level of a 2 or higher and a python_skill level of a 1, we will receive the output from the first elif statement. (Start off with the Python Foundation)\n  If the user has the git_skill level of a 2 and a python_skill level of a 2, we will receive the output from the second elif statement. (Start off with either Python Pillars or Git Pillars)\n  If the user has the git_skill level of a 3 and a python_skill level of a 2, we will receive the output from the third elif statement. (Start off with the Python Capstone)\n  If the user has any other combination (like a git_skill level of 3 and python_skill level of 3), we will receive the output from the else statement. (Git Capstone or Python Capstone)\n  main Although in Python you can call the function at the bottom of your program and it will run (as we have done in the examples above), many programming languages (like C++ and Java) require a main function in order to execute. Including a main() function, though not required, can structure our Python programs in a logical way that puts the most important components of the program into one function. It can also make our programs easier for non-Python programmers to read.\nWe\u0026rsquo;ll start with adding a main() function to the hello() example. We will include a print in the main() to let us know that we\u0026rsquo;re in the main() function. Additionally, let\u0026rsquo;s call the hello() function within the main() function.\ndef hello(): print(\u0026#34;Hello, World!\u0026#34;) def main(): print(\u0026#34;This is the main function\u0026#34;) hello() main() Output:\nThis is the main function. Hello, world! Because we called the hello() function within main() and then only called main() to run, the Hello, World! text printed only once, after the string that told us we were in the main function.\nNext we’re going to be working with multiple functions, so it is worth reviewing the variable scope of global and local variables. If you define a variable within a function block, you’ll only be able to use that variable within that function. If you would like to use variables across functions it may be better to declare a global variable.\nIn Python, '__main__' is the name of the scope where top-level code will execute. When a program is run from standard input, a script, or from an interactive prompt, its __name__ is set equal to '__main__'.\nBecause of this, these is a convention to use the following construction:\nif __name__ == \u0026#39;__main__\u0026#39;: ## Code to run when this is the main program here This lets program files be used either:\n as the main program and run what follows the if statement as a module and not run what follows the if statement  Let’s expand on our program above. In this program we’ll declare a global variable and modify our original names() function so that the instructions are in two discrete functions.\nThe first function, has_vowel() will check to see if the name string contains a vowel.\nThe second function print_letters() will print each letter of the name string.\n## Declare global variable name for use in all functions name = input(\u0026#39;Enter your name: \u0026#39;) ## Define function to check if name contains a vowel def has_vowel(): if set(\u0026#39;aeiou\u0026#39;).intersection(name.lower()): print(\u0026#39;Your name contains a vowel.\u0026#39;) else: print(\u0026#39;Your name does not contain a vowel.\u0026#39;) ## Iterate over letters in name string def print_letters(): for letter in name: print(letter) ## Define main method that calls other functions def main(): has_vowel() print_letters() ## Execute main() function if __name__ == \u0026#39;__main__\u0026#39;: main() The output from this file will only occur if the current file is the main file being run.\nConditional Statements Exercises\n"
},
{
	"uri": "/golang/foundations/gomods/",
	"title": "Go Modules Deep Dive",
	"tags": [],
	"description": "",
	"content": "Learning Objectives  Converting to GOMODs from GOPATH mode Getting dependencies Clean up the cache Versioning dependencies Creating a release version  Go Module mode -\u0026gt; GOPATH mode To convert a project from GOPATH to GOMODs mode, do the following:\n Upgrade your local version of golang to at least 1.11. Set your local environment variable GO111MODULE=on or to auto. Create a go.mod file or perform a go mod init x where x is the remote path to your project, i.e. github.homedepot.com/commons/tax where commons is the org and tax is the repository name. Add external dependencies to the go.mod file.  Modules and go get NOTE: If you are adding a new dependency or updating dependencies with go get -u, there is no corresponding entry in go.sum.\nChanges to go get -u command in version 1.13:\n go get -u (without any arguments) now only upgrades the direct and indirect dependencies of your current package, and no longer examines your entire module. go get -u ./\u0026hellip; from your module root upgrades all the direct and indirect dependencies of your module, and now excludes test dependencies. go get -u -t ./\u0026hellip; is similar, but also upgrades test dependencies. go get no longer supports -m (because it would have largely overlapped with go get -d due to other changes; you can usually replace go get -m foo with go get -d foo).  Documentation on go get\nDeep Dependency When a package requires additional dependencies, the go.mod file will not explicitly display those additional package dependencies.\ngo list -m all Displays all final versions that will be used in a build for all direct and indirect dependencies\ngo list -u -m all Displays all available minor and patch upgrades for all direct and indirect dependencies\nAs an illustration: if rsc.io/quote v1.5.2 is added to main.go, go modules will automatically add the following to the go.mod file upon build:\nrequire rsc.io/quote v1.5.2 If go list -m all is run, it shows all the dependencies that are actually downloaded.\ngolang.org/x/text v0.0.0-20170915032832-14c0d48ead0c rsc.io/quote v1.5.2 rsc.io/sampler v1.3.0 Cleanup the cache   Clean up Go will cache each version of the requested dependencies.\nIn order to clean up this cache of versions no longer in use, run the command go clean.\nThe go command builds most objects in a temporary directory, so go clean is mainly concerned with object files left by other tools or by manual invocations of go build.\nTidy Up go mod tidy when executed, will check to see if dependencies are no longer being used in the source code and remove them from the cache, go.sum, and the go.mod file.\nVersioning with GOMOD Go Modules allows us to control which versions of dependencies are used.\n  To automatically move to a previous version of the github.homedepot.com/ldap/salutations package, perform a go get specifying the requested version and rebuild.\n$ go get github.com/brianvoe/gofakeit@v3.18.0 $ go build The go.mod file will automatically update to the below:\nmodule github.homedepot.com/ldap/salutations require github.com/brianvoe/gofakeit v3.18.0 Updating Modules go get -u=patch will update all direct and indirect dependencies to latest minor or patch upgrades (pre-releases are ignored)\nRunning go get -u=patch on the github.homedepot.com/ldap/salutations module example gives the following go.mod file.\nmodule salutations require ( rsc.io/quote v1.5.2 rsc.io/sampler v1.3.1 // indirect ) Directives The go.mod file has four available directives: module, require, replace, and exclude. So far we\u0026rsquo;ve seen module and require.\n require is used to require dependencies module provides a name for the module exclude lists versions of dependencies not to download. This can be most helpful when two dependency versions are not compatible replace allows the main module to replace a dependency package with a path to a remote or local package  replace directive replace allows the main module to replace a dependency package with a path to a remote or local package. A replace directive must have a matching require statement.\nSay you are using a module called github.homedepot.com/ldap/test.\nIn this scenario, you do not want to use the remote version but the local copy you have stored at /Users/ldap/Documents/test. To use the local copy, use the replace directive to point to the local copy along with a corresponding require directive.\nrequire github.homedepot.com/ldap/test v0.0.0 replace github.homedepot.com/ldap/test =\u0026gt; /Users/ldap/Documents/test A version number is allowed on the left hand side of a replace statement, if only a specific version should be replaced. This could come in handy if a dependency version comes out with a bug.\nA previous version of a dependency could be forked locally, fixed and used as a temporary band-aid while the dependency fixes their code.\nAnother, more happy use case of replace is if you want to fork a repo and play around with the repository.\nPreparing for a Release Three things to keep in mind before tagging a release version:\n go mod tidy Clean up any unused dependencies. go test all Run all tests for your module, direct, and indirect dependencies. Ensure your go.sum file is included in your code versioning commit.  Conclusion GOMOD mode allows us to develop outside the GOPATH, provides versioning and clean documentation on dependencies. Go Modules mode became default in version 1.12.\nLab Go to Go Modules Lab and follow the instructions in the README.md.\nAdditional Resources   Go Wiki on Go 1.11 Modules\n  Go Wiki on Modules in 2019\n  Go Wiki on Using Modules\n  "
},
{
	"uri": "/react/pillars/testing/react-testing-library/rtl-cheat-sheet/",
	"title": "RTL Cheat Sheet",
	"tags": [],
	"description": "",
	"content": "This Cheatsheet was taken from RTL Cheatsheet (Printable PDF).\n For a more detailed cheatsheet, see: RTL Cheatsheet.\n  Figure 1. RTL Cheat Sheet  "
},
{
	"uri": "/python/foundation/conditional-statements-labs/",
	"title": "Conditional Statements Labs",
	"tags": [],
	"description": "",
	"content": "Applying your knowledge Run the below script and run through the exercise a couple of times with a partner to understand it.\nprint(\u0026#34;You enter a dark room with two doors. Do you go through door #1 or door #2?\u0026#34;) door = input(\u0026#34;\u0026gt; \u0026#34;) if door == \u0026#34;1\u0026#34;: print(\u0026#34;There\u0026#39;s a giant bear here eating a cheese cake. What do you do?\u0026#34;) print(\u0026#34;1. Take the cake.\u0026#34;) print(\u0026#34;2. Scream at the bear.\u0026#34;) bear = input(\u0026#34;\u0026gt; \u0026#34;) if bear == \u0026#34;1\u0026#34;: print(\u0026#34;The bear eats your face off. Good job!\u0026#34;) elif bear == \u0026#34;2\u0026#34;: print(\u0026#34;The bear eats your legs off. Good job!\u0026#34;) else: print(\u0026#34;Well, doing {} is probably better. Bear runs away.\u0026#34;.format(bear)) elif door == \u0026#34;2\u0026#34;: print(\u0026#34;You stare into the endless abyss at Cthuhlu\u0026#39;s retina.\u0026#34;) print(\u0026#34;1. Blueberries.\u0026#34;) print(\u0026#34;2. Yellow jacket clothespins.\u0026#34;) print(\u0026#34;3. Understanding revolvers yelling melodies.\u0026#34;) insanity = input(\u0026#34;\u0026gt; \u0026#34;) if insanity == \u0026#34;1\u0026#34; or insanity == \u0026#34;2\u0026#34;: print(\u0026#34;Your body survives powered by a mind of jello. Good job!\u0026#34;) else: print(\u0026#34;The insanity rots your eyes into a pool of muck. Good job!\u0026#34;) else: print(\u0026#34;You stumble around and fall on a knife and die. Good job!\u0026#34;) Conditional Statements Exercise In pairs, write another elif section of the story with your own storyline. Run it and make sure there are no errors.\nGo To Loops Lesson\n"
},
{
	"uri": "/javascript/foundations/promises/",
	"title": "Promises",
	"tags": [],
	"description": "",
	"content": "An introduction to JavaScript promises.\nWhat Are Promises? Promises are objects that:\n have state, the state being one of the following:  PENDING: we are still waiting for the data RESOLVED: we have successfully received the data REJECTED: an error has occurred   manage callbacks:  resolve - the success callback reject - the error callback   can be chained together  Promises have a then method that takes a callback used to process the data once it is available. Promises have a catch method that takes a callback used to process any errors that might have occurred.    A First Look Here is a simple example of using a promise:\n// a promise that resolves after 3 seconds const p = new Promise((resolve, reject) =\u0026gt; { // create a promise using the Promise constructor function  setTimeout(() =\u0026gt; resolve(\u0026#39;this is some data\u0026#39;), 3000); // call `resolve` when the data is ready }); p.then(data =\u0026gt; { // `.then` is executed when the promise is resolved  console.log(data); }).catch(error =\u0026gt; { // `.catch` is executed if the promise is rejected  console.log(error); }); resolve and reject vs. then and catch  resolve and reject are used to report the data or error. then and catch are used to handle the data or error. This is a separation of concerns pattern! Often the resolve and reject are hidden in an implementation library. The then and resolve callbacks are what we code as part of our business logic (what we want to do with the data or error).  How Do I Create A Promise?  Usually you don\u0026rsquo;t not need to create your own promises. This is because your code will call into a library function that returns a promise to you. Then you will just use .then and .catch to handle the resolved or rejected promise. When you do need to create a promise, use the Promise constructor function. This function takes a single argument, a callback function with two parameters, resolve and reject. The callback does something interesting such as calling an async operation, and then calls resolve if everything worked, otherwise it calls reject. It\u0026rsquo;s customary, but not required, to reject with an Error object.  Here is the Promise creation pattern:\nPromise Constructors const promise = new Promise((resolve, reject) =\u0026gt; { // Create a new Promise `constructor` function  // do a thing, possibly async, then...  if (/* everything turned out fine */) { resolve(\u0026#34;Stuff worked!\u0026#34;); // `resolve` if conditions are met  } else { reject(Error(\u0026#34;It broke\u0026#34;)); // `reject` if the conditions are not met  } }); Promise Chains One powerful feature of promises is how they can be chained together.\n// Don\u0026#39;t worry too much about the next few lines, we just need a slowAdder function to call. function slowAdder(a, b) { return new Promise((resolve, reject) =\u0026gt; { setTimeout(() =\u0026gt; resolve(a + b), 1000); }); } // This is how we can chain promises together: slowAdder(3, 5). then(first =\u0026gt; slowAdder(first, 10)). then(second =\u0026gt; slowAdder(second, 20)). then(third =\u0026gt; console.log(third)); // 38 (prints after 3 seconds) Using Promise.all  Promise.all allow us to execute multiple operations concurrently. This can greatly speed up the execution of our code. Once all promises have resolved, the data will be passed as an array to the .then function.  A few examples of where this pattern is beneficial include:\n fetching data from multiple endpoints multiple database queries merging data together from multiple sources  *Example:\nfunction slowAdder(a, b) { return new Promise((resolve, reject) =\u0026gt; { setTimeout(() =\u0026gt; resolve(a + b), 1000); }); } const promises = [slowAdder(1, 2), slowAdder(3, 4), slowAdder(5, 6)]; Promise.all(promises).then((data) =\u0026gt; { const sum = data.reduce((a, b) =\u0026gt; a + b, 0); console.log(sum); // 21 }); Error Handling  Promises make error handling simpler, especially when chaining promises together or using Promise.all  Example:\nfunction slowAdder(a, b) { return new Promise((resolve, reject) =\u0026gt; { setTimeout(() =\u0026gt; { if (typeof(a) !== \u0026#39;number\u0026#39;) { reject(new TypeError(`${a}is not a number.`)); // report an error  } else if (typeof(b) !== \u0026#39;number\u0026#39;) { reject(new TypeError(`${b}is not a number.`)); // report an error  } else { resolve(a + b); } }, 1000); }); } slowAdder(3, 5). then(first =\u0026gt; slowAdder(first, \u0026#39;banana\u0026#39;)). // we encounter an error here, due to `banana` not being a number  then(second =\u0026gt; slowAdder(second, 20)). // this line is never executed as `banana` caused an error  then(third =\u0026gt; console.log(third)) // this line is never executed as well  .catch(error =\u0026gt; console.log(\u0026#39;ERROR:\u0026#39;, error)); // the error handler  The expected output is: \u0026ldquo;ERROR: banana is not a number.\u0026rdquo;\nLab See instructions here.\nSummary  Promises are used to handle the asynchronous flow of JavaScript in a way that is more concise than callbacks. A Promise is an object that is in one of 3 states: Pending, Resolved, or Rejected. Promises can be chained together with .then() The return value from one promise is passed to the next function as an argument Errors can be handled with a .catch function  Additional Resources  JavaScript Promises: an Introduction Promises in Wicked Detail  "
},
{
	"uri": "/javascript/foundations/async-await/",
	"title": "Async / Await",
	"tags": [],
	"description": "",
	"content": "An introduction to Async/Await\nLearning Objectives  Understand how async / await simplifies asynchronous code Know when to use async / await Handle errors in async / await code with try / catch Refactor asynchronous code to read like synchronous code using async / await  The Problem  Promises improved our asynchronous code over callbacks, especially when performing multiple asynchronous operations with interdependencies. But Promises still require a lot of coding, such as adding the function expressions (callbacks) inside the .then() and .catch() blocks. Promises turned callback nesting into callback chaining, but we still have those callbacks.  The new JavaScript async / await Keywords  ES-2017 gives us a new way to deal with asynchronous execution. Instead of using callbacks or promises, we can now use the async and await keywords. async / await makes your asynchronous code almost as simple as your synchronous code  Let\u0026rsquo;s look at a Promise example and then how it looks with async / await:\nWith Promises:\nfunction slowAdder(a, b) { return new Promise((resolve, reject) =\u0026gt; { setTimeout(() =\u0026gt; resolve(a + b), 1000); }); } slowAdder(3, 5). then(first =\u0026gt; slowAdder(first, 10)). then(second =\u0026gt; slowAdder(second, 20)). then(third =\u0026gt; console.log(third)); // 38 (prints after 3 seconds) Now with async / await:\nfunction slowAdder(a, b) { return new Promise((resolve, reject) =\u0026gt; { setTimeout(() =\u0026gt; resolve(a + b), 1000); }); } async function run() { // an `async` function  const first = await slowAdder(3, 5); // `await`  const second = await slowAdder(first, 10); // `await`  const third = await slowAdder(second, 20); // `await`  console.log(third); // 38 (prints after 3 seconds) } run(); Here\u0026rsquo;s How It Works  async and await are simply promises in disguise. We use the async keyword to declare that a function contains await asynchronous operations. We can then use await expressions inside the async function to essentially block until the async operation completes.  NOTE: An await expression may only be used inside the block of an async function.\nLoop Example  In this example, we combine a for loop with async/await. A timer utility is blocking the program at determined intervals.  const clock = { seconds: 0, minutes: 0} const timer = (milliseconds) =\u0026gt; { // declare a `timer` utility which returns a \u0026#39;pending\u0026#39; promise.  return new Promise(resolve =\u0026gt; setTimeout(resolve, milliseconds)); } let move = async (clock) =\u0026gt; { // declare our `async` function.  for (let i = 1; i \u0026lt;= 10; i++) { clock.seconds = i; console.log(\u0026#34;Seconds: \u0026#34;, clock.seconds); await timer(1000); // calls `timer` and `await`s for the Promise to resolve.  } console.log(\u0026#34;This line is blocked until the for loop completes\u0026#34;); } move(clock); When Blocking Occurs This example shows how await blocks only inside the async function.\nfunction getAnswer() { return new Promise( (resolve, reject) =\u0026gt; { setTimeout(() =\u0026gt; resolve(42), 2000); }); } const getAnswerToEverything = async () =\u0026gt; { console.log(\u0026#39;getting the answer...\u0026#39;); // this happens first  const answer = await getAnswer(); console.log(`The answer is ${answer}.`); // this happens last }; getAnswerToEverything(); console.log(\u0026#39;We are done.\u0026#39;); // this happens second  Question: Why did \u0026ldquo;We are done.\u0026rdquo; get printed before the answer?\nAnswer: Because that line is outside of the async function.\nasync function getUserFollowers() { let user = await fetchJSON(\u0026#39;/users/me\u0026#39;); // get the user  let followerIDs = await fetchJSON(`/followers/${user.id}`); // get the followers  let promises = followerIDs.map((id) =\u0026gt; { // map over the followers to create an Array of promises  return fetchJSON(`/users/${id}`); }); let followers = await Promise.all(promises); // wait for ALL promises to be resolved  console.log(followers); } let promise = getUserFollowers(); Advantages of async / await  Concise and clean code Easier inter-promise dependencies - no more nesting to handle sequential dependencies between 3 or more promises. Better Error handling - we can use the classic try / catch blocks instead of the Promise specific .catch(err).  async error handling with try / catch async / await makes error handling easier. There are some best practices for how to handle errors inside of async functions:\n a try/catch inside an async function catches sync exceptions and rejected promises  Example:\nasync function getUserFollowers() { try { // Wrap our `async` code in a `try` block.  let user = await fetchJSON(\u0026#39;/users/me\u0026#39;); let followerIDs = await fetchJSON(`/followers/${user.id}`); let promises = followerIDs.map((id) =\u0026gt; { return fetchJSON(`/users/${id}`); }); let followers = await Promise.all(promises); console.log(followers); } catch (err) { // Any errors from the `try` block will be caught by `catch`  console.log(err); } } let promise = getUserFollowers();  a try/catch outside an async function only catches sync exceptions (not rejected promises) - so you still need to use .catch(err) { ... } to catch any async errors outside of the async functions.  Example\nasync function getUserFollowers() { let user = await fetchJSON(\u0026#39;/users/me\u0026#39;); let followerIDs = await fetchJSON(`/followers/${user.id}`); let promises = followerIDs.map((id) =\u0026gt; { return fetchJSON(`/users/${id}`); }); let followers = await Promise.all(promises); console.log(followers); } // try/catch outside of the async function try { let promise = getUserFollowers(); } catch (err) { console.log(err); }  a throw from inside an async function results in a rejected promise  Example\nasync function f() { throw new Error(\u0026#34;There\u0026#39;s a problem!\u0026#34;); } // Same as the code below  async function f() { await Promise.reject(new Error(\u0026#34;There\u0026#39;s a problem!\u0026#34;)); } Summary  Async operations require some form of a callback to handle the data once it is available. Callbacks can be difficult to work with:  sequential execution ⇒ leads to callback hell parallel execution ⇒ just plain difficult to code   Promises:  manage the callbacks for you provide objects that manage the status of the async operation make it easier to combine multiple async operations for either concurrent or sequential execution make it easier to handle errors from async operations are widely used on both the client and server side of JavaScript development   Async/Await  are syntactic sugar around promises allows you to write code in a sequential format but code may run concurrently or sequentially depending on where you put the await keyword use traditional try/catch for error handling    Lab See instructions here.\nAdditional Resources  http://rossboucher.com/await/#/[Nice Presentation on Async/Await] https://hackernoon.com/6-reasons-why-javascripts-async-await-blows-promises-away-tutorial-c7ec10518dd9[6 Reasons Why JavaScript’s Async/Await Blows Promises Away]  "
},
{
	"uri": "/python/foundation/loops/",
	"title": "Loops",
	"tags": [],
	"description": "",
	"content": "Loop Introduction From what we have learned so far, to print all of the values from a list called numbers we would have to do something like the following:\nnumbers = [10, 5, 2, 7] print(numbers[0]) print(numbers[1]) print(numbers[2]) print(numbers[3]) That is a lot of lines! We should not ever have to repeat the same action over and over again. This is where loops come in to play.\nFor loops For loops are used to repeat the same action a known number of times. A for loop can help with printing out all the values of any iterable. An iterable is an item that is capable of returning its members one at a time, such as a list, tuple, or string. Indentation is very important! Indentation tells the Python interpreter what belongs together. In the loops case, it tells the Python Interpreter which line(s) to repeat.\nSet Up In Python, for loops are constructed like so:\nfor [iterating variable] in [iterable]: [do something] iterating variable : the temporary name of the current element. This can be called any valid variable. It\u0026rsquo;s best practice not to name this the same name as another existing variable.\niterable : the iterable that you are looping through it\u0026rsquo;s elements\ndo something : any action that you are wanting to repeat\nExample 1: For loop going through a list, printing each item on the same line\nfor i in [10, 5, 2, 7]: print(i, end = \u0026#34; \u0026#34;) Output: 10 5 2 7\ni represents the iterating variable and holds the value of the element that is currently being used. It will be assigned to each element in turn for each iteration through the loop. An iteration is what number time you have repeated the action in the loop.\nReminder: end = \u0026quot; \u0026quot; prints all of the numbers on the same line with a space in between.\nExample 2: For loop printing the numbers 1, 2, 3, 4 each on the same line\nfor x in [1, 2, 3, 4]: print(x, end = \u0026#34; \u0026#34;) Output: 1 2 3 4\nExample 3: For loop going through a list called numbers, printing each item on the same line\nnumbers = [20, 30, 40, 50] for k in numbers: print(k, end = \u0026#34; \u0026#34;) Output: 20 30 40 50\nExample 4: For loop going through a string called name, printing each character on the same line\nname = \u0026#34;Betty\u0026#34; for w in name: print(w, end = \u0026#34; \u0026#34;) Output: B e t t y\nExample 2 leads to a need for a new function because counting from one number to the next is a very common need in development. What if you wanted to print out the numbers 1 through 100? If we did it the way shown above, you would have to physically type 100 numbers and commas! This is where range can help us out.\nRange Range is a handy function that creates lists in the following format:\nrange([start,] stop [,step]) The above square brackets, in this case, are used to mean \u0026ldquo;This is optional\u0026rdquo;. When both step and stop are not specified, the list will start at 0, step by 1\u0026rsquo;s, and go up to but not including stop. When start and stop are specified, the list starts at start, goes up by 1\u0026rsquo;s, and up to but not including stop. When all three values are specified, the list will start at start, go up by step, and go up to but not including stop. Below are some examples showing different uses for range.\nExample 1: Using just stop\nrange(4) The list generated above would be [0, 1, 2, 3]\nExample 2: Using just start and stop\nrange(1, 4) The list generated above would be [1, 2, 3]\nExample 3: Using start, stop, and step\nrange(1, 10, 2) The list generated above would be [1, 3, 5, 7, 9]\n[big red]For Loops with Range\nIf we combine the two concepts of for loops and range together, we can do things way more efficiently!\nExample 1: For loops using Range\nfor i in range(2, 10, 3): print(i, end = \u0026#34; \u0026#34;) Output: 2 5 8\nExample 2: For loops using Range as a counter\n## Say you wanted to repeat the word \u0026#34;OM\u0026#34; 5 times for i in range(5): print(\u0026#34;OM\u0026#34;, end = \u0026#34; \u0026#34;) Output: OM OM OM OM OM\nFor Loops using Operations There is often a need for the same operation to be done on or with every item in a list or tuple. For loops allow you to this:\nExample 1: Squaring every element in a list\nprices = [12, 7, 9, 10] for i in prices: print(i ** 2, end = \u0026#34; \u0026#34;) Output: 144 49 81 100\nExample 2: Finding the total of a list\nprices = [12, 7, 9, 10] total = 0 for i in prices: total += i print(total) Output: 38\nExample 2 is a little different than what we have seen before. Every iteration, we added on the current element in the list to it.\n The first iteration added the first item (12) in the list to total, change total\u0026rsquo;s value to 12. The second iteration added the second item (7) in the list to total, change total\u0026rsquo;s value to 19. The third iteration added the third item (9) in the list to total, change total\u0026rsquo;s value to 28. The fourth and final iteration added the fourth item (10) in the list to total, change total\u0026rsquo;s value to 38.  enumerate So far, we have just wanted to either loop through a list OR use range to count. enumerate adds a counter to an iterable and returns it.\nenumerate Set Up\nenumerate(iterable, start=0)  iterable: a sequence, an iterator, or objects that supports iteration start: (optional) starts counting from this number. If start is not provided, the count will start at 0.  enumerate Examples\ngrocery = [\u0026#39;bread\u0026#39;, \u0026#39;milk\u0026#39;, \u0026#39;butter\u0026#39;] for item in enumerate(grocery): print(item) print(\u0026#39;\\n\u0026#39;) for count, item in enumerate(grocery): print(count, item) for count, item in enumerate(grocery, 100): print(count, item) Output:\n(0, \u0026#39;bread\u0026#39;) (1, \u0026#39;milk\u0026#39;) (2, \u0026#39;butter\u0026#39;) 0 bread 1 milk 2 butter 100 bread 101 milk 102 butter Applying your knowledge  Create a for loop that prints off the numbers 89, 41, 73, and 90 - each on their own line Create a for loop that prints off the numbers 5 up-to but not including 15 Create a for loop that prints off the numbers 100 to 200 by 10\u0026rsquo;s Create a for loop that prints off the numbers from 80 to 32 by 8\u0026rsquo;s Create a for loop that prints off the word Alright three times. Create a for loop that creates the following image:  * ** *** **** ***** 7. Using range, create a for loop that prints off the numbers 1, 4, 9, 16.\n8. Create a for loop that goes through a list and counts the number of even and odd numbers. Use the following list as an example to work with: numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9]\nOutput:\nEven numbers: 4 Odd numbers: 5 9. Change the following starter code to choose a random number between 1 and 6 100 times and display it on the histogram:\nimport matplotlib.pyplot as plt import random a = [] ## create an empty list for roll in range(5): x = random.choice([1, 3, 10]) ## choose a random choice of either 1, 3 or 10 to a (the list) a += [x] plt.hist(a, range=(1, 10), align=\u0026#39;right\u0026#39;) ## options for aligning are \u0026#39;mid\u0026#39;, \u0026#39;left\u0026#39;, and \u0026#39;right\u0026#39; plt.show() Loops Exercises Loops Exercises\nWhile Loops While Loops are used when the same task needs to happen until a condition is met. The code that is in a while block will execute as long as the while statement evaluates to True. For example, when a user is typing in their password the login screen will remain up until the user types in the correct password. Who knows how many times they might type it in wrong! As opposed to for loops that execute a certain number of times, while loops are conditionally base, so you don\u0026rsquo;t need to know how many times to repeat the code going in.\nSet Up In Python, while loops are constructed like so:\nwhile [a condition is True]: [do something] a condition is True : a boolean statement that determines if you go into the loop or not.\ndo something : any action that you are wanting to repeat\nExample 1: While loop that repeats until the temperature of tea is at 112\ntemperature = 115 while (temperature \u0026gt; 112): print(temperature, end = \u0026#34;-\u0026#34;) temperature -= 1 print(\u0026#39;The tea is cool enough\u0026#39;) Output: 115-114-113-The tea is cool enough\nExample 2: While Loop that repeats the phrase \u0026ldquo;Waiting\u0026rdquo; until a user presses the x key\nx_input = input(\u0026#34;Enter the x key: \u0026#34;) while (x_input != \u0026#34;x\u0026#34;): print(\u0026#34;Waiting\u0026#34;) x_input = input(\u0026#34;Enter the x key: \u0026#34;) print(\u0026#34;Thank you for typing x!\u0026#34;) The output of Example 2 varies depending on that the user types in. Two example outputs are show below:\nExample 2 Output 1: User types in two incorrect inputs before typing in x.\nEnter the x key: hi Waiting Enter the x key: y Waiting Enter the x key: x Thank you for typing x! Example 2 Output 2: User types in x the first loop.\nEnter the x key: x Thank you for typing x! Common Mistakes Be VERY careful about infinite loops! This occurs when your condition would never return False. Two examples of this are shown below:\nwhile True: print(\u0026#34;Ah!\u0026#34;) while 5 == 5: print(\u0026#34;Forever looping!\u0026#34;) Both of these loops would go on forever!\nApplying your knowledge . Create a while loop that will count down from 10 to 1.\n. Asks the user to enter an integer that is greater than 0. The function will keep on asking the user for the number until it is valid.\n. Ask the user to enter two separate integers (The first number must be smaller than the second). Create a while loop that will count from the first number to the second.\n. Ask the user to respond by \u0026lsquo;Y\u0026rsquo;, \u0026lsquo;y\u0026rsquo;, \u0026lsquo;yes\u0026rsquo;, \u0026lsquo;YES\u0026rsquo; or \u0026lsquo;N\u0026rsquo;, \u0026lsquo;n\u0026rsquo;, \u0026lsquo;no\u0026rsquo;, \u0026lsquo;NO\u0026rsquo;. The function keeps on asking until the user enters the correct information.\nError handling with a while loop exercise Given this while loop, write a try/except statement. The input of the users guess can only be a whole number. Make sure the except throws an error (One exception total) for both floating point numbers and letters.\ncount = 0 while count \u0026lt; 5: guess = int(input(\u0026#34;Take a guess \u0026#34;)) count = count + 1 While Loops Exercises While Loops Exercises\n"
},
{
	"uri": "/python/foundation/file-manipulation/",
	"title": "File Manipulations",
	"tags": [],
	"description": "",
	"content": "File Systems Before talking about how to read and write to a file, we need to figure out direct the program to the location of the file. To locate a file, there are two different ways to do so: absolute vs. relative file paths.\nAbsolute File Paths Most file systems are hierarchical, forming a tree that begins with a root directory. An absolute filename specifies where the file is stored from the root.\n  In Windows, the root is typically indicated by the startup drive letter, such as C:\\\n  In Mac and Linux systems, the root is typically indicated by /\n  For example: the absolute file path of admin (in the green box below) is C:\\Users\\admin\nRelative File Paths Most operating systems and programming languages remember one location in the file system as your \u0026ldquo;present working directory\u0026rdquo;. A file can be described relative to that location: a relative file path.\nFor example: In the above picture, the relative file path of nice.jpg from admin is ./Student login/Desktop/nice.jpg. The two dots at the beginning represent \u0026ldquo;go up one directory\u0026rdquo;.\nFile Permissions To open a file in Python, we first need some way to associate the file with a variable in Python. This process is called opening a file. First, Python needs to know where the file is located. Since we created our files within the same directory and we are using relative file paths, we only need to say the name of the file.\nWe will use Python\u0026rsquo;s open() function to open our files. The open() function requires the path the file (just the file name in our case) as the first argument. The function also allows from many other parameters. However, most important is the optional mode parameter.\nMode is an optional string that specifies the mode in which the file is opened. This mode you choose will depend on what you wish to do with the file. Here are some of our mode options: r, r+, w, w+, a, and a+.\n    r r+ w w+ a a+     read ✔ ✔  ✔  ✔   write  ✔ ✔ ✔ ✔ ✔   write after seek  ✔ ✔ ✔     create   ✔ ✔ ✔ ✔   truncate   ✔ ✔     position at start ✔ ✔ ✔ ✔     position at end     ✔ ✔    File Types Python is a great tool for processing data. It is likely that any program you write will involve reading, writing, or manipulating data. For this reason, it\u0026rsquo;s especially useful to know how to handle different file formats, which store different types of data.\nPython is super accommodating and can, with relative ease, handle a number of different file formats, including but not limited to the following:\n   File Type Description     txt Plain text file stores data that represents only characters (or strings) and excludes any structured metadata   CSV Comma-separated value file uses commas (or other delimiters) to structure stored data, allowing data to be saved in a table format   JSON JavaScript Object Notation is a simple and efficient format, making it one of the most commonly used formats to store and transfer data    txt Files Creating Before we can begin working in Python, we need to make sure we have a file to work with. To do this, create a new file in your project called days.txt.\nIn the new file, enter a few lines of text. In this example, list the days of the week:\nMonday Tuesday Wednesday Thursday Friday Saturday Sunday Make sure to save your file (Command \u0026gt; S)\nOpening Create a Python file called txt_manipulation.py.\nIn this example, we only want to read from the file, so we will use the 'r' mode. We will use the open() function to open the days.txt file and assign it to the variable days_file. We are going to use the with statement and have all lines of code that deal with the file inside of this statement. This ensures that the file is properly and safely opened and closed. The as operator creates a variable that is now pointing to the location of the file.\nwith open(\u0026#39;days.txt\u0026#39;, \u0026#39;r\u0026#39;) as days_file: After we have opened the file, we can then read from it.\nReading Since our file has been opened, we can now manipulate it (i.e. read from it) through the variable we assigned to it. Python provides three related operations for reading information from a file. We will show how to use all three operations as examples that you can try out to get an understanding of how they work.\nread()\n\u0026lt;file\u0026gt;.read() returns the entire contents of the file as a single string. (Remember to indent so you are inside of the with statement)\nprint(days_file.read()) Output:\nMonday Tuesday Wednesday Thursday Friday Saturday Sunday readline()\n\u0026lt;file\u0026gt;.readline() returns the next line of the file, returning the text up to and including the next newline character. More simply put, this operation will read a file line-by-line. (Remember to indent so you are inside of the with statement)\nprint(days_file.readline()) Output:\nMonday Therefore, once you read a line with the readline operation it will pass to the next line. So if you were to call this operation again, it would return the next line in the file, as shown. c\nprint(days_file.readline()) print(days_file.readline()) Output:\nMonday Tuesday There is an extra line after Monday due to \\n that is technically in the text file to start Tuesday on the next line. To show all of the lines of code in the file, you could use a loop and call the days_file.readline(), but there is a command that does this for you.\nreadlines()\n\u0026lt;file\u0026gt;.readlines() returns a list of the lines in the file, where each item of the list represents a single line.\nprint(days_file.readlines()) Output:\n[\u0026#39;Monday\\n\u0026#39;, \u0026#39;Tuesday\\n\u0026#39;, \u0026#39;Wednesday\\n\u0026#39;, \u0026#39;Thursday\\n\u0026#39;, \u0026#39;Friday\\n\u0026#39;, \u0026#39;Saturday\\n\u0026#39;, \u0026#39;Sunday\u0026#39;] Something to keep in mind when you are reading from files, once a file has been read using one of the read operations, it cannot be read again. For example, if you were to first run days_file.read() followed by days_file.readlines() the second operation would return an empty string. Therefore, anytime you wish to read from a file you will have to first open a new file variable. Now that we have read from a file, let\u0026rsquo;s learn how to write to a new file.\nModifying It is not easy to use open to edit in the middle of a file. To simulate this happening, we can alter the list that is returned from readlines() and eventually write it directly back to the file we read it from.\nFor example, if we wanted to add Yay! It's to the beginning of every line of the file we could loop through and add it to the string at each index, like:\nwith open(\u0026#39;days.txt\u0026#39;, \u0026#39;r\u0026#39;) as days_file: days = days_file.readlines() num_lines = len(days) for i in range(num_lines): days[i] = \u0026#34;Yay! It\u0026#39;s \u0026#34; + days[i] Writing We also need to store the days of the week in a string variable, which we\u0026rsquo;ll call days. So far we opened the file in read mode, read the file, and store the returned output from the read operation in our new variable days.\nWe state that we want to enter in write mode. Remember, this will truncate any text already in the file specified. That is fine for our purposes since we have stored the existing text in a list.\nwith open(\u0026#39;days.txt\u0026#39;, \u0026#39;w\u0026#39;) as new_days: Now we can place a single string into the new file with write(). (Remember to indent so you are inside of the with statement)\nnew_days.write(\u0026#34;Days of the Week\\n\u0026#34;) print(title) We can place a list of Strings into the new file with writelines(). (Remember to indent so you are inside of the with statement)\nnew_days.writelines(days) print(days) Full Code with open(\u0026#39;days.txt\u0026#39;, \u0026#39;r\u0026#39;) as days_file: days = days_file.readlines() num_lines = len(days) for i in range(num_lines): days[i] = \u0026#34;Yay! It\u0026#39;s \u0026#34; + days[i] title = \u0026#34;Days of the Week\\n\u0026#34; with open(\u0026#39;days.txt\u0026#39;, \u0026#39;w\u0026#39;) as new_days: new_days.write(title) new_days.writelines(days) Output:\nDays of the Week Monday Tuesday Wednesday Thursday Friday Saturday Sunday The values of days.txt should look like the following:\nDays of the Week Yay! It\u0026#39;s Monday Yay! It\u0026#39;s Tuesday Yay! It\u0026#39;s Wednesday Yay! It\u0026#39;s Thursday Yay! It\u0026#39;s Friday Yay! It\u0026#39;s Saturday Yay! It\u0026#39;s Sunday IMPORTANT: Go to txt Exercise\ncsv Files CSV stands for \u0026ldquo;comma-separated values\u0026rdquo;, and CSVs are simplified spreadsheets which are stored as plain text files, so it\u0026rsquo;s easy for Python to parse through and for us to manipulate them.\nCSV files are simple, lacking many of the features of an Excel spreadsheet. For example, CSV files don\u0026rsquo;t have types for their values \u0026ndash; everything is a string. The advantage of a CSV is simplicity.\n Create a new Python file called csv_manipulation.py Download this CSV: Addresses  Place it into your project.    Opening The first step to read CSV files in Python is to import the csv module. Since the csv module comes with Python when you download it, we don\u0026rsquo;t have to install it separately.\nimport csv We\u0026rsquo;ll also need to open the file and save it to memory for Python to be able to read.\nwith open(\u0026#39;addresses.csv\u0026#39;, \u0026#39;r\u0026#39;) as address_data: Reading We now have to read the file that has been opened by passing the variable address_data into method reader() which calls upon the csv module that we imported on the first line on this file. That is all set to a variable called read_address_data so that we can use that read material to list or manipulate. read_address_data is\nread_address_data = csv.reader(address_data) In order for Python to give us a neat list of our data for us to manipulate, cast the the read_address_data variable with list() and print it out.\nlist_address_data = list(read_address_data) This is is all of the contents of the csv file placed into a readable, mutable list.\nThe Reader object which we\u0026rsquo;re calling by using csv.reader() can only be looped over once per call. If there was an update to the csv file, we would need to call csv.reader() again. This helps split each row into it\u0026rsquo;s own list and every cell is an element in the row.\nAccessing Now that we have a nice list, we can access each line/cell. Similarly to accessing indexes of a list, we\u0026rsquo;re going to use the bracket notation to access the rows and columns of the CSV file. If we want to list out just the cell of the 2nd column from the 5th row, we\u0026rsquo;ll print this:\nprint(list_address_data[4][1]) Output:\nTyler The syntax is list_address_data[row][col]\n Since we can pull data out using indexes, we can also utilize a statement we learned previously to grab data more efficiently: the for loop. Now we can print out the rows and read them all easily within our project.\nNow we\u0026rsquo;ll start our for loop below the line that states list_address_data = list(read_address_data):\nfor i, row in enumerate(list_address_data): print(f\u0026#34;Row #: {i} {row}\u0026#34;) enumerate in the above print() statement helps us keep track of the row numbers and the current row values.\nModifying Now that the information is stored in a list, we are able to add or modify existing values.\nChanging row 2\u0026rsquo;s values\nlist_address_data[2] = [\u0026#39;Reese\u0026#39;, \u0026#39;Witherspoon\u0026#39;, \u0026#39;362 Main St\u0026#39;, \u0026#39;Austin\u0026#39;, \u0026#39;TX\u0026#39;, \u0026#39;78704\u0026#39;] Changing row 3, column 1\u0026rsquo;s value\nlist_address_data[3][0] = \u0026#39;Elizabeth\u0026#39; The above examples changed the list, not the csv file. In order to change the actual file, we would need to write the new information to the csv file.\nWriting We know how to read CSV files, now let\u0026rsquo;s write to one. We\u0026rsquo;ll use a similar syntax: csv.writer() on the same file.\nFirst, we must use the open() method with w mode: address_data = open('addresses.csv', 'w')\nThen, we can use the Writer object on our new variable, and specify that we\u0026rsquo;d like to write a new row with a new set of strings.\nwith open(\u0026#39;addresses.csv\u0026#39;, \u0026#39;w\u0026#39;) as address_data_file: write_address_data = csv.writer(address_data_file) Run your code. If we open up the csv file, addresses.csv, we will see that there is no longer any text inside the file.\n If the file specified does not exist, writer creates a new, empty file with the name specified. If the file specified exists, writer opens up a file and \u0026ldquo;erases\u0026rdquo; any existing text inside the file.  NOTE: It is not an issue that the text has been erased due to the fact we stored all of the text into the list list_address_data.\nTo write multiple rows, you would use writerows and pass in a list. In the following code, we are going to pass in the list, list_address_data. This will place all of the lines that were previously in the csv file after the above line.\nwrite_address_data.writerows(list_address_data) At this point, addresses.csv has all of the text that was originally in that file.\nWe can use the writerow() method to specify that we\u0026rsquo;d like to write to a single row to the end of the CSV file. Each value we place into writerow() will become its own cell in the output CSV file.\nwrite_address_data.writerow([\u0026#39;Alegra\u0026#39;, \u0026#39;Cole\u0026#39;, \u0026#39;1 Broadway Rd\u0026#39;, \u0026#39;New York City\u0026#39;, \u0026#39;NY\u0026#39;, 15432]) Full Code import csv with open(\u0026#39;addresses.csv\u0026#39;, \u0026#39;r\u0026#39;) as address_data: read_address_data = csv.reader(address_data) list_address_data = list(read_address_data) list_address_data[2] = [\u0026#39;Reese\u0026#39;, \u0026#39;Witherspoon\u0026#39;, \u0026#39;362 Main St\u0026#39;, \u0026#39;Austin\u0026#39;, \u0026#39;TX\u0026#39;, \u0026#39;78704\u0026#39;] list_address_data[3][0] = \u0026#39;Elizabeth\u0026#39; with open(\u0026#39;addresses.csv\u0026#39;, \u0026#39;w\u0026#39;) as address_data_file: write_address_data = csv.writer(address_data_file) write_address_data.writerows(list_address_data) write_address_data.writerow([\u0026#39;Alegra\u0026#39;, \u0026#39;Cole\u0026#39;, \u0026#39;1 Broadway Rd\u0026#39;, \u0026#39;New York City\u0026#39;, \u0026#39;NY\u0026#39;, 15432]) Dictionary Formatting When using csv files it is possible to return the data from the file as a dictionary where the keys are the header values and the values are the corresponding rows with them. To read in the information from addresses.csv and convert it to an ordered dictionary, you can do the following:\nimport csv with open(\u0026#39;addresses.csv\u0026#39;, \u0026#39;r\u0026#39;) as address_data: reader = csv.DictReader(address_data) Reading If you wanted to print out all of the last names in the csv file, you can now use the key Last Name.\nimport csv with open(\u0026#39;addresses.csv\u0026#39;, \u0026#39;r\u0026#39;) as address_data: reader = csv.DictReader(address_data) for row in reader: print(row[\u0026#39;Last Name\u0026#39;]) Output:\nDoe Witherspoon Repici Tyler Cole To get a list of all of the headers, call the reader object\u0026rsquo;s variable, fieldnames. (Make sure this is indented since you are using the reader object)\nheaders = reader.fieldnames Prints out all of the information in a csv file\nimport csv with open(\u0026#39;addresses.csv\u0026#39;, \u0026#39;r\u0026#39;) as address_data: reader = csv.DictReader(address_data) headers = reader.fieldnames addresses = list(reader) Each row is an OrderedDict. To convert an OrderedDict to a dictionary, you simply cast it to a dict. Since a csv file is essentially lists of dictionaries, we could cast each row to a dictionary and append it to a list.\nThe following adds each row (which is casted to a dictionary) of the reader object to a list\nimport csv with open(\u0026#39;addresses.csv\u0026#39;, \u0026#39;r\u0026#39;) as address_data: reader = csv.DictReader(address_data) headers = reader.fieldnames addresses = list(reader) Output if you were to print out the contents of addresses you would get:\n[{\u0026#39;First Name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;Last Name\u0026#39;: \u0026#39;Doe\u0026#39;, \u0026#39;Address Line\u0026#39;: \u0026#39;120 jefferson st.\u0026#39;, \u0026#39;City\u0026#39;: \u0026#39;Riverside\u0026#39;, \u0026#39;State\u0026#39;: \u0026#39; NJ\u0026#39;, \u0026#39;Zipcode\u0026#39;: \u0026#39;8075\u0026#39;}, {\u0026#39;First Name\u0026#39;: \u0026#39;Jack\u0026#39;, \u0026#39;Last Name\u0026#39;: \u0026#39;McGinnis\u0026#39;, \u0026#39;Address Line\u0026#39;: \u0026#39;220 hobo Av.\u0026#39;, \u0026#39;City\u0026#39;: \u0026#39;Phila\u0026#39;, \u0026#39;State\u0026#39;: \u0026#39; PA\u0026#39;, \u0026#39;Zipcode\u0026#39;: \u0026#39;9119\u0026#39;}, {\u0026#39;First Name\u0026#39;: \u0026#39;John Da Man\u0026#39;, \u0026#39;Last Name\u0026#39;: \u0026#39; Repici\u0026#39;, \u0026#39;Address Line\u0026#39;: \u0026#39; 120 Jefferson St.\u0026#39;, \u0026#39;City\u0026#39;: \u0026#39;Riverside\u0026#39;, \u0026#39;State\u0026#39;: \u0026#39; NJ\u0026#39;, \u0026#39;Zipcode\u0026#39;: \u0026#39;8075\u0026#39;}, {\u0026#39;First Name\u0026#39;: \u0026#39;Stephen\u0026#39;, \u0026#39;Last Name\u0026#39;: \u0026#39;Tyler\u0026#39;, \u0026#39;Address Line\u0026#39;: \u0026#39;7452 Terrace At the Plaza road\u0026#39;, \u0026#39;City\u0026#39;: \u0026#39;SomeTown\u0026#39;, \u0026#39;State\u0026#39;: \u0026#39;SD\u0026#39;, \u0026#39;Zipcode\u0026#39;: \u0026#39;91234\u0026#39;}] Modifying If you wanted to alter the dictionary to no longer include the Address Line, you could delete Address Line from each row in the list.\nimport csv with open(\u0026#39;addresses.csv\u0026#39;, \u0026#39;r\u0026#39;) as address_data: reader = csv.DictReader(address_data) headers = reader.fieldnames addresses = list(reader) for row in addresses: del row[\u0026#34;Address Line\u0026#34;] The contents of the list of dictionaries no longer contains the Address Line column.\nMake sure to delete Address Line from the headers list. (The reason for this will be seen in the next step)\nheaders.remove(\u0026#39;Address Line\u0026#39;) Writing A DictWriter object helps with writing the dictionary to a file. A DictWriter object requires the name of the opened file variable, and the fieldnames. fieldnames are the titles of each column, or the keys. We had already got a list of all of the headers and placed it in the headers list.\nwith open(\u0026#39;addresses.csv\u0026#39;, \u0026#39;w\u0026#39;) as address_data: writer = csv.DictWriter(address_data, fieldnames=headers) Call writer.writeheader() to add a row with the field names (as specified in the constructor) to the constructor.\nwriter.writeheader() Write each row by passing the list of dictionaries to the csv file with writer.writerows(addresses)\nwriter.writerows(addresses) Full Code import csv with open(\u0026#39;addresses.csv\u0026#39;, \u0026#39;r\u0026#39;) as address_data: reader = csv.DictReader(address_data) headers = reader.fieldnames addresses = list(reader) for row in addresses: del row[\u0026#34;Address Line\u0026#34;] headers.remove(\u0026#34;Address Line\u0026#34;) with open(\u0026#39;addresses_altered.csv\u0026#39;, \u0026#39;w\u0026#39;) as address_data: writer = csv.DictWriter(address_data, fieldnames=headers) writer.writeheader() writer.writerows(addresses) IMPORTANT: Go to csv Exercise\njson Files JSON (JavaScript Object Notation) is an easy to read, flexible text based format that can be used to store and communicate information to other products. It is mainly based on key:value pairs and is web and .NET friendly. There are many libraries and products that support JSON.\nJSON could be used to store information for a door schedule, or a parts list. A report can be created on the name, size and location of all the bitmaps in a model. JSON files are used in several other places and products. JSON is also easy to display on dynamic webpages.\nHere is an example of a JSON structure describing a medical office. As you will see in the example, the medical space includes 5 rooms, with square footage and pricing for each dedicated space.\n{ \u0026#34;reception\u0026#34;: { \u0026#34;room-number\u0026#34;: 100, \u0026#34;sq-ft\u0026#34;: 50, \u0026#34;price\u0026#34;: 75 }, \u0026#34;waiting\u0026#34;: { \u0026#34;room-number\u0026#34;: 101, \u0026#34;sq-ft\u0026#34;: 250, \u0026#34;price\u0026#34;: 75 }, \u0026#34;examination\u0026#34;: { \u0026#34;room-number\u0026#34;: 102, \u0026#34;sq-ft\u0026#34;: 125, \u0026#34;price\u0026#34;: 150 }, \u0026#34;on-call\u0026#34;: { \u0026#34;room-number\u0026#34;: 103, \u0026#34;sq-ft\u0026#34;: 125, \u0026#34;price\u0026#34;: 150 }, \u0026#34;office\u0026#34;: { \u0026#34;room-number\u0026#34;: 104, \u0026#34;sq-ft\u0026#34;: 150, \u0026#34;price\u0026#34;: 100 } }  Create a new Python file called json_manipulation.py Create a new file called medical.json  Opening The first step to read JSON files in Python is to import the json module. Since the json module comes with Python when you download it, we don\u0026rsquo;t have to install it separately.\nimport json We\u0026rsquo;ll also need to open the file and save it to a letter for Python to be able to read.\nwith open(\u0026#39;medical.json\u0026#39;, \u0026#39;r\u0026#39;) as medical_rooms: Reading To convert the information from the json file, you must use json.load. It reads the string from the file, parses the JSON data, populates and returns a Python dict with the data.\ndata = json.load(medical_rooms) If we wanted to see the entirety of the new dictionary print in a neat format you can use json.dumps. This takes in the dictionary you want to print and has an optional parameter to specify the number of characters you would like to use for the indent. There is a another optional parameter sort_keys that states if you want the keys to print in a sorted order.\npretty_output = json.dumps(data, indent=4) If you were to print pretty_output, you would get the following output:\n{ \u0026#34;examination\u0026#34;: { \u0026#34;price\u0026#34;: 150, \u0026#34;room-number\u0026#34;: 102, \u0026#34;sq-ft\u0026#34;: 125 }, \u0026#34;office\u0026#34;: { \u0026#34;price\u0026#34;: 100, \u0026#34;room-number\u0026#34;: 104, \u0026#34;sq-ft\u0026#34;: 150 }, \u0026#34;on-call\u0026#34;: { \u0026#34;price\u0026#34;: 150, \u0026#34;room-number\u0026#34;: 103, \u0026#34;sq-ft\u0026#34;: 125 }, \u0026#34;reception\u0026#34;: { \u0026#34;price\u0026#34;: 75, \u0026#34;room-number\u0026#34;: 100, \u0026#34;sq-ft\u0026#34;: 50 }, \u0026#34;waiting\u0026#34;: { \u0026#34;price\u0026#34;: 75, \u0026#34;room-number\u0026#34;: 101, \u0026#34;sq-ft\u0026#34;: 250 } } Accessing If you wanted to access all of the room names in the medical_rooms dictionary, you could use a for loop.\nfor room_name in data: print(room_name) Output:\nreception waiting examination on-call office If you wanted to print out the room names and the room numbers, you could use a loop, as shown below:\nfor room_name in data: print(f\u0026#34;{room_name} is in room {data[room_name][\u0026#39;room-number\u0026#39;]}\u0026#34;) Notice that [room_name] is not surrounded with quotes. This is because room_name is a looping variable that is created in the for loop, returning the name of the current room for each iteration.\nModifying Now that the json file contents have been placed in a dictionary, modifying the contents is identical to how you change a dictionary.\nSay that there is a deal on rooms that makes every room 50%. If you wanted to go through and change the value of every room to half off, you could do this as follows:\nfor room_name in data: data[room_name][\u0026#39;price\u0026#39;] = data[room_name][\u0026#39;price\u0026#39;] * 0.5 If you were to print out the contents of the dictionary, you would see the updated prices.\nWriting To write back the new information, you first need to open up the file in w mode.\nwith open(\u0026#39;medical.json\u0026#39;, \u0026#39;w\u0026#39;) as medical_rooms: Use json.dump to place the dictionary into the file. This method takes in the dictionary, filename to write to and optionally the number of indents to place.\njson.dump(data, medical_rooms, indent=4) Full Code import json with open(\u0026#39;medical.json\u0026#39;, \u0026#39;r\u0026#39;) as medical_rooms: data = json.load(medical_rooms) for room_name in data: data[room_name][\u0026#39;price\u0026#39;] = data[room_name][\u0026#39;price\u0026#39;] * 0.5 print(f\u0026#34;{data[room_name][\u0026#39;price\u0026#39;]}\u0026#34;) with open(\u0026#39;medical.json\u0026#39;, \u0026#39;w\u0026#39;) as medical_rooms: json.dump(data, medical_rooms, indent=4) Python and APIs When a company offers an Application Programming Interface\u0026rsquo;s(API) to their customers, it just means that they’ve built a set of dedicated URLs that return pure data responses — meaning the responses won’t contain the kind of presentational overhead that you would expect in a graphical user interface like a website.\n Example Scenario\nYour business’s website has a form used to sign clients up for appointments. You want to give your clients the ability to create a Google calendar event with the details for that appointment.\nAPI use: The idea is to have your website’s server talk directly to Google’s server with a request to create an event with the given details. Your server would then receive Google’s response, process it, and send back relevant information to the browser, such as a confirmation message to the user.\nAlternatively, your browser can often send an API request directly to Google’s server bypassing your server. To render the whole web page, your browser expects a response in HTML, which contains presentational code, while Google Calendar’s API call would just return the data — likely in a format like JSON.\n '\u0026rsquo;\u0026rsquo;\nBut why use an API instead of a static dataset you can download? APIs are useful in the following cases:\n The data is changing quickly. You want a small piece of a much larger set of data. There is repeated computation involved.  Weather API We are going to use the OpenWeatherMap API found at: .\n To use this API, you first need to create an API key. An API key acts as both a unique identifier and a secret token for authentication, and will generally have a set of access rights on the API associated with it.  To get an API key with OpenWeatherMap, you have to sign up here:     Now that you have the API key, you can now make an API call to get the current weather information from Austin, Texas.\nimport requests import json command = f\u0026#34;http://api.openweathermap.org/data/2.5/weather?q=Austin,us\u0026amp;units=imperial\u0026amp;APPID={API_KEY_VARIABLE}\u0026#34; response = requests.get(command) IMPORTANT: Replace {YOUR_API_KEY} with the variable you set it to within your config.py file. Do not forget to put your config.py file into a .gitignore file before you push to GitHub\nNOTE: If you wanted to see other cities you can use and how to call them, go to: \nresponse now holds the information that was returned from the API. If you were to print the value currently stored in response, you would get the output: \u0026lt;Response [200]\u0026gt;. This means you successfully got back a result from the API call.\nTo actually see the data retrieved from the API call in a json format, you have to do the following:\nprint(json.dumps(response.json(), indent=4)) Weather changes, so here is just ONE example output:\n{ \u0026#34;coord\u0026#34;: { \u0026#34;lon\u0026#34;: -97.74, \u0026#34;lat\u0026#34;: 30.27 }, \u0026#34;weather\u0026#34;: [ { \u0026#34;id\u0026#34;: 802, \u0026#34;main\u0026#34;: \u0026#34;Clouds\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;scattered clouds\u0026#34;, \u0026#34;icon\u0026#34;: \u0026#34;03d\u0026#34; } ], \u0026#34;base\u0026#34;: \u0026#34;stations\u0026#34;, \u0026#34;main\u0026#34;: { \u0026#34;temp\u0026#34;: 84.18, \u0026#34;pressure\u0026#34;: 1019, \u0026#34;humidity\u0026#34;: 70, \u0026#34;temp_min\u0026#34;: 80.6, \u0026#34;temp_max\u0026#34;: 87.8 }, \u0026#34;visibility\u0026#34;: 16093, \u0026#34;wind\u0026#34;: { \u0026#34;speed\u0026#34;: 9.17, \u0026#34;deg\u0026#34;: 210 }, \u0026#34;clouds\u0026#34;: { \u0026#34;all\u0026#34;: 48 }, \u0026#34;dt\u0026#34;: 1528903320, \u0026#34;sys\u0026#34;: { \u0026#34;type\u0026#34;: 1, \u0026#34;id\u0026#34;: 2557, \u0026#34;message\u0026#34;: 0.0041, \u0026#34;country\u0026#34;: \u0026#34;US\u0026#34;, \u0026#34;sunrise\u0026#34;: 1528889323, \u0026#34;sunset\u0026#34;: 1528940028 }, \u0026#34;id\u0026#34;: 4671654, \u0026#34;name\u0026#34;: \u0026#34;Austin\u0026#34;, \u0026#34;cod\u0026#34;: 200 } If we wanted to work with the json data that is returned, we can set a variable to the value returned with response.json(). Calling the \u0026lsquo;main\u0026rsquo; key of the response\nimport requests import json command = \u0026#34;http://api.openweathermap.org/data/2.5/weather?q=Austin,us\u0026amp;units=imperial\u0026amp;APPID={YOUR_API_KEY}\u0026#34; response = requests.get(command) austin_data = response.json() print(austin_data[\u0026#39;main\u0026#39;]) Output:\n{\u0026#39;temp\u0026#39;: 84.18, \u0026#39;pressure\u0026#39;: 1019, \u0026#39;humidity\u0026#39;: 70, \u0026#39;temp_min\u0026#39;: 80.6, \u0026#39;temp_max\u0026#39;: 87.8} Printing response in a formatted print\naustin_data = response.json() print(f\u0026#34;\u0026#34;\u0026#34;Temperature: {austin_data[\u0026#39;main\u0026#39;][\u0026#39;temp\u0026#39;]} F Humidity: {austin_data[\u0026#39;main\u0026#39;][\u0026#39;humidity\u0026#39;]}%\u0026#34;\u0026#34;\u0026#34;) Output:\nTemperature: 87.8 F Humidity: 55% IMPORTANT: Go to json Exercise\nGo to File Manipulation Exercise\n"
},
{
	"uri": "/python/foundation/loops-labs/",
	"title": "Loops Labs",
	"tags": [],
	"description": "",
	"content": "For Loops Create a String letters = [\u0026#39;O\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;n\u0026#39;, \u0026#39;g\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39; \u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;d\u0026#39;] Create a function that is called create_string that does not have any parameters. Using a for loop, convert the above list letters into a single string and return the string. Do not just print the letters out side by side\nPlace the following at the bottom of your __main__:\nprint(create_string()) Example output:\nOrange Academy Filling Tickets Define a function fill_ticket() that will ask a user five times to insert a number. (Use a loop to do this). After every time they answer, their newest answer is placed at the end of a list. This list is then returned.\nPlace the following at the bottom of your __main__:\nguesses = fill_ticket() print(guesses) Example Output:\nEnter a number: 5 Enter a number: 1 Enter a number: 3 Enter a number: 4 Enter a number: 1 [5, 1, 3, 4, 1] Finding Matches The winning combination of this lottery is chosen by picking five numbers. Define a function matches(ticket, winners) that takes two lists and returns an integer that says how many numbers the two lists are in the exact same position.\nCopy and paste the code below at the bottom of your main function to test out your matches(ticket, winners) functions.\nguesses = fill_ticket() winners = [1, 2, 3, 4, 5] print(matches(guesses, winners)) Output:\nEnter a number: 5 Enter a number: 1 Enter a number: 3 Enter a number: 4 Enter a number: 1 2 Caesar Cipher In cryptography, a Caesar cipher is a very simple encryption technique in which each letter in plain text is replaced by a letter of some fixed number of positions further down the alphabet. For example, with a shift of 3, A would store it in variable D, B would become E, and so on. The method is named after Julius Caesar, who used it to communicate with his generals. He used a shift of 13.\ncipher_key = {'a': 'n', 'b': 'o', 'c': 'p', 'd': 'q', 'e': 'r', 'f': 's', 'g': 't', 'h': 'u', 'i': 'v', 'j': 'w', 'k': 'x', 'l': 'y', 'm': 'z', 'n': 'a', 'o': 'b', 'p': 'c', 'q': 'd', 'r': 'e', 's': 'f', 't': 'g', 'u': 'h', 'v': 'i', 'w': 'j', 'x': 'k', 'y': 'l', 'z': 'm'}\nCreate a function called caesar_cipher that takes in a string and then returns the string changed with a shift of 13 letters. Note: your dictionary only works with lower case letters\nPlace the following at the bottom of your __main__:\nprint(caesar_cipher(\u0026#34;pnrfne pvcure? v zhpu cersre pnrfne fnynq!\u0026#34;)) To figure out the answer, you must complete the exercise!\nIMPORTANT: While Loops Reference\nWhile Loops Dice Histogram - While Loops Style Alter the previous histogram code to create a histogram with the results of rolls of a 6-sided dice. Stop \u0026ldquo;rolling the dice\u0026rdquo; once your random number is 4.\nGuessing Game Create a program that will ask the user to guess a random number between 1 - 20. Keep asking the user until they guess it correctly.\nCredit Limit Create a program that has the user first set a value for their bank account balance. Then ask the user to enter a new amount that they just spent and subtract this value from the total. Once they reach a zero balance, print out \u0026quot;All out of money!\u0026quot;. If they reach a negative balance, raise a RuntimeError.\nExample Output:\n\u0026gt;\u0026gt;\u0026gt; Enter Account Balance: 100 \u0026gt;\u0026gt;\u0026gt; Enter Amount Spent: 55 Amount Left: 45 \u0026gt;\u0026gt;\u0026gt; Enter Amount Spent: 20 Amount Left: 25 \u0026gt;\u0026gt;\u0026gt; Enter Amount Spent: 30 Amount Left: -5 All out of money! Pig Latin Create a function called pig_latin that receives a String called pig and return pig in pig latin.\nHere\u0026rsquo;s how to translate the English word into the Pig Latin word:\n If there are no vowels in englishWord, then pigLatinWord is just englishWord + \u0026quot;ay\u0026quot;. (There are ten vowels: 'a', 'e', 'i', 'o', and 'u', and their uppercase counterparts. y is not considered to be a vowel for the purposes of this assignment, i.e. my becomes myay, why becomes whyay, etc.) Else, if englishWord begins with a vowel, then pigLatinWord is just englishWord + \u0026quot;yay\u0026quot; Otherwise (if englishWord has a vowel in it and yet doesn\u0026rsquo;t start with a vowel), then pigLatinWord is end + start + \u0026quot;ay\u0026quot;, where end and start are defined as follows:  Let start be all of englishWord up to (but not including) its first vowel. Let end be all of englishWord from its first vowel on.    Go to File Manipulation Lesson\n"
},
{
	"uri": "/web-essentials/",
	"title": "Web Essentials",
	"tags": [],
	"description": "",
	"content": "Objectives These lessons aim to speak to Web technology concepts and skills that do not fall under the purview of a programming language.\n"
},
{
	"uri": "/python/foundation/file-manipulation-labs/",
	"title": "File Manipulation Labs",
	"tags": [],
	"description": "",
	"content": "CSV Manipulation Exercises\nFor this exercise, we\u0026rsquo;ll use many of the concepts we\u0026rsquo;ve already reviewed in this course.\ntxt Exercise Reading .Instructions\n Download this txt: Names and drag it into your project Create a new file (if you have not already) called txt_manipulation.py Read in all of the lines from names.txt and store it in a list called names. (As shown in the reference page)  Modifying Use the list names in this portion of the exercise.\n.Instructions\n For every row in names, find if the name starts with a vowel. If so, add the last name Phillips. If not, add the last name Moses  Writing .Instructions\n Write all of the information from names to the old file called names.txt Close this new file.  IMPORTANT: Go to csv Reference\ncsv Exercise Reading .Instructions\n Download this CSV: SalesJan2009 and drag it into your project Create a new file (if you have not already) called csv_manipulation.py Read in the information from SalesJan2009.csv and store it in a list called list_sales_data. (As shown in the reference page) Print out how many rows there are in list_sales_data. Print out the row number, and the latitude/longitude of every row inside the csv file, excluding the header row. Change your print statement to print out the row number and the difference of the current latitude from 30.2672° N, and the difference of the current longitude from 97.7431° W (Rounded to two past the decimal).  For example: If row 15\u0026rsquo;s latitude and longitude is 50.2983, -120.32, the output would be: Transaction #15: 20.0311 218.0631. (Note there are not negative numbers)   Format your print statement to look like the following:  Modifying Use the list list_sales_data in this portion of the exercise.\n.Instructions\n Add two additional header names to list_sales_data called distance and potential_friend. (Remember the location of headers) For every row in list_sales_data (excluding the header row), calculate the distance between the current location and 30.2672° N, 97.7431° W (Use the distance formula! Round to two past the decimal). Append these values at the end of the row. If the distance is less than 100, place True in the potential_friend column. Otherwise, place False in the potential_friend column.  Writing .Instructions\n Write all of the information from list_sales_data to a new csv file called sales_and_friends.csv. Close this new file.  IMPORTANT: Go to json Reference\njson Exercise Home Depot Stores .Instructions\n Download this json: Stores and drag it into your project Create a new file (if you have not already) called json_manipulation.py Read in all of the lines from stores.json and load it in a json called store_data. (As shown in the reference page) Print all the stores (Which are represented with a STR in the JSON file) address, city, state and zip code Find and print out the address of the nearest store location to 30.410177° N, -97.661694° W.  Final Output\nDistance from Home Depot Technology Center: 0.014446940195068895 13309 I-35 NORTH, AUSTIN, TX 78753 Bonus .Instructions\n Create a function that will take in any latitude and longitude and find the nearest Home Depot to that location. Create a function that will find the weather(temperature and humidity) of the origin and the destinations.  Google Maps API  Create an API key with Google Maps Platform here:   Check to enable Maps, Routes, and Places. Call your project JSON Practice It will make you enter credit card information. We are not going to exceed the daily limit, so your card will not be charged. We also can delete the account before the 30 day trial ends.    The following works to get the directions from The Home Depot Technology Center to Universal Studios Hollywood. (Remember to replace {YOUR_API_KEY} with your API key)\ndef find_directions(origin, destination, key): command = f\u0026#34;https://maps.googleapis.com/maps/api/directions/json?origin={origin}\u0026amp;destination={destination}\u0026amp;key={key}\u0026#34; response = requests.get(command) directions = response.json() route_info = directions[\u0026#39;routes\u0026#39;][0][\u0026#39;legs\u0026#39;][0] return json.dumps(route_info, indent=4) if __name__ == \u0026#34;__main__\u0026#34;: origin = \u0026#34;the+home+depot+technology+center\u0026#34; destination = \u0026#34;Universal+Studios+Hollywood4\u0026#34; key = \u0026#34;{YOUR_API_KEY}\u0026#34; print(find_directions(origin, destination)) Using the above code as a start, create a function that takes in a starting location and ending location and print out the starting address, ending address, distance between locations, and every step. You should get an output similar to the one below:\nGoing from: 13011B McCallen Pass, Austin, TX 78753, USA To: 13609 I-35, Austin, TX 78753, USA Total distance: 1.4 mi 1 Head \u0026lt;b\u0026gt;north\u0026lt;/b\u0026gt; on \u0026lt;b\u0026gt;McCallen Pass\u0026lt;/b\u0026gt; 2 Turn \u0026lt;b\u0026gt;left\u0026lt;/b\u0026gt; onto \u0026lt;b\u0026gt;Center Ridge Dr\u0026lt;/b\u0026gt;\u0026lt;div style=\u0026#34;font-size:0.9em\u0026#34;\u0026gt;Pass by Mattress Firm Final Markdown (on the right in 0.6\u0026amp;nbsp;mi)\u0026lt;/div\u0026gt; 3 Turn \u0026lt;b\u0026gt;right\u0026lt;/b\u0026gt; onto \u0026lt;b\u0026gt;N Interstate 35 Frontage Rd\u0026lt;/b\u0026gt; 4 Turn \u0026lt;b\u0026gt;right\u0026lt;/b\u0026gt; 5 Turn \u0026lt;b\u0026gt;left\u0026lt;/b\u0026gt;\u0026lt;div style=\u0026#34;font-size:0.9em\u0026#34;\u0026gt;Destination will be on the left\u0026lt;/div\u0026gt; Bonus\nCombine Google Maps API and the Weather API to also output the temperature and humidity of each location.\nExample Output\nGoing from: 13011B McCallen Pass, Austin, TX 78753, USA To: 11001 S 1st St, Austin, TX 78748, USA Total distance: 22.1 mi Duration: 26 mins 1 Head \u0026lt;b\u0026gt;north\u0026lt;/b\u0026gt; on \u0026lt;b\u0026gt;McCallen Pass\u0026lt;/b\u0026gt; 2 Make a \u0026lt;b\u0026gt;U-turn\u0026lt;/b\u0026gt; 3 Turn \u0026lt;b\u0026gt;right\u0026lt;/b\u0026gt; onto \u0026lt;b\u0026gt;E Parmer Ln\u0026lt;/b\u0026gt; 4 Turn \u0026lt;b\u0026gt;left\u0026lt;/b\u0026gt; onto \u0026lt;b\u0026gt;N Interstate 35 Frontage Rd\u0026lt;/b\u0026gt; 5 Take the ramp on the \u0026lt;b\u0026gt;left\u0026lt;/b\u0026gt; onto \u0026lt;b\u0026gt;I-35 S\u0026lt;/b\u0026gt;\u0026lt;div style=\u0026#34;font-size:0.9em\u0026#34;\u0026gt;Pass by Motel 6 Austin Central - N (on the right in 4.7\u0026amp;nbsp;mi)\u0026lt;/div\u0026gt; 6 Keep \u0026lt;b\u0026gt;left\u0026lt;/b\u0026gt; at the fork to continue on \u0026lt;b\u0026gt;I-35 S\u0026lt;/b\u0026gt;/\u0026lt;b\u0026gt;US-290 W\u0026lt;/b\u0026gt;/\u0026lt;b\u0026gt;N Interstate 35\u0026lt;/b\u0026gt;, follow signs for \u0026lt;b\u0026gt;32nd St\u0026lt;/b\u0026gt; 7 Keep \u0026lt;b\u0026gt;left\u0026lt;/b\u0026gt; to continue on \u0026lt;b\u0026gt;I-35 S\u0026lt;/b\u0026gt; 8 Take exit \u0026lt;b\u0026gt;225\u0026lt;/b\u0026gt; toward \u0026lt;b\u0026gt;Onion Creek Pkwy\u0026lt;/b\u0026gt;/\u0026lt;b\u0026gt;Farm to Market Rd 1626\u0026lt;/b\u0026gt; 9 Merge onto \u0026lt;b\u0026gt;S IH 35 Frontage Rd\u0026lt;/b\u0026gt; 10 Turn \u0026lt;b\u0026gt;right\u0026lt;/b\u0026gt; onto \u0026lt;b\u0026gt;Farm to Market 1626 W\u0026lt;/b\u0026gt; 11 Turn \u0026lt;b\u0026gt;right\u0026lt;/b\u0026gt; onto \u0026lt;b\u0026gt;S 1st St\u0026lt;/b\u0026gt; 12 Turn \u0026lt;b\u0026gt;right\u0026lt;/b\u0026gt; onto \u0026lt;b\u0026gt;Colonial Dr\u0026lt;/b\u0026gt;\u0026lt;div style=\u0026#34;font-size:0.9em\u0026#34;\u0026gt;Restricted usage road\u0026lt;/div\u0026gt; 13 Turn \u0026lt;b\u0026gt;right\u0026lt;/b\u0026gt;\u0026lt;div style=\u0026#34;font-size:0.9em\u0026#34;\u0026gt;Restricted usage road\u0026lt;/div\u0026gt;\u0026lt;div style=\u0026#34;font-size:0.9em\u0026#34;\u0026gt;Destination will be on the right\u0026lt;/div\u0026gt; ============================================================ Origin: Temperature: 85.08 F Humidity: 66% Destination: Temperature: 85.77 F Humidity: 66% Go To Classes Lesson\n"
},
{
	"uri": "/python/foundation/classes/",
	"title": "Classes",
	"tags": [],
	"description": "",
	"content": "Python has been an object-oriented language since the time it existed. Object-oriented programming (OOP) focuses on creating reusable patterns of code, in contrast to procedural programming, which focuses on explicit sequenced instructions. When working on complex programs in particular, object-oriented programming lets you reuse code and write code that is more readable, which in turn makes it more maintainable.\nOne of the most important concepts in object-oriented programming is the distinction between classes and objects, which are defined as follows:\n Class - A blueprint created by a programmer for an object. This defines a set of attributes that will characterize any object that is instantiated from this class. Object - An instance of a class. This is an actual occurrence of the class.  Creating Classes Classes are like a blueprint or a prototype that you can define to use to create objects. We define classes by using the class keyword, similar to how we define functions by using the def keyword.\nClass Set Up\nclass ClassName: \u0026#34;\u0026#34;\u0026#34; Optional class documentation string \u0026#34;\u0026#34;\u0026#34; NOTE: The class has a documentation string, which can be accessed via **print(ClassName.**DUNDER**__doc__**DUNDER**)**\nPlayer Class\nclass Player: \u0026#34;\u0026#34;\u0026#34; Creates a game Player template. \u0026#34;\u0026#34;\u0026#34; def gain_point(self, points): \u0026#34;\u0026#34;\u0026#34;Prints that the user has gained a certain number of points.\u0026#34;\u0026#34;\u0026#34; print(f\u0026#34;Yay! You have gained {points} point(s)!\u0026#34;) def lose_point(self, points): \u0026#34;\u0026#34;\u0026#34;Prints that the user has lost a certain number of points.\u0026#34;\u0026#34;\u0026#34; print(f\u0026#34;Oh no! You have lost {points} point(s)!\u0026#34;) Because these functions are indented under the class Player, ther are called methods. Methods are a special kind of function that are defined within a class.\nThe argument that both of these functions has is the word self, which is a reference to objects that are made based on this class. To reference instances (or objects) of the class, self will always be the first parameter, but it does not have to be the only one.\nDefining this class did not create any Player objects, only the pattern for a Player object that we can define later. That is, if you run the program at this stage, nothing will be returned.\nCreating the Player class above provided us with a blueprint for an object.\nObjects An object is an instance of a class. We can take the Player class defined above, and use it to create an object or instance of it.\nWe will make a Player object called ralph:\nralph = Player() ralph.gain_point(10) ralph.lose_point(5) The Player object ralph is using the two methods gain_point and lose_point. We called these using the dot operator (.), which is used to reference an attribute of the object. In this case, the attribute is a method and it\u0026rsquo;s called with parentheses, like how you would also call with a function.\nBecause the keyword self was a parameter of the methods as defined in the Player class, the ralph object gets passed to the methods. The self parameter makes sure that the methods have a way of referring to object attributes.\nWhen we call the methods, the object ralph is being automatically passed with the dot operator.\nPlayer Class\nclass Player: \u0026#34;\u0026#34;\u0026#34; Creates a game Player template. \u0026#34;\u0026#34;\u0026#34; def gain_point(self, points): \u0026#34;\u0026#34;\u0026#34;Prints that the user has gained a certain number of points.\u0026#34;\u0026#34;\u0026#34; self.points += points print(f\u0026#34;Yay! You have gained {points} point(s)! That means you now have {self.points} points!\u0026#34;) def lose_point(self, points): \u0026#34;\u0026#34;\u0026#34;Prints that the user has lost a certain number of points.\u0026#34;\u0026#34;\u0026#34; self.points -= points print(f\u0026#34;Oh no! You have lost {points} point(s)! That means you now have {self.points} points!\u0026#34;) def main(): ralph = Player() ralph.gain_point(10) ralph.lose_point(5) if __name__ == \u0026#34;__main__\u0026#34;: main() Output:\nYay! You have gained a 10 points! Oh no! You have lost 5 points! Constructor Methods __init__ is a special method in Python classes, it is the constructor method for a class. The constructor method is used to initialize data. It is run as soon as an object of a class is instantiated. The first parameter is always self. self is a special variable which points to the current object.\nConstructor in the Player class\nclass Player: def __init__(self): print(\u0026#34;This is the constructor method\u0026#34;) If you added the above init method to the Player class in the program above, the program would output the following without your modifying anything within the ralph instantiation:\nOutput:\nThis is the constructor method. Yay! You have gained a 10 points! Oh no! You have lost 5 points! This is because the constructor method is automatically initialized. You should use this method to carry out any initializing you would like to do with your class objects.\nInstead of using the constructor method above, let’s create one that uses a points variable that we can use to assign points to objects. We’ll pass two parameters: user_name and points as a parameter with a default value of 0. We will set self.user_name equal to user_name and self.points equal to points.\nclass Player: def __init__(self, user_name, points=0): self.user_name = user_name self.points = points Next, we can modify the strings in our functions to reference points, as below:\nclass Player: \u0026#34;\u0026#34;\u0026#34; Creates a game Player template. \u0026#34;\u0026#34;\u0026#34; def __init__(self, user_name, points=0): self.user_name = user_name self.points = points def gain_point(self, points): \u0026#34;\u0026#34;\u0026#34;Prints that the user has gained a certain number of points.\u0026#34;\u0026#34;\u0026#34; self.points += points print(f\u0026#34;Yay {self.user_name}! You have gained {points} point(s)! That means you now have {self.points} points!\u0026#34;) def lose_point(self, points): \u0026#34;\u0026#34;\u0026#34;Prints that the user has lost a certain number of points.\u0026#34;\u0026#34;\u0026#34; self.points -= points print(f\u0026#34;Oh no, {self.user_name}! You have lost {points} point(s)! That means you now have {self.points} points!\u0026#34;) Finally, we can set the user name to \u0026quot;R@!ph123\u0026quot; and the number of points a Player object ralph has to 10 by passing it as a parameter of the Player class.\nclass Player: \u0026#34;\u0026#34;\u0026#34; Creates a game Player template. \u0026#34;\u0026#34;\u0026#34; def __init__(self, user_name, points=0): self.user_name = user_name self.points = points def gain_point(self, points): \u0026#34;\u0026#34;\u0026#34;Prints that the user has gained a certain number of points.\u0026#34;\u0026#34;\u0026#34; self.points += points print(f\u0026#34;Yay {self.user_name}! You have gained {points} point(s)! That means you now have {self.points} points!\u0026#34;) def lose_point(self, points): \u0026#34;\u0026#34;\u0026#34;Prints that the user has lost a certain number of points.\u0026#34;\u0026#34;\u0026#34; self.points -= points print(f\u0026#34;Oh no, {self.user_name}! You have lost {points} point(s)! That means you now have {self.points} points!\u0026#34;) def main(): ralph = Player(\u0026#34;R@!ph123\u0026#34;, 100) ralph.gain_point(10) ralph.lose_point(5) if __name__ == \u0026#34;__main__\u0026#34;: main() Output:\nYay R@!ph123! You have gained a 10 points! That means you now have 110 points! Oh no, R@!ph123! You have lost 5 points! That means you now have 105 points! IMPORTANT: Classes Exercises\nWorking with More Than One Object Classes are useful because they allow us to create many similar objects based on the same blueprint.\nTo get a sense for how this works, let\u0026rsquo;s add another Player object to our program:\nclass Player: \u0026#34;\u0026#34;\u0026#34; Creates a game Player template. \u0026#34;\u0026#34;\u0026#34; def __init__(self, user_name, points=0): self.user_name = user_name self.points = points def gain_point(self, points): \u0026#34;\u0026#34;\u0026#34;Prints that the user has gained a certain number of points.\u0026#34;\u0026#34;\u0026#34; self.points += points print(f\u0026#34;Yay {self.user_name}! You have gained {points} point(s)! That means you now have {self.points} points!\u0026#34;) def lose_point(self, points): \u0026#34;\u0026#34;\u0026#34;Prints that the user has lost a certain number of points.\u0026#34;\u0026#34;\u0026#34; self.points -= points print(f\u0026#34;Oh no, {self.user_name}! You have lost {points} point(s)! That means you now have {self.points} points!\u0026#34;) def main(): ralph = Player(\u0026#34;R@!ph123\u0026#34;, 100) ralph.gain_point(10) sally = Player(\u0026#34;iS@llee\u0026#34;, 1245) sally.lose_point(5) if __name__ == \u0026#34;__main__\u0026#34;: main() Output:\nYay R@!ph123! You have gained a 10 points! That means you now have 110 points! Oh no, iS@llee! You have lost 1 points! That means you now have 1244 points! Method Types Example\nclass Employee: \u0026#34;\u0026#34;\u0026#34; Creates the info for an Employee \u0026#34;\u0026#34;\u0026#34; emp_count = 0 def __init__(self, name, ldap): self.name = name self.ldap = ldap Employee.emp_count += 1 def display_employee(self): print (f\u0026#34;Name: {self.name}, LDAP: {self.ldap}\u0026#34;) @classmethod def get_count(cls): return Employee.emp_count @staticmethod def take_home_salary(salary): return salary * 0.7 Instance Methods\ndef display_employee(self): print (f\u0026#34;Name: {self.name}, LDAP: {self.ldap}\u0026#34;)  Takes one parameter, self, which points to an instance of the class when the method is called. Can freely access attributes and other methods on the same object. Able to modify an object’s class\u0026rsquo;s state. Can access the class itself through the self.__class__ attribute.  Class Methods\n@classmethod def get_count(cls): return Employee.emp_count  Marked with a @classmethod decorator to flag it as a class method. Take a cls parameter that points to the class—and not the object instance—when the method is called. It can’t modify object instance state. (That would require access to self.) It can still modify class state.  Static Methods\n@staticmethod def take_home_salary(salary): return salary * 0.7  Marked with a @staticmethod decorator to flag it as a static method. Takes neither a self nor a cls parameter (but free to accept other parameters). It can neither modify object state nor class state. Static methods are restricted in what data they can access.  Using Types of Methods if __name__ == \u0026#34;__main__\u0026#34;: print(\u0026#34;=================================\u0026#34;) e1 = Employee(\u0026#34;Hellen\u0026#34;, 25000) e1.display_employee() print(f\u0026#34;Number of Employees: {Employee.get_count()}\u0026#34;) print(f\u0026#34;Potential Salary: {Employee.take_home_salary(100)}\u0026#34;) print(\u0026#34;=================================\u0026#34;) e2 = Employee(\u0026#34;Jackson\u0026#34;, 58000) e2.display_employee() print(f\u0026#34;Number of Employees: {Employee.get_count()}\u0026#34;) print(f\u0026#34;Potential Salary: {Employee.take_home_salary(350)}\u0026#34;) Key Points  Instance methods need a class instance and can access the instance through self. Class methods don’t need a class instance. They can’t access the instance (self) but they have access to the class itself via cls. Static methods don’t have access to cls or self. They work like regular functions but belong to the class’s namespace.  Go to Classes Exercise\n"
},
{
	"uri": "/python/foundation/classes-labs/",
	"title": "Classes Labs",
	"tags": [],
	"description": "",
	"content": "String Manipulation Create a new file called string_manipulation.py.\nInside your new file, create a class called StringManipulation. Inside this class create the following methods.\nConstructor\nCreate a constructor that takes in a string called altering_str.\nString Reversal\nCreate a function called string_reversal that takes in a String called reverse that has a default value of \u0026lsquo;None\u0026rsquo;. If the value of reverse remains None, return self.altering_str reversed. If the value of reverse has changed, return the exact reversal of the characters in the new string.\nRemoving Case\nCreate a function called removing_case that takes in a String called removed that has a default value of \u0026lsquo;None\u0026rsquo;. If the value of removed remains None, return self.altering_str without any punctuation, spaces and all letters are converted to lowercase. If the value of removed has changed, return removed without any punctuation, spaces and all letters are converted to lowercase.\nIs Vowel\nCreate a function called is_vowel that takes in a String called searching that has a default value of \u0026lsquo;None\u0026rsquo;. If the value of searching remains None, return if self.altering_str contains any vowels. If the value of is_vowel has changed, return if is_vowel contains any vowels.\nPalindrome\nCreate a function called is_palindrome that takes in a String called searching that has a default value of \u0026lsquo;None\u0026rsquo;. If the value of searching remains None, return if self.altering_str is a palindrome. If the value of is_palindrome has changed, return if is_palindrome is a palindrome.\nShort Hand\nCreate a function called short_hand that takes in a String called short that has a default value of \u0026lsquo;None\u0026rsquo;. If the value of short remains None, return if self.altering_str in shorthand. If the value of short has changed, return short in short hand. The simplified shorthand form of a String is defined as follows:\n replace these four words: \u0026ldquo;and\u0026rdquo; with \u0026ldquo;\u0026amp;\u0026rdquo;, \u0026ldquo;to\u0026rdquo; with \u0026ldquo;2\u0026rdquo;, \u0026ldquo;you\u0026rdquo; with \u0026ldquo;U\u0026rdquo;, and \u0026ldquo;for\u0026rdquo; with \u0026ldquo;4\u0026rdquo;. remove all vowels (\u0026lsquo;a\u0026rsquo;, \u0026lsquo;e\u0026rsquo;, \u0026lsquo;i\u0026rsquo;, \u0026lsquo;o\u0026rsquo;, \u0026lsquo;u\u0026rsquo;, whether lowercase or uppercase). Be careful on removing U!  Pig Latin\nCreate a function called pig_latin that receives a String called pig, that has a default value of \u0026lsquo;None\u0026rsquo;. If the value of pig remains None, return if self.altering_str in pig latin. If the value of pig has changed, return pig in pig latin.\nHere\u0026rsquo;s how to translate the English word into the Pig Latin word:\n If there are no vowels in englishWord, then pigLatinWord is just englishWord + \u0026quot;ay\u0026quot;. (There are ten vowels: 'a', 'e', 'i', 'o', and 'u', and their uppercase counterparts. ‘y’ is not considered to be a vowel for the purposes of this assignment, i.e. my becomes myay, why becomes whyay, etc.) Else, if englishWord begins with a vowel, then pigLatinWord is just englishWord + \u0026quot;yay\u0026quot; Otherwise (if englishWord begins has a vowel in it and yet doesn\u0026rsquo;t start with a vowel), then pigLatinWord is end + start + \u0026quot;ay\u0026quot;, where end and start are defined as follows:  Let start be all of englishWord up to (but not including) its first vowel. Let end be all of englishWord from its first vowel on.    "
},
{
	"uri": "/python/testing/additional-material/unit-tests/",
	"title": "Unit Tests",
	"tags": [],
	"description": "",
	"content": "Introducing Unit Testing in Python Using the unittest module Let\u0026rsquo;s see what a unit and tests look like as a whole:\nimport unittest ## Here\u0026#39;s our \u0026#34;unit\u0026#34; checking that n is an odd number def is_odd(n): return n % 2 == 1 ## Here\u0026#39;s our \u0026#34;unit test\u0026#34; class class IsOddTests(unittest.TestCase): ## First function takes the IsOdd function and use the parameter n=1 as true, ## otherwise fail the test. def test_one(self): self.assertTrue(is_odd(1)) ## Second function takes IsOdd function and use the parameter n=2 ## as automatic fail of test. def test_two(self): self.assertFalse(is_odd(2)) if __name__ == \u0026#39;__main__\u0026#39;: unittest.main() Different assert statements\n   Method Checks That     assertEqual(a, b) a == b   assertNotEqual(a, b) a != b   assertTrue(x) bool(x) is True   assertFalse(x) bool(x) is False   assertIs(a, b) a is b   assertIsNot(a, b) a is not b   assertIsNone(x) x is None   assertIsNotNone(x) x is not None   assertIn(a, b) a in b   assertNotIn(a, b) a not in b   assertIsInstance(a, b) isinstance(a, b)   assertNotIsInstance(a, b) not isinstance(a, b)    Class? Wut? We have only mentioned classes in this course, but we can briefly explain them here. A class is used in this situation in order to run both \u0026ldquo;test cases\u0026rdquo; - test_one() and test_two().\nWhen you\u0026rsquo;re writing a method (or function) for a test, there are a few rules:\n The name of the function should start with the word test like test_one() and test_two() in the above example. They both must have the argument (self) as well. They have to be within a class whose argument must be (unittest.TestCase)  Technically IsOddTests is called a Test Fixture, even though TestCase is a class that it\u0026rsquo;s derived from. As a class itself, it\u0026rsquo;s derived from unittest.TestCase, and Test Fixtures group related test cases together.\n NOTE: It\u0026rsquo;s important to note that you wouldn\u0026rsquo;t usually write your tests in the same file as your unit that\u0026rsquo;s being tested. This is just for instructional purposes. You can also begin writing tests this way, but extract the code or tests later to organize your codebase properly.\n Start with tests Being test infected is a good thing! This means that you must write a program by first writing unit test. That\u0026rsquo;s right - don\u0026rsquo;t write the code first, write the tests first.\nFirst step in testing is to create an empty test fixture that fails:\nimport unittest class FooTests(unittest.TestCase): def test_foo(self): self.assertTrue(False) if __name__ == \u0026#39;__main__\u0026#39;: unittest.main() Output should look something like this:\nYou may be asking\u0026hellip; but I don\u0026rsquo;t even know what I\u0026rsquo;m testing yet!\nThat\u0026rsquo;s the point. You don\u0026rsquo;t have to. If you start with these bones to test before you even start writing code, you\u0026rsquo;ll be able to code to the tests instead of testing against old, buggy code.\nBefore we specify what code (unit) we want to test, let\u0026rsquo;s define what exactly a unit can consist of. It can be an entire module, a single function or even just a measley if/else statement. You just have to ensure that the code you\u0026rsquo;re testing is isolated from any other code in your codebase.\nExample: Prime number testing Say we\u0026rsquo;d like to figure out if a number is a prime number. Prime Number: A whole number, greater than 1, that cannot be formed by multiplying two smaller whole numbers\nWe\u0026rsquo;ll first take our test example from above, and we\u0026rsquo;ll change the name of the class to something relevant like PrimeTestCase and the function name to test_prime()\nimport unittest class PrimeTestCase(unittest.TestCase): def test_prime(self): self.assertTrue(False) if __name__ == \u0026#39;__main__\u0026#39;: unittest.main() Now, to add the unit to our test:\nimport unittest def is_prime(number): for i in range(2, number): if number % i == 0: return False return True class PrimeTestCase(unittest.TestCase): def test_prime(self): self.assertTrue(is_prime(5)) if __name__ == \u0026#39;__main__\u0026#39;: ## Call the unittest module on main() function which will run the entire program unittest.main() The output should be that the test is OK which means that we wrote our unit properly. Since we know 5 is a prime number already, we use it as the argument within the test case. This proves that our function to find prime numbers was written correctly.\nIn order to make sure it\u0026rsquo;s just not checking for the number 5, write more assertions with various numbers to test. Observe the output after running the file.\nUnit Test Exercise\n"
},
{
	"uri": "/python/testing/additional-material/unit-tests-labs/",
	"title": "Unit Test Labs",
	"tags": [],
	"description": "",
	"content": "Write a unit test Take the age calculator we created previously, and write a test for it. We want to make sure the answer is always a positive number.\ndef age_calculator(current_year, birth_year): ## Returns the age of a person age = current_year - birth_year if age \u0026lt; 0: ## If age is not a positive number, do not return the age print(\u0026#34;Not a correct age!\u0026#34;) else: return age if __name__ == \u0026#39;__main__\u0026#39;: print(age_calculator(2018, 1995)) Write a test validating that the function we wrote will always return a positive number for age.\n"
},
{
	"uri": "/python/foundation/generators/",
	"title": "Generators",
	"tags": [],
	"description": "",
	"content": "Iteration \u0026amp; Iterables Iteration is the repetition of some kind of process over and over again. Python\u0026rsquo;s for loop gives us an easy way to iterate over various objects. Often, you\u0026rsquo;ll iterate over a list, but we can also iterate over other Python objects such as strings and dictionaries.\n# Iterating over a list ez_list = [1, 2, 3] for i in ez_list: print(i) ----output---- \u0026gt;\u0026gt;\u0026gt; 1 \u0026gt;\u0026gt;\u0026gt; 2 \u0026gt;\u0026gt;\u0026gt; 3 # Iterating over a string ez_string = \u0026#34;Generators\u0026#34; for s in ez_string: print(s) ----output---- \u0026gt;\u0026gt;\u0026gt; \u0026#34;G\u0026#34; \u0026gt;\u0026gt;\u0026gt; \u0026#34;e\u0026#34; ... \u0026gt;\u0026gt;\u0026gt; \u0026#34;r\u0026#34; \u0026gt;\u0026gt;\u0026gt; \u0026#34;s\u0026#34; # Iterating over a dictionary ez_dict = {1 : \u0026#34;First\u0026#34;, 2 : \u0026#34;Second\u0026#34;} for key, value in ez_dict.items(): print(key, value) ----output---- \u0026gt;\u0026gt;\u0026gt; 1 \u0026#34;First\u0026#34; \u0026gt;\u0026gt;\u0026gt; 2 \u0026#34;Second\u0026#34; In each of the above examples, the for loop iterates over the sequence we give it. The code above used a list, string, and dictionary, but you can iterate over tuples and sets as well. In each loop above, we print each of the items in the sequence in the order they appear. For example, you can confirm that the order of the ez_list is replicated in the order that its items are printed out.\nWe refer to any object that can support iteration as an iterable.\nWhat defines an iterable? Iterables support something called the Iterator Protocol. The technical definition for the Iterator Protocol is out of the scope of this article, but it can be thought of as a set of requirements to be used for a for loop. That is to say: lists, strings and dictionaries all follow the Iterator Protocol, therefore we can use them in for loops. Conversely, objects that do not follow the protocol cannot be used in a for loop. One example of an object that does not follow the protocol is an integer.\nIf we try to give an integer to a for loop, Python will throw an error.\nnumber = 12345 for n in number: print(n) ----output---- \u0026gt;\u0026gt;\u0026gt; TypeError: \u0026#39;int\u0026#39; object is not iterable An integer is just a singular number, not a sequence. You may argue that the \u0026ldquo;first\u0026rdquo; number in number is 1, but it is not the same as the first item in a sequence. It doesn\u0026rsquo;t make sense to ask \u0026ldquo;What\u0026rsquo;s after 1?\u0026rdquo; from number since Python only understands integers as a single entities.\nTherefore, one of the requirements to be an iterable is to be able to describe to the for loop what the next item to perform the operation on is. For example, lists tell the for loop that the next item to iterate on is in the index+1 from the current one (1 comes after 0).\nConsequently, an iterable must also signal to a for loop when to stop iterating. This signal usually comes when we arrive at the end of a sequence (i.e. the end of a list or string). We will explore the specific functions that make something iterable later in this article, the important thing to know is that iterables describe how a for loop should traverse its contents.\nGenerators are iterables themselves. As you\u0026rsquo;ll see later, for loops are one of the main ways we use a generator, so they must be able to support iteration. We\u0026rsquo;ll delve into how we can create our own generators in the next secton.\nKey takeaways: basic terms to know   Iteration is the idea of repeating some process over a sequence of items. In Python, iteration is usually related to the for loop.\n  An iterable is an object that supports iteration.\n  To be an iterable, it must describe to a for loop two things:\n 1. What item comes next in the iteration. 2. When should the loop stop iteration.    Generators are Iterables.\n   Generators and you If you\u0026rsquo;ve never encountered a generator before, the most common real-life example of a generator is a backup generator, which creates — generates — electricity for your house or office.\nConceptually, Python generators generate values one at a time from a given sequence, instead of giving the entirety of the sequence at once. This one-at-a-time fashion of generators is what makes them so compatible with for loops.\nThere are two ways to create a generator. They differ in their syntax, but the end result is still a generator. We\u0026rsquo;ll teach these concepts by covering their syntax and comparing them to a similar, but non-generator equivalent.\n A generator function versus a regular function A generator expression versus a list comprehension   Simplified Code Generator functions allow you to declare a function that behaves like an iterator.\nThe Iterator Protocol mentioned previously looks for two methods within the class: __iter__ and __next__.\nWhy would you even want to make iterators? Saving memory space\nIterators don’t compute the value of each item when instantiated. They only compute it when you ask for it. This is known as lazy evaluation.\nLazy evaluation is useful when you have a very large data set to compute. It allows you to start using the data immediately, while the whole data set is being computed.\nLet’s say we want to get all the prime numbers that are smaller than a maximum number.\nWe first define the function that checks if a number is prime:\ndef check_prime(number): for divisor in range(2, int(number ** 0.5) + 1): if number % divisor == 0: return False return True Then, we define the iterator class that will include the __iter__ and __next__ methods:\nclass Primes: def __init__(self, max): self.max = max self.number = 1 def __iter__(self): return self def __next__(self): self.number += 1 if self.number \u0026gt;= self.max: raise StopIteration elif check_prime(self.number): return self.number else: return self.__next__() Class Primes: is instantiated with a maximum value. If the next prime is greater or equal than the max, the iterator will raise a StopIteration exception, which ends the iterator.\nWhen we request the __next__ element in the iterator, it will increment number by 1 and check if it’s a prime number. If it’s not, it will call __next__ again until number is prime. Once it is, the iterator returns the number.\nBy using an iterator, we’re not creating a list of prime numbers in our memory. Instead, we’re generating the next prime number every time we request for it.\nLet’s try it out:\nprimes = Primes(100000000000) print(primes) for x in primes: print(x) ----output---- \u0026lt;__main__.Primes object at 0x1021834a8\u0026gt; 2 3 5 7 11 ... Every iteration of the Primes object calls __next__ to generate the next prime number.\nIterators can only be iterated over once. If you try to iterate over primes again, no value will be returned. It will behave like an empty list.\nNow that we know what iterators are and how to make one, we’ll move on to generators.\n Generator Functions Recall that generator functions allow us to create iterators in a more simple fashion.\nGenerators introduce the yield statement to Python. It works a bit like return because it returns a value.\nThe difference is that it saves the state of the function. The next time the function is called, execution continues from where it left off, with the same variable values it had before yielding.\nIf we transform our Primes() iterator into a generator, it’ll look like this:\ndef Primes(max): number = 1 while number \u0026lt; max: number += 1 if check_prime(number): yield number primes = Primes(100000000000) print(primes) for x in primes: print(x) ----output---- \u0026lt;generator object Primes at 0x10214de08\u0026gt; 2 3 5 7 11 ... Now that’s pretty pythonic! Can we do better?\nYes! We can use Generator Expressions\n Generator Expressions This is the list comprehension equivalent of generators. It works exactly in the same way as a list comprehension, but the expression is surrounded with () as opposed to [].\nThe following expression can replace our generator function above:\nprimes = (i for i in range(2, 100000000000) if check_prime(i)) print(primes) for x in primes: print(x) ----output---- \u0026lt;generator object \u0026lt;genexpr\u0026gt; at 0x101868e08\u0026gt; 2 3 5 7 11 ... This is the beauty of generators in Python.\n In summary…  Generators allow you to create iterators in a very pythonic manner. Iterators allow lazy evaluation, only generating the next element of an iterable object when requested. This is useful for very large data sets. Iterators and generators can only be iterated over once. Generator Functions are better than Iterators. Generator Expressions are better than Iterators (for simple cases only).   Setup\n If you have not already, Fork https://github.homedepot.com/om-labs/Python-API to your Home Depot profile Clone down your newly forked repo cd into the resources/Adv_Concepts/Generators directory  World Development Indicator Data Generator  Using the big data file world_dev_ind.csv in this directory, complete the code in bigData.py. Complete the code from bigData_dict.py.   "
},
{
	"uri": "/python/foundation/decorators/",
	"title": "Decorators",
	"tags": [],
	"description": "",
	"content": "First Class Objects In Python, functions are first-class objects. This means that functions can be passed around, and used as arguments, just like any other value (e.g, string, int, float).\ndef foo(bar): return bar + 1 print(foo) print(foo(2)) print(type(foo)) def call_foo_with_arg(foo, arg): return foo(arg) print(call_foo_with_arg(foo, 3)) Nested Functions Because of the first-class nature of functions in Python, you can define functions inside other functions. Such functions are called nested functions.\ndef parent(): print(\u0026#34;Printing from the parent() function.\u0026#34;) def first_child(): return \u0026#34;Printing from the first_child() function.\u0026#34; def second_child(): return \u0026#34;Printing from the second_child() function.\u0026#34; print(first_child()) print(second_child()) What happens when you call the parent() function? Think about this for a minute. You should get…\nPrinting from the parent() function. Printing from the first_child() function. Printing from the second_child() function Try calling the first_child(). You should get an error:\nTraceback (most recent call last): File \u0026#34;decorator03.py\u0026#34;, line 15, in first_child() NameError: name \u0026#39;first_child\u0026#39; is not defined What have we learned? Whenever you call parent(), the sibling functions, first_child() and second_child() are also called AND because of scope, both of the sibling functions are not available (e.g., cannot be called) outside of the parent function.\n Returning Functions w/Functions Python also allows you to use functions as return values. The following example returns one of the inner functions from the outer parent() function:\ndef parent(num): def first_child(): return \u0026#34;Hi, I am Emma\u0026#34; def second_child(): return \u0026#34;Call me Liam\u0026#34; if num == 1: return first_child else: return second_child Note that you are returning first_child without the parentheses. Recall that this means that you are returning a reference to the function first_child. In contrast first_child() with parentheses refers to the result of evaluating the function. This can be seen in the following example:\n\u0026gt;\u0026gt;\u0026gt; first = parent(1) \u0026gt;\u0026gt;\u0026gt; second = parent(2) \u0026gt;\u0026gt;\u0026gt; first \u0026lt;function parent.\u0026lt;locals\u0026gt;.first_child at 0x7f599f1e2e18\u0026gt; \u0026gt;\u0026gt;\u0026gt; second \u0026lt;function parent.\u0026lt;locals\u0026gt;.second_child at 0x7f599dad5268\u0026gt; The somewhat cryptic output simply means that the first variable refers to the local first_child() function inside of parent(), while second points to second_child().\nYou can now use first and second as if they are regular functions, even though the functions they point to can’t be accessed directly:\n\u0026gt;\u0026gt;\u0026gt; first() \u0026#39;Hi, I am Emma\u0026#39; \u0026gt;\u0026gt;\u0026gt; second() \u0026#39;Call me Liam\u0026#39; Finally, note that in the earlier example you executed the inner functions within the parent function, for instance first_child(). However, in this last example, you did not add parentheses to the inner functions, first_child \u0026amp; second_child, upon returning. That way, you got a reference to each function that you could call in the future. Make sense?\nNow, my friend, you are ready to take on decorators!\n Decorators are very similar to closures in Javascript.\n Hmm\u0026hellip; how would we turn this into a decorator?\n Simple Decorators Now that you’ve seen that functions are just like any other object in Python, you’re ready to move on and see the magical beast that is the Python decorator. Let’s start with an example:\nExample 1 def my_decorator(some_function): def wrapper(): print(\u0026#34;Something is happening before some_function() is called.\u0026#34;) some_function() print(\u0026#34;Something is happening after some_function() is called.\u0026#34;) return wrapper def just_some_function(): print(\u0026#34;Wheee!\u0026#34;) just_some_function = my_decorator(just_some_function) just_some_function() Can you guess what happens when you call just_some_function()? Try it:\nSomething is happening before some_function() is called. Wheee! Something is happening after some_function() is called. To understand what\u0026rsquo;s going on here, just look back at the previous example. We are just applying everything we learned.\n Put simply, decorators wrap a function, modifying its behavior.\n Before moving on, let’s have a look at a second example. Because wrapper() is a regular Python function, the way a decorator modifies a function can change dynamically. So as not to disturb your neighbors, the following example will only run the decorated code during the day:\nExample 2 from datetime import datetime def not_during_the_night(func): def wrapper(): if 7 \u0026lt;= datetime.now().hour \u0026lt; 22: func() else: pass # Hush, the neighbors are asleep return wrapper def say_whee(): print(\u0026#34;Whee!\u0026#34;) banana = not_during_the_night(say_whee) If you try to call say_whee() after bedtime, nothing will happen:\n\u0026gt;\u0026gt;\u0026gt; banana() \u0026gt;\u0026gt;\u0026gt; Syntactic Sugar! The way you decorated say_whee() above is a little clunky. First of all, you end up typing the name say_whee three times. In addition, the decoration gets a bit hidden away below the definition of the function.\nInstead, Python allows you to use decorators in a simpler way with the @ symbol, sometimes called the “pie” syntax. The following example does the exact same thing as the first decorator example:\ndef my_decorator(func): def wrapper(): print(\u0026#34;Something is happening before the function is called.\u0026#34;) func() print(\u0026#34;Something is happening after the function is called.\u0026#34;) return wrapper @my_decorator def say_whee(): print(\u0026#34;Whee!\u0026#34;) Creating a module for the decorator #/decoratorfile.py def my_decorator(some_function): def wrapper(): num = 10 if num == 10: print(\u0026#34;Yes!\u0026#34;) else: print(\u0026#34;No!\u0026#34;) some_function() print(\u0026#34;Something is happening after some_function() is called.\u0026#34;) return wrapper Okay. Stay with me. Let\u0026rsquo;s look at how to call the function with the decorator:\nfrom decoratorfile import my_decorator @my_decorator def just_some_function(): print(\u0026#34;Wheee!\u0026#34;) just_some_function() When you run this example, you should get the same output as in the previous one:\nYes! Wheee! Something is happening after some_function() is called. So, @my_decorator is just an easier way of saying just_some_function = my_decorator(just_some_function). It\u0026rsquo;s how you apply a decorator to a function.\nReal World Examples How about a few real world examples …\nimport time def timing_function(some_function): \u0026#34;\u0026#34;\u0026#34; Outputs the time a function takes to execute. \u0026#34;\u0026#34;\u0026#34; def wrapper(): t1 = time.time() some_function() t2 = time.time() return \u0026#34;Time it took to run the function: \u0026#34; + str((t2 - t1)) + \u0026#34;n\u0026#34; return wrapper @timing_function def my_function(): num_list = [] for num in (range(0, 10000)): num_list.append(num) print(\u0026#34;Sum of all the numbers: \u0026#34; + str((sum(num_list)))) print(my_function()) This returns the time before you run my_function() as well as the time after. Then we simply subtract the two to see how long it took to run the function.\nRun it. Work through the code, line by line. Make sure you understand how it works.\nfrom time import sleep def sleep_decorator(function): \u0026#34;\u0026#34;\u0026#34; Limits how fast the function is called. \u0026#34;\u0026#34;\u0026#34; def wrapper(*args, **kwargs): sleep(2) return function(*args, **kwargs) return wrapper @sleep_decorator def print_number(num): return num print(print_number(222)) for num in range(1, 6): print(print_number(num)) This decorator is used for rate limiting. Test it out.\n functools.wraps example\nWhen you use a decorator, you\u0026rsquo;re replacing one function with another. In this example f() is replaced with the function with_logging().\n\u0026#39;\u0026#39;\u0026#39;from my_decorator import my_decorator @my_decorator def the_decorated_func(): print(\u0026#34;Hi from the decorated function!\u0026#34;) print(the_decorated_func) the_decorated_func() \u0026#39;\u0026#39;\u0026#39; from functools import wraps def logged(func): @wraps(func) def with_logging(*args, **kwargs): print(func.__name__ + \u0026#34; was called\u0026#34;) return func(*args, **kwargs) return with_logging @logged def f(x): \u0026#34;\u0026#34;\u0026#34;does some math\u0026#34;\u0026#34;\u0026#34; return x + x * x print(f(10)) # prints \u0026#39;f\u0026#39; print(f.__name__) # prints \u0026#39;f\u0026#39; print(f.__doc__ ) # prints \u0026#39;does some math\u0026#39; Unfortunately, this means that if you then say\nprint(f.__name__) it will print with_logging() because that\u0026rsquo;s the name of your new function. In fact, if you look at the docstring for f(), it will be blank because with_logging() has no docstring, and so the docstring you wrote won\u0026rsquo;t be there anymore. Also, if you look at the pydoc result for that function, it won\u0026rsquo;t be listed as taking one argument x; instead it\u0026rsquo;ll be listed as taking *args and **kwargs because that\u0026rsquo;s what with_logging() takes.\nIf using a decorator always meant losing this information about a function, it would be a serious problem. That\u0026rsquo;s why we have functools.wraps. This takes a function used in a decorator and adds the functionality of copying over the function name, docstring, arguments list, etc. And since wraps is itself a decorator, the following code does the correct thing:\nfrom functools import wraps def logged(func): @wraps(func) def with_logging(*args, **kwargs): print(func.__name__ + \u0026#34; was called\u0026#34;) return func(*args, **kwargs) return with_logging @logged def f(x): \u0026#34;\u0026#34;\u0026#34;does some math\u0026#34;\u0026#34;\u0026#34; return x + x * x print(f.__name__) # prints \u0026#39;f\u0026#39; print(f.__doc__ ) # prints \u0026#39;does some math\u0026#39; print(f(10)) # prints \u0026#39;f was called\u0026#39; #\u0026#39;110\u0026#39;  Flask Login Decorator One of the most used decorators in Python is the login_required() decorator, which ensures that a user is logged in/properly authenticated before s/he can access a specific route (/secret, in this case):\n The below example uses Flask, we will take a deeper look at Flask in the next section, for now focus on the @Decorators\n from functools import wraps from flask import g, request, redirect, url_for def login_required(f): @wraps(f) def decorated_function(*args, **kwargs): if g.user is None: return redirect(url_for(\u0026#39;login\u0026#39;, next=request.url)) return f(*args, **kwargs) return decorated_function @app.route(\u0026#39;/secret\u0026#39;) @login_required def secret(): pass Did you notice the functools.wraps() decorator?\n Flask Specific Request Decorator Let\u0026rsquo;s look at one last use case. Take a quick look at the following Flask route handler:\n@app.route(\u0026#39;/grade\u0026#39;, methods=[\u0026#39;POST\u0026#39;]) def update_grade(): json_data = request.get_json() if \u0026#39;student_id\u0026#39; not in json_data: abort(400) # update database return \u0026#34;success!\u0026#34; Below we ensure that the key student_id is part of the request. Although this validation works it really does not belong in the function itself. Plus, perhaps there are other routes that use the exact same validation. So, let\u0026rsquo;s keep it DRY and abstract out any unnecessary logic with a decorator.\n#app.py from flask import Flask, request, abort from functools import wraps app = Flask(__name__) def validate_json(*expected_args): def decorator(func): @wraps(func) def wrapper(*args, **kwargs): json_object = request.get_json() for expected_arg in expected_args: if expected_arg not in json_object: abort(400) return func(*args, **kwargs) return wrapper return decorator @app.route(\u0026#39;/grade\u0026#39;, methods=[\u0026#39;POST\u0026#39;]) @validate_json(\u0026#39;student_id\u0026#39;) def update_grade(): json_data = request.get_json() print(json_data) # update database return \u0026#34;success!\u0026#34; if __name__ == \u0026#39;__main__\u0026#39;: app.run() Run app.py and run the following curl command in your terminal.\n$ curl -H \u0026#34;Content-Type: application/json\u0026#34; -X POST -d \u0026#39;{\u0026#34;student_id\u0026#34;:1}\u0026#39; http://localhost:5000/grade In the above code, the decorator takes a variable length list as an argument so that we can pass in as many string arguments as necessary, each representing a key used to validate the JSON data.\n Exercise: HTML Text Decorator Create decorator that decorates a function called greet() that returns the string \u0026quot;hello\u0026quot;. There should be 7 decorators:\n uppercase() ~ converts string to uppercase lowercase() ~ converts string to lowercase emphasis() ~ places the HTML emphasistag around the string strong() ~ places the HTML strongtag around the string make_italic() ~ places the HTML italicstag around the string make_bold() ~ places the HTML boldtag around the string make_underline() ~ places the HTML underlinetag around the string  Your program will ask the user how they would like to decorate the string, giving them all 7 options to choose from but only allowing the user to choose 3 decorations.\nStarter Code for Lab:\ndef make_strong(fn): def wrapped(): return \u0026#34;\u0026lt;strong\u0026gt;\u0026#34; + fn() + \u0026#34;\u0026lt;/strong\u0026gt;\u0026#34; return wrapped # TODO: add the functions for the other 6 decorator functions choices = [\u0026#39;make_uppercase\u0026#39;, \u0026#39;make_lowercase\u0026#39;, \u0026#39;make_bold\u0026#39;, \u0026#39;make_italic\u0026#39;, \u0026#39;make_underline\u0026#39;, \u0026#39;make_emphasis\u0026#39;, \u0026#39;make_strong\u0026#39;] picked = [] # This will hold the users choices # TODO: ask the user to choose 3 of the options and store their choices in picked altered_text = \u0026#39;hello\u0026#39; if \u0026#39;make_strong\u0026#39; in picked: @make_strong def greeting(): return altered_text altered_text = greeting() # TODO: create other if statements to handle if the other 6 decorator functions are chosen print(altered_text) Bonus  Update your Text decorator program to automatically underline and place ilatics on characters inside single quotes inside your string. Consolidate your code to only declare greeting() once  "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/labs/",
	"title": "Labs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/software-eng-essentials/db-sql/data/vet-clinic/",
	"title": "vet-clinic Additional Resources",
	"tags": [],
	"description": "",
	"content": "vet-clinic Additional Material "
},
{
	"uri": "/software-eng-essentials/db-sql/data/",
	"title": "Additional Resources",
	"tags": [],
	"description": "",
	"content": "Additional Material "
},
{
	"uri": "/software-eng-essentials/db-sql/data/home-depot/",
	"title": "home-depot Additional Resources",
	"tags": [],
	"description": "",
	"content": "home-depot Additional Material "
},
{
	"uri": "/software-eng-essentials/git-foundations/unix-commands/",
	"title": "UNIX Shell Commands",
	"tags": [],
	"description": "",
	"content": "Directory Commands    Command Description Examples     pwd print the current working directory pwd   cd change to a new directory cd ~/Downloads   ls [options] [pattern] print a listing of the current directory ls; ls -als *.png   rm -rf directory recursively remove a directory and all of its contents rm -rf old-project   cp [-R] source target copy the source file or directory to the target location (file or directory) cp -R project1 archive/projects   mv source target move the source file or directory to the target location (file or directory) mv project1 new-project   mkdir [-pv] [-m mode] new-dir-name create a new directory mkdir project1   rmdir directory_name remove an empty directory rmdir project3    File Commands    Command Description Examples     touch filename create a new file or update the timestamp of an existing file touch project3/app.js   cat filename print the contents of a file cat fruit.txt   more filename display the contents of a file one screenfull at a time (pagination) more bigfile.txt   head [-n] filename print the first n lines of a file (defaults to 10 lines) head big-file.txt   tail [-n] filename print the last n lines of a file (defaults to 10 lines) tail big-file.txt   grep [-i] pattern filename Search a file (or stream of text) for lines matching the specified pattern grep javascript *.md   cp [-R] source target copy the source file to the target location (file or directory) cp monkey.png images/nice-monkey.png   mv source target move the source file or directory to the target location (file or directory) mv monkey.png images/nice-monkey.png   rm filename remove a file rm badfile.txt   chmod mode file_name change file or directory permissions chmod u+x my-script.sh   chown [-R] owner[:group] file_name change file owner and/or group chown lucy lucy-resume.pdf    Utilities and Other Commands    Command Description Examples     env print the environment variables env   history print a list of the previously executed BASH commands for this BASH session. history; history | grep mkdir   whoami display effective user id whoami   hostname display the name of current host system hostname   ping send a set of ICMP packets to a network host; useful for checking network connectivity. ping homedepot.com (use Control+c to break out)   df [-h] display free disk space df -h   man display the manual page for a command (use space to paginate and q to quit) man ls    "
},
{
	"uri": "/software-eng-essentials/git-pillars/unix-commands/",
	"title": "UNIX Shell Commands",
	"tags": [],
	"description": "",
	"content": "Directory Commands    Command Description Examples     pwd print the current working directory pwd   cd change to a new directory cd ~/Downloads   ls [options] [pattern] print a listing of the current directory ls; ls -als *.png   rm -rf directory recursively remove a directory and all of its contents rm -rf old-project   cp [-R] source target copy the source file or directory to the target location (file or directory) cp -R project1 archive/projects   mv source target move the source file or directory to the target location (file or directory) mv project1 new-project   mkdir [-pv] [-m mode] new-dir-name create a new directory mkdir project1   rmdir directory_name remove an empty directory rmdir project3    File Commands    Command Description Examples     touch filename create a new file or update the timestamp of an existing file touch project3/app.js   cat filename print the contents of a file cat fruit.txt   more filename display the contents of a file one screenfull at a time (pagination) more bigfile.txt   head [-n] filename print the first n lines of a file (defaults to 10 lines) head big-file.txt   tail [-n] filename print the last n lines of a file (defaults to 10 lines) tail big-file.txt   grep [-i] pattern filename Search a file (or stream of text) for lines matching the specified pattern grep javascript *.md   cp [-R] source target copy the source file to the target location (file or directory) cp monkey.png images/nice-monkey.png   mv source target move the source file or directory to the target location (file or directory) mv monkey.png images/nice-monkey.png   rm filename remove a file rm badfile.txt   chmod mode file_name change file or directory permissions chmod u+x my-script.sh   chown [-R] owner[:group] file_name change file owner and/or group chown lucy lucy-resume.pdf    Utilities and Other Commands    Command Description Examples     env print the environment variables env   history print a list of the previously executed BASH commands for this BASH session. history; history | grep mkdir   whoami display effective user id whoami   hostname display the name of current host system hostname   ping send a set of ICMP packets to a network host; useful for checking network connectivity. ping homedepot.com (use Control+c to break out)   df [-h] display free disk space df -h   man display the manual page for a command (use space to paginate and q to quit) man ls    "
},
{
	"uri": "/software-eng-essentials/terminal-and-shell/unix-commands/",
	"title": "UNIX Shell Commands",
	"tags": [],
	"description": "",
	"content": "Directory Commands    Command Description Examples     pwd print the current working directory pwd   cd change to a new directory cd ~/Downloads   ls [options] [pattern] print a listing of the current directory ls; ls -als *.png   rm -rf directory recursively remove a directory and all of its contents rm -rf old-project   cp [-R] source target copy the source file or directory to the target location (file or directory) cp -R project1 archive/projects   mv source target move the source file or directory to the target location (file or directory) mv project1 new-project   mkdir [-pv] [-m mode] new-dir-name create a new directory mkdir project1   rmdir directory_name remove an empty directory rmdir project3    File Commands    Command Description Examples     touch filename create a new file or update the timestamp of an existing file touch project3/app.js   cat filename print the contents of a file cat fruit.txt   more filename display the contents of a file one screenfull at a time (pagination) more bigfile.txt   head [-n] filename print the first n lines of a file (defaults to 10 lines) head big-file.txt   tail [-n] filename print the last n lines of a file (defaults to 10 lines) tail big-file.txt   grep [-i] pattern filename Search a file (or stream of text) for lines matching the specified pattern grep javascript *.md   cp [-R] source target copy the source file to the target location (file or directory) cp monkey.png images/nice-monkey.png   mv source target move the source file or directory to the target location (file or directory) mv monkey.png images/nice-monkey.png   rm filename remove a file rm badfile.txt   chmod mode file_name change file or directory permissions chmod u+x my-script.sh   chown [-R] owner[:group] file_name change file owner and/or group chown lucy lucy-resume.pdf    Utilities and Other Commands    Command Description Examples     env print the environment variables env   history print a list of the previously executed BASH commands for this BASH session. history; history | grep mkdir   whoami display effective user id whoami   hostname display the name of current host system hostname   ping send a set of ICMP packets to a network host; useful for checking network connectivity. ping homedepot.com (use Control+c to break out)   df [-h] display free disk space df -h   man display the manual page for a command (use space to paginate and q to quit) man ls    "
},
{
	"uri": "/software-eng-essentials/topic-cheatsheets/cli-cheatsheet/",
	"title": "CLI Cheatsheet",
	"tags": [],
	"description": "",
	"content": "This guide is for users of Mac OS and Windows Powershell. Unless specified, commands apply to usage on both systems.\nCommon Terms    Term Description Mac OS Example Windows Example     absolute paths exact description of the location of a file or directory  /Users/joehacker/documents/project.txt shows the location of the file project.txt C:\\Users\\Joehacker\\Documents\\project.txt shows the location of the file project.txt   relative path description of the location of a file or directory based the current working directory images/vacation.png shows the location of the vacation.png file inside a subdirectory of the current directory. images/vacation.png shows the location of the vacation.png file inside a subdirectory of the current directory.   HOME Directory associated with your login account, this directory contains all your file folders. echo $HOME =\u0026gt; output: User/joehacker echo $HOME =\u0026gt; output: C:\\Users\\Joehacker    Directory Commands    Commands Description     pwd Display the path of the current working directory   cd \u0026lt;directory\u0026gt; Change from current directory to    cd Navigate to HOME directory   cd .. Navigate to the parent directory   ls List the directory contents   ls -la (MacOS) List detailed directory contents, including hidden files   ls -Hidden (Windows)  List detailed directory contents, including hidden files    mkdir \u0026lt;directory\u0026gt; Create a new directory with name \u0026lt;directory\u0026gt;   rmdir \u0026lt;directory\u0026gt; Removes empty directory with name\u0026lt;directory\u0026gt;   rm -r \u0026lt;directory\u0026gt; Removes directory with name \u0026lt;directory\u0026gt; and it’s contents    File Commands    Commands Description     touch \u0026lt;file\u0026gt; (Mac OS) Creates \u0026lt;file\u0026gt; if it doesn’t exist; update file access and modification time   New-Item . -N \\\u0026lt;file\\\u0026gt; (Wndows) Creates \u0026lt;file\u0026gt; if it doesn’t exist; update file access and modification time   rm \u0026lt;file\u0026gt; Deletes \u0026lt;file\u0026gt;   rm -f \u0026lt;file\u0026gt; Forces deletion of \u0026lt;file\u0026gt;   mv \u0026lt;old-file\u0026gt; \u0026lt;new-file\u0026gt; Renames \u0026lt;old-file\u0026gt; to \u0026lt;new-file\u0026gt;   mv \u0026lt;file\u0026gt; \u0026lt;directory\u0026gt; Moves \u0026lt;file\u0026gt; to \u0026lt;directory\u0026gt; (may create or overwrite existing file of same name)   cp \u0026lt;file\u0026gt; \u0026lt;directory\u0026gt; Copies \u0026lt;file\u0026gt; to \u0026lt;directory\u0026gt; (may create or overwrite existing file of same name)   cp -r \u0026lt;directory-a\u0026gt; \u0026lt;directory-b\u0026gt; Copies \u0026lt;directory-a\u0026gt; and it’s contents to \u0026lt;directory-b\u0026gt; (may create or overwrite existing files in directory-b)    Output Commands    Commands Description     cat \u0026lt;file\u0026gt; Outputs the contents of \u0026lt;file\u0026gt;   less \u0026lt;file\u0026gt; Outputs the contents of \u0026lt;file\u0026gt; and allows pagination   head \u0026lt;file\u0026gt; Outputs the first 10 lines of \u0026lt;file\u0026gt;   \u0026lt;cmd\u0026gt; \u0026gt; \u0026lt;file\u0026gt; Redirects the output of \u0026lt;cmd\u0026gt; into \u0026lt;file\u0026gt; , i.e. echo \u0026quot;hello\u0026quot; \u0026gt; hello.txt. Overwrites the contents of \u0026lt;file\u0026gt;   \u0026lt;cmd\u0026gt; \u0026gt;\u0026gt; \u0026lt;file\u0026gt; Appends the output of \u0026lt;cmd\u0026gt; to \u0026lt;file\u0026gt;   \u0026lt;cmd-a\u0026gt; || \u0026lt;cmd-b\u0026gt; Directs the output of \u0026lt;cmd-a\u0026gt; to \u0026lt;cmd-b\u0026gt;    Search Commands    Command Description     find \u0026lt;directory\u0026gt; -name \u0026lt;file\u0026gt; (MacOS) Find all files named \u0026lt;file\u0026gt; inside \u0026lt;directory\u0026gt;   grep \u0026quot;\u0026lt;text\u0026gt;\u0026quot; \u0026lt;file\u0026gt; (MacOS) Output all occurences of \u0026lt;text\u0026gt; inside \u0026lt;file\u0026gt;   grep -rl \u0026quot;\u0026lt;text\u0026gt;\u0026quot; \u0026lt;dir\u0026gt; (MacOS) search for all the files containing \u0026lt;text\u0026gt; inside \u0026lt;dir\u0026gt;   Select-String -Pattern \u0026lt;PATTERM\u0026gt; -Path \u0026lt;PATH\u0026gt; (Windows) search for all files matching in the given     Network    Command Description     curl \u0026lt;urloffile\u0026gt; Download file via FTP or HTTP   ping \u0026lt;host\u0026gt; Send ping to host and dispay status    Help    Command Description     man \u0026lt;cmd\u0026gt; Displays detailed documentation about\\ \u0026lt;cmd\u0026gt;   \u0026lt;cmd\u0026gt; --help (Mac OS) Displays summary information about \u0026lt;cmd\u0026gt; (may not work for all commands)   Get-Help \u0026lt;cmd\u0026gt; (Windows) Displays summary information about\\ \u0026lt;cmd\u0026gt;    Keyboard Shortcuts    Command Description     \u0026lt;cmd-a\u0026gt; ; \u0026lt;cmd-b\u0026gt;; \u0026lt;cmd-c\u0026gt; Allow commands to run without needing to wait for each to finish before typing the next one.   cd ~ ~ is a shortcut for home and can be used for navigating the file system from the starting point of $HOME.   TAB allows for auto completion of file and directory names   ▲ ▼ allows you to scroll through the previous commands entered    Mac OS Command Prompt Shortcuts    Command Description     control + a Moves the caret to the beginning of the command being typed   control + e Moves the caret to the end of the command being typed   control + w Deletes the individual words before the caret   control + k Deletes all the characters that follow the current position of the caret   control + u Deletes all the characters that precede the current position of the caret   control + c Cancels the current running command   control + l clears the terminal screen (similar to typing clear)    "
},
{
	"uri": "/software-eng-essentials/topic-cheatsheets/git-cli-cheatsheet/",
	"title": "Git CLI Cheatsheet",
	"tags": [],
	"description": "",
	"content": "Resource Github Education Cheat Sheet\nCommon Terms    Term Description     Git Version control system that lets you manage and keep track of your source code history   Github A cloud-based hosting service that lets you manage Git repositories   Repository (Repo) Repository tracks all changes made to files in your project, building a history over time in the .git directory of the project folder.    Setup Commands    Command Description     git config --global user.name “[firstname lastname]” Set a name that is identifiable for credit when reviewing version history   git config --global user.email “[valid-email]”  Set an email address that will be associated with each history marker   git config --global color.ui auto Set automatic command line coloring for Git for easy reviewing    Creating a Repo    Command Description     git init Initialize an existing directory as a Git repository   git clone [url] Retrieve an entire repository from a hosted location via URL    Stage and Snapshot    Command Description     git status Show modified files in working directory, staged for your next commit   git add [file] Add a file as it looks now to your next commit (stage)   git reset [file] Unstage a file while retaining the changes in working directory   git diff Diff of what is changed but not staged   git commit -m \u0026quot;[descriptive message]\u0026quot; Commit your staged content as a new commit snapshot    Branching and Merging    Command Description     git branch List your branches. a ***** will appear next to the currently active branch   git branch [branch-name] Create a new branch at the current commit   git checkout Switch to a another branch and check it our into your working directory   git merge [branch-name] Merge the specified branch’s history into the current one   git log Show all commits in the current branch’s history    Sharing and Updating    Command Description     git remote add [alias] [url] Add a git URL as an alias   git fetch [alias] Fetch down all the branches from that Git remote   git merge [alias]/[branch] Merge a remote branch into your current branch to bring it up to date   git push [alias] [branch] Transmit local branch commits to the remote repository branch   git pull Fetch and merge any commits from the tracking remote branch    Rewriting History (use with caution)    Command Description     git reset --hard [commit] clear staging area, rewrite working tree from specified commit   git reset --soft [commit] Clear staging area, keeps work in working tree and resets head to [commit]    Temporary Commits    Command Description     git stash Save modified and staged changes   git stash list List stack-order of stashed file changes   git stash pop Write working from top of stash stack   git stash drop Discard the changes from top of stash stack    "
},
{
	"uri": "/react/foundations/labs/lab-budget-app/",
	"title": "Budget App",
	"tags": [],
	"description": "",
	"content": "A lab for working with components, props, state, and events.\nPart 1: Setup Let\u0026rsquo;s start by spinning up a react app and creating our first component.\n Use create-react-app to create an application for managing a budget Name the app something like budget-app Edit the App component to the following:  import React from \u0026#39;react\u0026#39;; import \u0026#39;./App.css\u0026#39;; function App() { return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;Balance: $100.00\u0026lt;/h3\u0026gt; \u0026lt;div className=\u0026#39;newTransactions\u0026#39;\u0026gt; \u0026lt;label\u0026gt; Transaction \u0026lt;/label\u0026gt; \u0026lt;input /\u0026gt; \u0026lt;br /\u0026gt; \u0026lt;button\u0026gt;Debit\u0026lt;/button\u0026gt; \u0026lt;button\u0026gt;Deposit\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } export default App;  Expected Result:\nStep 2 - Add State  Let\u0026rsquo;s add a current balance and then render the balance dynamically. Use the useState hook to add a currentBalance state variable with an initial value of 100.01.  You should have a variable named currentBalance and a setter function named setCurrentBalance.   Edit the \u0026lt;h3\u0026gt; tag to display the message: The account balance is: $${currentBalance}.  Expected Result:\nStep 3 - List transactions  Using the useState hook, create a state variable for your transactions.   You should have a variable named transactions and a setter function named setTransactions. Initialize the transactions array with the following data:  const initialTransactions = [ { id: 1, name: \u0026#39;lunch\u0026#39;, amount: 7.06, transactionType: \u0026#39;debit\u0026#39; }, { id: 2, name: \u0026#39;Home Depot purchase\u0026#39;, amount: 83.96, transactionType: \u0026#39;debit\u0026#39; }, { id: 3, name: \u0026#39;yard sell\u0026#39;, amount: 340.00, transactionType: \u0026#39;deposit\u0026#39; } ] Render each transaction within a div:   Use Array.map to create a new array of JSX expressions from the transactions state variable The new array should return a div with a class name of transactions that renders the message {transaction.transactionType} of ${transaction.amount} for {transaction.name}. Example: debit of $83.96 for Home Depot purchase.  Render the array of transaction divs under the text input.   NOTE: remember to use a key in your JSX Expressions array.\n Expected Result:\nStep 4 - Updating State  Use the useState hook to add a newTransaction object to your component\u0026rsquo;s state with the following initial value:  { name: \u0026#39;\u0026#39;, amount: 0.00, transaction: \u0026#39;\u0026#39; } Change the text of Add a transaction (inside of your \u0026lt;label\u0026gt;) to Name Add another label and input. The label should contain the text Amount  Expected Result:\nState Handler\u0026rsquo;s Lab 5 - New Transactions  Write a function for updating the transaction name Pass the appropriate values to the transaction name input Write a function for updating the transaction amount Pass the appropriate values to the transaction amount input Add the following function to your App Component to handle updating your balance and adding the new transaction to your transactions array  transactionClick = (event) =\u0026gt; { let currentBalance = this.state.currentBalance let newTransaction = Object.assign({}, this.state.newTransaction) let transactions = this.state.transactions.slice() newTransaction.transactionType = event.target.className newTransaction.id = transactions.length transactions.push(newTransaction) if (newTransaction.transactionType === \u0026#39;deposit\u0026#39;) { currentBalance += newTransaction.amount } else { currentBalance -= newTransaction.amount } newTransaction = { name: \u0026#39;\u0026#39;, amount: \u0026#39;\u0026#39;, transactionType: \u0026#39;\u0026#39; } this.setState({ currentBalance, newTransaction, transactions }) } The Result image::/react/budget-app-5.png[alt]\nProps Component Hierarchy This is great! we have a functional budgeting application that records Deposits and Debits, while always showing the current balance. While we could make this more robust, now would be a good time to refactor as our component is becoming tough to reason about\nFor example, we could move our newTransaction element into a separate component and then render it as a child of App. Similarly, we can move transactions into a separate component as well.\nLet\u0026rsquo;s start with newTransaction\nLab 6 - \u0026lt;NewTransaction/\u0026gt;  Read link:https://medium.freecodecamp.com/react-props-state-explained-through-darth-vaders-hunt-for-the-rebels-8ee486576492[this explanation] of State and Props.  Then\u0026hellip;\n create 2 new files ** newTransaction.js (to be used now) ** transaction.js (to be used later) extract the entire newTransaction div from the App component Then create a new component in newTransaction.js paste in the data comment out (or temporarily delete) the div containing {transactions}  Then\u0026hellip;\n Navigate Back to App.js Import your NewTransaction component Make a call to render NewTransaction in place of the extracted code  Then \u0026hellip;\n Pass this.state.newTransaction as a prop to your NewTransaction component Pass the functions (in App.js) down as props Refactor the NewTransaction elements to use props  ** Utilize the props in the NewTransaction component\nIf you create a new transaction and inspect with the React Dev Tools, you should see something similar to:\nimage::/react/NewTransactionProps.png[alt]\nLab 7 \u0026lt;Transaction\u0026gt; Now, we\u0026rsquo;re going to want to a create a Transaction component.\nWhy?\nBecause, each transaction has the same properties\n name amount transactionType id  So why not just move the configuration to a child (presentational) component and pass down the state as a prop?\n uncomment the div containing {transactions} (in newTransaction.js) Create a new component named Transaction Back in App.js you\u0026rsquo;ll want to modify the return value of the transactions array\u0026hellip; ** Move the return value (of the transactions array) into the Transaction component (transaction.js) ** Update the return value of transactions (in App.js) to return a \u0026lt;Transaction/\u0026gt; component ** Pass the transactions object (from the state) down as a prop (still in App.js) Update the body of the Transaction component to use the props (in transaction.js)  Props and immutability Once complete, open the React Dev Tools and watch the state (of App.js) update each time you change the input!\nYou should be able visualize the data always flowing in 1 direction.\nThough it would seem like we\u0026rsquo;re changing the props, we\u0026rsquo;re actually running everything from the parent component.\n Parent Component passes state down as a prop When an action happens on a child component, the event (and data) is passed back to the parent The Parent then updates it\u0026rsquo;s state and passes the new data back down to the child components.  It\u0026rsquo;s worth noting that a component\u0026rsquo;s state should be considered as private\n[IMPORTANT] State is managed internally by the component.\nMeaning, the NewTransaction component cannot modify the App component\u0026rsquo;s state. All changes to App \u0026rsquo;s state must come from within the App component.\nMake things even more compose-able There is one more option to refactor, can you see it?\nOur NewTransaction has code that can be broken into smaller more manageable components.\nThe label and input \u0026rsquo;s can be moved into a component named TransactionInput that takes a prop defining the label name, value, input type, etc.\nThe button\u0026rsquo;s can also be turned into a component that receive className, click handler, and value props.\nLab 8 - \u0026lt;TransactionInput\u0026gt; and \u0026lt;Button\u0026gt;  Create 2 new files ** transactionInput.js ** button.js Inside of your TransactionInput component pass the following props ** label - displays the value of the label (on the DOM) for the user ** transactionValue - the value of the actual input ** stateHandler - the particular function that you want to run onChange ** type - define the type of input (ie: text, number, email, etc.)  Then\u0026hellip;\n Inside of your Button component pass the following props ** className - simple enough (the name of the class) ** clickHandler - function to run when the button is clicked ** buttonText - text that will displayed inside of the button  "
},
{
	"uri": "/javascript/foundations/labs/",
	"title": "Labs",
	"tags": [],
	"description": "",
	"content": "Welcome to the Labs for JavaScript Foundations! "
},
{
	"uri": "/react/foundations/labs/",
	"title": "Labs",
	"tags": [],
	"description": "",
	"content": "Welcome to the Labs for React Foundations! "
},
{
	"uri": "/react/foundations/misc/",
	"title": "Misc",
	"tags": [],
	"description": "",
	"content": "React Foundations Misc Stuff "
},
{
	"uri": "/react/foundations/solutions/",
	"title": "Solutions",
	"tags": [],
	"description": "",
	"content": "React Foundations Solutions to Labs "
},
{
	"uri": "/react/foundations/cheatsheets/",
	"title": "Cheatsheets",
	"tags": [],
	"description": "",
	"content": "Welcome to React Cheatsheets!  React  "
},
{
	"uri": "/javascript/foundations/cheatsheets/",
	"title": "Fact Sheets",
	"tags": [],
	"description": "",
	"content": "Welcome to the Fact Sheets for JavaScript Foundations! "
},
{
	"uri": "/_footer/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/placeholder/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/software-eng-essentials/command-line-bash/playground/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/web-essentials/webmastery-foundations/solutions/frameworks-lab-with-answers/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Skills  How to install bootstrap on your project Become familiar with bootstrap documentation Build websites with ease  HTML - The Structure This is a paired exercise, feel free to work at your own pace with your partner. The instructor will explain things as you progress through the lab. Make git commits along the way and switch halfway through the lab.\nStarting with what we know.   Create your html document\n At the top of the \u0026lt;body\u0026gt; wrap an \u0026lt;h1\u0026gt; in a \u0026lt;div\u0026gt; and insert the content \u0026lsquo;Good Coffee Co.\u0026rsquo; Create another \u0026lt;div\u0026gt; and with class titled: \u0026lsquo;mission\u0026rsquo;  Create an \u0026lt;h3\u0026gt; and insert: + \u0026quot;Here at Good Coffee Co we are passionate about serving the best coffee you'll ever taste. Our staff are self-described coffee-nerds with impeccable technique. Stop by today and experience the Good Coffee difference.\u0026quot;      Create a new \u0026lt;div\u0026gt; with a class named: \u0026lsquo;features\u0026rsquo;\n Create 3 separate paragraphs Inside those paragraphs place the following text: + \u0026quot;The freshest locally sourced coffee. Organic and Fair Trade certified.\u0026quot; + \u0026quot;A perfect environment to meet with a friend or be alone and get things done.\u0026quot; + \u0026quot;Quality hand-crafted espresso shots pulled with the greatest of care.\u0026quot;    Your page should look like this: \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Good Coffee\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div \u0026gt; \u0026lt;h1\u0026gt; Good Coffee Co.\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;mission\u0026#34;\u0026gt; \u0026lt;h3\u0026gt; Here at Good Coffee Co we are passionate about serving the best coffee you\u0026#39;ll ever taste. \u0026lt;br\u0026gt; Our staff are self-described coffee-nerds with impeccable technique. \u0026lt;br\u0026gt; Stop by today and experience the Good Coffee difference. \u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;features\u0026#34;\u0026gt; \u0026lt;p\u0026gt; The freshest locally sourced coffee. Organic and Fair Trade certified\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; A perfect environment to meet with a friend or be alone and get work done.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; Quality hand-crafted espresso shots pulled with the greatest of care.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; The Footer Okay, let\u0026rsquo;s go ahead and put in the text for the footer as well.\n  Create a \u0026lt;footer\u0026gt;\n  Nest a \u0026lt;p\u0026gt; element in the \u0026lt;footer\u0026gt;\n Insert a copyright symbol Add the text: + \u0026quot;Good Coffee Co. 2017\u0026quot;    Nest an unordered list inside the \u0026lt;footer\u0026gt;\n Give the list 3 list items About Location Coffee Turn those list items into links (hint: point the link to a \u0026ldquo;#\u0026quot;)    Close out the \u0026lt;footer\u0026gt; and refresh!\n Result:**     \u0026lt;footer\u0026gt; \u0026lt;p\u0026gt;\u0026amp;copy; Good Coffee Co. 2015\u0026lt;/p\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;About\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Location\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Coffee\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/footer\u0026gt; Okay! we\u0026rsquo;re well on our way to having a great site. The last bit of structure that we need is a navbar.\nThe Navbar  At the top of the \u0026lt;body\u0026gt; create a \u0026lt;nav\u0026gt; element. The nav is an HTML 5 element that functions exactly like an unordered list. It mainly serves as an accessibility feature for screen readers. Additionaly, it helps the developer with code-readability Like you did with the \u0026lt;footer\u0026gt;, you\u0026rsquo;ll want to create an underderd list and nest the following list items:   Coffee\n  Mission\n  Fair Trade\n  Coffee Gear\n  The Result:**\n    \u0026gt; If you didn\u0026rsquo;t include the links, don\u0026rsquo;t worry about it. We\u0026rsquo;ll be modifying the navbar pretty significantly in just a few minutes.\n\u0026lt;nav\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Coffee\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Mission\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Fair Trade\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Coffee Gear\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/nav\u0026gt; And that\u0026rsquo;s it! We are done with the structure. Now we can install bootstrap and start styling the page.\nSetting up Bootstrap Okay, so we\u0026rsquo;ve briefly discussed what bootstrap is and what it does, but how do we install it into our project?\nWell\u0026hellip; that\u0026rsquo;s for you to figure out\u0026hellip;\nAdd Bootstrap to your project There are several ways to include bootstrap in your project. Which one is correct? Well\u0026hellip; it depends on the project. We are going to use a CDN (content delivery network) which is my preferred method and will work fine for this project.\n Go the getting started section of the bootsrap documentation. Review the Bootstrap CDN section and take the appropriate actions  \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;!-- Latest compiled and minified CSS --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css\u0026#34; integrity=\u0026#34;sha512-dTfge/zgoMYpP7QbHy4gWMEGsbsdZeCXz7irItjcC3sPUFtf0kuFbDz/ixG7ArTxmDjLXDmezHubeNikyKGVyQ==\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Good Coffee\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; Let\u0026rsquo;s go ahead and install JavaScript as well.Below your \u0026lt;footer\u0026gt; paste the following:\n\u0026lt;!-- Latest jQuery (without OldIE support--\u0026gt; \u0026lt;script src=\u0026#34;https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Latest compiled and minified JavaScript --\u0026gt; \u0026lt;script src=\u0026#34;https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js\u0026#34; integrity=\u0026#34;sha512-K1qjQ+NcF2TYO/eI3M6v8EiNYZfA95pQumfvcVrTHtwQVDG+aHRqLi/ETn2uB+1JqwYqVG3LIvdm9lj6imS/pQ==\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Add your own stylesheet One more thing\u0026hellip; this doesn\u0026rsquo;t necessarily relate to bootstrap, but let\u0026rsquo;s go ahead and create our main stylesheet (for custom styling). And you know how we roll, so go ahead and do all of this from the command line.\nfrom your project directory, create a new css directory\n$ mkdir css navigate to the directory\n$ cd css create the file\n$ touch main.css navigate back to the root of your project\n$ cd .. Now link the file to your index.html\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/main.css\u0026#34; media=\u0026#34;screen\u0026#34; title=\u0026#34;no title\u0026#34; charset=\u0026#34;utf-8\u0026#34;\u0026gt; Make sure you place this after the bootstrap link\nNow that we have everything setup, go ahead and refresh your page.\nYou\u0026rsquo;ll notice that our page has been \u0026lsquo;normalized\u0026rsquo; (or reset). A browser reset is baked into bootstrap. yay!\nNav - the bootstrap way Okay\u0026hellip; that navbar has to change\u0026hellip; like\u0026hellip; now\u0026hellip; So, let\u0026rsquo;s do that.\nInstall the navbar  Go to the navbar section of bootstrap\u0026rsquo;s documentation. READ Start with applying the basic navbar to our site. + (Don\u0026rsquo;t worry about the content right now)  Here\u0026rsquo;s what it should look like: Nothing magical here. All you have to do is copy and paste directly from the boostrap site. Now let\u0026rsquo;s add our custom links and make some slight modifications.\nCustomize the navbar   Find and change \u0026lsquo;Brand\u0026rsquo; to the name of the company\n  Find and replace the two \u0026lsquo;Links\u0026rsquo; on the left with:\n Coffee Mission Refresh here\u0026rsquo;s what you should have:     Now, remove the left dropdown menu and \u0026lt;form\u0026gt; (search bar and submit button)\n  modify the items on the right to say:\n Fair Trade Coffee Gear    Invert the color\n The Result:**     \u0026lt;body\u0026gt; \u0026lt;nav class=\u0026#34;navbar navbar-inverse\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;container-fluid\u0026#34;\u0026gt; \u0026lt;!-- Brand and toggle get grouped for better mobile display --\u0026gt; \u0026lt;div class=\u0026#34;navbar-header\u0026#34;\u0026gt; \u0026lt;button type=\u0026#34;button\u0026#34; class=\u0026#34;navbar-toggle collapsed\u0026#34; data-toggle=\u0026#34;collapse\u0026#34; data-target=\u0026#34;#bs-example-navbar-collapse-1\u0026#34; aria-expanded=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;sr-only\u0026#34;\u0026gt;Toggle navigation\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;icon-bar\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;icon-bar\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;icon-bar\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;a class=\u0026#34;navbar-brand\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;Good Coffee\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Collect the nav links, forms, and other content for toggling --\u0026gt; \u0026lt;div class=\u0026#34;collapse navbar-collapse\u0026#34; id=\u0026#34;bs-example-navbar-collapse-1\u0026#34;\u0026gt; \u0026lt;ul class=\u0026#34;nav navbar-nav\u0026#34;\u0026gt; \u0026lt;li class=\u0026#34;active\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Coffee \u0026lt;span class=\u0026#34;sr-only\u0026#34;\u0026gt;(current)\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Mission\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ul class=\u0026#34;nav navbar-nav navbar-right\u0026#34;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Fair Trade\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;dropdown\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;dropdown-toggle\u0026#34; data-toggle=\u0026#34;dropdown\u0026#34; role=\u0026#34;button\u0026#34; aria-haspopup=\u0026#34;true\u0026#34; aria-expanded=\u0026#34;false\u0026#34;\u0026gt;Coffee Gear \u0026lt;span class=\u0026#34;caret\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;ul class=\u0026#34;dropdown-menu\u0026#34;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Action\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Another action\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Something else here\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li role=\u0026#34;separator\u0026#34; class=\u0026#34;divider\u0026#34;\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Separated link\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- /.navbar-collapse --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- /.container-fluid --\u0026gt; \u0026lt;/nav\u0026gt; Go ahead and delete the original nav (as we no longer need it).\nFont and Color Font The instructor team has already picked out a font from google fonts, so let\u0026rsquo;s go ahead and add that into our project\nIn the \u0026lt;head\t\u0026gt; of your html document, paste the following:\nindex.html\n\u0026lt;!-- font family below --\u0026gt; \u0026lt;link href=\u0026#34;http://fonts.googleapis.com/css?family=Muli|Raleway:400,500,700|Yanone+Kaffeesatz\u0026#34; rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34;\u0026gt; body { font-family: \u0026#39;Raleway\u0026#39;, \u0026#39;sans-serif\u0026#39;; } Color Scheme The instructor team has also picked out a color scheme (feel free to change it up)\nWe\u0026rsquo;ll be using #A2DED0 as our primary color. + #323232 and #D64541 will be our secondary colors.\nGo ahead and apply the primary color to the background of our \u0026lt;body\u0026gt;.\nbackground-color: #A2DED0;\nOkay, it\u0026rsquo;s already starting to feel better. Next up. the hero image!\nJumbotron If you look at most well-designed websites, you\u0026rsquo;ll see some kind of hero image and/or captivating header at the top of the page. This is often called a hero image. In bootstrap we\u0026rsquo;ll use the .jumbotron class to style our hero image.\nFirst let\u0026rsquo;s start with a picture. You can use this URL and link to it directly in your CSS. Or create an images directory and store the image there. + the second option is preferred.\nHero Image Add your hero image  Just like we created the css directory. Create an images directory Assign the class \u0026quot;jumbotron\u0026quot; to the \u0026lt;div\u0026gt; surrounding your \u0026lt;h1\u0026gt; In your css, use the background-image property to display the hero image. (hint: use css documentation if you need help with the background image)  From your project root run: $ mkdir images\nindex.html\n\u0026lt;div class=\u0026#34;jumbotron\u0026#34;\u0026gt; \u0026lt;h1\u0026gt; Good Coffee Co.\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; .jumbotron { background-image: url(\u0026#34;./images/Drip_Coffee_Bangkok.jpg\u0026#34;); } If you refresh\u0026hellip; it isn\u0026rsquo;t pretty. let\u0026rsquo;s fix that.\nStyle your hero image   For the image\u0026hellip; within the .jumbotron declaration:\n set the background-repeat to no-repeat set the background-size to cover assign a width of 100%    Position the image\n draw the top margin up by 40px padding (on all sides) = 20% background-attachment = fixed background-position = center -238px Save and Refresh! At this point, your page should should look like:     Now we need to style the \u0026lt;h1\u0026gt;\n set the position to absolute move it 0 left assign a top margin of -10px assign left padding of 20px give the font a color of #F7FAFE Save and refresh!    You should have something like this:\n.jumbotron { background-image: url(\u0026#34;./images/Drip_Coffee_Bangkok.jpg\u0026#34;); padding: 20%; background-repeat: no-repeat; background-size: cover; width: 100%; margin-top: -40px; background-attachment: fixed; background-position: center -238px; } .jumbotron h1 { position: absolute; left:0; margin-top: -10px; padding-left: 20px; color: #F7FAFE; } Containers Let\u0026rsquo;s talk about containers for a moment. + With most web design, you\u0026rsquo;re going to want to establish very clear containers for groups of elements. \u0026lt;div\u0026gt;'s serve for this purpose. However, what about when you want to group a set of \u0026lt;div\u0026gt;'s together?\nYour best bet is to establish a container \u0026lt;div\u0026gt;\nSo, we\u0026rsquo;re going to create a some containers.\ncontainer-fluid  Add a class of \u0026lsquo;container-fluid\u0026rsquo; to your \u0026lsquo;mission\u0026rsquo; \u0026lt;div\u0026gt; Nest a \u0026lt;div\u0026gt; with the class of \u0026lsquo;row\u0026rsquo; Move your \u0026lt;h3\u0026gt; inside of the \u0026lsquo;row\u0026rsquo; \u0026lt;div\u0026gt; above your \u0026lt;h3\u0026gt; paste the following code \u0026lt;a name=\u0026quot;mission\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; + (this allows us to navigate around the page) Style the mission \u0026lt;div\u0026gt;!  Set the background color to #323232 Set the text color to #F7FAFE Move the top margin up by 30px   Specifically style the \u0026lt;h3\u0026gt;   set a padding of 5% top/bottom and 10% left/right\n  center the text\n  The Result:**\n    index.html\n\u0026lt;div class=\u0026#34;mission container-fluid\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;a name=\u0026#34;mission\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;h3\u0026gt; Here at Good Coffee Co we are passionate about serving the best coffee you\u0026#39;ll ever taste. \u0026lt;br\u0026gt; Our staff are self-described coffee-nerds with impeccable technique. \u0026lt;br\u0026gt; Stop by today and experience the Good Coffee difference. \u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; .mission { background-color: #323232; color: #F7FAFE; margin-top: 30px; } .mission h3 { padding: 5% 10% ; text-align: center; } Next up the Grid!\nThe Grid As previously discussed, one of the best features of using front-end frameworks is the grid system. Grid\u0026rsquo;s allow for much easier positioning than working with standard css positioning.\nTo recap: Divide the page into 12 columns. and then move content along those columns. This makes laying out your content incredibly simple (and helps with responsive design). So it\u0026rsquo;s a win-win.\nSetting up your grid Using the Boostrap Grid Documentation\n Add the container class to your features \u0026lt;div\u0026gt; Wrap each \u0026lt;p\u0026gt; in it\u0026rsquo;s own \u0026lt;div\u0026gt; Nest your new \u0026lt;div\u0026gt;'s within a row \u0026lt;div\u0026gt; Using bootstrap\u0026rsquo;s grid. make each \u0026lt;div\u0026gt; (within the row) span:   12 columns on extra small devices.\n  4 columns on small devices (and up)\n  The Result:**\n    \u0026lt;div class=\u0026#34;container features\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-sm-4\u0026#34;\u0026gt; \u0026lt;p\u0026gt; The freshest locally sourced coffee. Organic and Fair Trade certified\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-sm-4\u0026#34;\u0026gt; \u0026lt;p\u0026gt; A perfect environment to meet with a friend or be alone and get work done.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-sm-4\u0026#34;\u0026gt; \u0026lt;p\u0026gt; Quality hand-crafted espresso shots pulled with the greatest of care.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; We\u0026rsquo;re getting there!\nFeature Images  Add the following pictures to your images folder  coffee beans +  coffee_shop +  espresso +  In the html, create an \u0026lt;img\u0026gt; tag for each div (containing a paragraph) and change src attribute to display your new images. Save and refresh    image-responsive Got it?\nYeah\u0026hellip; it\u0026rsquo;s bad\u0026hellip; real bad\u0026hellip; the images are being displayed at their stock resolution. Thankfully, bootstrap offers a class that easily fixes this to make the images respond to the grid.\nsimply assign the class \u0026lsquo;img-responsive\u0026rsquo; to your \u0026lt;img\u0026gt; element like so: \u0026lt;img class=\u0026quot;img-reponsive\u0026quot;\u0026gt;\n\u0026lt;div class=\u0026#34;container features\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-sm-4\u0026#34;\u0026gt; \u0026lt;img class=\u0026#34;img-responsive\u0026#34; src=\u0026#34;images/coffee_beans.jpg\u0026#34; alt=\u0026#34;coffee beans\u0026#34; /\u0026gt; \u0026lt;p\u0026gt; The freshest locally sourced coffee. Organic and Fair Trade certified\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-sm-4\u0026#34;\u0026gt; \u0026lt;img class=\u0026#34;img-responsive\u0026#34; src=\u0026#34;images/coffee_shop.jpg\u0026#34; alt=\u0026#34;coffee shop\u0026#34; /\u0026gt; \u0026lt;p\u0026gt; A perfect environment to meet with a friend or be alone and get work done.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-sm-4\u0026#34;\u0026gt; \u0026lt;img class=\u0026#34;img-responsive\u0026#34; src=\u0026#34;images/espresso.jpg\u0026#34; alt=\u0026#34;espresso\u0026#34;\u0026gt; \u0026lt;p\u0026gt; Quality hand-crafted espresso shots pulled with the greatest of care.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Afterwards. Your page should look like this:\nStyle the containers Nice! Now we just need to add a touch of styling and this container is good-to-go!\n Set the features\u0026rsquo; container padding to 5% top/bottom and 0 left/right For the paragraphs:  Change the font to \u0026lsquo;Muli\u0026rsquo; with a fallback of \u0026lsquo;sans-serif\u0026rsquo; align the text to center set the font size to 1.2em give a top padding of 10px change the color to #323232   Save and refresh  You should see something like this:\n.features { padding: 5% 0; } .features p { font-family: \u0026#39;Muli\u0026#39; \u0026#39;sans-serif\u0026#39;; text-align: center; color: #323232; font-size: 1.2em; padding-top: 10px; } The Footer Unlike most of our other items. The majority of our footer work is going to be completed using vanilla css. Ugh! I know\u0026hellip;\nPosition and Color   Set the background color to: #D64541\n  Set a position of absolute\n  width = 100%\n  set the height to auto (to take care of unforseen viewport issues) +   Style each list item\n Set the display to inline-block strip the bullets off of each list item set a padding of 2% all-around float these items to the right +     Float each paragraph left and give a padding of 2%\n  For the links and paragraphs\n set the vertical alignment to middle change the text-color to #fff    Save and refresh!\n The Result:**    footer p { float: left; padding: 2%; } footer a, footer p { color:#fff; vertical-align: middle; } That\u0026rsquo;s it! you\u0026rsquo;ve created a site using bootstrap!\nExtra Credit Animate!   Go checkout animate.css\n  Download the file and move it into your project (place it inside the css directory)\n  link your index.html to the new stylesheet (make sure to place it under your main.css link)\n  add the value \u0026lsquo;animated fadeInDown\u0026rsquo; to your \u0026lt;h1\u0026gt;\n The Code:**    to link:\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/animate.css\u0026#34; media=\u0026#34;screen\u0026#34; title=\u0026#34;no title\u0026#34; charset=\u0026#34;utf-8\u0026#34;\u0026gt; to implement:\n\u0026lt;div class=\u0026#34;jumbotron\u0026#34;\u0026gt; \u0026lt;h1 class=\u0026#34;animated fadeInDown\u0026#34;\u0026gt; Good Coffee Co.\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; Modal  Check out the modal section in Bootstrap\u0026rsquo;s docs. Inside your navbar, paste the appropriate modal code after your \u0026lsquo;Fair Trade\u0026rsquo; \u0026lt;li\u0026gt; Change the id from myModal to videoModal In your Fair Trade\u0026lt;li\u0026gt;  Create a data-toggle attribute with the value of \u0026ldquo;modal\u0026rdquo; Crate a data-target attribute with the value of \u0026ldquo;#videoModal\u0026rdquo;   Remove the title, button and footer Inside the modal body place the following code: \u0026lt;iframe width=\u0026quot;100%\u0026quot; height=\u0026quot;350\u0026quot;src=\u0026quot;http://www.youtube.com/embed/7K4G5-ydhS0\u0026quot;\u0026gt;\u0026lt;/iframe\u0026gt; Add some comments above and below your modal (signifying start and end) for better readability.  That\u0026rsquo;s it! now you should have a fancy Fair Trade modal.\n The Code:**  \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34; data-toggle=\u0026#34;modal\u0026#34; data-target=\u0026#34;#videoModal\u0026#34;\u0026gt;Fair Trade\u0026lt;/a\u0026gt; \u0026lt;!-- BEGIN Modal --\u0026gt; \u0026lt;div class=\u0026#34;modal fade\u0026#34; id=\u0026#34;videoModal\u0026#34; tabindex=\u0026#34;-1\u0026#34; role=\u0026#34;dialog\u0026#34; aria-labelledby=\u0026#34;videoModalLabel\u0026#34; aria-hidden=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;modal-dialog\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;modal-content\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;modal-body\u0026#34;\u0026gt; \u0026lt;iframe width=\u0026#34;100%\u0026#34; height=\u0026#34;350\u0026#34; src=\u0026#34;http://www.youtube.com/embed/7K4G5-ydhS0\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;!-- END MODAL --\u0026gt;  Final html**  index.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;!-- Latest compiled and minified CSS --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css\u0026#34; integrity=\u0026#34;sha512-dTfge/zgoMYpP7QbHy4gWMEGsbsdZeCXz7irItjcC3sPUFtf0kuFbDz/ixG7ArTxmDjLXDmezHubeNikyKGVyQ==\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;!-- font family below --\u0026gt; \u0026lt;link href=\u0026#34;http://fonts.googleapis.com/css?family=Muli|Raleway:400,500,700|Yanone+Kaffeesatz\u0026#34; rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/main.css\u0026#34; media=\u0026#34;screen\u0026#34; title=\u0026#34;no title\u0026#34; charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/animate.css\u0026#34; media=\u0026#34;screen\u0026#34; title=\u0026#34;no title\u0026#34; charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Good Coffee\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;nav class=\u0026#34;navbar navbar-inverse\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;container-fluid\u0026#34;\u0026gt; \u0026lt;!-- Brand and toggle get grouped for better mobile display --\u0026gt; \u0026lt;div class=\u0026#34;navbar-header\u0026#34;\u0026gt; \u0026lt;button type=\u0026#34;button\u0026#34; class=\u0026#34;navbar-toggle collapsed\u0026#34; data-toggle=\u0026#34;collapse\u0026#34; data-target=\u0026#34;#bs-example-navbar-collapse-1\u0026#34; aria-expanded=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;sr-only\u0026#34;\u0026gt;Toggle navigation\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;icon-bar\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;icon-bar\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;icon-bar\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;a class=\u0026#34;navbar-brand\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;Good Coffee\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Collect the nav links, forms, and other content for toggling --\u0026gt; \u0026lt;div class=\u0026#34;collapse navbar-collapse\u0026#34; id=\u0026#34;bs-example-navbar-collapse-1\u0026#34;\u0026gt; \u0026lt;ul class=\u0026#34;nav navbar-nav\u0026#34;\u0026gt; \u0026lt;li class=\u0026#34;active\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Coffee \u0026lt;span class=\u0026#34;sr-only\u0026#34;\u0026gt;(current)\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#mission\u0026#34;\u0026gt;Mission\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ul class=\u0026#34;nav navbar-nav navbar-right\u0026#34;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34; data-toggle=\u0026#34;modal\u0026#34; data-target=\u0026#34;#videoModal\u0026#34;\u0026gt;Fair Trade\u0026lt;/a\u0026gt; \u0026lt;!-- Modal --\u0026gt; \u0026lt;div class=\u0026#34;modal fade\u0026#34; id=\u0026#34;videoModal\u0026#34; tabindex=\u0026#34;-1\u0026#34; role=\u0026#34;dialog\u0026#34; aria-labelledby=\u0026#34;videoModalLabel\u0026#34; aria-hidden=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;modal-dialog\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;modal-content\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;modal-body\u0026#34;\u0026gt; \u0026lt;iframe width=\u0026#34;100%\u0026#34; height=\u0026#34;350\u0026#34; src=\u0026#34;http://www.youtube.com/embed/7K4G5-ydhS0\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;!-- END MODAL --\u0026gt; \u0026lt;li class=\u0026#34;dropdown\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;dropdown-toggle\u0026#34; data-toggle=\u0026#34;dropdown\u0026#34; role=\u0026#34;button\u0026#34; aria-haspopup=\u0026#34;true\u0026#34; aria-expanded=\u0026#34;false\u0026#34;\u0026gt;Coffee Gear \u0026lt;span class=\u0026#34;caret\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;ul class=\u0026#34;dropdown-menu\u0026#34;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Action\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Another action\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Something else here\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li role=\u0026#34;separator\u0026#34; class=\u0026#34;divider\u0026#34;\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Separated link\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- /.navbar-collapse --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- /.container-fluid --\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;div class=\u0026#34;jumbotron\u0026#34;\u0026gt; \u0026lt;h1 class=\u0026#34;animated fadeInDown\u0026#34;\u0026gt; Good Coffee Co.\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;mission\u0026#34;\u0026gt; \u0026lt;a name=\u0026#34;mission\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;h3\u0026gt; Here at Good Coffee Co we are passionate about serving the best coffee you\u0026#39;ll ever taste. \u0026lt;br\u0026gt; Our staff are self-described coffee-nerds with impeccable technique. \u0026lt;br\u0026gt; Stop by today and experience the Good Coffee difference. \u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;container features\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-sm-4\u0026#34;\u0026gt; \u0026lt;img class=\u0026#34;img-responsive\u0026#34; src=\u0026#34;images/coffee_beans.jpg\u0026#34; alt=\u0026#34;coffee beans\u0026#34; /\u0026gt; \u0026lt;p\u0026gt; The freshest locally sourced coffee. Organic and Fair Trade certified\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-sm-4\u0026#34;\u0026gt; \u0026lt;img class=\u0026#34;img-responsive\u0026#34; src=\u0026#34;images/coffee_shop.jpg\u0026#34; alt=\u0026#34;coffee shop\u0026#34; /\u0026gt; \u0026lt;p\u0026gt; A perfect environment to meet with a friend or be alone and get work done.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col-sm-4\u0026#34;\u0026gt; \u0026lt;img class=\u0026#34;img-responsive\u0026#34; src=\u0026#34;images/espresso.jpg\u0026#34; alt=\u0026#34;espresso\u0026#34;\u0026gt; \u0026lt;p\u0026gt; Quality hand-crafted espresso shots pulled with the greatest of care.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;footer\u0026gt; \u0026lt;p\u0026gt;\u0026amp;copy; Good Coffee Co. 2015\u0026lt;/p\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;About\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Location\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Coffee\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;!-- Latest jQuery (without OldIE support--\u0026gt; \u0026lt;script src=\u0026#34;https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Latest compiled and minified JavaScript --\u0026gt; \u0026lt;script src=\u0026#34;https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js\u0026#34; integrity=\u0026#34;sha512-K1qjQ+NcF2TYO/eI3M6v8EiNYZfA95pQumfvcVrTHtwQVDG+aHRqLi/ETn2uB+1JqwYqVG3LIvdm9lj6imS/pQ==\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Final css**  body { font-family: \u0026#39;Raleway\u0026#39;, \u0026#39;sans-serif\u0026#39;; background-color: #A2DED0; } .jumbotron { background-image: url(\u0026#34;./images/Drip_Coffee_Bangkok.jpg\u0026#34;); padding: 20%; background-repeat: no-repeat; background-size: cover; width: 100%; margin-top: -40px; background-attachment: fixed; background-position: center -238px; } .jumbotron h1 { position: absolute; margin-top: -10px; left: 0; padding-left: 20px; color: #F7FAFE; } .mission { background-color: #323232; color: #F7FAFE; margin-top: -30px; } .mission h3 { padding: 5% 10%; text-align: center; } .features { padding: 5% 0; } .features p { font-family: \u0026#39;Muli\u0026#39; \u0026#39;sans-serif\u0026#39;; text-align: center; color: #323232; font-size: 1.2em; padding-top: 10px; } footer { background-color: #D64541; position: absolute; width: 100%; height: auto; } footer ul li { display: inline-block; list-style: none; padding: 2%; float: right; } footer p { float: left; padding: 2%; } footer a, footer p { color: #fff; vertical-align: middle; } "
},
{
	"uri": "/web-essentials/webmastery-foundations/solutions/sass-lab-with-answers/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Lab The starter for this lab is at SASS Lab 1 Starter The completed lab is at SASS Lab 1 Finished\nGiven a div container that has 3 child divs:\n\u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt;Colors \u0026lt;div class=\u0026#34;red\u0026#34;\u0026gt; \u0026lt;p\u0026gt;Red\u0026lt;/p\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;green\u0026#34;\u0026gt;\u0026lt;p\u0026gt;Green\u0026lt;/p\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;blue\u0026#34;\u0026gt; \u0026lt;p\u0026gt;Blue\u0026lt;/p\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; Using only vanilla CSS (no SASS, no Bootstrap, no Foundation) style the above HTML as follows:\n The outer div has:  a width of 400px a height of 200px background color of light gray a border of black, a border radius of 20px and a label of \u0026ldquo;Colors\u0026rdquo; near the top of the div   The inner divs should fit nicely inside the outer div and have the following:  Background colors of \u0026ldquo;##FFB3B3\u0026rdquo;, \u0026ldquo;light green\u0026rdquo;, and \u0026ldquo;light blue\u0026rdquo;, respectively. Borders of red, green, and blue, respectively. Labels of \u0026ldquo;Red\u0026rdquo;, \u0026ldquo;Green\u0026rdquo;, and \u0026ldquo;Blue\u0026rdquo;, respectively.s A border radius of 10px.   Now convert the CSS to SASS and make it as DRY as possible. Feel free to use the Compass SASS library. Bonus:  Make it easy to resize the outer div and have the inner div\u0026rsquo;s resized accordingly (don\u0026rsquo;t use percentages). Make the labels in the color divs have a text color that is the complement of the background color.    "
},
{
	"uri": "/web-essentials/webmastery-foundations/solutions/sign_up_form_with_answers/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Learning Objectives Concepts  Understand custom styling with vanilla css  Skills  Build an html form Gain understanding of the more complex parts of css  HTML Create a new project  create the HTML document create a css directory and a main stylesheet link the css and html together  \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/main.css\u0026#34; media=\u0026#34;screen\u0026#34; title=\u0026#34;no title\u0026#34; charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Create the Body of your Document Start by building out the body of our document.\n Structure and Style\nWhen building with html and css, it is strongly encouraged to structure your document (with html) first, and style your document (with css) afterwards.\n  Inside the \u0026lt;body\u0026gt; of your html  create a container \u0026lt;div\u0026gt; with the id attribute of login-box   Within the login-box \u0026lt;div\u0026gt;  create another \u0026lt;div\u0026gt; with a class of left   Inside of the \u0026lsquo;left\u0026rsquo; \u0026lt;div\u0026gt;  create a top-level header that contains the text: \u0026lsquo;Create Account\u0026rsquo;    \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;login-box\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;left\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Create Account\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; The Form Create a sign-up form.\n Create a \u0026lt;form\u0026gt; element which contains:  A class attribute titled \u0026lsquo;sign-up\u0026rsquo; An action attribute pointing to \u0026lsquo;index.html\u0026rsquo; + (the action attribute defines the location (an URL) where the form\u0026rsquo;s collected data should be sent) A method attribute with the value of \u0026lsquo;post\u0026rsquo; + The method attribute defines which HTTP method to send the data with (it can be \u0026ldquo;get\u0026rdquo; or \u0026ldquo;post\u0026rdquo;)   Within the \u0026lt;form\u0026gt;, nest 4 \u0026lt;input\u0026gt; elements  username email password password_confirmation   Nest a button (inside the \u0026lt;form\u0026gt;) with the following attributes:  A class attribute of \u0026lsquo;sign-up-button\u0026rsquo; A type attribute of \u0026lsquo;submit\u0026rsquo;   Close out your \u0026lsquo;left\u0026rsquo; \u0026lt;div\u0026gt;  hint: You may want to check out the Mozilla or W3 documentation on how to create a form\nOnce complete, your index.html page should look something like this: \u0026lt;div class=\u0026#34;left\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Create Account\u0026lt;/h1\u0026gt; \u0026lt;form class=\u0026#34;sign-up\u0026#34; action=\u0026#34;index.html\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34; placeholder=\u0026#34;Username\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;email\u0026#34; placeholder=\u0026#34;E-mail\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34; placeholder=\u0026#34;Password\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password2\u0026#34; placeholder=\u0026#34;Retype password\u0026#34; /\u0026gt; \u0026lt;button class=\u0026#34;sign-up-button\u0026#34; type=\u0026#34;submit\u0026#34;/\u0026gt; Sign Me Up \u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; The other buttons  Create a \u0026lt;div\u0026gt; with a class attribute of \u0026lsquo;right\u0026rsquo; Inside of the \u0026lsquo;right\u0026rsquo; \u0026lt;div\u0026gt;  Nest a \u0026lt;span\u0026gt; with the class attribute of \u0026lsquo;loginwith\u0026rsquo; Inside the \u0026lt;span\u0026gt; put the text: \u0026lsquo;Sign in with Social Network\u0026rsquo;   Create 3 \u0026lt;button\u0026gt; elements with:  class attributes of \u0026ldquo;social-signin\u0026rdquo;   Select the top \u0026lt;button\u0026gt;and  Assign a class attribute of \u0026lsquo;facebook\u0026rsquo; Include the text: \u0026lsquo;Log in with facebook\u0026rsquo;   Do the same thing for Twitter and Google+ close out the \u0026lsquo;right\u0026rsquo; \u0026lt;div\u0026gt;  The Result: \u0026lt;div class=\u0026#34;right\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;loginwith\u0026#34;\u0026gt;Sign in with \u0026lt;br\u0026gt; social network\u0026lt;/span\u0026gt; \u0026lt;button class=\u0026#34;social-signin facebook\u0026#34;\u0026gt;Log in with facebook\u0026lt;/button\u0026gt; \u0026lt;button class=\u0026#34;social-signin twitter\u0026#34;\u0026gt;Log in with Twitter\u0026lt;/button\u0026gt; \u0026lt;button class=\u0026#34;social-signin google\u0026#34;\u0026gt;Log in with Google+\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; Or Create a \u0026lt;div\u0026gt; with the class attribute of \u0026ldquo;or\u0026rdquo; and the inner-text \u0026lsquo;OR\u0026rsquo;\n\u0026lt;div class=\u0026#34;or\u0026#34;\u0026gt;OR\u0026lt;/div\u0026gt; At this point, your webpage should look like this: Now that we have completed the structure of our html document, all that\u0026rsquo;s left is to add some style!\nCSS Normalize A.K.A. - Browser Reset Okay, so first things first. We need to get rid of this awful default browser styling\nLet\u0026rsquo;s https://necolas.github.io/normalize.css/[Normalize!]   Go to the site above and download the file\n  Create a new stylesheet and paste in the contents of normalize.css\n  link the stylesheet to your index.html page\n Before and After:**     \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/normalize.css\u0026#34; media=\u0026#34;screen\u0026#34; title=\u0026#34;no title\u0026#34; charset=\u0026#34;utf-8\u0026#34;\u0026gt; Setting up the Body Start by using the * selector to apply border-box to the all of the elements.\n* { box-sizing: border-box; } So, what does the above code do? Well, according to learnlayout.com:\n When you set box-sizing: border-box; on an element, the padding and border of that element no longer increase its width. This is incredibly helpful as it removes unexpected layout issues.\n Next we\u0026rsquo;ll work on the body.\ncolors!  Give the body a background color of #DDD Give the text a color of #222  Result: body { background: #DDD; color: #222; } While we\u0026rsquo;re at it, let\u0026rsquo;s go ahead and select a font (I\u0026rsquo;ve already picked out Noto Sans, but feel free to experiment)\nRight below your * selector apply the following:\n@import url(https://fonts.googleapis.com/css?family=Noto+Sans|Comfortaa:400,300,700); After completing the above challenge, add the following to your body declaration:\nfont-family: \u0026#39;Noto Sans\u0026#39;, sans-serif; font-weight: 300; Here\u0026rsquo;s how it will look on the web: That should take care of the body. Next up, positioning!\nPositioning The Login-Box - part 1   Start by giving the login-box a relative position\n  Apply a margin of\n 5% on the top/bottom auto on the left/right    Give the box a background-color of #FFF\n The Result you\u0026rsquo;re looking for:**     #login-box { position: relative; margin: 5% auto; } Great! Even though, it doesn\u0026rsquo;t look like much happened. The good news is that our Login Box is responding.\nThe Login-Box - Part 2 Now all we need to do is set a width and height (and give it some style)\n Set a width of 600px Set a height of 400px Refresh your browser and make sure the box is still responding Assign a border-radius of 2px Add some box-shadow and assign the following values:  horizontal shadow of: 0 vertical shadow of: 2px blur of: 4px color of: rgba(0,0,0,0.4)    (hint: you may find http://www.w3schools.com/cssref/css3_pr_box-shadow.asp[this] helpful for box-shadow)\nThe Result: #login-box { position: relative; margin: 5% auto; width: 600px; height: 400px; background: #FFF; border-radius: 2px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.4); } Ahhh much better. Now we can start focusing on the right and left \u0026lt;div\u0026gt; \u0026rsquo;s\nPosition the div's Position the left \u0026lt;div\u0026gt;   Give the \u0026lt;div\u0026gt; some padding, height and width\n padding of: 40px width of: 300px height of: 400px    Refresh your browser You\u0026rsquo;ll probably get something like this:   Now, give the left div an absolute position\n Place it at at the top/left of it\u0026rsquo;s parent \u0026lt;div\u0026gt;    [WARNING] You\u0026rsquo;ll notice all sorts of weirdness happening with the right div. This is normal, and will be fixed shortly. .left { padding: 40px; width: 300px; height: 400px; position: absolute; top: 0; left: 0; } Position the right \u0026lt;div\u0026gt;  Apply the same attributes from the left \u0026lt;div\u0026gt;, to the right \u0026lt;div\u0026gt; with one exception\u0026hellip; +  Position this \u0026lt;div\u0026gt; at the top right of it\u0026rsquo;s parent \u0026lt;div\u0026gt; (instead of the top left**     ==== Thankfully, we can reuse a good bit of the code from our left \u0026lt;div\u0026gt;. yay!. ====\n What kind of refactoring could be done?\n The Result:**   .left, .right { padding: 40px; width: 300px; height: 400px; position: absolute; top: 0 } .left { left: 0; } .right { right: 0; Let\u0026rsquo;s go ahead and throw in our background picture while we\u0026rsquo;re here. In your .right declaration (under right: 0;) paste the following code:\n.right { right: 0; background: url(\u0026#39;https://goo.gl/YbktSj\u0026#39;); background-size: cover; background-position: center; border-radius: 0 2px 2px 0; } Refresh and take a deep breath. We\u0026rsquo;re getting close!\nStyle the .left Let\u0026rsquo;s go ahead and knock out the styling on our left \u0026lt;div\u0026gt;\nWe\u0026rsquo;ll start with the \u0026lt;h1\u0026gt;\n Type** the following code in your stylesheet:  h1 { margin: 0 0 20px 0; font-weight: 300; font-size: 2em; } Refresh if you want to see the change\nsign-up form inputs  Let\u0026rsquo;s start by removing that border Now apply a border to only the bottom.  give it a 1px solid bottom-border give it the color #AAA   Give each input a display of block Refresh   .sign-up input { border: none; border-bottom: 1px solid #AAA; display: block; margin-bottom: 20px; padding: 4px; width: 220px; height: 32px; font-weight: 400; }   Now, apply some margin and padding to make it look pretty\n Separate the inputs by adding a bottom margin of 20px add about 4px of padding    Refresh\n  Add some height and width\u0026hellip;\n height of 32px width of 220px    Make the font a little stronger by giving it a weight of 400\n The Result:**     Cool, things are starting to look decent. Let\u0026rsquo;s go ahead and work on the button next.\nThe Sign Me Up Button   Properly apply spacing and width/height\n give a top and bottom margin of 5px a width of 220px a height of 32px    While we\u0026rsquo;re at it, go ahead and remove the border\n  give it a border-radius of 2px\n  Apply some color!\n give the background a color of #16A085 set the text color to #FFF    Finally, set the transform-text proptery to uppercase, and the font-weight to 400\n The Result:**    Here\u0026rsquo;s what you should have so far.\n.sign-up-button { margin: 5px auto; width: 220px; height: 32px; border: none; border-radius: 2px; background: #16a085; color: #FFF; font-weight: 400; text-transform: uppercase; } We also want to give the button some hover effects to call the user to action.\nHover   Using the :hover pseudo selector\n Set the opacity to 0.8 give a box-shadow of: 0 2px 4px rgba(0, 0, 0, 0.4) set the transition property to 0.1s ease    Refresh and check it out\n  Now use the :active pseudo selector to:\n apply an opacity of 1 and a box-shadow of 0 1px 2px rgba(0, 0, 0, 0.4)    .sign-up-button:hover { opacity: 0.8; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.4); transition: 0.1s ease; } .sign-up-button:active { opacity: 1; box-shadow: 0 1px 2px rgba(0, 0, 0, 0.4); } Let\u0026rsquo;s put the finishing touches on this side\u0026hellip;\nFocus Using a :focus pseudo selector, apply the following code to input:\nborder-bottom: 2px solid #16a085; color: #16a085; transition: 0.2s ease; Once complete, you\u0026rsquo;ll want to modify focus on the entire document.\nPlace the following code near the top of your stylesheet\n*:focus { outline: none; } ... .sign-up input:focus { border: none; border-bottom: 2px solid #16a085; color: #16a085; transition: 0.2s ease; } Styling the .right style the \u0026lt;span\u0026gt;   Set the display of your \u0026lsquo;logmein\u0026rsquo; class to block\n  Give it a margin bottom of 40px\n  Assign a font-size of 2em\n  Give a color of #FFF\n  Center the text\n This is what you\u0026rsquo;re looking for:**     .loginwith { display: block; margin-bottom: 40px; font-size: 2em; color: #FFF; text-align: center; } Got it! Awesome, now let\u0026rsquo;s style those buttons.\nStyle ALL buttons   give a margin bottom of 20px\n  width of 220px\n  height of 36px\n  remove the border\n  give a border-radius of 2px\n  set the text color to #FFF\n The Result:**     button.social-signin { margin-bottom: 20px; width: 220px; height: 36px; border: none; border-radius: 2px; color: #FFF; } You may notice some code duplication. Let\u0026rsquo;s go ahead and refactor\nRefactor the buttons  Group the buttons (from your left and right \u0026lt;div\u0026gt;'s together in your css Refresh and make sure everything looks good Refactor the code duplication  /********************************************** start of button styling /**********************************************/ button { margin-bottom: 20px; width: 220px; height: 36px; border: none; border-radius: 2px; color: #FFF; font-weight: 400; } button:hover { opacity: 0.8; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.4); transition: 0.1s ease; } button:active { opacity: 1; box-shadow: 0 1px 2px rgba(0, 0, 0, 0.4); } .sign-up-button { margin: 5px auto; background: #16a085; text-transform: uppercase; } /********************************************** end of button styling /**********************************************/ Add some color to the right buttons   Apply the following background colors\n for the facebook class: #32508E twitter class: #55ACEE google class: #DD4B39    Refresh!\n The Result:**     .facebook { background: #32508E; } .twitter { background: #55ACEE; } .google { background: #DD4B39; } OR We\u0026rsquo;re close to the end. Let\u0026rsquo;s style that \u0026lsquo;or\u0026rsquo; div\n Give a position of absolute set it to:  180px from top 280px from left   Assign a width of 40px Give a height of 40px Refresh!  .or { position: absolute; top: 180px; left: 280px; width: 40px; height: 40px; } Okay, not exactly what we\u0026rsquo;re looking for. Now try this:\n  Challenge 20**\n  Set the background to #DDD\n  give a border-radius of 50%\n  center the text\n  set a line-height of 40px\n  declare a box-shadow of 0 2px 4px rgba(0, 0, 0, 0.4)\n  Refresh and enjoy the fruits of your labor\u0026hellip; Which should look something like this:\n.or { position: absolute; top: 180px; left: 280px; width: 40px; height: 40px; background: #DDD; border-radius: 50%; text-align: center; line-height: 40px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.4); } * { box-sizing: border-box; } @import url(https://fonts.googleapis.com/css?family=Noto+Sans|Comfortaa:400,300,700); *:focus { outline: none; } body { background: #DDD; color: #222; font-family: \u0026#39;Noto Sans\u0026#39;, sans-serif; font-weight: 300; } #login-box { position: relative; margin: 5% auto; width: 600px; height: 400px; background: #FFF; border-radius: 2px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.4); } /********************************************** Left and Right div Positioning /**********************************************/ .left, .right { padding: 40px; width: 300px; height: 400px; position: absolute; top: 0 } .left { left: 0; } .right { right: 0; background: url(\u0026#39;https://goo.gl/YbktSj\u0026#39;); background-size: cover; background-position: center; border-radius: 0 2px 2px 0; } /********************************************** END div positioning /**********************************************/ /********************************************** Left div styling /**********************************************/ h1 { margin: 0 0 20px 0; font-weight: 300; font-size: 2em; } .sign-up input { border: none; border-bottom: 1px solid #AAA; display: block; margin-bottom: 20px; padding: 4px; width: 220px; height: 32px; font-weight: 400; /*transition: 0.2s ease*/ } .sign-up input:focus { border: none; border-bottom: 2px solid #16a085; color: #16a085; transition: 0.2s ease; } /********************************************** end of left div styling /**********************************************/ /********************************************** start of button styling /**********************************************/ button { margin-bottom: 20px; width: 220px; height: 36px; border: none; border-radius: 2px; color: #FFF; font-weight: 400; } button:hover { opacity: 0.8; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.4); transition: 0.1s ease; } button:active { opacity: 1; box-shadow: 0 1px 2px rgba(0, 0, 0, 0.4); } .sign-up-button { margin: 5px auto; background: #16a085; text-transform: uppercase; } .facebook { background: #32508E; } .twitter { background: #55ACEE; } .google { background: #DD4B39; } /********************************************** end of button styling /**********************************************/ .loginwith { display: block; margin-bottom: 40px; font-size: 2em; color: #FFF; text-align: center; } .or { position: absolute; top: 180px; left: 280px; width: 40px; height: 40px; background: #DDD; border-radius: 50%; text-align: center; line-height: 40px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.4); } "
},
{
	"uri": "/web-essentials/webmastery-foundations/src/sass/mixins/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Mixins \u0026lt;section class=\u0026#34;box1\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;News\u0026lt;/h1\u0026gt; \u0026lt;article\u0026gt; \u0026lt;h2\u0026gt;Article goes here.\u0026lt;/h2\u0026gt; \u0026lt;/article\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;section class=\u0026#34;box2\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Weather\u0026lt;/h1\u0026gt; \u0026lt;article\u0026gt; \u0026lt;h2\u0026gt;Article goes here.\u0026lt;/h2\u0026gt; \u0026lt;/article\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;section class=\u0026#34;box3\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Sports\u0026lt;/h1\u0026gt; \u0026lt;article\u0026gt; \u0026lt;h2\u0026gt;Article goes here.\u0026lt;/h2\u0026gt; \u0026lt;/article\u0026gt; \u0026lt;/section\u0026gt; @mixin nice-border($color, $radius) { margin: 10px; padding: 10px; border: 4px solid $color; border-radius: $radius; } .box1 { @include nice-border(red, 10px); } .box2 { @include nice-border(green, 20px); } .box3 { @include nice-border(blue, 30px); } "
},
{
	"uri": "/web-essentials/webmastery-foundations/src/sass/nesting/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Nesting \u0026lt;nav\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#news\u0026#34;\u0026gt;News\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#weather\u0026#34;\u0026gt;Weather\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#sports\u0026#34;\u0026gt;Sports\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;h2\u0026gt;Here is some fruit\u0026lt;/h2\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;Apple\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Orange\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Banana\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; nav { ul { margin: 0; padding: 0; list-style: none; } li { display: inline-block; } a { display: block; padding: 6px 12px; text-decoration: none; } } "
},
{
	"uri": "/web-essentials/webmastery-foundations/src/sass/vars/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Variables and Color Functions \u0026lt;h1\u0026gt;This is a level 1 heading\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;This is a level 2 heading\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;This is a paragraph\u0026lt;/p\u0026gt; \u0026lt;button\u0026gt;I am a button, click Me!\u0026lt;/button\u0026gt; $base-color: #AD141E; $button-fg-color: yellow; $button-bg-color: blue; $color-amount: 10%; p { color: $base-color; } h1 { color: darken( $base-color, $color-amount ); } h2 { color: lighten( $base-color, $color-amount ); } button { color: $button-fg-color; background-color: $button-bg-color; \u0026amp;:hover { color: invert($button-fg-color); background-color: invert($button-bg-color); } } "
},
{
	"uri": "/python/testing/additional-material/",
	"title": "Additional Testing Material",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/python/automation/automating/",
	"title": "Automating Python Scripts Additional Files",
	"tags": [],
	"description": "",
	"content": "Automating Python Scripts Additional Files "
},
{
	"uri": "/python/foundation/additional-resources/base-conversions/",
	"title": "Base Conversion",
	"tags": [],
	"description": "",
	"content": "Base Introduction Our everyday number system is a Base-10 system. The Base-10 number system is known as the decimal system and has 10 digits to show all numbers 0, 1, 2, 3, 4, 5, 6, 7, 8, 9.\nWe do not have a single-digit numeral for \u0026ldquo;ten\u0026rdquo;. (The Romans did, in their character \u0026ldquo;X\u0026rdquo;.) Yes, we write \u0026ldquo;10\u0026rdquo;, but this stands for \u0026ldquo;1 ten and 0 ones\u0026rdquo;. This is two digits; we have no single solitary digit that stands for \u0026ldquo;ten\u0026rdquo;.\nInstead, when we need to count to one more than nine, we zero out the ones column and add one to the tens column. When we get too big in the tens column \u0026ndash; when we need one more than nine tens and nine ones (\u0026ldquo;99\u0026rdquo;), we zero out the tens and ones columns, and add one to the ten-times-ten, or hundreds, column.\nThe only reason base-ten math seems \u0026ldquo;natural\u0026rdquo; and the other bases don\u0026rsquo;t is that you\u0026rsquo;ve been doing base-ten since you were a child. And (nearly) every civilization has used base-ten math probably for the simple reason that we have ten fingers. If instead we lived in a cartoon world, where we would have only four fingers on each hand (count them next time you\u0026rsquo;re watching TV or reading the comics), then the \u0026ldquo;natural\u0026rdquo; base system would likely have been base-eight, or \u0026ldquo;octal\u0026rdquo;.\nBinary Let’s look at base-two, or binary, numbers. How would you write, for instance, 12~10~ (\u0026ldquo;twelve, base ten\u0026rdquo;) as a binary number? You would have to convert to base-two columns, the analogue of base-ten columns. In base ten, you have columns or \u0026ldquo;places\u0026rdquo; for 10^0^ = 1, 10^1^ = 10, 10^2^ = 100, 10^3^ = 1000, and so forth. Similarly in base two, you have columns or \u0026ldquo;places\u0026rdquo; for 2^0^ = 1, 2^1^ = 2, 2^2^ = 4, 2^3^ = 8, 2^4^ = 16, and so forth.\n   Binary Decimal Expansion     0 0 0 ones   1 1 1 one   10 2 1 two and 0 ones   11 3 1 two and 1 one   100 4 1 four, 0 twos, and 0 ones   101 5 1 fours, 0 twos, and 1 one   110 6 1 four, 0 twos, and 1 one   111 7 1 eight, 0 fours, 0 twos, and 0 ones   1000 8 1 eight, 0 fours, 0 twos, and 1 ones   1001 9 1 eight, 0 fours, 1 twos, and 0 ones   1010 10 1 eight, 0 fours, 1 twos, and 1 ones   1011 11 1 eight, 1 fours, 0 twos, and 0 ones   1100 12 1 eight, 1 fours, 0 twos, and 1 ones   1101 13 1 eight, 1 fours, 1 twos, and 0 ones   1110 14 1 eight, 1 fours, 1 twos, and 0 ones   1111 15 1 eight, 1 fours, 1 twos, and 1 ones   10000 16 1 sixteen, 1 eight, 0 fours, 0 twos, and 0 ones    The following table can help with the conversion from binary to decimal.\n   Binary Number              2^7 2^6 2^5 2^4 2^3 2^2 2^1 2^0   Decimal Number            128 64 32 16 8 4 2 1    To convert 10111010~2~ to decimal, you first need to place each binary digit in a separate column.\n   Binary Number 1 0 1 1 1 0 1 0      2^7 2^6 2^5 2^4 2^3 2^2 2^1 2^0   Decimal Number            128 64 32 16 8 4 2 1    Then multiply each binary digit with the corresponding 2n.\n   Binary Number 1 0 1 1 1 0 1 0      2^7 2^6 2^5 2^4 2^3 2^2 2^1 2^0    128 64 32 16 8 4 2 1   Decimal Number 128 0 32 16 8 0 2 0    Then add all of the numbers of the last row.\n128+0+32+16+8+0+2+0 which equals 186.\nThis means 10111010~2~ equals 186~10~.\nHexadecimal In this activity, you will learn convert from one base to another using Python. We are going to create a program to convert hex (base-16) to binary (base-2). In your project called Cryptography, create a base_conversion file. Hexadecimal in relation to decimal (base-10) counting from zero upward\n   Hexadecimal Decimal     0 0   1 1   2 2   3 3   4 4   5 5   6 6   7 7   8 8   9 9   A 10   B 11   C 12   D 13   E 14   F 15    Hexadecimal to Binary    Hexadecimal Decimal     0 0000   1 0001   2 0010   3 0011   4 0100   5 0101   6 0110   7 0111   8 1000   9 1001   A 1010   B 1011   C 1100   D 1101   E 1110   F 1111    Example of A1F5 to Binary\n   A 1 F 5     1010 0001 1111 0101    So, A1F5 equates to 1010000111110101.\nCreate a function, hex_to_bin(hexstring), that will take in a string of hexadecimal, and return the binary equivalent!\nprint(hex_to_bin(\u0026#39;A1F5\u0026#39;)) Output: 1010000111110101\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/python/automation/charts/",
	"title": "Chart Creation Additional Files",
	"tags": [],
	"description": "",
	"content": "Chart Creation Additional Files "
},
{
	"uri": "/web-essentials/webmastery-foundations/src/css-transitions-and-animations/",
	"title": "CSS Transitions and Animations",
	"tags": [],
	"description": "",
	"content": "Index "
},
{
	"uri": "/golang/fromjava/faq/",
	"title": "Go FAQs",
	"tags": [],
	"description": "",
	"content": "Java libraries are \u0026ldquo;mature\u0026rdquo;, how can I be sure Go libraries can handle our needs? There are several things in Go\u0026rsquo;s corner here:\n Go includes many toolsets internally that most languages need external imports for (Testing, debugging, http functionality, and concurrency for instance, are all built in). Go is open source and its support and contributor community is very active. Whatever your needs are, we can find some support for you. Go is growing as a dominating presence in the cloud computing sphere (both Docker and Kubernetes are written in Go). Beyond just cloud computing, there are hundreds of established companies that rely on Go as their language of choice. Check out this list when you have a chance and see what you think.  We do a lot of data handling and manipulation (e.g. converting to and from JSON), how does Go handle that? Go has built-in support for marshaling/unmarshaling many common data formats such as JSON, XML, and CSV. No external libraries needed!\nMost of this functionality can be found in the build-in encoding package.\nWe practice TDD, what does this look like in Go? Go\u0026rsquo;s testing library is built-in and extensive. Out of the box you have the ability to tag and skip tests, mock up dependencies, create table-driven tests, get detailed information on run statistics with different run environments, and more!\nCheck out \u0026ldquo;Testing in Go\u0026rdquo; content at Orange Academy for more hands-on examples.\nWhat do deployments look like? You have options. Go is widely supported in cloud technology so finding support to deploy and run your project in its expanded form is possible. Simply deploy a Go docker image and run go run ..\nHowever, to fully take advantage of Go\u0026rsquo;s size and performance enhancements, we recommend you compile your project in your pipeline with go build. This creates a small executable binary that can be deployed and run anywhere as a native command.\nDo we have any pipeline examples? manifest-np.yml - Simple example\n--- applications: - name: team-management-api buildpacks: - binary_buildpack command: ./team-management-api services: - team-management-db env: PROXY_HOST: http://thd-svr-proxy-qa.homedepot.com PROXY_PORT: 9090 memory: 64M disk_quota: 32M instances: 2 stack: cflinuxfs3 branch-manager-pipeline.yml - Complex example\nresources: - name: concourse-branch-manager type: git source: uri: git@github.homedepot.com:Pipeline-Engineering/concourse-branch-manager.git branch: master ignore_paths: [Gemfile, Gemfile.lock] private_key: ((github-private-key)) # This `git-branches` input resource determines which branches will be processed - name: branch-manager-git-branches type: git-branches source: # Set this to the uri of your repo for which you want to dynamically build arbitrary branches uri: ((github-uri)) branch_regexp: \u0026#34;^.*(feature|story|bug|chore)/.*\u0026#34; max_branches: 10 private_key: ((github-private-key)) # Build Image resource - a docker image build for running both java and Node Applications on Pipeline - name: build-image type: docker-image source: repository: ((docker-image-repo)) tag: ((docker-image-tag)) # This repo containing your resource/job templates and any non-secret # non-credential config that needs to be passed into your generated pipeline # via fly --load-vars-from options. can be the same repo as # the one in the git-branches resource above, but it doesn\u0026#39;t have to be - name: branch-manager-ci-repo type: git source: # Set this to the uri of your repo containing your resource/job templates for building branches uri: ((github-uri)) branch: master private_key: ((github-private-key)) # This repo contains any secret credential config that needs to be # passed into your generated pipeline via fly --load-vars-from options - name: branch-manager-credentials type: git source: # Set this to the uri of your repo containing your non-secret non-credential config uri: ((github-credentials-uri)) branch: master private_key: ((github-private-key)) - name: master type: git source: uri: ((github-uri)) branch: master private_key: ((github-private-key)) - name: two-weeks type: time source: {interval: 336h} - name: gh-release type: github-release source: owner: ((github-org-name)) repository: ((github-repo-name)) github_api_url: https://github.homedepot.com/api/v3/ access_token: ((github-token)) - name: change-request type: snowfield-resource source: url: ((cr-snowfield-url)) resource_types: - name: git-branches type: docker-image source: repository: docker.artifactory.homedepot.com/tracker/git-branches-resource - name: snowfield-resource type: docker-image source: repository: docker.artifactory.homedepot.com/snowfield-resource jobs: - name: branch-manager serial: true plan: - get: concourse-branch-manager trigger: true - get: git-branches resource: branch-manager-git-branches trigger: true - get: template-repo resource: branch-manager-ci-repo trigger: true - get: credentials-repo resource: branch-manager-credentials trigger: true - get: config-repo resource: branch-manager-ci-repo params: {submodules: none} trigger: true - task: manage-branches file: concourse-branch-manager/tasks/manage-branches.yml params: BRANCH_RESOURCE_TEMPLATE: template-repo/ci/pipelines/templates/branch-resource-template.yml.erb BRANCH_JOB_TEMPLATE: template-repo/ci/pipelines/templates/branch-job-template.yml.erb PIPELINE_COMMON_RESOURCES_TEMPLATE: template-repo/ci/pipelines/templates/common-resources-template.yml.erb PIPELINE_RESOURCE_TYPE_TEMPLATE: template-repo/ci/pipelines/templates/resource-type-template.yml.erb CONCOURSE_URL: ((concourse-url)) CONCOURSE_USERNAME: ((CONCOURSE_USERNAME)) CONCOURSE_PASSWORD: ((CONCOURSE_PASSWORD)) CONCOURSE_TEAM: branch-manager PIPELINE_LOAD_VARS_FROM_1: config-repo/branch-manager-config.yml PIPELINE_LOAD_VARS_FROM_2: credentials-repo/branch-manager-credentials.yml GROUP_PER_BRANCH: true - name: Security Scan max_in_flight: 1 plan: - get: code-src resource: master - get: two-weeks trigger: true - get: build-image - task: security scan image: build-image file: code-src/ci/tasks/security-scan.yml params: PROJECT_NAME: ((fortify-name)) PROJECT_VERSION: ((fortify-version)) FORTIFY_TOKEN: ((fortify-token)) EMAIL: ((fortify-email)) PROJECT_LAN: ((project-language)) - name: Create Change Request max_in_flight: 1 plan: - get: code-src resource: master - get: gh-release - put: change-request - task: get-description image: build-image file: code-src/ci/tasks/get-change-description.yml params: template: ((cr-template)) assigned_to: ((cr-assigned-to)) description_path: gh-release/body Dependency management is a nightmare, can Go solve that? Yes! Starting out dependency management was pretty rough in Go as well. It involved curating and maintaining all projects and dependencies in a \u0026ldquo;Go Path\u0026rdquo;. However, with the introduction of Go Modules, dependency management in Go is streamlined and simplified.\nCheck out the Orange Academy content on Go Path and Go Modules to learn more and get started.\nOur product takes a lot of traffic and needs high performance, can Go keep up? Go has consistently out-performed Java in most benchmarks. Obviously every scenario is going to have its nuances and so its worth doing your own research. But in most cases you will find Go to be comparable or faster than Java.\nCheck this article for a slightly deeper look.\nHow does Go support 12 factor development? Coming soon.\nI (we) don\u0026rsquo;t have time to learn a new language\u0026hellip; This is one concern we at Orange Academy would love to help you with. Please let us know how we can make our content and services more available to you. If you cannot make it to workshops we can also be available for office hours where you can drop by and talk through some of the lesson material on your own time. We also have consulting services available if it would be better for us to come to you.\nWe are here to help with this! Just reach out.\nAdditional Resources  Official Go FAQ  "
},
{
	"uri": "/software-eng-essentials/command-line-bash/if-and-functions/",
	"title": "If and Functions",
	"tags": [],
	"description": "",
	"content": "Objectives  If statements Tests Boolean operators Functions Passing arguments to a function Return values Overriding commands  If statements An if statement basically says, if a particular test is true, then perform a given set of actions. If it is not true then don\u0026rsquo;t perform those actions. Anything between then and fi \u0026ndash; if backwards\u0026ndash;will be executed only if the test (between the square brackets) is true.\n#!/bin/bash  if [ $1 -gt 100 ] then echo Hey that\\\u0026#39;s a big number. pwd fi date Test The square brackets [] in the if statement above are actually a reference to the command test. Check the man page for test to see all of the possible operators, but some of the more common ones are listed below.\n   Operator Description     ! EXPRESSION The EXPRESSION is false.   -n STRING The length of STRING is greater than zero.   -z STRING The lengh of STRING is zero (ie it is empty).   STRING1 = STRING2 STRING1 is equal to STRING2   STRING1 != STRING2 STRING1 is not equal to STRING2   INTEGER1 -eq INTEGER2 INTEGER1 is numerically equal to INTEGER2   INTEGER1 -gt INTEGER2 INTEGER1 is numerically greater than INTEGER2   INTEGER1 -lt INTEGER2 INTEGER1 is numerically less than INTEGER2   -d FILE FILE exists and is a directory.   -e FILE FILE exists.   -r FILE FILE exists and the read permission is granted.   -s FILE FILE exists and it\u0026rsquo;s size is greater than zero (ie. it is not empty).   -w FILE FILE exists and the write permission is granted.   -x FILE FILE exists and the execute permission is granted.    Boolean Operations Sometimes we only want to do something if multiple conditions are met. Other times we would like to perform the action if one condition is met. We can accommodate these with boolean operators.\n \u0026amp;\u0026amp; \u0026ndash; \u0026ldquo;and\u0026rdquo; || \u0026ndash; \u0026ldquo;or\u0026rdquo;  Looking for a readable and sizeable file\n#!/bin/bash # and example if [ -r $1 ] \u0026amp;\u0026amp; [ -s $1 ] then echo This file is useful. fi Or example\n#!/bin/bash # or example if [ $USER == \u0026#39;bob\u0026#39; ] || [ $USER == \u0026#39;andy\u0026#39; ] then ls -alh else ls fi Exercises\n Create a Bash script which will take 2 numbers as command line arguments. It will print to the screen the larger of the two numbers. Create a Bash script which will accept a file as a command line argument and analyse it in certain ways. E.g. you could check if the file is executable or writable. You should print a certain message if true and another if false. Create a Bash script which will print a message based upon which day of the week it is (e.g., \u0026lsquo;Happy hump day\u0026rsquo; for Wedensday, \u0026lsquo;TGIF\u0026rsquo; for Friday etc).  Functions Functions in bash may take the following form:\nfunction_name () { \u0026lt;function_commands\u0026gt; } Passing arguments to a function Like in other programming languages, bash functions may be passed arguments.\nThe first argument is assigned to the variable $1 by the system.\n#!/bin/bash # Passing a single argument to a function epic_characters () { echo I am $1 } epic_characters Beowulf epic_characters Grendel The second argument is assigned to the variable $2.\n#!/bin/bash # Passing two arguments to a function epic_characters () { echo I am $1 the $2! } epic_characters Beowulf hero epic_characters Grendel monster  $0 is the variable name assigned to the name of your program. $# is the variable name assigned to the number of arguments passed.\n Return values Many programming languages have functions which may give a return value from their functions. Bash functions don\u0026rsquo;t allow us to do this. They do however allow us to set a return status.\nA return_status script\n#!/bin/bash # Setting a return status for a function print_something () { echo Hello $1 return 5 } print_something Beowulf print_something Grendel echo The previous function has a return value of $? Executing return_status\n$ ./return_status Hello Beowulf Hello Grendel The previous function has a return value of 5  A return status of 0 usually indicates that everything went successfully. A non zero value would indicate that an error occurred.\n Overriding commands It is possible to name a function as the same name as a command you would normally use on the command line. This allows us to create a wrapper.\n#!/bin/bash # Create a wrapper around the command ls ls () { command ls -lh } ls When we have a function with the same name as a command we need to put the keyword command in front of the the name when we want the command as opposed to the function as the function normally takes precedence.\n"
},
{
	"uri": "/software-eng-essentials/db-sql/intro-to-datagrip/",
	"title": "Intro to DataGrip",
	"tags": [],
	"description": "",
	"content": "DataGrip DataGrip is an IDE from JetBrains built for database developers. It allows you to quickly migrate and refactor relational databases, construct efficient, statically checked SQL queries and much more.\nDataGrip Installation\nInstallation  Click Do not import settings on the Complete Installation page. Click OK. Click the License Server radio button on the DataGrip License Activation page. If you are on a THD network, this will automatically populate. Click Activate. Chose the UI theme and click Next: Editor Color Themes. Choose the desired editor color theme and click Next: IDE Defaults. Choose PostgreSQL as the preferred dialect for SQL files. Click Start using DataGrip.  Set Up  On the edge of the new window (either left or right), click on Databases. This will open up the Databases panel. Set your data source to your clap database. Do this by clicking on the + \u0026gt; Data Source \u0026gt; PostgreSQL. (If you have not created this database already, go to Creating a Database). This will open up the Databases and Drivers window. If this is your first time working with a PostgreSQL database in DataGrip, click Download at the bottom of the window where it says Download missing driver files. Fill out the form in the window with the following information:  Host: localhost Database: vet_clinic User: [place your newly created user name here] Password: Orange Academy   Click on Test Connection. If successful, click OK, otherwise repeat the steps here with the above credentials.  Viewing Tables Click on the ... next to clap@localhost. Expand clap@localhost \u0026gt; databases \u0026gt; vet_clinic \u0026gt; schemas \u0026gt; public \u0026gt; tables \u0026gt; pets.\nYou are now able to see all of the column\u0026rsquo;s name and data types. If you double click on pets, you will see all of the data inside the data.\nAdding Tables To add a table using DataGrip using the GUI, right click on public \u0026gt; New \u0026gt; Table.\nHere you create the table using the + or write the SQL script in the SQL Script section.\nPlace the following in the SQL Script section:\nCREATE TABLE public.owners ( id serial PRIMARY KEY, first_name varchar(50) NOT NULL, age integer ); Click Execute.\nNow you have two tables.\nRunning Scripts On the edge of the new window (either left or right), click on Files. This will open up the Files panel.\nRight click in the middle of the panel, then click Attach Directory. Go to the same directory as your print_pets.sql and then click Open. Inside the panel and right click on the directory folder \u0026gt; new \u0026gt; SQL file and create a file called fill_owners.sql.\nDouble click on the new file and paste the following in the file:\nINSERT INTO owners (first_name, age) VALUES (\u0026#39;Elliot\u0026#39;, 32); INSERT INTO owners (first_name, age) VALUES (\u0026#39;Roslyn\u0026#39;, 12); INSERT INTO owners (first_name, age) VALUES (\u0026#39;Minta\u0026#39;, 56); INSERT INTO owners (first_name, age) VALUES (\u0026#39;John\u0026#39;, 48); To execute this script, click on the green play button in the top left corner. Choose the corresponding console for vet_clinic.\nIf you double click on owners in the database panel to view to contents of the table.\n"
},
{
	"uri": "/software-eng-essentials/command-line-bash/login/",
	"title": "Logging in",
	"tags": [],
	"description": "",
	"content": "Linux Intro What Is Linux? Linux is a piece of software called the kernel.\nThe kernel handles tasks such as booting the system and interacting with hardware devices.\nThe kernel- by itself- doesn\u0026rsquo;t provide much functionality for users.\nThe Linux kernel combined with the collection of software known as the operating system (OS)\ngives users functionality. This combination makes up a Linux distribution (also called a distro).\nDistros are maintained by the community, or an organization like RHEL.\nAccessing a Linux System Logging In There are three ways to log in to a Linux system.\n Via the GUI- On laptops, desktops, and some servers, a GUI-based login appears by default. Via the command line- GUI software uses a lot of resources (CPU, RAM, etc.), so a command-line login is often selected by system administrators. Via the network- with special software installed, a network-based login is possible.  Using the GUI Best advice when given the choice to use a Linux GUI:\nDon\u0026rsquo;t.\nBut if you do, access the command-line environment by opening a terminal window.\nBasic Command-Line Execution The most common Shell program in Linux is bash.\nShell Prompt After login, you will see one of two different prompts.\nThe default prompt for the regular user, a dollar sign:\n$ or\nThe default prompt for a root user, a pound sign:\n# In most Linux systems, the $ and # prompts are preceded by your username, system name, and current directory name.\nFor example, a login prompt for the user name leslie on a computer named techtalentsouth with /usr/lib/ as the current working directory would appear as:\n$ Running Simple Commands Bash commands are available that need no options or arguments to run.\nSimply enter the command and voila!- you have output!\n$ date Thu Jan 11 21:56:00 CST 2018 $ hostname mainframe $ ls Desktop Downloads Pictures Templates Documents Music Public Videos $ pwd /home/student Command-Line Structure Commands can be more complicated- taking options to modify behavior,\nand receiving arguments declaring which file or folder to act on.\nThe command structure or syntax is simple, and consists of three parts:\n Command Name Option(s) Arguments  Options Also referred to as flags, most commands have one or more options\nwhich are predefined values for changing the behavior of a command.\nOption syntax is typically a single letter prepended with a hyphen:\n~$ ls -a . .. .bash_history .bash_logout .bash_profile .bashrc Or the command may take a whole word as an option, prepended with a double hyphen.\n~$ ls --all . .. .bash_history .bash_logout .bash_profile .bashrc There are some commands that take whole word options with a single hyphen,\nbut most commands will use the double hyphen syntax.\nArguments provides useful information to the command, typically a filename or user name that you want the command to be performed on.\nGetting Meta Like Derek Zoolander peering thoughtfully into a puddle at his own reflection,\nyou can peer into the darkness of the shell and ask the username you are currently logged in as with whoami.\nThe shell will answer.\n~$ whoami student The who command lets you see information about your current login session.\n~$ who student tty1 2018-1-10 19:41 The -u option tells the who command to add information about idle time\nand the process ID (PID).\nThe -H option asks that a header be printed.\nLet\u0026rsquo;s see the two combined!\n~$ who -uH NAME LINE TIME IDLE PID COMMENT student tty1 2018-1-10 19:41 - 646 Use the id command to find out information about your identity.\n~$ id uid=1000(student) gid=1000(student) groups=1000(student),10(wheel) context=unconfined_u:u nconfined_r:unconfined_t:s0-s0:c0.c1023 Getting Help The Filesystem Understanding the Filesystem Most Used Directories Naming Considerations Navigating the Filesystem Linux reserves the special names\n. for the current directory and\n.. for the current directory\u0026rsquo;s parent directory.\nManaging the Filesystem Managing Directories Managing Files Wildcards Redirection "
},
{
	"uri": "/software-eng-essentials/command-line-bash/metacharacters/",
	"title": "Metacharacters",
	"tags": [],
	"description": "",
	"content": "Advanced Linux Commands Intro Connecting and Expanding Commands Metacharacters The shell uses metacharacters to allow commands to be strung together.\nMetacharacters include:\n | Pipe Character \u0026amp; Ampersand ; Semicolon ) Right Parenthesis ( Left Parenthesis \u0026lt; Less Than Sign \u0026gt; Greater Than Sign  Piping Between Commands The pipe | metacharacter connects the output from one command to the input of another command.\nThis lets you have one command work on some data and the have the next command deal with the results.\n$ cat /etc/passwd | sort | less  The cat command lists the contents of the /etc/passwd file and pipes the output to the sort command. The sort command takes the usernames that begin each line of the /etc/passwd, sorts them alphabetically, and pipes the output to the less command. The less command pages through the output.  Sequential Commands Background Commands Expanding Commands Expanding Arithmetic Expressions Expanding Variables Using Shell Variables Environment Variables Creating and Using Aliases Creating Your Shell Environment You can customize your shell to help you work more efficiently.\nShortcuts are created by setting aliases.\nBits of information can be stored in environment variables.\nConfiguring Your Shell Setting Your Prompt Adding Environment Variables "
},
{
	"uri": "/python/nonrelational-db/mongo-files/",
	"title": "Mongo Files",
	"tags": [],
	"description": "",
	"content": "Mongo files "
},
{
	"uri": "/web-essentials/webmastery-foundations/src/one-page-many-stylesheets/",
	"title": "One page many stylesheets",
	"tags": [],
	"description": "",
	"content": "Index "
},
{
	"uri": "/",
	"title": "Orange Academy",
	"tags": [],
	"description": "",
	"content": "Welcome to Orange Academy! Curriculum for our current offerings can be found on the navbar to the left.\n"
},
{
	"uri": "/python/relational-db/orm-files/",
	"title": "ORM Files",
	"tags": [],
	"description": "",
	"content": "Welcome to Python Database Pillars ORM Class Exercise Files:\n Starter Code Models Seed File  "
},
{
	"uri": "/golang/testing/future-additions/performance/",
	"title": "Performance",
	"tags": [],
	"description": "",
	"content": "Benchmarking Tests func BenchmarkCalculate(b *testing.B){ ... Ran with: go test -bench\nCapping CPU Usage During Test Note: We\u0026rsquo;re going to use benchmarking in the next couple of topics as it can clearly demonstrate the concepts being covered, but rest assured, benchmarking will have its own lesson.\nIt\u0026rsquo;s not uncommon to have packages that are being tested to contain goroutines, channels and other synchronization systems. By default, a go test will run with max CPU\u0026rsquo;s at 1, unless runtime.GOMAXPROCS has been set in the code or in the environment variables.\nYou could use\nGOMAXPROCS=3 go test in order to run tests with 3 cores.\nBut! There\u0026rsquo;s a better way. Let\u0026rsquo;s say you wanted to see the difference in running with different amounts of cores. In this case you could do:\ngo test -cpu=1,2,4 The above will run the test three times, first with one cpu, then with 2, and then with 4 cpu\u0026rsquo;s.\nLet\u0026rsquo;s say we have the following benchmark test on a Fibenacci function.\nfunc benchmarkFib(fibArg int, b *testing.B) { //run the Fib function b.N times. \tfor n := 0; n \u0026lt; b.N; n++ { Fib(fibArg) //fmt.Println(\u0026#34;new iteration occured: \u0026#34;, n) \t} } func BenchmarkFib1(b *testing.B) { benchmarkFib(1, b) } func BenchmarkFib2(b *testing.B) { benchmarkFib(2, b) } func BenchmarkFib3(b *testing.B) { benchmarkFib(3, b) } func BenchmarkFib10(b *testing.B) { benchmarkFib(10, b) } func BenchmarkFib20(b *testing.B) { benchmarkFib(20, b) } func BenchmarkFib40(b *testing.B) { benchmarkFib(40, b) } Using the above example of benchmarking the Fib function, we could use the cpu and verbose flags to get the following:\n$ go test -bench=. -v -cpu=1,2,4 -race goos: darwin goarch: amd64 pkg: github.homedepot.com/om-labs/go-testing/benchmarking BenchmarkFibBase 500000 2474 ns/op BenchmarkFibBase-2 500000 2484 ns/op BenchmarkFibBase-4 500000 2480 ns/op BenchmarkFib1 50000000 24.1 ns/op BenchmarkFib1-2 100000000 24.1 ns/op BenchmarkFib1-4 50000000 25.5 ns/op BenchmarkFib2 30000000 52.2 ns/op BenchmarkFib2-2 30000000 52.0 ns/op BenchmarkFib2-4 30000000 54.5 ns/op BenchmarkFib3 20000000 81.1 ns/op BenchmarkFib3-2 20000000 79.7 ns/op BenchmarkFib3-4 20000000 79.1 ns/op BenchmarkFib10 500000 2572 ns/op BenchmarkFib10-2 500000 2536 ns/op BenchmarkFib10-4 500000 2492 ns/op BenchmarkFib20 5000 311494 ns/op BenchmarkFib20-2 5000 308299 ns/op BenchmarkFib20-4 5000 309446 ns/op BenchmarkFib40 1 4568477072 ns/op BenchmarkFib40-2 1 4642059146 ns/op BenchmarkFib40-4 1 4656502555 ns/op PASS ok github.homedepot.com/om-labs/go-testing/benchmarking 42.293s Note: The race option should be paired with this command for any serious concurrency programming, but is outside the scope of this lesson.\n"
},
{
	"uri": "/python/foundation/additional-resources/picture-manipulation/",
	"title": "Picture Manipulation",
	"tags": [],
	"description": "",
	"content": "Create a Python file called picture_manipulation.py within a PyCharm project called python-fundamentals\nHave you ever played with special photo effects on a computer? In this lesson, we are going to talk about how those special effects are created.\nFile Systems Before talking about how to change an image, we need to figure out direct the program to the location of the file. To locate a file, there are two different ways to do so: absolute vs. relative file paths.\nAbsolute File Paths Most file systems are hierarchical, forming a tree that begins with a root directory. An absolute filename specifies where the file is stored from the root.\n  In Windows, the root is typically indicated by the startup drive letter, such as C:\\\n  In Mac and Linux systems, the root is typically indicated by /\n  For example: the absolute file path of admin (in the green box below) is C:\\Users\\admin\nRelative File Paths Most operating systems and programming languages remember one location in the file system as your \u0026ldquo;present working directory\u0026rdquo;. A file can be described relative to that location: a relative file path.\nFor example: In the above picture, the relative file path of nice.jpg from admin is ./Student login/Desktop/nice.jpg. The two dots at the beginning represent \u0026ldquo;go up one directory\u0026rdquo;.\nRGB Percentages RGB represents red, green and blue light added together in various ways to reproduce a broad array of colors. An RGB color value is specified with three values: [red, green, blue]. Each parameter defines the intensity of the color as a floating point number between 0 and 1.\nFor example, [0, 0, 1] is rendered as blue, because the blue parameter is set to its highest value (1) and the others are set to 0.\nNumpy Arrays Numpy is the core library for scientific computing in Python. We have talked about arrays and typed arrays before, a numpy array is a typed array and is indexed by a tuple of positive (non-negative) integers.\nBefore we can convert an image to a 3D numpy array, we would need to place the image in the current project that we are working on. Take the following image and save in your PyCharm project.\nArrays can be defined with items that are made up of arrays, with each bracketed array enclosed inside the larger brackets of the parent array. Say that we had an image that was a 2x3 pixel image. (2 rows and 3 columns) like the following:\nWe would create that with the following in Python:\nimport numpy as np img = np.array([[[1, 0, 0], [1, 0, 0], [0, 0, 0]], [[1, 0, 0], [0, 0, 0], [1, 0, 0]]]) print(img) Output:\n[[[1 0 0] [1 0 0] [0 0 0]] [[1 0 0] [0 0 0] [1 0 0]]] Rendering an Image To render an image on a screen, we are going to use the Python library matplotlib. matplotlib is a Python 2D plotting library which allows you to create plots, histograms, bar charts, scatterplots, etc. The figures created by matplotlib are interactive graphical user interfaces (GUIs). To be able to manipulate the images, the images are converted into a numpy array.\nRead the Image Data Using the above numpy array, finding out the number of rows of the image is as follows:\nOutput:\nprint(len(img)) Output: 2\nTo find out the number of columns of the image: Output:\nprint(len(img[0])) Output: 3\nFrom the table, it is visible that at position (0,1) is [1, 0, 0]. To access this same pixel in img, do the following:\nprint(img[0][1]) Output: [1, 0, 0]\nIf we wanted to change the bottom right pixel (img[1][2]) to green ([0, 1, 0]), we would do the following:\nprint(\u0026#34;Before: \u0026#34;, img[1][2], end=\u0026#34;\u0026#34;) img[1][2] = [0, 1, 0] print(\u0026#34; After: \u0026#34;, img[1][2]) Output: Before: [1, 0, 0] After: [0, 1, 0]\nImage Set Up You can copy and paste the image into the project by right clicking on the image and clicking copy, go into PyCharm and right click on the project name in PyCharm and click paste.\nFile Paths in Python\nWhen working with images in this lesson, we will be primarily using absolute file path. Since every user will save their projects/images in varying places, this allows the navigation to the project work on every computer. To get access to finding absolute paths in Python we are going to use the os library.\nTo work with file paths, we need to import the os module with the following:\nimport os If we wanted to print the absolute file path of the current project in Python, we would do the following:\ndirectory = os.path.dirname(os.path.abspath(__file__)) The above would set directory to a value with a value like the following:\n/Users/user123/PycharmProjects/python-fundamentals If we had an image called thd-vivid-orange.png in the python-fundamentals folder, we would need to do the following to directly \u0026ldquo;point\u0026rdquo; at it.\nfilename = os.path.join(directory, \u0026#39;thd-vivid-orange.png\u0026#39;) The above would use the absolute path to the current directory that was receive with the dirname call and attach the file name, thd-vivid-orange.png, to the end.\nConvert to Numpy Array\nTo work with numpy arrays, we need to import both matplotlib and numpy with the following:\nimport matplotlib.pyplot as plt import numpy as np When working with an image in matplotlib, you need to convert the image into a numpy array. To convert the image, use the following command:\nimg = plt.imread(filename) File Permissions\nWhen working with an image, you need to make sure that you have permission to alter the image. In order to do this, you must change the image\u0026rsquo;s \u0026ldquo;write\u0026rdquo; permission to allow this.\nThis is done with:\nimg.setflags(write=1) Set Up Image Output When working with image windows in matplotlib, you need to figure out how many images you want to show and where would you put them. The set up of images is in a grid format, so we will need to specify how many rows and columns that you need to show the desired images.\nTo create a 1x1 grid (1 row and 1 column) of images in a window, place the following line:\nfig, ax = plt.subplots(1,1) Software tools stretch the size of the image and generate pixels to fill in the blanks. Interpolation is the process by which a small image is made larger. Interpolated images produce smoother lines and a better large print than if the original, small image was simply printed large.\nThe default mode of an image in matplotlib is interpolated. To change img to not be interpolated and place the image in the 1x1 grid., use the following line of code:\nax.imshow(img, interpolation=\u0026#39;none\u0026#39;) Objects and Methods\nA class is a category of objects that have properties (a set of variables with potentially unique values for each object) and methods (a common set of scripts that do things). An object is an instance of its class.\nNote: We are not going to get too into this right now, just needed to show the terminology before we go over some examples.\nFrom the above code:\n   Code Snippet Description     fig, ax = plt.subplots(1,1) This line returns (gives back) a tuple that has two items in it: an object of the Figure which is being stored in a new variable, fig. An object of the AxesSubplot class which is being stored in the variable ax.   ax.imshow(img, interpolation='none') The method is imshow() being called on the object ax. It is being given 1 argument: img.    Figure The whole figure. The figure keeps track of all the child Axes, artists (titles, figure legends, etc), and the canvas. A figure can have any number of Axes, but to be useful should have at least one.\n| | |:\u0026mdash;-:|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; |Axes |'a plot\u0026rsquo;, it is the region of the image with the data space. The Axes class and it’s member functions are the primary entry point to working with the OO interface. |Axis |These are the number-line-like objects. They take care of setting the graph limits and generating the ticks. |Artist |Basically everything you can see on the figure is an artist. This includes Figure, Axes, Axis, Text, Line2D, Collection, and Patch Objects. When the figure is rendered, all of the artists are drawn to the canvas.\nShowing the Image Place the following starter code in a new Python file called changing_views.py:\nimport matplotlib.pyplot as plt import os.path import numpy as np \u0026#39;\u0026#39;\u0026#39;Read the Image Data\u0026#39;\u0026#39;\u0026#39; directory = os.path.dirname(os.path.abspath(__file__)) filename = os.path.join(directory, \u0026#39;thd-vivid-orange.png\u0026#39;) img = plt.imread(filename) img.setflags(write=1) \u0026#39;\u0026#39;\u0026#39;Set Up Image Output\u0026#39;\u0026#39;\u0026#39; fig, ax = plt.subplots(1, 1) ax.imshow(img, interpolation=\u0026#39;none\u0026#39;) \u0026#39;\u0026#39;\u0026#39;Show Image \u0026#39;\u0026#39;\u0026#39; plt.ioff() plt.show() Run your code and see the output.\nPicture Manipulation Lab\n"
},
{
	"uri": "/python/foundation/additional-resources/picture-manipulation-labs/",
	"title": "Picture Manipulation Lab",
	"tags": [],
	"description": "",
	"content": "Picture Manipulation\nChanging Views of Images Open your Python file called changing_view.py within PyCharm. Your file should look like the following:\nimport matplotlib.pyplot as plt import os.path import numpy as np \u0026#39;\u0026#39;\u0026#39;Read the Image Data\u0026#39;\u0026#39;\u0026#39; directory = os.path.dirname(os.path.abspath(__file__)) filename = os.path.join(directory, \u0026#39;thd-vivid-orange.png\u0026#39;) img = plt.imread(filename) img.setflags(write=1) \u0026#39;\u0026#39;\u0026#39;Set Up Image Output\u0026#39;\u0026#39;\u0026#39; fig, ax = plt.subplots(1, 1) ax.imshow(img, interpolation=\u0026#39;none\u0026#39;) \u0026#39;\u0026#39;\u0026#39;Show Image \u0026#39;\u0026#39;\u0026#39; fig.show() plt.ioff() plt.show() Showing Two Images In your changing_view.py file, replace lines 12 and 13 with the following 2 lines:\nOld:\nfig, ax = plt.subplots(1, 1) ax.imshow(img) New:\nfig, ax = plt.subplots(1, 2) ax[0].imshow(img) Run the code to see the new output.\nModify the code to look like the following:\nShowing Five Images Comment out the changes you made in Showing Two Images. Using a for loop, modify the code to look like the following:\nimage:picture-manipulation/modifying_five_images.png[THD, 600, 300]\nZooming In Comment out the changes you made in Showing Five Images. Replace all of the code in the '''Set Up Image Output''' section and replace it with:\nfig, ax = plt.subplots(1, 2) ax[0].imshow(img) ax[1].imshow(img) ax[1].set_xlim(300, 665) ax[1].set_ylim(470, 120) Here we introduce two new methods: set_xlim and set_ylim\n   Methods Description     set_xlim(xmin,xmax) Set lower and upper limits to x-axis   set_ylim(ymin,ymax) Set lower and upper limits to y-axis. Notice the first number is larger than the first number.    This allows us to zoom in to the specific range of an image.\nUsing the above image, zoom in to three different 10 pixel by 10 pixel regions. An example is shown below:\nModifying Images Changing Pixels Create a new file called manipulate_images.py inside of your picture-manipulation project. Place the following in the file:\nimport matplotlib.pyplot as plt import os.path import numpy as np \u0026#39;\u0026#39;\u0026#39;Read the Image Data\u0026#39;\u0026#39;\u0026#39; directory = os.path.dirname(os.path.abspath(__file__)) filename = os.path.join(directory, \u0026#39;orange-method.png\u0026#39;) img = plt.imread(filename) img.setflags(write=1) \u0026#39;\u0026#39;\u0026#39;Modify Image\u0026#39;\u0026#39;\u0026#39; height = (len(img)) width = (len(img[0])) for row in range(100, 120): for column in range(50, 100): img[row][column] = [0, 0, 1] \u0026#39;\u0026#39;\u0026#39;Show Image \u0026#39;\u0026#39;\u0026#39; fig, ax = plt.subplots(1, 1) ax.imshow(img) plt.ioff() plt.show() Run your code.\nAlter the code to place a black box covering the M.\nChanging Pixels Based on Color Comment out the following lines of code with a multi-line comment:\nfor row in range(100, 120): for column in range(50, 100): img[row][column] = [0, 0, 1] Under your new comment, add the following:\nfor row in range(155): for column in range(width): if sum(img[row][column]) \u0026gt; 2: img[row][column] = [0, 0, 1] Run your code. Change your code to change the color of only the orange box around the word Method to a color of your choice.\nExample Output For a list of RGB percentages, look here: http://www.december.com/html/spec/colorpercompact\nChallenge: Create your own filter Using the tactics from the previous activities, create a filter like black and white or sepia on the Orange Academy image or an image of your choice. (It is best to use a .png file)\nCreating an Image Altering Images So far we have modified already created images. We are now going to create our own image. link:python-files/picture-manipulation-starter/make_image.py[Download this File]. Modify the code to look like following:\nAdding a Newly Created Image Create a fourth image with a crazy design of your choice.\n"
},
{
	"uri": "/python/relational-db/postgres-files/",
	"title": "Postgres Files",
	"tags": [],
	"description": "",
	"content": "Welcome to Python Database Pillars Postgres-Python Starter Code\n"
},
{
	"uri": "/software-eng-essentials/db-sql/postgres-setup/",
	"title": "PostgreSQL Setup",
	"tags": [],
	"description": "",
	"content": "Background PostgreSQL has already been installed on each computer via homebrew. Now we just need a way to auto-start or manual-start postgres when a student is logged in. I researched how to configure postgres to auto-start when logging in as Orange Academy. That was easy but I could not get postgres to remain running after Orange Academy logs out.\nThere is a way to use ssh to allow students to connect to a postgres macOS user and startup the postgres server, but it seems a bit too complex as each student would have to create ssh keys and then get them added to the postgres user\u0026rsquo;s .ssh/authorized_keys file. Here is a link with more information.\nThe third option is to configure the students to have admin rights on their computer. Then they can sudo su - Orange Academy and startup or shutdown postgres as needed. This looks like the best solution so far. Below are the steps.\nStep 1 - Make Each Student an Admin User on Their Computer  Login as Orange Academy Go to System Preferences =\u0026gt; Users \u0026amp; Groups and make each student an Admin user Also update the workstation-setup files as aliases have changed: cd ~/workstation-setup \u0026amp;\u0026amp; git pull Logout as Orange Academy and restart the machine to make the Admin user updates active.  Step 2 - Startup postgres and create a postgres user   Each student should login with their LDAP credentials\n  From the Terminal run sudo su - Orange Academy and enter your password\n  Start postgres: pg-start\n  Create a postgres user with your LDAP name as the user name: createuser -sed myLdapUserName\n  From here on out, you don\u0026rsquo;t need to be the Orange Academy user anymore. Exit out of the sudo su session and continue as yourself. exit\n  Create a test database with your LDAP name as the db name: createdb whoami# you need the backquotes for this to work\n  Helpful Aliases I setup the following aliases to make it easier to manage postgres:\nalias pg-create-user=\u0026#39;createuser -sed $*\u0026#39; alias pg-start=\u0026#39;pg_ctl -D /usr/local/var/postgres -l /usr/local/var/log/postgres.log start\u0026#39; alias pg-status=\u0026#39;pg_ctl -D /usr/local/var/postgres status\u0026#39; alias pg-log=\u0026#39;tail /usr/local/var/log/postgres.log\u0026#39; alias pg-pid=\u0026#39;ls -als /usr/local/var/postgres/postmaster.pid\u0026#39; alias pg-stop=\u0026#39;pg_ctl -D /usr/local/var/postgres stop -s -m fast\u0026#39; "
},
{
	"uri": "/software-eng-essentials/db-sql/remote-postgres-setup/",
	"title": "Remote Postgres Setup",
	"tags": [],
	"description": "",
	"content": "The following instructions will guide you through setting up a postgreSQL database on an ephermal server on https://server.homedepot.com\nGo to https://server.homedepot.com\n  Click Catalog (Located at the top of the window)\n  Click on PostgreSQL and use the following credentials:\n Group: Development Name of depoloyed service: Postgresql (CentOS7) Environment: Atlanta - Dev Servers Server Size: Small (1 x 2) Quantity: 1.0 New Password: 0r@ngeMethod Confirm Password: 0r@ngeMethod Click Submit. (Wait ~10 minutes for the server to be created)    Once your Server is created, click on the newly created server\n  Click on Console on the left of the screen and type the following in the console:\n  Use the user name: root password: 0r@ngeMethod\n  Log in to postgres: su - postgres\n  Create super user: psql\n  Type CREATE USER \u0026lt;username\u0026gt; WITH ENCRYPTED PASSWORD \u0026lt;password\u0026gt;;. Fill in and with the desired user name and password.\n  Type ALTER USER \u0026lt;username\u0026gt; SUPERUSER;\n  Type \\q then press enter\n  Type exit\n  Type cd /var/lib/pgsql/9.6/data\n Note: Find the most current version (9.6 at the time)\n   Modify the pg_hba.conf file by opening it up in vi.\nNavigate to the bottom of the file and update all instances of the word \u0026lsquo;peer\u0026rsquo; to be \u0026lsquo;md5\u0026rsquo;.\n\u0026ldquo;local\u0026rdquo; is for Unix domain socket connections only\nlocal all all md5 At the very bottom of pg_hba.conf add the following two lines:\nhost all all 0.0.0.0/0 md5 host all all ::/0 md5 Save the file with :wq\nEdit /var/lib/pgsql/9.6/data/postgresql.conf (with vi): Find the following line:\nlisten_addresses = \u0026#39;localhost\u0026#39; Make sure to uncomment the line and change it to:\nlisten_addresses = \u0026#39;*\u0026#39; Type: reboot\nTo log into your database remotely via the command line:\npsql -h \u0026lt;DB_HOST\u0026gt; -d \u0026lt;DB_NAME\u0026gt; -p \u0026lt;PORT\u0026gt; -U \u0026lt;DB_USER\u0026gt; -W For example: psql -h 10.16.46.401 -d products -p 5432 -U jsmith -W\n"
},
{
	"uri": "/python/automation/reports/",
	"title": "Report Creation Additional Files",
	"tags": [],
	"description": "",
	"content": "Report Creation Additional Files "
},
{
	"uri": "/web-essentials/webmastery-foundations/src/sass/",
	"title": "SASS",
	"tags": [],
	"description": "",
	"content": "Index "
},
{
	"uri": "/software-eng-essentials/command-line-bash/scripting-fundamentals/",
	"title": "Scripting Fundamentals",
	"tags": [],
	"description": "",
	"content": "Objectives  Command line arguments Variables User input Reading from STDIN  Command line arguments We have already created a script that receives command line arguments. The ekill program receives a \u0026lt;pid\u0026gt; argument. That argument was assigned to the $1 variable by the system default. A second command line argument would be assigned to $2.\nUsing a couple of command line arguments\nfanciercopy script\n#!/bin/bash # A fancier copy script cp $1 $2 # Verify the copy worked echo Details for $2 ls -lh $2 Executing the fanciercopy script\n$ ./fanciercopy /tbs-archives/jcvd/highlights.data ./tps-reports.data Details for ./tps-reports.data drwxr--r-- 34 KXB0QJK staff 777K Oct 9 23:58 tps-reports.data Variables A variable is a label that represents data.\nSpecial Variables In addition to $1 and $2, the system sets other special variables for you to use.\nSpecial Variables\n   Variable Description     $0 The name of the Bash script.   $1-$9 The first 9 arguments to the Bash script.   $# How many arguments were passed to the Bash script.   $@ All the arguments supplied to the Bash script.   $? The exit status of the most recently run process.   $$ The process ID of the current script.   $USER The username of the user running the script.   $HOSTNAME The hostname of the machine the script is running on.   $SECONDS The number of seconds since the script was started.   $RANDOM Returns a different random number each time is it referred to.   $LINENO Returns the current line number in the Bash script.    Setting and Calling Variables If we take choose to name a variable var1 and assign it a value Beowulf, it would look like this:\nSetting a variable\n$ hero=Beowulf And when we want to call the variable:\nCalling a variable\n$ echo $hero Beowulf There are two things to remember\n When setting the variable, leave no spaces around the = sign. When calling the variable, prepend a $ to the variable name.  Quotations We need to use single quotes to assign complex values with spaces to variable names.\nSingle quotes around values\n$ story=\u0026#39;Epic Poem\u0026#39; And double quotes when we want variable expansion or substitution to be allowed.\nDouble quotes around values, using substitution\n$ tag=\u0026#34;An $storyabout $hero\u0026#34; $ echo $tag An Epic Poem about Beowulf Command substitution allows us to take the output of a command or program (what would normally be printed to the screen) and save it as the value of a variable. To do this we place it within parens, preceded by a $ sign.\n Command substitution does remove any newlines from the output.\n $ hereheis=$(ls | grep -i beowulf) $ echo $hereheis beowulf_1.txt beowulf_1_copy.txt beowulf_1_reversed.txt beowulf_1_sk8er.txt beowulf_complete.txt beowulf_head.txt Exercises\n Create a simple script which will accept some arguments from the command line and echo out some details about them (e.g., how many are there, what is the second one, etc.). Create a script which will print a random word.  Hint: There is a file containing a list of words on your system (usually /usr/share/dict/words or /usr/dict/words).    User Input We have already written and executed bash scripts that took user input\u0026ndash;command line arguments. But now we want to write scripts that deal more interactively with user input.\nIf we would like to prompt the user for input then we use a command called read. This command takes the input and will save it to a variable.\nThe basic syntax for read\nread \u0026lt;variable_name\u0026gt; Interactive introduction script\nUsing read with introscript\n#!/bin/bash # Ask the user for their name echo Hello, who am I talking to? read varname echo It is nice to meet you $varname. executing the introscript\n$ ./introduction Hello, who am I talking to? JCVD It is nice to meet you JCVD. $ The read command has useful options that are essential for interactive scripts.\nUsing read with loginscript\n#!/bin/bash # Ask the user for login details read -p \u0026#39;Username: \u0026#39; uservar read -sp \u0026#39;Password: \u0026#39; passvar echo echo Thank you, $uservar. We now have your login details. executing the loginscript\n$ ./loginscript Username: jcvd_fan_1960 Password: Thank you, jcvd_fan_1960. We now have your login details. $ Using read with multiple arguments\nUsing read and multiple arguments with moviescript\n#!/bin/bash # Demonstrate how read actually works echo What movies do you like? read movie1 movie2 movie3 echo Your first movies was: $movie1 echo Your second movies was: $movie2 echo Your third movies was: $movie3 executing the moviescript\n$ ./moviescript What movies do you like? Kickboxer Timecop Cyborg Your first movies was: Kickboxer Your second movies was: Timecop Your third movies was: Cyborg $ ./moviescript What movies do you like? Kickboxer Timecop Universal Soldier Your first movies was: Kickboxer Your second movies was: Timecop Your third movies was: Universal Soldier $ Reading from STDIN The ability to pipeline a series of simple, single purpose commands together to create a larger solution tailored to our exact is one of the real strenghs of Unix. Once we have a firm grasp of these commands and concepts, we can easily implement this with our scripts also. By using redirection and proficient use Unix utilites, we can create scripts that act as filters to modify data in specific ways for us.\nIn the link:./basics#input_output[Basics] lesson, we learning that Unix accomodates piping and redirection by way of special files. Each process gets its own set of files (one for STDIN, STDOUT and STDERR respectively) and they are linked when piping or redirection is invoked.\nReading from STD\nUsing STDIN and awk with blockbustersummary\n#!/bin/bash # A basic summary of blockbuster movies echo Here is a summary of the blockbuster movie data: echo ================================================ echo cat /dev/stdin | awk \u0026#39;$3 \u0026gt;= 100 {print $1 \u0026#34; - \u0026#34; $2 \u0026#34; $ \u0026#34; $3 \u0026#34; (in millions)\u0026#34;}\u0026#39; inspecting the movieboxofficedata.txt file\n$ cat movieboxofficedata.txt Under Seagal 1 DieHard Willis 5 Predator Arnold 11 Commando Arnold 13 Kickboxer JCVD 130 Timecop JCVD 120 Sidekicks Norris 101 KarateKid Macchio 100 Rambo Stallone 107 Cyborg JCVD 100 executing the blockbustersummary script\n$ cat movieboxofficedata.txt | ./blockbustersummary Here is a summary of the blockbuster movie data: ================================================ Kickboxer - JCVD $ 130 (in millions) Timecop - JCVD $ 120 (in millions) Sidekicks - Norris $ 101 (in millions) KarateKid - Macchio $ 100 (in millions) Rambo - Stallone $ 107 (in millions) Cyborg - JCVD $ 100 (in millions) Exercises\n Create a simple script which will ask the user for a few pieces of information, then combine this into a message which is echo\u0026rsquo;d to the screen. Add to the previous script to add in some data coming from command line arguments and maybe some of the other system variables. Create a script which will take data from STDIN and print the 3rd line only.  Functions Functions in bash may take the following form:\nfunction_name () { \u0026lt;function_commands\u0026gt; } Passing Arguments to a Function Like in other programming languages, bash functions may be passed arguments.\nThe first argument is assigned to the variable $1 by the system.\n#!/bin/bash # Passing a single argument to a function epic_characters () { echo I am $1 } epic_characters Beowulf epic_characters Grendel The second argument is assigned to the variable $2.\n#!/bin/bash # Passing two arguments to a function epic_characters () { echo I am $1 the $2! } epic_characters Beowulf hero epic_characters Grendel monster  $0 is the variable name assigned to the name of your program.\n$# is the variable name assigned to the number of arguments passed.\n Return Values Many programming languages have functions which may give a return value from their functions.\n"
},
{
	"uri": "/python/automation/send_email/",
	"title": "Sending Emails Additional Files",
	"tags": [],
	"description": "",
	"content": "Sending Emails Additional Files "
},
{
	"uri": "/web-essentials/webmastery-foundations/solutions/",
	"title": "Solutions",
	"tags": [],
	"description": "",
	"content": "Objectives This directory holds all of the solution files for webmastery foundations\nIndex "
},
{
	"uri": "/web-essentials/webmastery-foundations/src/",
	"title": "Source files",
	"tags": [],
	"description": "",
	"content": "Objectives This directory holds all of the source files for webmastery foundations\nIndex "
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/python/relational-db/teacher-postgresql-setup/",
	"title": "Teacher PostgreSQL Setup",
	"tags": [],
	"description": "",
	"content": "Go to https://server.homedepot.com\n Click Catalog (Located at the top of the window) Click on PostgreSQL and use the following credentials:  Group: Development Name of depoloyed service: Postgresql (CentOS7) Environment: Atlanta - Dev Servers Server Size: Small (1 x 2) Quantity: 1.0 New Password: Orange Academy Confirm Password: Orange Academy Click Submit. (Wait ~10 minutes for the server to be created)   Once your Server is created, click on the newly created server  Click on Console on the left of the screen and type the following in the console\n  Use the user name: root password: Orange Academy\n  Log in to postgres: su - postgres\n  Create super user: psql\n  Type CREATE USER \u0026lt;username\u0026gt; WITH ENCRYPTED PASSWORD \u0026lt;password\u0026gt;;. Fill in and with the desired user name and password.\n  Type ALTER USER \u0026lt;username\u0026gt; SUPERUSER;\n  Type \\q then press enter\n  Type exit\n  Type cd /var/lib/pgsql/9.6/data Note: Find the most current version (9.6 at the time)\n  Modify the pg_hba.conf file by opening it up in vi.\n  Navigate to the bottom of the file and update all instances of the word 'peer' to be 'md5'\n# \u0026#34;local\u0026#34; is for Unix domain socket connections only local all all md5 At the very bottom of pg_hba.conf add the following two lines:\nhost all all 0.0.0.0/0 md5 host all all ::/0 md5 Save the file with :wq\n Edit /var/lib/pgsql/9.6/data/postgresql.conf (with vi):  Find the following line: listen_addresses = 'localhost'\nMake sure to uncomment the line and change it to: listen_addresses = '*'\n  Type: reboot\n  To log into your database remotely via command line: psql -h \u0026lt;DB_HOST\u0026gt; -d \u0026lt;DB_NAME\u0026gt; -p \u0026lt;PORT\u0026gt; -U \u0026lt;DB_USER\u0026gt; -W\n  For example: psql -h 10.16.46.401 -d products -p 5432 -U jsmith -W\n  "
},
{
	"uri": "/python/foundation/additional-resources/tkinter/",
	"title": "Tkinter",
	"tags": [],
	"description": "",
	"content": "Tkinter Tkinter is the standard GUI library for Python. Python when combined with Tkinter provides a fast and easy way to create GUI applications. Tkinter provides a powerful object-oriented interface to the Tk GUI toolkit.\nTkinter makes it to where creating a GUI application is an easy process. To create the \u0026ldquo;Hello World\u0026rdquo; of Tkinter you need to follow the following steps:\n Import the Tkinter module. Create the GUI application window Enter the main event loop  from tkinter import * root = Tk() root.mainloop() Window Properties Resizing The geometry() method is used to resize the window by specifying the desired width and height in pixels.\nfrom tkinter import * root = Tk() root.geometry(\u0026#34;530x150\u0026#34;) root.mainloop() Title The title() method is used to change the title of the window (what is stated at the top of the window).\nfrom tkinter import * root = Tk() root.geometry(\u0026#34;530x150\u0026#34;) root.title(\u0026#34;Tkinter Tutorial\u0026#34;) root.mainloop() Geometry Management Tkinter windows have properties that have the purpose of organizing items on the window. Tkinter has three geometry manager classes: pack, grid, and place. We are going to focus the grid() manager. In the grid manager, we can specify which row and column we want to put a widget.\nExample of the breakdown of a window using the grid() Geometry Manager\nTkinter Widgets Tkinter provides various controls, such as buttons, labels and text boxes called widgets used in a GUI application. Each widget has a set of event handlers to allow for user interaction. Widgets are called before the root.mainloop() line.\nThere are currently 15 types of widgets in Tkinter. Some of the widgets are described below:\n   Widget Name Description     Label Provides a single-line caption for other widgets. It can also contain images.   Entry Displays a single-line text field for accepting values from a user.   Radiobutton Displays a number of options as radio buttons. The user can select only one option at a time.   Button Displays the buttons in an application   tkMessageBox Displays message boxes    To explain the different widgets, we are going to go through an example application that is shown below.\nLabel In row 0, column 2, there is a Label widget that says Tkinter Widget Lesson.\nLabel Set Up\nLabel(window, text=\u0026#34;what you want the label to say\u0026#34;, font=\u0026#34;font font_size font_style\u0026#34;) Label Example\ntitle_label = Label(root, text=\u0026#34;Tkinter Widget Lesson\u0026#34;, font=\u0026#34;Helvetica 12 bold\u0026#34;) title_label.grid(row=0, column=2) Entry The Entry widget is covering row 1, columns 1, 2, and 3. columnspan details how many columns the widget spreads across. To specify how wide you want the Entry widget to be, you use the width attribute, which represents how many characters could fit.\nEntry Set Up\nEntry(window) Entry Example\nname_entry = Entry(root, width=40) name_entry.grid(row=1, column=1, columnspan=3) If we wanted to have a default value inside of the Entry widget we would use insert(). This would give a value in the widget when the application first is pulled up, but it is still possible for the user to change the value.\ninsert Set Up\ninsert(location_of_text, text) Entry using Default Value\nname_entry = Entry(root, width=40) name_entry.insert(END, \u0026#34;Jane Doe\u0026#34;) name_entry.grid(row=1, column=1, columnspan=3) If we wanted to print out the value that the user types in the Entry box, we would need to use get().\nprint(name_entry.get()) Radiobutton In rows 5 - 9, column 1, there are radio buttons. Radio buttons only allow for the user to select one option at a time. There are more steps than the previous widgets to set up a radio button.\n Create a list with the options Create a list that will hold each individual radio button Create a variable that will store the selected value Create a for loop that will:  create each radio button with each option place the new radiobutton in the list of radio buttons place the new radiobutton on the window    Radiobuttons Example\nsizes_choices = [\u0026#34;S\u0026#34;, \u0026#34;M\u0026#34;, \u0026#34;L\u0026#34;, \u0026#34;XL\u0026#34;, \u0026#34;XXL\u0026#34;] sizes_radios = [] data = StringVar() for i, option in enumerate(sizes_choices): curr_button = Radiobutton(root, text=str(option), variable=data, value=i) sizes_radios += [curr_button] sizes_radios[i].grid(row=i + 5, column=1, sticky=W) tkMessageBox tkMessageBox module is used to display message boxes in applications. This widget provides a number of functions that you can use to display an appropriate message. Two examples of uses are showinfo() and showerror().\ntkMessageBox Set Up\nmessagebox.use(title, message) tkMessageBox Example\nmessagebox.showinfo(\u0026#34;Welcome!\u0026#34;, \u0026#34;Successfully Registered for the Race!\u0026#34;) Button In row 10, column 3, there is a Button widget that says Submit. In this example, this is the first widget that we have that is using an event handler. A button event handler takes care of what to do (which function to call) when a user clicks on the button.\nButton Set Up\nButton(window, text=\u0026#34;what you want the label to say\u0026#34;, command=function to call) Say there is a function greeting:\ndef greeting(): messagebox.showinfo(\u0026#34;Welcome!\u0026#34;, \u0026#34;Successfully Registered for the Race!\u0026#34;) If you want to have a Button that will call the greeting function when clicked, you would write it in the following way:\nsubmit_button = Button(root, text=\u0026#34;Submit\u0026#34;, command=greeting) submit_button.grid(row=10, column=3) If we changed greeting to have parameters, like the following:\ndef greeting(name): messagebox.showinfo(\u0026#34;Welcome!\u0026#34;, name + \u0026#34; You have successfully registered for the race!\u0026#34;) You would need to change the button command argument to use lambda. (We are not going to get into lambda details right now).\nname = name_entry.get() submit_button = Button(root, text=\u0026#34;Submit\u0026#34;, command=lambda: greeting(name)) submit_button.grid(row=10, column=3) Example Tkinter Program The complete code to create the above application is here:\nfrom tkinter import * from tkinter import messagebox def main_window(root): title_label = Label(root, text=\u0026#34;Tkinter Widget Lesson\u0026#34;, font=\u0026#34;Helvetica 12 bold\u0026#34;) title_label.grid(pady=5, row=0, column=2, sticky=W) name_label = Label(root, text=\u0026#34;Enter Name\u0026#34;, font=(\u0026#34;Helvetica\u0026#34;, 12)) name_label.grid(padx=5, row=1, column=0, sticky=E) age_label = Label(root, text=\u0026#34;Enter Age\u0026#34;, font=(\u0026#34;Helvetica\u0026#34;, 12)) age_label.grid(padx=5, row=2, column=0, sticky=E) tshirt_label = Label(root, text=\u0026#34;T-shirt Size\u0026#34;, font=(\u0026#34;Helvetica\u0026#34;, 12)) tshirt_label.grid(padx=5, row=4, column=0, sticky=E, pady=5) name_entry = Entry(root, width=40) name_entry.insert(END, \u0026#34;Jane Doe\u0026#34;) name_entry.grid(row=1, column=1, columnspan=3) age_entry = Entry(root, width=40) age_entry.grid(row=2, column=1, columnspan=3) sizes_radios = [] sizes_choices = [\u0026#34;S\u0026#34;, \u0026#34;M\u0026#34;, \u0026#34;L\u0026#34;, \u0026#34;XL\u0026#34;, \u0026#34;XXL\u0026#34;] data = StringVar() for i, option in enumerate(sizes_choices): curr_button = Radiobutton(root, text=str(option), variable=data, value=i) sizes_radios += [curr_button] sizes_radios[i].grid(row=i + 5, column=1, sticky=W) submit_button = Button(root, text=\u0026#34;Submit\u0026#34;, command=greeting) submit_button.grid(row=10, column=3, sticky=E) def greeting(): messagebox.showinfo(\u0026#34;Welcome!\u0026#34;, \u0026#34;Successfully Registered for the Race!\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: root = Tk() root.geometry(\u0026#34;455x280\u0026#34;) root.title(\u0026#34;Tkinter Tutorial\u0026#34;) main_window(root) root.mainloop() "
},
{
	"uri": "/python/foundation/additional-resources/tkinter-labs/",
	"title": "Tkinter Lab",
	"tags": [],
	"description": "",
	"content": "GitHub GUI The goto way of working with GitHub is to work in the terminal. This is a great way for a user to fully understand how Git and GitHub work. If a user does not need to know any nitty-gritty details about Git, a GUI is a great option. In this lab, we are going to create a GUI for GitHub using Tkinter and command line commands.\nIn this lab, you will start with placing the following starter files in the :\n Follow the instructions in the TODO\u0026rsquo;s. After you complete the tasks, you should have a GUI that successfully will do add, commit, push, and pull commands.\n "
}]